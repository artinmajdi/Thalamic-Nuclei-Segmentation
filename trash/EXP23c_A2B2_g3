2019-07-28 13:51:00.665296: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-28 13:51:02.483015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:09:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-28 13:51:02.483065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 13:51:02.858449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 13:51:02.858498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 13:51:02.858511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 13:51:02.858969: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:36,  1.22it/s]Loading train:   1%|          | 2/266 [00:01<03:22,  1.31it/s]Loading train:   1%|          | 3/266 [00:01<02:57,  1.48it/s]Loading train:   2%|▏         | 4/266 [00:02<02:47,  1.56it/s]Loading train:   2%|▏         | 5/266 [00:03<02:40,  1.63it/s]Loading train:   2%|▏         | 6/266 [00:03<02:42,  1.60it/s]Loading train:   3%|▎         | 7/266 [00:04<02:38,  1.63it/s]Loading train:   3%|▎         | 8/266 [00:04<02:33,  1.68it/s]Loading train:   3%|▎         | 9/266 [00:05<02:28,  1.73it/s]Loading train:   4%|▍         | 10/266 [00:05<02:30,  1.70it/s]Loading train:   4%|▍         | 11/266 [00:06<02:33,  1.67it/s]Loading train:   5%|▍         | 12/266 [00:07<02:34,  1.65it/s]Loading train:   5%|▍         | 13/266 [00:07<02:30,  1.68it/s]Loading train:   5%|▌         | 14/266 [00:08<02:35,  1.62it/s]Loading train:   6%|▌         | 15/266 [00:09<02:30,  1.67it/s]Loading train:   6%|▌         | 16/266 [00:09<02:25,  1.72it/s]Loading train:   6%|▋         | 17/266 [00:10<02:22,  1.75it/s]Loading train:   7%|▋         | 18/266 [00:10<02:29,  1.66it/s]Loading train:   7%|▋         | 19/266 [00:11<02:42,  1.52it/s]Loading train:   8%|▊         | 20/266 [00:12<02:43,  1.51it/s]Loading train:   8%|▊         | 21/266 [00:12<02:40,  1.52it/s]Loading train:   8%|▊         | 22/266 [00:13<02:38,  1.54it/s]Loading train:   9%|▊         | 23/266 [00:14<02:31,  1.61it/s]Loading train:   9%|▉         | 24/266 [00:14<02:29,  1.62it/s]Loading train:   9%|▉         | 25/266 [00:15<02:30,  1.60it/s]Loading train:  10%|▉         | 26/266 [00:15<02:27,  1.63it/s]Loading train:  10%|█         | 27/266 [00:16<02:30,  1.59it/s]Loading train:  11%|█         | 28/266 [00:17<02:20,  1.69it/s]Loading train:  11%|█         | 29/266 [00:17<02:20,  1.69it/s]Loading train:  11%|█▏        | 30/266 [00:18<02:25,  1.62it/s]Loading train:  12%|█▏        | 31/266 [00:18<02:22,  1.65it/s]Loading train:  12%|█▏        | 32/266 [00:19<02:15,  1.72it/s]Loading train:  12%|█▏        | 33/266 [00:20<02:13,  1.75it/s]Loading train:  13%|█▎        | 34/266 [00:20<02:13,  1.74it/s]Loading train:  13%|█▎        | 35/266 [00:21<02:16,  1.70it/s]Loading train:  14%|█▎        | 36/266 [00:21<02:18,  1.66it/s]Loading train:  14%|█▍        | 37/266 [00:22<02:17,  1.67it/s]Loading train:  14%|█▍        | 38/266 [00:23<02:34,  1.47it/s]Loading train:  15%|█▍        | 39/266 [00:24<02:36,  1.45it/s]Loading train:  15%|█▌        | 40/266 [00:24<02:35,  1.46it/s]Loading train:  15%|█▌        | 41/266 [00:25<02:28,  1.51it/s]Loading train:  16%|█▌        | 42/266 [00:25<02:23,  1.56it/s]Loading train:  16%|█▌        | 43/266 [00:26<02:20,  1.59it/s]Loading train:  17%|█▋        | 44/266 [00:27<02:14,  1.65it/s]Loading train:  17%|█▋        | 45/266 [00:27<02:09,  1.70it/s]Loading train:  17%|█▋        | 46/266 [00:28<02:08,  1.71it/s]Loading train:  18%|█▊        | 47/266 [00:28<02:05,  1.75it/s]Loading train:  18%|█▊        | 48/266 [00:29<02:03,  1.77it/s]Loading train:  18%|█▊        | 49/266 [00:29<02:01,  1.79it/s]Loading train:  19%|█▉        | 50/266 [00:30<02:01,  1.77it/s]Loading train:  19%|█▉        | 51/266 [00:30<01:57,  1.83it/s]Loading train:  20%|█▉        | 52/266 [00:31<01:51,  1.92it/s]Loading train:  20%|█▉        | 53/266 [00:31<01:58,  1.80it/s]Loading train:  20%|██        | 54/266 [00:32<01:59,  1.77it/s]Loading train:  21%|██        | 55/266 [00:33<01:58,  1.78it/s]Loading train:  21%|██        | 56/266 [00:33<01:53,  1.85it/s]Loading train:  21%|██▏       | 57/266 [00:34<01:48,  1.93it/s]Loading train:  22%|██▏       | 58/266 [00:34<01:43,  2.02it/s]Loading train:  22%|██▏       | 59/266 [00:35<01:43,  1.99it/s]Loading train:  23%|██▎       | 60/266 [00:35<01:37,  2.12it/s]Loading train:  23%|██▎       | 61/266 [00:35<01:41,  2.02it/s]Loading train:  23%|██▎       | 62/266 [00:36<01:41,  2.02it/s]Loading train:  24%|██▎       | 63/266 [00:37<01:42,  1.97it/s]Loading train:  24%|██▍       | 64/266 [00:37<01:47,  1.87it/s]Loading train:  24%|██▍       | 65/266 [00:38<01:44,  1.93it/s]Loading train:  25%|██▍       | 66/266 [00:38<01:43,  1.93it/s]Loading train:  25%|██▌       | 67/266 [00:39<01:46,  1.87it/s]Loading train:  26%|██▌       | 68/266 [00:39<01:43,  1.91it/s]Loading train:  26%|██▌       | 69/266 [00:40<01:48,  1.82it/s]Loading train:  26%|██▋       | 70/266 [00:40<01:46,  1.84it/s]Loading train:  27%|██▋       | 71/266 [00:41<01:41,  1.92it/s]Loading train:  27%|██▋       | 72/266 [00:41<01:39,  1.95it/s]Loading train:  27%|██▋       | 73/266 [00:42<01:41,  1.89it/s]Loading train:  28%|██▊       | 74/266 [00:42<01:40,  1.90it/s]Loading train:  28%|██▊       | 75/266 [00:43<01:40,  1.91it/s]Loading train:  29%|██▊       | 76/266 [00:43<01:39,  1.91it/s]Loading train:  29%|██▉       | 77/266 [00:44<01:35,  1.97it/s]Loading train:  29%|██▉       | 78/266 [00:44<01:39,  1.89it/s]Loading train:  30%|██▉       | 79/266 [00:45<01:41,  1.85it/s]Loading train:  30%|███       | 80/266 [00:46<01:43,  1.79it/s]Loading train:  30%|███       | 81/266 [00:46<01:43,  1.78it/s]Loading train:  31%|███       | 82/266 [00:47<01:43,  1.78it/s]Loading train:  31%|███       | 83/266 [00:47<01:45,  1.74it/s]Loading train:  32%|███▏      | 84/266 [00:48<01:47,  1.69it/s]Loading train:  32%|███▏      | 85/266 [00:49<01:46,  1.69it/s]Loading train:  32%|███▏      | 86/266 [00:49<01:44,  1.72it/s]Loading train:  33%|███▎      | 87/266 [00:50<01:42,  1.75it/s]Loading train:  33%|███▎      | 88/266 [00:50<01:44,  1.70it/s]Loading train:  33%|███▎      | 89/266 [00:51<01:44,  1.70it/s]Loading train:  34%|███▍      | 90/266 [00:51<01:43,  1.71it/s]Loading train:  34%|███▍      | 91/266 [00:52<01:40,  1.74it/s]Loading train:  35%|███▍      | 92/266 [00:53<01:43,  1.68it/s]Loading train:  35%|███▍      | 93/266 [00:53<01:39,  1.73it/s]Loading train:  35%|███▌      | 94/266 [00:54<01:37,  1.76it/s]Loading train:  36%|███▌      | 95/266 [00:54<01:34,  1.82it/s]Loading train:  36%|███▌      | 96/266 [00:55<01:31,  1.85it/s]Loading train:  36%|███▋      | 97/266 [00:55<01:33,  1.82it/s]Loading train:  37%|███▋      | 98/266 [00:56<01:33,  1.80it/s]Loading train:  37%|███▋      | 99/266 [00:56<01:29,  1.86it/s]Loading train:  38%|███▊      | 100/266 [00:57<01:29,  1.85it/s]Loading train:  38%|███▊      | 101/266 [00:57<01:27,  1.88it/s]Loading train:  38%|███▊      | 102/266 [00:58<01:29,  1.83it/s]Loading train:  39%|███▊      | 103/266 [00:59<01:31,  1.78it/s]Loading train:  39%|███▉      | 104/266 [00:59<01:27,  1.85it/s]Loading train:  39%|███▉      | 105/266 [01:00<01:25,  1.87it/s]Loading train:  40%|███▉      | 106/266 [01:00<01:28,  1.81it/s]Loading train:  40%|████      | 107/266 [01:01<01:26,  1.83it/s]Loading train:  41%|████      | 108/266 [01:01<01:25,  1.85it/s]Loading train:  41%|████      | 109/266 [01:02<01:21,  1.94it/s]Loading train:  41%|████▏     | 110/266 [01:02<01:18,  1.98it/s]Loading train:  42%|████▏     | 111/266 [01:03<01:17,  1.99it/s]Loading train:  42%|████▏     | 112/266 [01:03<01:19,  1.94it/s]Loading train:  42%|████▏     | 113/266 [01:04<01:18,  1.95it/s]Loading train:  43%|████▎     | 114/266 [01:04<01:15,  2.01it/s]Loading train:  43%|████▎     | 115/266 [01:05<01:16,  1.97it/s]Loading train:  44%|████▎     | 116/266 [01:05<01:16,  1.97it/s]Loading train:  44%|████▍     | 117/266 [01:06<01:17,  1.93it/s]Loading train:  44%|████▍     | 118/266 [01:06<01:17,  1.91it/s]Loading train:  45%|████▍     | 119/266 [01:07<01:18,  1.87it/s]Loading train:  45%|████▌     | 120/266 [01:08<01:18,  1.86it/s]Loading train:  45%|████▌     | 121/266 [01:08<01:19,  1.83it/s]Loading train:  46%|████▌     | 122/266 [01:09<01:19,  1.82it/s]Loading train:  46%|████▌     | 123/266 [01:09<01:20,  1.77it/s]Loading train:  47%|████▋     | 124/266 [01:10<01:23,  1.69it/s]Loading train:  47%|████▋     | 125/266 [01:11<01:24,  1.66it/s]Loading train:  47%|████▋     | 126/266 [01:11<01:26,  1.62it/s]Loading train:  48%|████▊     | 127/266 [01:12<01:25,  1.62it/s]Loading train:  48%|████▊     | 128/266 [01:12<01:21,  1.69it/s]Loading train:  48%|████▊     | 129/266 [01:13<01:19,  1.73it/s]Loading train:  49%|████▉     | 130/266 [01:14<01:21,  1.66it/s]Loading train:  49%|████▉     | 131/266 [01:14<01:31,  1.48it/s]Loading train:  50%|████▉     | 132/266 [01:15<01:28,  1.51it/s]Loading train:  50%|█████     | 133/266 [01:16<01:22,  1.61it/s]Loading train:  50%|█████     | 134/266 [01:16<01:18,  1.68it/s]Loading train:  51%|█████     | 135/266 [01:17<01:14,  1.75it/s]Loading train:  51%|█████     | 136/266 [01:17<01:16,  1.69it/s]Loading train:  52%|█████▏    | 137/266 [01:18<01:13,  1.74it/s]Loading train:  52%|█████▏    | 138/266 [01:18<01:09,  1.83it/s]Loading train:  52%|█████▏    | 139/266 [01:19<01:06,  1.91it/s]Loading train:  53%|█████▎    | 140/266 [01:19<01:07,  1.86it/s]Loading train:  53%|█████▎    | 141/266 [01:20<01:09,  1.81it/s]Loading train:  53%|█████▎    | 142/266 [01:21<01:12,  1.71it/s]Loading train:  54%|█████▍    | 143/266 [01:21<01:12,  1.69it/s]Loading train:  54%|█████▍    | 144/266 [01:22<01:14,  1.65it/s]Loading train:  55%|█████▍    | 145/266 [01:22<01:15,  1.60it/s]Loading train:  55%|█████▍    | 146/266 [01:23<01:12,  1.66it/s]Loading train:  55%|█████▌    | 147/266 [01:24<01:14,  1.59it/s]Loading train:  56%|█████▌    | 148/266 [01:25<01:23,  1.42it/s]Loading train:  56%|█████▌    | 149/266 [01:26<01:37,  1.21it/s]Loading train:  56%|█████▋    | 150/266 [01:27<01:51,  1.04it/s]Loading train:  57%|█████▋    | 151/266 [01:28<01:58,  1.03s/it]Loading train:  57%|█████▋    | 152/266 [01:30<02:18,  1.21s/it]Loading train:  58%|█████▊    | 153/266 [01:32<02:58,  1.58s/it]Loading train:  58%|█████▊    | 154/266 [01:34<03:13,  1.73s/it]Loading train:  58%|█████▊    | 155/266 [01:37<03:36,  1.95s/it]Loading train:  59%|█████▊    | 156/266 [01:39<03:43,  2.03s/it]Loading train:  59%|█████▉    | 157/266 [01:40<03:24,  1.88s/it]Loading train:  59%|█████▉    | 158/266 [01:41<02:38,  1.47s/it]Loading train:  60%|█████▉    | 159/266 [01:41<02:02,  1.14s/it]Loading train:  60%|██████    | 160/266 [01:42<01:41,  1.04it/s]Loading train:  61%|██████    | 161/266 [01:42<01:24,  1.24it/s]Loading train:  61%|██████    | 162/266 [01:43<01:15,  1.38it/s]Loading train:  61%|██████▏   | 163/266 [01:43<01:06,  1.54it/s]Loading train:  62%|██████▏   | 164/266 [01:44<00:58,  1.75it/s]Loading train:  62%|██████▏   | 165/266 [01:44<00:53,  1.89it/s]Loading train:  62%|██████▏   | 166/266 [01:45<00:53,  1.87it/s]Loading train:  63%|██████▎   | 167/266 [01:45<00:52,  1.89it/s]Loading train:  63%|██████▎   | 168/266 [01:46<00:49,  1.98it/s]Loading train:  64%|██████▎   | 169/266 [01:46<00:47,  2.03it/s]Loading train:  64%|██████▍   | 170/266 [01:47<00:48,  2.00it/s]Loading train:  64%|██████▍   | 171/266 [01:47<00:47,  1.98it/s]Loading train:  65%|██████▍   | 172/266 [01:48<00:45,  2.07it/s]Loading train:  65%|██████▌   | 173/266 [01:48<00:44,  2.11it/s]Loading train:  65%|██████▌   | 174/266 [01:49<00:45,  2.03it/s]Loading train:  66%|██████▌   | 175/266 [01:49<00:47,  1.93it/s]Loading train:  66%|██████▌   | 176/266 [01:50<00:48,  1.84it/s]Loading train:  67%|██████▋   | 177/266 [01:50<00:46,  1.90it/s]Loading train:  67%|██████▋   | 178/266 [01:51<00:45,  1.93it/s]Loading train:  67%|██████▋   | 179/266 [01:51<00:41,  2.08it/s]Loading train:  68%|██████▊   | 180/266 [01:52<00:43,  1.96it/s]Loading train:  68%|██████▊   | 181/266 [01:52<00:43,  1.96it/s]Loading train:  68%|██████▊   | 182/266 [01:53<00:44,  1.89it/s]Loading train:  69%|██████▉   | 183/266 [01:53<00:44,  1.88it/s]Loading train:  69%|██████▉   | 184/266 [01:54<00:42,  1.93it/s]Loading train:  70%|██████▉   | 185/266 [01:54<00:42,  1.90it/s]Loading train:  70%|██████▉   | 186/266 [01:55<00:42,  1.90it/s]Loading train:  70%|███████   | 187/266 [01:56<00:42,  1.84it/s]Loading train:  71%|███████   | 188/266 [01:56<00:40,  1.91it/s]Loading train:  71%|███████   | 189/266 [01:57<00:39,  1.94it/s]Loading train:  71%|███████▏  | 190/266 [01:57<00:38,  1.97it/s]Loading train:  72%|███████▏  | 191/266 [01:58<00:38,  1.93it/s]Loading train:  72%|███████▏  | 192/266 [01:58<00:37,  2.00it/s]Loading train:  73%|███████▎  | 193/266 [01:59<00:37,  1.96it/s]Loading train:  73%|███████▎  | 194/266 [01:59<00:37,  1.92it/s]Loading train:  73%|███████▎  | 195/266 [02:00<00:36,  1.92it/s]Loading train:  74%|███████▎  | 196/266 [02:00<00:38,  1.82it/s]Loading train:  74%|███████▍  | 197/266 [02:01<00:37,  1.85it/s]Loading train:  74%|███████▍  | 198/266 [02:01<00:36,  1.86it/s]Loading train:  75%|███████▍  | 199/266 [02:02<00:35,  1.89it/s]Loading train:  75%|███████▌  | 200/266 [02:02<00:35,  1.87it/s]Loading train:  76%|███████▌  | 201/266 [02:03<00:34,  1.86it/s]Loading train:  76%|███████▌  | 202/266 [02:03<00:34,  1.87it/s]Loading train:  76%|███████▋  | 203/266 [02:04<00:34,  1.84it/s]Loading train:  77%|███████▋  | 204/266 [02:05<00:34,  1.82it/s]Loading train:  77%|███████▋  | 205/266 [02:05<00:34,  1.75it/s]Loading train:  77%|███████▋  | 206/266 [02:06<00:34,  1.76it/s]Loading train:  78%|███████▊  | 207/266 [02:06<00:34,  1.73it/s]Loading train:  78%|███████▊  | 208/266 [02:07<00:33,  1.75it/s]Loading train:  79%|███████▊  | 209/266 [02:07<00:32,  1.75it/s]Loading train:  79%|███████▉  | 210/266 [02:08<00:31,  1.80it/s]Loading train:  79%|███████▉  | 211/266 [02:09<00:30,  1.79it/s]Loading train:  80%|███████▉  | 212/266 [02:09<00:28,  1.86it/s]Loading train:  80%|████████  | 213/266 [02:10<00:29,  1.79it/s]Loading train:  80%|████████  | 214/266 [02:10<00:29,  1.74it/s]Loading train:  81%|████████  | 215/266 [02:11<00:29,  1.73it/s]Loading train:  81%|████████  | 216/266 [02:11<00:27,  1.83it/s]Loading train:  82%|████████▏ | 217/266 [02:12<00:25,  1.90it/s]Loading train:  82%|████████▏ | 218/266 [02:12<00:24,  1.95it/s]Loading train:  82%|████████▏ | 219/266 [02:13<00:23,  2.01it/s]Loading train:  83%|████████▎ | 220/266 [02:13<00:23,  1.94it/s]Loading train:  83%|████████▎ | 221/266 [02:14<00:23,  1.93it/s]Loading train:  83%|████████▎ | 222/266 [02:14<00:22,  1.95it/s]Loading train:  84%|████████▍ | 223/266 [02:15<00:21,  1.99it/s]Loading train:  84%|████████▍ | 224/266 [02:15<00:21,  1.99it/s]Loading train:  85%|████████▍ | 225/266 [02:16<00:20,  1.97it/s]Loading train:  85%|████████▍ | 226/266 [02:17<00:24,  1.61it/s]Loading train:  85%|████████▌ | 227/266 [02:17<00:23,  1.70it/s]Loading train:  86%|████████▌ | 228/266 [02:18<00:22,  1.67it/s]Loading train:  86%|████████▌ | 229/266 [02:19<00:23,  1.56it/s]Loading train:  86%|████████▋ | 230/266 [02:20<00:35,  1.02it/s]Loading train:  87%|████████▋ | 231/266 [02:23<00:48,  1.39s/it]Loading train:  87%|████████▋ | 232/266 [02:26<01:03,  1.86s/it]Loading train:  88%|████████▊ | 233/266 [02:28<01:08,  2.07s/it]Loading train:  88%|████████▊ | 234/266 [02:30<01:03,  1.99s/it]Loading train:  88%|████████▊ | 235/266 [02:31<00:56,  1.81s/it]Loading train:  89%|████████▊ | 236/266 [02:33<00:53,  1.80s/it]Loading train:  89%|████████▉ | 237/266 [02:36<00:58,  2.01s/it]Loading train:  89%|████████▉ | 238/266 [02:38<00:58,  2.10s/it]Loading train:  90%|████████▉ | 239/266 [02:39<00:45,  1.68s/it]Loading train:  90%|█████████ | 240/266 [02:39<00:34,  1.34s/it]Loading train:  91%|█████████ | 241/266 [02:40<00:27,  1.08s/it]Loading train:  91%|█████████ | 242/266 [02:40<00:21,  1.10it/s]Loading train:  91%|█████████▏| 243/266 [02:41<00:18,  1.25it/s]Loading train:  92%|█████████▏| 244/266 [02:41<00:16,  1.32it/s]Loading train:  92%|█████████▏| 245/266 [02:42<00:15,  1.39it/s]Loading train:  92%|█████████▏| 246/266 [02:43<00:13,  1.50it/s]Loading train:  93%|█████████▎| 247/266 [02:43<00:12,  1.58it/s]Loading train:  93%|█████████▎| 248/266 [02:44<00:11,  1.60it/s]Loading train:  94%|█████████▎| 249/266 [02:44<00:09,  1.73it/s]Loading train:  94%|█████████▍| 250/266 [02:45<00:09,  1.65it/s]Loading train:  94%|█████████▍| 251/266 [02:46<00:09,  1.61it/s]Loading train:  95%|█████████▍| 252/266 [02:46<00:08,  1.62it/s]Loading train:  95%|█████████▌| 253/266 [02:47<00:07,  1.71it/s]Loading train:  95%|█████████▌| 254/266 [02:47<00:07,  1.69it/s]Loading train:  96%|█████████▌| 255/266 [02:48<00:06,  1.67it/s]Loading train:  96%|█████████▌| 256/266 [02:49<00:06,  1.61it/s]Loading train:  97%|█████████▋| 257/266 [02:49<00:05,  1.70it/s]Loading train:  97%|█████████▋| 258/266 [02:50<00:05,  1.59it/s]Loading train:  97%|█████████▋| 259/266 [02:50<00:04,  1.60it/s]Loading train:  98%|█████████▊| 260/266 [02:51<00:03,  1.62it/s]Loading train:  98%|█████████▊| 261/266 [02:52<00:03,  1.59it/s]Loading train:  98%|█████████▊| 262/266 [02:52<00:02,  1.57it/s]Loading train:  99%|█████████▉| 263/266 [02:53<00:02,  1.41it/s]Loading train:  99%|█████████▉| 264/266 [02:54<00:01,  1.41it/s]Loading train: 100%|█████████▉| 265/266 [02:55<00:00,  1.45it/s]Loading train: 100%|██████████| 266/266 [02:55<00:00,  1.54it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:27,  9.71it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:20, 12.47it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:15, 16.33it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:11, 21.02it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:09, 26.06it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:07, 31.86it/s]concatenating: train:  15%|█▍        | 39/266 [00:00<00:06, 37.28it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:05, 40.79it/s]concatenating: train:  19%|█▉        | 51/266 [00:00<00:04, 45.12it/s]concatenating: train:  22%|██▏       | 58/266 [00:01<00:04, 49.23it/s]concatenating: train:  24%|██▍       | 64/266 [00:01<00:03, 52.03it/s]concatenating: train:  27%|██▋       | 71/266 [00:01<00:03, 54.78it/s]concatenating: train:  29%|██▉       | 77/266 [00:01<00:03, 54.41it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:03, 56.61it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:03, 56.93it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 55.88it/s]concatenating: train:  38%|███▊      | 102/266 [00:01<00:02, 55.17it/s]concatenating: train:  41%|████      | 108/266 [00:02<00:03, 45.72it/s]concatenating: train:  42%|████▏     | 113/266 [00:02<00:03, 46.36it/s]concatenating: train:  44%|████▍     | 118/266 [00:02<00:03, 43.94it/s]concatenating: train:  46%|████▌     | 123/266 [00:02<00:03, 41.47it/s]concatenating: train:  49%|████▉     | 130/266 [00:02<00:02, 46.13it/s]concatenating: train:  52%|█████▏    | 137/266 [00:02<00:02, 50.07it/s]concatenating: train:  54%|█████▍    | 143/266 [00:02<00:02, 47.82it/s]concatenating: train:  56%|█████▌    | 149/266 [00:02<00:02, 48.76it/s]concatenating: train:  59%|█████▊    | 156/266 [00:02<00:02, 52.68it/s]concatenating: train:  61%|██████    | 162/266 [00:03<00:01, 53.51it/s]concatenating: train:  64%|██████▍   | 170/266 [00:03<00:01, 57.87it/s]concatenating: train:  66%|██████▌   | 176/266 [00:03<00:01, 56.55it/s]concatenating: train:  68%|██████▊   | 182/266 [00:03<00:01, 50.01it/s]concatenating: train:  71%|███████   | 188/266 [00:03<00:01, 52.09it/s]concatenating: train:  73%|███████▎  | 194/266 [00:03<00:01, 45.79it/s]concatenating: train:  76%|███████▌  | 201/266 [00:03<00:01, 48.99it/s]concatenating: train:  78%|███████▊  | 207/266 [00:04<00:01, 43.79it/s]concatenating: train:  80%|████████  | 213/266 [00:04<00:01, 46.64it/s]concatenating: train:  82%|████████▏ | 218/266 [00:04<00:01, 44.98it/s]concatenating: train:  85%|████████▍ | 225/266 [00:04<00:00, 49.11it/s]concatenating: train:  87%|████████▋ | 231/266 [00:04<00:00, 49.39it/s]concatenating: train:  90%|█████████ | 240/266 [00:04<00:00, 56.68it/s]concatenating: train:  93%|█████████▎| 247/266 [00:04<00:00, 41.66it/s]concatenating: train:  95%|█████████▌| 253/266 [00:04<00:00, 44.63it/s]concatenating: train:  98%|█████████▊| 260/266 [00:05<00:00, 48.82it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 49.18it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  1.63it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.76it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  1.80it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.74it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation:  25%|██▌       | 1/4 [00:00<00:00,  9.06it/s]concatenating: validation:  75%|███████▌  | 3/4 [00:00<00:00,  9.37it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00,  9.75it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<03:39,  1.21it/s]Loading trainS:   1%|          | 2/266 [00:01<03:39,  1.20it/s]Loading trainS:   1%|          | 3/266 [00:02<03:20,  1.31it/s]Loading trainS:   2%|▏         | 4/266 [00:02<02:56,  1.48it/s]Loading trainS:   2%|▏         | 5/266 [00:03<02:58,  1.47it/s]Loading trainS:   2%|▏         | 6/266 [00:04<02:57,  1.46it/s]Loading trainS:   3%|▎         | 7/266 [00:04<02:50,  1.52it/s]Loading trainS:   3%|▎         | 8/266 [00:05<02:44,  1.56it/s]Loading trainS:   3%|▎         | 9/266 [00:05<02:43,  1.58it/s]Loading trainS:   4%|▍         | 10/266 [00:06<02:35,  1.65it/s]Loading trainS:   4%|▍         | 11/266 [00:07<02:29,  1.71it/s]Loading trainS:   5%|▍         | 12/266 [00:07<02:29,  1.70it/s]Loading trainS:   5%|▍         | 13/266 [00:08<02:26,  1.73it/s]Loading trainS:   5%|▌         | 14/266 [00:08<02:30,  1.67it/s]Loading trainS:   6%|▌         | 15/266 [00:09<02:20,  1.79it/s]Loading trainS:   6%|▌         | 16/266 [00:09<02:30,  1.67it/s]Loading trainS:   6%|▋         | 17/266 [00:10<02:35,  1.60it/s]Loading trainS:   7%|▋         | 18/266 [00:11<02:39,  1.55it/s]Loading trainS:   7%|▋         | 19/266 [00:11<02:39,  1.55it/s]Loading trainS:   8%|▊         | 20/266 [00:12<02:31,  1.62it/s]Loading trainS:   8%|▊         | 21/266 [00:13<02:35,  1.58it/s]Loading trainS:   8%|▊         | 22/266 [00:14<02:54,  1.40it/s]Loading trainS:   9%|▊         | 23/266 [00:14<02:45,  1.47it/s]Loading trainS:   9%|▉         | 24/266 [00:16<03:31,  1.15it/s]Loading trainS:   9%|▉         | 25/266 [00:17<03:59,  1.01it/s]Loading trainS:  10%|▉         | 26/266 [00:18<03:46,  1.06it/s]Loading trainS:  10%|█         | 27/266 [00:18<03:27,  1.15it/s]Loading trainS:  11%|█         | 28/266 [00:19<03:02,  1.30it/s]Loading trainS:  11%|█         | 29/266 [00:20<02:58,  1.33it/s]Loading trainS:  11%|█▏        | 30/266 [00:20<02:46,  1.42it/s]Loading trainS:  12%|█▏        | 31/266 [00:21<02:37,  1.50it/s]Loading trainS:  12%|█▏        | 32/266 [00:21<02:29,  1.57it/s]Loading trainS:  12%|█▏        | 33/266 [00:22<02:29,  1.56it/s]Loading trainS:  13%|█▎        | 34/266 [00:23<02:23,  1.61it/s]Loading trainS:  13%|█▎        | 35/266 [00:24<03:06,  1.24it/s]Loading trainS:  14%|█▎        | 36/266 [00:25<03:07,  1.22it/s]Loading trainS:  14%|█▍        | 37/266 [00:25<02:55,  1.31it/s]Loading trainS:  14%|█▍        | 38/266 [00:26<02:36,  1.45it/s]Loading trainS:  15%|█▍        | 39/266 [00:26<02:33,  1.47it/s]Loading trainS:  15%|█▌        | 40/266 [00:27<02:30,  1.51it/s]Loading trainS:  15%|█▌        | 41/266 [00:28<02:26,  1.53it/s]Loading trainS:  16%|█▌        | 42/266 [00:28<02:18,  1.62it/s]Loading trainS:  16%|█▌        | 43/266 [00:29<02:18,  1.61it/s]Loading trainS:  17%|█▋        | 44/266 [00:29<02:11,  1.69it/s]Loading trainS:  17%|█▋        | 45/266 [00:30<02:11,  1.68it/s]Loading trainS:  17%|█▋        | 46/266 [00:31<02:07,  1.72it/s]Loading trainS:  18%|█▊        | 47/266 [00:31<02:07,  1.72it/s]Loading trainS:  18%|█▊        | 48/266 [00:32<01:58,  1.83it/s]Loading trainS:  18%|█▊        | 49/266 [00:32<01:51,  1.95it/s]Loading trainS:  19%|█▉        | 50/266 [00:32<01:48,  2.00it/s]Loading trainS:  19%|█▉        | 51/266 [00:33<02:17,  1.56it/s]Loading trainS:  20%|█▉        | 52/266 [00:34<02:09,  1.66it/s]Loading trainS:  20%|█▉        | 53/266 [00:36<03:37,  1.02s/it]Loading trainS:  20%|██        | 54/266 [00:38<05:10,  1.47s/it]Loading trainS:  21%|██        | 55/266 [00:41<06:39,  1.89s/it]Loading trainS:  21%|██        | 56/266 [00:42<05:15,  1.50s/it]Loading trainS:  21%|██▏       | 57/266 [00:44<05:31,  1.59s/it]Loading trainS:  22%|██▏       | 58/266 [00:46<05:41,  1.64s/it]Loading trainS:  22%|██▏       | 59/266 [00:46<04:38,  1.34s/it]Loading trainS:  23%|██▎       | 60/266 [00:48<05:29,  1.60s/it]Loading trainS:  23%|██▎       | 61/266 [00:50<05:21,  1.57s/it]Loading trainS:  23%|██▎       | 62/266 [00:50<04:22,  1.28s/it]Loading trainS:  24%|██▎       | 63/266 [00:52<04:46,  1.41s/it]Loading trainS:  24%|██▍       | 64/266 [00:54<04:42,  1.40s/it]Loading trainS:  24%|██▍       | 65/266 [00:55<05:09,  1.54s/it]Loading trainS:  25%|██▍       | 66/266 [00:56<04:29,  1.35s/it]Loading trainS:  25%|██▌       | 67/266 [00:58<04:42,  1.42s/it]Loading trainS:  26%|██▌       | 68/266 [00:59<04:39,  1.41s/it]Loading trainS:  26%|██▌       | 69/266 [01:01<05:21,  1.63s/it]Loading trainS:  26%|██▋       | 70/266 [01:04<06:08,  1.88s/it]Loading trainS:  27%|██▋       | 71/266 [01:06<05:58,  1.84s/it]Loading trainS:  27%|██▋       | 72/266 [01:07<05:21,  1.66s/it]Loading trainS:  27%|██▋       | 73/266 [01:09<05:59,  1.87s/it]Loading trainS:  28%|██▊       | 74/266 [01:11<05:36,  1.75s/it]Loading trainS:  28%|██▊       | 75/266 [01:13<06:12,  1.95s/it]Loading trainS:  29%|██▊       | 76/266 [01:15<06:28,  2.04s/it]Loading trainS:  29%|██▉       | 77/266 [01:18<06:46,  2.15s/it]Loading trainS:  29%|██▉       | 78/266 [01:20<07:07,  2.28s/it]Loading trainS:  30%|██▉       | 79/266 [01:23<07:15,  2.33s/it]Loading trainS:  30%|███       | 80/266 [01:24<06:08,  1.98s/it]Loading trainS:  30%|███       | 81/266 [01:25<05:08,  1.67s/it]Loading trainS:  31%|███       | 82/266 [01:26<04:51,  1.58s/it]Loading trainS:  31%|███       | 83/266 [01:28<04:55,  1.61s/it]Loading trainS:  32%|███▏      | 84/266 [01:30<05:02,  1.66s/it]Loading trainS:  32%|███▏      | 85/266 [01:31<04:52,  1.61s/it]Loading trainS:  32%|███▏      | 86/266 [01:33<04:37,  1.54s/it]Loading trainS:  33%|███▎      | 87/266 [01:34<04:25,  1.49s/it]Loading trainS:  33%|███▎      | 88/266 [01:35<03:44,  1.26s/it]Loading trainS:  33%|███▎      | 89/266 [01:35<03:06,  1.05s/it]Loading trainS:  34%|███▍      | 90/266 [01:36<02:38,  1.11it/s]Loading trainS:  34%|███▍      | 91/266 [01:36<02:15,  1.29it/s]Loading trainS:  35%|███▍      | 92/266 [01:37<02:05,  1.39it/s]Loading trainS:  35%|███▍      | 93/266 [01:38<02:00,  1.44it/s]Loading trainS:  35%|███▌      | 94/266 [01:38<01:58,  1.46it/s]Loading trainS:  36%|███▌      | 95/266 [01:39<01:51,  1.53it/s]Loading trainS:  36%|███▌      | 96/266 [01:39<01:45,  1.62it/s]Loading trainS:  36%|███▋      | 97/266 [01:40<01:41,  1.66it/s]Loading trainS:  37%|███▋      | 98/266 [01:41<01:49,  1.54it/s]Loading trainS:  37%|███▋      | 99/266 [01:41<01:39,  1.68it/s]Loading trainS:  38%|███▊      | 100/266 [01:42<01:35,  1.73it/s]Loading trainS:  38%|███▊      | 101/266 [01:42<01:35,  1.73it/s]Loading trainS:  38%|███▊      | 102/266 [01:43<01:31,  1.79it/s]Loading trainS:  39%|███▊      | 103/266 [01:43<01:29,  1.82it/s]Loading trainS:  39%|███▉      | 104/266 [01:44<01:29,  1.81it/s]Loading trainS:  39%|███▉      | 105/266 [01:44<01:27,  1.83it/s]Loading trainS:  40%|███▉      | 106/266 [01:45<01:30,  1.77it/s]Loading trainS:  40%|████      | 107/266 [01:46<01:35,  1.67it/s]Loading trainS:  41%|████      | 108/266 [01:46<01:31,  1.72it/s]Loading trainS:  41%|████      | 109/266 [01:47<01:36,  1.62it/s]Loading trainS:  41%|████▏     | 110/266 [01:47<01:34,  1.64it/s]Loading trainS:  42%|████▏     | 111/266 [01:48<01:30,  1.72it/s]Loading trainS:  42%|████▏     | 112/266 [01:49<01:26,  1.78it/s]Loading trainS:  42%|████▏     | 113/266 [01:49<01:22,  1.85it/s]Loading trainS:  43%|████▎     | 114/266 [01:50<01:28,  1.73it/s]Loading trainS:  43%|████▎     | 115/266 [01:51<01:38,  1.54it/s]Loading trainS:  44%|████▎     | 116/266 [01:51<01:32,  1.62it/s]Loading trainS:  44%|████▍     | 117/266 [01:52<01:33,  1.59it/s]Loading trainS:  44%|████▍     | 118/266 [01:52<01:33,  1.58it/s]Loading trainS:  45%|████▍     | 119/266 [01:53<01:30,  1.63it/s]Loading trainS:  45%|████▌     | 120/266 [01:53<01:28,  1.65it/s]Loading trainS:  45%|████▌     | 121/266 [01:54<01:25,  1.70it/s]Loading trainS:  46%|████▌     | 122/266 [01:54<01:17,  1.87it/s]Loading trainS:  46%|████▌     | 123/266 [01:55<01:13,  1.94it/s]Loading trainS:  47%|████▋     | 124/266 [01:55<01:08,  2.08it/s]Loading trainS:  47%|████▋     | 125/266 [01:56<01:09,  2.04it/s]Loading trainS:  47%|████▋     | 126/266 [01:56<01:06,  2.10it/s]Loading trainS:  48%|████▊     | 127/266 [01:57<01:05,  2.13it/s]Loading trainS:  48%|████▊     | 128/266 [01:57<01:07,  2.05it/s]Loading trainS:  48%|████▊     | 129/266 [01:58<01:08,  2.00it/s]Loading trainS:  49%|████▉     | 130/266 [01:58<01:09,  1.96it/s]Loading trainS:  49%|████▉     | 131/266 [01:59<01:13,  1.83it/s]Loading trainS:  50%|████▉     | 132/266 [01:59<01:12,  1.85it/s]Loading trainS:  50%|█████     | 133/266 [02:00<01:12,  1.83it/s]Loading trainS:  50%|█████     | 134/266 [02:01<01:28,  1.48it/s]Loading trainS:  51%|█████     | 135/266 [02:02<01:26,  1.52it/s]Loading trainS:  51%|█████     | 136/266 [02:03<01:35,  1.36it/s]Loading trainS:  52%|█████▏    | 137/266 [02:03<01:28,  1.46it/s]Loading trainS:  52%|█████▏    | 138/266 [02:04<01:24,  1.51it/s]Loading trainS:  52%|█████▏    | 139/266 [02:04<01:21,  1.55it/s]Loading trainS:  53%|█████▎    | 140/266 [02:05<01:19,  1.58it/s]Loading trainS:  53%|█████▎    | 141/266 [02:05<01:10,  1.77it/s]Loading trainS:  53%|█████▎    | 142/266 [02:06<01:14,  1.66it/s]Loading trainS:  54%|█████▍    | 143/266 [02:07<01:45,  1.17it/s]Loading trainS:  54%|█████▍    | 144/266 [02:08<01:28,  1.37it/s]Loading trainS:  55%|█████▍    | 145/266 [02:08<01:15,  1.60it/s]Loading trainS:  55%|█████▍    | 146/266 [02:09<01:05,  1.83it/s]Loading trainS:  55%|█████▌    | 147/266 [02:09<01:04,  1.86it/s]Loading trainS:  56%|█████▌    | 148/266 [02:10<01:00,  1.94it/s]Loading trainS:  56%|█████▌    | 149/266 [02:10<00:53,  2.18it/s]Loading trainS:  56%|█████▋    | 150/266 [02:10<00:48,  2.41it/s]Loading trainS:  57%|█████▋    | 151/266 [02:11<00:44,  2.59it/s]Loading trainS:  57%|█████▋    | 152/266 [02:11<00:48,  2.34it/s]Loading trainS:  58%|█████▊    | 153/266 [02:12<00:51,  2.21it/s]Loading trainS:  58%|█████▊    | 154/266 [02:12<00:47,  2.35it/s]Loading trainS:  58%|█████▊    | 155/266 [02:12<00:42,  2.59it/s]Loading trainS:  59%|█████▊    | 156/266 [02:13<00:38,  2.88it/s]Loading trainS:  59%|█████▉    | 157/266 [02:13<00:38,  2.84it/s]Loading trainS:  59%|█████▉    | 158/266 [02:13<00:39,  2.75it/s]Loading trainS:  60%|█████▉    | 159/266 [02:14<00:37,  2.82it/s]Loading trainS:  60%|██████    | 160/266 [02:14<00:36,  2.89it/s]Loading trainS:  61%|██████    | 161/266 [02:14<00:39,  2.66it/s]Loading trainS:  61%|██████    | 162/266 [02:15<00:49,  2.08it/s]Loading trainS:  61%|██████▏   | 163/266 [02:15<00:43,  2.35it/s]Loading trainS:  62%|██████▏   | 164/266 [02:16<00:38,  2.66it/s]Loading trainS:  62%|██████▏   | 165/266 [02:16<00:37,  2.72it/s]Loading trainS:  62%|██████▏   | 166/266 [02:16<00:34,  2.91it/s]Loading trainS:  63%|██████▎   | 167/266 [02:17<00:48,  2.06it/s]Loading trainS:  63%|██████▎   | 168/266 [02:18<01:03,  1.54it/s]Loading trainS:  64%|██████▎   | 169/266 [02:20<01:34,  1.02it/s]Loading trainS:  64%|██████▍   | 170/266 [02:21<01:48,  1.13s/it]Loading trainS:  64%|██████▍   | 171/266 [02:22<01:41,  1.07s/it]Loading trainS:  65%|██████▍   | 172/266 [02:24<01:55,  1.23s/it]Loading trainS:  65%|██████▌   | 173/266 [02:24<01:32,  1.00it/s]Loading trainS:  65%|██████▌   | 174/266 [02:26<01:41,  1.11s/it]Loading trainS:  66%|██████▌   | 175/266 [02:27<01:45,  1.16s/it]Loading trainS:  66%|██████▌   | 176/266 [02:28<01:43,  1.15s/it]Loading trainS:  67%|██████▋   | 177/266 [02:29<01:40,  1.13s/it]Loading trainS:  67%|██████▋   | 178/266 [02:30<01:20,  1.10it/s]Loading trainS:  67%|██████▋   | 179/266 [02:30<01:16,  1.13it/s]Loading trainS:  68%|██████▊   | 180/266 [02:31<01:13,  1.17it/s]Loading trainS:  68%|██████▊   | 181/266 [02:32<01:19,  1.06it/s]Loading trainS:  68%|██████▊   | 182/266 [02:33<01:17,  1.08it/s]Loading trainS:  69%|██████▉   | 183/266 [02:35<01:26,  1.04s/it]Loading trainS:  69%|██████▉   | 184/266 [02:35<01:11,  1.15it/s]Loading trainS:  70%|██████▉   | 185/266 [02:36<01:14,  1.08it/s]Loading trainS:  70%|██████▉   | 186/266 [02:36<00:59,  1.34it/s]Loading trainS:  70%|███████   | 187/266 [02:37<01:03,  1.25it/s]Loading trainS:  71%|███████   | 188/266 [02:38<00:55,  1.39it/s]Loading trainS:  71%|███████   | 189/266 [02:39<00:57,  1.34it/s]Loading trainS:  71%|███████▏  | 190/266 [02:40<00:58,  1.30it/s]Loading trainS:  72%|███████▏  | 191/266 [02:40<00:51,  1.45it/s]Loading trainS:  72%|███████▏  | 192/266 [02:41<00:46,  1.60it/s]Loading trainS:  73%|███████▎  | 193/266 [02:41<00:47,  1.54it/s]Loading trainS:  73%|███████▎  | 194/266 [02:42<00:48,  1.49it/s]Loading trainS:  73%|███████▎  | 195/266 [02:43<00:55,  1.29it/s]Loading trainS:  74%|███████▎  | 196/266 [02:44<00:50,  1.37it/s]Loading trainS:  74%|███████▍  | 197/266 [02:44<00:48,  1.44it/s]Loading trainS:  74%|███████▍  | 198/266 [02:45<00:39,  1.71it/s]Loading trainS:  75%|███████▍  | 199/266 [02:46<00:49,  1.36it/s]Loading trainS:  75%|███████▌  | 200/266 [02:46<00:41,  1.60it/s]Loading trainS:  76%|███████▌  | 201/266 [02:47<00:47,  1.36it/s]Loading trainS:  76%|███████▌  | 202/266 [02:47<00:39,  1.62it/s]Loading trainS:  76%|███████▋  | 203/266 [02:48<00:41,  1.50it/s]Loading trainS:  77%|███████▋  | 204/266 [02:49<00:37,  1.64it/s]Loading trainS:  77%|███████▋  | 205/266 [02:49<00:35,  1.71it/s]Loading trainS:  77%|███████▋  | 206/266 [02:50<00:34,  1.74it/s]Loading trainS:  78%|███████▊  | 207/266 [02:50<00:35,  1.68it/s]Loading trainS:  78%|███████▊  | 208/266 [02:51<00:29,  1.98it/s]Loading trainS:  79%|███████▊  | 209/266 [02:51<00:25,  2.21it/s]Loading trainS:  79%|███████▉  | 210/266 [02:52<00:35,  1.56it/s]Loading trainS:  79%|███████▉  | 211/266 [02:52<00:31,  1.77it/s]Loading trainS:  80%|███████▉  | 212/266 [02:53<00:35,  1.50it/s]Loading trainS:  80%|████████  | 213/266 [02:54<00:39,  1.33it/s]Loading trainS:  80%|████████  | 214/266 [02:55<00:32,  1.61it/s]Loading trainS:  81%|████████  | 215/266 [02:56<00:42,  1.21it/s]Loading trainS:  81%|████████  | 216/266 [02:57<00:46,  1.07it/s]Loading trainS:  82%|████████▏ | 217/266 [02:58<00:44,  1.11it/s]Loading trainS:  82%|████████▏ | 218/266 [02:59<00:46,  1.03it/s]Loading trainS:  82%|████████▏ | 219/266 [02:59<00:36,  1.29it/s]Loading trainS:  83%|████████▎ | 220/266 [03:00<00:29,  1.55it/s]Loading trainS:  83%|████████▎ | 221/266 [03:01<00:36,  1.23it/s]Loading trainS:  83%|████████▎ | 222/266 [03:02<00:34,  1.26it/s]Loading trainS:  84%|████████▍ | 223/266 [03:02<00:31,  1.36it/s]Loading trainS:  84%|████████▍ | 224/266 [03:03<00:26,  1.57it/s]Loading trainS:  85%|████████▍ | 225/266 [03:04<00:35,  1.17it/s]Loading trainS:  85%|████████▍ | 226/266 [03:05<00:34,  1.17it/s]Loading trainS:  85%|████████▌ | 227/266 [03:06<00:38,  1.02it/s]Loading trainS:  86%|████████▌ | 228/266 [03:07<00:34,  1.09it/s]Loading trainS:  86%|████████▌ | 229/266 [03:09<00:45,  1.24s/it]Loading trainS:  86%|████████▋ | 230/266 [03:10<00:45,  1.27s/it]Loading trainS:  87%|████████▋ | 231/266 [03:11<00:36,  1.05s/it]Loading trainS:  87%|████████▋ | 232/266 [03:11<00:28,  1.18it/s]Loading trainS:  88%|████████▊ | 233/266 [03:12<00:23,  1.38it/s]Loading trainS:  88%|████████▊ | 234/266 [03:12<00:20,  1.56it/s]Loading trainS:  88%|████████▊ | 235/266 [03:12<00:16,  1.85it/s]Loading trainS:  89%|████████▊ | 236/266 [03:13<00:14,  2.11it/s]Loading trainS:  89%|████████▉ | 237/266 [03:13<00:12,  2.38it/s]Loading trainS:  89%|████████▉ | 238/266 [03:13<00:11,  2.42it/s]Loading trainS:  90%|████████▉ | 239/266 [03:14<00:10,  2.53it/s]Loading trainS:  90%|█████████ | 240/266 [03:14<00:09,  2.61it/s]Loading trainS:  91%|█████████ | 241/266 [03:15<00:10,  2.29it/s]Loading trainS:  91%|█████████ | 242/266 [03:15<00:10,  2.25it/s]Loading trainS:  91%|█████████▏| 243/266 [03:15<00:09,  2.37it/s]Loading trainS:  92%|█████████▏| 244/266 [03:16<00:09,  2.33it/s]Loading trainS:  92%|█████████▏| 245/266 [03:16<00:09,  2.25it/s]Loading trainS:  92%|█████████▏| 246/266 [03:17<00:08,  2.41it/s]Loading trainS:  93%|█████████▎| 247/266 [03:17<00:07,  2.53it/s]Loading trainS:  93%|█████████▎| 248/266 [03:17<00:07,  2.57it/s]Loading trainS:  94%|█████████▎| 249/266 [03:18<00:07,  2.43it/s]Loading trainS:  94%|█████████▍| 250/266 [03:18<00:07,  2.25it/s]Loading trainS:  94%|█████████▍| 251/266 [03:19<00:06,  2.39it/s]Loading trainS:  95%|█████████▍| 252/266 [03:19<00:05,  2.49it/s]Loading trainS:  95%|█████████▌| 253/266 [03:20<00:05,  2.34it/s]Loading trainS:  95%|█████████▌| 254/266 [03:20<00:05,  2.17it/s]Loading trainS:  96%|█████████▌| 255/266 [03:21<00:04,  2.22it/s]Loading trainS:  96%|█████████▌| 256/266 [03:21<00:04,  2.32it/s]Loading trainS:  97%|█████████▋| 257/266 [03:21<00:03,  2.38it/s]Loading trainS:  97%|█████████▋| 258/266 [03:22<00:03,  2.29it/s]Loading trainS:  97%|█████████▋| 259/266 [03:22<00:03,  2.15it/s]Loading trainS:  98%|█████████▊| 260/266 [03:23<00:02,  2.08it/s]Loading trainS:  98%|█████████▊| 261/266 [03:23<00:02,  2.06it/s]Loading trainS:  98%|█████████▊| 262/266 [03:24<00:01,  2.04it/s]Loading trainS:  99%|█████████▉| 263/266 [03:24<00:01,  2.11it/s]Loading trainS:  99%|█████████▉| 264/266 [03:25<00:00,  2.05it/s]Loading trainS: 100%|█████████▉| 265/266 [03:25<00:00,  2.06it/s]Loading trainS: 100%|██████████| 266/266 [03:26<00:00,  2.05it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  2.44it/s]Loading testS:  50%|█████     | 2/4 [00:00<00:00,  2.39it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  2.47it/s]Loading testS: 100%|██████████| 4/4 [00:01<00:00,  2.34it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.01it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.92it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.57it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.08it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.21it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.10it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.26it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.57it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:07,  3.52it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:05,  4.42it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  4.62it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  6.03it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.75it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:04<00:01,  7.51it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:01,  6.56it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  8.28it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.90it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:05<00:01,  4.16it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:01,  3.86it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  3.34it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.69it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 10) 100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 10) 40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 10) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 108, 116, 10) 0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 10) 910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 10) 40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 10) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 108, 116, 10) 0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 108, 116, 11) 0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 108, 116, 20) 2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 108, 116, 20) 80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 108, 116, 20) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 108, 116, 20) 3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 108, 116, 20) 80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 108, 116, 20) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 54, 58, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 54, 58, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 58, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 54, 58, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 54, 58, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 58, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 54, 58, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 27, 29, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 27, 29, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 27, 29, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 27, 29, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 27, 29, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 27, 29, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 27, 29, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 27, 29, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 54, 58, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 58, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 54, 58, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 54, 58, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 54, 58, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 58, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 54, 58, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 20) 7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 108, 116, 20) 80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 108, 116, 20) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 108, 116, 20) 3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 108, 116, 20) 80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 108, 116, 20) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 108, 116, 60) 0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 108, 116, 60) 0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 108, 116, 10) 5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 108, 116, 10) 40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 108, 116, 10) 0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 108, 116, 10) 0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 108, 116, 10) 910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 108, 116, 10) 40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 108, 116, 10) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 108, 116, 10) 0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 108, 116, 70) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 108, 116, 2)  142         concatenate_8[0][0]              
==================================================================================================
Total params: 232,472
Trainable params: 57,712
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 256 samples
Epoch 1/300
 - 61s - loss: 0.4469 - acc: 0.8894 - mDice: 0.5989 - val_loss: 0.4794 - val_acc: 0.9786 - val_mDice: 0.6591

Epoch 00001: val_mDice improved from -inf to 0.65910, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 47s - loss: 0.0965 - acc: 0.9902 - mDice: 0.8316 - val_loss: 0.3381 - val_acc: 0.9910 - val_mDice: 0.7660

Epoch 00002: val_mDice improved from 0.65910 to 0.76603, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 51s - loss: 0.0796 - acc: 0.9915 - mDice: 0.8579 - val_loss: 0.3468 - val_acc: 0.9899 - val_mDice: 0.7835

Epoch 00003: val_mDice improved from 0.76603 to 0.78354, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 48s - loss: 0.0713 - acc: 0.9922 - mDice: 0.8715 - val_loss: 0.2397 - val_acc: 0.9926 - val_mDice: 0.8245

Epoch 00004: val_mDice improved from 0.78354 to 0.82452, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 51s - loss: 0.0662 - acc: 0.9927 - mDice: 0.8800 - val_loss: 0.3005 - val_acc: 0.9920 - val_mDice: 0.8192

Epoch 00005: val_mDice did not improve from 0.82452
Epoch 6/300
 - 47s - loss: 0.0631 - acc: 0.9930 - mDice: 0.8851 - val_loss: 0.2908 - val_acc: 0.9920 - val_mDice: 0.8176

Epoch 00006: val_mDice did not improve from 0.82452
Epoch 7/300
 - 54s - loss: 0.0607 - acc: 0.9932 - mDice: 0.8892 - val_loss: 0.2017 - val_acc: 0.9936 - val_mDice: 0.8330

Epoch 00007: val_mDice improved from 0.82452 to 0.83297, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 48s - loss: 0.0596 - acc: 0.9933 - mDice: 0.8911 - val_loss: 0.2186 - val_acc: 0.9922 - val_mDice: 0.8207

Epoch 00008: val_mDice did not improve from 0.83297
Epoch 9/300
 - 48s - loss: 0.0576 - acc: 0.9935 - mDice: 0.8946 - val_loss: 0.1974 - val_acc: 0.9937 - val_mDice: 0.8439

Epoch 00009: val_mDice improved from 0.83297 to 0.84393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 53s - loss: 0.0560 - acc: 0.9937 - mDice: 0.8972 - val_loss: 0.1835 - val_acc: 0.9939 - val_mDice: 0.8465

Epoch 00010: val_mDice improved from 0.84393 to 0.84650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 48s - loss: 0.0545 - acc: 0.9938 - mDice: 0.8998 - val_loss: 0.1980 - val_acc: 0.9937 - val_mDice: 0.8449

Epoch 00011: val_mDice did not improve from 0.84650
Epoch 12/300
 - 48s - loss: 0.0541 - acc: 0.9938 - mDice: 0.9006 - val_loss: 0.2384 - val_acc: 0.9929 - val_mDice: 0.8101

Epoch 00012: val_mDice did not improve from 0.84650
Epoch 13/300
 - 48s - loss: 0.0530 - acc: 0.9939 - mDice: 0.9025 - val_loss: 0.3238 - val_acc: 0.9921 - val_mDice: 0.8266

Epoch 00013: val_mDice did not improve from 0.84650
Epoch 14/300
 - 49s - loss: 0.0518 - acc: 0.9940 - mDice: 0.9045 - val_loss: 0.2052 - val_acc: 0.9928 - val_mDice: 0.8070

Epoch 00014: val_mDice did not improve from 0.84650
Epoch 15/300
 - 49s - loss: 0.0507 - acc: 0.9941 - mDice: 0.9065 - val_loss: 0.1825 - val_acc: 0.9933 - val_mDice: 0.8427

Epoch 00015: val_mDice did not improve from 0.84650
Epoch 16/300
 - 49s - loss: 0.0502 - acc: 0.9942 - mDice: 0.9073 - val_loss: 0.1766 - val_acc: 0.9935 - val_mDice: 0.8450

Epoch 00016: val_mDice did not improve from 0.84650
Epoch 17/300
 - 49s - loss: 0.0502 - acc: 0.9942 - mDice: 0.9073 - val_loss: 0.1854 - val_acc: 0.9940 - val_mDice: 0.8552

Epoch 00017: val_mDice improved from 0.84650 to 0.85518, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 48s - loss: 0.0487 - acc: 0.9943 - mDice: 0.9099 - val_loss: 0.3577 - val_acc: 0.9903 - val_mDice: 0.8047

Epoch 00018: val_mDice did not improve from 0.85518
Epoch 19/300
 - 49s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9082 - val_loss: 0.1819 - val_acc: 0.9940 - val_mDice: 0.8544

Epoch 00019: val_mDice did not improve from 0.85518
Epoch 20/300
 - 48s - loss: 0.0476 - acc: 0.9944 - mDice: 0.9120 - val_loss: 0.1746 - val_acc: 0.9942 - val_mDice: 0.8537

Epoch 00020: val_mDice did not improve from 0.85518
Epoch 21/300
 - 50s - loss: 0.0469 - acc: 0.9945 - mDice: 0.9132 - val_loss: 0.1854 - val_acc: 0.9941 - val_mDice: 0.8577

Epoch 00021: val_mDice improved from 0.85518 to 0.85769, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 51s - loss: 0.0460 - acc: 0.9946 - mDice: 0.9148 - val_loss: 0.3181 - val_acc: 0.9927 - val_mDice: 0.8414

Epoch 00022: val_mDice did not improve from 0.85769
Epoch 23/300
 - 48s - loss: 0.0456 - acc: 0.9946 - mDice: 0.9154 - val_loss: 0.4181 - val_acc: 0.9881 - val_mDice: 0.5869

Epoch 00023: val_mDice did not improve from 0.85769
Epoch 24/300
 - 53s - loss: 0.0453 - acc: 0.9947 - mDice: 0.9160 - val_loss: 0.1607 - val_acc: 0.9941 - val_mDice: 0.8526

Epoch 00024: val_mDice did not improve from 0.85769
Epoch 25/300
 - 47s - loss: 0.0446 - acc: 0.9947 - mDice: 0.9172 - val_loss: 0.1644 - val_acc: 0.9936 - val_mDice: 0.8521

Epoch 00025: val_mDice did not improve from 0.85769
Epoch 26/300
 - 47s - loss: 0.0445 - acc: 0.9947 - mDice: 0.9174 - val_loss: 0.1731 - val_acc: 0.9937 - val_mDice: 0.8362

Epoch 00026: val_mDice did not improve from 0.85769
Epoch 27/300
 - 47s - loss: 0.0437 - acc: 0.9948 - mDice: 0.9189 - val_loss: 0.3456 - val_acc: 0.9907 - val_mDice: 0.8071

Epoch 00027: val_mDice did not improve from 0.85769
Epoch 28/300
 - 47s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9191 - val_loss: 0.1582 - val_acc: 0.9942 - val_mDice: 0.8527

Epoch 00028: val_mDice did not improve from 0.85769
Epoch 29/300
 - 46s - loss: 0.0431 - acc: 0.9949 - mDice: 0.9198 - val_loss: 0.1939 - val_acc: 0.9927 - val_mDice: 0.8397

Epoch 00029: val_mDice did not improve from 0.85769
Epoch 30/300
 - 46s - loss: 0.0424 - acc: 0.9949 - mDice: 0.9212 - val_loss: 0.1600 - val_acc: 0.9941 - val_mDice: 0.8487

Epoch 00030: val_mDice did not improve from 0.85769
Epoch 31/300
 - 47s - loss: 0.0421 - acc: 0.9949 - mDice: 0.9217 - val_loss: 0.1576 - val_acc: 0.9934 - val_mDice: 0.8438

Epoch 00031: val_mDice did not improve from 0.85769
Epoch 32/300
 - 47s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.1973 - val_acc: 0.9923 - val_mDice: 0.7917

Epoch 00032: val_mDice did not improve from 0.85769
Epoch 33/300
 - 47s - loss: 0.0417 - acc: 0.9950 - mDice: 0.9224 - val_loss: 0.3169 - val_acc: 0.9918 - val_mDice: 0.8230

Epoch 00033: val_mDice did not improve from 0.85769
Epoch 34/300
 - 46s - loss: 0.0417 - acc: 0.9950 - mDice: 0.9224 - val_loss: 0.1542 - val_acc: 0.9941 - val_mDice: 0.8520

Epoch 00034: val_mDice did not improve from 0.85769
Epoch 35/300
 - 47s - loss: 0.0409 - acc: 0.9950 - mDice: 0.9238 - val_loss: 0.1459 - val_acc: 0.9939 - val_mDice: 0.8556

Epoch 00035: val_mDice did not improve from 0.85769
Epoch 36/300
 - 47s - loss: 0.0408 - acc: 0.9951 - mDice: 0.9241 - val_loss: 0.1569 - val_acc: 0.9935 - val_mDice: 0.8316

Epoch 00036: val_mDice did not improve from 0.85769
Epoch 37/300
 - 48s - loss: 0.0405 - acc: 0.9951 - mDice: 0.9246 - val_loss: 0.1533 - val_acc: 0.9939 - val_mDice: 0.8519

Epoch 00037: val_mDice did not improve from 0.85769
Epoch 38/300
 - 47s - loss: 0.0404 - acc: 0.9951 - mDice: 0.9248 - val_loss: 0.1390 - val_acc: 0.9940 - val_mDice: 0.8510

Epoch 00038: val_mDice did not improve from 0.85769
Epoch 39/300
 - 48s - loss: 0.0399 - acc: 0.9951 - mDice: 0.9257 - val_loss: 0.1534 - val_acc: 0.9939 - val_mDice: 0.8534

Epoch 00039: val_mDice did not improve from 0.85769
Epoch 40/300
 - 47s - loss: 0.0400 - acc: 0.9952 - mDice: 0.9255 - val_loss: 0.1425 - val_acc: 0.9938 - val_mDice: 0.8511

Epoch 00040: val_mDice did not improve from 0.85769
Epoch 41/300
 - 48s - loss: 0.0395 - acc: 0.9952 - mDice: 0.9263 - val_loss: 0.1431 - val_acc: 0.9935 - val_mDice: 0.8367

Epoch 00041: val_mDice did not improve from 0.85769
Epoch 42/300
 - 48s - loss: 0.0397 - acc: 0.9952 - mDice: 0.9260 - val_loss: 0.2991 - val_acc: 0.9927 - val_mDice: 0.8369

Epoch 00042: val_mDice did not improve from 0.85769
Epoch 43/300
 - 47s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.1395 - val_acc: 0.9939 - val_mDice: 0.8504

Epoch 00043: val_mDice did not improve from 0.85769
Epoch 44/300
 - 47s - loss: 0.0392 - acc: 0.9952 - mDice: 0.9269 - val_loss: 0.1257 - val_acc: 0.9942 - val_mDice: 0.8561

Epoch 00044: val_mDice did not improve from 0.85769
Epoch 45/300
 - 47s - loss: 0.0390 - acc: 0.9953 - mDice: 0.9273 - val_loss: 0.1388 - val_acc: 0.9937 - val_mDice: 0.8446

Epoch 00045: val_mDice did not improve from 0.85769
Epoch 46/300
 - 47s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9276 - val_loss: 0.1368 - val_acc: 0.9940 - val_mDice: 0.8469

Epoch 00046: val_mDice did not improve from 0.85769
Epoch 47/300
 - 47s - loss: 0.0384 - acc: 0.9953 - mDice: 0.9284 - val_loss: 0.1220 - val_acc: 0.9940 - val_mDice: 0.8495

Epoch 00047: val_mDice did not improve from 0.85769
Epoch 48/300
 - 47s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9287 - val_loss: 0.1382 - val_acc: 0.9938 - val_mDice: 0.8526

Epoch 00048: val_mDice did not improve from 0.85769
Epoch 49/300
 - 47s - loss: 0.0385 - acc: 0.9953 - mDice: 0.9281 - val_loss: 0.2390 - val_acc: 0.9933 - val_mDice: 0.8436

Epoch 00049: val_mDice did not improve from 0.85769
Epoch 50/300
 - 47s - loss: 0.0380 - acc: 0.9954 - mDice: 0.9290 - val_loss: 0.1313 - val_acc: 0.9939 - val_mDice: 0.8491

Epoch 00050: val_mDice did not improve from 0.85769
Epoch 51/300
 - 47s - loss: 0.0378 - acc: 0.9954 - mDice: 0.9294 - val_loss: 0.1631 - val_acc: 0.9938 - val_mDice: 0.8497

Epoch 00051: val_mDice did not improve from 0.85769
Epoch 52/300
 - 47s - loss: 0.0375 - acc: 0.9954 - mDice: 0.9299 - val_loss: 0.1320 - val_acc: 0.9939 - val_mDice: 0.8472

Epoch 00052: val_mDice did not improve from 0.85769
Epoch 53/300
 - 48s - loss: 0.0378 - acc: 0.9954 - mDice: 0.9295 - val_loss: 0.1187 - val_acc: 0.9936 - val_mDice: 0.8501

Epoch 00053: val_mDice did not improve from 0.85769
Epoch 54/300
 - 48s - loss: 0.0373 - acc: 0.9954 - mDice: 0.9304 - val_loss: 0.1247 - val_acc: 0.9935 - val_mDice: 0.8443

Epoch 00054: val_mDice did not improve from 0.85769
Epoch 55/300
 - 47s - loss: 0.0378 - acc: 0.9954 - mDice: 0.9294 - val_loss: 0.1462 - val_acc: 0.9936 - val_mDice: 0.8499

Epoch 00055: val_mDice did not improve from 0.85769
Epoch 56/300
 - 48s - loss: 0.0373 - acc: 0.9954 - mDice: 0.9303 - val_loss: 0.2093 - val_acc: 0.9927 - val_mDice: 0.8379

Epoch 00056: val_mDice did not improve from 0.85769
Epoch 57/300
 - 49s - loss: 0.0369 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.1151 - val_acc: 0.9941 - val_mDice: 0.8529

Epoch 00057: val_mDice did not improve from 0.85769
Epoch 58/300
 - 48s - loss: 0.0367 - acc: 0.9955 - mDice: 0.9314 - val_loss: 0.1056 - val_acc: 0.9939 - val_mDice: 0.8529

Epoch 00058: val_mDice did not improve from 0.85769
Epoch 59/300
 - 49s - loss: 0.0370 - acc: 0.9955 - mDice: 0.9308 - val_loss: 0.1147 - val_acc: 0.9939 - val_mDice: 0.8508

Epoch 00059: val_mDice did not improve from 0.85769
Epoch 60/300
 - 49s - loss: 0.0369 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.0987 - val_acc: 0.9938 - val_mDice: 0.8449

Epoch 00060: val_mDice did not improve from 0.85769
Epoch 61/300
 - 52s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.2935 - val_acc: 0.9933 - val_mDice: 0.8447

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:06,  2.09s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:03,  1.61s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:01,  1.23s/it]predicting test subjects: 100%|██████████| 4/4 [00:03<00:00,  1.00s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<02:50,  1.55it/s]predicting train subjects:   1%|          | 2/266 [00:01<02:42,  1.62it/s]predicting train subjects:   1%|          | 3/266 [00:01<02:46,  1.58it/s]predicting train subjects:   2%|▏         | 4/266 [00:02<02:55,  1.49it/s]predicting train subjects:   2%|▏         | 5/266 [00:03<02:48,  1.55it/s]predicting train subjects:   2%|▏         | 6/266 [00:03<02:48,  1.55it/s]predicting train subjects:   3%|▎         | 7/266 [00:04<02:39,  1.62it/s]predicting train subjects:   3%|▎         | 8/266 [00:05<02:43,  1.58it/s]predicting train subjects:   3%|▎         | 9/266 [00:05<02:38,  1.62it/s]predicting train subjects:   4%|▍         | 10/266 [00:06<02:40,  1.60it/s]predicting train subjects:   4%|▍         | 11/266 [00:06<02:32,  1.67it/s]predicting train subjects:   5%|▍         | 12/266 [00:07<02:29,  1.70it/s]predicting train subjects:   5%|▍         | 13/266 [00:07<02:18,  1.82it/s]predicting train subjects:   5%|▌         | 14/266 [00:08<02:07,  1.98it/s]predicting train subjects:   6%|▌         | 15/266 [00:08<02:22,  1.76it/s]predicting train subjects:   6%|▌         | 16/266 [00:09<02:17,  1.82it/s]predicting train subjects:   6%|▋         | 17/266 [00:10<02:21,  1.76it/s]predicting train subjects:   7%|▋         | 18/266 [00:10<02:25,  1.71it/s]predicting train subjects:   7%|▋         | 19/266 [00:11<02:16,  1.81it/s]predicting train subjects:   8%|▊         | 20/266 [00:11<02:16,  1.80it/s]predicting train subjects:   8%|▊         | 21/266 [00:12<02:22,  1.72it/s]predicting train subjects:   8%|▊         | 22/266 [00:12<02:15,  1.81it/s]predicting train subjects:   9%|▊         | 23/266 [00:13<02:25,  1.67it/s]predicting train subjects:   9%|▉         | 24/266 [00:14<02:27,  1.64it/s]predicting train subjects:   9%|▉         | 25/266 [00:14<02:31,  1.59it/s]predicting train subjects:  10%|▉         | 26/266 [00:15<02:29,  1.60it/s]predicting train subjects:  10%|█         | 27/266 [00:16<02:23,  1.66it/s]predicting train subjects:  11%|█         | 28/266 [00:16<02:34,  1.55it/s]predicting train subjects:  11%|█         | 29/266 [00:17<02:20,  1.69it/s]predicting train subjects:  11%|█▏        | 30/266 [00:17<02:27,  1.60it/s]predicting train subjects:  12%|█▏        | 31/266 [00:18<02:14,  1.75it/s]predicting train subjects:  12%|█▏        | 32/266 [00:18<02:11,  1.77it/s]predicting train subjects:  12%|█▏        | 33/266 [00:19<02:07,  1.83it/s]predicting train subjects:  13%|█▎        | 34/266 [00:20<02:06,  1.83it/s]predicting train subjects:  13%|█▎        | 35/266 [00:20<02:10,  1.77it/s]predicting train subjects:  14%|█▎        | 36/266 [00:21<02:07,  1.81it/s]predicting train subjects:  14%|█▍        | 37/266 [00:21<02:04,  1.84it/s]predicting train subjects:  14%|█▍        | 38/266 [00:22<01:58,  1.92it/s]predicting train subjects:  15%|█▍        | 39/266 [00:22<02:04,  1.82it/s]predicting train subjects:  15%|█▌        | 40/266 [00:23<02:00,  1.88it/s]predicting train subjects:  15%|█▌        | 41/266 [00:23<02:02,  1.84it/s]predicting train subjects:  16%|█▌        | 42/266 [00:24<01:55,  1.93it/s]predicting train subjects:  16%|█▌        | 43/266 [00:24<01:52,  1.99it/s]predicting train subjects:  17%|█▋        | 44/266 [00:25<01:51,  2.00it/s]predicting train subjects:  17%|█▋        | 45/266 [00:25<01:54,  1.93it/s]predicting train subjects:  17%|█▋        | 46/266 [00:26<01:46,  2.07it/s]predicting train subjects:  18%|█▊        | 47/266 [00:26<01:42,  2.13it/s]predicting train subjects:  18%|█▊        | 48/266 [00:27<01:41,  2.15it/s]predicting train subjects:  18%|█▊        | 49/266 [00:27<01:58,  1.84it/s]predicting train subjects:  19%|█▉        | 50/266 [00:28<01:45,  2.05it/s]predicting train subjects:  19%|█▉        | 51/266 [00:28<01:34,  2.27it/s]predicting train subjects:  20%|█▉        | 52/266 [00:28<01:34,  2.26it/s]predicting train subjects:  20%|█▉        | 53/266 [00:29<01:30,  2.36it/s]predicting train subjects:  20%|██        | 54/266 [00:29<01:32,  2.30it/s]predicting train subjects:  21%|██        | 55/266 [00:30<01:30,  2.34it/s]predicting train subjects:  21%|██        | 56/266 [00:30<01:32,  2.28it/s]predicting train subjects:  21%|██▏       | 57/266 [00:31<01:47,  1.94it/s]predicting train subjects:  22%|██▏       | 58/266 [00:31<01:39,  2.08it/s]predicting train subjects:  22%|██▏       | 59/266 [00:32<01:40,  2.05it/s]predicting train subjects:  23%|██▎       | 60/266 [00:32<01:44,  1.98it/s]predicting train subjects:  23%|██▎       | 61/266 [00:33<01:32,  2.21it/s]predicting train subjects:  23%|██▎       | 62/266 [00:33<01:33,  2.18it/s]predicting train subjects:  24%|██▎       | 63/266 [00:34<01:53,  1.79it/s]predicting train subjects:  24%|██▍       | 64/266 [00:35<02:06,  1.59it/s]predicting train subjects:  24%|██▍       | 65/266 [00:35<01:52,  1.79it/s]predicting train subjects:  25%|██▍       | 66/266 [00:36<01:44,  1.92it/s]predicting train subjects:  25%|██▌       | 67/266 [00:36<01:36,  2.06it/s]predicting train subjects:  26%|██▌       | 68/266 [00:36<01:33,  2.12it/s]predicting train subjects:  26%|██▌       | 69/266 [00:37<01:29,  2.20it/s]predicting train subjects:  26%|██▋       | 70/266 [00:37<01:21,  2.39it/s]predicting train subjects:  27%|██▋       | 71/266 [00:38<01:28,  2.22it/s]predicting train subjects:  27%|██▋       | 72/266 [00:38<01:24,  2.30it/s]predicting train subjects:  27%|██▋       | 73/266 [00:38<01:21,  2.37it/s]predicting train subjects:  28%|██▊       | 74/266 [00:39<01:22,  2.33it/s]predicting train subjects:  28%|██▊       | 75/266 [00:39<01:24,  2.27it/s]predicting train subjects:  29%|██▊       | 76/266 [00:40<01:21,  2.35it/s]predicting train subjects:  29%|██▉       | 77/266 [00:40<01:19,  2.38it/s]predicting train subjects:  29%|██▉       | 78/266 [00:41<01:29,  2.10it/s]predicting train subjects:  30%|██▉       | 79/266 [00:41<01:33,  1.99it/s]predicting train subjects:  30%|███       | 80/266 [00:42<01:51,  1.67it/s]predicting train subjects:  30%|███       | 81/266 [00:43<01:54,  1.62it/s]predicting train subjects:  31%|███       | 82/266 [00:43<01:55,  1.60it/s]predicting train subjects:  31%|███       | 83/266 [00:44<01:48,  1.68it/s]predicting train subjects:  32%|███▏      | 84/266 [00:45<01:52,  1.62it/s]predicting train subjects:  32%|███▏      | 85/266 [00:45<01:44,  1.74it/s]predicting train subjects:  32%|███▏      | 86/266 [00:46<01:59,  1.50it/s]predicting train subjects:  33%|███▎      | 87/266 [00:47<02:06,  1.42it/s]predicting train subjects:  33%|███▎      | 88/266 [00:48<02:14,  1.32it/s]predicting train subjects:  33%|███▎      | 89/266 [00:49<02:24,  1.22it/s]predicting train subjects:  34%|███▍      | 90/266 [00:49<02:05,  1.41it/s]predicting train subjects:  34%|███▍      | 91/266 [00:50<02:22,  1.23it/s]predicting train subjects:  35%|███▍      | 92/266 [00:51<02:09,  1.34it/s]predicting train subjects:  35%|███▍      | 93/266 [00:51<02:04,  1.39it/s]predicting train subjects:  35%|███▌      | 94/266 [00:52<01:50,  1.55it/s]predicting train subjects:  36%|███▌      | 95/266 [00:52<01:46,  1.61it/s]predicting train subjects:  36%|███▌      | 96/266 [00:53<01:43,  1.65it/s]predicting train subjects:  36%|███▋      | 97/266 [00:54<01:41,  1.67it/s]predicting train subjects:  37%|███▋      | 98/266 [00:54<01:38,  1.71it/s]predicting train subjects:  37%|███▋      | 99/266 [00:55<01:36,  1.72it/s]predicting train subjects:  38%|███▊      | 100/266 [00:55<01:31,  1.81it/s]predicting train subjects:  38%|███▊      | 101/266 [00:56<01:34,  1.75it/s]predicting train subjects:  38%|███▊      | 102/266 [00:56<01:24,  1.94it/s]predicting train subjects:  39%|███▊      | 103/266 [00:57<01:29,  1.81it/s]predicting train subjects:  39%|███▉      | 104/266 [00:57<01:21,  1.98it/s]predicting train subjects:  39%|███▉      | 105/266 [00:58<01:24,  1.91it/s]predicting train subjects:  40%|███▉      | 106/266 [00:59<01:47,  1.49it/s]predicting train subjects:  40%|████      | 107/266 [00:59<01:38,  1.61it/s]predicting train subjects:  41%|████      | 108/266 [01:00<01:29,  1.77it/s]predicting train subjects:  41%|████      | 109/266 [01:00<01:20,  1.94it/s]predicting train subjects:  41%|████▏     | 110/266 [01:01<01:20,  1.94it/s]predicting train subjects:  42%|████▏     | 111/266 [01:01<01:16,  2.02it/s]predicting train subjects:  42%|████▏     | 112/266 [01:02<01:44,  1.48it/s]predicting train subjects:  42%|████▏     | 113/266 [01:03<01:38,  1.56it/s]predicting train subjects:  43%|████▎     | 114/266 [01:03<01:40,  1.52it/s]predicting train subjects:  43%|████▎     | 115/266 [01:04<01:40,  1.50it/s]predicting train subjects:  44%|████▎     | 116/266 [01:05<01:38,  1.53it/s]predicting train subjects:  44%|████▍     | 117/266 [01:05<01:38,  1.51it/s]predicting train subjects:  44%|████▍     | 118/266 [01:06<01:45,  1.40it/s]predicting train subjects:  45%|████▍     | 119/266 [01:07<01:48,  1.36it/s]predicting train subjects:  45%|████▌     | 120/266 [01:08<01:48,  1.34it/s]predicting train subjects:  45%|████▌     | 121/266 [01:08<01:41,  1.43it/s]predicting train subjects:  46%|████▌     | 122/266 [01:09<01:51,  1.29it/s]predicting train subjects:  46%|████▌     | 123/266 [01:10<02:04,  1.15it/s]predicting train subjects:  47%|████▋     | 124/266 [01:11<02:00,  1.18it/s]predicting train subjects:  47%|████▋     | 125/266 [01:12<01:45,  1.34it/s]predicting train subjects:  47%|████▋     | 126/266 [01:12<01:35,  1.46it/s]predicting train subjects:  48%|████▊     | 127/266 [01:13<01:32,  1.50it/s]predicting train subjects:  48%|████▊     | 128/266 [01:13<01:24,  1.64it/s]predicting train subjects:  48%|████▊     | 129/266 [01:14<01:22,  1.66it/s]predicting train subjects:  49%|████▉     | 130/266 [01:15<01:17,  1.77it/s]predicting train subjects:  49%|████▉     | 131/266 [01:15<01:16,  1.76it/s]predicting train subjects:  50%|████▉     | 132/266 [01:16<01:10,  1.89it/s]predicting train subjects:  50%|█████     | 133/266 [01:16<01:12,  1.83it/s]predicting train subjects:  50%|█████     | 134/266 [01:17<01:24,  1.56it/s]predicting train subjects:  51%|█████     | 135/266 [01:17<01:15,  1.74it/s]predicting train subjects:  51%|█████     | 136/266 [01:18<01:18,  1.67it/s]predicting train subjects:  52%|█████▏    | 137/266 [01:19<01:16,  1.69it/s]predicting train subjects:  52%|█████▏    | 138/266 [01:19<01:17,  1.65it/s]predicting train subjects:  52%|█████▏    | 139/266 [01:20<01:11,  1.78it/s]predicting train subjects:  53%|█████▎    | 140/266 [01:20<01:09,  1.80it/s]predicting train subjects:  53%|█████▎    | 141/266 [01:21<01:06,  1.88it/s]predicting train subjects:  53%|█████▎    | 142/266 [01:21<01:08,  1.82it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:22<01:07,  1.81it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:22<01:03,  1.92it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:23<01:01,  1.98it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:23<01:00,  1.98it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:24<01:03,  1.87it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:25<01:11,  1.66it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:25<01:13,  1.59it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:26<01:10,  1.65it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:26<01:06,  1.72it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:27<01:02,  1.83it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:27<01:01,  1.83it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:28<01:10,  1.60it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:29<01:11,  1.55it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:29<01:02,  1.77it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:30<01:00,  1.79it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:30<01:01,  1.76it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:31<00:55,  1.94it/s]predicting train subjects:  60%|██████    | 160/266 [01:31<00:54,  1.95it/s]predicting train subjects:  61%|██████    | 161/266 [01:32<00:56,  1.86it/s]predicting train subjects:  61%|██████    | 162/266 [01:32<00:54,  1.90it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:33<00:49,  2.08it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:33<00:51,  1.97it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:34<00:46,  2.18it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:35<01:01,  1.62it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:35<00:53,  1.86it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:35<00:47,  2.05it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:36<00:44,  2.16it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:36<00:43,  2.21it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:37<00:41,  2.29it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:37<00:51,  1.84it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:38<00:47,  1.97it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:38<00:48,  1.91it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:39<00:44,  2.04it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:39<00:43,  2.07it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:40<00:43,  2.04it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:40<00:43,  2.04it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:41<00:40,  2.15it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:41<00:45,  1.87it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:42<00:53,  1.60it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:43<00:47,  1.77it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:43<00:46,  1.79it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:44<00:44,  1.84it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:44<00:40,  1.99it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:45<00:40,  1.96it/s]predicting train subjects:  70%|███████   | 187/266 [01:45<00:38,  2.05it/s]predicting train subjects:  71%|███████   | 188/266 [01:46<00:40,  1.94it/s]predicting train subjects:  71%|███████   | 189/266 [01:46<00:39,  1.95it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:47<00:40,  1.86it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:47<00:40,  1.87it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:48<00:46,  1.58it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:49<00:41,  1.77it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:49<00:42,  1.71it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:50<00:38,  1.87it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:51<00:44,  1.57it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:51<00:40,  1.69it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:52<00:39,  1.72it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:52<00:40,  1.66it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:53<00:40,  1.64it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:54<00:44,  1.47it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:54<00:42,  1.50it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:55<00:36,  1.74it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:55<00:38,  1.62it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:56<00:34,  1.77it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:56<00:33,  1.81it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:57<00:32,  1.81it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:58<00:33,  1.71it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:58<00:33,  1.68it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:59<00:36,  1.53it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:59<00:32,  1.68it/s]predicting train subjects:  80%|███████▉  | 212/266 [02:00<00:32,  1.64it/s]predicting train subjects:  80%|████████  | 213/266 [02:01<00:37,  1.40it/s]predicting train subjects:  80%|████████  | 214/266 [02:02<00:39,  1.30it/s]predicting train subjects:  81%|████████  | 215/266 [02:03<00:39,  1.29it/s]predicting train subjects:  81%|████████  | 216/266 [02:03<00:34,  1.45it/s]predicting train subjects:  82%|████████▏ | 217/266 [02:04<00:31,  1.57it/s]predicting train subjects:  82%|████████▏ | 218/266 [02:04<00:30,  1.58it/s]predicting train subjects:  82%|████████▏ | 219/266 [02:05<00:27,  1.71it/s]predicting train subjects:  83%|████████▎ | 220/266 [02:05<00:27,  1.69it/s]predicting train subjects:  83%|████████▎ | 221/266 [02:06<00:26,  1.73it/s]predicting train subjects:  83%|████████▎ | 222/266 [02:07<00:25,  1.76it/s]predicting train subjects:  84%|████████▍ | 223/266 [02:07<00:25,  1.66it/s]predicting train subjects:  84%|████████▍ | 224/266 [02:08<00:22,  1.84it/s]predicting train subjects:  85%|████████▍ | 225/266 [02:08<00:21,  1.88it/s]predicting train subjects:  85%|████████▍ | 226/266 [02:09<00:20,  1.91it/s]predicting train subjects:  85%|████████▌ | 227/266 [02:09<00:20,  1.94it/s]predicting train subjects:  86%|████████▌ | 228/266 [02:10<00:20,  1.89it/s]predicting train subjects:  86%|████████▌ | 229/266 [02:11<00:23,  1.57it/s]predicting train subjects:  86%|████████▋ | 230/266 [02:11<00:23,  1.53it/s]predicting train subjects:  87%|████████▋ | 231/266 [02:12<00:20,  1.68it/s]predicting train subjects:  87%|████████▋ | 232/266 [02:12<00:18,  1.80it/s]predicting train subjects:  88%|████████▊ | 233/266 [02:13<00:17,  1.84it/s]predicting train subjects:  88%|████████▊ | 234/266 [02:13<00:18,  1.78it/s]predicting train subjects:  88%|████████▊ | 235/266 [02:14<00:17,  1.82it/s]predicting train subjects:  89%|████████▊ | 236/266 [02:14<00:15,  1.88it/s]predicting train subjects:  89%|████████▉ | 237/266 [02:15<00:14,  1.96it/s]predicting train subjects:  89%|████████▉ | 238/266 [02:15<00:13,  2.08it/s]predicting train subjects:  90%|████████▉ | 239/266 [02:16<00:12,  2.20it/s]predicting train subjects:  90%|█████████ | 240/266 [02:16<00:11,  2.26it/s]predicting train subjects:  91%|█████████ | 241/266 [02:17<00:11,  2.10it/s]predicting train subjects:  91%|█████████ | 242/266 [02:17<00:11,  2.16it/s]predicting train subjects:  91%|█████████▏| 243/266 [02:18<00:11,  2.08it/s]predicting train subjects:  92%|█████████▏| 244/266 [02:18<00:09,  2.21it/s]predicting train subjects:  92%|█████████▏| 245/266 [02:18<00:10,  2.03it/s]predicting train subjects:  92%|█████████▏| 246/266 [02:19<00:10,  1.97it/s]predicting train subjects:  93%|█████████▎| 247/266 [02:19<00:09,  2.02it/s]predicting train subjects:  93%|█████████▎| 248/266 [02:20<00:08,  2.02it/s]predicting train subjects:  94%|█████████▎| 249/266 [02:21<00:09,  1.84it/s]predicting train subjects:  94%|█████████▍| 250/266 [02:21<00:08,  1.87it/s]predicting train subjects:  94%|█████████▍| 251/266 [02:22<00:07,  1.94it/s]predicting train subjects:  95%|█████████▍| 252/266 [02:22<00:07,  1.79it/s]predicting train subjects:  95%|█████████▌| 253/266 [02:23<00:07,  1.74it/s]predicting train subjects:  95%|█████████▌| 254/266 [02:23<00:06,  1.75it/s]predicting train subjects:  96%|█████████▌| 255/266 [02:24<00:06,  1.73it/s]predicting train subjects:  96%|█████████▌| 256/266 [02:25<00:05,  1.76it/s]predicting train subjects:  97%|█████████▋| 257/266 [02:25<00:05,  1.76it/s]predicting train subjects:  97%|█████████▋| 258/266 [02:26<00:04,  1.78it/s]predicting train subjects:  97%|█████████▋| 259/266 [02:26<00:03,  1.86it/s]predicting train subjects:  98%|█████████▊| 260/266 [02:27<00:03,  1.82it/s]predicting train subjects:  98%|█████████▊| 261/266 [02:27<00:02,  1.88it/s]predicting train subjects:  98%|█████████▊| 262/266 [02:28<00:02,  1.89it/s]predicting train subjects:  99%|█████████▉| 263/266 [02:28<00:01,  1.95it/s]predicting train subjects:  99%|█████████▉| 264/266 [02:29<00:01,  1.88it/s]predicting train subjects: 100%|█████████▉| 265/266 [02:29<00:00,  1.83it/s]predicting train subjects: 100%|██████████| 266/266 [02:30<00:00,  1.82it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:01,  2.15it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  2.21it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:01<00:00,  2.34it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:01<00:00,  2.00it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<03:10,  1.39it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:01<02:54,  1.51it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<02:44,  1.60it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:02<02:29,  1.75it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:02<02:33,  1.70it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:03<02:36,  1.66it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:04<02:38,  1.64it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:04<02:34,  1.67it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:05<02:24,  1.78it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:06<02:49,  1.51it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:06<02:40,  1.59it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:07<02:38,  1.61it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:07<02:27,  1.72it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:08<02:30,  1.67it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:09<02:38,  1.58it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:09<02:34,  1.62it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:10<02:28,  1.67it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:10<02:37,  1.58it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:11<02:37,  1.57it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:13<03:42,  1.11it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:14<04:32,  1.11s/it]predicting train subjects sagittal:   8%|▊         | 22/266 [00:16<05:18,  1.31s/it]predicting train subjects sagittal:   9%|▊         | 23/266 [00:17<05:06,  1.26s/it]predicting train subjects sagittal:   9%|▉         | 24/266 [00:18<04:49,  1.20s/it]predicting train subjects sagittal:   9%|▉         | 25/266 [00:19<04:42,  1.17s/it]predicting train subjects sagittal:  10%|▉         | 26/266 [00:20<04:38,  1.16s/it]predicting train subjects sagittal:  10%|█         | 27/266 [00:21<04:25,  1.11s/it]predicting train subjects sagittal:  11%|█         | 28/266 [00:23<04:42,  1.19s/it]predicting train subjects sagittal:  11%|█         | 29/266 [00:24<04:45,  1.21s/it]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:25<04:41,  1.19s/it]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:26<03:53,  1.01it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:26<03:16,  1.19it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:27<02:50,  1.37it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:28<02:58,  1.30it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:28<02:40,  1.44it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:29<02:34,  1.48it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:29<02:31,  1.51it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:30<02:29,  1.52it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:31<02:30,  1.50it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:31<02:28,  1.52it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:32<02:15,  1.66it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:33<02:38,  1.41it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:33<02:18,  1.61it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:34<02:07,  1.74it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:34<02:19,  1.58it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:35<02:10,  1.69it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:35<02:06,  1.73it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:36<02:09,  1.68it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:37<02:05,  1.73it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:37<02:13,  1.62it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:38<02:08,  1.68it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:39<02:14,  1.59it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:39<02:06,  1.68it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:40<01:58,  1.79it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:40<02:01,  1.74it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:41<02:16,  1.54it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:41<02:09,  1.61it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:42<01:59,  1.74it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:43<02:39,  1.30it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:44<03:04,  1.12it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:46<03:21,  1.02it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:47<03:38,  1.07s/it]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:48<03:46,  1.12s/it]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:49<03:18,  1.02it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:49<02:56,  1.14it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:50<02:34,  1.29it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:50<02:22,  1.40it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:51<02:08,  1.55it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:52<02:04,  1.59it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:52<01:59,  1.64it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:53<01:50,  1.76it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:53<01:55,  1.67it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:54<02:26,  1.32it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:55<02:36,  1.22it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:56<02:22,  1.34it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:56<02:06,  1.51it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:57<02:14,  1.41it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:58<02:19,  1.34it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:58<02:02,  1.52it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:59<01:58,  1.57it/s]predicting train subjects sagittal:  30%|███       | 81/266 [01:00<02:01,  1.53it/s]predicting train subjects sagittal:  31%|███       | 82/266 [01:00<01:54,  1.61it/s]predicting train subjects sagittal:  31%|███       | 83/266 [01:01<02:13,  1.37it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [01:02<02:23,  1.27it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [01:03<02:28,  1.22it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [01:04<02:08,  1.40it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [01:04<01:51,  1.61it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [01:05<01:59,  1.49it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [01:05<01:47,  1.65it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [01:06<01:42,  1.71it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [01:06<01:35,  1.82it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [01:07<01:51,  1.56it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [01:08<01:45,  1.63it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [01:08<01:40,  1.71it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [01:09<01:41,  1.69it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [01:09<01:40,  1.69it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [01:10<01:57,  1.44it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [01:11<01:44,  1.60it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [01:11<01:36,  1.72it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [01:12<01:29,  1.85it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [01:12<01:31,  1.81it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [01:13<01:27,  1.88it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [01:13<01:26,  1.89it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [01:14<01:28,  1.82it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [01:14<01:29,  1.80it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [01:15<01:43,  1.54it/s]predicting train subjects sagittal:  40%|████      | 107/266 [01:16<01:36,  1.65it/s]predicting train subjects sagittal:  41%|████      | 108/266 [01:16<01:26,  1.83it/s]predicting train subjects sagittal:  41%|████      | 109/266 [01:17<01:19,  1.96it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [01:17<01:25,  1.83it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [01:18<01:24,  1.84it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [01:18<01:18,  1.96it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [01:19<01:17,  1.98it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [01:19<01:13,  2.08it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [01:20<01:13,  2.04it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [01:20<01:25,  1.76it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [01:21<01:23,  1.79it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [01:22<01:32,  1.60it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [01:23<01:43,  1.42it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [01:23<01:45,  1.39it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [01:24<01:46,  1.36it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [01:25<01:45,  1.36it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [01:25<01:34,  1.51it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [01:26<01:42,  1.38it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [01:27<01:31,  1.53it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [01:27<01:28,  1.57it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [01:28<01:22,  1.69it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [01:28<01:24,  1.63it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [01:29<01:23,  1.64it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [01:30<01:18,  1.73it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [01:30<01:29,  1.51it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [01:31<01:29,  1.49it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [01:32<01:23,  1.60it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [01:32<01:26,  1.53it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [01:33<01:16,  1.71it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [01:34<01:26,  1.50it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [01:34<01:21,  1.57it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [01:35<01:17,  1.65it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [01:35<01:12,  1.76it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [01:36<01:10,  1.79it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [01:36<01:09,  1.80it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [01:37<01:05,  1.90it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [01:37<01:06,  1.84it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [01:38<01:17,  1.58it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [01:39<01:11,  1.68it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [01:39<01:11,  1.68it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [01:40<01:23,  1.43it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [01:41<01:25,  1.38it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [01:42<01:35,  1.22it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [01:43<01:41,  1.14it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [01:44<01:39,  1.16it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [01:45<01:35,  1.20it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [01:45<01:33,  1.21it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [01:46<01:24,  1.32it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [01:47<01:17,  1.43it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [01:48<01:28,  1.25it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [01:49<01:32,  1.17it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [01:50<01:33,  1.16it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [01:50<01:21,  1.31it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [01:51<01:11,  1.48it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [01:51<01:04,  1.64it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [01:51<00:58,  1.78it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [01:52<00:58,  1.75it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [01:53<00:55,  1.85it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [01:53<00:54,  1.85it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [01:54<00:53,  1.87it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [01:54<00:51,  1.94it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [01:55<00:52,  1.85it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [01:55<00:51,  1.89it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [01:56<00:48,  1.96it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [01:56<00:49,  1.94it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [01:56<00:43,  2.18it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [01:57<00:52,  1.76it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [01:58<00:58,  1.57it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [01:59<00:57,  1.58it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [01:59<00:53,  1.68it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [02:00<00:52,  1.71it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [02:00<00:50,  1.74it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [02:01<00:48,  1.81it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [02:02<00:54,  1.59it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [02:02<00:53,  1.60it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [02:03<00:52,  1.59it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [02:03<00:46,  1.77it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [02:04<00:45,  1.80it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [02:04<00:45,  1.79it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [02:05<00:40,  1.96it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [02:05<00:39,  2.01it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [02:06<00:38,  2.00it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [02:06<00:39,  1.93it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [02:07<00:37,  2.01it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [02:07<00:38,  1.95it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [02:08<00:36,  2.01it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [02:08<00:36,  1.98it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [02:09<00:41,  1.74it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [02:10<00:38,  1.86it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [02:10<00:36,  1.90it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [02:11<00:36,  1.90it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [02:11<00:34,  1.98it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [02:12<00:36,  1.82it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [02:12<00:38,  1.71it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [02:13<00:34,  1.86it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [02:13<00:34,  1.83it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [02:14<00:37,  1.67it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [02:15<00:38,  1.61it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [02:15<00:34,  1.79it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [02:16<00:30,  1.95it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [02:16<00:32,  1.83it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [02:17<00:30,  1.92it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [02:17<00:28,  1.98it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [02:18<00:29,  1.90it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [02:18<00:27,  1.96it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [02:18<00:24,  2.16it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [02:19<00:25,  2.06it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [02:20<00:25,  2.01it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [02:20<00:24,  2.11it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [02:20<00:23,  2.10it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [02:21<00:23,  2.10it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [02:21<00:22,  2.17it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [02:22<00:23,  1.99it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [02:22<00:23,  1.94it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [02:23<00:23,  1.94it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [02:24<00:23,  1.90it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [02:24<00:24,  1.74it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [02:25<00:25,  1.65it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [02:25<00:23,  1.78it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [02:26<00:20,  1.93it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [02:26<00:19,  2.05it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [02:27<00:17,  2.23it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [02:27<00:16,  2.20it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [02:27<00:15,  2.36it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [02:28<00:14,  2.40it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [02:28<00:14,  2.29it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [02:29<00:14,  2.28it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [02:29<00:14,  2.27it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [02:30<00:13,  2.36it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [02:30<00:13,  2.21it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [02:31<00:13,  2.14it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [02:31<00:13,  2.09it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [02:32<00:12,  2.14it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [02:32<00:13,  1.93it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [02:33<00:13,  1.82it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [02:33<00:13,  1.72it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [02:34<00:12,  1.88it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [02:34<00:10,  2.01it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [02:35<00:09,  2.11it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [02:35<00:10,  1.94it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [02:36<00:10,  1.89it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [02:36<00:09,  1.82it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [02:37<00:08,  1.92it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [02:37<00:08,  1.85it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [02:38<00:08,  1.81it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [02:39<00:07,  1.81it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [02:39<00:07,  1.73it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [02:40<00:06,  1.79it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [02:40<00:05,  1.88it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [02:41<00:05,  1.92it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [02:41<00:05,  1.78it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [02:42<00:04,  1.91it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [02:43<00:04,  1.70it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [02:43<00:03,  1.73it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [02:44<00:02,  1.80it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [02:44<00:02,  1.90it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [02:45<00:01,  1.97it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [02:45<00:01,  1.88it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [02:46<00:00,  1.79it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [02:47<00:00,  1.59it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 73.54it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 6/266 [00:00<00:04, 53.91it/s]saving BB  train1-THALAMUS:   4%|▍         | 11/266 [00:00<00:05, 48.64it/s]saving BB  train1-THALAMUS:   6%|▌         | 15/266 [00:00<00:05, 42.43it/s]saving BB  train1-THALAMUS:   7%|▋         | 19/266 [00:00<00:06, 36.76it/s]saving BB  train1-THALAMUS:   9%|▉         | 25/266 [00:00<00:05, 40.67it/s]saving BB  train1-THALAMUS:  12%|█▏        | 31/266 [00:00<00:05, 44.86it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:05, 43.69it/s]saving BB  train1-THALAMUS:  15%|█▌        | 41/266 [00:00<00:05, 44.88it/s]saving BB  train1-THALAMUS:  17%|█▋        | 46/266 [00:01<00:04, 45.08it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:01<00:05, 37.07it/s]saving BB  train1-THALAMUS:  21%|██        | 55/266 [00:01<00:05, 37.68it/s]saving BB  train1-THALAMUS:  24%|██▎       | 63/266 [00:01<00:04, 44.25it/s]saving BB  train1-THALAMUS:  26%|██▌       | 69/266 [00:01<00:04, 46.75it/s]saving BB  train1-THALAMUS:  28%|██▊       | 75/266 [00:01<00:03, 49.22it/s]saving BB  train1-THALAMUS:  30%|███       | 81/266 [00:01<00:03, 49.23it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:03, 48.93it/s]saving BB  train1-THALAMUS:  36%|███▌      | 95/266 [00:02<00:03, 53.98it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:02<00:02, 55.21it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:02<00:03, 50.15it/s]saving BB  train1-THALAMUS:  42%|████▏     | 113/266 [00:02<00:03, 44.62it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:02<00:03, 45.99it/s]saving BB  train1-THALAMUS:  47%|████▋     | 124/266 [00:02<00:02, 48.66it/s]saving BB  train1-THALAMUS:  49%|████▉     | 131/266 [00:02<00:02, 51.92it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 137/266 [00:02<00:02, 50.26it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 143/266 [00:03<00:02, 50.22it/s]saving BB  train1-THALAMUS:  56%|█████▋    | 150/266 [00:03<00:02, 54.34it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 158/266 [00:03<00:01, 59.85it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 167/266 [00:03<00:01, 65.63it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 174/266 [00:03<00:01, 63.75it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 181/266 [00:03<00:01, 60.79it/s]saving BB  train1-THALAMUS:  71%|███████   | 188/266 [00:03<00:01, 56.65it/s]saving BB  train1-THALAMUS:  74%|███████▎  | 196/266 [00:03<00:01, 61.27it/s]saving BB  train1-THALAMUS:  76%|███████▋  | 203/266 [00:03<00:01, 62.14it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:04<00:00, 57.16it/s]saving BB  train1-THALAMUS:  81%|████████  | 216/266 [00:04<00:01, 46.62it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 222/266 [00:04<00:00, 49.79it/s]saving BB  train1-THALAMUS:  86%|████████▋ | 230/266 [00:04<00:00, 54.95it/s]saving BB  train1-THALAMUS:  89%|████████▊ | 236/266 [00:04<00:00, 56.30it/s]saving BB  train1-THALAMUS:  91%|█████████ | 242/266 [00:04<00:00, 45.81it/s]saving BB  train1-THALAMUS:  94%|█████████▎| 249/266 [00:04<00:00, 48.70it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 255/266 [00:05<00:00, 39.05it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 261/266 [00:05<00:00, 43.14it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:05<00:00, 50.27it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 68.41it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:03, 66.94it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:03, 65.99it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 20/266 [00:00<00:04, 60.53it/s]saving BB  train1-THALAMUS Sagittal:  10%|▉         | 26/266 [00:00<00:04, 57.44it/s]saving BB  train1-THALAMUS Sagittal:  12%|█▏        | 33/266 [00:00<00:03, 58.77it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▌        | 40/266 [00:00<00:03, 61.45it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 46/266 [00:00<00:03, 59.31it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 52/266 [00:00<00:03, 55.42it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 58/266 [00:01<00:04, 49.86it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▍       | 64/266 [00:01<00:03, 52.07it/s]saving BB  train1-THALAMUS Sagittal:  27%|██▋       | 71/266 [00:01<00:03, 56.27it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 79/266 [00:01<00:03, 60.91it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 87/266 [00:01<00:02, 61.28it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▌      | 94/266 [00:01<00:03, 51.93it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 100/266 [00:01<00:04, 36.44it/s]saving BB  train1-THALAMUS Sagittal:  40%|███▉      | 106/266 [00:02<00:03, 40.71it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 113/266 [00:02<00:03, 45.99it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 120/266 [00:02<00:02, 50.54it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 126/266 [00:02<00:03, 43.78it/s]saving BB  train1-THALAMUS Sagittal:  50%|████▉     | 132/266 [00:02<00:02, 44.96it/s]saving BB  train1-THALAMUS Sagittal:  52%|█████▏    | 137/266 [00:02<00:03, 37.00it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 142/266 [00:03<00:04, 26.13it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▌    | 149/266 [00:03<00:03, 32.00it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 154/266 [00:03<00:03, 35.58it/s]saving BB  train1-THALAMUS Sagittal:  60%|█████▉    | 159/266 [00:03<00:03, 34.78it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 164/266 [00:03<00:02, 37.63it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 170/266 [00:03<00:02, 41.26it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 177/266 [00:03<00:01, 46.33it/s]saving BB  train1-THALAMUS Sagittal:  70%|██████▉   | 185/266 [00:03<00:01, 52.88it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 193/266 [00:03<00:01, 58.32it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▌  | 200/266 [00:04<00:01, 41.40it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 206/266 [00:04<00:01, 39.85it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 211/266 [00:04<00:01, 38.17it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 218/266 [00:04<00:01, 43.50it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 224/266 [00:04<00:00, 45.60it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 232/266 [00:04<00:00, 50.98it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 238/266 [00:05<00:00, 53.22it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 244/266 [00:05<00:00, 53.16it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▍| 252/266 [00:05<00:00, 57.41it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 259/266 [00:05<00:00, 58.70it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:05<00:00, 55.23it/s]
Epoch 00061: val_mDice did not improve from 0.85769
Restoring model weights from the end of the best epoch
Epoch 00061: early stopping
{'val_loss': [0.47936036228202283, 0.3380930865823757, 0.3467801983060781, 0.2396916402503848, 0.30054263363126665, 0.2908473158022389, 0.2017043732921593, 0.21859538310673088, 0.19741111251641996, 0.1835270157607738, 0.19804351241327822, 0.23838249812251888, 0.3237888780713547, 0.20518268016166985, 0.18250510763027705, 0.17657546792179346, 0.18537695161649026, 0.3577271258982364, 0.1819408549927175, 0.17462220101151615, 0.1854130050924141, 0.3181054402666632, 0.41811323625734076, 0.1607061062240973, 0.1644083715218585, 0.17313130717957392, 0.3455957810219843, 0.1581549385737162, 0.19394277638639323, 0.16001541857258417, 0.15760341443819925, 0.19728309399215505, 0.3169298450520728, 0.15421264112228528, 0.14588298369199038, 0.15686137386364862, 0.153312056674622, 0.1390390884480439, 0.15342199138831347, 0.1425213736074511, 0.14310409518657252, 0.299069316504756, 0.13948839050135575, 0.12565179396187887, 0.13876490836264566, 0.13681419196655042, 0.12199391875765286, 0.13820263353409246, 0.2390306098095607, 0.13134315435308963, 0.16312030059634708, 0.1320484592288267, 0.11874782355153002, 0.12468324409564957, 0.14621821022592485, 0.2092502694868017, 0.11510568106314167, 0.10563516500405967, 0.11469634043169208, 0.0986567415529862, 0.2934533802908845], 'val_acc': [0.9785917107947171, 0.9910288313403726, 0.9898739336058497, 0.9925541807897389, 0.9920368902385235, 0.9919823301024735, 0.993557867128402, 0.9921519425697625, 0.9936916283331811, 0.9938805820420384, 0.9936648178845644, 0.9928650446236134, 0.9921058057807386, 0.9928026809357107, 0.993335863109678, 0.9935447704046965, 0.9940196517854929, 0.9902683575637639, 0.9940361711196601, 0.9942313530482352, 0.9940795241855085, 0.9926598905585706, 0.9881153693422675, 0.994118488393724, 0.9936383217573166, 0.9936710461042821, 0.9907264071516693, 0.9941864516586065, 0.9926826334558427, 0.9940592446364462, 0.9934287858195603, 0.9922891613095999, 0.9918152200989425, 0.9940561247058213, 0.9938525259494781, 0.9934855266474187, 0.9938525259494781, 0.9940174748189747, 0.99394949991256, 0.9938144814223051, 0.9934833613224328, 0.9926577005535364, 0.9938506633043289, 0.9942061025649309, 0.9937274726107717, 0.9939878354780376, 0.9940015724860132, 0.9938291264697909, 0.9933452093973756, 0.9939092551358044, 0.9937948421575129, 0.993932037614286, 0.9935862375423312, 0.9934565392322838, 0.9936146079562604, 0.9927453231066465, 0.9941103858873248, 0.9938587541691959, 0.9939005356281996, 0.993782676756382, 0.993266960605979], 'val_mDice': [0.6590971257537603, 0.7660316419787705, 0.7835389114916325, 0.8245181990787387, 0.8191877044737339, 0.8176020113751292, 0.8329688920639455, 0.8206981234252453, 0.8439274970442057, 0.8464961778372526, 0.8449101587757468, 0.8101454470306635, 0.8266235119663179, 0.8070166571997106, 0.8426787331700325, 0.8450112421996891, 0.855177897028625, 0.8046643459238112, 0.8544178446754813, 0.8536825538612902, 0.8576874271966517, 0.8413931587710977, 0.5868814565474167, 0.8525585290044546, 0.8520590956322849, 0.8362193824723363, 0.8071099757216871, 0.8527223137207329, 0.8397429599426687, 0.848687335383147, 0.8437859825789928, 0.7916910224594176, 0.8229774422943592, 0.8519606664776802, 0.8556147804483771, 0.8316183346323669, 0.851906999014318, 0.8510042913258076, 0.8534027612768114, 0.8510805899277329, 0.8367251721210778, 0.8368668728508055, 0.8503616671077907, 0.8560811867937446, 0.8445522980764508, 0.8468643762171268, 0.8495020447298884, 0.8526253513991833, 0.8436404634267092, 0.8490863023325801, 0.8497207774780691, 0.8471998502500355, 0.8500745170749724, 0.8443321101367474, 0.8499113377183676, 0.837908242829144, 0.8528799284249544, 0.8529119309969246, 0.8507767110131681, 0.8448952226899564, 0.8447175030596554], 'loss': [0.4469046286543487, 0.09645209829911089, 0.07956584050006618, 0.07129256529347246, 0.06618529414788167, 0.06310259009653771, 0.06069094384033062, 0.059604647870060735, 0.05757743430526134, 0.056032811279072225, 0.05452217464154019, 0.054083001700873656, 0.053004781350595574, 0.05182183739886448, 0.05070286468095559, 0.05022769319020152, 0.05023691691202861, 0.04872656541696766, 0.049759950877046204, 0.04756627509274576, 0.04689411855294852, 0.04597480694812163, 0.0456261250416694, 0.04527131683710693, 0.044642146865705154, 0.04447525000974209, 0.04367386521448016, 0.04355346092931988, 0.04313056355192296, 0.042386962348220654, 0.04210002543267278, 0.04221749482078012, 0.04172822499680847, 0.04168982234770161, 0.04092433841158264, 0.040772954981496655, 0.040490779751312087, 0.04038177718455691, 0.03986406991085351, 0.039984796509368294, 0.03950532984654635, 0.03967396970165272, 0.039401015500715834, 0.03919837323110583, 0.038988674235884785, 0.038817727949114936, 0.03838365302472334, 0.03819735670784486, 0.038501637728640924, 0.03799978148162303, 0.037799959497850255, 0.037545451686215606, 0.037769313875044334, 0.037268170868549194, 0.037790484704138705, 0.03730859784135645, 0.03688261492031334, 0.0366832807770905, 0.03702663859057935, 0.03685514985163778, 0.036836959803815614], 'acc': [0.8893913848335782, 0.9901521949592444, 0.9915442748311866, 0.9922462473475755, 0.9926707813641994, 0.9929710097798795, 0.9931781145287292, 0.9932823546176257, 0.9934769516776798, 0.9936508841668048, 0.9937670463550045, 0.993810448009987, 0.993927138149773, 0.9940170045304523, 0.9941199488017677, 0.9941886015590425, 0.9941803146020812, 0.9943312622881163, 0.9942222882524883, 0.9944383760175598, 0.9944935156671071, 0.9945708127876074, 0.9946233508851978, 0.9946532933238603, 0.9947034165988584, 0.9947054360931421, 0.9947965567890631, 0.9948169313145249, 0.9948583543681511, 0.9949058601010534, 0.994930357450778, 0.9949248706101955, 0.9949911849360523, 0.9949740422814929, 0.9950473110989105, 0.995079558742189, 0.9950860480931463, 0.9951019487038049, 0.9951438405752819, 0.9951631120027697, 0.9951886605812003, 0.9951842434109608, 0.9952094679969078, 0.9952321270831553, 0.9952566104510305, 0.9952670821567937, 0.9952939673764816, 0.9953335096739969, 0.9953141149929402, 0.9953517491869829, 0.9953730359467478, 0.9954106105430708, 0.9953748531162607, 0.9954473875853413, 0.9953781236017208, 0.9954448768496167, 0.9954866191312329, 0.9954915553611843, 0.9954543570005702, 0.9954690658022638, 0.9954947533196961], 'mDice': [0.5988829720527733, 0.83161191221063, 0.8579464438859907, 0.8715000402031287, 0.8799649789051629, 0.8851395840704116, 0.88922577012606, 0.8911047787551086, 0.8945624266571598, 0.8972401392574827, 0.8998248929053327, 0.9005775266689776, 0.9024857757772125, 0.9045029162834285, 0.906480367270665, 0.9072982395680036, 0.9072932269261027, 0.9099331633463212, 0.908151904942752, 0.9119763580766915, 0.91316845279351, 0.9147890108213672, 0.9154027413238808, 0.916037736252596, 0.917150445442603, 0.9174495423534017, 0.9188766999085135, 0.9190966014498075, 0.9198351688566171, 0.9211792937482401, 0.9216850724759883, 0.9214757574938365, 0.9223511831414427, 0.9224208874321295, 0.9238089849908163, 0.9240708410899177, 0.9245769804510434, 0.9247723323578367, 0.9257047640137436, 0.9254818540549076, 0.9263377886997417, 0.926030900117702, 0.9265282247434083, 0.926883912860717, 0.9272567437087615, 0.9275835271744248, 0.9283621947884739, 0.9286877485508286, 0.9281365330714831, 0.9290474210450829, 0.9294031375415984, 0.9298599224840153, 0.9294636159446218, 0.9303589365174023, 0.9294230085473533, 0.9302885199972627, 0.9310516603693558, 0.9314135647241116, 0.9307972522677757, 0.9311146023964043, 0.9311334223950576]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:04<21:49,  4.94s/it]Loading train:   1%|          | 2/266 [00:07<18:16,  4.15s/it]Loading train:   1%|          | 3/266 [00:09<15:16,  3.48s/it]Loading train:   2%|▏         | 4/266 [00:12<14:33,  3.33s/it]Loading train:   2%|▏         | 5/266 [00:16<15:23,  3.54s/it]Loading train:   2%|▏         | 6/266 [00:20<16:20,  3.77s/it]Loading train:   3%|▎         | 7/266 [00:22<13:39,  3.17s/it]Loading train:   3%|▎         | 8/266 [00:23<11:45,  2.74s/it]Loading train:   3%|▎         | 9/266 [00:25<10:25,  2.43s/it]Loading train:   4%|▍         | 10/266 [00:29<12:06,  2.84s/it]Loading train:   4%|▍         | 11/266 [00:32<12:10,  2.87s/it]Loading train:   5%|▍         | 12/266 [00:35<12:43,  3.00s/it]Loading train:   5%|▍         | 13/266 [00:39<13:09,  3.12s/it]Loading train:   5%|▌         | 14/266 [00:41<11:31,  2.74s/it]Loading train:   6%|▌         | 15/266 [00:43<10:45,  2.57s/it]Loading train:   6%|▌         | 16/266 [00:45<10:28,  2.51s/it]Loading train:   6%|▋         | 17/266 [00:48<11:22,  2.74s/it]Loading train:   7%|▋         | 18/266 [00:51<11:48,  2.86s/it]Loading train:   7%|▋         | 19/266 [00:54<11:47,  2.86s/it]Loading train:   8%|▊         | 20/266 [00:56<10:09,  2.48s/it]Loading train:   8%|▊         | 21/266 [00:58<09:11,  2.25s/it]Loading train:   8%|▊         | 22/266 [00:59<08:31,  2.10s/it]Loading train:   9%|▊         | 23/266 [01:01<07:42,  1.90s/it]Loading train:   9%|▉         | 24/266 [01:02<07:21,  1.82s/it]Loading train:   9%|▉         | 25/266 [01:04<07:05,  1.77s/it]Loading train:  10%|▉         | 26/266 [01:05<06:22,  1.59s/it]Loading train:  10%|█         | 27/266 [01:07<06:26,  1.62s/it]Loading train:  11%|█         | 28/266 [01:09<06:54,  1.74s/it]Loading train:  11%|█         | 29/266 [01:11<07:16,  1.84s/it]Loading train:  11%|█▏        | 30/266 [01:16<10:27,  2.66s/it]Loading train:  12%|█▏        | 31/266 [01:17<09:02,  2.31s/it]Loading train:  12%|█▏        | 32/266 [01:19<08:09,  2.09s/it]Loading train:  12%|█▏        | 33/266 [01:20<07:38,  1.97s/it]Loading train:  13%|█▎        | 34/266 [01:22<07:43,  2.00s/it]Loading train:  13%|█▎        | 35/266 [01:25<08:07,  2.11s/it]Loading train:  14%|█▎        | 36/266 [01:27<07:45,  2.03s/it]Loading train:  14%|█▍        | 37/266 [01:29<08:00,  2.10s/it]Loading train:  14%|█▍        | 38/266 [01:32<08:49,  2.32s/it]Loading train:  15%|█▍        | 39/266 [01:33<07:49,  2.07s/it]Loading train:  15%|█▌        | 40/266 [01:35<07:21,  1.95s/it]Loading train:  15%|█▌        | 41/266 [01:37<07:12,  1.92s/it]Loading train:  16%|█▌        | 42/266 [01:38<06:53,  1.85s/it]Loading train:  16%|█▌        | 43/266 [01:40<06:57,  1.87s/it]Loading train:  17%|█▋        | 44/266 [01:43<07:22,  1.99s/it]Loading train:  17%|█▋        | 45/266 [01:45<07:11,  1.95s/it]Loading train:  17%|█▋        | 46/266 [01:47<07:20,  2.00s/it]Loading train:  18%|█▊        | 47/266 [01:49<07:21,  2.02s/it]Loading train:  18%|█▊        | 48/266 [01:51<07:21,  2.03s/it]Loading train:  18%|█▊        | 49/266 [01:53<07:43,  2.14s/it]Loading train:  19%|█▉        | 50/266 [01:55<07:55,  2.20s/it]Loading train:  19%|█▉        | 51/266 [01:58<07:49,  2.18s/it]Loading train:  20%|█▉        | 52/266 [01:59<07:27,  2.09s/it]Loading train:  20%|█▉        | 53/266 [02:01<07:11,  2.03s/it]Loading train:  20%|██        | 54/266 [02:03<06:45,  1.91s/it]Loading train:  21%|██        | 55/266 [02:04<06:15,  1.78s/it]Loading train:  21%|██        | 56/266 [02:06<06:06,  1.74s/it]Loading train:  21%|██▏       | 57/266 [02:08<05:48,  1.67s/it]Loading train:  22%|██▏       | 58/266 [02:09<05:57,  1.72s/it]Loading train:  22%|██▏       | 59/266 [02:11<06:05,  1.77s/it]Loading train:  23%|██▎       | 60/266 [02:13<06:13,  1.81s/it]Loading train:  23%|██▎       | 61/266 [02:16<06:56,  2.03s/it]Loading train:  23%|██▎       | 62/266 [02:18<06:54,  2.03s/it]Loading train:  24%|██▎       | 63/266 [02:24<11:02,  3.26s/it]Loading train:  24%|██▍       | 64/266 [02:26<09:19,  2.77s/it]Loading train:  24%|██▍       | 65/266 [02:28<08:32,  2.55s/it]Loading train:  25%|██▍       | 66/266 [02:29<07:19,  2.20s/it]Loading train:  25%|██▌       | 67/266 [02:31<07:31,  2.27s/it]Loading train:  26%|██▌       | 68/266 [02:34<07:36,  2.31s/it]Loading train:  26%|██▌       | 69/266 [02:35<06:42,  2.04s/it]Loading train:  26%|██▋       | 70/266 [02:38<06:57,  2.13s/it]Loading train:  27%|██▋       | 71/266 [02:40<07:13,  2.22s/it]Loading train:  27%|██▋       | 72/266 [02:42<07:11,  2.22s/it]Loading train:  27%|██▋       | 73/266 [02:44<06:55,  2.15s/it]Loading train:  28%|██▊       | 74/266 [02:46<06:31,  2.04s/it]Loading train:  28%|██▊       | 75/266 [02:48<06:29,  2.04s/it]Loading train:  29%|██▊       | 76/266 [02:50<06:10,  1.95s/it]Loading train:  29%|██▉       | 77/266 [02:51<05:34,  1.77s/it]Loading train:  29%|██▉       | 78/266 [02:52<05:00,  1.60s/it]Loading train:  30%|██▉       | 79/266 [02:54<05:07,  1.64s/it]Loading train:  30%|███       | 80/266 [02:55<04:51,  1.57s/it]Loading train:  30%|███       | 81/266 [02:57<04:38,  1.50s/it]Loading train:  31%|███       | 82/266 [02:58<04:28,  1.46s/it]Loading train:  31%|███       | 83/266 [03:00<04:26,  1.46s/it]Loading train:  32%|███▏      | 84/266 [03:01<04:39,  1.54s/it]Loading train:  32%|███▏      | 85/266 [03:03<05:03,  1.68s/it]Loading train:  32%|███▏      | 86/266 [03:05<04:56,  1.65s/it]Loading train:  33%|███▎      | 87/266 [03:06<04:47,  1.61s/it]Loading train:  33%|███▎      | 88/266 [03:08<04:38,  1.57s/it]Loading train:  33%|███▎      | 89/266 [03:09<04:26,  1.51s/it]Loading train:  34%|███▍      | 90/266 [03:11<04:25,  1.51s/it]Loading train:  34%|███▍      | 91/266 [03:12<04:22,  1.50s/it]Loading train:  35%|███▍      | 92/266 [03:14<04:13,  1.45s/it]Loading train:  35%|███▍      | 93/266 [03:15<04:02,  1.40s/it]Loading train:  35%|███▌      | 94/266 [03:16<04:07,  1.44s/it]Loading train:  36%|███▌      | 95/266 [03:18<04:14,  1.49s/it]Loading train:  36%|███▌      | 96/266 [03:20<04:23,  1.55s/it]Loading train:  36%|███▋      | 97/266 [03:22<04:32,  1.61s/it]Loading train:  37%|███▋      | 98/266 [03:24<04:51,  1.74s/it]Loading train:  37%|███▋      | 99/266 [03:25<04:47,  1.72s/it]Loading train:  38%|███▊      | 100/266 [03:27<04:48,  1.74s/it]Loading train:  38%|███▊      | 101/266 [03:28<04:15,  1.55s/it]Loading train:  38%|███▊      | 102/266 [03:29<04:04,  1.49s/it]Loading train:  39%|███▊      | 103/266 [03:31<04:07,  1.52s/it]Loading train:  39%|███▉      | 104/266 [03:33<04:17,  1.59s/it]Loading train:  39%|███▉      | 105/266 [03:35<04:39,  1.74s/it]Loading train:  40%|███▉      | 106/266 [03:36<04:23,  1.65s/it]Loading train:  40%|████      | 107/266 [03:38<04:17,  1.62s/it]Loading train:  41%|████      | 108/266 [03:40<04:36,  1.75s/it]Loading train:  41%|████      | 109/266 [03:41<04:14,  1.62s/it]Loading train:  41%|████▏     | 110/266 [03:42<03:54,  1.50s/it]Loading train:  42%|████▏     | 111/266 [03:44<03:42,  1.43s/it]Loading train:  42%|████▏     | 112/266 [03:45<03:30,  1.36s/it]Loading train:  42%|████▏     | 113/266 [03:47<03:37,  1.42s/it]Loading train:  43%|████▎     | 114/266 [03:48<03:30,  1.39s/it]Loading train:  43%|████▎     | 115/266 [03:49<03:26,  1.36s/it]Loading train:  44%|████▎     | 116/266 [03:51<03:26,  1.37s/it]Loading train:  44%|████▍     | 117/266 [03:52<03:26,  1.39s/it]Loading train:  44%|████▍     | 118/266 [03:53<03:31,  1.43s/it]Loading train:  45%|████▍     | 119/266 [03:55<03:21,  1.37s/it]Loading train:  45%|████▌     | 120/266 [03:56<03:11,  1.31s/it]Loading train:  45%|████▌     | 121/266 [03:57<03:13,  1.33s/it]Loading train:  46%|████▌     | 122/266 [03:59<03:22,  1.41s/it]Loading train:  46%|████▌     | 123/266 [04:00<03:26,  1.44s/it]Loading train:  47%|████▋     | 124/266 [04:02<03:32,  1.50s/it]Loading train:  47%|████▋     | 125/266 [04:04<03:45,  1.60s/it]Loading train:  47%|████▋     | 126/266 [04:05<03:35,  1.54s/it]Loading train:  48%|████▊     | 127/266 [04:07<03:45,  1.62s/it]Loading train:  48%|████▊     | 128/266 [04:08<03:34,  1.55s/it]Loading train:  48%|████▊     | 129/266 [04:10<03:29,  1.53s/it]Loading train:  49%|████▉     | 130/266 [04:11<03:12,  1.41s/it]Loading train:  49%|████▉     | 131/266 [04:12<03:06,  1.38s/it]Loading train:  50%|████▉     | 132/266 [04:14<03:08,  1.41s/it]Loading train:  50%|█████     | 133/266 [04:15<03:12,  1.45s/it]Loading train:  50%|█████     | 134/266 [04:17<03:05,  1.41s/it]Loading train:  51%|█████     | 135/266 [04:18<03:05,  1.42s/it]Loading train:  51%|█████     | 136/266 [04:20<03:14,  1.50s/it]Loading train:  52%|█████▏    | 137/266 [04:21<03:14,  1.51s/it]Loading train:  52%|█████▏    | 138/266 [04:23<03:28,  1.63s/it]Loading train:  52%|█████▏    | 139/266 [04:25<03:22,  1.60s/it]Loading train:  53%|█████▎    | 140/266 [04:26<03:26,  1.64s/it]Loading train:  53%|█████▎    | 141/266 [04:28<03:37,  1.74s/it]Loading train:  53%|█████▎    | 142/266 [04:30<03:18,  1.60s/it]Loading train:  54%|█████▍    | 143/266 [04:31<03:16,  1.59s/it]Loading train:  54%|█████▍    | 144/266 [04:33<03:11,  1.57s/it]Loading train:  55%|█████▍    | 145/266 [04:34<02:58,  1.48s/it]Loading train:  55%|█████▍    | 146/266 [04:35<02:44,  1.37s/it]Loading train:  55%|█████▌    | 147/266 [04:37<02:40,  1.35s/it]Loading train:  56%|█████▌    | 148/266 [04:38<02:38,  1.34s/it]Loading train:  56%|█████▌    | 149/266 [04:39<02:33,  1.31s/it]Loading train:  56%|█████▋    | 150/266 [04:40<02:31,  1.30s/it]Loading train:  57%|█████▋    | 151/266 [04:42<02:33,  1.33s/it]Loading train:  57%|█████▋    | 152/266 [04:43<02:28,  1.30s/it]Loading train:  58%|█████▊    | 153/266 [04:44<02:26,  1.29s/it]Loading train:  58%|█████▊    | 154/266 [04:46<02:34,  1.38s/it]Loading train:  58%|█████▊    | 155/266 [04:47<02:27,  1.33s/it]Loading train:  59%|█████▊    | 156/266 [04:48<02:18,  1.26s/it]Loading train:  59%|█████▉    | 157/266 [04:49<02:16,  1.25s/it]Loading train:  59%|█████▉    | 158/266 [04:51<02:15,  1.25s/it]Loading train:  60%|█████▉    | 159/266 [04:52<02:10,  1.22s/it]Loading train:  60%|██████    | 160/266 [04:53<02:16,  1.28s/it]Loading train:  61%|██████    | 161/266 [04:55<02:18,  1.32s/it]Loading train:  61%|██████    | 162/266 [04:56<02:11,  1.26s/it]Loading train:  61%|██████▏   | 163/266 [04:57<02:08,  1.24s/it]Loading train:  62%|██████▏   | 164/266 [04:58<01:59,  1.17s/it]Loading train:  62%|██████▏   | 165/266 [05:00<02:13,  1.32s/it]Loading train:  62%|██████▏   | 166/266 [05:02<02:44,  1.65s/it]Loading train:  63%|██████▎   | 167/266 [05:08<04:51,  2.94s/it]Loading train:  63%|██████▎   | 168/266 [05:10<04:30,  2.76s/it]Loading train:  64%|██████▎   | 169/266 [05:11<03:39,  2.26s/it]Loading train:  64%|██████▍   | 170/266 [05:13<03:05,  1.93s/it]Loading train:  64%|██████▍   | 171/266 [05:14<02:38,  1.67s/it]Loading train:  65%|██████▍   | 172/266 [05:15<02:18,  1.47s/it]Loading train:  65%|██████▌   | 173/266 [05:16<02:09,  1.39s/it]Loading train:  65%|██████▌   | 174/266 [05:18<02:14,  1.46s/it]Loading train:  66%|██████▌   | 175/266 [05:19<02:04,  1.37s/it]Loading train:  66%|██████▌   | 176/266 [05:20<02:02,  1.36s/it]Loading train:  67%|██████▋   | 177/266 [05:21<01:57,  1.32s/it]Loading train:  67%|██████▋   | 178/266 [05:22<01:49,  1.24s/it]Loading train:  67%|██████▋   | 179/266 [05:23<01:42,  1.18s/it]Loading train:  68%|██████▊   | 180/266 [05:24<01:38,  1.14s/it]Loading train:  68%|██████▊   | 181/266 [05:26<01:40,  1.18s/it]Loading train:  68%|██████▊   | 182/266 [05:28<01:58,  1.41s/it]Loading train:  69%|██████▉   | 183/266 [05:29<02:02,  1.48s/it]Loading train:  69%|██████▉   | 184/266 [05:30<01:56,  1.42s/it]Loading train:  70%|██████▉   | 185/266 [05:32<01:57,  1.45s/it]Loading train:  70%|██████▉   | 186/266 [05:34<02:10,  1.63s/it]Loading train:  70%|███████   | 187/266 [05:36<02:07,  1.61s/it]Loading train:  71%|███████   | 188/266 [05:37<01:54,  1.47s/it]Loading train:  71%|███████   | 189/266 [05:38<01:52,  1.47s/it]Loading train:  71%|███████▏  | 190/266 [05:39<01:44,  1.38s/it]Loading train:  72%|███████▏  | 191/266 [05:41<01:45,  1.40s/it]Loading train:  72%|███████▏  | 192/266 [05:42<01:41,  1.37s/it]Loading train:  73%|███████▎  | 193/266 [05:43<01:38,  1.35s/it]Loading train:  73%|███████▎  | 194/266 [05:45<01:49,  1.52s/it]Loading train:  73%|███████▎  | 195/266 [05:47<01:44,  1.46s/it]Loading train:  74%|███████▎  | 196/266 [05:48<01:46,  1.52s/it]Loading train:  74%|███████▍  | 197/266 [05:50<01:50,  1.60s/it]Loading train:  74%|███████▍  | 198/266 [05:52<01:49,  1.61s/it]Loading train:  75%|███████▍  | 199/266 [05:53<01:40,  1.50s/it]Loading train:  75%|███████▌  | 200/266 [05:54<01:34,  1.43s/it]Loading train:  76%|███████▌  | 201/266 [05:55<01:27,  1.35s/it]Loading train:  76%|███████▌  | 202/266 [05:56<01:20,  1.25s/it]Loading train:  76%|███████▋  | 203/266 [05:58<01:18,  1.25s/it]Loading train:  77%|███████▋  | 204/266 [05:59<01:12,  1.17s/it]Loading train:  77%|███████▋  | 205/266 [06:00<01:11,  1.18s/it]Loading train:  77%|███████▋  | 206/266 [06:01<01:10,  1.18s/it]Loading train:  78%|███████▊  | 207/266 [06:02<01:07,  1.15s/it]Loading train:  78%|███████▊  | 208/266 [06:03<01:06,  1.15s/it]Loading train:  79%|███████▊  | 209/266 [06:04<01:05,  1.14s/it]Loading train:  79%|███████▉  | 210/266 [06:06<01:11,  1.28s/it]Loading train:  79%|███████▉  | 211/266 [06:07<01:09,  1.27s/it]Loading train:  80%|███████▉  | 212/266 [06:09<01:11,  1.33s/it]Loading train:  80%|████████  | 213/266 [06:10<01:05,  1.25s/it]Loading train:  80%|████████  | 214/266 [06:12<01:15,  1.45s/it]Loading train:  81%|████████  | 215/266 [06:13<01:13,  1.44s/it]Loading train:  81%|████████  | 216/266 [06:15<01:14,  1.49s/it]Loading train:  82%|████████▏ | 217/266 [06:17<01:18,  1.59s/it]Loading train:  82%|████████▏ | 218/266 [06:18<01:19,  1.65s/it]Loading train:  82%|████████▏ | 219/266 [06:20<01:17,  1.65s/it]Loading train:  83%|████████▎ | 220/266 [06:21<01:12,  1.58s/it]Loading train:  83%|████████▎ | 221/266 [06:23<01:04,  1.44s/it]Loading train:  83%|████████▎ | 222/266 [06:24<00:59,  1.34s/it]Loading train:  84%|████████▍ | 223/266 [06:25<00:54,  1.26s/it]Loading train:  84%|████████▍ | 224/266 [06:26<00:51,  1.22s/it]Loading train:  85%|████████▍ | 225/266 [06:27<00:51,  1.26s/it]Loading train:  85%|████████▍ | 226/266 [06:29<00:54,  1.35s/it]Loading train:  85%|████████▌ | 227/266 [06:30<00:48,  1.24s/it]Loading train:  86%|████████▌ | 228/266 [06:31<00:45,  1.20s/it]Loading train:  86%|████████▌ | 229/266 [06:33<00:52,  1.42s/it]Loading train:  86%|████████▋ | 230/266 [06:34<00:46,  1.30s/it]Loading train:  87%|████████▋ | 231/266 [06:35<00:48,  1.38s/it]Loading train:  87%|████████▋ | 232/266 [06:36<00:44,  1.30s/it]Loading train:  88%|████████▊ | 233/266 [06:38<00:41,  1.25s/it]Loading train:  88%|████████▊ | 234/266 [06:39<00:39,  1.25s/it]Loading train:  88%|████████▊ | 235/266 [06:40<00:36,  1.16s/it]Loading train:  89%|████████▊ | 236/266 [06:41<00:37,  1.25s/it]Loading train:  89%|████████▉ | 237/266 [06:42<00:35,  1.23s/it]Loading train:  89%|████████▉ | 238/266 [06:44<00:33,  1.19s/it]Loading train:  90%|████████▉ | 239/266 [06:45<00:31,  1.17s/it]Loading train:  90%|█████████ | 240/266 [06:46<00:31,  1.21s/it]Loading train:  91%|█████████ | 241/266 [06:47<00:29,  1.19s/it]Loading train:  91%|█████████ | 242/266 [06:48<00:27,  1.15s/it]Loading train:  91%|█████████▏| 243/266 [06:49<00:25,  1.10s/it]Loading train:  92%|█████████▏| 244/266 [06:50<00:23,  1.08s/it]Loading train:  92%|█████████▏| 245/266 [06:52<00:24,  1.18s/it]Loading train:  92%|█████████▏| 246/266 [06:53<00:25,  1.27s/it]Loading train:  93%|█████████▎| 247/266 [06:54<00:22,  1.21s/it]Loading train:  93%|█████████▎| 248/266 [06:56<00:25,  1.44s/it]Loading train:  94%|█████████▎| 249/266 [06:58<00:25,  1.52s/it]Loading train:  94%|█████████▍| 250/266 [06:59<00:24,  1.52s/it]Loading train:  94%|█████████▍| 251/266 [07:01<00:23,  1.54s/it]Loading train:  95%|█████████▍| 252/266 [07:02<00:21,  1.54s/it]Loading train:  95%|█████████▌| 253/266 [07:04<00:17,  1.38s/it]Loading train:  95%|█████████▌| 254/266 [07:05<00:18,  1.51s/it]Loading train:  96%|█████████▌| 255/266 [07:07<00:15,  1.42s/it]Loading train:  96%|█████████▌| 256/266 [07:08<00:13,  1.35s/it]Loading train:  97%|█████████▋| 257/266 [07:09<00:11,  1.31s/it]Loading train:  97%|█████████▋| 258/266 [07:11<00:11,  1.40s/it]Loading train:  97%|█████████▋| 259/266 [07:11<00:08,  1.26s/it]Loading train:  98%|█████████▊| 260/266 [07:12<00:07,  1.18s/it]Loading train:  98%|█████████▊| 261/266 [07:13<00:05,  1.11s/it]Loading train:  98%|█████████▊| 262/266 [07:14<00:04,  1.08s/it]Loading train:  99%|█████████▉| 263/266 [07:15<00:03,  1.07s/it]Loading train:  99%|█████████▉| 264/266 [07:17<00:02,  1.07s/it]Loading train: 100%|█████████▉| 265/266 [07:17<00:01,  1.03s/it]Loading train: 100%|██████████| 266/266 [07:18<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:01, 208.45it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:01, 179.05it/s]concatenating: train:  23%|██▎       | 60/266 [00:00<00:01, 195.70it/s]concatenating: train:  36%|███▌      | 96/266 [00:00<00:00, 225.80it/s]concatenating: train:  49%|████▉     | 130/266 [00:00<00:00, 247.51it/s]concatenating: train:  62%|██████▏   | 165/266 [00:00<00:00, 271.18it/s]concatenating: train:  76%|███████▌  | 201/266 [00:00<00:00, 292.22it/s]concatenating: train:  88%|████████▊ | 235/266 [00:00<00:00, 303.99it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 294.50it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.32s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.26s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.29s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 762.98it/s]2019-07-28 15:00:28.063409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 15:00:28.063507: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 15:00:28.063526: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 15:00:28.063537: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 15:00:28.229525: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.59it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.42it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.84it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.29it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:15,  2.28it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:11,  2.82it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:11,  2.68it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:07,  3.66it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:03<00:05,  4.44it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.52it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.88it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.71it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:04<00:02,  7.13it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.47it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:02,  4.45it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  4.62it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:06<00:01,  4.56it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.36it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.98it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.43it/s]
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 84, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 84, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 84, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 84, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 84, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 84, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 84, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 84, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 84, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 42, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 42, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 42, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 42, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 42, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 42, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 42, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 21, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 21, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 21, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 21, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 21, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 21, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 21, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 21, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 42, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 42, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 42, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 42, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 42, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 42, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 42, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 84, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 84, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 84, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 84, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 84, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 84, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 84, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 84, 10)   5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 84, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 84, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 84, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 84, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 84, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 84, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 84, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 84, 70)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 84, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 233,253
Trainable params: 58,493
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.32418873e-02 3.27773921e-02 7.66454234e-02 9.52357926e-03
 2.75634070e-02 7.21118848e-03 8.55350899e-02 1.13920804e-01
 8.94503165e-02 1.35906158e-02 2.90015520e-01 1.90262437e-01
 2.62339384e-04]
Train on 9601 samples, validate on 144 samples
Epoch 1/300
 - 21s - loss: 2.2843 - acc: 0.4141 - mDice: 0.2119 - val_loss: 1.1576 - val_acc: 0.9285 - val_mDice: 0.3965

Epoch 00001: val_mDice improved from -inf to 0.39652, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.6593 - acc: 0.9112 - mDice: 0.5140 - val_loss: 0.5112 - val_acc: 0.9349 - val_mDice: 0.5870

Epoch 00002: val_mDice improved from 0.39652 to 0.58699, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5056 - acc: 0.9231 - mDice: 0.5906 - val_loss: 0.5011 - val_acc: 0.9323 - val_mDice: 0.5956

Epoch 00003: val_mDice improved from 0.58699 to 0.59557, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.4820 - acc: 0.9267 - mDice: 0.6051 - val_loss: 0.4590 - val_acc: 0.9402 - val_mDice: 0.6233

Epoch 00004: val_mDice improved from 0.59557 to 0.62331, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5236 - acc: 0.9226 - mDice: 0.5846 - val_loss: 0.4627 - val_acc: 0.9436 - val_mDice: 0.6238

Epoch 00005: val_mDice improved from 0.62331 to 0.62375, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4491 - acc: 0.9306 - mDice: 0.6249 - val_loss: 0.4457 - val_acc: 0.9427 - val_mDice: 0.6303

Epoch 00006: val_mDice improved from 0.62375 to 0.63031, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4272 - acc: 0.9336 - mDice: 0.6394 - val_loss: 0.4365 - val_acc: 0.9447 - val_mDice: 0.6364

Epoch 00007: val_mDice improved from 0.63031 to 0.63636, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4192 - acc: 0.9347 - mDice: 0.6447 - val_loss: 0.4794 - val_acc: 0.9485 - val_mDice: 0.6190

Epoch 00008: val_mDice did not improve from 0.63636
Epoch 9/300
 - 13s - loss: 0.4291 - acc: 0.9337 - mDice: 0.6390 - val_loss: 0.4269 - val_acc: 0.9496 - val_mDice: 0.6440

Epoch 00009: val_mDice improved from 0.63636 to 0.64401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4011 - acc: 0.9368 - mDice: 0.6561 - val_loss: 0.5037 - val_acc: 0.9462 - val_mDice: 0.6039

Epoch 00010: val_mDice did not improve from 0.64401
Epoch 11/300
 - 13s - loss: 0.5134 - acc: 0.9260 - mDice: 0.5899 - val_loss: 0.4332 - val_acc: 0.9451 - val_mDice: 0.6371

Epoch 00011: val_mDice did not improve from 0.64401
Epoch 12/300
 - 13s - loss: 0.4334 - acc: 0.9333 - mDice: 0.6351 - val_loss: 0.4235 - val_acc: 0.9499 - val_mDice: 0.6465

Epoch 00012: val_mDice improved from 0.64401 to 0.64648, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 13s - loss: 0.4200 - acc: 0.9351 - mDice: 0.6448 - val_loss: 0.4467 - val_acc: 0.9390 - val_mDice: 0.6278

Epoch 00013: val_mDice did not improve from 0.64648
Epoch 14/300
 - 13s - loss: 0.4043 - acc: 0.9358 - mDice: 0.6539 - val_loss: 0.4345 - val_acc: 0.9444 - val_mDice: 0.6360

Epoch 00014: val_mDice did not improve from 0.64648
Epoch 15/300
 - 13s - loss: 0.3923 - acc: 0.9377 - mDice: 0.6621 - val_loss: 0.4777 - val_acc: 0.9459 - val_mDice: 0.6190

Epoch 00015: val_mDice did not improve from 0.64648
Epoch 16/300
 - 13s - loss: 0.4293 - acc: 0.9337 - mDice: 0.6385 - val_loss: 0.4193 - val_acc: 0.9480 - val_mDice: 0.6487

Epoch 00016: val_mDice improved from 0.64648 to 0.64866, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.3974 - acc: 0.9374 - mDice: 0.6586 - val_loss: 0.4146 - val_acc: 0.9479 - val_mDice: 0.6509

Epoch 00017: val_mDice improved from 0.64866 to 0.65090, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 13s - loss: 0.3896 - acc: 0.9378 - mDice: 0.6638 - val_loss: 0.4438 - val_acc: 0.9499 - val_mDice: 0.6377

Epoch 00018: val_mDice did not improve from 0.65090
Epoch 19/300
 - 13s - loss: 0.4434 - acc: 0.9322 - mDice: 0.6302 - val_loss: 0.4263 - val_acc: 0.9474 - val_mDice: 0.6441

Epoch 00019: val_mDice did not improve from 0.65090
Epoch 20/300
 - 13s - loss: 0.3846 - acc: 0.9384 - mDice: 0.6670 - val_loss: 0.4237 - val_acc: 0.9496 - val_mDice: 0.6476

Epoch 00020: val_mDice did not improve from 0.65090
Epoch 21/300
 - 13s - loss: 0.3982 - acc: 0.9373 - mDice: 0.6585 - val_loss: 0.4334 - val_acc: 0.9494 - val_mDice: 0.6425

Epoch 00021: val_mDice did not improve from 0.65090
Epoch 22/300
 - 14s - loss: 0.3759 - acc: 0.9390 - mDice: 0.6735 - val_loss: 0.4595 - val_acc: 0.9490 - val_mDice: 0.6306

Epoch 00022: val_mDice did not improve from 0.65090
Epoch 23/300
 - 13s - loss: 0.3869 - acc: 0.9382 - mDice: 0.6662 - val_loss: 0.4784 - val_acc: 0.9487 - val_mDice: 0.6221

Epoch 00023: val_mDice did not improve from 0.65090
Epoch 24/300
 - 15s - loss: 0.3893 - acc: 0.9377 - mDice: 0.6644 - val_loss: 0.4348 - val_acc: 0.9506 - val_mDice: 0.6445

Epoch 00024: val_mDice did not improve from 0.65090
Epoch 25/300
 - 13s - loss: 0.4106 - acc: 0.9361 - mDice: 0.6519 - val_loss: 0.4324 - val_acc: 0.9499 - val_mDice: 0.6432

Epoch 00025: val_mDice did not improve from 0.65090
Epoch 26/300
 - 13s - loss: 0.3793 - acc: 0.9386 - mDice: 0.6712 - val_loss: 0.4177 - val_acc: 0.9492 - val_mDice: 0.6503

Epoch 00026: val_mDice did not improve from 0.65090
Epoch 27/300
 - 13s - loss: 0.3694 - acc: 0.9397 - mDice: 0.6784 - val_loss: 0.4308 - val_acc: 0.9499 - val_mDice: 0.6444

Epoch 00027: val_mDice did not improve from 0.65090
Epoch 28/300
 - 13s - loss: 0.3904 - acc: 0.9369 - mDice: 0.6637 - val_loss: 0.4235 - val_acc: 0.9418 - val_mDice: 0.6433

Epoch 00028: val_mDice did not improve from 0.65090
Epoch 29/300
 - 14s - loss: 0.3832 - acc: 0.9378 - mDice: 0.6684 - val_loss: 0.4150 - val_acc: 0.9448 - val_mDice: 0.6503

Epoch 00029: val_mDice did not improve from 0.65090
Epoch 30/300
 - 13s - loss: 0.3810 - acc: 0.9385 - mDice: 0.6701 - val_loss: 0.4222 - val_acc: 0.9447 - val_mDice: 0.6468

Epoch 00030: val_mDice did not improve from 0.65090
Epoch 31/300
 - 13s - loss: 0.3703 - acc: 0.9395 - mDice: 0.6773 - val_loss: 0.4313 - val_acc: 0.9461 - val_mDice: 0.6413

Epoch 00031: val_mDice did not improve from 0.65090
Epoch 32/300
 - 14s - loss: 0.3813 - acc: 0.9376 - mDice: 0.6694 - val_loss: 0.4302 - val_acc: 0.9475 - val_mDice: 0.6427

Epoch 00032: val_mDice did not improve from 0.65090
Epoch 33/300
 - 14s - loss: 0.3664 - acc: 0.9398 - mDice: 0.6799 - val_loss: 0.4425 - val_acc: 0.9380 - val_mDice: 0.6313

Epoch 00033: val_mDice did not improve from 0.65090
Epoch 34/300
 - 13s - loss: 0.3930 - acc: 0.9365 - mDice: 0.6621 - val_loss: 0.4781 - val_acc: 0.9473 - val_mDice: 0.6209

Epoch 00034: val_mDice did not improve from 0.65090
Epoch 35/300
 - 13s - loss: 0.3657 - acc: 0.9397 - mDice: 0.6803 - val_loss: 0.4123 - val_acc: 0.9473 - val_mDice: 0.6520

Epoch 00035: val_mDice improved from 0.65090 to 0.65195, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 13s - loss: 0.3708 - acc: 0.9399 - mDice: 0.6775 - val_loss: 0.4636 - val_acc: 0.9482 - val_mDice: 0.6330

Epoch 00036: val_mDice did not improve from 0.65195
Epoch 37/300
 - 13s - loss: 0.4631 - acc: 0.9312 - mDice: 0.6211 - val_loss: 0.4551 - val_acc: 0.9358 - val_mDice: 0.6234

Epoch 00037: val_mDice did not improve from 0.65195
Epoch 38/300
 - 13s - loss: 0.4097 - acc: 0.9363 - mDice: 0.6510 - val_loss: 0.4411 - val_acc: 0.9369 - val_mDice: 0.6325

Epoch 00038: val_mDice did not improve from 0.65195
Epoch 39/300
 - 15s - loss: 0.3943 - acc: 0.9368 - mDice: 0.6617 - val_loss: 0.4193 - val_acc: 0.9435 - val_mDice: 0.6461

Epoch 00039: val_mDice did not improve from 0.65195
Epoch 40/300
 - 13s - loss: 0.3781 - acc: 0.9385 - mDice: 0.6717 - val_loss: 0.4520 - val_acc: 0.9491 - val_mDice: 0.6324

Epoch 00040: val_mDice did not improve from 0.65195
Epoch 41/300
 - 14s - loss: 0.3829 - acc: 0.9378 - mDice: 0.6691 - val_loss: 0.4216 - val_acc: 0.9493 - val_mDice: 0.6487

Epoch 00041: val_mDice did not improve from 0.65195
Epoch 42/300
 - 15s - loss: 0.3816 - acc: 0.9385 - mDice: 0.6699 - val_loss: 0.4263 - val_acc: 0.9443 - val_mDice: 0.6435

Epoch 00042: val_mDice did not improve from 0.65195
Epoch 43/300
 - 13s - loss: 0.4753 - acc: 0.9311 - mDice: 0.6172 - val_loss: 0.4447 - val_acc: 0.9405 - val_mDice: 0.6308

Epoch 00043: val_mDice did not improve from 0.65195
Epoch 44/300
 - 13s - loss: 0.3912 - acc: 0.9369 - mDice: 0.6624 - val_loss: 0.4319 - val_acc: 0.9474 - val_mDice: 0.6413

Epoch 00044: val_mDice did not improve from 0.65195
Epoch 45/300
 - 14s - loss: 0.3759 - acc: 0.9381 - mDice: 0.6727 - val_loss: 0.4217 - val_acc: 0.9479 - val_mDice: 0.6467

Epoch 00045: val_mDice did not improve from 0.65195
Epoch 46/300
 - 13s - loss: 0.3670 - acc: 0.9394 - mDice: 0.6790 - val_loss: 0.4223 - val_acc: 0.9491 - val_mDice: 0.6480

Epoch 00046: val_mDice did not improve from 0.65195
Epoch 47/300
 - 12s - loss: 0.3679 - acc: 0.9397 - mDice: 0.6785 - val_loss: 0.4196 - val_acc: 0.9468 - val_mDice: 0.6483

Epoch 00047: val_mDice did not improve from 0.65195
Epoch 48/300
 - 13s - loss: 0.3656 - acc: 0.9394 - mDice: 0.6806 - val_loss: 0.4196 - val_acc: 0.9496 - val_mDice: 0.6489

Epoch 00048: val_mDice did not improve from 0.65195
Epoch 49/300
 - 13s - loss: 0.3661 - acc: 0.9395 - mDice: 0.6800 - val_loss: 0.4097 - val_acc: 0.9503 - val_mDice: 0.6541

Epoch 00049: val_mDice improved from 0.65195 to 0.65414, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 50/300
 - 12s - loss: 0.3567 - acc: 0.9404 - mDice: 0.6864 - val_loss: 0.4125 - val_acc: 0.9457 - val_mDice: 0.6515

Epoch 00050: val_mDice did not improve from 0.65414
Epoch 51/300
 - 12s - loss: 0.3506 - acc: 0.9409 - mDice: 0.6908 - val_loss: 0.4142 - val_acc: 0.9489 - val_mDice: 0.6519

Epoch 00051: val_mDice did not improve from 0.65414
Epoch 52/300
 - 13s - loss: 0.3502 - acc: 0.9410 - mDice: 0.6911 - val_loss: 0.4417 - val_acc: 0.9493 - val_mDice: 0.6391

Epoch 00052: val_mDice did not improve from 0.65414
Epoch 53/300
 - 13s - loss: 0.3602 - acc: 0.9391 - mDice: 0.6836 - val_loss: 0.4213 - val_acc: 0.9474 - val_mDice: 0.6479

Epoch 00053: val_mDice did not improve from 0.65414
Epoch 54/300
 - 13s - loss: 0.3570 - acc: 0.9406 - mDice: 0.6865 - val_loss: 0.4184 - val_acc: 0.9469 - val_mDice: 0.6487

Epoch 00054: val_mDice did not improve from 0.65414
Epoch 55/300
 - 13s - loss: 0.3495 - acc: 0.9410 - mDice: 0.6913 - val_loss: 0.4324 - val_acc: 0.9481 - val_mDice: 0.6438

Epoch 00055: val_mDice did not improve from 0.65414
Epoch 56/300
 - 13s - loss: 0.3466 - acc: 0.9413 - mDice: 0.6936 - val_loss: 0.4328 - val_acc: 0.9410 - val_mDice: 0.6379

Epoch 00056: val_mDice did not improve from 0.65414
Epoch 57/300
 - 12s - loss: 0.4141 - acc: 0.9349 - mDice: 0.6511 - val_loss: 0.4371 - val_acc: 0.9476 - val_mDice: 0.6406

Epoch 00057: val_mDice did not improve from 0.65414
Epoch 58/300
 - 13s - loss: 0.4270 - acc: 0.9331 - mDice: 0.6418 - val_loss: 0.4290 - val_acc: 0.9431 - val_mDice: 0.6416

Epoch 00058: val_mDice did not improve from 0.65414
Epoch 59/300
 - 13s - loss: 0.3706 - acc: 0.9389 - mDice: 0.6764 - val_loss: 0.4246 - val_acc: 0.9486 - val_mDice: 0.6467

Epoch 00059: val_mDice did not improve from 0.65414
Epoch 60/300
 - 13s - loss: 0.3559 - acc: 0.9404 - mDice: 0.6869 - val_loss: 0.4199 - val_acc: 0.9442 - val_mDice: 0.6466

Epoch 00060: val_mDice did not improve from 0.65414
Epoch 61/300
 - 12s - loss: 0.3674 - acc: 0.9394 - mDice: 0.6800 - val_loss: 0.4751 - val_acc: 0.9499 - val_mDice: 0.6234

Epoch 00061: val_mDice did not improve from 0.65414
Epoch 62/300
 - 13s - loss: 0.3829 - acc: 0.9377 - mDice: 0.6700 - val_loss: 0.4300 - val_acc: 0.9411 - val_mDice: 0.6401

Epoch 00062: val_mDice did not improve from 0.65414
Epoch 63/300
 - 13s - loss: 0.4177 - acc: 0.9327 - mDice: 0.6463 - val_loss: 0.4283 - val_acc: 0.9470 - val_mDice: 0.6420

Epoch 00063: val_mDice did not improve from 0.65414
Epoch 64/300
 - 13s - loss: 0.3700 - acc: 0.9390 - mDice: 0.6769 - val_loss: 0.4253 - val_acc: 0.9500 - val_mDice: 0.6458

Epoch 00064: val_mDice did not improve from 0.65414
Epoch 65/300
 - 13s - loss: 0.3560 - acc: 0.9404 - mDice: 0.6868 - val_loss: 0.4394 - val_acc: 0.9414 - val_mDice: 0.6336

Epoch 00065: val_mDice did not improve from 0.65414
Epoch 66/300
 - 13s - loss: 0.4114 - acc: 0.9334 - mDice: 0.6526 - val_loss: 0.4517 - val_acc: 0.9482 - val_mDice: 0.6347

Epoch 00066: val_mDice did not improve from 0.65414
Epoch 67/300
 - 12s - loss: 0.3948 - acc: 0.9365 - mDice: 0.6608 - val_loss: 0.4427 - val_acc: 0.9439 - val_mDice: 0.6359

Epoch 00067: val_mDice did not improve from 0.65414
Epoch 68/300
 - 12s - loss: 0.3690 - acc: 0.9394 - mDice: 0.6782 - val_loss: 0.4530 - val_acc: 0.9380 - val_mDice: 0.6272

Epoch 00068: val_mDice did not improve from 0.65414
Epoch 69/300
 - 12s - loss: 0.4139 - acc: 0.9336 - mDice: 0.6494 - val_loss: 0.4441 - val_acc: 0.9476 - val_mDice: 0.6369

Epoch 00069: val_mDice did not improve from 0.65414
Epoch 70/300
 - 13s - loss: 0.3755 - acc: 0.9387 - mDice: 0.6742 - val_loss: 0.4317 - val_acc: 0.9476 - val_mDice: 0.6424

Epoch 00070: val_mDice did not improve from 0.65414
Epoch 71/300
 - 13s - loss: 0.3624 - acc: 0.9400 - mDice: 0.6826 - val_loss: 0.4249 - val_acc: 0.9493 - val_mDice: 0.6465

Epoch 00071: val_mDice did not improve from 0.65414
Epoch 72/300
 - 12s - loss: 0.3512 - acc: 0.9411 - mDice: 0.6904 - val_loss: 0.4189 - val_acc: 0.9491 - val_mDice: 0.6498

Epoch 00072: val_mDice did not improve from 0.65414
Epoch 73/300
 - 13s - loss: 0.3448 - acc: 0.9416 - mDice: 0.6947 - val_loss: 0.4157 - val_acc: 0.9467 - val_mDice: 0.6498

Epoch 00073: val_mDice did not improve from 0.65414
Epoch 74/300
 - 13s - loss: 0.3804 - acc: 0.9379 - mDice: 0.6707 - val_loss: 0.4270 - val_acc: 0.9503 - val_mDice: 0.6466

Epoch 00074: val_mDice did not improve from 0.65414
Epoch 75/300
 - 13s - loss: 0.3664 - acc: 0.9396 - mDice: 0.6798 - val_loss: 0.4223 - val_acc: 0.9451 - val_mDice: 0.6464

Epoch 00075: val_mDice did not improve from 0.65414
Epoch 76/300
 - 12s - loss: 0.4161 - acc: 0.9356 - mDice: 0.6509 - val_loss: 0.4566 - val_acc: 0.9433 - val_mDice: 0.6274

Epoch 00076: val_mDice did not improve from 0.65414
Epoch 77/300
 - 13s - loss: 0.3846 - acc: 0.9375 - mDice: 0.6674 - val_loss: 0.4226 - val_acc: 0.9486 - val_mDice: 0.6465

Epoch 00077: val_mDice did not improve from 0.65414
Epoch 78/300
 - 13s - loss: 0.3645 - acc: 0.9397 - mDice: 0.6812 - val_loss: 0.4169 - val_acc: 0.9489 - val_mDice: 0.6498

Epoch 00078: val_mDice did not improve from 0.65414
Epoch 79/300
 - 13s - loss: 0.3592 - acc: 0.9400 - mDice: 0.6843 - val_loss: 0.4241 - val_acc: 0.9493 - val_mDice: 0.6469

Epoch 00079: val_mDice did not improve from 0.65414
Epoch 80/300
 - 13s - loss: 0.3480 - acc: 0.9410 - mDice: 0.6926 - val_loss: 0.4174 - val_acc: 0.9500 - val_mDice: 0.6509

Epoch 00080: val_mDice did not improve from 0.65414
Epoch 81/300
 - 13s - loss: 0.3556 - acc: 0.9406 - mDice: 0.6876 - val_loss: 0.4145 - val_acc: 0.9480 - val_mDice: 0.6516

Epoch 00081: val_mDice did not improve from 0.65414
Epoch 82/300
 - 13s - loss: 0.3689 - acc: 0.9391 - mDice: 0.6785 - val_loss: 0.4204 - val_acc: 0.9494 - val_mDice: 0.6488

Epoch 00082: val_mDice did not improve from 0.65414
Epoch 83/300
 - 13s - loss: 0.3472 - acc: 0.9412 - mDice: 0.6935 - val_loss: 0.4120 - val_acc: 0.9492 - val_mDice: 0.6532

Epoch 00083: val_mDice did not improve from 0.65414
Epoch 84/300
 - 13s - loss: 0.3488 - acc: 0.9412 - mDice: 0.6921 - val_loss: 0.4285 - val_acc: 0.9512 - val_mDice: 0.6463

Epoch 00084: val_mDice did not improve from 0.65414
Epoch 85/300
 - 14s - loss: 0.3502 - acc: 0.9407 - mDice: 0.6909 - val_loss: 0.4072 - val_acc: 0.9487 - val_mDice: 0.6547

Epoch 00085: val_mDice improved from 0.65414 to 0.65468, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 86/300
 - 13s - loss: 0.3378 - acc: 0.9423 - mDice: 0.6997 - val_loss: 0.4082 - val_acc: 0.9477 - val_mDice: 0.6535

Epoch 00086: val_mDice did not improve from 0.65468
Epoch 87/300
 - 13s - loss: 0.3707 - acc: 0.9375 - mDice: 0.6774 - val_loss: 0.4185 - val_acc: 0.9477 - val_mDice: 0.6474

Epoch 00087: val_mDice did not improve from 0.65468
Epoch 88/300
 - 13s - loss: 0.3931 - acc: 0.9372 - mDice: 0.6632 - val_loss: 0.4051 - val_acc: 0.9488 - val_mDice: 0.6557

Epoch 00088: val_mDice improved from 0.65468 to 0.65566, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 89/300
 - 13s - loss: 0.3577 - acc: 0.9399 - mDice: 0.6854 - val_loss: 0.4084 - val_acc: 0.9510 - val_mDice: 0.6553

Epoch 00089: val_mDice did not improve from 0.65566
Epoch 90/300
 - 13s - loss: 0.3437 - acc: 0.9414 - mDice: 0.6958 - val_loss: 0.4130 - val_acc: 0.9499 - val_mDice: 0.6528

Epoch 00090: val_mDice did not improve from 0.65566
Epoch 91/300
 - 13s - loss: 0.3381 - acc: 0.9422 - mDice: 0.6997 - val_loss: 0.4846 - val_acc: 0.9494 - val_mDice: 0.6187

Epoch 00091: val_mDice did not improve from 0.65566
Epoch 92/300
 - 13s - loss: 0.4887 - acc: 0.9270 - mDice: 0.6050 - val_loss: 0.4550 - val_acc: 0.9456 - val_mDice: 0.6254

Epoch 00092: val_mDice did not improve from 0.65566
Epoch 93/300
 - 13s - loss: 0.3838 - acc: 0.9368 - mDice: 0.6678 - val_loss: 0.4385 - val_acc: 0.9460 - val_mDice: 0.6352

Epoch 00093: val_mDice did not improve from 0.65566
Epoch 94/300
 - 13s - loss: 0.3964 - acc: 0.9355 - mDice: 0.6602 - val_loss: 0.4357 - val_acc: 0.9433 - val_mDice: 0.6353

Epoch 00094: val_mDice did not improve from 0.65566
Epoch 95/300
 - 13s - loss: 0.4092 - acc: 0.9352 - mDice: 0.6530 - val_loss: 0.4171 - val_acc: 0.9478 - val_mDice: 0.6485

Epoch 00095: val_mDice did not improve from 0.65566
Epoch 96/300
 - 13s - loss: 0.3622 - acc: 0.9395 - mDice: 0.6828 - val_loss: 0.4168 - val_acc: 0.9492 - val_mDice: 0.6498

Epoch 00096: val_mDice did not improve from 0.65566
Epoch 97/300
 - 13s - loss: 0.3686 - acc: 0.9391 - mDice: 0.6785 - val_loss: 0.4137 - val_acc: 0.9503 - val_mDice: 0.6531

Epoch 00097: val_mDice did not improve from 0.65566
Epoch 98/300
 - 13s - loss: 0.3575 - acc: 0.9405 - mDice: 0.6859 - val_loss: 0.4105 - val_acc: 0.9501 - val_mDice: 0.6537

Epoch 00098: val_mDice did not improve from 0.65566
Epoch 99/300
 - 13s - loss: 0.3423 - acc: 0.9418 - mDice: 0.6972 - val_loss: 0.4024 - val_acc: 0.9497 - val_mDice: 0.6580

Epoch 00099: val_mDice improved from 0.65566 to 0.65797, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 100/300
 - 13s - loss: 0.3465 - acc: 0.9413 - mDice: 0.6935 - val_loss: 0.4088 - val_acc: 0.9497 - val_mDice: 0.6551

Epoch 00100: val_mDice did not improve from 0.65797
Epoch 101/300
 - 13s - loss: 0.3470 - acc: 0.9421 - mDice: 0.6990 - val_loss: 0.4060 - val_acc: 0.9468 - val_mDice: 0.6547

Epoch 00101: val_mDice did not improve from 0.65797
Epoch 102/300
 - 13s - loss: 0.3740 - acc: 0.9380 - mDice: 0.6750 - val_loss: 0.4166 - val_acc: 0.9452 - val_mDice: 0.6477

Epoch 00102: val_mDice did not improve from 0.65797
Epoch 103/300
 - 14s - loss: 0.3610 - acc: 0.9398 - mDice: 0.6834 - val_loss: 0.4041 - val_acc: 0.9479 - val_mDice: 0.6562

Epoch 00103: val_mDice did not improve from 0.65797
Epoch 104/300
 - 13s - loss: 0.3504 - acc: 0.9407 - mDice: 0.6910 - val_loss: 0.4131 - val_acc: 0.9507 - val_mDice: 0.6540

Epoch 00104: val_mDice did not improve from 0.65797
Epoch 105/300
 - 13s - loss: 0.3673 - acc: 0.9392 - mDice: 0.6791 - val_loss: 0.4194 - val_acc: 0.9453 - val_mDice: 0.6469

Epoch 00105: val_mDice did not improve from 0.65797
Epoch 106/300
 - 13s - loss: 0.3431 - acc: 0.9415 - mDice: 0.6962 - val_loss: 0.4080 - val_acc: 0.9505 - val_mDice: 0.6562

Epoch 00106: val_mDice did not improve from 0.65797
Epoch 107/300
 - 13s - loss: 0.3449 - acc: 0.9416 - mDice: 0.6947 - val_loss: 0.4099 - val_acc: 0.9484 - val_mDice: 0.6536

Epoch 00107: val_mDice did not improve from 0.65797
Epoch 108/300
 - 12s - loss: 0.3393 - acc: 0.9421 - mDice: 0.6990 - val_loss: 0.4114 - val_acc: 0.9470 - val_mDice: 0.6521

Epoch 00108: val_mDice did not improve from 0.65797
Epoch 109/300
 - 13s - loss: 0.3582 - acc: 0.9389 - mDice: 0.6858 - val_loss: 0.4260 - val_acc: 0.9508 - val_mDice: 0.6487

Epoch 00109: val_mDice did not improve from 0.65797
Epoch 110/300
 - 13s - loss: 0.3549 - acc: 0.9409 - mDice: 0.6882 - val_loss: 0.4023 - val_acc: 0.9510 - val_mDice: 0.6592

Epoch 00110: val_mDice improved from 0.65797 to 0.65916, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 111/300
 - 13s - loss: 0.3595 - acc: 0.9408 - mDice: 0.6848 - val_loss: 0.4083 - val_acc: 0.9472 - val_mDice: 0.6542

Epoch 00111: val_mDice did not improve from 0.65916
Epoch 112/300
 - 13s - loss: 0.3445 - acc: 0.9421 - mDice: 0.6953 - val_loss: 0.4023 - val_acc: 0.9511 - val_mDice: 0.6599

Epoch 00112: val_mDice improved from 0.65916 to 0.65989, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 113/300
 - 13s - loss: 0.3348 - acc: 0.9428 - mDice: 0.7022 - val_loss: 0.4135 - val_acc: 0.9453 - val_mDice: 0.6508

Epoch 00113: val_mDice did not improve from 0.65989
Epoch 114/300
 - 13s - loss: 0.3527 - acc: 0.9405 - mDice: 0.6894 - val_loss: 0.4070 - val_acc: 0.9503 - val_mDice: 0.6571

Epoch 00114: val_mDice did not improve from 0.65989
Epoch 115/300
 - 14s - loss: 0.3442 - acc: 0.9419 - mDice: 0.6962 - val_loss: 0.4060 - val_acc: 0.9503 - val_mDice: 0.6570

Epoch 00115: val_mDice did not improve from 0.65989
Epoch 116/300
 - 13s - loss: 0.3317 - acc: 0.9428 - mDice: 0.7046 - val_loss: 0.5229 - val_acc: 0.9480 - val_mDice: 0.6065

Epoch 00116: val_mDice did not improve from 0.65989
Epoch 117/300
 - 12s - loss: 0.3937 - acc: 0.9363 - mDice: 0.6667 - val_loss: 0.4167 - val_acc: 0.9450 - val_mDice: 0.6478

Epoch 00117: val_mDice did not improve from 0.65989
Epoch 118/300
 - 13s - loss: 0.3913 - acc: 0.9367 - mDice: 0.6635 - val_loss: 0.4100 - val_acc: 0.9483 - val_mDice: 0.6528

Epoch 00118: val_mDice did not improve from 0.65989
Epoch 119/300
 - 12s - loss: 0.3526 - acc: 0.9404 - mDice: 0.6888 - val_loss: 0.4148 - val_acc: 0.9488 - val_mDice: 0.6511

Epoch 00119: val_mDice did not improve from 0.65989
Epoch 120/300
 - 13s - loss: 0.3610 - acc: 0.9394 - mDice: 0.6835 - val_loss: 0.4204 - val_acc: 0.9500 - val_mDice: 0.6485

Epoch 00120: val_mDice did not improve from 0.65989
Epoch 121/300
 - 13s - loss: 0.3449 - acc: 0.9415 - mDice: 0.6947 - val_loss: 0.4264 - val_acc: 0.9494 - val_mDice: 0.6453

Epoch 00121: val_mDice did not improve from 0.65989
Epoch 122/300
 - 13s - loss: 0.3687 - acc: 0.9375 - mDice: 0.6780 - val_loss: 0.4334 - val_acc: 0.9381 - val_mDice: 0.6359

Epoch 00122: val_mDice did not improve from 0.65989
Epoch 123/300
 - 12s - loss: 0.3906 - acc: 0.9330 - mDice: 0.6639 - val_loss: 0.4288 - val_acc: 0.9501 - val_mDice: 0.6465

Epoch 00123: val_mDice did not improve from 0.65989
Epoch 124/300
 - 12s - loss: 0.3546 - acc: 0.9396 - mDice: 0.6876 - val_loss: 0.4275 - val_acc: 0.9473 - val_mDice: 0.6435

Epoch 00124: val_mDice did not improve from 0.65989
Epoch 125/300
 - 12s - loss: 0.4074 - acc: 0.9370 - mDice: 0.6589 - val_loss: 0.4101 - val_acc: 0.9498 - val_mDice: 0.6547

Epoch 00125: val_mDice did not improve from 0.65989
Epoch 126/300
 - 13s - loss: 0.3582 - acc: 0.9403 - mDice: 0.6854 - val_loss: 0.4234 - val_acc: 0.9505 - val_mDice: 0.6491

Epoch 00126: val_mDice did not improve from 0.65989
Epoch 127/300
 - 13s - loss: 0.4256 - acc: 0.9350 - mDice: 0.6477 - val_loss: 0.4609 - val_acc: 0.9484 - val_mDice: 0.6282

Epoch 00127: val_mDice did not improve from 0.65989
Epoch 128/300
 - 13s - loss: 0.4906 - acc: 0.9284 - mDice: 0.6069 - val_loss: 0.4747 - val_acc: 0.9357 - val_mDice: 0.6133

Epoch 00128: val_mDice did not improve from 0.65989
Epoch 129/300
 - 12s - loss: 0.3885 - acc: 0.9367 - mDice: 0.6645 - val_loss: 0.4414 - val_acc: 0.9445 - val_mDice: 0.6344

Epoch 00129: val_mDice did not improve from 0.65989
Epoch 130/300
 - 12s - loss: 0.3663 - acc: 0.9393 - mDice: 0.6798 - val_loss: 0.4315 - val_acc: 0.9478 - val_mDice: 0.6416

Epoch 00130: val_mDice did not improve from 0.65989
Epoch 131/300
 - 13s - loss: 0.3581 - acc: 0.9402 - mDice: 0.6856 - val_loss: 0.4288 - val_acc: 0.9477 - val_mDice: 0.6426

Epoch 00131: val_mDice did not improve from 0.65989
Epoch 132/300
 - 12s - loss: 0.3622 - acc: 0.9394 - mDice: 0.6825 - val_loss: 0.4271 - val_acc: 0.9450 - val_mDice: 0.6424

Epoch 00132: val_mDice did not improve from 0.65989
Epoch 133/300
 - 13s - loss: 0.3639 - acc: 0.9393 - mDice: 0.6821 - val_loss: 0.4233 - val_acc: 0.9464 - val_mDice: 0.6447

Epoch 00133: val_mDice did not improve from 0.65989
Epoch 134/300
 - 13s - loss: 0.3566 - acc: 0.9402 - mDice: 0.6865 - val_loss: 0.4161 - val_acc: 0.9477 - val_mDice: 0.6491

Epoch 00134: val_mDice did not improve from 0.65989
Epoch 135/300
 - 12s - loss: 0.3463 - acc: 0.9412 - mDice: 0.6935 - val_loss: 0.4183 - val_acc: 0.9468 - val_mDice: 0.6477

Epoch 00135: val_mDice did not improve from 0.65989
Epoch 136/300
 - 12s - loss: 0.3937 - acc: 0.9351 - mDice: 0.6627 - val_loss: 0.4218 - val_acc: 0.9454 - val_mDice: 0.6460

Epoch 00136: val_mDice did not improve from 0.65989
Epoch 137/300
 - 13s - loss: 0.3624 - acc: 0.9387 - mDice: 0.6826 - val_loss: 0.4219 - val_acc: 0.9468 - val_mDice: 0.6460

Epoch 00137: val_mDice did not improve from 0.65989
Epoch 138/300
 - 13s - loss: 0.3554 - acc: 0.9388 - mDice: 0.6871 - val_loss: 0.4230 - val_acc: 0.9460 - val_mDice: 0.6460

Epoch 00138: val_mDice did not improve from 0.65989
Epoch 139/300
 - 14s - loss: 0.3412 - acc: 0.9411 - mDice: 0.6973 - val_loss: 0.4209 - val_acc: 0.9490 - val_mDice: 0.6481

Epoch 00139: val_mDice did not improve from 0.65989
Epoch 140/300
 - 13s - loss: 0.3854 - acc: 0.9366 - mDice: 0.6676 - val_loss: 0.4269 - val_acc: 0.9438 - val_mDice: 0.6421

Epoch 00140: val_mDice did not improve from 0.65989
Epoch 141/300
 - 14s - loss: 0.3498 - acc: 0.9404 - mDice: 0.6911 - val_loss: 0.4178 - val_acc: 0.9479 - val_mDice: 0.6493

Epoch 00141: val_mDice did not improve from 0.65989
Epoch 142/300
 - 13s - loss: 0.3384 - acc: 0.9416 - mDice: 0.6993 - val_loss: 0.4138 - val_acc: 0.9449 - val_mDice: 0.6498

Epoch 00142: val_mDice did not improve from 0.65989
Epoch 143/300
 - 13s - loss: 0.3525 - acc: 0.9394 - mDice: 0.6892 - val_loss: 0.4090 - val_acc: 0.9502 - val_mDice: 0.6553

Epoch 00143: val_mDice did not improve from 0.65989
Epoch 144/300
 - 13s - loss: 0.3329 - acc: 0.9420 - mDice: 0.7031 - val_loss: 0.4068 - val_acc: 0.9502 - val_mDice: 0.6567

Epoch 00144: val_mDice did not improve from 0.65989
Epoch 145/300
 - 13s - loss: 0.3286 - acc: 0.9426 - mDice: 0.7062 - val_loss: 0.4116 - val_acc: 0.9510 - val_mDice: 0.6546

Epoch 00145: val_mDice did not improve from 0.65989
Epoch 146/300
 - 13s - loss: 0.3707 - acc: 0.9401 - mDice: 0.6802 - val_loss: 0.4164 - val_acc: 0.9435 - val_mDice: 0.6484

Epoch 00146: val_mDice did not improve from 0.65989
Epoch 147/300
 - 13s - loss: 0.4108 - acc: 0.9331 - mDice: 0.6524 - val_loss: 0.4129 - val_acc: 0.9515 - val_mDice: 0.6514

Epoch 00147: val_mDice did not improve from 0.65989
Epoch 148/300
 - 13s - loss: 0.3441 - acc: 0.9412 - mDice: 0.6954 - val_loss: 0.4294 - val_acc: 0.9437 - val_mDice: 0.6396

Epoch 00148: val_mDice did not improve from 0.65989
Epoch 149/300
 - 14s - loss: 0.4373 - acc: 0.9325 - mDice: 0.6347 - val_loss: 0.4191 - val_acc: 0.9504 - val_mDice: 0.6485

Epoch 00149: val_mDice did not improve from 0.65989
Epoch 150/300
 - 13s - loss: 0.3586 - acc: 0.9400 - mDice: 0.6846 - val_loss: 0.4114 - val_acc: 0.9520 - val_mDice: 0.6552

Epoch 00150: val_mDice did not improve from 0.65989
Epoch 151/300
 - 13s - loss: 0.3490 - acc: 0.9410 - mDice: 0.6915 - val_loss: 0.4064 - val_acc: 0.9516 - val_mDice: 0.6580

Epoch 00151: val_mDice did not improve from 0.65989
Epoch 152/300
 - 13s - loss: 0.3431 - acc: 0.9416 - mDice: 0.6963 - val_loss: 0.4028 - val_acc: 0.9522 - val_mDice: 0.6607

Epoch 00152: val_mDice improved from 0.65989 to 0.66069, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 153/300
 - 13s - loss: 0.3752 - acc: 0.9379 - mDice: 0.6743 - val_loss: 0.5509 - val_acc: 0.9488 - val_mDice: 0.6002

Epoch 00153: val_mDice did not improve from 0.66069
Epoch 154/300
 - 13s - loss: 0.4992 - acc: 0.9204 - mDice: 0.6019 - val_loss: 0.4491 - val_acc: 0.9440 - val_mDice: 0.6294

Epoch 00154: val_mDice did not improve from 0.66069
Epoch 155/300
 - 13s - loss: 0.4027 - acc: 0.9315 - mDice: 0.6550 - val_loss: 0.4290 - val_acc: 0.9466 - val_mDice: 0.6425

Epoch 00155: val_mDice did not improve from 0.66069
Epoch 156/300
 - 13s - loss: 0.3787 - acc: 0.9354 - mDice: 0.6713 - val_loss: 0.4272 - val_acc: 0.9438 - val_mDice: 0.6430

Epoch 00156: val_mDice did not improve from 0.66069
Epoch 157/300
 - 13s - loss: 0.4303 - acc: 0.9311 - mDice: 0.6424 - val_loss: 0.4449 - val_acc: 0.9443 - val_mDice: 0.6322

Epoch 00157: val_mDice did not improve from 0.66069
Epoch 158/300
 - 14s - loss: 0.3973 - acc: 0.9344 - mDice: 0.6593 - val_loss: 0.4194 - val_acc: 0.9488 - val_mDice: 0.6478

Epoch 00158: val_mDice did not improve from 0.66069
Epoch 159/300
 - 13s - loss: 0.3622 - acc: 0.9382 - mDice: 0.6823 - val_loss: 0.4166 - val_acc: 0.9488 - val_mDice: 0.6499

Epoch 00159: val_mDice did not improve from 0.66069
Epoch 160/300
 - 12s - loss: 0.3766 - acc: 0.9373 - mDice: 0.6732 - val_loss: 0.4214 - val_acc: 0.9491 - val_mDice: 0.6480

Epoch 00160: val_mDice did not improve from 0.66069
Epoch 161/300
 - 13s - loss: 0.3549 - acc: 0.9395 - mDice: 0.6876 - val_loss: 0.4181 - val_acc: 0.9504 - val_mDice: 0.6506

Epoch 00161: val_mDice did not improve from 0.66069
Epoch 162/300
 - 12s - loss: 0.3533 - acc: 0.9401 - mDice: 0.6890 - val_loss: 0.4182 - val_acc: 0.9488 - val_mDice: 0.6495

Epoch 00162: val_mDice did not improve from 0.66069
Epoch 163/300
 - 12s - loss: 0.3740 - acc: 0.9385 - mDice: 0.6750 - val_loss: 0.4407 - val_acc: 0.9472 - val_mDice: 0.6373

Epoch 00163: val_mDice did not improve from 0.66069
Epoch 164/300
 - 12s - loss: 0.3733 - acc: 0.9388 - mDice: 0.6771 - val_loss: 0.4233 - val_acc: 0.9482 - val_mDice: 0.6471

Epoch 00164: val_mDice did not improve from 0.66069
Epoch 165/300
 - 12s - loss: 0.3492 - acc: 0.9407 - mDice: 0.6917 - val_loss: 0.4173 - val_acc: 0.9504 - val_mDice: 0.6515

Epoch 00165: val_mDice did not improve from 0.66069
Epoch 166/300
 - 12s - loss: 0.3559 - acc: 0.9399 - mDice: 0.6868 - val_loss: 0.4106 - val_acc: 0.9500 - val_mDice: 0.6549

Epoch 00166: val_mDice did not improve from 0.66069
Epoch 167/300
 - 12s - loss: 0.3395 - acc: 0.9418 - mDice: 0.6985 - val_loss: 0.4101 - val_acc: 0.9502 - val_mDice: 0.6546

Epoch 00167: val_mDice did not improve from 0.66069
Epoch 168/300
 - 12s - loss: 0.3344 - acc: 0.9423 - mDice: 0.7021 - val_loss: 0.4082 - val_acc: 0.9507 - val_mDice: 0.6565

Epoch 00168: val_mDice did not improve from 0.66069
Epoch 169/300
 - 12s - loss: 0.3510 - acc: 0.9407 - mDice: 0.6903 - val_loss: 0.4138 - val_acc: 0.9484 - val_mDice: 0.6520

Epoch 00169: val_mDice did not improve from 0.66069
Epoch 170/300
 - 12s - loss: 0.3460 - acc: 0.9409 - mDice: 0.6939 - val_loss: 0.4128 - val_acc: 0.9481 - val_mDice: 0.6521

Epoch 00170: val_mDice did not improve from 0.66069
Epoch 171/300
 - 12s - loss: 0.3893 - acc: 0.9376 - mDice: 0.6664 - val_loss: 0.4177 - val_acc: 0.9509 - val_mDice: 0.6510

Epoch 00171: val_mDice did not improve from 0.66069
Epoch 172/300
 - 12s - loss: 0.3527 - acc: 0.9405 - mDice: 0.6892 - val_loss: 0.4123 - val_acc: 0.9472 - val_mDice: 0.6522

Epoch 00172: val_mDice did not improve from 0.66069
Epoch 173/300
 - 12s - loss: 0.3535 - acc: 0.9404 - mDice: 0.6886 - val_loss: 0.4027 - val_acc: 0.9513 - val_mDice: 0.6599

Epoch 00173: val_mDice did not improve from 0.66069
Epoch 174/300
 - 12s - loss: 0.3457 - acc: 0.9422 - mDice: 0.6991 - val_loss: 0.4037 - val_acc: 0.9511 - val_mDice: 0.6594

Epoch 00174: val_mDice did not improve from 0.66069
Epoch 175/300
 - 12s - loss: 0.3322 - acc: 0.9427 - mDice: 0.7038 - val_loss: 0.4022 - val_acc: 0.9510 - val_mDice: 0.6604

Epoch 00175: val_mDice did not improve from 0.66069
Epoch 176/300
 - 12s - loss: 0.3281 - acc: 0.9431 - mDice: 0.7069 - val_loss: 0.4097 - val_acc: 0.9519 - val_mDice: 0.6572

Epoch 00176: val_mDice did not improve from 0.66069
Epoch 177/300
 - 12s - loss: 0.3342 - acc: 0.9426 - mDice: 0.7023 - val_loss: 0.4015 - val_acc: 0.9500 - val_mDice: 0.6604

Epoch 00177: val_mDice did not improve from 0.66069
Epoch 178/300
 - 12s - loss: 0.3238 - acc: 0.9436 - mDice: 0.7103 - val_loss: 0.4169 - val_acc: 0.9516 - val_mDice: 0.6532

Epoch 00178: val_mDice did not improve from 0.66069
Epoch 179/300
 - 17s - loss: 0.3400 - acc: 0.9423 - mDice: 0.6986 - val_loss: 0.4096 - val_acc: 0.9454 - val_mDice: 0.6528

Epoch 00179: val_mDice did not improve from 0.66069
Epoch 180/300
 - 18s - loss: 0.3634 - acc: 0.9385 - mDice: 0.6826 - val_loss: 0.4042 - val_acc: 0.9484 - val_mDice: 0.6571

Epoch 00180: val_mDice did not improve from 0.66069
Epoch 181/300
 - 18s - loss: 0.3732 - acc: 0.9389 - mDice: 0.6764 - val_loss: 0.4086 - val_acc: 0.9502 - val_mDice: 0.6557

Epoch 00181: val_mDice did not improve from 0.66069
Epoch 182/300
 - 12s - loss: 0.3405 - acc: 0.9417 - mDice: 0.6979 - val_loss: 0.4073 - val_acc: 0.9501 - val_mDice: 0.6562

Epoch 00182: val_mDice did not improve from 0.66069
Epoch 183/300
 - 12s - loss: 0.3320 - acc: 0.9425 - mDice: 0.7041 - val_loss: 0.4115 - val_acc: 0.9510 - val_mDice: 0.6553

Epoch 00183: val_mDice did not improve from 0.66069
Epoch 184/300
 - 12s - loss: 0.3391 - acc: 0.9422 - mDice: 0.6996 - val_loss: 0.4119 - val_acc: 0.9501 - val_mDice: 0.6537

Epoch 00184: val_mDice did not improve from 0.66069
Epoch 185/300
 - 12s - loss: 0.3318 - acc: 0.9423 - mDice: 0.7044 - val_loss: 0.4110 - val_acc: 0.9501 - val_mDice: 0.6545

Epoch 00185: val_mDice did not improve from 0.66069
Epoch 186/300
 - 12s - loss: 0.3280 - acc: 0.9430 - mDice: 0.7072 - val_loss: 0.4285 - val_acc: 0.9504 - val_mDice: 0.6472

Epoch 00186: val_mDice did not improve from 0.66069
Epoch 187/300
 - 12s - loss: 0.4004 - acc: 0.9347 - mDice: 0.6600 - val_loss: 0.4189 - val_acc: 0.9490 - val_mDice: 0.6498

Epoch 00187: val_mDice did not improve from 0.66069
Epoch 188/300
 - 12s - loss: 0.3741 - acc: 0.9391 - mDice: 0.6785 - val_loss: 0.4109 - val_acc: 0.9454 - val_mDice: 0.6520

Epoch 00188: val_mDice did not improve from 0.66069
Epoch 189/300
 - 12s - loss: 0.3408 - acc: 0.9414 - mDice: 0.6976 - val_loss: 0.4031 - val_acc: 0.9509 - val_mDice: 0.6594

Epoch 00189: val_mDice did not improve from 0.66069
Epoch 190/300
 - 12s - loss: 0.3364 - acc: 0.9424 - mDice: 0.7011 - val_loss: 0.4005 - val_acc: 0.9502 - val_mDice: 0.6608

Epoch 00190: val_mDice improved from 0.66069 to 0.66080, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 191/300
 - 12s - loss: 0.3352 - acc: 0.9423 - mDice: 0.7020 - val_loss: 0.4397 - val_acc: 0.9508 - val_mDice: 0.6421

Epoch 00191: val_mDice did not improve from 0.66080
Epoch 192/300
 - 12s - loss: 0.3930 - acc: 0.9379 - mDice: 0.6682 - val_loss: 0.4082 - val_acc: 0.9488 - val_mDice: 0.6553

Epoch 00192: val_mDice did not improve from 0.66080
Epoch 193/300
 - 12s - loss: 0.3409 - acc: 0.9417 - mDice: 0.6975 - val_loss: 0.4022 - val_acc: 0.9495 - val_mDice: 0.6588

Epoch 00193: val_mDice did not improve from 0.66080
Epoch 194/300
 - 12s - loss: 0.3664 - acc: 0.9391 - mDice: 0.6806 - val_loss: 0.4034 - val_acc: 0.9500 - val_mDice: 0.6586

Epoch 00194: val_mDice did not improve from 0.66080
Epoch 195/300
 - 12s - loss: 0.3341 - acc: 0.9423 - mDice: 0.7024 - val_loss: 0.4026 - val_acc: 0.9494 - val_mDice: 0.6593

Epoch 00195: val_mDice did not improve from 0.66080
Epoch 196/300
 - 12s - loss: 0.3306 - acc: 0.9428 - mDice: 0.7053 - val_loss: 0.4063 - val_acc: 0.9506 - val_mDice: 0.6578

Epoch 00196: val_mDice did not improve from 0.66080
Epoch 197/300
 - 12s - loss: 0.3365 - acc: 0.9425 - mDice: 0.7014 - val_loss: 0.4089 - val_acc: 0.9515 - val_mDice: 0.6578

Epoch 00197: val_mDice did not improve from 0.66080
Epoch 198/300
 - 12s - loss: 0.3503 - acc: 0.9408 - mDice: 0.6913 - val_loss: 0.4104 - val_acc: 0.9503 - val_mDice: 0.6555

Epoch 00198: val_mDice did not improve from 0.66080
Epoch 199/300
 - 12s - loss: 0.3399 - acc: 0.9419 - mDice: 0.6986 - val_loss: 0.4361 - val_acc: 0.9511 - val_mDice: 0.6453

Epoch 00199: val_mDice did not improve from 0.66080
Epoch 200/300
 - 12s - loss: 0.3510 - acc: 0.9415 - mDice: 0.6958 - val_loss: 0.4064 - val_acc: 0.9490 - val_mDice: 0.6579

Epoch 00200: val_mDice did not improve from 0.66080
Epoch 201/300
 - 12s - loss: 0.3276 - acc: 0.9429 - mDice: 0.7070 - val_loss: 0.4044 - val_acc: 0.9498 - val_mDice: 0.6590

Epoch 00201: val_mDice did not improve from 0.66080
Epoch 202/300
 - 12s - loss: 0.3243 - acc: 0.9434 - mDice: 0.7098 - val_loss: 0.4260 - val_acc: 0.9417 - val_mDice: 0.6423

Epoch 00202: val_mDice did not improve from 0.66080
Epoch 203/300
 - 12s - loss: 0.3783 - acc: 0.9352 - mDice: 0.6736 - val_loss: 0.4139 - val_acc: 0.9511 - val_mDice: 0.6526

Epoch 00203: val_mDice did not improve from 0.66080
Epoch 204/300
 - 12s - loss: 0.3350 - acc: 0.9421 - mDice: 0.7019 - val_loss: 0.4066 - val_acc: 0.9512 - val_mDice: 0.6582

Epoch 00204: val_mDice did not improve from 0.66080
Epoch 205/300
 - 12s - loss: 0.3361 - acc: 0.9420 - mDice: 0.7007 - val_loss: 0.4045 - val_acc: 0.9514 - val_mDice: 0.6598

Epoch 00205: val_mDice did not improve from 0.66080
Epoch 206/300
 - 12s - loss: 0.3305 - acc: 0.9429 - mDice: 0.7054 - val_loss: 0.4079 - val_acc: 0.9498 - val_mDice: 0.6567

Epoch 00206: val_mDice did not improve from 0.66080
Epoch 207/300
 - 12s - loss: 0.3388 - acc: 0.9407 - mDice: 0.6991 - val_loss: 0.4175 - val_acc: 0.9457 - val_mDice: 0.6489

Epoch 00207: val_mDice did not improve from 0.66080
Epoch 208/300
 - 12s - loss: 0.3774 - acc: 0.9368 - mDice: 0.6760 - val_loss: 0.4048 - val_acc: 0.9506 - val_mDice: 0.6584

Epoch 00208: val_mDice did not improve from 0.66080
Epoch 209/300
 - 12s - loss: 0.3393 - acc: 0.9412 - mDice: 0.6986 - val_loss: 0.4053 - val_acc: 0.9514 - val_mDice: 0.6587

Epoch 00209: val_mDice did not improve from 0.66080
Epoch 210/300
 - 18s - loss: 0.3273 - acc: 0.9428 - mDice: 0.7074 - val_loss: 0.4031 - val_acc: 0.9511 - val_mDice: 0.6597

Epoch 00210: val_mDice did not improve from 0.66080
Epoch 211/300
 - 19s - loss: 0.3283 - acc: 0.9430 - mDice: 0.7074 - val_loss: 0.4009 - val_acc: 0.9512 - val_mDice: 0.6606

Epoch 00211: val_mDice did not improve from 0.66080
Epoch 212/300
 - 12s - loss: 0.3230 - acc: 0.9434 - mDice: 0.7105 - val_loss: 0.3983 - val_acc: 0.9516 - val_mDice: 0.6630

Epoch 00212: val_mDice improved from 0.66080 to 0.66296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 213/300
 - 12s - loss: 0.3279 - acc: 0.9429 - mDice: 0.7071 - val_loss: 0.4025 - val_acc: 0.9499 - val_mDice: 0.6597

Epoch 00213: val_mDice did not improve from 0.66296
Epoch 214/300
 - 12s - loss: 0.3391 - acc: 0.9417 - mDice: 0.6986 - val_loss: 0.4043 - val_acc: 0.9516 - val_mDice: 0.6592

Epoch 00214: val_mDice did not improve from 0.66296
Epoch 215/300
 - 13s - loss: 0.3236 - acc: 0.9433 - mDice: 0.7103 - val_loss: 0.3994 - val_acc: 0.9522 - val_mDice: 0.6627

Epoch 00215: val_mDice did not improve from 0.66296
Epoch 216/300
 - 12s - loss: 0.3191 - acc: 0.9438 - mDice: 0.7132 - val_loss: 0.3998 - val_acc: 0.9510 - val_mDice: 0.6618

Epoch 00216: val_mDice did not improve from 0.66296
Epoch 217/300
 - 12s - loss: 0.3170 - acc: 0.9440 - mDice: 0.7154 - val_loss: 0.4125 - val_acc: 0.9526 - val_mDice: 0.6557

Epoch 00217: val_mDice did not improve from 0.66296
Epoch 218/300
 - 12s - loss: 0.3821 - acc: 0.9369 - mDice: 0.6705 - val_loss: 0.4106 - val_acc: 0.9512 - val_mDice: 0.6567

Epoch 00218: val_mDice did not improve from 0.66296
Epoch 219/300
 - 12s - loss: 0.3987 - acc: 0.9352 - mDice: 0.6604 - val_loss: 0.4054 - val_acc: 0.9501 - val_mDice: 0.6584

Epoch 00219: val_mDice did not improve from 0.66296
Epoch 220/300
 - 12s - loss: 0.3412 - acc: 0.9408 - mDice: 0.6977 - val_loss: 0.4066 - val_acc: 0.9497 - val_mDice: 0.6577

Epoch 00220: val_mDice did not improve from 0.66296
Epoch 221/300
 - 12s - loss: 0.3403 - acc: 0.9410 - mDice: 0.6979 - val_loss: 0.4152 - val_acc: 0.9497 - val_mDice: 0.6530

Epoch 00221: val_mDice did not improve from 0.66296
Epoch 222/300
 - 12s - loss: 0.3454 - acc: 0.9410 - mDice: 0.6954 - val_loss: 0.4125 - val_acc: 0.9494 - val_mDice: 0.6540

Epoch 00222: val_mDice did not improve from 0.66296
Epoch 223/300
 - 12s - loss: 0.3293 - acc: 0.9425 - mDice: 0.7063 - val_loss: 0.4144 - val_acc: 0.9518 - val_mDice: 0.6550

Epoch 00223: val_mDice did not improve from 0.66296
Epoch 224/300
 - 12s - loss: 0.3760 - acc: 0.9372 - mDice: 0.6737 - val_loss: 0.4169 - val_acc: 0.9487 - val_mDice: 0.6494

Epoch 00224: val_mDice did not improve from 0.66296
Epoch 225/300
 - 12s - loss: 0.3441 - acc: 0.9403 - mDice: 0.6950 - val_loss: 0.4160 - val_acc: 0.9484 - val_mDice: 0.6498

Epoch 00225: val_mDice did not improve from 0.66296
Epoch 226/300
 - 12s - loss: 0.3339 - acc: 0.9419 - mDice: 0.7031 - val_loss: 0.4082 - val_acc: 0.9494 - val_mDice: 0.6553

Epoch 00226: val_mDice did not improve from 0.66296
Epoch 227/300
 - 12s - loss: 0.3737 - acc: 0.9381 - mDice: 0.6757 - val_loss: 0.4180 - val_acc: 0.9480 - val_mDice: 0.6489

Epoch 00227: val_mDice did not improve from 0.66296
Epoch 228/300
 - 12s - loss: 0.3432 - acc: 0.9412 - mDice: 0.6963 - val_loss: 0.4095 - val_acc: 0.9494 - val_mDice: 0.6547

Epoch 00228: val_mDice did not improve from 0.66296
Epoch 229/300
 - 12s - loss: 0.3358 - acc: 0.9418 - mDice: 0.7012 - val_loss: 0.4067 - val_acc: 0.9514 - val_mDice: 0.6587

Epoch 00229: val_mDice did not improve from 0.66296
Epoch 230/300
 - 12s - loss: 0.3658 - acc: 0.9393 - mDice: 0.6806 - val_loss: 0.4045 - val_acc: 0.9489 - val_mDice: 0.6573

Epoch 00230: val_mDice did not improve from 0.66296
Epoch 231/300
 - 12s - loss: 0.3326 - acc: 0.9423 - mDice: 0.7036 - val_loss: 0.4005 - val_acc: 0.9499 - val_mDice: 0.6604

Epoch 00231: val_mDice did not improve from 0.66296
Epoch 232/300
 - 12s - loss: 0.3291 - acc: 0.9429 - mDice: 0.7064 - val_loss: 0.4038 - val_acc: 0.9509 - val_mDice: 0.6592

Epoch 00232: val_mDice did not improve from 0.66296
Epoch 233/300
 - 12s - loss: 0.3240 - acc: 0.9436 - mDice: 0.7098 - val_loss: 0.4117 - val_acc: 0.9487 - val_mDice: 0.6541

Epoch 00233: val_mDice did not improve from 0.66296
Epoch 234/300
 - 12s - loss: 0.3781 - acc: 0.9371 - mDice: 0.6721 - val_loss: 0.4257 - val_acc: 0.9480 - val_mDice: 0.6454

Epoch 00234: val_mDice did not improve from 0.66296
Epoch 235/300
 - 12s - loss: 0.3385 - acc: 0.9411 - mDice: 0.6993 - val_loss: 0.4121 - val_acc: 0.9494 - val_mDice: 0.6543

Epoch 00235: val_mDice did not improve from 0.66296
Epoch 236/300
 - 12s - loss: 0.3325 - acc: 0.9420 - mDice: 0.7038 - val_loss: 0.4094 - val_acc: 0.9513 - val_mDice: 0.6575

Epoch 00236: val_mDice did not improve from 0.66296
Epoch 237/300
 - 12s - loss: 0.3332 - acc: 0.9427 - mDice: 0.7073 - val_loss: 0.4035 - val_acc: 0.9496 - val_mDice: 0.6594

Epoch 00237: val_mDice did not improve from 0.66296
Epoch 238/300
 - 12s - loss: 0.3343 - acc: 0.9423 - mDice: 0.7026 - val_loss: 0.4172 - val_acc: 0.9518 - val_mDice: 0.6545

Epoch 00238: val_mDice did not improve from 0.66296
Epoch 239/300
 - 12s - loss: 0.3299 - acc: 0.9423 - mDice: 0.7056 - val_loss: 0.4029 - val_acc: 0.9510 - val_mDice: 0.6604

Epoch 00239: val_mDice did not improve from 0.66296
Epoch 240/300
 - 13s - loss: 0.3236 - acc: 0.9436 - mDice: 0.7105 - val_loss: 0.4068 - val_acc: 0.9499 - val_mDice: 0.6575

Epoch 00240: val_mDice did not improve from 0.66296
Epoch 241/300
 - 18s - loss: 0.3638 - acc: 0.9403 - mDice: 0.6840 - val_loss: 0.4040 - val_acc: 0.9516 - val_mDice: 0.6594

Epoch 00241: val_mDice did not improve from 0.66296
Epoch 242/300
 - 19s - loss: 0.3292 - acc: 0.9429 - mDice: 0.7063 - val_loss: 0.4007 - val_acc: 0.9512 - val_mDice: 0.6609

Epoch 00242: val_mDice did not improve from 0.66296
Epoch 243/300
 - 12s - loss: 0.3488 - acc: 0.9409 - mDice: 0.6922 - val_loss: 0.4156 - val_acc: 0.9510 - val_mDice: 0.6525

Epoch 00243: val_mDice did not improve from 0.66296
Epoch 244/300
 - 12s - loss: 0.3643 - acc: 0.9377 - mDice: 0.6817 - val_loss: 0.4145 - val_acc: 0.9485 - val_mDice: 0.6518

Epoch 00244: val_mDice did not improve from 0.66296
Epoch 245/300
 - 12s - loss: 0.3467 - acc: 0.9405 - mDice: 0.6939 - val_loss: 0.4189 - val_acc: 0.9479 - val_mDice: 0.6490

Epoch 00245: val_mDice did not improve from 0.66296
Epoch 246/300
 - 12s - loss: 0.3313 - acc: 0.9421 - mDice: 0.7043 - val_loss: 0.4113 - val_acc: 0.9485 - val_mDice: 0.6535

Epoch 00246: val_mDice did not improve from 0.66296
Epoch 247/300
 - 12s - loss: 0.3258 - acc: 0.9428 - mDice: 0.7086 - val_loss: 0.4152 - val_acc: 0.9515 - val_mDice: 0.6545

Epoch 00247: val_mDice did not improve from 0.66296
Epoch 248/300
 - 13s - loss: 0.3292 - acc: 0.9427 - mDice: 0.7059 - val_loss: 0.4092 - val_acc: 0.9495 - val_mDice: 0.6552

Epoch 00248: val_mDice did not improve from 0.66296
Epoch 249/300
 - 12s - loss: 0.3213 - acc: 0.9431 - mDice: 0.7119 - val_loss: 0.4052 - val_acc: 0.9512 - val_mDice: 0.6594

Epoch 00249: val_mDice did not improve from 0.66296
Epoch 250/300
 - 12s - loss: 0.3250 - acc: 0.9429 - mDice: 0.7091 - val_loss: 0.4146 - val_acc: 0.9496 - val_mDice: 0.6527

Epoch 00250: val_mDice did not improve from 0.66296
Epoch 251/300
 - 12s - loss: 0.3294 - acc: 0.9428 - mDice: 0.7061 - val_loss: 0.4102 - val_acc: 0.9506 - val_mDice: 0.6561

Epoch 00251: val_mDice did not improve from 0.66296
Epoch 252/300
 - 12s - loss: 0.3184 - acc: 0.9437 - mDice: 0.7140 - val_loss: 0.4223 - val_acc: 0.9471 - val_mDice: 0.6470

Epoch 00252: val_mDice did not improve from 0.66296
Restoring model weights from the end of the best epoch
Epoch 00252: early stopping
{'val_loss': [1.1576372567150328, 0.5112454183399677, 0.5010681061281098, 0.45903239937292206, 0.46270014428430134, 0.44571298567785156, 0.436481687757704, 0.4794124625623226, 0.42689261337121326, 0.5036906943553023, 0.433153771277931, 0.4235331424408489, 0.44669322048624355, 0.43452833261754775, 0.47773639319671524, 0.4193369700676865, 0.4146258338458008, 0.44378288173013264, 0.4262642289201419, 0.4237377689116531, 0.4334129004014863, 0.4594905624787013, 0.47836844250559807, 0.4348006736901071, 0.4324299142592483, 0.4176688856548733, 0.4307737727132108, 0.4235035218298435, 0.41503214794728494, 0.4221567110055023, 0.43132153815693325, 0.4302119625111421, 0.44254934415221214, 0.4780956564678086, 0.4123281298412217, 0.46359390765428543, 0.455110145939721, 0.4411175073020988, 0.419324043724272, 0.4519934426579211, 0.4215967572397656, 0.42631330258316463, 0.44467319258385235, 0.4318667948246002, 0.4216673399011294, 0.4222782970302635, 0.4195774959193336, 0.41963757119245, 0.40972820710804725, 0.41253427705831, 0.41418447759416366, 0.441733723713292, 0.421307984739542, 0.41842854685253567, 0.4323699275652568, 0.43279420253303313, 0.43710048827860093, 0.42897053476836944, 0.42455194352401626, 0.41987597238686347, 0.47506241790122455, 0.4300386230978701, 0.4283190721438991, 0.4252668333550294, 0.43941694994767505, 0.4516725209024217, 0.4427090986735291, 0.4529762922061814, 0.4440866820514202, 0.43170932597584194, 0.4248845995300346, 0.41890819287962383, 0.41569483114613426, 0.4270138012038337, 0.4223333096338643, 0.45659108087420464, 0.4226212025516563, 0.4168704230752256, 0.4240841505428155, 0.4173987747894393, 0.4144938799242179, 0.4203764833509922, 0.41198152634832597, 0.42854567286041045, 0.4071875272525681, 0.40815621780024636, 0.4185277728570832, 0.40512344365318614, 0.4084198462466399, 0.41297490646441776, 0.48463931183020276, 0.45496487990021706, 0.4384794251786338, 0.43568214277426404, 0.4171249460842874, 0.4168245750996802, 0.41370354178879, 0.4104640434185664, 0.402429510321882, 0.4088277535306083, 0.40601787716150284, 0.41661808929509586, 0.4040866216851605, 0.41307050900326836, 0.41938701561755604, 0.40795209010442096, 0.40992192054788273, 0.4114187728199694, 0.42603180102176136, 0.4023135093351205, 0.40827306277222103, 0.4023265644080109, 0.4135141939752632, 0.4069648049771786, 0.4059888178275691, 0.5229455903172493, 0.41674290349086124, 0.41003751506408054, 0.414840969360537, 0.4204304864009221, 0.4263968753317992, 0.433414988219738, 0.42883788670102757, 0.4274565974871318, 0.41010549954242176, 0.42338625548614395, 0.460920722120338, 0.47467317390773034, 0.44144855812191963, 0.43148547576533425, 0.428834017780092, 0.42708992461363476, 0.42332155216071343, 0.4160526105099254, 0.4183392429517375, 0.42180435442262226, 0.4219379540946748, 0.42301565450098777, 0.4209093757801586, 0.42690610678659546, 0.4178073149588373, 0.41383451720078784, 0.4090287085208628, 0.40680921491649413, 0.41163832280370927, 0.4164337097770638, 0.41290009228719604, 0.42936470814877087, 0.4191104794541995, 0.4113655893339051, 0.4064306000040637, 0.4027971265216668, 0.5509106227093272, 0.44913040763802, 0.42900273328026134, 0.42724184898866546, 0.44486407356129753, 0.41942360003789264, 0.41662433991829556, 0.42135675127307576, 0.4180699549615383, 0.4181741091112296, 0.44067889120843673, 0.42329565311471623, 0.41726866323086953, 0.4106167136794991, 0.4101206780307823, 0.40819595961107147, 0.41379618023832637, 0.4128015782270167, 0.4176737169424693, 0.4123058079017533, 0.40271485472718876, 0.40369263912240666, 0.4022177788946364, 0.4097153859006034, 0.40146201186709934, 0.4169037768410312, 0.409595032946931, 0.40424909939368564, 0.4086027575863732, 0.4073156254986922, 0.4114711061120033, 0.41188475241263706, 0.411010788132747, 0.42852557119395995, 0.4188891529209084, 0.41086608005894554, 0.40312296110722756, 0.40047654426760143, 0.439682226214144, 0.408157797737254, 0.4022446601755089, 0.4034013727472888, 0.4026357875102096, 0.40631231913963956, 0.4089030118452178, 0.410381056368351, 0.43612901493906975, 0.4063771603008111, 0.40438541811373496, 0.42600372475054527, 0.4139388994210296, 0.4065878478189309, 0.404476681103309, 0.4078641976747248, 0.4175418263508214, 0.4048257821963893, 0.4053278449508879, 0.40307652370797264, 0.4009055859512753, 0.3982684165239334, 0.40249791989723843, 0.4042738775412242, 0.39940520003437996, 0.3997568103174369, 0.4125220730072922, 0.4106183962689506, 0.4053598137365447, 0.4066476556989882, 0.415248588555389, 0.4124670810997486, 0.41438615280720925, 0.416884634229872, 0.4160465962356991, 0.4081810563802719, 0.41799964217676056, 0.4094948180847698, 0.4066765353911453, 0.40450801452000934, 0.40051423261562985, 0.40381525498297477, 0.41170207659403485, 0.4256815467443731, 0.4120570561952061, 0.40942934072679943, 0.40347833476132816, 0.41715604356593555, 0.40287915451659095, 0.4068199507892132, 0.40399691545301014, 0.40067697688937187, 0.41564833745360374, 0.41452473608983886, 0.41887223513589966, 0.41130915615293717, 0.41520368970102733, 0.40924809210830265, 0.4052288528117869, 0.41456135196818245, 0.41016410125626457, 0.42228791241844493], 'val_acc': [0.928458548254437, 0.934908556441466, 0.9322550917665163, 0.9402011492186122, 0.9436113759875298, 0.9427067612608274, 0.9447290251652399, 0.9484874192211363, 0.9495542049407959, 0.9462457373738289, 0.9450533696346812, 0.9499071265260378, 0.9390071771211095, 0.944387200805876, 0.9459277581837442, 0.94801364839077, 0.9479484649168121, 0.9499421185917325, 0.9474301892850134, 0.9496194140778648, 0.949427025185691, 0.949016840921508, 0.9487163449327151, 0.9505844397677315, 0.9498658089174165, 0.9491615262296464, 0.9498689927988582, 0.9418243757552571, 0.9448196548554633, 0.9446622538897727, 0.9461122022734748, 0.9475255592001809, 0.9379816999038061, 0.9472838921679391, 0.9473013977209727, 0.9482235138614973, 0.9358290599452125, 0.9369435658057531, 0.9434698538647758, 0.9490629509091377, 0.9492902747458882, 0.9443363298972448, 0.9404730043477483, 0.947444478670756, 0.9479071489638753, 0.9490502253174782, 0.9468403425481584, 0.9495939537882805, 0.9503173347976472, 0.9456956527299352, 0.948929396768411, 0.9492537139190568, 0.9474238091044955, 0.9468975845310423, 0.9481233565343751, 0.9410262745287683, 0.9475557770993974, 0.943113748398092, 0.9486082535650995, 0.944202789829837, 0.9498944323923852, 0.941131204366684, 0.9469659485750728, 0.9500232057438956, 0.9413760445184178, 0.9482394134004911, 0.9438705046971639, 0.9379976251059108, 0.9476082134577963, 0.9475621465179656, 0.9492648450864686, 0.9491217707594236, 0.9466781814893087, 0.9502553302380774, 0.9451217187775506, 0.9433378999431928, 0.9486241531040933, 0.9488530970282025, 0.94928710659345, 0.9500454540054003, 0.9480438538723521, 0.9493729579779837, 0.9492171729604403, 0.951201270851824, 0.9487418135007223, 0.9476718430717787, 0.9477322358224127, 0.9487608696023623, 0.9509739221798049, 0.9499421293536822, 0.9493984058499336, 0.9456288864215215, 0.9460485867328114, 0.9432965666055679, 0.9477815470761723, 0.9492394071486261, 0.9503030139538977, 0.9501026959882842, 0.9497243314981461, 0.9497211459610198, 0.9468482914898131, 0.9452377955118815, 0.9478785172104836, 0.9506591517064307, 0.9453252322143979, 0.9505367212825351, 0.9483522814181116, 0.9469961432947053, 0.9508070109619035, 0.9510136884119775, 0.94724573691686, 0.9511329068077935, 0.9453490674495697, 0.9503396070665784, 0.9502696469426155, 0.9480422652430005, 0.9449818109472593, 0.9482632569140859, 0.9487863042288356, 0.9500025378333198, 0.9494174718856812, 0.9381359385119544, 0.9500502397616705, 0.9473014192448722, 0.9498356084028879, 0.9504635905226072, 0.9484190485543675, 0.9357145917084482, 0.9445430305269029, 0.9478133436706331, 0.9476781959335009, 0.9449833979209264, 0.9463554405503802, 0.9477258655760024, 0.9467576717336973, 0.9454015211926566, 0.9467513122492366, 0.9459897486699952, 0.9490200165245268, 0.9437560422552956, 0.9479405126637883, 0.9448594003915787, 0.9501949076851209, 0.9501837814847628, 0.9510009653038449, 0.9435223283039199, 0.9514922317531374, 0.9436574810081058, 0.9504492804408073, 0.9520295858383179, 0.9516432591610484, 0.9522108369403415, 0.9488228691948785, 0.9440024710363812, 0.9465827710098691, 0.9437814851601919, 0.9442520721091164, 0.9487783627377616, 0.9487529297669729, 0.9491090410285525, 0.9503857096036276, 0.9487656338347329, 0.9471535417768691, 0.9481535578767458, 0.9503634489244885, 0.9500486494766341, 0.9502155731121699, 0.9506766473253568, 0.9483904325299792, 0.9480756413605478, 0.9508992210030556, 0.9472059963477982, 0.9512537527415488, 0.9511456489562988, 0.9509850690762202, 0.9518626721368896, 0.9500088998013072, 0.9516114708450105, 0.9454349064164691, 0.9483507027228674, 0.9502458026011785, 0.9501090538170602, 0.9510486548145612, 0.9501392526759042, 0.9501027100616031, 0.9503538989358478, 0.9490056956807772, 0.9454460425509347, 0.9508658415741391, 0.950166280898783, 0.950797456006209, 0.9487672357095612, 0.9495462535156144, 0.9500470533967018, 0.9493665960099962, 0.9505717174874412, 0.951477925810549, 0.9503475444184409, 0.9511106701360809, 0.9489723154240184, 0.9498292480905851, 0.9416717539230982, 0.951051850285795, 0.9512028834886022, 0.9514063828521304, 0.9498483273718092, 0.945736980272664, 0.950605095260673, 0.9513888963394694, 0.9510502600007587, 0.9512171861198213, 0.9516416688760122, 0.9499326058559947, 0.9515510441528426, 0.9521631466017829, 0.9509802990489535, 0.9525764981905619, 0.9511917531490326, 0.9501487960418066, 0.9496845652659734, 0.9496639048059782, 0.9493650073806444, 0.9517688751220703, 0.9487354457378387, 0.9484317832522922, 0.9493538969092898, 0.9480057027604845, 0.9493697782357534, 0.9514254447486665, 0.9489341618286239, 0.9499119313226806, 0.950861067407661, 0.9487243046363195, 0.9479659613635805, 0.9494127142760489, 0.9513332338796722, 0.9496193933818076, 0.9518276941445138, 0.950999390747812, 0.949861056274838, 0.9515717319316335, 0.9512330748968654, 0.950972361697091, 0.9484921917319298, 0.9479261943035655, 0.9484969601035118, 0.9515176622403992, 0.9495049251450433, 0.9511997136804793, 0.9495875876810815, 0.950560579697291, 0.9470581544770135], 'val_mDice': [0.3965194382601314, 0.5869863405823708, 0.5955749261710379, 0.6233120817277167, 0.6237506742278734, 0.6303108500109779, 0.6363574026359452, 0.6189962828324901, 0.6440100289053388, 0.6038502620326148, 0.6371271858612696, 0.6464751544925902, 0.6277634617355135, 0.6360291772418551, 0.6190405951605903, 0.6486563541822963, 0.650901080833541, 0.6376528913776079, 0.6441233472691642, 0.6476295698020194, 0.6425258508986897, 0.6306225433945656, 0.6220639430814319, 0.644502519733376, 0.6431688931253221, 0.6503311908907361, 0.6444483200709025, 0.6432615278495682, 0.6503454786207941, 0.6467740899986691, 0.6412820418675741, 0.6426684028572507, 0.6312792003154755, 0.620910021993849, 0.6519544604751799, 0.6330107707116339, 0.623402458926042, 0.6324861736761199, 0.6460536089208391, 0.6324268240067694, 0.6487467082010375, 0.6434830675522486, 0.6307936360438665, 0.641299746102757, 0.6466898926430278, 0.6479630867640177, 0.6482867416408327, 0.6488885316583846, 0.6541444336374601, 0.6514620963070128, 0.6518787244955698, 0.6391254448228412, 0.6479222103953362, 0.6487460310260454, 0.6438158320056068, 0.6378699739774069, 0.6406083487802081, 0.6416343930694792, 0.6466862915290726, 0.6465540635916922, 0.6234234828088019, 0.6400867270098792, 0.6419545147154067, 0.6457822380794419, 0.6336336880922318, 0.6347166680627399, 0.6358718367086517, 0.6271655940347247, 0.6369483437803056, 0.6424106235305468, 0.6465371466345258, 0.6498380344774988, 0.6498159840703011, 0.6466210467947854, 0.6463680275612407, 0.6273568487829633, 0.6464522141549323, 0.6498305458161566, 0.6468946701950498, 0.6508938198288282, 0.6515852941407098, 0.6488427023092905, 0.6532265990972519, 0.6463128063413832, 0.654680936700768, 0.6534750602311559, 0.6473684228128858, 0.6556556291050382, 0.6553271719151073, 0.6527684653798739, 0.6186837645040618, 0.625423421462377, 0.6352333443032371, 0.6352719482448366, 0.6484872831238641, 0.6497837644484308, 0.6530723795294762, 0.6537240114476945, 0.657965299155977, 0.6550756734278467, 0.6547135752108362, 0.6477302213509878, 0.6562226290504137, 0.653977047238085, 0.6468608188960288, 0.6561570862929026, 0.6535547922054926, 0.6520512228210767, 0.6487204970584975, 0.6591578291522132, 0.6541965992914306, 0.6598883635467954, 0.6508148999677764, 0.6570664255155457, 0.6570177500446638, 0.6064647340940105, 0.6477569623125924, 0.6527766121758355, 0.6510635026627116, 0.648456016348468, 0.6453467102514373, 0.6359421420428488, 0.646517216331429, 0.6434512709577879, 0.6546729803085327, 0.6490580745869212, 0.6282386506597201, 0.6132900193333626, 0.6344267461034987, 0.6416142144136958, 0.6425983549820052, 0.6424498111009598, 0.6447330133782493, 0.6491341392199198, 0.6476987542377578, 0.6459534217913946, 0.6459864551822344, 0.6460038216577636, 0.6481459745102458, 0.6420625348885854, 0.6492725585897764, 0.6498050027423434, 0.6553160978688134, 0.6566982393463453, 0.654601256052653, 0.6483863070607185, 0.6514191577831904, 0.6396349602275424, 0.6484605620304743, 0.6552161466744211, 0.6580380631817712, 0.6606945602430238, 0.6001854348513815, 0.6294303354289796, 0.6425356699360741, 0.6430253932873408, 0.6322287768125534, 0.6477980464696884, 0.6499182300435172, 0.6480089881353908, 0.6505999979045656, 0.6495149930318197, 0.6373012198342217, 0.6471169483330514, 0.6514999336666532, 0.6549125437935194, 0.6545727286073897, 0.6565374384323756, 0.6519961828986803, 0.6521253105666902, 0.6509683728218079, 0.6522329383426242, 0.6598897808127933, 0.6594468851884207, 0.6603648629453447, 0.6572195515036583, 0.6604377867447006, 0.6532439266641935, 0.6528304202689065, 0.6571350188718902, 0.6556591408120261, 0.656203037334813, 0.6552906665537093, 0.6537265926599503, 0.6545007783505652, 0.6471827973922094, 0.6497601320346197, 0.6520257567365965, 0.659416053030226, 0.660796447760529, 0.642051625582907, 0.6553318873047829, 0.6587790565358268, 0.658585121234258, 0.6592724811699655, 0.6578280470437474, 0.6578317036231359, 0.6554684597584937, 0.6453056832154592, 0.6578664994902081, 0.6589693791336484, 0.6422716900706291, 0.6525669884350564, 0.6582410476273961, 0.6597844668560557, 0.6566973800460497, 0.6488755428128772, 0.6583948276109166, 0.6586909708049562, 0.6597233845127953, 0.660628935529126, 0.6629618629813194, 0.6597404653827349, 0.6591750888360871, 0.6627460420131683, 0.6618427957097689, 0.6556568857696321, 0.6567266119851006, 0.658430241048336, 0.6576587624020047, 0.6530416227049298, 0.6540073404709498, 0.6549780749612384, 0.6494427447517713, 0.6497750282287598, 0.6553396292858653, 0.6488623643914858, 0.6547181101308929, 0.6586595740583208, 0.6572693404224184, 0.6603521514270041, 0.6591534324818187, 0.654093029598395, 0.6454376387927268, 0.654297509127193, 0.6575057374106513, 0.6594473189777799, 0.6544908947414823, 0.6604257176319758, 0.6574701906906234, 0.6593545724948248, 0.6609049911300341, 0.6525311569372813, 0.6518140244815085, 0.6490361822976006, 0.6535038360291057, 0.6545316005746523, 0.6552456981605954, 0.6593552215231789, 0.6527090089188682, 0.65609393765529, 0.6470294437474675], 'loss': [2.284348778855787, 0.6593187609857202, 0.505619096608227, 0.48198218454160907, 0.5235612777642515, 0.4490955111297788, 0.42716890256264073, 0.4191522146249709, 0.4290593034363627, 0.40109600843631804, 0.5133764035514762, 0.43337378157586953, 0.4200446503433805, 0.4042900620295522, 0.3923465800700045, 0.4293118248183508, 0.39743949796194683, 0.3896130581980335, 0.4433611685901169, 0.38457002420373765, 0.3982168392282813, 0.3758825803222712, 0.38694854683335184, 0.3892823336658571, 0.41059976434374884, 0.3793367408995901, 0.36940068540418164, 0.3904358403668554, 0.3832082419690459, 0.3809500474716745, 0.3703031995845032, 0.381300478363494, 0.3664433665603862, 0.39303439006918656, 0.3656793249086742, 0.37077599737795924, 0.46314194466642833, 0.40969312585849166, 0.39425691264133356, 0.37809162943354, 0.3829427400848143, 0.3815632017686111, 0.47532302181542685, 0.3912064280873499, 0.3758644963314031, 0.3670087412873502, 0.36791802650192806, 0.36562984609415156, 0.36610649585872873, 0.356690897269617, 0.35058477901813945, 0.35018310441584427, 0.3601545744073377, 0.35698776452594244, 0.34949475574612604, 0.3465942959775032, 0.41413033384169756, 0.4269789657534665, 0.37062010194793144, 0.35594267355204995, 0.36740077538932814, 0.38291326729832387, 0.417676780406615, 0.36996039960200855, 0.3559973870959211, 0.4113561949274488, 0.39483900621972623, 0.3690229145552563, 0.41390000352784007, 0.37546028139541304, 0.3624378334742116, 0.3512377483920993, 0.34476814818449314, 0.38037209283708345, 0.3664211568118706, 0.4161409684400138, 0.3846277591524342, 0.3645356242426509, 0.35918343572514266, 0.3480396333330312, 0.35562696357330126, 0.36893205763883685, 0.34718972705898277, 0.34877004676555023, 0.35023579746717565, 0.3378424700405831, 0.3706715238453162, 0.39311820965808525, 0.35770531419465573, 0.34365210784200506, 0.33805426062798577, 0.48867799772370446, 0.3837810238504544, 0.39637293083421166, 0.40917180761199806, 0.3621660341087598, 0.36864422913107225, 0.35754560409840314, 0.3423240475140069, 0.3465074479933791, 0.3469692014205109, 0.3740345206673897, 0.36103725910757917, 0.3504149169490283, 0.36728975812062264, 0.3430583447531454, 0.344946774458242, 0.33927129703987985, 0.35816954206816914, 0.35494095624058136, 0.35954647680804475, 0.3444995639374102, 0.33475145663138345, 0.35265528931926654, 0.34418175516246746, 0.3317166932323751, 0.3937483193439539, 0.3913382677942027, 0.35264588161603, 0.3609946588155764, 0.3449438247888265, 0.3687180113809802, 0.39063955306907505, 0.35455482627635027, 0.40736627704140393, 0.3581712459191818, 0.4255935217226412, 0.49056970809924205, 0.388507052313945, 0.36626327417130494, 0.3581035794311359, 0.3621609107788224, 0.36387297480991143, 0.3566102307360069, 0.3462890397631964, 0.3936809727194756, 0.362361283777108, 0.35540720689744953, 0.3412406812942397, 0.3854371866463696, 0.34979429624686825, 0.33835357046415376, 0.35254922967045993, 0.3329062920140172, 0.3285749850329254, 0.3707414997976132, 0.41075401554603325, 0.34414757686212105, 0.43734422766557646, 0.35855355775302905, 0.34895383219503634, 0.3430878169498597, 0.3752370392415762, 0.4992289330211608, 0.4026901575193196, 0.37868163597085874, 0.43031230448136887, 0.3972696362839504, 0.36220168755111837, 0.37660021820443085, 0.3548689267682776, 0.3533146724503756, 0.37398563485731123, 0.37330650327205905, 0.34921757573448686, 0.3559298038656495, 0.33950704348272315, 0.3344172760603664, 0.3510104164383384, 0.34603701050909047, 0.3892775174665297, 0.35268960196131804, 0.35354488803103445, 0.3456729423092152, 0.33220124918121235, 0.32805706323925227, 0.3342198467514761, 0.3237865555101404, 0.3400239141865728, 0.3634235506044826, 0.37317790368387765, 0.34046926276533074, 0.3319694958506941, 0.3391062038576289, 0.3317632846950976, 0.3279624925207538, 0.40044568876539244, 0.3740839586569833, 0.3407584831883741, 0.3363777009252086, 0.3351565700883034, 0.39299199876903484, 0.34087095904034903, 0.36636419893987304, 0.3341375108175434, 0.330595701892554, 0.336530223499672, 0.35026251927053864, 0.33985056449765777, 0.3509930848032345, 0.32760344323714863, 0.3243481249824661, 0.3782927063390273, 0.33502179270622046, 0.3361310259325655, 0.3304703103143863, 0.3387915295817531, 0.3774385409775581, 0.3393385853634292, 0.3272799589512013, 0.32827776921886836, 0.32302578508003393, 0.3278647288222224, 0.33907932722870227, 0.323561110355968, 0.3190782010429552, 0.3169994835567504, 0.38211443894555847, 0.39869432406939015, 0.34115018122345936, 0.34034007073144046, 0.3454166650089196, 0.3292671713142665, 0.37604250274416234, 0.34409672700806887, 0.3339330397190098, 0.373727226366588, 0.3432090488303119, 0.33579968812006017, 0.3657827646878098, 0.33264789687086055, 0.3290923436213727, 0.32401541773446735, 0.3781291940363481, 0.33846211466313947, 0.33245587245261543, 0.33323199541515863, 0.3342928552910656, 0.32988502151481114, 0.3235711604775817, 0.36384010094551356, 0.3291997472925269, 0.3488265213935577, 0.36430156428967153, 0.34667531211802566, 0.3312627344240237, 0.32580194362388676, 0.32916824954361384, 0.32133799177348, 0.32495070371065593, 0.3294188894836645, 0.3184376680072478], 'acc': [0.41414613407324435, 0.9111729458450911, 0.9230686738123286, 0.9267364458707009, 0.9226416516845368, 0.9306051856142172, 0.9335857638032867, 0.9347331224599364, 0.9337064440815837, 0.9368121834139491, 0.9259823161405196, 0.9332621124818565, 0.9351039622652196, 0.9357760395125639, 0.9376904016645634, 0.9336932087091093, 0.9373615549425448, 0.9377615358131451, 0.9322117805766533, 0.9384336100495267, 0.9372593052634819, 0.938969769802904, 0.9381523567268643, 0.9376781258269183, 0.9361421582525241, 0.9386421869774806, 0.9396574652861734, 0.9369187711080081, 0.9377987322155702, 0.9384957523460674, 0.9395467992276403, 0.9376094245051434, 0.9398002270521838, 0.9364504052902085, 0.9397285465597672, 0.9398835423327699, 0.9311521941827569, 0.9362651064686198, 0.9368078203986503, 0.938514444756267, 0.937750803277016, 0.9384944405223961, 0.9310956577151632, 0.9369060874183952, 0.9380976808107144, 0.9394312221958493, 0.9397453350917012, 0.9393918766489675, 0.9394932454693455, 0.9403820488741219, 0.9409024707104635, 0.9409894840926655, 0.9390813648582759, 0.9405673745832969, 0.9409926808100171, 0.9412665876196444, 0.9348588591192604, 0.9331168932115618, 0.938893418227145, 0.9403752078179108, 0.939384415961469, 0.9377149196543205, 0.9327280995386639, 0.9389683374972682, 0.9403573460547132, 0.9334040881879453, 0.9364623034662187, 0.9393541343869449, 0.933611324604272, 0.9387447213446172, 0.9400278053089003, 0.9410757066532791, 0.9416496843462772, 0.9379062048594985, 0.9396154734321267, 0.9356015160013991, 0.9375383433122558, 0.9396722498020521, 0.939954886870041, 0.9409581746561877, 0.9406214080034675, 0.939102993795194, 0.9412443384678708, 0.9412349212940702, 0.9407309519972681, 0.942261623561463, 0.9374920104508747, 0.9371810460286816, 0.93985425885823, 0.9414476210369987, 0.9421652882698365, 0.9270193224995723, 0.9368253708283065, 0.9355263571145199, 0.9351525133555786, 0.939509766615377, 0.9390853471264791, 0.9404694171215566, 0.9418163130449984, 0.9413478746536859, 0.9421400132930201, 0.9379854879519826, 0.9398047332278938, 0.9406606798283248, 0.9392480926580223, 0.941519868875491, 0.941607092559468, 0.9420999282785362, 0.9389241071880242, 0.940899705374046, 0.9407774246666484, 0.9420690963124498, 0.9428391808669352, 0.9405373776720136, 0.9419282215446895, 0.9427947778774294, 0.93632822068529, 0.9367320409678827, 0.9403828136213942, 0.9393852977948367, 0.941469415632738, 0.9375399656686146, 0.932984961009177, 0.9396001903256604, 0.937040432612482, 0.9402879822218173, 0.9350457816567971, 0.9284136708410268, 0.9366920989275649, 0.9393309058652373, 0.9402144909364434, 0.9394280275209859, 0.9393260656651228, 0.9402284869153404, 0.941236447150627, 0.9350590386523293, 0.9387349205555462, 0.9388128924141351, 0.941104082574001, 0.9365931686393023, 0.9403982396151123, 0.9416434357419832, 0.9393533206820401, 0.9419537328479315, 0.9425845838079799, 0.9401173197519107, 0.9331003944025277, 0.9412271937545719, 0.9324923441591592, 0.9399730816891685, 0.9409905783510024, 0.9415716403549556, 0.9379284517763307, 0.920390762819398, 0.9315015508810464, 0.9354043406703152, 0.9310663276483039, 0.9343564896679908, 0.9381583424585956, 0.9372568234914591, 0.9394786979627913, 0.9401350617905406, 0.9384743614428218, 0.9387521577395446, 0.9407483609737598, 0.9398709519085021, 0.9418371786438988, 0.9423427698686959, 0.940710899581786, 0.9408765270826457, 0.9375842204504665, 0.9405052580072065, 0.9403786142907183, 0.9421748049047363, 0.9427021861808919, 0.943118667009038, 0.9426408332780604, 0.9435825759315848, 0.9422771713036123, 0.9385493300182349, 0.9389180008253323, 0.9416958483081722, 0.9425158127746586, 0.9422081634906689, 0.9422827269208766, 0.9430048798486698, 0.9346504270155074, 0.9390649853392375, 0.941358391282062, 0.9423573141221689, 0.9423192334155244, 0.9378832887080967, 0.9417333800325095, 0.9390953643820383, 0.9423473944155925, 0.9427951861329282, 0.9424882490999213, 0.94076619697305, 0.9418733059124529, 0.9415421908242717, 0.9428582310043341, 0.9433573586421017, 0.9351898992189503, 0.9421109456579433, 0.9420047148529807, 0.9429286924603953, 0.940693897035591, 0.936755363139842, 0.9411846532596672, 0.9427819017717807, 0.9430350898429883, 0.9434465844176012, 0.9428994578876144, 0.9416906495117146, 0.9432997458329512, 0.9437692358697185, 0.9439995548102076, 0.936886748129248, 0.9351628370836816, 0.9408058981611858, 0.9409564335437358, 0.9410473297951234, 0.9424948060702513, 0.9371709842108746, 0.9403172865309773, 0.941887564416255, 0.9380952711403836, 0.9411978877629976, 0.9418154323228932, 0.9393424233251929, 0.9423233391207813, 0.942851672022557, 0.9435846755907146, 0.9370722427875744, 0.9410868213085095, 0.9419797247877321, 0.942732853866371, 0.9422905250596896, 0.9423422444526037, 0.9436070424059433, 0.940319288225177, 0.942853317727845, 0.9408949373501214, 0.9376725434089822, 0.9405486341839395, 0.9420649254462357, 0.9427715042657796, 0.942676649064077, 0.9431393412100426, 0.9428551052029139, 0.9428451602911654, 0.9437074763441369], 'mDice': [0.21190062565415704, 0.5140327396426719, 0.5906141956899703, 0.6051234549786222, 0.5845995609696154, 0.6248537820896101, 0.6393618331254988, 0.6446534927196024, 0.6389607761151069, 0.6561051870979203, 0.5899177820891928, 0.6351183725730688, 0.6448212551233756, 0.6538701906804926, 0.6621410501784253, 0.6384798968481454, 0.6585925066859731, 0.6637899194651129, 0.6301780372172044, 0.6669903305555033, 0.6585250258346409, 0.6735481584002115, 0.6662185784274496, 0.6643832270744728, 0.6519417081875251, 0.6712193370001998, 0.6783768821788224, 0.6636669034977007, 0.6684117754720521, 0.6701155679789127, 0.6773369888373557, 0.6694038584386045, 0.6799378936549435, 0.6621255729641967, 0.6802869608297707, 0.6775429153576479, 0.6211104120885739, 0.6509651618722254, 0.6616579843181587, 0.6717260646771644, 0.669055094123942, 0.6699499721288582, 0.6171703344427686, 0.6624455022732425, 0.672658226860276, 0.6790100909182087, 0.678518316268598, 0.6805628168466202, 0.680037456156127, 0.6863848704271621, 0.6908272009394514, 0.6910834500111959, 0.6836458841483676, 0.6865283690564472, 0.6913433599417415, 0.6936159274277868, 0.6511173349887726, 0.6418314860545277, 0.6764176345879728, 0.6868693920525768, 0.6800321898628878, 0.6700042671753011, 0.646265476963791, 0.6768855502109777, 0.6867999291900495, 0.6525682673120533, 0.6607586437557503, 0.6781694542800135, 0.6494276237734878, 0.6742383326860583, 0.6825943122883784, 0.6904398271310157, 0.6947218874272872, 0.6706580207901887, 0.6797945597602382, 0.650915961934929, 0.6673834413699763, 0.6811795367344898, 0.6843422958471169, 0.6925947990576161, 0.6875863264403782, 0.6785497559959498, 0.6935079931318853, 0.692069429778119, 0.6909265943386073, 0.6997393560482802, 0.6773670651883883, 0.6631519425497019, 0.6853991856631879, 0.6957977346524188, 0.699713167986166, 0.6049888098212582, 0.6678468072017696, 0.6602228800867538, 0.6530021692598726, 0.6828446719202197, 0.6784740318706688, 0.6859368580590312, 0.6971608666178709, 0.693479475829393, 0.698958918236529, 0.6750246511547034, 0.6834252317638873, 0.6909706092988336, 0.6791260572674745, 0.6962300508255239, 0.6946899025915265, 0.6990106628998011, 0.685753487619357, 0.6881689965575949, 0.6847605610648713, 0.6953207786574164, 0.7022054058700139, 0.6894007259055409, 0.6961534238739469, 0.7045627441103974, 0.6667221657820833, 0.6634980950234098, 0.6888373201215731, 0.6834576422069832, 0.694697064161611, 0.6780317376248726, 0.6638511429415582, 0.6875785594898616, 0.6588698905615146, 0.6854055773285624, 0.6477383680314946, 0.6069097638893793, 0.6644979642308164, 0.6798046440981835, 0.6855944155057437, 0.6824635996407313, 0.6820623299741159, 0.6865079269447919, 0.6934650980386992, 0.6627259875955513, 0.6825936438651392, 0.6870923344821511, 0.6972554752519945, 0.6676460969977802, 0.691095846423928, 0.6993271727888997, 0.6892351158465362, 0.7031364868226343, 0.7061936269854645, 0.6801988286948951, 0.652368259503188, 0.6953962860399454, 0.6346888190420353, 0.6846283838880793, 0.6915130908384185, 0.696306071454579, 0.6743314368507723, 0.6018634877991098, 0.6550289392758442, 0.6712918280123417, 0.6424103809630991, 0.6592816028240732, 0.682280613933798, 0.6732487511838454, 0.6875849472037356, 0.6889668706928289, 0.6749595947631162, 0.6770882351769593, 0.6916884739064832, 0.6867872203263053, 0.698457969500241, 0.7021473436436422, 0.6903399137044596, 0.6939248305573437, 0.6663599162005643, 0.6892002619016843, 0.6885851718723593, 0.6991174896829216, 0.7037531979915165, 0.7069438434419452, 0.7023146592717706, 0.7102550348755271, 0.6986470367891778, 0.6825722048225756, 0.6763779394031378, 0.6979335941643582, 0.7041304014478049, 0.6996166800185549, 0.7043728094678746, 0.7072059751665104, 0.6599895245903992, 0.6785230662795159, 0.6976122559994884, 0.7010954837198866, 0.7019889807064152, 0.6682177599507463, 0.6975448107349415, 0.6806392312366483, 0.7023654174412332, 0.7052666318812677, 0.7014217925883744, 0.6912865386494944, 0.6986462438917324, 0.6958390383866414, 0.7069567165304231, 0.7098023493629411, 0.6736325335253056, 0.7019072007405337, 0.7006595401562274, 0.7054444709613278, 0.6990844416420927, 0.6759568364275531, 0.6986253393955397, 0.7073778349395196, 0.7073762671809162, 0.7105497049144278, 0.7070720673294977, 0.6986434939391613, 0.710257375430296, 0.7131992383787202, 0.7153605073209282, 0.6704859748126122, 0.660402149983265, 0.6976976337289825, 0.6978816648825124, 0.6953662196002569, 0.7062550894221519, 0.6736845148005792, 0.6949660251034062, 0.7030686923290003, 0.6756847011379966, 0.6962713884392848, 0.7012347668516439, 0.680629644415277, 0.7035503952239481, 0.7064010716471097, 0.7098259968826105, 0.6720559135368064, 0.6993202722894563, 0.7038227436772462, 0.7072657948475668, 0.7026113285697161, 0.7056382318149443, 0.7104938441534214, 0.6839892548107254, 0.7062764037289901, 0.692203235947804, 0.6817106203714542, 0.6939312664497248, 0.7043487580787786, 0.7085628581908752, 0.7059183603071344, 0.711864583021203, 0.7090568647522714, 0.7061276019252771, 0.7139889174417933]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:10,  3.45s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:06,  3.07s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:07<00:02,  2.71s/it]predicting test subjects: 100%|██████████| 4/4 [00:10<00:00,  2.79s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:50,  3.36s/it]predicting train subjects:   1%|          | 2/266 [00:06<13:55,  3.17s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:34,  2.87s/it]predicting train subjects:   2%|▏         | 4/266 [00:10<11:36,  2.66s/it]predicting train subjects:   2%|▏         | 5/266 [00:13<11:53,  2.73s/it]predicting train subjects:   2%|▏         | 6/266 [00:16<12:44,  2.94s/it]predicting train subjects:   3%|▎         | 7/266 [00:20<13:16,  3.08s/it]predicting train subjects:   3%|▎         | 8/266 [00:23<13:35,  3.16s/it]predicting train subjects:   3%|▎         | 9/266 [00:26<13:23,  3.13s/it]predicting train subjects:   4%|▍         | 10/266 [00:29<13:32,  3.17s/it]predicting train subjects:   4%|▍         | 11/266 [00:32<13:17,  3.13s/it]predicting train subjects:   5%|▍         | 12/266 [00:36<13:18,  3.14s/it]predicting train subjects:   5%|▍         | 13/266 [00:39<13:22,  3.17s/it]predicting train subjects:   5%|▌         | 14/266 [00:42<13:19,  3.17s/it]predicting train subjects:   6%|▌         | 15/266 [00:45<12:55,  3.09s/it]predicting train subjects:   6%|▌         | 16/266 [00:48<13:03,  3.14s/it]predicting train subjects:   6%|▋         | 17/266 [00:51<13:09,  3.17s/it]predicting train subjects:   7%|▋         | 18/266 [00:54<12:54,  3.12s/it]predicting train subjects:   7%|▋         | 19/266 [00:58<12:56,  3.14s/it]predicting train subjects:   8%|▊         | 20/266 [01:01<13:20,  3.25s/it]predicting train subjects:   8%|▊         | 21/266 [01:04<13:06,  3.21s/it]predicting train subjects:   8%|▊         | 22/266 [01:07<12:58,  3.19s/it]predicting train subjects:   9%|▊         | 23/266 [01:10<12:49,  3.17s/it]predicting train subjects:   9%|▉         | 24/266 [01:13<12:39,  3.14s/it]predicting train subjects:   9%|▉         | 25/266 [01:16<11:52,  2.96s/it]predicting train subjects:  10%|▉         | 26/266 [01:19<11:23,  2.85s/it]predicting train subjects:  10%|█         | 27/266 [01:21<11:05,  2.79s/it]predicting train subjects:  11%|█         | 28/266 [01:24<11:15,  2.84s/it]predicting train subjects:  11%|█         | 29/266 [01:27<11:27,  2.90s/it]predicting train subjects:  11%|█▏        | 30/266 [01:30<11:46,  2.99s/it]predicting train subjects:  12%|█▏        | 31/266 [01:34<11:47,  3.01s/it]predicting train subjects:  12%|█▏        | 32/266 [01:36<11:07,  2.85s/it]predicting train subjects:  12%|█▏        | 33/266 [01:39<11:27,  2.95s/it]predicting train subjects:  13%|█▎        | 34/266 [01:42<11:26,  2.96s/it]predicting train subjects:  13%|█▎        | 35/266 [01:45<11:24,  2.96s/it]predicting train subjects:  14%|█▎        | 36/266 [01:48<10:58,  2.87s/it]predicting train subjects:  14%|█▍        | 37/266 [01:50<10:29,  2.75s/it]predicting train subjects:  14%|█▍        | 38/266 [01:53<10:19,  2.72s/it]predicting train subjects:  15%|█▍        | 39/266 [01:56<10:28,  2.77s/it]predicting train subjects:  15%|█▌        | 40/266 [01:59<10:39,  2.83s/it]predicting train subjects:  15%|█▌        | 41/266 [02:01<10:20,  2.76s/it]predicting train subjects:  16%|█▌        | 42/266 [02:03<09:35,  2.57s/it]predicting train subjects:  16%|█▌        | 43/266 [02:06<09:06,  2.45s/it]predicting train subjects:  17%|█▋        | 44/266 [02:08<08:48,  2.38s/it]predicting train subjects:  17%|█▋        | 45/266 [02:10<08:25,  2.29s/it]predicting train subjects:  17%|█▋        | 46/266 [02:12<08:09,  2.22s/it]predicting train subjects:  18%|█▊        | 47/266 [02:14<08:08,  2.23s/it]predicting train subjects:  18%|█▊        | 48/266 [02:16<08:02,  2.21s/it]predicting train subjects:  18%|█▊        | 49/266 [02:19<08:11,  2.27s/it]predicting train subjects:  19%|█▉        | 50/266 [02:21<08:18,  2.31s/it]predicting train subjects:  19%|█▉        | 51/266 [02:23<07:54,  2.21s/it]predicting train subjects:  20%|█▉        | 52/266 [02:25<07:41,  2.16s/it]predicting train subjects:  20%|█▉        | 53/266 [02:27<07:31,  2.12s/it]predicting train subjects:  20%|██        | 54/266 [02:29<07:25,  2.10s/it]predicting train subjects:  21%|██        | 55/266 [02:32<07:32,  2.14s/it]predicting train subjects:  21%|██        | 56/266 [02:34<07:36,  2.17s/it]predicting train subjects:  21%|██▏       | 57/266 [02:36<07:37,  2.19s/it]predicting train subjects:  22%|██▏       | 58/266 [02:38<07:22,  2.13s/it]predicting train subjects:  22%|██▏       | 59/266 [02:40<07:16,  2.11s/it]predicting train subjects:  23%|██▎       | 60/266 [02:42<07:03,  2.05s/it]predicting train subjects:  23%|██▎       | 61/266 [02:44<06:55,  2.03s/it]predicting train subjects:  23%|██▎       | 62/266 [02:46<06:43,  1.98s/it]predicting train subjects:  24%|██▎       | 63/266 [02:48<06:38,  1.96s/it]predicting train subjects:  24%|██▍       | 64/266 [02:50<06:28,  1.93s/it]predicting train subjects:  24%|██▍       | 65/266 [02:51<06:23,  1.91s/it]predicting train subjects:  25%|██▍       | 66/266 [02:53<06:24,  1.92s/it]predicting train subjects:  25%|██▌       | 67/266 [02:55<06:23,  1.93s/it]predicting train subjects:  26%|██▌       | 68/266 [02:58<06:33,  1.99s/it]predicting train subjects:  26%|██▌       | 69/266 [02:59<06:25,  1.95s/it]predicting train subjects:  26%|██▋       | 70/266 [03:01<06:20,  1.94s/it]predicting train subjects:  27%|██▋       | 71/266 [03:03<06:18,  1.94s/it]predicting train subjects:  27%|██▋       | 72/266 [03:05<06:17,  1.95s/it]predicting train subjects:  27%|██▋       | 73/266 [03:07<06:16,  1.95s/it]predicting train subjects:  28%|██▊       | 74/266 [03:09<06:12,  1.94s/it]predicting train subjects:  28%|██▊       | 75/266 [03:11<06:36,  2.08s/it]predicting train subjects:  29%|██▊       | 76/266 [03:14<06:56,  2.19s/it]predicting train subjects:  29%|██▉       | 77/266 [03:16<06:36,  2.10s/it]predicting train subjects:  29%|██▉       | 78/266 [03:19<07:18,  2.33s/it]predicting train subjects:  30%|██▉       | 79/266 [03:21<07:22,  2.37s/it]predicting train subjects:  30%|███       | 80/266 [03:24<07:53,  2.55s/it]predicting train subjects:  30%|███       | 81/266 [03:27<08:23,  2.72s/it]predicting train subjects:  31%|███       | 82/266 [03:30<08:14,  2.69s/it]predicting train subjects:  31%|███       | 83/266 [03:33<08:48,  2.89s/it]predicting train subjects:  32%|███▏      | 84/266 [03:36<09:01,  2.97s/it]predicting train subjects:  32%|███▏      | 85/266 [03:39<09:04,  3.01s/it]predicting train subjects:  32%|███▏      | 86/266 [03:43<09:07,  3.04s/it]predicting train subjects:  33%|███▎      | 87/266 [03:46<09:16,  3.11s/it]predicting train subjects:  33%|███▎      | 88/266 [03:49<09:24,  3.17s/it]predicting train subjects:  33%|███▎      | 89/266 [03:53<09:31,  3.23s/it]predicting train subjects:  34%|███▍      | 90/266 [03:56<09:33,  3.26s/it]predicting train subjects:  34%|███▍      | 91/266 [03:59<09:31,  3.26s/it]predicting train subjects:  35%|███▍      | 92/266 [04:02<08:53,  3.07s/it]predicting train subjects:  35%|███▍      | 93/266 [04:05<08:36,  2.98s/it]predicting train subjects:  35%|███▌      | 94/266 [04:07<08:31,  2.98s/it]predicting train subjects:  36%|███▌      | 95/266 [04:10<08:10,  2.87s/it]predicting train subjects:  36%|███▌      | 96/266 [04:12<07:35,  2.68s/it]predicting train subjects:  36%|███▋      | 97/266 [04:15<07:43,  2.74s/it]predicting train subjects:  37%|███▋      | 98/266 [04:18<07:42,  2.75s/it]predicting train subjects:  37%|███▋      | 99/266 [04:20<06:52,  2.47s/it]predicting train subjects:  38%|███▊      | 100/266 [04:22<06:30,  2.35s/it]predicting train subjects:  38%|███▊      | 101/266 [04:25<06:51,  2.49s/it]predicting train subjects:  38%|███▊      | 102/266 [04:27<06:46,  2.48s/it]predicting train subjects:  39%|███▊      | 103/266 [04:29<06:34,  2.42s/it]predicting train subjects:  39%|███▉      | 104/266 [04:32<06:33,  2.43s/it]predicting train subjects:  39%|███▉      | 105/266 [04:35<06:44,  2.51s/it]predicting train subjects:  40%|███▉      | 106/266 [04:37<06:55,  2.59s/it]predicting train subjects:  40%|████      | 107/266 [04:40<06:55,  2.61s/it]predicting train subjects:  41%|████      | 108/266 [04:43<06:53,  2.62s/it]predicting train subjects:  41%|████      | 109/266 [04:45<06:40,  2.55s/it]predicting train subjects:  41%|████▏     | 110/266 [04:47<06:18,  2.42s/it]predicting train subjects:  42%|████▏     | 111/266 [04:49<06:03,  2.34s/it]predicting train subjects:  42%|████▏     | 112/266 [04:52<06:04,  2.37s/it]predicting train subjects:  42%|████▏     | 113/266 [04:54<05:58,  2.34s/it]predicting train subjects:  43%|████▎     | 114/266 [04:57<06:13,  2.46s/it]predicting train subjects:  43%|████▎     | 115/266 [04:59<06:01,  2.39s/it]predicting train subjects:  44%|████▎     | 116/266 [05:01<05:51,  2.34s/it]predicting train subjects:  44%|████▍     | 117/266 [05:03<05:43,  2.30s/it]predicting train subjects:  44%|████▍     | 118/266 [05:06<05:38,  2.29s/it]predicting train subjects:  45%|████▍     | 119/266 [05:09<05:59,  2.45s/it]predicting train subjects:  45%|████▌     | 120/266 [05:12<06:31,  2.68s/it]predicting train subjects:  45%|████▌     | 121/266 [05:15<06:43,  2.78s/it]predicting train subjects:  46%|████▌     | 122/266 [05:18<06:41,  2.79s/it]predicting train subjects:  46%|████▌     | 123/266 [05:21<06:53,  2.89s/it]predicting train subjects:  47%|████▋     | 124/266 [05:24<07:09,  3.02s/it]predicting train subjects:  47%|████▋     | 125/266 [05:27<07:18,  3.11s/it]predicting train subjects:  47%|████▋     | 126/266 [05:31<07:23,  3.17s/it]predicting train subjects:  48%|████▊     | 127/266 [05:34<07:29,  3.24s/it]predicting train subjects:  48%|████▊     | 128/266 [05:37<07:30,  3.27s/it]predicting train subjects:  48%|████▊     | 129/266 [05:41<07:22,  3.23s/it]predicting train subjects:  49%|████▉     | 130/266 [05:44<07:15,  3.20s/it]predicting train subjects:  49%|████▉     | 131/266 [05:47<07:13,  3.21s/it]predicting train subjects:  50%|████▉     | 132/266 [05:50<07:10,  3.21s/it]predicting train subjects:  50%|█████     | 133/266 [05:53<07:06,  3.21s/it]predicting train subjects:  50%|█████     | 134/266 [05:57<07:05,  3.22s/it]predicting train subjects:  51%|█████     | 135/266 [06:00<07:06,  3.26s/it]predicting train subjects:  51%|█████     | 136/266 [06:03<07:03,  3.25s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:06<06:54,  3.22s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:09<06:29,  3.04s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:12<06:28,  3.06s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:15<06:31,  3.11s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:18<06:28,  3.11s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:22<06:29,  3.14s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:25<06:33,  3.20s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:27<06:08,  3.02s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:30<05:55,  2.94s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:33<05:58,  2.99s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:37<06:02,  3.05s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:39<05:53,  3.00s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:42<05:51,  3.00s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:46<05:50,  3.02s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:48<05:29,  2.87s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:50<05:09,  2.71s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:53<04:58,  2.64s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:56<04:56,  2.65s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:58<04:47,  2.59s/it]predicting train subjects:  59%|█████▊    | 156/266 [07:00<04:31,  2.47s/it]predicting train subjects:  59%|█████▉    | 157/266 [07:02<04:09,  2.29s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:04<03:52,  2.15s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:06<04:02,  2.26s/it]predicting train subjects:  60%|██████    | 160/266 [07:08<03:54,  2.21s/it]predicting train subjects:  61%|██████    | 161/266 [07:10<03:44,  2.14s/it]predicting train subjects:  61%|██████    | 162/266 [07:12<03:33,  2.05s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:14<03:31,  2.06s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:16<03:30,  2.07s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:19<03:37,  2.15s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:21<03:40,  2.21s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:23<03:29,  2.12s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:25<03:29,  2.14s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:27<03:29,  2.16s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:30<03:24,  2.13s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:32<03:22,  2.13s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:34<03:28,  2.21s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:37<03:41,  2.38s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:40<03:48,  2.48s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:42<03:32,  2.34s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:44<03:27,  2.30s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:46<03:30,  2.37s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:49<03:30,  2.39s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:51<03:26,  2.37s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:53<03:14,  2.27s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:55<03:16,  2.31s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:57<03:05,  2.20s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:59<02:59,  2.16s/it]predicting train subjects:  69%|██████▉   | 184/266 [08:02<02:59,  2.19s/it]predicting train subjects:  70%|██████▉   | 185/266 [08:04<03:05,  2.29s/it]predicting train subjects:  70%|██████▉   | 186/266 [08:06<02:59,  2.24s/it]predicting train subjects:  70%|███████   | 187/266 [08:09<02:54,  2.21s/it]predicting train subjects:  71%|███████   | 188/266 [08:11<02:46,  2.14s/it]predicting train subjects:  71%|███████   | 189/266 [08:13<02:45,  2.15s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:15<02:43,  2.15s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:18<02:59,  2.39s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:20<02:53,  2.34s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:22<02:41,  2.22s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:25<02:55,  2.44s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:28<03:03,  2.58s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:30<03:02,  2.61s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:33<02:50,  2.47s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:35<02:43,  2.40s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:37<02:40,  2.39s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:40<02:37,  2.38s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:42<02:34,  2.38s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:45<02:35,  2.43s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:47<02:30,  2.39s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:50<02:33,  2.48s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:52<02:36,  2.56s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:54<02:25,  2.42s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:57<02:33,  2.59s/it]predicting train subjects:  78%|███████▊  | 208/266 [09:00<02:23,  2.47s/it]predicting train subjects:  79%|███████▊  | 209/266 [09:02<02:26,  2.57s/it]predicting train subjects:  79%|███████▉  | 210/266 [09:05<02:23,  2.56s/it]predicting train subjects:  79%|███████▉  | 211/266 [09:08<02:26,  2.67s/it]predicting train subjects:  80%|███████▉  | 212/266 [09:10<02:16,  2.53s/it]predicting train subjects:  80%|████████  | 213/266 [09:12<02:04,  2.34s/it]predicting train subjects:  80%|████████  | 214/266 [09:14<01:54,  2.21s/it]predicting train subjects:  81%|████████  | 215/266 [09:16<01:49,  2.15s/it]predicting train subjects:  81%|████████  | 216/266 [09:18<01:45,  2.11s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:20<01:38,  2.01s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:22<01:35,  1.98s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:23<01:31,  1.95s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:26<01:32,  2.01s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:28<01:30,  2.02s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:29<01:25,  1.95s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:31<01:25,  1.99s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:33<01:21,  1.94s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:35<01:18,  1.92s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:37<01:16,  1.92s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:40<01:21,  2.09s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:42<01:20,  2.12s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:44<01:15,  2.04s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:46<01:17,  2.15s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:49<01:19,  2.29s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:51<01:19,  2.35s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:53<01:17,  2.35s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:56<01:18,  2.44s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:59<01:16,  2.48s/it]predicting train subjects:  89%|████████▊ | 236/266 [10:01<01:12,  2.43s/it]predicting train subjects:  89%|████████▉ | 237/266 [10:03<01:09,  2.40s/it]predicting train subjects:  89%|████████▉ | 238/266 [10:06<01:07,  2.42s/it]predicting train subjects:  90%|████████▉ | 239/266 [10:08<01:07,  2.49s/it]predicting train subjects:  90%|█████████ | 240/266 [10:11<01:03,  2.44s/it]predicting train subjects:  91%|█████████ | 241/266 [10:13<01:00,  2.43s/it]predicting train subjects:  91%|█████████ | 242/266 [10:15<00:55,  2.31s/it]predicting train subjects:  91%|█████████▏| 243/266 [10:17<00:50,  2.21s/it]predicting train subjects:  92%|█████████▏| 244/266 [10:19<00:46,  2.11s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:21<00:44,  2.13s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:23<00:41,  2.07s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:25<00:38,  2.03s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:27<00:35,  2.00s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:30<00:38,  2.27s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:33<00:37,  2.36s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:36<00:38,  2.59s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:38<00:37,  2.66s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:41<00:35,  2.72s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:44<00:33,  2.75s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:47<00:29,  2.67s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:50<00:27,  2.78s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:52<00:24,  2.75s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:55<00:21,  2.68s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:58<00:19,  2.76s/it]predicting train subjects:  98%|█████████▊| 260/266 [11:01<00:16,  2.74s/it]predicting train subjects:  98%|█████████▊| 261/266 [11:03<00:13,  2.76s/it]predicting train subjects:  98%|█████████▊| 262/266 [11:06<00:11,  2.81s/it]predicting train subjects:  99%|█████████▉| 263/266 [11:09<00:08,  2.88s/it]predicting train subjects:  99%|█████████▉| 264/266 [11:12<00:05,  2.97s/it]predicting train subjects: 100%|█████████▉| 265/266 [11:15<00:02,  2.97s/it]predicting train subjects: 100%|██████████| 266/266 [11:18<00:00,  2.92s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:41,  1.64it/s]Loading train:   1%|          | 2/266 [00:01<02:42,  1.62it/s]Loading train:   1%|          | 3/266 [00:01<02:37,  1.67it/s]Loading train:   2%|▏         | 4/266 [00:02<02:27,  1.78it/s]Loading train:   2%|▏         | 5/266 [00:02<02:24,  1.81it/s]Loading train:   2%|▏         | 6/266 [00:03<02:28,  1.75it/s]Loading train:   3%|▎         | 7/266 [00:04<02:43,  1.58it/s]Loading train:   3%|▎         | 8/266 [00:04<02:29,  1.73it/s]Loading train:   3%|▎         | 9/266 [00:05<02:13,  1.92it/s]Loading train:   4%|▍         | 10/266 [00:05<02:03,  2.06it/s]Loading train:   4%|▍         | 11/266 [00:05<01:58,  2.15it/s]Loading train:   5%|▍         | 12/266 [00:06<02:04,  2.04it/s]Loading train:   5%|▍         | 13/266 [00:06<02:00,  2.11it/s]Loading train:   5%|▌         | 14/266 [00:07<02:10,  1.93it/s]Loading train:   6%|▌         | 15/266 [00:08<02:14,  1.86it/s]Loading train:   6%|▌         | 16/266 [00:08<02:13,  1.87it/s]Loading train:   6%|▋         | 17/266 [00:09<02:11,  1.90it/s]Loading train:   7%|▋         | 18/266 [00:09<02:07,  1.95it/s]Loading train:   7%|▋         | 19/266 [00:09<02:00,  2.05it/s]Loading train:   8%|▊         | 20/266 [00:10<02:06,  1.94it/s]Loading train:   8%|▊         | 21/266 [00:11<02:11,  1.86it/s]Loading train:   8%|▊         | 22/266 [00:11<02:19,  1.75it/s]Loading train:   9%|▊         | 23/266 [00:12<02:23,  1.69it/s]Loading train:   9%|▉         | 24/266 [00:13<02:25,  1.67it/s]Loading train:   9%|▉         | 25/266 [00:13<02:21,  1.70it/s]Loading train:  10%|▉         | 26/266 [00:14<02:23,  1.67it/s]Loading train:  10%|█         | 27/266 [00:14<02:23,  1.67it/s]Loading train:  11%|█         | 28/266 [00:15<02:25,  1.63it/s]Loading train:  11%|█         | 29/266 [00:15<02:13,  1.77it/s]Loading train:  11%|█▏        | 30/266 [00:16<02:15,  1.74it/s]Loading train:  12%|█▏        | 31/266 [00:17<02:10,  1.79it/s]Loading train:  12%|█▏        | 32/266 [00:17<02:29,  1.56it/s]Loading train:  12%|█▏        | 33/266 [00:18<02:25,  1.60it/s]Loading train:  13%|█▎        | 34/266 [00:19<02:23,  1.62it/s]Loading train:  13%|█▎        | 35/266 [00:19<02:12,  1.74it/s]Loading train:  14%|█▎        | 36/266 [00:20<02:10,  1.76it/s]Loading train:  14%|█▍        | 37/266 [00:20<02:06,  1.81it/s]Loading train:  14%|█▍        | 38/266 [00:21<02:02,  1.86it/s]Loading train:  15%|█▍        | 39/266 [00:21<02:03,  1.84it/s]Loading train:  15%|█▌        | 40/266 [00:22<02:05,  1.80it/s]Loading train:  15%|█▌        | 41/266 [00:22<02:02,  1.83it/s]Loading train:  16%|█▌        | 42/266 [00:23<01:54,  1.95it/s]Loading train:  16%|█▌        | 43/266 [00:23<01:48,  2.06it/s]Loading train:  17%|█▋        | 44/266 [00:24<01:43,  2.14it/s]Loading train:  17%|█▋        | 45/266 [00:24<01:44,  2.11it/s]Loading train:  17%|█▋        | 46/266 [00:25<01:46,  2.06it/s]Loading train:  18%|█▊        | 47/266 [00:25<01:46,  2.06it/s]Loading train:  18%|█▊        | 48/266 [00:26<01:46,  2.04it/s]Loading train:  18%|█▊        | 49/266 [00:26<01:41,  2.14it/s]Loading train:  19%|█▉        | 50/266 [00:26<01:40,  2.15it/s]Loading train:  19%|█▉        | 51/266 [00:27<01:36,  2.22it/s]Loading train:  20%|█▉        | 52/266 [00:27<01:36,  2.23it/s]Loading train:  20%|█▉        | 53/266 [00:28<01:43,  2.07it/s]Loading train:  20%|██        | 54/266 [00:28<01:44,  2.02it/s]Loading train:  21%|██        | 55/266 [00:29<01:43,  2.04it/s]Loading train:  21%|██        | 56/266 [00:29<01:45,  1.99it/s]Loading train:  21%|██▏       | 57/266 [00:30<01:49,  1.90it/s]Loading train:  22%|██▏       | 58/266 [00:30<01:46,  1.96it/s]Loading train:  22%|██▏       | 59/266 [00:31<01:41,  2.04it/s]Loading train:  23%|██▎       | 60/266 [00:31<01:42,  2.01it/s]Loading train:  23%|██▎       | 61/266 [00:32<01:45,  1.94it/s]Loading train:  23%|██▎       | 62/266 [00:32<01:40,  2.02it/s]Loading train:  24%|██▎       | 63/266 [00:33<01:33,  2.18it/s]Loading train:  24%|██▍       | 64/266 [00:33<01:28,  2.29it/s]Loading train:  24%|██▍       | 65/266 [00:34<01:35,  2.11it/s]Loading train:  25%|██▍       | 66/266 [00:34<01:38,  2.02it/s]Loading train:  25%|██▌       | 67/266 [00:35<01:35,  2.08it/s]Loading train:  26%|██▌       | 68/266 [00:35<01:30,  2.19it/s]Loading train:  26%|██▌       | 69/266 [00:36<01:25,  2.32it/s]Loading train:  26%|██▋       | 70/266 [00:36<01:21,  2.41it/s]Loading train:  27%|██▋       | 71/266 [00:36<01:27,  2.23it/s]Loading train:  27%|██▋       | 72/266 [00:37<01:32,  2.09it/s]Loading train:  27%|██▋       | 73/266 [00:37<01:29,  2.16it/s]Loading train:  28%|██▊       | 74/266 [00:38<01:26,  2.22it/s]Loading train:  28%|██▊       | 75/266 [00:38<01:32,  2.06it/s]Loading train:  29%|██▊       | 76/266 [00:39<01:34,  2.01it/s]Loading train:  29%|██▉       | 77/266 [00:39<01:30,  2.08it/s]Loading train:  29%|██▉       | 78/266 [00:40<01:43,  1.82it/s]Loading train:  30%|██▉       | 79/266 [00:41<01:41,  1.85it/s]Loading train:  30%|███       | 80/266 [00:41<01:33,  1.98it/s]Loading train:  30%|███       | 81/266 [00:41<01:27,  2.10it/s]Loading train:  31%|███       | 82/266 [00:42<01:27,  2.10it/s]Loading train:  31%|███       | 83/266 [00:42<01:27,  2.09it/s]Loading train:  32%|███▏      | 84/266 [00:43<01:31,  1.99it/s]Loading train:  32%|███▏      | 85/266 [00:43<01:29,  2.03it/s]Loading train:  32%|███▏      | 86/266 [00:44<01:25,  2.11it/s]Loading train:  33%|███▎      | 87/266 [00:44<01:25,  2.09it/s]Loading train:  33%|███▎      | 88/266 [00:45<01:31,  1.94it/s]Loading train:  33%|███▎      | 89/266 [00:46<01:36,  1.84it/s]Loading train:  34%|███▍      | 90/266 [00:46<01:34,  1.87it/s]Loading train:  34%|███▍      | 91/266 [00:47<01:32,  1.89it/s]Loading train:  35%|███▍      | 92/266 [00:47<01:32,  1.88it/s]Loading train:  35%|███▍      | 93/266 [00:48<01:32,  1.87it/s]Loading train:  35%|███▌      | 94/266 [00:48<01:28,  1.95it/s]Loading train:  36%|███▌      | 95/266 [00:49<01:33,  1.82it/s]Loading train:  36%|███▌      | 96/266 [00:49<01:31,  1.86it/s]Loading train:  36%|███▋      | 97/266 [00:50<01:28,  1.91it/s]Loading train:  37%|███▋      | 98/266 [00:50<01:30,  1.86it/s]Loading train:  37%|███▋      | 99/266 [00:51<01:24,  1.97it/s]Loading train:  38%|███▊      | 100/266 [00:51<01:24,  1.96it/s]Loading train:  38%|███▊      | 101/266 [00:52<01:21,  2.02it/s]Loading train:  38%|███▊      | 102/266 [00:52<01:20,  2.03it/s]Loading train:  39%|███▊      | 103/266 [00:53<01:20,  2.03it/s]Loading train:  39%|███▉      | 104/266 [00:53<01:19,  2.04it/s]Loading train:  39%|███▉      | 105/266 [00:54<01:15,  2.13it/s]Loading train:  40%|███▉      | 106/266 [00:54<01:16,  2.09it/s]Loading train:  40%|████      | 107/266 [00:55<01:14,  2.14it/s]Loading train:  41%|████      | 108/266 [00:55<01:20,  1.97it/s]Loading train:  41%|████      | 109/266 [00:56<01:19,  1.97it/s]Loading train:  41%|████▏     | 110/266 [00:56<01:16,  2.04it/s]Loading train:  42%|████▏     | 111/266 [00:57<01:15,  2.06it/s]Loading train:  42%|████▏     | 112/266 [00:57<01:12,  2.12it/s]Loading train:  42%|████▏     | 113/266 [00:58<01:15,  2.02it/s]Loading train:  43%|████▎     | 114/266 [00:58<01:12,  2.10it/s]Loading train:  43%|████▎     | 115/266 [00:59<01:13,  2.04it/s]Loading train:  44%|████▎     | 116/266 [00:59<01:12,  2.07it/s]Loading train:  44%|████▍     | 117/266 [00:59<01:11,  2.09it/s]Loading train:  44%|████▍     | 118/266 [01:00<01:12,  2.05it/s]Loading train:  45%|████▍     | 119/266 [01:01<01:15,  1.96it/s]Loading train:  45%|████▌     | 120/266 [01:01<01:17,  1.88it/s]Loading train:  45%|████▌     | 121/266 [01:02<01:23,  1.73it/s]Loading train:  46%|████▌     | 122/266 [01:02<01:18,  1.83it/s]Loading train:  46%|████▌     | 123/266 [01:03<01:12,  1.97it/s]Loading train:  47%|████▋     | 124/266 [01:03<01:10,  2.02it/s]Loading train:  47%|████▋     | 125/266 [01:04<01:13,  1.91it/s]Loading train:  47%|████▋     | 126/266 [01:04<01:19,  1.77it/s]Loading train:  48%|████▊     | 127/266 [01:05<01:21,  1.70it/s]Loading train:  48%|████▊     | 128/266 [01:06<01:16,  1.80it/s]Loading train:  48%|████▊     | 129/266 [01:06<01:19,  1.72it/s]Loading train:  49%|████▉     | 130/266 [01:07<01:13,  1.85it/s]Loading train:  49%|████▉     | 131/266 [01:07<01:10,  1.93it/s]Loading train:  50%|████▉     | 132/266 [01:08<01:12,  1.84it/s]Loading train:  50%|█████     | 133/266 [01:08<01:15,  1.77it/s]Loading train:  50%|█████     | 134/266 [01:09<01:16,  1.71it/s]Loading train:  51%|█████     | 135/266 [01:09<01:15,  1.73it/s]Loading train:  51%|█████     | 136/266 [01:10<01:15,  1.72it/s]Loading train:  52%|█████▏    | 137/266 [01:11<01:11,  1.80it/s]Loading train:  52%|█████▏    | 138/266 [01:11<01:06,  1.91it/s]Loading train:  52%|█████▏    | 139/266 [01:11<01:02,  2.03it/s]Loading train:  53%|█████▎    | 140/266 [01:12<00:58,  2.15it/s]Loading train:  53%|█████▎    | 141/266 [01:12<00:55,  2.27it/s]Loading train:  53%|█████▎    | 142/266 [01:13<00:53,  2.33it/s]Loading train:  54%|█████▍    | 143/266 [01:13<00:50,  2.45it/s]Loading train:  54%|█████▍    | 144/266 [01:13<00:49,  2.45it/s]Loading train:  55%|█████▍    | 145/266 [01:14<00:49,  2.44it/s]Loading train:  55%|█████▍    | 146/266 [01:14<00:53,  2.25it/s]Loading train:  55%|█████▌    | 147/266 [01:15<00:55,  2.15it/s]Loading train:  56%|█████▌    | 148/266 [01:15<00:58,  2.01it/s]Loading train:  56%|█████▌    | 149/266 [01:16<01:00,  1.95it/s]Loading train:  56%|█████▋    | 150/266 [01:17<01:00,  1.90it/s]Loading train:  57%|█████▋    | 151/266 [01:17<00:59,  1.93it/s]Loading train:  57%|█████▋    | 152/266 [01:18<01:01,  1.85it/s]Loading train:  58%|█████▊    | 153/266 [01:18<01:02,  1.81it/s]Loading train:  58%|█████▊    | 154/266 [01:19<01:02,  1.79it/s]Loading train:  58%|█████▊    | 155/266 [01:19<00:57,  1.92it/s]Loading train:  59%|█████▊    | 156/266 [01:20<01:01,  1.78it/s]Loading train:  59%|█████▉    | 157/266 [01:20<01:00,  1.81it/s]Loading train:  59%|█████▉    | 158/266 [01:21<00:57,  1.88it/s]Loading train:  60%|█████▉    | 159/266 [01:21<00:55,  1.93it/s]Loading train:  60%|██████    | 160/266 [01:22<00:54,  1.94it/s]Loading train:  61%|██████    | 161/266 [01:22<00:53,  1.97it/s]Loading train:  61%|██████    | 162/266 [01:23<00:52,  1.99it/s]Loading train:  61%|██████▏   | 163/266 [01:23<00:51,  2.01it/s]Loading train:  62%|██████▏   | 164/266 [01:24<00:50,  2.00it/s]Loading train:  62%|██████▏   | 165/266 [01:24<00:47,  2.12it/s]Loading train:  62%|██████▏   | 166/266 [01:25<00:44,  2.24it/s]Loading train:  63%|██████▎   | 167/266 [01:25<00:47,  2.10it/s]Loading train:  63%|██████▎   | 168/266 [01:26<00:46,  2.10it/s]Loading train:  64%|██████▎   | 169/266 [01:26<00:50,  1.94it/s]Loading train:  64%|██████▍   | 170/266 [01:27<00:49,  1.94it/s]Loading train:  64%|██████▍   | 171/266 [01:27<00:46,  2.06it/s]Loading train:  65%|██████▍   | 172/266 [01:28<00:46,  2.00it/s]Loading train:  65%|██████▌   | 173/266 [01:28<00:46,  1.99it/s]Loading train:  65%|██████▌   | 174/266 [01:29<00:45,  2.01it/s]Loading train:  66%|██████▌   | 175/266 [01:29<00:50,  1.79it/s]Loading train:  66%|██████▌   | 176/266 [01:30<01:03,  1.41it/s]Loading train:  67%|██████▋   | 177/266 [01:31<00:57,  1.56it/s]Loading train:  67%|██████▋   | 178/266 [01:31<00:50,  1.73it/s]Loading train:  67%|██████▋   | 179/266 [01:32<00:48,  1.81it/s]Loading train:  68%|██████▊   | 180/266 [01:32<00:48,  1.76it/s]Loading train:  68%|██████▊   | 181/266 [01:33<00:49,  1.73it/s]Loading train:  68%|██████▊   | 182/266 [01:34<00:45,  1.86it/s]Loading train:  69%|██████▉   | 183/266 [01:34<00:41,  1.98it/s]Loading train:  69%|██████▉   | 184/266 [01:34<00:39,  2.09it/s]Loading train:  70%|██████▉   | 185/266 [01:35<00:37,  2.17it/s]Loading train:  70%|██████▉   | 186/266 [01:35<00:35,  2.25it/s]Loading train:  70%|███████   | 187/266 [01:36<00:39,  1.99it/s]Loading train:  71%|███████   | 188/266 [01:36<00:39,  1.96it/s]Loading train:  71%|███████   | 189/266 [01:37<00:39,  1.97it/s]Loading train:  71%|███████▏  | 190/266 [01:37<00:37,  2.02it/s]Loading train:  72%|███████▏  | 191/266 [01:38<00:37,  1.97it/s]Loading train:  72%|███████▏  | 192/266 [01:38<00:35,  2.09it/s]Loading train:  73%|███████▎  | 193/266 [01:39<00:35,  2.05it/s]Loading train:  73%|███████▎  | 194/266 [01:39<00:37,  1.90it/s]Loading train:  73%|███████▎  | 195/266 [01:40<00:39,  1.81it/s]Loading train:  74%|███████▎  | 196/266 [01:41<00:39,  1.77it/s]Loading train:  74%|███████▍  | 197/266 [01:41<00:35,  1.93it/s]Loading train:  74%|███████▍  | 198/266 [01:41<00:33,  2.00it/s]Loading train:  75%|███████▍  | 199/266 [01:42<00:36,  1.85it/s]Loading train:  75%|███████▌  | 200/266 [01:43<00:33,  1.97it/s]Loading train:  76%|███████▌  | 201/266 [01:43<00:34,  1.90it/s]Loading train:  76%|███████▌  | 202/266 [01:44<00:32,  1.95it/s]Loading train:  76%|███████▋  | 203/266 [01:44<00:33,  1.89it/s]Loading train:  77%|███████▋  | 204/266 [01:45<00:33,  1.83it/s]Loading train:  77%|███████▋  | 205/266 [01:45<00:32,  1.86it/s]Loading train:  77%|███████▋  | 206/266 [01:46<00:31,  1.90it/s]Loading train:  78%|███████▊  | 207/266 [01:46<00:29,  1.97it/s]Loading train:  78%|███████▊  | 208/266 [01:47<00:30,  1.90it/s]Loading train:  79%|███████▊  | 209/266 [01:47<00:28,  1.98it/s]Loading train:  79%|███████▉  | 210/266 [01:48<00:27,  2.01it/s]Loading train:  79%|███████▉  | 211/266 [01:48<00:25,  2.17it/s]Loading train:  80%|███████▉  | 212/266 [01:48<00:22,  2.37it/s]Loading train:  80%|████████  | 213/266 [01:49<00:20,  2.56it/s]Loading train:  80%|████████  | 214/266 [01:49<00:20,  2.55it/s]Loading train:  81%|████████  | 215/266 [01:50<00:21,  2.39it/s]Loading train:  81%|████████  | 216/266 [01:50<00:21,  2.35it/s]Loading train:  82%|████████▏ | 217/266 [01:51<00:21,  2.24it/s]Loading train:  82%|████████▏ | 218/266 [01:51<00:21,  2.20it/s]Loading train:  82%|████████▏ | 219/266 [01:52<00:21,  2.18it/s]Loading train:  83%|████████▎ | 220/266 [01:52<00:20,  2.28it/s]Loading train:  83%|████████▎ | 221/266 [01:52<00:18,  2.45it/s]Loading train:  83%|████████▎ | 222/266 [01:53<00:17,  2.54it/s]Loading train:  84%|████████▍ | 223/266 [01:53<00:17,  2.53it/s]Loading train:  84%|████████▍ | 224/266 [01:54<00:18,  2.32it/s]Loading train:  85%|████████▍ | 225/266 [01:54<00:19,  2.10it/s]Loading train:  85%|████████▍ | 226/266 [01:55<00:18,  2.13it/s]Loading train:  85%|████████▌ | 227/266 [01:55<00:17,  2.28it/s]Loading train:  86%|████████▌ | 228/266 [01:55<00:17,  2.21it/s]Loading train:  86%|████████▌ | 229/266 [01:56<00:17,  2.16it/s]Loading train:  86%|████████▋ | 230/266 [01:56<00:16,  2.23it/s]Loading train:  87%|████████▋ | 231/266 [01:57<00:15,  2.24it/s]Loading train:  87%|████████▋ | 232/266 [01:57<00:15,  2.23it/s]Loading train:  88%|████████▊ | 233/266 [01:58<00:16,  2.03it/s]Loading train:  88%|████████▊ | 234/266 [01:58<00:15,  2.07it/s]Loading train:  88%|████████▊ | 235/266 [01:59<00:18,  1.71it/s]Loading train:  89%|████████▊ | 236/266 [02:00<00:17,  1.70it/s]Loading train:  89%|████████▉ | 237/266 [02:01<00:24,  1.16it/s]Loading train:  89%|████████▉ | 238/266 [02:02<00:24,  1.16it/s]Loading train:  90%|████████▉ | 239/266 [02:03<00:25,  1.08it/s]Loading train:  90%|█████████ | 240/266 [02:05<00:29,  1.15s/it]Loading train:  91%|█████████ | 241/266 [02:05<00:25,  1.01s/it]Loading train:  91%|█████████ | 242/266 [02:06<00:22,  1.07it/s]Loading train:  91%|█████████▏| 243/266 [02:07<00:19,  1.15it/s]Loading train:  92%|█████████▏| 244/266 [02:08<00:17,  1.23it/s]Loading train:  92%|█████████▏| 245/266 [02:08<00:17,  1.23it/s]Loading train:  92%|█████████▏| 246/266 [02:09<00:17,  1.14it/s]Loading train:  93%|█████████▎| 247/266 [02:10<00:14,  1.28it/s]Loading train:  93%|█████████▎| 248/266 [02:11<00:12,  1.43it/s]Loading train:  94%|█████████▎| 249/266 [02:11<00:11,  1.54it/s]Loading train:  94%|█████████▍| 250/266 [02:12<00:10,  1.46it/s]Loading train:  94%|█████████▍| 251/266 [02:13<00:10,  1.39it/s]Loading train:  95%|█████████▍| 252/266 [02:13<00:10,  1.32it/s]Loading train:  95%|█████████▌| 253/266 [02:15<00:13,  1.01s/it]Loading train:  95%|█████████▌| 254/266 [02:16<00:11,  1.09it/s]Loading train:  96%|█████████▌| 255/266 [02:17<00:10,  1.04it/s]Loading train:  96%|█████████▌| 256/266 [02:18<00:09,  1.04it/s]Loading train:  97%|█████████▋| 257/266 [02:19<00:08,  1.07it/s]Loading train:  97%|█████████▋| 258/266 [02:20<00:08,  1.01s/it]Loading train:  97%|█████████▋| 259/266 [02:21<00:07,  1.00s/it]Loading train:  98%|█████████▊| 260/266 [02:22<00:05,  1.07it/s]Loading train:  98%|█████████▊| 261/266 [02:23<00:04,  1.07it/s]Loading train:  98%|█████████▊| 262/266 [02:24<00:04,  1.19s/it]Loading train:  99%|█████████▉| 263/266 [02:26<00:03,  1.22s/it]Loading train:  99%|█████████▉| 264/266 [02:27<00:02,  1.12s/it]Loading train: 100%|█████████▉| 265/266 [02:27<00:00,  1.04it/s]Loading train: 100%|██████████| 266/266 [02:28<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/266 [00:00<00:09, 27.35it/s]concatenating: train:   3%|▎         | 9/266 [00:00<00:07, 32.24it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:07, 34.91it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:07, 33.72it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:07, 32.10it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:07, 31.05it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:08, 27.36it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:08, 26.61it/s]concatenating: train:  13%|█▎        | 34/266 [00:01<00:07, 29.58it/s]concatenating: train:  14%|█▍        | 38/266 [00:01<00:10, 22.69it/s]concatenating: train:  16%|█▌        | 42/266 [00:01<00:09, 24.72it/s]concatenating: train:  18%|█▊        | 48/266 [00:01<00:07, 29.82it/s]concatenating: train:  21%|██        | 55/266 [00:01<00:05, 35.37it/s]concatenating: train:  23%|██▎       | 61/266 [00:01<00:05, 40.02it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:04, 44.86it/s]concatenating: train:  28%|██▊       | 74/266 [00:01<00:04, 46.29it/s]concatenating: train:  30%|███       | 80/266 [00:02<00:03, 48.25it/s]concatenating: train:  33%|███▎      | 87/266 [00:02<00:03, 51.79it/s]concatenating: train:  35%|███▍      | 93/266 [00:02<00:03, 45.22it/s]concatenating: train:  37%|███▋      | 98/266 [00:02<00:04, 35.79it/s]concatenating: train:  39%|███▊      | 103/266 [00:02<00:05, 32.18it/s]concatenating: train:  40%|████      | 107/266 [00:02<00:04, 33.47it/s]concatenating: train:  43%|████▎     | 114/266 [00:02<00:03, 39.15it/s]concatenating: train:  45%|████▌     | 121/266 [00:03<00:03, 44.76it/s]concatenating: train:  48%|████▊     | 127/266 [00:03<00:03, 45.37it/s]concatenating: train:  50%|█████     | 134/266 [00:03<00:02, 49.00it/s]concatenating: train:  53%|█████▎    | 140/266 [00:03<00:02, 46.18it/s]concatenating: train:  55%|█████▍    | 145/266 [00:03<00:03, 37.48it/s]concatenating: train:  56%|█████▋    | 150/266 [00:03<00:02, 39.72it/s]concatenating: train:  59%|█████▊    | 156/266 [00:03<00:02, 43.06it/s]concatenating: train:  61%|██████▏   | 163/266 [00:04<00:02, 47.49it/s]concatenating: train:  64%|██████▎   | 169/266 [00:04<00:02, 48.22it/s]concatenating: train:  66%|██████▌   | 176/266 [00:04<00:01, 51.77it/s]concatenating: train:  68%|██████▊   | 182/266 [00:04<00:01, 42.91it/s]concatenating: train:  70%|███████   | 187/266 [00:04<00:01, 40.04it/s]concatenating: train:  73%|███████▎  | 194/266 [00:04<00:01, 43.57it/s]concatenating: train:  75%|███████▍  | 199/266 [00:04<00:01, 38.96it/s]concatenating: train:  77%|███████▋  | 204/266 [00:05<00:01, 36.28it/s]concatenating: train:  79%|███████▉  | 210/266 [00:05<00:01, 40.17it/s]concatenating: train:  81%|████████  | 215/266 [00:05<00:01, 39.42it/s]concatenating: train:  83%|████████▎ | 220/266 [00:05<00:01, 40.10it/s]concatenating: train:  85%|████████▍ | 225/266 [00:05<00:01, 39.38it/s]concatenating: train:  87%|████████▋ | 232/266 [00:05<00:00, 43.66it/s]concatenating: train:  89%|████████▉ | 237/266 [00:05<00:00, 39.01it/s]concatenating: train:  91%|█████████ | 242/266 [00:05<00:00, 36.62it/s]concatenating: train:  93%|█████████▎| 247/266 [00:06<00:00, 39.41it/s]concatenating: train:  95%|█████████▌| 254/266 [00:06<00:00, 44.32it/s]concatenating: train:  97%|█████████▋| 259/266 [00:06<00:00, 40.18it/s]concatenating: train: 100%|██████████| 266/266 [00:06<00:00, 44.97it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.11it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.20it/s]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.29it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.36it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation:  75%|███████▌  | 3/4 [00:00<00:00, 21.48it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 23.29it/s]2019-07-28 16:09:05.081081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 16:09:05.081186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 16:09:05.081206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 16:09:05.081217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 16:09:05.081600: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:19,  2.20it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:14,  2.85it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:12,  3.19it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:08,  4.26it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  4.30it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.08it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.00it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.37it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.00it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:10,  2.23it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:09,  2.45it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:06,  3.13it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:04,  3.90it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:04,  3.76it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:03,  4.54it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:02,  4.49it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.82it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  6.57it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  5.72it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:01,  3.39it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:07<00:00,  3.34it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:07<00:00,  6.04it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 10)  100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 10)  40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 10)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 76, 108, 10)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 10)  910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 10)  40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 10)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 76, 108, 10)  0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 76, 108, 11)  0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 76, 108, 30)  3000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 76, 108, 30)  120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 76, 108, 30)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 76, 108, 30)  8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 76, 108, 30)  120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 108, 30)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 38, 54, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 38, 54, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 54, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 38, 54, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 38, 54, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 38, 54, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 38, 54, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 19, 27, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 19, 27, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 19, 27, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 19, 27, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 19, 27, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 19, 27, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 19, 27, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 19, 27, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 54, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 54, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 38, 54, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 38, 54, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 38, 54, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 38, 54, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 38, 54, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 30)  16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 76, 108, 30)  120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 76, 108, 30)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 76, 108, 30)  8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 76, 108, 30)  120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 76, 108, 30)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 76, 108, 90)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 76, 108, 90)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 76, 108, 10)  8110        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 76, 108, 10)  40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 76, 108, 10)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 76, 108, 10)  0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 76, 108, 10)  910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 76, 108, 10)  40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 76, 108, 10)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 76, 108, 10)  0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 76, 108, 100) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 76, 108, 2)   202         concatenate_8[0][0]              
==================================================================================================
Total params: 513,252
Trainable params: 120,952
Non-trainable params: 392,300
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 396 samples
Epoch 1/300
 - 72s - loss: 0.1471 - acc: 0.9727 - mDice: 0.8158 - val_loss: 0.0624 - val_acc: 0.9946 - val_mDice: 0.8857

Epoch 00001: val_mDice improved from -inf to 0.88568, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 66s - loss: 0.0542 - acc: 0.9941 - mDice: 0.9003 - val_loss: 0.0602 - val_acc: 0.9947 - val_mDice: 0.8897

Epoch 00002: val_mDice improved from 0.88568 to 0.88970, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 66s - loss: 0.0485 - acc: 0.9947 - mDice: 0.9101 - val_loss: 0.0592 - val_acc: 0.9947 - val_mDice: 0.8915

Epoch 00003: val_mDice improved from 0.88970 to 0.89148, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 66s - loss: 0.0453 - acc: 0.9950 - mDice: 0.9159 - val_loss: 0.0621 - val_acc: 0.9947 - val_mDice: 0.8869

Epoch 00004: val_mDice did not improve from 0.89148
Epoch 5/300
 - 67s - loss: 0.0426 - acc: 0.9952 - mDice: 0.9207 - val_loss: 0.0582 - val_acc: 0.9952 - val_mDice: 0.8934

Epoch 00005: val_mDice improved from 0.89148 to 0.89340, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 66s - loss: 0.0404 - acc: 0.9954 - mDice: 0.9246 - val_loss: 0.0623 - val_acc: 0.9948 - val_mDice: 0.8862

Epoch 00006: val_mDice did not improve from 0.89340
Epoch 7/300
 - 67s - loss: 0.0394 - acc: 0.9955 - mDice: 0.9264 - val_loss: 0.0607 - val_acc: 0.9945 - val_mDice: 0.8889

Epoch 00007: val_mDice did not improve from 0.89340
Epoch 8/300
 - 68s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9291 - val_loss: 0.0629 - val_acc: 0.9946 - val_mDice: 0.8852

Epoch 00008: val_mDice did not improve from 0.89340
Epoch 9/300
 - 68s - loss: 0.0370 - acc: 0.9957 - mDice: 0.9306 - val_loss: 0.0615 - val_acc: 0.9948 - val_mDice: 0.8879

Epoch 00009: val_mDice did not improve from 0.89340
Epoch 10/300
 - 69s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9324 - val_loss: 0.0603 - val_acc: 0.9946 - val_mDice: 0.8896

Epoch 00010: val_mDice did not improve from 0.89340
Epoch 11/300
 - 69s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9337 - val_loss: 0.0615 - val_acc: 0.9947 - val_mDice: 0.8879

Epoch 00011: val_mDice did not improve from 0.89340
Epoch 12/300
 - 67s - loss: 0.0346 - acc: 0.9959 - mDice: 0.9350 - val_loss: 0.0625 - val_acc: 0.9947 - val_mDice: 0.8860

Epoch 00012: val_mDice did not improve from 0.89340
Epoch 13/300
 - 68s - loss: 0.0340 - acc: 0.9960 - mDice: 0.9361 - val_loss: 0.0632 - val_acc: 0.9947 - val_mDice: 0.8851

Epoch 00013: val_mDice did not improve from 0.89340
Epoch 14/300
 - 68s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9374 - val_loss: 0.0636 - val_acc: 0.9945 - val_mDice: 0.8846

Epoch 00014: val_mDice did not improve from 0.89340
Epoch 15/300
 - 70s - loss: 0.0330 - acc: 0.9961 - mDice: 0.9380 - val_loss: 0.0621 - val_acc: 0.9948 - val_mDice: 0.8869

Epoch 00015: val_mDice did not improve from 0.89340
Epoch 16/300
 - 69s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9393 - val_loss: 0.0617 - val_acc: 0.9948 - val_mDice: 0.8876

Epoch 00016: val_mDice did not improve from 0.89340
Epoch 17/300
 - 69s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9398 - val_loss: 0.0600 - val_acc: 0.9948 - val_mDice: 0.8903

Epoch 00017: val_mDice did not improve from 0.89340
Epoch 18/300
 - 70s - loss: 0.0316 - acc: 0.9962 - mDice: 0.9405 - val_loss: 0.0641 - val_acc: 0.9948 - val_mDice: 0.8835

Epoch 00018: val_mDice did not improve from 0.89340
Epoch 19/300
 - 76s - loss: 0.0313 - acc: 0.9962 - mDice: 0.9411 - val_loss: 0.0630 - val_acc: 0.9948 - val_mDice: 0.8854

Epoch 00019: val_mDice did not improve from 0.89340
Epoch 20/300
 - 82s - loss: 0.0309 - acc: 0.9962 - mDice: 0.9419 - val_loss: 0.0626 - val_acc: 0.9949 - val_mDice: 0.8860

Epoch 00020: val_mDice did not improve from 0.89340
Epoch 21/300
 - 67s - loss: 0.0307 - acc: 0.9963 - mDice: 0.9422 - val_loss: 0.0620 - val_acc: 0.9946 - val_mDice: 0.8872

Epoch 00021: val_mDice did not improve from 0.89340
Epoch 22/300
 - 66s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9430 - val_loss: 0.0645 - val_acc: 0.9946 - val_mDice: 0.8831

Epoch 00022: val_mDice did not improve from 0.89340
Epoch 23/300
 - 66s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9433 - val_loss: 0.0623 - val_acc: 0.9947 - val_mDice: 0.8867

Epoch 00023: val_mDice did not improve from 0.89340
Epoch 24/300
 - 66s - loss: 0.0297 - acc: 0.9963 - mDice: 0.9440 - val_loss: 0.0637 - val_acc: 0.9947 - val_mDice: 0.8844

Epoch 00024: val_mDice did not improve from 0.89340
Epoch 25/300
 - 66s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9439 - val_loss: 0.0639 - val_acc: 0.9946 - val_mDice: 0.8839

Epoch 00025: val_mDice did not improve from 0.89340
Epoch 26/300
 - 66s - loss: 0.0295 - acc: 0.9964 - mDice: 0.9444 - val_loss: 0.0620 - val_acc: 0.9947 - val_mDice: 0.8871

Epoch 00026: val_mDice did not improve from 0.89340
Epoch 27/300
 - 66s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9453 - val_loss: 0.0616 - val_acc: 0.9948 - val_mDice: 0.8877

Epoch 00027: val_mDice did not improve from 0.89340
Epoch 28/300
 - 79s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9454 - val_loss: 0.0622 - val_acc: 0.9942 - val_mDice: 0.8868

Epoch 00028: val_mDice did not improve from 0.89340
Epoch 29/300
 - 66s - loss: 0.0287 - acc: 0.9964 - mDice: 0.9459 - val_loss: 0.0618 - val_acc: 0.9945 - val_mDice: 0.8875

Epoch 00029: val_mDice did not improve from 0.89340
Epoch 30/300
 - 65s - loss: 0.0285 - acc: 0.9965 - mDice: 0.9463 - val_loss: 0.0627 - val_acc: 0.9949 - val_mDice: 0.8861

Epoch 00030: val_mDice did not improve from 0.89340
Epoch 31/300
 - 66s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9466 - val_loss: 0.0634 - val_acc: 0.9945 - val_mDice: 0.8847

Epoch 00031: val_mDice did not improve from 0.89340
Epoch 32/300
 - 65s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9466 - val_loss: 0.0623 - val_acc: 0.9947 - val_mDice: 0.8866

Epoch 00032: val_mDice did not improve from 0.89340
Epoch 33/300
 - 65s - loss: 0.0281 - acc: 0.9965 - mDice: 0.9470 - val_loss: 0.0619 - val_acc: 0.9948 - val_mDice: 0.8873

Epoch 00033: val_mDice did not improve from 0.89340
Epoch 34/300
 - 66s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9474 - val_loss: 0.0636 - val_acc: 0.9942 - val_mDice: 0.8845

Epoch 00034: val_mDice did not improve from 0.89340
Epoch 35/300
 - 66s - loss: 0.0279 - acc: 0.9965 - mDice: 0.9474 - val_loss: 0.0607 - val_acc: 0.9946 - val_mDice: 0.8894

Epoch 00035: val_mDice did not improve from 0.89340
Epoch 36/300
 - 68s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9477 - val_loss: 0.0614 - val_acc: 0.9948 - val_mDice: 0.8882

Epoch 00036: val_mDice did not improve from 0.89340
Epoch 37/300
 - 68s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9480 - val_loss: 0.0615 - val_acc: 0.9945 - val_mDice: 0.8878

Epoch 00037: val_mDice did not improve from 0.89340
Epoch 38/300
 - 69s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9483 - val_loss: 0.0627 - val_acc: 0.9946 - val_mDice: 0.8858

Epoch 00038: val_mDice did not improve from 0.89340
Epoch 39/300
 - 70s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9484 - val_loss: 0.0655 - val_acc: 0.9948 - val_mDice: 0.8813

Epoch 00039: val_mDice did not improve from 0.89340
Epoch 40/300
 - 70s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9489 - val_loss: 0.0653 - val_acc: 0.9947 - val_mDice: 0.8816

Epoch 00040: val_mDice did not improve from 0.89340
Epoch 41/300
 - 70s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9489 - val_loss: 0.0629 - val_acc: 0.9946 - val_mDice: 0.8856

Epoch 00041: val_mDice did not improve from 0.89340
Epoch 42/300
 - 69s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9491 - val_loss: 0.0643 - val_acc: 0.9946 - val_mDice: 0.8833

Epoch 00042: val_mDice did not improve from 0.89340
Epoch 43/300
 - 69s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9492 - val_loss: 0.0633 - val_acc: 0.9944 - val_mDice: 0.8852

Epoch 00043: val_mDice did not improve from 0.89340
Epoch 44/300
 - 69s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9495 - val_loss: 0.0623 - val_acc: 0.9948 - val_mDice: 0.8866

Epoch 00044: val_mDice did not improve from 0.89340
Epoch 45/300
 - 67s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9499 - val_loss: 0.0664 - val_acc: 0.9946 - val_mDice: 0.8797

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.63s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.33s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:01,  1.10s/it]predicting test subjects: 100%|██████████| 4/4 [00:03<00:00,  1.04it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<02:49,  1.56it/s]predicting train subjects:   1%|          | 2/266 [00:01<03:00,  1.46it/s]predicting train subjects:   1%|          | 3/266 [00:01<02:47,  1.57it/s]predicting train subjects:   2%|▏         | 4/266 [00:02<02:31,  1.73it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<02:32,  1.72it/s]predicting train subjects:   2%|▏         | 6/266 [00:03<02:34,  1.69it/s]predicting train subjects:   3%|▎         | 7/266 [00:04<02:29,  1.74it/s]predicting train subjects:   3%|▎         | 8/266 [00:04<02:22,  1.81it/s]predicting train subjects:   3%|▎         | 9/266 [00:05<02:20,  1.83it/s]predicting train subjects:   4%|▍         | 10/266 [00:05<02:19,  1.84it/s]predicting train subjects:   4%|▍         | 11/266 [00:06<02:27,  1.73it/s]predicting train subjects:   5%|▍         | 12/266 [00:06<02:27,  1.72it/s]predicting train subjects:   5%|▍         | 13/266 [00:07<02:30,  1.68it/s]predicting train subjects:   5%|▌         | 14/266 [00:08<02:23,  1.75it/s]predicting train subjects:   6%|▌         | 15/266 [00:08<02:18,  1.82it/s]predicting train subjects:   6%|▌         | 16/266 [00:09<02:19,  1.79it/s]predicting train subjects:   6%|▋         | 17/266 [00:09<02:23,  1.74it/s]predicting train subjects:   7%|▋         | 18/266 [00:10<02:32,  1.63it/s]predicting train subjects:   7%|▋         | 19/266 [00:11<02:24,  1.71it/s]predicting train subjects:   8%|▊         | 20/266 [00:11<02:24,  1.71it/s]predicting train subjects:   8%|▊         | 21/266 [00:12<02:23,  1.71it/s]predicting train subjects:   8%|▊         | 22/266 [00:12<02:36,  1.56it/s]predicting train subjects:   9%|▊         | 23/266 [00:13<02:39,  1.52it/s]predicting train subjects:   9%|▉         | 24/266 [00:14<02:28,  1.63it/s]predicting train subjects:   9%|▉         | 25/266 [00:14<02:20,  1.71it/s]predicting train subjects:  10%|▉         | 26/266 [00:15<02:13,  1.80it/s]predicting train subjects:  10%|█         | 27/266 [00:15<02:14,  1.78it/s]predicting train subjects:  11%|█         | 28/266 [00:16<02:09,  1.83it/s]predicting train subjects:  11%|█         | 29/266 [00:16<02:06,  1.87it/s]predicting train subjects:  11%|█▏        | 30/266 [00:17<02:05,  1.88it/s]predicting train subjects:  12%|█▏        | 31/266 [00:17<02:05,  1.87it/s]predicting train subjects:  12%|█▏        | 32/266 [00:18<02:09,  1.80it/s]predicting train subjects:  12%|█▏        | 33/266 [00:18<02:09,  1.80it/s]predicting train subjects:  13%|█▎        | 34/266 [00:19<02:09,  1.80it/s]predicting train subjects:  13%|█▎        | 35/266 [00:20<02:11,  1.75it/s]predicting train subjects:  14%|█▎        | 36/266 [00:20<02:15,  1.70it/s]predicting train subjects:  14%|█▍        | 37/266 [00:21<02:10,  1.75it/s]predicting train subjects:  14%|█▍        | 38/266 [00:21<02:07,  1.78it/s]predicting train subjects:  15%|█▍        | 39/266 [00:22<02:05,  1.80it/s]predicting train subjects:  15%|█▌        | 40/266 [00:22<02:07,  1.77it/s]predicting train subjects:  15%|█▌        | 41/266 [00:23<02:13,  1.69it/s]predicting train subjects:  16%|█▌        | 42/266 [00:24<02:14,  1.66it/s]predicting train subjects:  16%|█▌        | 43/266 [00:24<02:12,  1.68it/s]predicting train subjects:  17%|█▋        | 44/266 [00:25<02:07,  1.74it/s]predicting train subjects:  17%|█▋        | 45/266 [00:25<02:08,  1.72it/s]predicting train subjects:  17%|█▋        | 46/266 [00:26<02:09,  1.69it/s]predicting train subjects:  18%|█▊        | 47/266 [00:27<02:02,  1.79it/s]predicting train subjects:  18%|█▊        | 48/266 [00:27<01:58,  1.83it/s]predicting train subjects:  18%|█▊        | 49/266 [00:28<01:58,  1.84it/s]predicting train subjects:  19%|█▉        | 50/266 [00:28<01:49,  1.96it/s]predicting train subjects:  19%|█▉        | 51/266 [00:28<01:42,  2.10it/s]predicting train subjects:  20%|█▉        | 52/266 [00:29<01:37,  2.19it/s]predicting train subjects:  20%|█▉        | 53/266 [00:29<01:35,  2.23it/s]predicting train subjects:  20%|██        | 54/266 [00:30<01:42,  2.06it/s]predicting train subjects:  21%|██        | 55/266 [00:30<01:49,  1.93it/s]predicting train subjects:  21%|██        | 56/266 [00:31<01:44,  2.01it/s]predicting train subjects:  21%|██▏       | 57/266 [00:31<01:41,  2.07it/s]predicting train subjects:  22%|██▏       | 58/266 [00:32<01:38,  2.11it/s]predicting train subjects:  22%|██▏       | 59/266 [00:32<01:37,  2.12it/s]predicting train subjects:  23%|██▎       | 60/266 [00:33<01:35,  2.16it/s]predicting train subjects:  23%|██▎       | 61/266 [00:33<01:34,  2.16it/s]predicting train subjects:  23%|██▎       | 62/266 [00:34<01:31,  2.22it/s]predicting train subjects:  24%|██▎       | 63/266 [00:34<01:30,  2.25it/s]predicting train subjects:  24%|██▍       | 64/266 [00:34<01:32,  2.19it/s]predicting train subjects:  24%|██▍       | 65/266 [00:35<01:33,  2.15it/s]predicting train subjects:  25%|██▍       | 66/266 [00:35<01:33,  2.13it/s]predicting train subjects:  25%|██▌       | 67/266 [00:36<01:37,  2.05it/s]predicting train subjects:  26%|██▌       | 68/266 [00:36<01:32,  2.14it/s]predicting train subjects:  26%|██▌       | 69/266 [00:37<01:31,  2.16it/s]predicting train subjects:  26%|██▋       | 70/266 [00:37<01:32,  2.13it/s]predicting train subjects:  27%|██▋       | 71/266 [00:38<01:30,  2.15it/s]predicting train subjects:  27%|██▋       | 72/266 [00:38<01:36,  2.02it/s]predicting train subjects:  27%|██▋       | 73/266 [00:39<01:36,  1.99it/s]predicting train subjects:  28%|██▊       | 74/266 [00:39<01:32,  2.07it/s]predicting train subjects:  28%|██▊       | 75/266 [00:40<01:30,  2.12it/s]predicting train subjects:  29%|██▊       | 76/266 [00:40<01:27,  2.16it/s]predicting train subjects:  29%|██▉       | 77/266 [00:41<01:23,  2.26it/s]predicting train subjects:  29%|██▉       | 78/266 [00:41<01:36,  1.94it/s]predicting train subjects:  30%|██▉       | 79/266 [00:42<01:41,  1.83it/s]predicting train subjects:  30%|███       | 80/266 [00:43<01:48,  1.71it/s]predicting train subjects:  30%|███       | 81/266 [00:43<02:00,  1.53it/s]predicting train subjects:  31%|███       | 82/266 [00:44<02:02,  1.51it/s]predicting train subjects:  31%|███       | 83/266 [00:45<01:56,  1.57it/s]predicting train subjects:  32%|███▏      | 84/266 [00:45<01:54,  1.59it/s]predicting train subjects:  32%|███▏      | 85/266 [00:46<01:50,  1.65it/s]predicting train subjects:  32%|███▏      | 86/266 [00:46<01:50,  1.63it/s]predicting train subjects:  33%|███▎      | 87/266 [00:47<01:53,  1.58it/s]predicting train subjects:  33%|███▎      | 88/266 [00:48<01:56,  1.53it/s]predicting train subjects:  33%|███▎      | 89/266 [00:48<01:48,  1.64it/s]predicting train subjects:  34%|███▍      | 90/266 [00:49<01:41,  1.73it/s]predicting train subjects:  34%|███▍      | 91/266 [00:49<01:35,  1.83it/s]predicting train subjects:  35%|███▍      | 92/266 [00:50<01:36,  1.80it/s]predicting train subjects:  35%|███▍      | 93/266 [00:50<01:31,  1.89it/s]predicting train subjects:  35%|███▌      | 94/266 [00:51<01:33,  1.84it/s]predicting train subjects:  36%|███▌      | 95/266 [00:51<01:32,  1.85it/s]predicting train subjects:  36%|███▌      | 96/266 [00:52<01:31,  1.86it/s]predicting train subjects:  36%|███▋      | 97/266 [00:53<01:31,  1.85it/s]predicting train subjects:  37%|███▋      | 98/266 [00:53<01:39,  1.69it/s]predicting train subjects:  37%|███▋      | 99/266 [00:54<01:36,  1.73it/s]predicting train subjects:  38%|███▊      | 100/266 [00:54<01:32,  1.79it/s]predicting train subjects:  38%|███▊      | 101/266 [00:55<01:30,  1.83it/s]predicting train subjects:  38%|███▊      | 102/266 [00:55<01:26,  1.91it/s]predicting train subjects:  39%|███▊      | 103/266 [00:56<01:27,  1.85it/s]predicting train subjects:  39%|███▉      | 104/266 [00:56<01:26,  1.87it/s]predicting train subjects:  39%|███▉      | 105/266 [00:57<01:23,  1.93it/s]predicting train subjects:  40%|███▉      | 106/266 [00:57<01:21,  1.96it/s]predicting train subjects:  40%|████      | 107/266 [00:58<01:22,  1.93it/s]predicting train subjects:  41%|████      | 108/266 [00:58<01:18,  2.01it/s]predicting train subjects:  41%|████      | 109/266 [00:59<01:25,  1.84it/s]predicting train subjects:  41%|████▏     | 110/266 [00:59<01:20,  1.93it/s]predicting train subjects:  42%|████▏     | 111/266 [01:00<01:29,  1.74it/s]predicting train subjects:  42%|████▏     | 112/266 [01:01<01:29,  1.72it/s]predicting train subjects:  42%|████▏     | 113/266 [01:01<01:28,  1.73it/s]predicting train subjects:  43%|████▎     | 114/266 [01:02<01:27,  1.74it/s]predicting train subjects:  43%|████▎     | 115/266 [01:03<01:34,  1.60it/s]predicting train subjects:  44%|████▎     | 116/266 [01:03<01:37,  1.54it/s]predicting train subjects:  44%|████▍     | 117/266 [01:04<01:45,  1.41it/s]predicting train subjects:  44%|████▍     | 118/266 [01:05<01:40,  1.47it/s]predicting train subjects:  45%|████▍     | 119/266 [01:05<01:33,  1.58it/s]predicting train subjects:  45%|████▌     | 120/266 [01:06<01:35,  1.53it/s]predicting train subjects:  45%|████▌     | 121/266 [01:07<01:33,  1.55it/s]predicting train subjects:  46%|████▌     | 122/266 [01:07<01:28,  1.63it/s]predicting train subjects:  46%|████▌     | 123/266 [01:08<01:23,  1.70it/s]predicting train subjects:  47%|████▋     | 124/266 [01:08<01:22,  1.72it/s]predicting train subjects:  47%|████▋     | 125/266 [01:09<01:24,  1.67it/s]predicting train subjects:  47%|████▋     | 126/266 [01:10<01:28,  1.59it/s]predicting train subjects:  48%|████▊     | 127/266 [01:10<01:29,  1.56it/s]predicting train subjects:  48%|████▊     | 128/266 [01:11<01:28,  1.56it/s]predicting train subjects:  48%|████▊     | 129/266 [01:12<01:25,  1.61it/s]predicting train subjects:  49%|████▉     | 130/266 [01:12<01:24,  1.62it/s]predicting train subjects:  49%|████▉     | 131/266 [01:13<01:18,  1.73it/s]predicting train subjects:  50%|████▉     | 132/266 [01:13<01:13,  1.81it/s]predicting train subjects:  50%|█████     | 133/266 [01:14<01:11,  1.86it/s]predicting train subjects:  50%|█████     | 134/266 [01:14<01:09,  1.89it/s]predicting train subjects:  51%|█████     | 135/266 [01:15<01:06,  1.98it/s]predicting train subjects:  51%|█████     | 136/266 [01:15<01:08,  1.90it/s]predicting train subjects:  52%|█████▏    | 137/266 [01:16<01:07,  1.90it/s]predicting train subjects:  52%|█████▏    | 138/266 [01:16<01:04,  2.00it/s]predicting train subjects:  52%|█████▏    | 139/266 [01:17<01:01,  2.05it/s]predicting train subjects:  53%|█████▎    | 140/266 [01:17<01:01,  2.05it/s]predicting train subjects:  53%|█████▎    | 141/266 [01:18<01:03,  1.97it/s]predicting train subjects:  53%|█████▎    | 142/266 [01:18<01:02,  1.98it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:19<01:02,  1.97it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:19<01:04,  1.89it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:20<01:04,  1.88it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:20<01:03,  1.90it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:21<01:03,  1.88it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:21<01:00,  1.94it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:22<00:59,  1.98it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:22<01:00,  1.90it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:23<01:01,  1.86it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:24<01:04,  1.77it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:24<01:00,  1.86it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:25<01:00,  1.86it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:25<00:58,  1.89it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:26<00:57,  1.92it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:26<00:54,  1.98it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:26<00:51,  2.09it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:27<00:50,  2.11it/s]predicting train subjects:  60%|██████    | 160/266 [01:27<00:52,  2.01it/s]predicting train subjects:  61%|██████    | 161/266 [01:28<00:51,  2.02it/s]predicting train subjects:  61%|██████    | 162/266 [01:28<00:51,  2.01it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:29<00:48,  2.11it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:29<00:44,  2.28it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:30<00:41,  2.43it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:30<00:39,  2.51it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:30<00:38,  2.56it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:31<00:39,  2.51it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:31<00:40,  2.42it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:32<00:42,  2.25it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:32<00:43,  2.17it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:33<00:45,  2.07it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:33<00:45,  2.05it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:34<00:43,  2.10it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:34<00:42,  2.13it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:35<00:44,  2.02it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:35<00:42,  2.09it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:36<00:43,  2.01it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:36<00:42,  2.03it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:37<00:44,  1.94it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:37<00:45,  1.86it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:38<00:45,  1.84it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:38<00:46,  1.78it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:39<00:44,  1.83it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:39<00:41,  1.95it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:40<00:40,  1.97it/s]predicting train subjects:  70%|███████   | 187/266 [01:41<00:42,  1.85it/s]predicting train subjects:  71%|███████   | 188/266 [01:41<00:43,  1.78it/s]predicting train subjects:  71%|███████   | 189/266 [01:42<00:41,  1.85it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:42<00:42,  1.81it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:43<00:43,  1.74it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:43<00:43,  1.71it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:44<00:41,  1.75it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:45<00:43,  1.67it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:45<00:42,  1.69it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:46<00:37,  1.88it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:46<00:38,  1.79it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:47<00:36,  1.88it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:47<00:33,  1.97it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:48<00:35,  1.84it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:48<00:33,  1.93it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:49<00:34,  1.86it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:49<00:32,  1.92it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:50<00:33,  1.85it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:51<00:34,  1.79it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:51<00:34,  1.74it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:52<00:34,  1.70it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:52<00:32,  1.77it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:53<00:31,  1.83it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:53<00:29,  1.92it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:54<00:27,  1.99it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:54<00:27,  1.99it/s]predicting train subjects:  80%|████████  | 213/266 [01:55<00:25,  2.05it/s]predicting train subjects:  80%|████████  | 214/266 [01:55<00:25,  2.06it/s]predicting train subjects:  81%|████████  | 215/266 [01:56<00:24,  2.07it/s]predicting train subjects:  81%|████████  | 216/266 [01:56<00:22,  2.20it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:56<00:21,  2.32it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:57<00:19,  2.40it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:57<00:19,  2.40it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:58<00:18,  2.51it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:58<00:18,  2.46it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:58<00:17,  2.52it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:59<00:16,  2.56it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:59<00:17,  2.38it/s]predicting train subjects:  85%|████████▍ | 225/266 [02:00<00:18,  2.24it/s]predicting train subjects:  85%|████████▍ | 226/266 [02:00<00:17,  2.32it/s]predicting train subjects:  85%|████████▌ | 227/266 [02:00<00:16,  2.36it/s]predicting train subjects:  86%|████████▌ | 228/266 [02:01<00:15,  2.50it/s]predicting train subjects:  86%|████████▌ | 229/266 [02:01<00:14,  2.56it/s]predicting train subjects:  86%|████████▋ | 230/266 [02:02<00:13,  2.62it/s]predicting train subjects:  87%|████████▋ | 231/266 [02:02<00:14,  2.48it/s]predicting train subjects:  87%|████████▋ | 232/266 [02:02<00:13,  2.45it/s]predicting train subjects:  88%|████████▊ | 233/266 [02:03<00:13,  2.47it/s]predicting train subjects:  88%|████████▊ | 234/266 [02:03<00:13,  2.45it/s]predicting train subjects:  88%|████████▊ | 235/266 [02:04<00:12,  2.49it/s]predicting train subjects:  89%|████████▊ | 236/266 [02:04<00:12,  2.45it/s]predicting train subjects:  89%|████████▉ | 237/266 [02:04<00:12,  2.41it/s]predicting train subjects:  89%|████████▉ | 238/266 [02:05<00:12,  2.22it/s]predicting train subjects:  90%|████████▉ | 239/266 [02:05<00:12,  2.22it/s]predicting train subjects:  90%|█████████ | 240/266 [02:06<00:11,  2.28it/s]predicting train subjects:  91%|█████████ | 241/266 [02:06<00:10,  2.34it/s]predicting train subjects:  91%|█████████ | 242/266 [02:07<00:10,  2.35it/s]predicting train subjects:  91%|█████████▏| 243/266 [02:07<00:09,  2.35it/s]predicting train subjects:  92%|█████████▏| 244/266 [02:08<00:09,  2.35it/s]predicting train subjects:  92%|█████████▏| 245/266 [02:08<00:08,  2.42it/s]predicting train subjects:  92%|█████████▏| 246/266 [02:08<00:08,  2.42it/s]predicting train subjects:  93%|█████████▎| 247/266 [02:09<00:08,  2.37it/s]predicting train subjects:  93%|█████████▎| 248/266 [02:09<00:07,  2.27it/s]predicting train subjects:  94%|█████████▎| 249/266 [02:10<00:07,  2.23it/s]predicting train subjects:  94%|█████████▍| 250/266 [02:10<00:07,  2.11it/s]predicting train subjects:  94%|█████████▍| 251/266 [02:11<00:07,  2.05it/s]predicting train subjects:  95%|█████████▍| 252/266 [02:11<00:07,  1.95it/s]predicting train subjects:  95%|█████████▌| 253/266 [02:12<00:06,  1.87it/s]predicting train subjects:  95%|█████████▌| 254/266 [02:13<00:06,  1.83it/s]predicting train subjects:  96%|█████████▌| 255/266 [02:13<00:06,  1.80it/s]predicting train subjects:  96%|█████████▌| 256/266 [02:14<00:05,  1.92it/s]predicting train subjects:  97%|█████████▋| 257/266 [02:14<00:04,  1.86it/s]predicting train subjects:  97%|█████████▋| 258/266 [02:15<00:04,  1.92it/s]predicting train subjects:  97%|█████████▋| 259/266 [02:15<00:03,  1.93it/s]predicting train subjects:  98%|█████████▊| 260/266 [02:16<00:03,  1.88it/s]predicting train subjects:  98%|█████████▊| 261/266 [02:16<00:02,  1.82it/s]predicting train subjects:  98%|█████████▊| 262/266 [02:17<00:02,  1.88it/s]predicting train subjects:  99%|█████████▉| 263/266 [02:17<00:01,  1.72it/s]predicting train subjects:  99%|█████████▉| 264/266 [02:18<00:01,  1.71it/s]predicting train subjects: 100%|█████████▉| 265/266 [02:19<00:00,  1.75it/s]predicting train subjects: 100%|██████████| 266/266 [02:19<00:00,  1.78it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 40.04it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 5/266 [00:00<00:05, 44.57it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:06, 40.91it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:05, 42.90it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:06, 39.14it/s]saving BB  train1-THALAMUS:   8%|▊         | 22/266 [00:00<00:06, 37.60it/s]saving BB  train1-THALAMUS:  10%|▉         | 26/266 [00:00<00:07, 33.93it/s]saving BB  train1-THALAMUS:  11%|█▏        | 30/266 [00:00<00:06, 34.56it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:06, 37.41it/s]saving BB  train1-THALAMUS:  15%|█▍        | 39/266 [00:01<00:06, 37.70it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:01<00:06, 37.00it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:01<00:05, 42.96it/s]saving BB  train1-THALAMUS:  21%|██▏       | 57/266 [00:01<00:04, 45.28it/s]saving BB  train1-THALAMUS:  24%|██▎       | 63/266 [00:01<00:04, 48.82it/s]saving BB  train1-THALAMUS:  26%|██▋       | 70/266 [00:01<00:03, 50.94it/s]saving BB  train1-THALAMUS:  29%|██▊       | 76/266 [00:01<00:03, 49.64it/s]saving BB  train1-THALAMUS:  31%|███       | 82/266 [00:01<00:04, 45.94it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:03, 46.98it/s]saving BB  train1-THALAMUS:  35%|███▍      | 92/266 [00:02<00:03, 45.05it/s]saving BB  train1-THALAMUS:  36%|███▋      | 97/266 [00:02<00:04, 41.12it/s]saving BB  train1-THALAMUS:  38%|███▊      | 102/266 [00:02<00:04, 39.68it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:02<00:04, 38.41it/s]saving BB  train1-THALAMUS:  42%|████▏     | 111/266 [00:02<00:04, 34.46it/s]saving BB  train1-THALAMUS:  43%|████▎     | 115/266 [00:02<00:04, 32.91it/s]saving BB  train1-THALAMUS:  45%|████▍     | 119/266 [00:02<00:04, 33.67it/s]saving BB  train1-THALAMUS:  46%|████▌     | 123/266 [00:03<00:04, 32.74it/s]saving BB  train1-THALAMUS:  48%|████▊     | 127/266 [00:03<00:04, 32.84it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:03<00:03, 35.51it/s]saving BB  train1-THALAMUS:  51%|█████     | 136/266 [00:03<00:03, 33.68it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:03<00:03, 36.58it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 147/266 [00:03<00:02, 40.71it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 154/266 [00:03<00:02, 45.87it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:03<00:02, 50.79it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 167/266 [00:03<00:01, 52.63it/s]saving BB  train1-THALAMUS:  65%|██████▌   | 174/266 [00:04<00:01, 55.86it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 180/266 [00:04<00:01, 56.55it/s]saving BB  train1-THALAMUS:  71%|███████   | 188/266 [00:04<00:01, 60.96it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 195/266 [00:04<00:01, 61.79it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:04<00:01, 60.19it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:04<00:00, 63.74it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:04<00:00, 67.36it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 225/266 [00:04<00:00, 67.99it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 232/266 [00:04<00:00, 67.86it/s]saving BB  train1-THALAMUS:  90%|████████▉ | 239/266 [00:05<00:00, 64.52it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 246/266 [00:05<00:00, 63.14it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 253/266 [00:05<00:00, 60.43it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:05<00:00, 57.68it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:05<00:00, 51.97it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<10:05,  2.28s/it]Loading train:   1%|          | 2/266 [00:04<10:18,  2.34s/it]Loading train:   1%|          | 3/266 [00:06<10:02,  2.29s/it]Loading train:   2%|▏         | 4/266 [00:08<09:24,  2.15s/it]Loading train:   2%|▏         | 5/266 [00:11<09:33,  2.20s/it]Loading train:   2%|▏         | 6/266 [00:12<09:05,  2.10s/it]Loading train:   3%|▎         | 7/266 [00:15<09:25,  2.18s/it]Loading train:   3%|▎         | 8/266 [00:17<09:02,  2.10s/it]Loading train:   3%|▎         | 9/266 [00:18<08:32,  1.99s/it]Loading train:   4%|▍         | 10/266 [00:20<08:19,  1.95s/it]Loading train:   4%|▍         | 11/266 [00:22<08:14,  1.94s/it]Loading train:   5%|▍         | 12/266 [00:25<08:50,  2.09s/it]Loading train:   5%|▍         | 13/266 [00:27<08:29,  2.01s/it]Loading train:   5%|▌         | 14/266 [00:28<08:02,  1.92s/it]Loading train:   6%|▌         | 15/266 [00:30<08:18,  1.98s/it]Loading train:   6%|▌         | 16/266 [00:33<08:42,  2.09s/it]Loading train:   6%|▋         | 17/266 [00:34<07:46,  1.87s/it]Loading train:   7%|▋         | 18/266 [00:36<07:51,  1.90s/it]Loading train:   7%|▋         | 19/266 [00:38<07:26,  1.81s/it]Loading train:   8%|▊         | 20/266 [00:40<07:40,  1.87s/it]Loading train:   8%|▊         | 21/266 [00:41<07:17,  1.79s/it]Loading train:   8%|▊         | 22/266 [00:43<07:49,  1.92s/it]Loading train:   9%|▊         | 23/266 [00:45<07:34,  1.87s/it]Loading train:   9%|▉         | 24/266 [00:47<07:34,  1.88s/it]Loading train:   9%|▉         | 25/266 [00:49<07:46,  1.94s/it]Loading train:  10%|▉         | 26/266 [00:51<07:20,  1.84s/it]Loading train:  10%|█         | 27/266 [00:52<06:53,  1.73s/it]Loading train:  11%|█         | 28/266 [00:54<06:35,  1.66s/it]Loading train:  11%|█         | 29/266 [00:56<06:50,  1.73s/it]Loading train:  11%|█▏        | 30/266 [00:57<06:50,  1.74s/it]Loading train:  12%|█▏        | 31/266 [00:59<06:54,  1.76s/it]Loading train:  12%|█▏        | 32/266 [01:01<06:28,  1.66s/it]Loading train:  12%|█▏        | 33/266 [01:03<06:46,  1.75s/it]Loading train:  13%|█▎        | 34/266 [01:04<06:51,  1.77s/it]Loading train:  13%|█▎        | 35/266 [01:06<06:41,  1.74s/it]Loading train:  14%|█▎        | 36/266 [01:08<06:46,  1.77s/it]Loading train:  14%|█▍        | 37/266 [01:10<06:48,  1.79s/it]Loading train:  14%|█▍        | 38/266 [01:12<06:45,  1.78s/it]Loading train:  15%|█▍        | 39/266 [01:13<06:31,  1.72s/it]Loading train:  15%|█▌        | 40/266 [01:14<06:06,  1.62s/it]Loading train:  15%|█▌        | 41/266 [01:16<05:54,  1.58s/it]Loading train:  16%|█▌        | 42/266 [01:18<06:12,  1.66s/it]Loading train:  16%|█▌        | 43/266 [01:19<05:42,  1.54s/it]Loading train:  17%|█▋        | 44/266 [01:20<05:30,  1.49s/it]Loading train:  17%|█▋        | 45/266 [01:22<05:15,  1.43s/it]Loading train:  17%|█▋        | 46/266 [01:23<05:28,  1.49s/it]Loading train:  18%|█▊        | 47/266 [01:25<05:36,  1.54s/it]Loading train:  18%|█▊        | 48/266 [01:27<05:44,  1.58s/it]Loading train:  18%|█▊        | 49/266 [01:28<05:25,  1.50s/it]Loading train:  19%|█▉        | 50/266 [01:30<05:27,  1.52s/it]Loading train:  19%|█▉        | 51/266 [01:31<05:06,  1.42s/it]Loading train:  20%|█▉        | 52/266 [01:32<05:03,  1.42s/it]Loading train:  20%|█▉        | 53/266 [01:34<05:20,  1.51s/it]Loading train:  20%|██        | 54/266 [01:36<05:36,  1.59s/it]Loading train:  21%|██        | 55/266 [01:37<05:40,  1.61s/it]Loading train:  21%|██        | 56/266 [01:39<05:52,  1.68s/it]Loading train:  21%|██▏       | 57/266 [01:41<06:02,  1.73s/it]Loading train:  22%|██▏       | 58/266 [01:43<05:45,  1.66s/it]Loading train:  22%|██▏       | 59/266 [01:44<05:41,  1.65s/it]Loading train:  23%|██▎       | 60/266 [01:46<05:31,  1.61s/it]Loading train:  23%|██▎       | 61/266 [01:47<05:33,  1.63s/it]Loading train:  23%|██▎       | 62/266 [01:49<05:36,  1.65s/it]Loading train:  24%|██▎       | 63/266 [01:50<05:18,  1.57s/it]Loading train:  24%|██▍       | 64/266 [01:52<05:16,  1.57s/it]Loading train:  24%|██▍       | 65/266 [01:54<05:15,  1.57s/it]Loading train:  25%|██▍       | 66/266 [01:55<05:22,  1.61s/it]Loading train:  25%|██▌       | 67/266 [01:57<05:24,  1.63s/it]Loading train:  26%|██▌       | 68/266 [01:58<05:09,  1.56s/it]Loading train:  26%|██▌       | 69/266 [02:00<05:25,  1.65s/it]Loading train:  26%|██▋       | 70/266 [02:02<05:19,  1.63s/it]Loading train:  27%|██▋       | 71/266 [02:04<05:27,  1.68s/it]Loading train:  27%|██▋       | 72/266 [02:05<05:31,  1.71s/it]Loading train:  27%|██▋       | 73/266 [02:07<05:12,  1.62s/it]Loading train:  28%|██▊       | 74/266 [02:08<05:12,  1.63s/it]Loading train:  28%|██▊       | 75/266 [02:10<04:58,  1.56s/it]Loading train:  29%|██▊       | 76/266 [02:12<05:14,  1.65s/it]Loading train:  29%|██▉       | 77/266 [02:13<04:57,  1.57s/it]Loading train:  29%|██▉       | 78/266 [02:15<05:24,  1.72s/it]Loading train:  30%|██▉       | 79/266 [02:17<05:33,  1.78s/it]Loading train:  30%|███       | 80/266 [02:19<05:56,  1.92s/it]Loading train:  30%|███       | 81/266 [02:21<05:40,  1.84s/it]Loading train:  31%|███       | 82/266 [02:23<05:33,  1.81s/it]Loading train:  31%|███       | 83/266 [02:25<05:37,  1.85s/it]Loading train:  32%|███▏      | 84/266 [02:26<05:33,  1.83s/it]Loading train:  32%|███▏      | 85/266 [02:28<05:42,  1.89s/it]Loading train:  32%|███▏      | 86/266 [02:30<05:15,  1.75s/it]Loading train:  33%|███▎      | 87/266 [02:32<05:26,  1.82s/it]Loading train:  33%|███▎      | 88/266 [02:34<05:54,  1.99s/it]Loading train:  33%|███▎      | 89/266 [02:37<06:24,  2.17s/it]Loading train:  34%|███▍      | 90/266 [02:39<06:27,  2.20s/it]Loading train:  34%|███▍      | 91/266 [02:41<06:31,  2.24s/it]Loading train:  35%|███▍      | 92/266 [02:43<06:01,  2.08s/it]Loading train:  35%|███▍      | 93/266 [02:45<05:48,  2.01s/it]Loading train:  35%|███▌      | 94/266 [02:47<05:30,  1.92s/it]Loading train:  36%|███▌      | 95/266 [02:49<05:33,  1.95s/it]Loading train:  36%|███▌      | 96/266 [02:51<05:34,  1.97s/it]Loading train:  36%|███▋      | 97/266 [02:53<06:04,  2.16s/it]Loading train:  37%|███▋      | 98/266 [02:56<06:14,  2.23s/it]Loading train:  37%|███▋      | 99/266 [02:58<06:07,  2.20s/it]Loading train:  38%|███▊      | 100/266 [03:00<06:10,  2.23s/it]Loading train:  38%|███▊      | 101/266 [03:02<06:01,  2.19s/it]Loading train:  38%|███▊      | 102/266 [03:04<05:53,  2.16s/it]Loading train:  39%|███▊      | 103/266 [03:06<05:18,  1.96s/it]Loading train:  39%|███▉      | 104/266 [03:07<04:54,  1.82s/it]Loading train:  39%|███▉      | 105/266 [03:09<04:52,  1.82s/it]Loading train:  40%|███▉      | 106/266 [03:11<04:36,  1.73s/it]Loading train:  40%|████      | 107/266 [03:12<04:37,  1.74s/it]Loading train:  41%|████      | 108/266 [03:14<04:21,  1.65s/it]Loading train:  41%|████      | 109/266 [03:16<04:38,  1.77s/it]Loading train:  41%|████▏     | 110/266 [03:18<04:47,  1.85s/it]Loading train:  42%|████▏     | 111/266 [03:20<04:36,  1.78s/it]Loading train:  42%|████▏     | 112/266 [03:21<04:32,  1.77s/it]Loading train:  42%|████▏     | 113/266 [03:23<04:31,  1.78s/it]Loading train:  43%|████▎     | 114/266 [03:25<04:25,  1.75s/it]Loading train:  43%|████▎     | 115/266 [03:26<04:16,  1.70s/it]Loading train:  44%|████▎     | 116/266 [03:28<04:20,  1.74s/it]Loading train:  44%|████▍     | 117/266 [03:30<04:24,  1.78s/it]Loading train:  44%|████▍     | 118/266 [03:32<04:28,  1.82s/it]Loading train:  45%|████▍     | 119/266 [03:34<04:37,  1.89s/it]Loading train:  45%|████▌     | 120/266 [03:36<04:20,  1.78s/it]Loading train:  45%|████▌     | 121/266 [03:37<04:20,  1.80s/it]Loading train:  46%|████▌     | 122/266 [03:39<04:05,  1.71s/it]Loading train:  46%|████▌     | 123/266 [03:41<04:20,  1.82s/it]Loading train:  47%|████▋     | 124/266 [03:44<04:47,  2.03s/it]Loading train:  47%|████▋     | 125/266 [03:46<04:46,  2.04s/it]Loading train:  47%|████▋     | 126/266 [03:47<04:32,  1.95s/it]Loading train:  48%|████▊     | 127/266 [03:49<04:30,  1.94s/it]Loading train:  48%|████▊     | 128/266 [03:51<04:13,  1.83s/it]Loading train:  48%|████▊     | 129/266 [03:53<04:12,  1.84s/it]Loading train:  49%|████▉     | 130/266 [03:55<04:36,  2.03s/it]Loading train:  49%|████▉     | 131/266 [03:57<04:44,  2.11s/it]Loading train:  50%|████▉     | 132/266 [03:59<04:27,  2.00s/it]Loading train:  50%|█████     | 133/266 [04:02<04:37,  2.09s/it]Loading train:  50%|█████     | 134/266 [04:03<04:14,  1.93s/it]Loading train:  51%|█████     | 135/266 [04:05<03:58,  1.82s/it]Loading train:  51%|█████     | 136/266 [04:06<03:49,  1.77s/it]Loading train:  52%|█████▏    | 137/266 [04:08<03:49,  1.78s/it]Loading train:  52%|█████▏    | 138/266 [04:10<03:35,  1.68s/it]Loading train:  52%|█████▏    | 139/266 [04:12<03:51,  1.82s/it]Loading train:  53%|█████▎    | 140/266 [04:13<03:45,  1.79s/it]Loading train:  53%|█████▎    | 141/266 [04:15<03:37,  1.74s/it]Loading train:  53%|█████▎    | 142/266 [04:17<03:37,  1.75s/it]Loading train:  54%|█████▍    | 143/266 [04:18<03:32,  1.73s/it]Loading train:  54%|█████▍    | 144/266 [04:20<03:27,  1.70s/it]Loading train:  55%|█████▍    | 145/266 [04:22<03:28,  1.72s/it]Loading train:  55%|█████▍    | 146/266 [04:24<03:26,  1.72s/it]Loading train:  55%|█████▌    | 147/266 [04:25<03:17,  1.66s/it]Loading train:  56%|█████▌    | 148/266 [04:27<03:17,  1.68s/it]Loading train:  56%|█████▌    | 149/266 [04:28<03:09,  1.62s/it]Loading train:  56%|█████▋    | 150/266 [04:30<03:12,  1.66s/it]Loading train:  57%|█████▋    | 151/266 [04:32<03:17,  1.72s/it]Loading train:  57%|█████▋    | 152/266 [04:34<03:11,  1.68s/it]Loading train:  58%|█████▊    | 153/266 [04:35<03:09,  1.68s/it]Loading train:  58%|█████▊    | 154/266 [04:37<03:00,  1.61s/it]Loading train:  58%|█████▊    | 155/266 [04:38<03:05,  1.67s/it]Loading train:  59%|█████▊    | 156/266 [04:41<03:38,  1.98s/it]Loading train:  59%|█████▉    | 157/266 [04:43<03:39,  2.01s/it]Loading train:  59%|█████▉    | 158/266 [04:45<03:38,  2.02s/it]Loading train:  60%|█████▉    | 159/266 [04:47<03:41,  2.07s/it]Loading train:  60%|██████    | 160/266 [04:50<03:41,  2.09s/it]Loading train:  61%|██████    | 161/266 [04:52<03:43,  2.13s/it]Loading train:  61%|██████    | 162/266 [04:54<03:32,  2.05s/it]Loading train:  61%|██████▏   | 163/266 [04:55<03:14,  1.89s/it]Loading train:  62%|██████▏   | 164/266 [04:56<02:53,  1.70s/it]Loading train:  62%|██████▏   | 165/266 [04:58<02:40,  1.59s/it]Loading train:  62%|██████▏   | 166/266 [04:59<02:40,  1.60s/it]Loading train:  63%|██████▎   | 167/266 [05:00<02:22,  1.44s/it]Loading train:  63%|██████▎   | 168/266 [05:02<02:11,  1.34s/it]Loading train:  64%|██████▎   | 169/266 [05:03<02:01,  1.26s/it]Loading train:  64%|██████▍   | 170/266 [05:04<02:02,  1.27s/it]Loading train:  64%|██████▍   | 171/266 [05:05<01:50,  1.17s/it]Loading train:  65%|██████▍   | 172/266 [05:06<01:47,  1.14s/it]Loading train:  65%|██████▌   | 173/266 [05:07<01:46,  1.15s/it]Loading train:  65%|██████▌   | 174/266 [05:08<01:47,  1.17s/it]Loading train:  66%|██████▌   | 175/266 [05:09<01:42,  1.12s/it]Loading train:  66%|██████▌   | 176/266 [05:11<01:42,  1.14s/it]Loading train:  67%|██████▋   | 177/266 [05:12<01:41,  1.14s/it]Loading train:  67%|██████▋   | 178/266 [05:13<01:37,  1.11s/it]Loading train:  67%|██████▋   | 179/266 [05:14<01:38,  1.13s/it]Loading train:  68%|██████▊   | 180/266 [05:15<01:37,  1.13s/it]Loading train:  68%|██████▊   | 181/266 [05:16<01:38,  1.16s/it]Loading train:  68%|██████▊   | 182/266 [05:18<01:40,  1.20s/it]Loading train:  69%|██████▉   | 183/266 [05:19<01:33,  1.13s/it]Loading train:  69%|██████▉   | 184/266 [05:20<01:33,  1.14s/it]Loading train:  70%|██████▉   | 185/266 [05:21<01:28,  1.10s/it]Loading train:  70%|██████▉   | 186/266 [05:22<01:27,  1.10s/it]Loading train:  70%|███████   | 187/266 [05:23<01:26,  1.09s/it]Loading train:  71%|███████   | 188/266 [05:24<01:26,  1.11s/it]Loading train:  71%|███████   | 189/266 [05:25<01:24,  1.10s/it]Loading train:  71%|███████▏  | 190/266 [05:26<01:29,  1.18s/it]Loading train:  72%|███████▏  | 191/266 [05:28<01:38,  1.31s/it]Loading train:  72%|███████▏  | 192/266 [05:29<01:36,  1.30s/it]Loading train:  73%|███████▎  | 193/266 [05:31<01:35,  1.31s/it]Loading train:  73%|███████▎  | 194/266 [05:32<01:39,  1.38s/it]Loading train:  73%|███████▎  | 195/266 [05:34<01:36,  1.36s/it]Loading train:  74%|███████▎  | 196/266 [05:35<01:27,  1.26s/it]Loading train:  74%|███████▍  | 197/266 [05:36<01:22,  1.19s/it]Loading train:  74%|███████▍  | 198/266 [05:37<01:15,  1.12s/it]Loading train:  75%|███████▍  | 199/266 [05:38<01:12,  1.07s/it]Loading train:  75%|███████▌  | 200/266 [05:38<01:08,  1.03s/it]Loading train:  76%|███████▌  | 201/266 [05:40<01:11,  1.10s/it]Loading train:  76%|███████▌  | 202/266 [05:41<01:12,  1.13s/it]Loading train:  76%|███████▋  | 203/266 [05:42<01:11,  1.14s/it]Loading train:  77%|███████▋  | 204/266 [05:43<01:08,  1.11s/it]Loading train:  77%|███████▋  | 205/266 [05:44<01:04,  1.06s/it]Loading train:  77%|███████▋  | 206/266 [05:45<01:04,  1.07s/it]Loading train:  78%|███████▊  | 207/266 [05:46<01:06,  1.12s/it]Loading train:  78%|███████▊  | 208/266 [05:47<01:04,  1.12s/it]Loading train:  79%|███████▊  | 209/266 [05:49<01:04,  1.14s/it]Loading train:  79%|███████▉  | 210/266 [05:50<01:06,  1.18s/it]Loading train:  79%|███████▉  | 211/266 [05:51<01:03,  1.15s/it]Loading train:  80%|███████▉  | 212/266 [05:52<01:05,  1.21s/it]Loading train:  80%|████████  | 213/266 [05:54<01:04,  1.21s/it]Loading train:  80%|████████  | 214/266 [05:55<00:59,  1.14s/it]Loading train:  81%|████████  | 215/266 [05:56<00:59,  1.18s/it]Loading train:  81%|████████  | 216/266 [05:57<00:58,  1.18s/it]Loading train:  82%|████████▏ | 217/266 [05:58<00:57,  1.18s/it]Loading train:  82%|████████▏ | 218/266 [05:59<00:57,  1.20s/it]Loading train:  82%|████████▏ | 219/266 [06:01<00:57,  1.23s/it]Loading train:  83%|████████▎ | 220/266 [06:02<00:55,  1.20s/it]Loading train:  83%|████████▎ | 221/266 [06:03<00:52,  1.16s/it]Loading train:  83%|████████▎ | 222/266 [06:04<00:52,  1.20s/it]Loading train:  84%|████████▍ | 223/266 [06:05<00:50,  1.16s/it]Loading train:  84%|████████▍ | 224/266 [06:06<00:46,  1.12s/it]Loading train:  85%|████████▍ | 225/266 [06:07<00:44,  1.08s/it]Loading train:  85%|████████▍ | 226/266 [06:08<00:41,  1.03s/it]Loading train:  85%|████████▌ | 227/266 [06:09<00:38,  1.02it/s]Loading train:  86%|████████▌ | 228/266 [06:10<00:40,  1.07s/it]Loading train:  86%|████████▌ | 229/266 [06:11<00:37,  1.01s/it]Loading train:  86%|████████▋ | 230/266 [06:12<00:38,  1.06s/it]Loading train:  87%|████████▋ | 231/266 [06:14<00:39,  1.12s/it]Loading train:  87%|████████▋ | 232/266 [06:15<00:38,  1.14s/it]Loading train:  88%|████████▊ | 233/266 [06:16<00:37,  1.14s/it]Loading train:  88%|████████▊ | 234/266 [06:17<00:35,  1.12s/it]Loading train:  88%|████████▊ | 235/266 [06:18<00:34,  1.12s/it]Loading train:  89%|████████▊ | 236/266 [06:20<00:35,  1.18s/it]Loading train:  89%|████████▉ | 237/266 [06:21<00:33,  1.17s/it]Loading train:  89%|████████▉ | 238/266 [06:22<00:32,  1.17s/it]Loading train:  90%|████████▉ | 239/266 [06:23<00:31,  1.17s/it]Loading train:  90%|█████████ | 240/266 [06:24<00:29,  1.12s/it]Loading train:  91%|█████████ | 241/266 [06:25<00:26,  1.04s/it]Loading train:  91%|█████████ | 242/266 [06:26<00:24,  1.03s/it]Loading train:  91%|█████████▏| 243/266 [06:27<00:22,  1.01it/s]Loading train:  92%|█████████▏| 244/266 [06:28<00:21,  1.03it/s]Loading train:  92%|█████████▏| 245/266 [06:29<00:21,  1.04s/it]Loading train:  92%|█████████▏| 246/266 [06:30<00:23,  1.17s/it]Loading train:  93%|█████████▎| 247/266 [06:31<00:21,  1.13s/it]Loading train:  93%|█████████▎| 248/266 [06:32<00:18,  1.05s/it]Loading train:  94%|█████████▎| 249/266 [06:34<00:19,  1.13s/it]Loading train:  94%|█████████▍| 250/266 [06:35<00:17,  1.10s/it]Loading train:  94%|█████████▍| 251/266 [06:36<00:17,  1.19s/it]Loading train:  95%|█████████▍| 252/266 [06:37<00:17,  1.24s/it]Loading train:  95%|█████████▌| 253/266 [06:39<00:16,  1.25s/it]Loading train:  95%|█████████▌| 254/266 [06:40<00:15,  1.27s/it]Loading train:  96%|█████████▌| 255/266 [06:41<00:13,  1.26s/it]Loading train:  96%|█████████▌| 256/266 [06:43<00:13,  1.33s/it]Loading train:  97%|█████████▋| 257/266 [06:44<00:11,  1.23s/it]Loading train:  97%|█████████▋| 258/266 [06:45<00:09,  1.23s/it]Loading train:  97%|█████████▋| 259/266 [06:46<00:08,  1.24s/it]Loading train:  98%|█████████▊| 260/266 [06:47<00:07,  1.18s/it]Loading train:  98%|█████████▊| 261/266 [06:49<00:06,  1.22s/it]Loading train:  98%|█████████▊| 262/266 [06:50<00:04,  1.22s/it]Loading train:  99%|█████████▉| 263/266 [06:51<00:03,  1.29s/it]Loading train:  99%|█████████▉| 264/266 [06:53<00:02,  1.35s/it]Loading train: 100%|█████████▉| 265/266 [06:54<00:01,  1.27s/it]Loading train: 100%|██████████| 266/266 [06:55<00:00,  1.20s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/266 [00:00<00:13, 19.97it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:11, 23.01it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:08, 28.39it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:07, 33.95it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:05, 43.07it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:04, 51.62it/s]concatenating: train:  22%|██▏       | 59/266 [00:00<00:03, 65.18it/s]concatenating: train:  34%|███▍      | 91/266 [00:00<00:02, 85.64it/s]concatenating: train:  44%|████▎     | 116/266 [00:00<00:01, 106.52it/s]concatenating: train:  55%|█████▍    | 145/266 [00:01<00:00, 130.04it/s]concatenating: train:  65%|██████▍   | 172/266 [00:01<00:00, 153.89it/s]concatenating: train:  75%|███████▍  | 199/266 [00:01<00:00, 175.74it/s]concatenating: train:  85%|████████▌ | 227/266 [00:01<00:00, 196.70it/s]concatenating: train:  97%|█████████▋| 258/266 [00:01<00:00, 219.83it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 178.56it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.42s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.35s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.34s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.45s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 112.22it/s]2019-07-28 17:10:30.213831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 17:10:30.213919: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 17:10:30.213935: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 17:10:30.213944: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 17:10:30.214358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.05it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.86it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.71it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.06it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.53it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.31it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.61it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.30it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.83it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.69it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.21it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.32it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.48it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.63it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.32it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.56it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.80it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.00it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.63it/s]
Epoch 00045: val_mDice did not improve from 0.89340
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [0.06235682996309767, 0.06023406737832108, 0.059244790180313464, 0.06212929862015175, 0.05823202816901183, 0.06234716087805502, 0.060665891007191004, 0.06291921574133214, 0.061512716265037806, 0.060327166277501315, 0.061481663110581314, 0.06253331449974064, 0.06324136321141262, 0.06355370703444939, 0.062069695800392316, 0.06167808739524899, 0.06002348898486658, 0.06407656308000136, 0.06302076640228431, 0.06259786777875641, 0.061974929212921796, 0.06452457996254618, 0.06232084623641438, 0.06371321801961673, 0.06391116098096275, 0.06201856383922124, 0.06156909343494912, 0.06217917209171286, 0.06180558487246133, 0.06265322862174173, 0.06338533548393635, 0.062317699062252284, 0.061880344355648216, 0.06360079489196792, 0.0606631153084413, 0.06139294948014948, 0.06150063565659403, 0.06272737044050838, 0.06546943260337969, 0.06530748731033369, 0.06287756082460735, 0.06433554618346571, 0.0632510119955046, 0.06230686437526737, 0.06644765244364137], 'val_acc': [0.9946049153804779, 0.9946938313619055, 0.9946682877612837, 0.9947264492511749, 0.9952189946415448, 0.9948467383481036, 0.9945141558695321, 0.9946301495186006, 0.9948356648286184, 0.9945750847609356, 0.994746747342023, 0.99474398325188, 0.994747359644283, 0.9944670880683745, 0.9947738280199995, 0.9948021158425495, 0.994831051790353, 0.9947968950175275, 0.9948006013427118, 0.9948630486473893, 0.9946335334368427, 0.9946347511175907, 0.9947221294195965, 0.9946790768040551, 0.9945701423919562, 0.9947396730533754, 0.9947710579091852, 0.9941591247163638, 0.9945409337077478, 0.9948513613204764, 0.994467093185945, 0.994690763528901, 0.9947510617549973, 0.9942212670740455, 0.9945830756967718, 0.9947538285544424, 0.994488630932991, 0.9946039833805778, 0.9947756700443499, 0.9947427514225545, 0.9946132353459946, 0.9945719946514476, 0.9944341646300422, 0.9947584391844393, 0.9946039984322558], 'val_mDice': [0.8856791510726466, 0.8896963530116611, 0.8914820371252118, 0.8869158411868895, 0.893402367529243, 0.8862024515566199, 0.8888940001376952, 0.8851838999926441, 0.8879040512773726, 0.8895580907060643, 0.8879090333827818, 0.8860283430778619, 0.8851063537477243, 0.8846047385172411, 0.8869203566902816, 0.887575937340958, 0.8902801780989675, 0.8835496974713875, 0.8854271290880261, 0.8860139557809541, 0.8871736014732207, 0.8831047409712666, 0.8866767215006279, 0.8844202437786141, 0.8838869417556608, 0.887094031680714, 0.8877242129258435, 0.8868358099099362, 0.8875326309541259, 0.8860886596670055, 0.8846852150228288, 0.8866174901374663, 0.8872999359260906, 0.8845150446650958, 0.8893557573207701, 0.8881539335154524, 0.8878429107593767, 0.8858125631255332, 0.8812708987130059, 0.8815691573451264, 0.8856132948639417, 0.8832523572926569, 0.8852020309428976, 0.8866185223815417, 0.8797002269162072], 'loss': [0.1471405874772852, 0.054183427411209, 0.04854451034590908, 0.04525061951176902, 0.042558554471562426, 0.04041097231490668, 0.03938678389013625, 0.037900284471639664, 0.03703510484849158, 0.03607232482285857, 0.03534847020868103, 0.034641482441920994, 0.034010929194110535, 0.0333212486692509, 0.03300295836056706, 0.03229534091605555, 0.03197415020991297, 0.031629745830141276, 0.03126893619193684, 0.03087815834557999, 0.030665428417653573, 0.030265461888739176, 0.03011077756873642, 0.029692686069280886, 0.0297636751323916, 0.029513589621461268, 0.029013741134041995, 0.028943619271113045, 0.028701458831378986, 0.028484956900473597, 0.028308824947680947, 0.028292616148895146, 0.02809537853183756, 0.02786026386534192, 0.027875536238862443, 0.027712455832510873, 0.02752926390020831, 0.027362169793984637, 0.027333578888296135, 0.02704688584481988, 0.027069432995903295, 0.026937723139491086, 0.02691091815962832, 0.026717181440932505, 0.026542519442275217], 'acc': [0.9726779828295385, 0.9941467367431829, 0.994652192600799, 0.9949655904538013, 0.995195116847088, 0.995383465271328, 0.9954820124053553, 0.9956160813882028, 0.9956991089375562, 0.995772700454234, 0.995826650548391, 0.995894652999269, 0.9959585021030023, 0.996020786729099, 0.9960504105442329, 0.9961155958338711, 0.9961340882521152, 0.9961792214462755, 0.9962105543943031, 0.996234458220854, 0.9962632080773199, 0.9962930687350356, 0.9963056246077563, 0.9963443422511736, 0.9963534434483093, 0.9963788572549351, 0.9964168783032754, 0.9964262590546502, 0.9964411993112263, 0.9964516997107331, 0.9964816536611013, 0.9964784206325024, 0.9964933989068194, 0.9965156516355134, 0.9965133271374265, 0.9965319464085471, 0.996542654185875, 0.9965602289179145, 0.996557024416997, 0.9965795423988191, 0.9965899124974227, 0.9965967387147334, 0.9966088097616932, 0.996625381514127, 0.9966474704988287], 'mDice': [0.8157912150771305, 0.9003367733630813, 0.9101137249365912, 0.9159218860293574, 0.9207145139885412, 0.9245605066742899, 0.9263928421066646, 0.9290732429351021, 0.9306299366632211, 0.9323775370830542, 0.9336926843097161, 0.9349787935300984, 0.9361257629685537, 0.9373788839709181, 0.9379561428672423, 0.9392553540668452, 0.9398438530144262, 0.9404708536895315, 0.9411334107448363, 0.9418576841961427, 0.9422428120638041, 0.942980443583248, 0.9432625316234375, 0.9440371858799756, 0.9439001453073179, 0.9443565212709538, 0.9452814828839662, 0.9454115197521981, 0.9458584079797975, 0.9462616501307016, 0.9465812933863681, 0.9466149055630242, 0.9469761090820938, 0.9474127618246883, 0.9473871972888264, 0.9476851841220733, 0.9480280723671278, 0.9483343246099236, 0.9483937502384407, 0.9489218798779928, 0.9488766526074409, 0.9491199229794964, 0.9491667965538918, 0.9495292923630815, 0.9498516692649079]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 48, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 48, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 48, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 48, 52, 30)   3000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 48, 52, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 48, 52, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 48, 52, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 48, 52, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 48, 52, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 24, 26, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 24, 26, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 24, 26, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 24, 26, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 24, 26, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 24, 26, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 24, 26, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 12, 13, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 12, 13, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 12, 13, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 12, 13, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 12, 13, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 12, 13, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 12, 13, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 13, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 24, 26, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 26, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 24, 26, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 24, 26, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 26, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 24, 26, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 26, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 48, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 48, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 48, 52, 30)   8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 48, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 48, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 48, 52, 90)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 48, 52, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 48, 52, 10)   8110        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 48, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 48, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 48, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 48, 52, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 48, 52, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 48, 52, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 48, 52, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 48, 52, 100)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 48, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 514,363
Trainable params: 122,063
Non-trainable params: 392,300
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34775605e-02 3.29004816e-02 7.69209268e-02 9.55781195e-03
 2.76624842e-02 7.23710924e-03 8.42781076e-02 1.14330294e-01
 8.97718474e-02 1.36394676e-02 2.91057986e-01 1.88901994e-01
 2.63928949e-04]
Train on 16768 samples, validate on 241 samples
Epoch 1/300
 - 24s - loss: 1.3272 - acc: 0.8004 - mDice: 0.3453 - val_loss: 1.3920 - val_acc: 0.9127 - val_mDice: 0.4320

Epoch 00001: val_mDice improved from -inf to 0.43199, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 16s - loss: 0.5669 - acc: 0.8947 - mDice: 0.5624 - val_loss: 0.9193 - val_acc: 0.9377 - val_mDice: 0.5506

Epoch 00002: val_mDice improved from 0.43199 to 0.55058, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 17s - loss: 0.4482 - acc: 0.9063 - mDice: 0.6302 - val_loss: 0.9806 - val_acc: 0.9427 - val_mDice: 0.5564

Epoch 00003: val_mDice improved from 0.55058 to 0.55637, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 16s - loss: 0.4352 - acc: 0.9128 - mDice: 0.6459 - val_loss: 0.8719 - val_acc: 0.9469 - val_mDice: 0.5909

Epoch 00004: val_mDice improved from 0.55637 to 0.59087, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 17s - loss: 0.3893 - acc: 0.9187 - mDice: 0.6722 - val_loss: 0.8106 - val_acc: 0.9478 - val_mDice: 0.5852

Epoch 00005: val_mDice did not improve from 0.59087
Epoch 6/300
 - 16s - loss: 0.3940 - acc: 0.9337 - mDice: 0.6698 - val_loss: 0.7611 - val_acc: 0.9487 - val_mDice: 0.5958

Epoch 00006: val_mDice improved from 0.59087 to 0.59579, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 16s - loss: 0.3719 - acc: 0.9428 - mDice: 0.6835 - val_loss: 0.7288 - val_acc: 0.9462 - val_mDice: 0.6069

Epoch 00007: val_mDice improved from 0.59579 to 0.60693, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 16s - loss: 0.3696 - acc: 0.9430 - mDice: 0.6852 - val_loss: 0.7898 - val_acc: 0.9457 - val_mDice: 0.5887

Epoch 00008: val_mDice did not improve from 0.60693
Epoch 9/300
 - 17s - loss: 0.3889 - acc: 0.9410 - mDice: 0.6715 - val_loss: 0.7295 - val_acc: 0.9481 - val_mDice: 0.6078

Epoch 00009: val_mDice improved from 0.60693 to 0.60777, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 16s - loss: 0.3410 - acc: 0.9453 - mDice: 0.7030 - val_loss: 0.8204 - val_acc: 0.9465 - val_mDice: 0.5941

Epoch 00010: val_mDice did not improve from 0.60777
Epoch 11/300
 - 16s - loss: 0.3293 - acc: 0.9460 - mDice: 0.7098 - val_loss: 0.6017 - val_acc: 0.9492 - val_mDice: 0.6194

Epoch 00011: val_mDice improved from 0.60777 to 0.61940, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 16s - loss: 0.3166 - acc: 0.9471 - mDice: 0.7188 - val_loss: 0.5848 - val_acc: 0.9491 - val_mDice: 0.6157

Epoch 00012: val_mDice did not improve from 0.61940
Epoch 13/300
 - 16s - loss: 0.3206 - acc: 0.9472 - mDice: 0.7187 - val_loss: 0.7326 - val_acc: 0.9516 - val_mDice: 0.6157

Epoch 00013: val_mDice did not improve from 0.61940
Epoch 14/300
 - 16s - loss: 0.2963 - acc: 0.9485 - mDice: 0.7317 - val_loss: 0.6228 - val_acc: 0.9510 - val_mDice: 0.6108

Epoch 00014: val_mDice did not improve from 0.61940
Epoch 15/300
 - 16s - loss: 0.2905 - acc: 0.9490 - mDice: 0.7361 - val_loss: 0.7605 - val_acc: 0.9522 - val_mDice: 0.5861

Epoch 00015: val_mDice did not improve from 0.61940
Epoch 16/300
 - 16s - loss: 0.3037 - acc: 0.9480 - mDice: 0.7275 - val_loss: 0.6047 - val_acc: 0.9512 - val_mDice: 0.6133

Epoch 00016: val_mDice did not improve from 0.61940
Epoch 17/300
 - 16s - loss: 0.2944 - acc: 0.9490 - mDice: 0.7371 - val_loss: 0.6983 - val_acc: 0.9513 - val_mDice: 0.6210

Epoch 00017: val_mDice improved from 0.61940 to 0.62101, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 16s - loss: 0.3262 - acc: 0.9473 - mDice: 0.7222 - val_loss: 0.9265 - val_acc: 0.9480 - val_mDice: 0.5803

Epoch 00018: val_mDice did not improve from 0.62101
Epoch 19/300
 - 16s - loss: 0.2970 - acc: 0.9487 - mDice: 0.7362 - val_loss: 0.9901 - val_acc: 0.9518 - val_mDice: 0.6060

Epoch 00019: val_mDice did not improve from 0.62101
Epoch 20/300
 - 16s - loss: 0.3090 - acc: 0.9476 - mDice: 0.7251 - val_loss: 0.7224 - val_acc: 0.9521 - val_mDice: 0.5954

Epoch 00020: val_mDice did not improve from 0.62101
Epoch 21/300
 - 16s - loss: 0.2845 - acc: 0.9499 - mDice: 0.7449 - val_loss: 0.7061 - val_acc: 0.9508 - val_mDice: 0.6160

Epoch 00021: val_mDice did not improve from 0.62101
Epoch 22/300
 - 17s - loss: 0.2893 - acc: 0.9496 - mDice: 0.7431 - val_loss: 0.6761 - val_acc: 0.9516 - val_mDice: 0.6086

Epoch 00022: val_mDice did not improve from 0.62101
Epoch 23/300
 - 17s - loss: 0.2951 - acc: 0.9493 - mDice: 0.7408 - val_loss: 0.7171 - val_acc: 0.9514 - val_mDice: 0.6159

Epoch 00023: val_mDice did not improve from 0.62101
Epoch 24/300
 - 16s - loss: 0.2622 - acc: 0.9509 - mDice: 0.7573 - val_loss: 0.6179 - val_acc: 0.9521 - val_mDice: 0.6157

Epoch 00024: val_mDice did not improve from 0.62101
Epoch 25/300
 - 16s - loss: 0.2671 - acc: 0.9510 - mDice: 0.7571 - val_loss: 0.7378 - val_acc: 0.9514 - val_mDice: 0.6012

Epoch 00025: val_mDice did not improve from 0.62101
Epoch 26/300
 - 16s - loss: 0.2673 - acc: 0.9507 - mDice: 0.7543 - val_loss: 0.6011 - val_acc: 0.9508 - val_mDice: 0.6097

Epoch 00026: val_mDice did not improve from 0.62101
Epoch 27/300
 - 16s - loss: 0.2561 - acc: 0.9516 - mDice: 0.7626 - val_loss: 0.6016 - val_acc: 0.9518 - val_mDice: 0.6124

Epoch 00027: val_mDice did not improve from 0.62101
Epoch 28/300
 - 17s - loss: 0.2825 - acc: 0.9496 - mDice: 0.7455 - val_loss: 0.9872 - val_acc: 0.9476 - val_mDice: 0.5929

Epoch 00028: val_mDice did not improve from 0.62101
Epoch 29/300
 - 16s - loss: 0.2574 - acc: 0.9516 - mDice: 0.7622 - val_loss: 0.5673 - val_acc: 0.9507 - val_mDice: 0.6199

Epoch 00029: val_mDice did not improve from 0.62101
Epoch 30/300
 - 16s - loss: 0.2703 - acc: 0.9513 - mDice: 0.7592 - val_loss: 0.6102 - val_acc: 0.9527 - val_mDice: 0.6054

Epoch 00030: val_mDice did not improve from 0.62101
Epoch 31/300
 - 16s - loss: 0.2693 - acc: 0.9514 - mDice: 0.7601 - val_loss: 0.6471 - val_acc: 0.9500 - val_mDice: 0.6185

Epoch 00031: val_mDice did not improve from 0.62101
Epoch 32/300
 - 16s - loss: 0.2634 - acc: 0.9516 - mDice: 0.7618 - val_loss: 0.5575 - val_acc: 0.9491 - val_mDice: 0.6143

Epoch 00032: val_mDice did not improve from 0.62101
Epoch 33/300
 - 17s - loss: 0.2555 - acc: 0.9519 - mDice: 0.7659 - val_loss: 0.7436 - val_acc: 0.9504 - val_mDice: 0.6087

Epoch 00033: val_mDice did not improve from 0.62101
Epoch 34/300
 - 16s - loss: 0.2575 - acc: 0.9512 - mDice: 0.7617 - val_loss: 0.7178 - val_acc: 0.9513 - val_mDice: 0.6118

Epoch 00034: val_mDice did not improve from 0.62101
Epoch 35/300
 - 16s - loss: 0.2423 - acc: 0.9526 - mDice: 0.7733 - val_loss: 0.6657 - val_acc: 0.9514 - val_mDice: 0.6015

Epoch 00035: val_mDice did not improve from 0.62101
Epoch 36/300
 - 16s - loss: 0.2419 - acc: 0.9526 - mDice: 0.7736 - val_loss: 0.5803 - val_acc: 0.9506 - val_mDice: 0.6197

Epoch 00036: val_mDice did not improve from 0.62101
Epoch 37/300
 - 16s - loss: 0.2357 - acc: 0.9532 - mDice: 0.7792 - val_loss: 0.7159 - val_acc: 0.9530 - val_mDice: 0.6082

Epoch 00037: val_mDice did not improve from 0.62101
Epoch 38/300
 - 16s - loss: 0.2824 - acc: 0.9496 - mDice: 0.7476 - val_loss: 0.7417 - val_acc: 0.9501 - val_mDice: 0.6113

Epoch 00038: val_mDice did not improve from 0.62101
Epoch 39/300
 - 17s - loss: 0.2640 - acc: 0.9512 - mDice: 0.7607 - val_loss: 0.7361 - val_acc: 0.9479 - val_mDice: 0.6009

Epoch 00039: val_mDice did not improve from 0.62101
Epoch 40/300
 - 16s - loss: 0.2497 - acc: 0.9525 - mDice: 0.7723 - val_loss: 0.7975 - val_acc: 0.9501 - val_mDice: 0.5974

Epoch 00040: val_mDice did not improve from 0.62101
Epoch 41/300
 - 16s - loss: 0.2560 - acc: 0.9528 - mDice: 0.7739 - val_loss: 0.7560 - val_acc: 0.9515 - val_mDice: 0.6017

Epoch 00041: val_mDice did not improve from 0.62101
Epoch 42/300
 - 16s - loss: 0.2738 - acc: 0.9501 - mDice: 0.7560 - val_loss: 0.7004 - val_acc: 0.9482 - val_mDice: 0.6066

Epoch 00042: val_mDice did not improve from 0.62101
Epoch 43/300
 - 17s - loss: 0.2805 - acc: 0.9502 - mDice: 0.7504 - val_loss: 0.6748 - val_acc: 0.9507 - val_mDice: 0.6112

Epoch 00043: val_mDice did not improve from 0.62101
Epoch 44/300
 - 16s - loss: 0.2406 - acc: 0.9527 - mDice: 0.7746 - val_loss: 0.7034 - val_acc: 0.9510 - val_mDice: 0.6149

Epoch 00044: val_mDice did not improve from 0.62101
Epoch 45/300
 - 16s - loss: 0.2344 - acc: 0.9532 - mDice: 0.7797 - val_loss: 0.5299 - val_acc: 0.9511 - val_mDice: 0.6184

Epoch 00045: val_mDice did not improve from 0.62101
Epoch 46/300
 - 16s - loss: 0.2438 - acc: 0.9530 - mDice: 0.7777 - val_loss: 0.7104 - val_acc: 0.9505 - val_mDice: 0.6059

Epoch 00046: val_mDice did not improve from 0.62101
Epoch 47/300
 - 16s - loss: 0.2366 - acc: 0.9536 - mDice: 0.7818 - val_loss: 0.7709 - val_acc: 0.9510 - val_mDice: 0.6019

Epoch 00047: val_mDice did not improve from 0.62101
Epoch 48/300
 - 17s - loss: 0.2504 - acc: 0.9529 - mDice: 0.7774 - val_loss: 0.7549 - val_acc: 0.9505 - val_mDice: 0.6078

Epoch 00048: val_mDice did not improve from 0.62101
Epoch 49/300
 - 16s - loss: 0.2359 - acc: 0.9533 - mDice: 0.7808 - val_loss: 0.7226 - val_acc: 0.9513 - val_mDice: 0.6123

Epoch 00049: val_mDice did not improve from 0.62101
Epoch 50/300
 - 16s - loss: 0.2340 - acc: 0.9537 - mDice: 0.7829 - val_loss: 0.7026 - val_acc: 0.9513 - val_mDice: 0.6094

Epoch 00050: val_mDice did not improve from 0.62101
Epoch 51/300
 - 16s - loss: 0.2321 - acc: 0.9537 - mDice: 0.7826 - val_loss: 0.7282 - val_acc: 0.9497 - val_mDice: 0.6069

Epoch 00051: val_mDice did not improve from 0.62101
Epoch 52/300
 - 17s - loss: 0.2481 - acc: 0.9526 - mDice: 0.7740 - val_loss: 0.5661 - val_acc: 0.9503 - val_mDice: 0.6070

Epoch 00052: val_mDice did not improve from 0.62101
Epoch 53/300
 - 16s - loss: 0.2404 - acc: 0.9528 - mDice: 0.7781 - val_loss: 1.4839 - val_acc: 0.9177 - val_mDice: 0.4457

Epoch 00053: val_mDice did not improve from 0.62101
Epoch 54/300
 - 16s - loss: 0.2918 - acc: 0.9498 - mDice: 0.7473 - val_loss: 0.7834 - val_acc: 0.9488 - val_mDice: 0.5979

Epoch 00054: val_mDice did not improve from 0.62101
Epoch 55/300
 - 16s - loss: 0.2460 - acc: 0.9530 - mDice: 0.7767 - val_loss: 0.7664 - val_acc: 0.9510 - val_mDice: 0.6004

Epoch 00055: val_mDice did not improve from 0.62101
Epoch 56/300
 - 17s - loss: 0.2390 - acc: 0.9530 - mDice: 0.7767 - val_loss: 0.7634 - val_acc: 0.9482 - val_mDice: 0.6030

Epoch 00056: val_mDice did not improve from 0.62101
Epoch 57/300
 - 16s - loss: 0.2502 - acc: 0.9523 - mDice: 0.7720 - val_loss: 0.7497 - val_acc: 0.9500 - val_mDice: 0.6101

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.02s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:05,  2.72s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:07<00:02,  2.51s/it]predicting test subjects: 100%|██████████| 4/4 [00:09<00:00,  2.50s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:31,  2.83s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:13,  2.78s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:27,  2.61s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:34,  2.42s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:43,  2.46s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:04,  2.56s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:21,  2.63s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:33,  2.69s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:43,  2.74s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:46,  2.76s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:40,  2.75s/it]predicting train subjects:   5%|▍         | 12/266 [00:31<11:39,  2.75s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:35,  2.75s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:30,  2.74s/it]predicting train subjects:   6%|▌         | 15/266 [00:39<11:24,  2.73s/it]predicting train subjects:   6%|▌         | 16/266 [00:42<11:27,  2.75s/it]predicting train subjects:   6%|▋         | 17/266 [00:45<11:31,  2.78s/it]predicting train subjects:   7%|▋         | 18/266 [00:48<11:29,  2.78s/it]predicting train subjects:   7%|▋         | 19/266 [00:51<11:30,  2.79s/it]predicting train subjects:   8%|▊         | 20/266 [00:53<11:25,  2.79s/it]predicting train subjects:   8%|▊         | 21/266 [00:56<11:33,  2.83s/it]predicting train subjects:   8%|▊         | 22/266 [00:59<11:30,  2.83s/it]predicting train subjects:   9%|▊         | 23/266 [01:02<11:32,  2.85s/it]predicting train subjects:   9%|▉         | 24/266 [01:05<11:08,  2.76s/it]predicting train subjects:   9%|▉         | 25/266 [01:07<10:51,  2.70s/it]predicting train subjects:  10%|▉         | 26/266 [01:10<10:57,  2.74s/it]predicting train subjects:  10%|█         | 27/266 [01:13<10:39,  2.68s/it]predicting train subjects:  11%|█         | 28/266 [01:15<10:32,  2.66s/it]predicting train subjects:  11%|█         | 29/266 [01:18<10:29,  2.66s/it]predicting train subjects:  11%|█▏        | 30/266 [01:21<10:29,  2.67s/it]predicting train subjects:  12%|█▏        | 31/266 [01:23<10:23,  2.65s/it]predicting train subjects:  12%|█▏        | 32/266 [01:26<10:14,  2.63s/it]predicting train subjects:  12%|█▏        | 33/266 [01:28<10:07,  2.61s/it]predicting train subjects:  13%|█▎        | 34/266 [01:31<10:04,  2.61s/it]predicting train subjects:  13%|█▎        | 35/266 [01:33<09:58,  2.59s/it]predicting train subjects:  14%|█▎        | 36/266 [01:36<09:55,  2.59s/it]predicting train subjects:  14%|█▍        | 37/266 [01:39<09:54,  2.60s/it]predicting train subjects:  14%|█▍        | 38/266 [01:41<09:48,  2.58s/it]predicting train subjects:  15%|█▍        | 39/266 [01:44<09:45,  2.58s/it]predicting train subjects:  15%|█▌        | 40/266 [01:46<09:44,  2.59s/it]predicting train subjects:  15%|█▌        | 41/266 [01:49<09:45,  2.60s/it]predicting train subjects:  16%|█▌        | 42/266 [01:51<09:17,  2.49s/it]predicting train subjects:  16%|█▌        | 43/266 [01:54<08:59,  2.42s/it]predicting train subjects:  17%|█▋        | 44/266 [01:56<08:39,  2.34s/it]predicting train subjects:  17%|█▋        | 45/266 [01:58<08:25,  2.29s/it]predicting train subjects:  17%|█▋        | 46/266 [02:00<08:16,  2.26s/it]predicting train subjects:  18%|█▊        | 47/266 [02:02<08:11,  2.25s/it]predicting train subjects:  18%|█▊        | 48/266 [02:04<08:05,  2.23s/it]predicting train subjects:  18%|█▊        | 49/266 [02:07<07:57,  2.20s/it]predicting train subjects:  19%|█▉        | 50/266 [02:09<07:57,  2.21s/it]predicting train subjects:  19%|█▉        | 51/266 [02:11<07:57,  2.22s/it]predicting train subjects:  20%|█▉        | 52/266 [02:13<07:53,  2.21s/it]predicting train subjects:  20%|█▉        | 53/266 [02:15<07:49,  2.20s/it]predicting train subjects:  20%|██        | 54/266 [02:18<07:47,  2.21s/it]predicting train subjects:  21%|██        | 55/266 [02:20<07:40,  2.18s/it]predicting train subjects:  21%|██        | 56/266 [02:22<07:36,  2.17s/it]predicting train subjects:  21%|██▏       | 57/266 [02:24<07:33,  2.17s/it]predicting train subjects:  22%|██▏       | 58/266 [02:26<07:34,  2.19s/it]predicting train subjects:  22%|██▏       | 59/266 [02:28<07:30,  2.17s/it]predicting train subjects:  23%|██▎       | 60/266 [02:31<07:23,  2.15s/it]predicting train subjects:  23%|██▎       | 61/266 [02:33<07:31,  2.20s/it]predicting train subjects:  23%|██▎       | 62/266 [02:35<07:17,  2.15s/it]predicting train subjects:  24%|██▎       | 63/266 [02:37<07:05,  2.09s/it]predicting train subjects:  24%|██▍       | 64/266 [02:39<06:57,  2.07s/it]predicting train subjects:  24%|██▍       | 65/266 [02:41<06:59,  2.09s/it]predicting train subjects:  25%|██▍       | 66/266 [02:43<06:52,  2.06s/it]predicting train subjects:  25%|██▌       | 67/266 [02:45<06:50,  2.06s/it]predicting train subjects:  26%|██▌       | 68/266 [02:47<06:46,  2.05s/it]predicting train subjects:  26%|██▌       | 69/266 [02:49<06:44,  2.05s/it]predicting train subjects:  26%|██▋       | 70/266 [02:51<06:41,  2.05s/it]predicting train subjects:  27%|██▋       | 71/266 [02:53<06:42,  2.07s/it]predicting train subjects:  27%|██▋       | 72/266 [02:55<06:35,  2.04s/it]predicting train subjects:  27%|██▋       | 73/266 [02:57<06:31,  2.03s/it]predicting train subjects:  28%|██▊       | 74/266 [02:59<06:28,  2.02s/it]predicting train subjects:  28%|██▊       | 75/266 [03:01<06:25,  2.02s/it]predicting train subjects:  29%|██▊       | 76/266 [03:03<06:25,  2.03s/it]predicting train subjects:  29%|██▉       | 77/266 [03:05<06:26,  2.05s/it]predicting train subjects:  29%|██▉       | 78/266 [03:08<06:56,  2.21s/it]predicting train subjects:  30%|██▉       | 79/266 [03:11<07:13,  2.32s/it]predicting train subjects:  30%|███       | 80/266 [03:13<07:30,  2.42s/it]predicting train subjects:  30%|███       | 81/266 [03:16<07:36,  2.47s/it]predicting train subjects:  31%|███       | 82/266 [03:18<07:40,  2.50s/it]predicting train subjects:  31%|███       | 83/266 [03:21<07:43,  2.53s/it]predicting train subjects:  32%|███▏      | 84/266 [03:24<08:02,  2.65s/it]predicting train subjects:  32%|███▏      | 85/266 [03:27<07:57,  2.64s/it]predicting train subjects:  32%|███▏      | 86/266 [03:29<07:49,  2.61s/it]predicting train subjects:  33%|███▎      | 87/266 [03:32<07:47,  2.61s/it]predicting train subjects:  33%|███▎      | 88/266 [03:34<07:43,  2.61s/it]predicting train subjects:  33%|███▎      | 89/266 [03:37<07:40,  2.60s/it]predicting train subjects:  34%|███▍      | 90/266 [03:39<07:37,  2.60s/it]predicting train subjects:  34%|███▍      | 91/266 [03:42<07:34,  2.59s/it]predicting train subjects:  35%|███▍      | 92/266 [03:45<07:34,  2.61s/it]predicting train subjects:  35%|███▍      | 93/266 [03:47<07:37,  2.64s/it]predicting train subjects:  35%|███▌      | 94/266 [03:50<07:31,  2.63s/it]predicting train subjects:  36%|███▌      | 95/266 [03:53<07:28,  2.62s/it]predicting train subjects:  36%|███▌      | 96/266 [03:55<07:12,  2.54s/it]predicting train subjects:  36%|███▋      | 97/266 [03:58<07:08,  2.54s/it]predicting train subjects:  37%|███▋      | 98/266 [04:00<07:04,  2.53s/it]predicting train subjects:  37%|███▋      | 99/266 [04:02<06:29,  2.33s/it]predicting train subjects:  38%|███▊      | 100/266 [04:04<06:14,  2.25s/it]predicting train subjects:  38%|███▊      | 101/266 [04:06<06:11,  2.25s/it]predicting train subjects:  38%|███▊      | 102/266 [04:08<06:09,  2.25s/it]predicting train subjects:  39%|███▊      | 103/266 [04:11<06:08,  2.26s/it]predicting train subjects:  39%|███▉      | 104/266 [04:13<06:07,  2.27s/it]predicting train subjects:  39%|███▉      | 105/266 [04:15<06:02,  2.25s/it]predicting train subjects:  40%|███▉      | 106/266 [04:18<06:00,  2.25s/it]predicting train subjects:  40%|████      | 107/266 [04:20<06:00,  2.27s/it]predicting train subjects:  41%|████      | 108/266 [04:22<06:00,  2.28s/it]predicting train subjects:  41%|████      | 109/266 [04:24<05:59,  2.29s/it]predicting train subjects:  41%|████▏     | 110/266 [04:27<05:53,  2.27s/it]predicting train subjects:  42%|████▏     | 111/266 [04:29<05:49,  2.26s/it]predicting train subjects:  42%|████▏     | 112/266 [04:31<05:45,  2.24s/it]predicting train subjects:  42%|████▏     | 113/266 [04:33<05:43,  2.25s/it]predicting train subjects:  43%|████▎     | 114/266 [04:36<05:48,  2.29s/it]predicting train subjects:  43%|████▎     | 115/266 [04:38<05:46,  2.30s/it]predicting train subjects:  44%|████▎     | 116/266 [04:40<05:46,  2.31s/it]predicting train subjects:  44%|████▍     | 117/266 [04:43<05:48,  2.34s/it]predicting train subjects:  44%|████▍     | 118/266 [04:45<05:41,  2.31s/it]predicting train subjects:  45%|████▍     | 119/266 [04:48<05:52,  2.40s/it]predicting train subjects:  45%|████▌     | 120/266 [04:50<06:00,  2.47s/it]predicting train subjects:  45%|████▌     | 121/266 [04:53<06:06,  2.53s/it]predicting train subjects:  46%|████▌     | 122/266 [04:56<06:08,  2.56s/it]predicting train subjects:  46%|████▌     | 123/266 [04:58<06:04,  2.55s/it]predicting train subjects:  47%|████▋     | 124/266 [05:01<06:04,  2.57s/it]predicting train subjects:  47%|████▋     | 125/266 [05:03<06:02,  2.57s/it]predicting train subjects:  47%|████▋     | 126/266 [05:06<06:01,  2.58s/it]predicting train subjects:  48%|████▊     | 127/266 [05:09<05:59,  2.59s/it]predicting train subjects:  48%|████▊     | 128/266 [05:11<05:55,  2.58s/it]predicting train subjects:  48%|████▊     | 129/266 [05:14<05:51,  2.57s/it]predicting train subjects:  49%|████▉     | 130/266 [05:16<05:49,  2.57s/it]predicting train subjects:  49%|████▉     | 131/266 [05:19<05:47,  2.57s/it]predicting train subjects:  50%|████▉     | 132/266 [05:21<05:47,  2.59s/it]predicting train subjects:  50%|█████     | 133/266 [05:24<05:46,  2.60s/it]predicting train subjects:  50%|█████     | 134/266 [05:27<05:44,  2.61s/it]predicting train subjects:  51%|█████     | 135/266 [05:29<05:42,  2.61s/it]predicting train subjects:  51%|█████     | 136/266 [05:32<05:41,  2.63s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:34<05:36,  2.61s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:37<05:30,  2.58s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:40<05:26,  2.57s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:42<05:23,  2.57s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:45<05:21,  2.57s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:47<05:20,  2.58s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:50<05:17,  2.59s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:52<05:14,  2.58s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:55<05:17,  2.63s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:58<05:10,  2.59s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:00<05:08,  2.60s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:03<05:08,  2.61s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:05<05:01,  2.57s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:08<05:01,  2.60s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:11<04:56,  2.58s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:13<04:52,  2.57s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:16<04:49,  2.56s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:18<04:47,  2.57s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:20<04:19,  2.34s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:22<04:04,  2.22s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:24<03:52,  2.13s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:26<03:41,  2.05s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:28<03:39,  2.05s/it]predicting train subjects:  60%|██████    | 160/266 [06:30<03:34,  2.02s/it]predicting train subjects:  61%|██████    | 161/266 [06:32<03:28,  1.98s/it]predicting train subjects:  61%|██████    | 162/266 [06:34<03:22,  1.95s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:35<03:16,  1.91s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:37<03:14,  1.91s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:39<03:11,  1.89s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:41<03:11,  1.91s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:43<03:08,  1.91s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:45<03:08,  1.92s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:47<03:09,  1.96s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:49<03:07,  1.95s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:51<03:01,  1.91s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:53<02:57,  1.89s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:55<03:00,  1.94s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:57<03:01,  1.98s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:59<03:03,  2.02s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:01<03:02,  2.03s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:03<03:02,  2.05s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:05<03:02,  2.07s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:07<02:59,  2.06s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:09<02:55,  2.05s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:11<02:56,  2.08s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:13<02:54,  2.08s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:16<02:54,  2.11s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:18<02:52,  2.10s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:20<02:50,  2.11s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:22<02:48,  2.11s/it]predicting train subjects:  70%|███████   | 187/266 [07:24<02:46,  2.10s/it]predicting train subjects:  71%|███████   | 188/266 [07:26<02:44,  2.11s/it]predicting train subjects:  71%|███████   | 189/266 [07:28<02:44,  2.14s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:30<02:42,  2.14s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:33<02:42,  2.17s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:35<02:37,  2.13s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:37<02:34,  2.12s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:39<02:42,  2.26s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:42<02:40,  2.26s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:44<02:37,  2.25s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:46<02:35,  2.25s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:48<02:33,  2.25s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:51<02:29,  2.24s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:53<02:28,  2.25s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:55<02:26,  2.26s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:57<02:25,  2.27s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:00<02:21,  2.24s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:02<02:19,  2.25s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:04<02:16,  2.23s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:06<02:14,  2.24s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:09<02:11,  2.23s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:11<02:10,  2.25s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:13<02:08,  2.25s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:15<02:05,  2.23s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:18<02:02,  2.23s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:20<02:00,  2.23s/it]predicting train subjects:  80%|████████  | 213/266 [08:22<01:54,  2.15s/it]predicting train subjects:  80%|████████  | 214/266 [08:24<01:48,  2.10s/it]predicting train subjects:  81%|████████  | 215/266 [08:26<01:45,  2.07s/it]predicting train subjects:  81%|████████  | 216/266 [08:28<01:41,  2.03s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:30<01:38,  2.02s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:32<01:37,  2.02s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:34<01:33,  2.00s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:36<01:31,  1.99s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:38<01:30,  2.01s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:40<01:29,  2.04s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:42<01:28,  2.06s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:44<01:25,  2.04s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:46<01:23,  2.03s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:48<01:20,  2.01s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:50<01:18,  2.00s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:52<01:16,  2.02s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:54<01:14,  2.01s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:56<01:12,  2.00s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:58<01:09,  1.99s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:00<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:02<01:05,  1.98s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:04<01:03,  1.99s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:06<01:01,  1.98s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:08<01:01,  2.05s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:10<00:59,  2.04s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:12<00:56,  2.02s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:14<00:54,  2.01s/it]predicting train subjects:  90%|█████████ | 240/266 [09:16<00:53,  2.05s/it]predicting train subjects:  91%|█████████ | 241/266 [09:18<00:50,  2.03s/it]predicting train subjects:  91%|█████████ | 242/266 [09:20<00:48,  2.02s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:22<00:46,  2.02s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:24<00:44,  2.04s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:26<00:43,  2.08s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:28<00:41,  2.10s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:30<00:39,  2.07s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:32<00:37,  2.06s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:35<00:38,  2.24s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:38<00:37,  2.34s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:40<00:36,  2.40s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:43<00:34,  2.48s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:46<00:32,  2.52s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:48<00:30,  2.55s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:51<00:28,  2.55s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:53<00:25,  2.59s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:56<00:23,  2.57s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:59<00:20,  2.58s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:01<00:18,  2.59s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:04<00:15,  2.61s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:06<00:12,  2.59s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:09<00:10,  2.59s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:11<00:07,  2.58s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:14<00:05,  2.61s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:17<00:02,  2.62s/it]predicting train subjects: 100%|██████████| 266/266 [10:19<00:00,  2.61s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:19,  1.66s/it]Loading train:   1%|          | 2/266 [00:03<07:14,  1.65s/it]Loading train:   1%|          | 3/266 [00:04<06:52,  1.57s/it]Loading train:   2%|▏         | 4/266 [00:05<06:31,  1.50s/it]Loading train:   2%|▏         | 5/266 [00:07<06:31,  1.50s/it]Loading train:   2%|▏         | 6/266 [00:08<05:46,  1.33s/it]Loading train:   3%|▎         | 7/266 [00:09<05:07,  1.19s/it]Loading train:   3%|▎         | 8/266 [00:10<04:46,  1.11s/it]Loading train:   3%|▎         | 9/266 [00:11<04:28,  1.04s/it]Loading train:   4%|▍         | 10/266 [00:12<04:22,  1.02s/it]Loading train:   4%|▍         | 11/266 [00:13<04:15,  1.00s/it]Loading train:   5%|▍         | 12/266 [00:13<04:09,  1.02it/s]Loading train:   5%|▍         | 13/266 [00:14<04:02,  1.04it/s]Loading train:   5%|▌         | 14/266 [00:15<03:55,  1.07it/s]Loading train:   6%|▌         | 15/266 [00:16<03:54,  1.07it/s]Loading train:   6%|▌         | 16/266 [00:17<03:57,  1.05it/s]Loading train:   6%|▋         | 17/266 [00:18<03:56,  1.05it/s]Loading train:   7%|▋         | 18/266 [00:19<03:49,  1.08it/s]Loading train:   7%|▋         | 19/266 [00:20<03:45,  1.09it/s]Loading train:   8%|▊         | 20/266 [00:21<03:45,  1.09it/s]Loading train:   8%|▊         | 21/266 [00:22<03:55,  1.04it/s]Loading train:   8%|▊         | 22/266 [00:23<03:52,  1.05it/s]Loading train:   9%|▊         | 23/266 [00:24<03:54,  1.04it/s]Loading train:   9%|▉         | 24/266 [00:25<03:57,  1.02it/s]Loading train:   9%|▉         | 25/266 [00:26<03:56,  1.02it/s]Loading train:  10%|▉         | 26/266 [00:27<03:56,  1.02it/s]Loading train:  10%|█         | 27/266 [00:28<03:49,  1.04it/s]Loading train:  11%|█         | 28/266 [00:29<03:46,  1.05it/s]Loading train:  11%|█         | 29/266 [00:30<03:47,  1.04it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:37,  1.09it/s]Loading train:  12%|█▏        | 31/266 [00:31<03:32,  1.11it/s]Loading train:  12%|█▏        | 32/266 [00:32<03:35,  1.09it/s]Loading train:  12%|█▏        | 33/266 [00:33<03:29,  1.11it/s]Loading train:  13%|█▎        | 34/266 [00:34<03:30,  1.10it/s]Loading train:  13%|█▎        | 35/266 [00:35<03:33,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:36<03:43,  1.03it/s]Loading train:  14%|█▍        | 37/266 [00:37<03:47,  1.01it/s]Loading train:  14%|█▍        | 38/266 [00:38<03:45,  1.01it/s]Loading train:  15%|█▍        | 39/266 [00:39<03:41,  1.03it/s]Loading train:  15%|█▌        | 40/266 [00:40<03:35,  1.05it/s]Loading train:  15%|█▌        | 41/266 [00:41<03:34,  1.05it/s]Loading train:  16%|█▌        | 42/266 [00:42<03:28,  1.07it/s]Loading train:  16%|█▌        | 43/266 [00:43<03:25,  1.09it/s]Loading train:  17%|█▋        | 44/266 [00:44<03:32,  1.04it/s]Loading train:  17%|█▋        | 45/266 [00:45<03:23,  1.08it/s]Loading train:  17%|█▋        | 46/266 [00:45<03:21,  1.09it/s]Loading train:  18%|█▊        | 47/266 [00:46<03:11,  1.14it/s]Loading train:  18%|█▊        | 48/266 [00:47<03:03,  1.19it/s]Loading train:  18%|█▊        | 49/266 [00:48<02:52,  1.26it/s]Loading train:  19%|█▉        | 50/266 [00:49<02:53,  1.24it/s]Loading train:  19%|█▉        | 51/266 [00:49<02:51,  1.25it/s]Loading train:  20%|█▉        | 52/266 [00:50<02:47,  1.27it/s]Loading train:  20%|█▉        | 53/266 [00:51<02:43,  1.30it/s]Loading train:  20%|██        | 54/266 [00:52<02:41,  1.31it/s]Loading train:  21%|██        | 55/266 [00:52<02:38,  1.33it/s]Loading train:  21%|██        | 56/266 [00:53<02:42,  1.30it/s]Loading train:  21%|██▏       | 57/266 [00:54<02:40,  1.30it/s]Loading train:  22%|██▏       | 58/266 [00:55<02:35,  1.34it/s]Loading train:  22%|██▏       | 59/266 [00:55<02:34,  1.34it/s]Loading train:  23%|██▎       | 60/266 [00:56<02:46,  1.24it/s]Loading train:  23%|██▎       | 61/266 [00:57<02:45,  1.24it/s]Loading train:  23%|██▎       | 62/266 [00:58<02:37,  1.30it/s]Loading train:  24%|██▎       | 63/266 [00:59<02:38,  1.28it/s]Loading train:  24%|██▍       | 64/266 [00:59<02:43,  1.24it/s]Loading train:  24%|██▍       | 65/266 [01:00<02:42,  1.24it/s]Loading train:  25%|██▍       | 66/266 [01:01<02:47,  1.19it/s]Loading train:  25%|██▌       | 67/266 [01:02<02:41,  1.23it/s]Loading train:  26%|██▌       | 68/266 [01:03<02:36,  1.26it/s]Loading train:  26%|██▌       | 69/266 [01:03<02:35,  1.27it/s]Loading train:  26%|██▋       | 70/266 [01:04<02:40,  1.22it/s]Loading train:  27%|██▋       | 71/266 [01:05<02:33,  1.27it/s]Loading train:  27%|██▋       | 72/266 [01:06<02:31,  1.28it/s]Loading train:  27%|██▋       | 73/266 [01:07<02:30,  1.28it/s]Loading train:  28%|██▊       | 74/266 [01:07<02:34,  1.25it/s]Loading train:  28%|██▊       | 75/266 [01:08<02:33,  1.25it/s]Loading train:  29%|██▊       | 76/266 [01:09<02:31,  1.25it/s]Loading train:  29%|██▉       | 77/266 [01:10<02:30,  1.26it/s]Loading train:  29%|██▉       | 78/266 [01:11<02:45,  1.14it/s]Loading train:  30%|██▉       | 79/266 [01:12<02:52,  1.09it/s]Loading train:  30%|███       | 80/266 [01:13<02:50,  1.09it/s]Loading train:  30%|███       | 81/266 [01:14<02:50,  1.08it/s]Loading train:  31%|███       | 82/266 [01:15<02:50,  1.08it/s]Loading train:  31%|███       | 83/266 [01:16<02:47,  1.09it/s]Loading train:  32%|███▏      | 84/266 [01:17<02:51,  1.06it/s]Loading train:  32%|███▏      | 85/266 [01:18<02:55,  1.03it/s]Loading train:  32%|███▏      | 86/266 [01:18<02:51,  1.05it/s]Loading train:  33%|███▎      | 87/266 [01:19<02:52,  1.04it/s]Loading train:  33%|███▎      | 88/266 [01:21<03:00,  1.01s/it]Loading train:  33%|███▎      | 89/266 [01:22<02:59,  1.01s/it]Loading train:  34%|███▍      | 90/266 [01:23<02:56,  1.01s/it]Loading train:  34%|███▍      | 91/266 [01:24<02:53,  1.01it/s]Loading train:  35%|███▍      | 92/266 [01:24<02:49,  1.03it/s]Loading train:  35%|███▍      | 93/266 [01:25<02:49,  1.02it/s]Loading train:  35%|███▌      | 94/266 [01:26<02:45,  1.04it/s]Loading train:  36%|███▌      | 95/266 [01:27<02:47,  1.02it/s]Loading train:  36%|███▌      | 96/266 [01:29<03:05,  1.09s/it]Loading train:  36%|███▋      | 97/266 [01:30<03:22,  1.20s/it]
Epoch 00057: val_mDice did not improve from 0.62101
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [1.392035517949781, 0.9192910278486514, 0.9806315607055094, 0.8718897216794896, 0.8106286781704772, 0.76109377712135, 0.7288204527989463, 0.7897515019935196, 0.729507661583018, 0.8203542388326399, 0.6017269814904794, 0.5848049920871544, 0.732643474063438, 0.6227872064994084, 0.760493344043795, 0.6047333558070709, 0.6982784570500069, 0.9264822194190441, 0.9901164067731358, 0.7224119896710661, 0.7061241045285063, 0.67610110274489, 0.7171477959858431, 0.6179429139339083, 0.7378232145210519, 0.6010647706718366, 0.6016352708408942, 0.9872094553535905, 0.5672692618182091, 0.6102116530861598, 0.6470650843812222, 0.5575022280710862, 0.7436236437425574, 0.717780389355426, 0.6657497170555147, 0.5802597413419194, 0.7159474239804438, 0.7416869144716698, 0.7360798795688202, 0.7975132093142672, 0.7559906688221263, 0.7004237649846373, 0.6747954084665448, 0.7034144861569543, 0.5299007817175378, 0.7103934085220717, 0.7708705533836887, 0.7548771799847298, 0.7226225786931287, 0.7025533527506832, 0.7281706642313123, 0.5660587889277588, 1.4838822721445708, 0.7833550104956409, 0.7664113400882705, 0.7634056148687339, 0.749742963254699], 'val_acc': [0.9126851919775681, 0.9376845070435298, 0.9427399165402804, 0.9469059154205797, 0.9477520723560539, 0.9487478673705422, 0.9462110194922483, 0.9457272672059625, 0.9480729253954907, 0.946531879456706, 0.9491668066543167, 0.9490753731292313, 0.951587271393582, 0.9509788242118488, 0.9521707610470626, 0.9511932898853824, 0.9513279315841643, 0.9480313690866178, 0.9518133701130562, 0.9520909897519345, 0.9508042691654189, 0.951643784758461, 0.9513545127825124, 0.9520893183486591, 0.9513595277343053, 0.9507810077726594, 0.9518299802704966, 0.9475675630866245, 0.9506945659510823, 0.9527326646682138, 0.9500029846345736, 0.9490521008542959, 0.9503654001659377, 0.9512863765119023, 0.9514492849096717, 0.9506463405996932, 0.9529936743969739, 0.950072820008543, 0.9479416077067743, 0.950132640070935, 0.9515423727728024, 0.9481776737573235, 0.9507194933060293, 0.9510469884298649, 0.9510835708424263, 0.9504584969326668, 0.9509954487139753, 0.9505432730393786, 0.9513129787326353, 0.9513063163678181, 0.9496871369013647, 0.9502723009259869, 0.9177356085341996, 0.9488476222976114, 0.95102038373591, 0.9482092605092218, 0.9500196111152776], 'val_mDice': [0.43198835528243135, 0.5505788768970126, 0.5563738991610737, 0.5908656921624148, 0.5851555909358614, 0.5957939041106038, 0.6069251135671782, 0.5886871770209792, 0.6077720742997292, 0.5940532362807341, 0.6193993981943091, 0.6156671393461742, 0.6157484272208946, 0.610824439288175, 0.5861285318972164, 0.6133188783380501, 0.6210146452381403, 0.5802856228658273, 0.6060282172503808, 0.5954463956761656, 0.6160403732442262, 0.6085878791156152, 0.615939687643803, 0.6157256797636198, 0.6012357834463792, 0.6097382158659306, 0.6123791863809482, 0.5929205259346864, 0.6198685658917882, 0.605426792287233, 0.6184676640755903, 0.6143409201713024, 0.608671625620102, 0.6117712716838631, 0.6014834296159229, 0.6196708600056122, 0.6082049056702135, 0.6112635595669885, 0.6008598646187684, 0.5974050023249076, 0.6017295087521501, 0.6066373932905712, 0.6112218390361897, 0.6148647262842328, 0.6184382700821176, 0.6058966346796123, 0.6018754983344019, 0.6077778895860886, 0.6123190034969219, 0.609401889114459, 0.6069394006274054, 0.6069614254092774, 0.4457004406640144, 0.5979296463653755, 0.6004135635878535, 0.6029523927641113, 0.6101326428013718], 'loss': [1.3272000680897982, 0.5669017575844725, 0.44820601661611376, 0.4351613682175752, 0.38928450179776847, 0.3939881984691868, 0.3719181484322398, 0.36960971426887024, 0.38887018760140163, 0.34100920614921526, 0.3292976499833735, 0.31664153549265656, 0.3206167226259149, 0.2963149920852414, 0.2904606114536211, 0.3037355337611876, 0.29444377833820934, 0.32623343773626984, 0.29701111947349806, 0.3090088806374581, 0.2845273579822725, 0.2892920807259911, 0.29508716819758124, 0.2621742071377696, 0.26713080403309686, 0.26734987090569245, 0.2560730573049398, 0.28248659180093355, 0.2573544064941923, 0.2702749401263409, 0.2693225277644646, 0.2634485484623414, 0.25547483050307074, 0.25751873938622705, 0.2422921976771291, 0.2419439095467016, 0.23569571329387373, 0.2824497439326249, 0.26401234387583633, 0.24966556068246773, 0.2559971124705155, 0.2737926706522419, 0.28046023241557066, 0.2406445806330596, 0.23438138104548664, 0.24376810171804925, 0.23655000281029645, 0.2503583005874752, 0.23593579863468256, 0.2340492012302697, 0.2320802906307726, 0.24810860430615606, 0.24038482766477604, 0.29178953406095276, 0.24595548473263004, 0.23903590529439048, 0.2502238844834154], 'acc': [0.8004444522604538, 0.8947093016930096, 0.9063418206353565, 0.912840006154969, 0.9187346225433791, 0.93370595211803, 0.9427776483406547, 0.9429889586647503, 0.940959592470686, 0.9453365837316249, 0.9459841137766155, 0.9471190397250857, 0.947158606914903, 0.9485197307485091, 0.9490216546443128, 0.9480019155392096, 0.9490224197506905, 0.9472778092586357, 0.948736585612686, 0.9476413693321684, 0.9499035035295569, 0.9495911492845257, 0.9492837391253418, 0.9509368347117805, 0.9510278238467019, 0.9507109739583071, 0.9516114616937196, 0.9495732047175633, 0.9515624802332115, 0.9513448137818402, 0.9514208440704428, 0.9515774634361039, 0.9518584937625031, 0.9512311057934096, 0.9526259664033774, 0.9526352849540137, 0.9531684133245517, 0.9495933252024172, 0.9512431491166353, 0.9524771346504451, 0.9528346256715537, 0.9501170614691636, 0.9502211645217115, 0.9526818520425044, 0.9532340255615707, 0.9530138010301321, 0.9535870936322417, 0.9529463270224119, 0.9532608571853346, 0.953650817395906, 0.9537016391213841, 0.9525724456979687, 0.9527850485769392, 0.9498019098510383, 0.9529589419217623, 0.9530409917747247, 0.9522577242371235], 'mDice': [0.34525786880423753, 0.5624044561680435, 0.6301677182729122, 0.6458887004485453, 0.6721683679902144, 0.6697844249011508, 0.683517720941312, 0.6851925807756208, 0.6714971441818216, 0.7029923169184049, 0.7097634790991326, 0.7188060462034045, 0.7187279493384461, 0.7317174080162103, 0.736110815849468, 0.7275002364723282, 0.7371112299187266, 0.7221803877161432, 0.7362447348956502, 0.7251487845370105, 0.7449198645461379, 0.7430842449917024, 0.7407887035568479, 0.7573310688905815, 0.7570907029941791, 0.7543262101368595, 0.7625659214304262, 0.745462792122182, 0.7622375850572841, 0.759234604034715, 0.7600583234972512, 0.7618156130788208, 0.7658543744984702, 0.7616782392169, 0.7732585299091826, 0.7736350118203927, 0.779221355026403, 0.7475590958750544, 0.7606952132529202, 0.7723427365057682, 0.7738933299191808, 0.7559767210401083, 0.7503799876084424, 0.7745805931924522, 0.7797128337627376, 0.7777451354981834, 0.7818338890126302, 0.7773879302366999, 0.7807704357942211, 0.782883538587289, 0.7825834949337344, 0.7739928236288083, 0.7781157530844212, 0.7472678547767737, 0.7766660818659509, 0.7766762153736053, 0.7720282755095427]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values minLoading train:  37%|███▋      | 98/266 [01:31<03:19,  1.19s/it]Loading train:  37%|███▋      | 99/266 [01:32<03:04,  1.10s/it]Loading train:  38%|███▊      | 100/266 [01:34<03:11,  1.15s/it]Loading train:  38%|███▊      | 101/266 [01:34<02:57,  1.08s/it]Loading train:  38%|███▊      | 102/266 [01:35<02:39,  1.03it/s]Loading train:  39%|███▊      | 103/266 [01:36<02:24,  1.13it/s]Loading train:  39%|███▉      | 104/266 [01:37<02:15,  1.19it/s]Loading train:  39%|███▉      | 105/266 [01:37<02:10,  1.23it/s]Loading train:  40%|███▉      | 106/266 [01:38<02:04,  1.29it/s]Loading train:  40%|████      | 107/266 [01:39<01:59,  1.33it/s]Loading train:  41%|████      | 108/266 [01:40<02:05,  1.26it/s]Loading train:  41%|████      | 109/266 [01:40<02:05,  1.25it/s]Loading train:  41%|████▏     | 110/266 [01:41<02:03,  1.26it/s]Loading train:  42%|████▏     | 111/266 [01:42<02:03,  1.25it/s]Loading train:  42%|████▏     | 112/266 [01:43<02:02,  1.25it/s]Loading train:  42%|████▏     | 113/266 [01:44<02:00,  1.27it/s]Loading train:  43%|████▎     | 114/266 [01:44<01:57,  1.30it/s]Loading train:  43%|████▎     | 115/266 [01:45<01:53,  1.33it/s]Loading train:  44%|████▎     | 116/266 [01:46<01:53,  1.32it/s]Loading train:  44%|████▍     | 117/266 [01:47<01:52,  1.33it/s]Loading train:  44%|████▍     | 118/266 [01:47<01:53,  1.30it/s]Loading train:  45%|████▍     | 119/266 [01:48<02:04,  1.18it/s]Loading train:  45%|████▌     | 120/266 [01:49<02:12,  1.10it/s]Loading train:  45%|████▌     | 121/266 [01:50<02:13,  1.09it/s]Loading train:  46%|████▌     | 122/266 [01:51<02:13,  1.08it/s]Loading train:  46%|████▌     | 123/266 [01:52<02:14,  1.06it/s]Loading train:  47%|████▋     | 124/266 [01:53<02:18,  1.03it/s]Loading train:  47%|████▋     | 125/266 [01:54<02:15,  1.04it/s]Loading train:  47%|████▋     | 126/266 [01:55<02:11,  1.06it/s]Loading train:  48%|████▊     | 127/266 [01:56<02:08,  1.08it/s]Loading train:  48%|████▊     | 128/266 [01:57<02:07,  1.08it/s]Loading train:  48%|████▊     | 129/266 [01:58<02:05,  1.09it/s]Loading train:  49%|████▉     | 130/266 [01:59<01:59,  1.14it/s]Loading train:  49%|████▉     | 131/266 [02:00<02:01,  1.11it/s]Loading train:  50%|████▉     | 132/266 [02:01<02:02,  1.10it/s]Loading train:  50%|█████     | 133/266 [02:01<01:58,  1.12it/s]Loading train:  50%|█████     | 134/266 [02:02<01:57,  1.12it/s]Loading train:  51%|█████     | 135/266 [02:03<02:02,  1.07it/s]Loading train:  51%|█████     | 136/266 [02:04<01:58,  1.10it/s]Loading train:  52%|█████▏    | 137/266 [02:05<02:04,  1.03it/s]Loading train:  52%|█████▏    | 138/266 [02:06<02:03,  1.03it/s]Loading train:  52%|█████▏    | 139/266 [02:07<02:06,  1.00it/s]Loading train:  53%|█████▎    | 140/266 [02:08<02:07,  1.01s/it]Loading train:  53%|█████▎    | 141/266 [02:09<02:03,  1.02it/s]Loading train:  53%|█████▎    | 142/266 [02:10<02:03,  1.01it/s]Loading train:  54%|█████▍    | 143/266 [02:11<01:57,  1.04it/s]Loading train:  54%|█████▍    | 144/266 [02:12<01:59,  1.02it/s]Loading train:  55%|█████▍    | 145/266 [02:13<01:58,  1.02it/s]Loading train:  55%|█████▍    | 146/266 [02:14<01:57,  1.02it/s]Loading train:  55%|█████▌    | 147/266 [02:15<01:53,  1.05it/s]Loading train:  56%|█████▌    | 148/266 [02:16<01:50,  1.06it/s]Loading train:  56%|█████▌    | 149/266 [02:17<01:50,  1.06it/s]Loading train:  56%|█████▋    | 150/266 [02:18<01:51,  1.04it/s]Loading train:  57%|█████▋    | 151/266 [02:19<01:52,  1.02it/s]Loading train:  57%|█████▋    | 152/266 [02:20<01:52,  1.01it/s]Loading train:  58%|█████▊    | 153/266 [02:21<01:50,  1.02it/s]Loading train:  58%|█████▊    | 154/266 [02:22<01:48,  1.03it/s]Loading train:  58%|█████▊    | 155/266 [02:23<01:40,  1.10it/s]Loading train:  59%|█████▊    | 156/266 [02:23<01:33,  1.18it/s]Loading train:  59%|█████▉    | 157/266 [02:24<01:27,  1.24it/s]Loading train:  59%|█████▉    | 158/266 [02:25<01:21,  1.33it/s]Loading train:  60%|█████▉    | 159/266 [02:25<01:20,  1.33it/s]Loading train:  60%|██████    | 160/266 [02:26<01:15,  1.40it/s]Loading train:  61%|██████    | 161/266 [02:27<01:19,  1.33it/s]Loading train:  61%|██████    | 162/266 [02:28<01:17,  1.34it/s]Loading train:  61%|██████▏   | 163/266 [02:28<01:14,  1.37it/s]Loading train:  62%|██████▏   | 164/266 [02:29<01:18,  1.30it/s]Loading train:  62%|██████▏   | 165/266 [02:30<01:15,  1.34it/s]Loading train:  62%|██████▏   | 166/266 [02:31<01:11,  1.39it/s]Loading train:  63%|██████▎   | 167/266 [02:31<01:10,  1.41it/s]Loading train:  63%|██████▎   | 168/266 [02:32<01:08,  1.43it/s]Loading train:  64%|██████▎   | 169/266 [02:33<01:10,  1.38it/s]Loading train:  64%|██████▍   | 170/266 [02:33<01:11,  1.34it/s]Loading train:  64%|██████▍   | 171/266 [02:34<01:08,  1.39it/s]Loading train:  65%|██████▍   | 172/266 [02:35<01:11,  1.31it/s]Loading train:  65%|██████▌   | 173/266 [02:36<01:09,  1.34it/s]Loading train:  65%|██████▌   | 174/266 [02:36<01:07,  1.37it/s]Loading train:  66%|██████▌   | 175/266 [02:37<01:05,  1.39it/s]Loading train:  66%|██████▌   | 176/266 [02:38<01:03,  1.43it/s]Loading train:  67%|██████▋   | 177/266 [02:38<01:02,  1.42it/s]Loading train:  67%|██████▋   | 178/266 [02:39<01:03,  1.39it/s]Loading train:  67%|██████▋   | 179/266 [02:40<01:03,  1.36it/s]Loading train:  68%|██████▊   | 180/266 [02:41<01:02,  1.37it/s]Loading train:  68%|██████▊   | 181/266 [02:41<01:02,  1.36it/s]Loading train:  68%|██████▊   | 182/266 [02:42<00:59,  1.41it/s]Loading train:  69%|██████▉   | 183/266 [02:43<00:57,  1.44it/s]Loading train:  69%|██████▉   | 184/266 [02:43<00:57,  1.44it/s]Loading train:  70%|██████▉   | 185/266 [02:44<00:57,  1.40it/s]Loading train:  70%|██████▉   | 186/266 [02:45<00:56,  1.41it/s]Loading train:  70%|███████   | 187/266 [02:46<00:55,  1.43it/s]Loading train:  71%|███████   | 188/266 [02:46<00:53,  1.45it/s]Loading train:  71%|███████   | 189/266 [02:47<00:52,  1.47it/s]Loading train:  71%|███████▏  | 190/266 [02:48<00:52,  1.44it/s]Loading train:  72%|███████▏  | 191/266 [02:49<01:04,  1.16it/s]Loading train:  72%|███████▏  | 192/266 [02:50<01:10,  1.05it/s]Loading train:  73%|███████▎  | 193/266 [02:51<01:15,  1.04s/it]Loading train:  73%|███████▎  | 194/266 [02:53<01:23,  1.15s/it]Loading train:  73%|███████▎  | 195/266 [02:54<01:17,  1.09s/it]Loading train:  74%|███████▎  | 196/266 [02:55<01:11,  1.03s/it]Loading train:  74%|███████▍  | 197/266 [02:55<01:08,  1.00it/s]Loading train:  74%|███████▍  | 198/266 [02:56<01:03,  1.07it/s]Loading train:  75%|███████▍  | 199/266 [02:57<00:59,  1.13it/s]Loading train:  75%|███████▌  | 200/266 [02:58<00:55,  1.18it/s]Loading train:  76%|███████▌  | 201/266 [02:59<00:54,  1.20it/s]Loading train:  76%|███████▌  | 202/266 [02:59<00:51,  1.23it/s]Loading train:  76%|███████▋  | 203/266 [03:00<00:49,  1.26it/s]Loading train:  77%|███████▋  | 204/266 [03:01<00:48,  1.27it/s]Loading train:  77%|███████▋  | 205/266 [03:02<00:46,  1.30it/s]Loading train:  77%|███████▋  | 206/266 [03:02<00:45,  1.30it/s]Loading train:  78%|███████▊  | 207/266 [03:03<00:46,  1.27it/s]Loading train:  78%|███████▊  | 208/266 [03:04<00:45,  1.28it/s]Loading train:  79%|███████▊  | 209/266 [03:05<00:45,  1.26it/s]Loading train:  79%|███████▉  | 210/266 [03:06<00:43,  1.29it/s]Loading train:  79%|███████▉  | 211/266 [03:06<00:43,  1.27it/s]Loading train:  80%|███████▉  | 212/266 [03:07<00:41,  1.29it/s]Loading train:  80%|████████  | 213/266 [03:08<00:40,  1.32it/s]Loading train:  80%|████████  | 214/266 [03:08<00:38,  1.36it/s]Loading train:  81%|████████  | 215/266 [03:09<00:37,  1.35it/s]Loading train:  81%|████████  | 216/266 [03:10<00:37,  1.32it/s]Loading train:  82%|████████▏ | 217/266 [03:11<00:36,  1.32it/s]Loading train:  82%|████████▏ | 218/266 [03:11<00:35,  1.35it/s]Loading train:  82%|████████▏ | 219/266 [03:12<00:34,  1.38it/s]Loading train:  83%|████████▎ | 220/266 [03:13<00:34,  1.35it/s]Loading train:  83%|████████▎ | 221/266 [03:14<00:32,  1.37it/s]Loading train:  83%|████████▎ | 222/266 [03:14<00:32,  1.36it/s]Loading train:  84%|████████▍ | 223/266 [03:15<00:31,  1.35it/s]Loading train:  84%|████████▍ | 224/266 [03:16<00:33,  1.24it/s]Loading train:  85%|████████▍ | 225/266 [03:17<00:32,  1.27it/s]Loading train:  85%|████████▍ | 226/266 [03:18<00:31,  1.28it/s]Loading train:  85%|████████▌ | 227/266 [03:18<00:29,  1.32it/s]Loading train:  86%|████████▌ | 228/266 [03:19<00:28,  1.33it/s]Loading train:  86%|████████▌ | 229/266 [03:20<00:30,  1.22it/s]Loading train:  86%|████████▋ | 230/266 [03:21<00:28,  1.25it/s]Loading train:  87%|████████▋ | 231/266 [03:22<00:28,  1.22it/s]Loading train:  87%|████████▋ | 232/266 [03:22<00:26,  1.28it/s]Loading train:  88%|████████▊ | 233/266 [03:23<00:25,  1.28it/s]Loading train:  88%|████████▊ | 234/266 [03:24<00:24,  1.30it/s]Loading train:  88%|████████▊ | 235/266 [03:25<00:24,  1.25it/s]Loading train:  89%|████████▊ | 236/266 [03:26<00:24,  1.23it/s]Loading train:  89%|████████▉ | 237/266 [03:26<00:22,  1.28it/s]Loading train:  89%|████████▉ | 238/266 [03:27<00:22,  1.25it/s]Loading train:  90%|████████▉ | 239/266 [03:28<00:21,  1.24it/s]Loading train:  90%|█████████ | 240/266 [03:29<00:20,  1.27it/s]Loading train:  91%|█████████ | 241/266 [03:30<00:19,  1.26it/s]Loading train:  91%|█████████ | 242/266 [03:30<00:19,  1.26it/s]Loading train:  91%|█████████▏| 243/266 [03:31<00:18,  1.22it/s]Loading train:  92%|█████████▏| 244/266 [03:32<00:17,  1.25it/s]Loading train:  92%|█████████▏| 245/266 [03:33<00:16,  1.24it/s]Loading train:  92%|█████████▏| 246/266 [03:34<00:15,  1.27it/s]Loading train:  93%|█████████▎| 247/266 [03:34<00:14,  1.31it/s]Loading train:  93%|█████████▎| 248/266 [03:35<00:13,  1.30it/s]Loading train:  94%|█████████▎| 249/266 [03:36<00:15,  1.13it/s]Loading train:  94%|█████████▍| 250/266 [03:37<00:13,  1.16it/s]Loading train:  94%|█████████▍| 251/266 [03:38<00:12,  1.16it/s]Loading train:  95%|█████████▍| 252/266 [03:39<00:12,  1.15it/s]Loading train:  95%|█████████▌| 253/266 [03:40<00:11,  1.15it/s]Loading train:  95%|█████████▌| 254/266 [03:41<00:10,  1.12it/s]Loading train:  96%|█████████▌| 255/266 [03:41<00:09,  1.16it/s]Loading train:  96%|█████████▌| 256/266 [03:42<00:08,  1.18it/s]Loading train:  97%|█████████▋| 257/266 [03:43<00:07,  1.19it/s]Loading train:  97%|█████████▋| 258/266 [03:44<00:06,  1.19it/s]Loading train:  97%|█████████▋| 259/266 [03:45<00:05,  1.19it/s]Loading train:  98%|█████████▊| 260/266 [03:45<00:05,  1.18it/s]Loading train:  98%|█████████▊| 261/266 [03:46<00:04,  1.21it/s]Loading train:  98%|█████████▊| 262/266 [03:47<00:03,  1.22it/s]Loading train:  99%|█████████▉| 263/266 [03:48<00:02,  1.24it/s]Loading train:  99%|█████████▉| 264/266 [03:49<00:01,  1.26it/s]Loading train: 100%|█████████▉| 265/266 [03:49<00:00,  1.26it/s]Loading train: 100%|██████████| 266/266 [03:50<00:00,  1.25it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 16/266 [00:00<00:01, 157.57it/s]concatenating: train:  13%|█▎        | 34/266 [00:00<00:01, 163.00it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:01, 149.13it/s]concatenating: train:  23%|██▎       | 61/266 [00:00<00:01, 145.82it/s]concatenating: train:  28%|██▊       | 75/266 [00:00<00:01, 140.55it/s]concatenating: train:  33%|███▎      | 87/266 [00:00<00:01, 133.34it/s]concatenating: train:  40%|███▉      | 106/266 [00:00<00:01, 145.37it/s]concatenating: train:  50%|█████     | 134/266 [00:00<00:00, 169.55it/s]concatenating: train:  59%|█████▉    | 158/266 [00:00<00:00, 183.92it/s]concatenating: train:  70%|███████   | 187/266 [00:01<00:00, 206.32it/s]concatenating: train:  79%|███████▉  | 211/266 [00:01<00:00, 211.69it/s]concatenating: train:  88%|████████▊ | 234/266 [00:01<00:00, 203.80it/s]concatenating: train:  97%|█████████▋| 258/266 [00:01<00:00, 213.15it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 191.83it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.23s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.16s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 62.87it/s]2019-07-28 17:41:09.081913: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 17:41:09.082035: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 17:41:09.082055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 17:41:09.082065: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 17:41:09.082496: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.09it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.00it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.69it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.26it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.18it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.07it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.21it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.02it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.57it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.14it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.87it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.23it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.29it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.31it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.02it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.16it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.29it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.31it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.41it/s] 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 84, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 84, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 84, 52, 40)   4000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 84, 52, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 84, 52, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 84, 52, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 84, 52, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 84, 52, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 42, 26, 80)   28880       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 42, 26, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 42, 26, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 42, 26, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 42, 26, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 42, 26, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 26, 120)  0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 21, 13, 160)  172960      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 21, 13, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 21, 13, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 21, 13, 160)  230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 21, 13, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 21, 13, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 13, 280)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 21, 13, 280)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 42, 26, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 42, 26, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 42, 26, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 42, 26, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 42, 26, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 26, 280)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 42, 26, 280)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 40)   28840       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 84, 52, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 84, 52, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 84, 52, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 84, 52, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 84, 52, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 52, 120)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 84, 52, 120)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 84, 52, 10)   10810       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 84, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 84, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 84, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 84, 52, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 84, 52, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 84, 52, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 84, 52, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 84, 52, 130)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 84, 52, 13)   1703        concatenate_8[0][0]              
==================================================================================================
Total params: 905,873
Trainable params: 209,233
Non-trainable params: 696,640
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34081218e-02 3.28635491e-02 7.68468897e-02 9.54861246e-03
 2.76358588e-02 7.23014345e-03 8.42934161e-02 1.14220250e-01
 8.96854411e-02 1.36263394e-02 2.90777840e-01 1.89622058e-01
 2.41479882e-04]
Train on 10351 samples, validate on 151 samples
Epoch 1/300
 - 27s - loss: 1.6279 - acc: 0.7916 - mDice: 0.2935 - val_loss: 0.8101 - val_acc: 0.9173 - val_mDice: 0.4696

Epoch 00001: val_mDice improved from -inf to 0.46960, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 21s - loss: 0.6105 - acc: 0.9065 - mDice: 0.5370 - val_loss: 0.7097 - val_acc: 0.9320 - val_mDice: 0.5166

Epoch 00002: val_mDice improved from 0.46960 to 0.51664, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 20s - loss: 0.5292 - acc: 0.9263 - mDice: 0.5842 - val_loss: 0.5351 - val_acc: 0.9504 - val_mDice: 0.6096

Epoch 00003: val_mDice improved from 0.51664 to 0.60959, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 21s - loss: 0.4552 - acc: 0.9360 - mDice: 0.6236 - val_loss: 0.5190 - val_acc: 0.9533 - val_mDice: 0.6204

Epoch 00004: val_mDice improved from 0.60959 to 0.62040, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 20s - loss: 0.4320 - acc: 0.9400 - mDice: 0.6380 - val_loss: 0.4956 - val_acc: 0.9505 - val_mDice: 0.6300

Epoch 00005: val_mDice improved from 0.62040 to 0.63002, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 20s - loss: 0.4118 - acc: 0.9415 - mDice: 0.6499 - val_loss: 0.5099 - val_acc: 0.9523 - val_mDice: 0.6184

Epoch 00006: val_mDice did not improve from 0.63002
Epoch 7/300
 - 20s - loss: 0.4018 - acc: 0.9427 - mDice: 0.6569 - val_loss: 0.4780 - val_acc: 0.9520 - val_mDice: 0.6362

Epoch 00007: val_mDice improved from 0.63002 to 0.63618, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 21s - loss: 0.4108 - acc: 0.9419 - mDice: 0.6511 - val_loss: 0.8359 - val_acc: 0.9509 - val_mDice: 0.5777

Epoch 00008: val_mDice did not improve from 0.63618
Epoch 9/300
 - 20s - loss: 0.4478 - acc: 0.9398 - mDice: 0.6306 - val_loss: 0.5380 - val_acc: 0.9438 - val_mDice: 0.6041

Epoch 00009: val_mDice did not improve from 0.63618
Epoch 10/300
 - 20s - loss: 0.4326 - acc: 0.9408 - mDice: 0.6415 - val_loss: 0.5043 - val_acc: 0.9489 - val_mDice: 0.6171

Epoch 00010: val_mDice did not improve from 0.63618
Epoch 11/300
 - 20s - loss: 0.3903 - acc: 0.9436 - mDice: 0.6642 - val_loss: 0.4836 - val_acc: 0.9530 - val_mDice: 0.6306

Epoch 00011: val_mDice did not improve from 0.63618
Epoch 12/300
 - 21s - loss: 0.3752 - acc: 0.9453 - mDice: 0.6742 - val_loss: 0.4651 - val_acc: 0.9514 - val_mDice: 0.6386

Epoch 00012: val_mDice improved from 0.63618 to 0.63860, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 21s - loss: 0.3665 - acc: 0.9464 - mDice: 0.6830 - val_loss: 0.4816 - val_acc: 0.9529 - val_mDice: 0.6270

Epoch 00013: val_mDice did not improve from 0.63860
Epoch 14/300
 - 21s - loss: 0.4115 - acc: 0.9421 - mDice: 0.6527 - val_loss: 0.4892 - val_acc: 0.9499 - val_mDice: 0.6243

Epoch 00014: val_mDice did not improve from 0.63860
Epoch 15/300
 - 21s - loss: 0.3604 - acc: 0.9460 - mDice: 0.6846 - val_loss: 0.5102 - val_acc: 0.9536 - val_mDice: 0.6149

Epoch 00015: val_mDice did not improve from 0.63860
Epoch 16/300
 - 21s - loss: 0.3808 - acc: 0.9445 - mDice: 0.6716 - val_loss: 0.4611 - val_acc: 0.9513 - val_mDice: 0.6390

Epoch 00016: val_mDice improved from 0.63860 to 0.63902, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 21s - loss: 0.3441 - acc: 0.9473 - mDice: 0.6954 - val_loss: 0.4518 - val_acc: 0.9527 - val_mDice: 0.6431

Epoch 00017: val_mDice improved from 0.63902 to 0.64307, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 21s - loss: 0.3374 - acc: 0.9481 - mDice: 0.7004 - val_loss: 0.4456 - val_acc: 0.9529 - val_mDice: 0.6467

Epoch 00018: val_mDice improved from 0.64307 to 0.64670, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 20s - loss: 0.3369 - acc: 0.9486 - mDice: 0.7049 - val_loss: 0.4637 - val_acc: 0.9485 - val_mDice: 0.6318

Epoch 00019: val_mDice did not improve from 0.64670
Epoch 20/300
 - 21s - loss: 0.3280 - acc: 0.9486 - mDice: 0.7072 - val_loss: 0.4563 - val_acc: 0.9525 - val_mDice: 0.6360

Epoch 00020: val_mDice did not improve from 0.64670
Epoch 21/300
 - 21s - loss: 0.4345 - acc: 0.9404 - mDice: 0.6406 - val_loss: 0.4698 - val_acc: 0.9519 - val_mDice: 0.6311

Epoch 00021: val_mDice did not improve from 0.64670
Epoch 22/300
 - 21s - loss: 0.3623 - acc: 0.9456 - mDice: 0.6828 - val_loss: 0.4517 - val_acc: 0.9530 - val_mDice: 0.6377

Epoch 00022: val_mDice did not improve from 0.64670
Epoch 23/300
 - 21s - loss: 0.3501 - acc: 0.9465 - mDice: 0.6918 - val_loss: 0.4565 - val_acc: 0.9507 - val_mDice: 0.6327

Epoch 00023: val_mDice did not improve from 0.64670
Epoch 24/300
 - 21s - loss: 0.3668 - acc: 0.9452 - mDice: 0.6801 - val_loss: 0.4524 - val_acc: 0.9530 - val_mDice: 0.6358

Epoch 00024: val_mDice did not improve from 0.64670
Epoch 25/300
 - 21s - loss: 0.3840 - acc: 0.9454 - mDice: 0.6765 - val_loss: 0.5241 - val_acc: 0.9528 - val_mDice: 0.6077

Epoch 00025: val_mDice did not improve from 0.64670
Epoch 26/300
 - 21s - loss: 0.3393 - acc: 0.9478 - mDice: 0.6992 - val_loss: 0.4453 - val_acc: 0.9524 - val_mDice: 0.6392

Epoch 00026: val_mDice did not improve from 0.64670
Epoch 27/300
 - 21s - loss: 0.3393 - acc: 0.9475 - mDice: 0.6987 - val_loss: 0.4387 - val_acc: 0.9513 - val_mDice: 0.6386

Epoch 00027: val_mDice did not improve from 0.64670
Epoch 28/300
 - 21s - loss: 0.3481 - acc: 0.9476 - mDice: 0.6954 - val_loss: 1.1070 - val_acc: 0.9489 - val_mDice: 0.5442

Epoch 00028: val_mDice did not improve from 0.64670
Epoch 29/300
 - 21s - loss: 0.3853 - acc: 0.9435 - mDice: 0.6681 - val_loss: 0.4550 - val_acc: 0.9523 - val_mDice: 0.6315

Epoch 00029: val_mDice did not improve from 0.64670
Epoch 30/300
 - 21s - loss: 0.3809 - acc: 0.9442 - mDice: 0.6716 - val_loss: 0.5001 - val_acc: 0.9452 - val_mDice: 0.6078

Epoch 00030: val_mDice did not improve from 0.64670
Epoch 31/300
 - 21s - loss: 0.3623 - acc: 0.9452 - mDice: 0.6828 - val_loss: 0.4410 - val_acc: 0.9495 - val_mDice: 0.6360

Epoch 00031: val_mDice did not improve from 0.64670
Epoch 32/300
 - 21s - loss: 0.3455 - acc: 0.9467 - mDice: 0.6943 - val_loss: 0.4310 - val_acc: 0.9515 - val_mDice: 0.6411

Epoch 00032: val_mDice did not improve from 0.64670
Epoch 33/300
 - 22s - loss: 0.3670 - acc: 0.9445 - mDice: 0.6806 - val_loss: 0.4488 - val_acc: 0.9520 - val_mDice: 0.6313

Epoch 00033: val_mDice did not improve from 0.64670
Epoch 34/300
 - 24s - loss: 0.3698 - acc: 0.9454 - mDice: 0.6798 - val_loss: 0.4703 - val_acc: 0.9512 - val_mDice: 0.6297

Epoch 00034: val_mDice did not improve from 0.64670
Epoch 35/300
 - 23s - loss: 0.3498 - acc: 0.9469 - mDice: 0.6920 - val_loss: 0.4536 - val_acc: 0.9533 - val_mDice: 0.6324

Epoch 00035: val_mDice did not improve from 0.64670
Epoch 36/300
 - 23s - loss: 0.3411 - acc: 0.9473 - mDice: 0.6982 - val_loss: 0.5796 - val_acc: 0.9533 - val_mDice: 0.5889

Epoch 00036: val_mDice did not improve from 0.64670
Epoch 37/300
 - 24s - loss: 0.3832 - acc: 0.9442 - mDice: 0.6713 - val_loss: 0.4351 - val_acc: 0.9518 - val_mDice: 0.6381

Epoch 00037: val_mDice did not improve from 0.64670
Epoch 38/300
 - 23s - loss: 0.3458 - acc: 0.9475 - mDice: 0.6986 - val_loss: 0.4402 - val_acc: 0.9494 - val_mDice: 0.6333

Epoch 00038: val_mDice did not improve from 0.64670
Epoch 39/300
 - 23s - loss: 0.3446 - acc: 0.9468 - mDice: 0.6951 - val_loss: 0.4330 - val_acc: 0.9528 - val_mDice: 0.6396

Epoch 00039: val_mDice did not improve from 0.64670
Epoch 40/300
 - 23s - loss: 0.3325 - acc: 0.9483 - mDice: 0.7040 - val_loss: 0.4280 - val_acc: 0.9516 - val_mDice: 0.6410

Epoch 00040: val_mDice did not improve from 0.64670
Epoch 41/300
 - 24s - loss: 0.3410 - acc: 0.9481 - mDice: 0.6993 - val_loss: 0.4360 - val_acc: 0.9524 - val_mDice: 0.6387

Epoch 00041: val_mDice did not improve from 0.64670
Epoch 42/300
 - 23s - loss: 0.3357 - acc: 0.9482 - mDice: 0.7024 - val_loss: 0.4745 - val_acc: 0.9455 - val_mDice: 0.6129

Epoch 00042: val_mDice did not improve from 0.64670
Epoch 43/300
 - 24s - loss: 0.3295 - acc: 0.9486 - mDice: 0.7055 - val_loss: 0.4201 - val_acc: 0.9521 - val_mDice: 0.6439

Epoch 00043: val_mDice did not improve from 0.64670
Epoch 44/300
 - 22s - loss: 0.3274 - acc: 0.9489 - mDice: 0.7073 - val_loss: 0.4318 - val_acc: 0.9502 - val_mDice: 0.6360

Epoch 00044: val_mDice did not improve from 0.64670
Epoch 45/300
 - 22s - loss: 0.3324 - acc: 0.9481 - mDice: 0.7038 - val_loss: 0.4373 - val_acc: 0.9515 - val_mDice: 0.6349

Epoch 00045: val_mDice did not improve from 0.64670
Epoch 46/300
 - 22s - loss: 0.3138 - acc: 0.9498 - mDice: 0.7173 - val_loss: 0.4284 - val_acc: 0.9538 - val_mDice: 0.6409

Epoch 00046: val_mDice did not improve from 0.64670
Epoch 47/300
 - 22s - loss: 0.3125 - acc: 0.9499 - mDice: 0.7186 - val_loss: 0.5419 - val_acc: 0.9530 - val_mDice: 0.5953

Epoch 00047: val_mDice did not improve from 0.64670
Epoch 48/300
 - 22s - loss: 0.3625 - acc: 0.9464 - mDice: 0.6853 - val_loss: 0.4347 - val_acc: 0.9496 - val_mDice: 0.6348

Epoch 00048: val_mDice did not improve from 0.64670
Epoch 49/300
 - 22s - loss: 0.3349 - acc: 0.9479 - mDice: 0.7027 - val_loss: 0.4311 - val_acc: 0.9524 - val_mDice: 0.6379

Epoch 00049: val_mDice did not improve from 0.64670
Epoch 50/300
 - 22s - loss: 0.3248 - acc: 0.9488 - mDice: 0.7097 - val_loss: 0.4283 - val_acc: 0.9521 - val_mDice: 0.6373

Epoch 00050: val_mDice did not improve from 0.64670
Epoch 51/300
 - 22s - loss: 0.3820 - acc: 0.9447 - mDice: 0.6723 - val_loss: 0.4394 - val_acc: 0.9501 - val_mDice: 0.6318

Epoch 00051: val_mDice did not improve from 0.64670
Epoch 52/300
 - 22s - loss: 0.3439 - acc: 0.9474 - mDice: 0.6959 - val_loss: 0.4494 - val_acc: 0.9501 - val_mDice: 0.6315

Epoch 00052: val_mDice did not improve from 0.64670
Epoch 53/300
 - 22s - loss: 0.3213 - acc: 0.9490 - mDice: 0.7119 - val_loss: 0.4603 - val_acc: 0.9541 - val_mDice: 0.6295

Epoch 00053: val_mDice did not improve from 0.64670
Epoch 54/300
 - 21s - loss: 0.3707 - acc: 0.9456 - mDice: 0.6813 - val_loss: 0.4392 - val_acc: 0.9517 - val_mDice: 0.6360

Epoch 00054: val_mDice did not improve from 0.64670
Epoch 55/300
 - 21s - loss: 0.3458 - acc: 0.9470 - mDice: 0.6951 - val_loss: 0.4291 - val_acc: 0.9529 - val_mDice: 0.6395

Epoch 00055: val_mDice did not improve from 0.64670
Epoch 56/300
 - 21s - loss: 0.3247 - acc: 0.9486 - mDice: 0.7096 - val_loss: 0.4331 - val_acc: 0.9521 - val_mDice: 0.6374

Epoch 00056: val_mDice did not improve from 0.64670
Epoch 57/300
 - 21s - loss: 0.3159 - acc: 0.9496 - mDice: 0.7159 - val_loss: 0.4413 - val_acc: 0.9523 - val_mDice: 0.6322

Epoch 00057: val_mDice did not improve from 0.64670
Epoch 58/300
 - 21s - loss: 0.3365 - acc: 0.9482 - mDice: 0.7033 - val_loss: 0.4349 - val_acc: 0.9507 - val_mDice: 0.6360

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:08,  2.97s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.66s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:06<00:02,  2.42s/it]predicting test subjects: 100%|██████████| 4/4 [00:09<00:00,  2.37s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:21,  2.80s/it]predicting train subjects:   1%|          | 2/266 [00:05<11:56,  2.71s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:13,  2.56s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:28,  2.40s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:38,  2.45s/it]predicting train subjects:   2%|▏         | 6/266 [00:14<10:54,  2.52s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:13,  2.60s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:21,  2.64s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:29,  2.68s/it]predicting train subjects:   4%|▍         | 10/266 [00:25<11:35,  2.72s/it]predicting train subjects:   4%|▍         | 11/266 [00:28<11:36,  2.73s/it]predicting train subjects:   5%|▍         | 12/266 [00:31<11:32,  2.73s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<12:02,  2.86s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<12:19,  2.94s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<12:16,  2.93s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<12:37,  3.03s/it]predicting train subjects:   6%|▋         | 17/266 [00:47<12:52,  3.10s/it]predicting train subjects:   7%|▋         | 18/266 [00:50<12:51,  3.11s/it]predicting train subjects:   7%|▋         | 19/266 [00:53<13:02,  3.17s/it]predicting train subjects:   8%|▊         | 20/266 [00:56<13:16,  3.24s/it]predicting train subjects:   8%|▊         | 21/266 [01:00<13:32,  3.32s/it]predicting train subjects:   8%|▊         | 22/266 [01:03<13:37,  3.35s/it]predicting train subjects:   9%|▊         | 23/266 [01:06<13:03,  3.22s/it]predicting train subjects:   9%|▉         | 24/266 [01:09<12:44,  3.16s/it]predicting train subjects:   9%|▉         | 25/266 [01:12<12:23,  3.09s/it]predicting train subjects:  10%|▉         | 26/266 [01:15<11:57,  2.99s/it]predicting train subjects:  10%|█         | 27/266 [01:18<11:50,  2.97s/it]predicting train subjects:  11%|█         | 28/266 [01:21<11:27,  2.89s/it]predicting train subjects:  11%|█         | 29/266 [01:23<11:14,  2.85s/it]predicting train subjects:  11%|█▏        | 30/266 [01:26<11:10,  2.84s/it]predicting train subjects:  12%|█▏        | 31/266 [01:29<11:31,  2.94s/it]predicting train subjects:  12%|█▏        | 32/266 [01:32<11:42,  3.00s/it]predicting train subjects:  12%|█▏        | 33/266 [01:36<11:45,  3.03s/it]predicting train subjects:  13%|█▎        | 34/266 [01:39<11:51,  3.07s/it]predicting train subjects:  13%|█▎        | 35/266 [01:42<11:36,  3.02s/it]predicting train subjects:  14%|█▎        | 36/266 [01:45<11:25,  2.98s/it]predicting train subjects:  14%|█▍        | 37/266 [01:48<11:27,  3.00s/it]predicting train subjects:  14%|█▍        | 38/266 [01:51<11:31,  3.03s/it]predicting train subjects:  15%|█▍        | 39/266 [01:54<11:22,  3.01s/it]predicting train subjects:  15%|█▌        | 40/266 [01:56<11:04,  2.94s/it]predicting train subjects:  15%|█▌        | 41/266 [01:59<11:06,  2.96s/it]predicting train subjects:  16%|█▌        | 42/266 [02:02<10:29,  2.81s/it]predicting train subjects:  16%|█▌        | 43/266 [02:04<10:05,  2.71s/it]predicting train subjects:  17%|█▋        | 44/266 [02:07<09:45,  2.64s/it]predicting train subjects:  17%|█▋        | 45/266 [02:09<09:10,  2.49s/it]predicting train subjects:  17%|█▋        | 46/266 [02:11<08:39,  2.36s/it]predicting train subjects:  18%|█▊        | 47/266 [02:13<08:27,  2.32s/it]predicting train subjects:  18%|█▊        | 48/266 [02:16<08:30,  2.34s/it]predicting train subjects:  18%|█▊        | 49/266 [02:18<08:48,  2.43s/it]predicting train subjects:  19%|█▉        | 50/266 [02:21<08:53,  2.47s/it]predicting train subjects:  19%|█▉        | 51/266 [02:23<08:57,  2.50s/it]predicting train subjects:  20%|█▉        | 52/266 [02:26<08:45,  2.46s/it]predicting train subjects:  20%|█▉        | 53/266 [02:28<08:45,  2.47s/it]predicting train subjects:  20%|██        | 54/266 [02:31<08:49,  2.50s/it]predicting train subjects:  21%|██        | 55/266 [02:33<08:51,  2.52s/it]predicting train subjects:  21%|██        | 56/266 [02:36<08:52,  2.54s/it]predicting train subjects:  21%|██▏       | 57/266 [02:39<08:52,  2.55s/it]predicting train subjects:  22%|██▏       | 58/266 [02:41<08:50,  2.55s/it]predicting train subjects:  22%|██▏       | 59/266 [02:44<08:50,  2.56s/it]predicting train subjects:  23%|██▎       | 60/266 [02:46<08:36,  2.51s/it]predicting train subjects:  23%|██▎       | 61/266 [02:48<08:25,  2.46s/it]predicting train subjects:  23%|██▎       | 62/266 [02:51<08:14,  2.42s/it]predicting train subjects:  24%|██▎       | 63/266 [02:53<08:04,  2.39s/it]predicting train subjects:  24%|██▍       | 64/266 [02:56<08:05,  2.41s/it]predicting train subjects:  24%|██▍       | 65/266 [02:58<07:58,  2.38s/it]predicting train subjects:  25%|██▍       | 66/266 [03:00<07:48,  2.34s/it]predicting train subjects:  25%|██▌       | 67/266 [03:02<07:41,  2.32s/it]predicting train subjects:  26%|██▌       | 68/266 [03:05<07:28,  2.26s/it]predicting train subjects:  26%|██▌       | 69/266 [03:07<07:22,  2.25s/it]predicting train subjects:  26%|██▋       | 70/266 [03:09<07:19,  2.24s/it]predicting train subjects:  27%|██▋       | 71/266 [03:11<07:21,  2.26s/it]predicting train subjects:  27%|██▋       | 72/266 [03:13<07:08,  2.21s/it]predicting train subjects:  27%|██▋       | 73/266 [03:16<07:18,  2.27s/it]predicting train subjects:  28%|██▊       | 74/266 [03:18<07:22,  2.31s/it]predicting train subjects:  28%|██▊       | 75/266 [03:20<07:19,  2.30s/it]predicting train subjects:  29%|██▊       | 76/266 [03:23<07:12,  2.28s/it]predicting train subjects:  29%|██▉       | 77/266 [03:25<07:12,  2.29s/it]predicting train subjects:  29%|██▉       | 78/266 [03:28<08:01,  2.56s/it]predicting train subjects:  30%|██▉       | 79/266 [03:31<08:32,  2.74s/it]predicting train subjects:  30%|███       | 80/266 [03:34<08:51,  2.86s/it]predicting train subjects:  30%|███       | 81/266 [03:38<09:07,  2.96s/it]predicting train subjects:  31%|███       | 82/266 [03:41<09:10,  2.99s/it]predicting train subjects:  31%|███       | 83/266 [03:44<08:58,  2.94s/it]predicting train subjects:  32%|███▏      | 84/266 [03:47<08:59,  2.96s/it]predicting train subjects:  32%|███▏      | 85/266 [03:50<08:59,  2.98s/it]predicting train subjects:  32%|███▏      | 86/266 [03:53<09:06,  3.04s/it]predicting train subjects:  33%|███▎      | 87/266 [03:56<09:08,  3.06s/it]predicting train subjects:  33%|███▎      | 88/266 [03:59<08:58,  3.03s/it]predicting train subjects:  33%|███▎      | 89/266 [04:02<08:51,  3.00s/it]predicting train subjects:  34%|███▍      | 90/266 [04:05<08:47,  3.00s/it]predicting train subjects:  34%|███▍      | 91/266 [04:08<08:45,  3.01s/it]predicting train subjects:  35%|███▍      | 92/266 [04:11<08:54,  3.07s/it]predicting train subjects:  35%|███▍      | 93/266 [04:14<08:53,  3.08s/it]predicting train subjects:  35%|███▌      | 94/266 [04:17<08:51,  3.09s/it]predicting train subjects:  36%|███▌      | 95/266 [04:20<08:45,  3.07s/it]predicting train subjects:  36%|███▌      | 96/266 [04:23<08:20,  2.95s/it]predicting train subjects:  36%|███▋      | 97/266 [04:26<08:26,  2.99s/it]predicting train subjects:  37%|███▋      | 98/266 [04:29<08:30,  3.04s/it]predicting train subjects:  37%|███▋      | 99/266 [04:31<07:45,  2.79s/it]predicting train subjects:  38%|███▊      | 100/266 [04:34<07:30,  2.71s/it]predicting train subjects:  38%|███▊      | 101/266 [04:37<07:27,  2.71s/it]predicting train subjects:  38%|███▊      | 102/266 [04:39<07:12,  2.64s/it]predicting train subjects:  39%|███▊      | 103/266 [04:42<07:13,  2.66s/it]predicting train subjects:  39%|███▉      | 104/266 [04:44<06:55,  2.56s/it]predicting train subjects:  39%|███▉      | 105/266 [04:47<06:46,  2.52s/it]predicting train subjects:  40%|███▉      | 106/266 [04:49<06:51,  2.57s/it]predicting train subjects:  40%|████      | 107/266 [04:52<06:46,  2.56s/it]predicting train subjects:  41%|████      | 108/266 [04:55<07:00,  2.66s/it]predicting train subjects:  41%|████      | 109/266 [04:57<06:46,  2.59s/it]predicting train subjects:  41%|████▏     | 110/266 [05:00<06:40,  2.56s/it]predicting train subjects:  42%|████▏     | 111/266 [05:02<06:36,  2.56s/it]predicting train subjects:  42%|████▏     | 112/266 [05:05<06:33,  2.55s/it]predicting train subjects:  42%|████▏     | 113/266 [05:07<06:28,  2.54s/it]predicting train subjects:  43%|████▎     | 114/266 [05:10<06:19,  2.50s/it]predicting train subjects:  43%|████▎     | 115/266 [05:12<06:17,  2.50s/it]predicting train subjects:  44%|████▎     | 116/266 [05:15<06:15,  2.50s/it]predicting train subjects:  44%|████▍     | 117/266 [05:17<06:21,  2.56s/it]predicting train subjects:  44%|████▍     | 118/266 [05:20<06:28,  2.62s/it]predicting train subjects:  45%|████▍     | 119/266 [05:23<06:47,  2.77s/it]predicting train subjects:  45%|████▌     | 120/266 [05:26<06:53,  2.83s/it]predicting train subjects:  45%|████▌     | 121/266 [05:29<07:07,  2.95s/it]predicting train subjects:  46%|████▌     | 122/266 [05:32<07:07,  2.97s/it]predicting train subjects:  46%|████▌     | 123/266 [05:35<07:04,  2.97s/it]predicting train subjects:  47%|████▋     | 124/266 [05:39<07:22,  3.12s/it]predicting train subjects:  47%|████▋     | 125/266 [05:42<07:08,  3.04s/it]predicting train subjects:  47%|████▋     | 126/266 [05:45<07:03,  3.02s/it]predicting train subjects:  48%|████▊     | 127/266 [05:48<06:55,  2.99s/it]predicting train subjects:  48%|████▊     | 128/266 [05:50<06:42,  2.92s/it]predicting train subjects:  48%|████▊     | 129/266 [05:53<06:45,  2.96s/it]predicting train subjects:  49%|████▉     | 130/266 [05:56<06:32,  2.89s/it]predicting train subjects:  49%|████▉     | 131/266 [05:59<06:29,  2.89s/it]predicting train subjects:  50%|████▉     | 132/266 [06:02<06:22,  2.86s/it]predicting train subjects:  50%|█████     | 133/266 [06:05<06:24,  2.89s/it]predicting train subjects:  50%|█████     | 134/266 [06:08<06:24,  2.91s/it]predicting train subjects:  51%|█████     | 135/266 [06:11<06:21,  2.91s/it]predicting train subjects:  51%|█████     | 136/266 [06:14<06:21,  2.94s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:16<06:17,  2.92s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:20<06:22,  2.99s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:23<06:18,  2.98s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:25<06:08,  2.92s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:28<06:02,  2.90s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:31<05:59,  2.90s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:34<06:06,  2.98s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:37<05:58,  2.94s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:40<06:03,  3.01s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:43<05:48,  2.90s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:46<05:45,  2.90s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:49<05:36,  2.85s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:51<05:22,  2.76s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:54<05:12,  2.70s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:56<05:02,  2.63s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:59<04:55,  2.59s/it]predicting train subjects:  58%|█████▊    | 153/266 [07:01<04:57,  2.63s/it]predicting train subjects:  58%|█████▊    | 154/266 [07:04<04:49,  2.58s/it]predicting train subjects:  58%|█████▊    | 155/266 [07:06<04:24,  2.38s/it]predicting train subjects:  59%|█████▊    | 156/266 [07:08<04:09,  2.27s/it]predicting train subjects:  59%|█████▉    | 157/266 [07:10<03:49,  2.11s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:11<03:36,  2.01s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:13<03:28,  1.95s/it]predicting train subjects:  60%|██████    | 160/266 [07:15<03:22,  1.91s/it]predicting train subjects:  61%|██████    | 161/266 [07:17<03:20,  1.91s/it]predicting train subjects:  61%|██████    | 162/266 [07:19<03:15,  1.88s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:20<03:12,  1.87s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:22<03:07,  1.84s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:24<03:05,  1.84s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:26<03:03,  1.83s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:28<03:01,  1.83s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:30<02:59,  1.83s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:31<02:57,  1.83s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:33<02:54,  1.82s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:35<02:52,  1.82s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:37<02:49,  1.80s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:39<02:54,  1.87s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:41<02:55,  1.90s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:43<02:55,  1.93s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:45<03:04,  2.05s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:47<03:00,  2.03s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:49<02:57,  2.02s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:51<02:54,  2.00s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:53<02:52,  2.01s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:55<02:50,  2.01s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:57<02:48,  2.00s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:59<02:46,  2.00s/it]predicting train subjects:  69%|██████▉   | 184/266 [08:01<02:44,  2.00s/it]predicting train subjects:  70%|██████▉   | 185/266 [08:03<02:45,  2.05s/it]predicting train subjects:  70%|██████▉   | 186/266 [08:05<02:43,  2.05s/it]predicting train subjects:  70%|███████   | 187/266 [08:07<02:39,  2.02s/it]predicting train subjects:  71%|███████   | 188/266 [08:09<02:35,  1.99s/it]predicting train subjects:  71%|███████   | 189/266 [08:11<02:33,  2.00s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:13<02:30,  1.99s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:15<02:33,  2.05s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:17<02:28,  2.00s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:19<02:23,  1.96s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:21<02:31,  2.10s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:24<02:30,  2.12s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:26<02:29,  2.13s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:28<02:30,  2.17s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:30<02:26,  2.16s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:32<02:24,  2.16s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:35<02:22,  2.16s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:37<02:20,  2.16s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:39<02:17,  2.15s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:41<02:14,  2.14s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:43<02:12,  2.14s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:45<02:12,  2.17s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:47<02:09,  2.16s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:50<02:07,  2.15s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:52<02:04,  2.15s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:54<02:03,  2.17s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:56<02:01,  2.17s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:58<01:59,  2.18s/it]predicting train subjects:  80%|███████▉  | 212/266 [09:00<01:57,  2.17s/it]predicting train subjects:  80%|████████  | 213/266 [09:02<01:51,  2.10s/it]predicting train subjects:  80%|████████  | 214/266 [09:04<01:46,  2.05s/it]predicting train subjects:  81%|████████  | 215/266 [09:06<01:42,  2.01s/it]predicting train subjects:  81%|████████  | 216/266 [09:08<01:39,  1.99s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:10<01:36,  1.97s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:12<01:33,  1.94s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:14<01:33,  2.00s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:16<01:29,  1.95s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:18<01:27,  1.94s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:20<01:25,  1.94s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:22<01:23,  1.93s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:24<01:20,  1.91s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:26<01:18,  1.92s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:27<01:16,  1.92s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:29<01:13,  1.90s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:31<01:12,  1.91s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:33<01:10,  1.91s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:35<01:09,  1.93s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:37<01:07,  1.93s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:39<01:05,  1.92s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:41<01:03,  1.92s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:43<01:01,  1.91s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:45<00:59,  1.91s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:47<00:57,  1.90s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:48<00:55,  1.90s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:50<00:53,  1.91s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:52<00:51,  1.90s/it]predicting train subjects:  90%|█████████ | 240/266 [09:54<00:49,  1.89s/it]predicting train subjects:  91%|█████████ | 241/266 [09:56<00:47,  1.91s/it]predicting train subjects:  91%|█████████ | 242/266 [09:58<00:45,  1.90s/it]predicting train subjects:  91%|█████████▏| 243/266 [10:00<00:43,  1.90s/it]predicting train subjects:  92%|█████████▏| 244/266 [10:02<00:41,  1.91s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:04<00:39,  1.89s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:06<00:37,  1.89s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:07<00:35,  1.88s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:09<00:34,  1.90s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:12<00:35,  2.08s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:14<00:34,  2.18s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:17<00:34,  2.27s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:19<00:32,  2.32s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:22<00:30,  2.37s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:24<00:28,  2.40s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:27<00:26,  2.42s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:29<00:24,  2.42s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:32<00:21,  2.44s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:34<00:19,  2.44s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:37<00:17,  2.48s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:39<00:14,  2.47s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:42<00:12,  2.58s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:44<00:10,  2.57s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:47<00:07,  2.53s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:49<00:05,  2.51s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:52<00:02,  2.49s/it]predicting train subjects: 100%|██████████| 266/266 [10:54<00:00,  2.46s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:10,  2.03it/s]Loading train:   1%|          | 2/266 [00:00<02:06,  2.09it/s]Loading train:   1%|          | 3/266 [00:01<01:56,  2.26it/s]Loading train:   2%|▏         | 4/266 [00:01<01:48,  2.41it/s]Loading train:   2%|▏         | 5/266 [00:02<01:49,  2.38it/s]Loading train:   2%|▏         | 6/266 [00:02<01:55,  2.25it/s]Loading train:   3%|▎         | 7/266 [00:03<01:55,  2.24it/s]Loading train:   3%|▎         | 8/266 [00:03<01:47,  2.40it/s]Loading train:   3%|▎         | 9/266 [00:03<01:52,  2.28it/s]Loading train:   4%|▍         | 10/266 [00:04<02:01,  2.10it/s]Loading train:   4%|▍         | 11/266 [00:04<02:02,  2.09it/s]Loading train:   5%|▍         | 12/266 [00:05<01:57,  2.17it/s]Loading train:   5%|▍         | 13/266 [00:05<01:51,  2.26it/s]Loading train:   5%|▌         | 14/266 [00:06<01:49,  2.30it/s]Loading train:   6%|▌         | 15/266 [00:06<01:49,  2.29it/s]Loading train:   6%|▌         | 16/266 [00:07<01:53,  2.20it/s]Loading train:   6%|▋         | 17/266 [00:07<01:50,  2.26it/s]Loading train:   7%|▋         | 18/266 [00:07<01:48,  2.28it/s]Loading train:   7%|▋         | 19/266 [00:08<01:48,  2.27it/s]Loading train:   8%|▊         | 20/266 [00:08<01:49,  2.24it/s]Loading train:   8%|▊         | 21/266 [00:09<01:52,  2.17it/s]Loading train:   8%|▊         | 22/266 [00:09<01:55,  2.12it/s]Loading train:   9%|▊         | 23/266 [00:10<01:56,  2.09it/s]Loading train:   9%|▉         | 24/266 [00:10<01:51,  2.18it/s]Loading train:   9%|▉         | 25/266 [00:11<01:50,  2.17it/s]Loading train:  10%|▉         | 26/266 [00:11<01:46,  2.26it/s]Loading train:  10%|█         | 27/266 [00:12<01:42,  2.33it/s]Loading train:  11%|█         | 28/266 [00:12<01:41,  2.35it/s]Loading train:  11%|█         | 29/266 [00:12<01:35,  2.47it/s]Loading train:  11%|█▏        | 30/266 [00:13<01:30,  2.59it/s]Loading train:  12%|█▏        | 31/266 [00:13<01:27,  2.68it/s]Loading train:  12%|█▏        | 32/266 [00:13<01:29,  2.62it/s]Loading train:  12%|█▏        | 33/266 [00:14<01:30,  2.56it/s]Loading train:  13%|█▎        | 34/266 [00:14<01:31,  2.54it/s]Loading train:  13%|█▎        | 35/266 [00:15<01:33,  2.48it/s]Loading train:  14%|█▎        | 36/266 [00:15<01:30,  2.53it/s]Loading train:  14%|█▍        | 37/266 [00:15<01:27,  2.61it/s]Loading train:  14%|█▍        | 38/266 [00:16<01:27,  2.60it/s]Loading train:  15%|█▍        | 39/266 [00:16<01:26,  2.61it/s]Loading train:  15%|█▌        | 40/266 [00:17<01:30,  2.50it/s]Loading train:  15%|█▌        | 41/266 [00:17<01:34,  2.38it/s]Loading train:  16%|█▌        | 42/266 [00:17<01:29,  2.51it/s]Loading train:  16%|█▌        | 43/266 [00:18<01:23,  2.66it/s]Loading train:  17%|█▋        | 44/266 [00:18<01:21,  2.71it/s]Loading train:  17%|█▋        | 45/266 [00:18<01:18,  2.80it/s]Loading train:  17%|█▋        | 46/266 [00:19<01:18,  2.79it/s]Loading train:  18%|█▊        | 47/266 [00:19<01:14,  2.94it/s]Loading train:  18%|█▊        | 48/266 [00:19<01:13,  2.98it/s]Loading train:  18%|█▊        | 49/266 [00:20<01:12,  3.00it/s]Loading train:  19%|█▉        | 50/266 [00:20<01:12,  3.00it/s]Loading train:  19%|█▉        | 51/266 [00:20<01:08,  3.16it/s]Loading train:  20%|█▉        | 52/266 [00:21<01:07,  3.17it/s]Loading train:  20%|█▉        | 53/266 [00:21<01:05,  3.26it/s]Loading train:  20%|██        | 54/266 [00:21<01:07,  3.14it/s]Loading train:  21%|██        | 55/266 [00:22<01:05,  3.23it/s]Loading train:  21%|██        | 56/266 [00:22<01:07,  3.13it/s]Loading train:  21%|██▏       | 57/266 [00:22<01:12,  2.87it/s]Loading train:  22%|██▏       | 58/266 [00:23<01:09,  2.98it/s]Loading train:  22%|██▏       | 59/266 [00:23<01:05,  3.15it/s]Loading train:  23%|██▎       | 60/266 [00:23<01:04,  3.20it/s]Loading train:  23%|██▎       | 61/266 [00:23<01:02,  3.29it/s]Loading train:  23%|██▎       | 62/266 [00:24<01:01,  3.29it/s]Loading train:  24%|██▎       | 63/266 [00:24<01:03,  3.18it/s]Loading train:  24%|██▍       | 64/266 [00:24<01:02,  3.21it/s]Loading train:  24%|██▍       | 65/266 [00:25<01:05,  3.09it/s]Loading train:  25%|██▍       | 66/266 [00:25<01:08,  2.91it/s]Loading train:  25%|██▌       | 67/266 [00:25<01:09,  2.86it/s]Loading train:  26%|██▌       | 68/266 [00:26<01:06,  2.98it/s]Loading train:  26%|██▌       | 69/266 [00:26<01:03,  3.12it/s]Loading train:  26%|██▋       | 70/266 [00:26<01:02,  3.14it/s]Loading train:  27%|██▋       | 71/266 [00:27<01:01,  3.17it/s]Loading train:  27%|██▋       | 72/266 [00:27<01:02,  3.10it/s]Loading train:  27%|██▋       | 73/266 [00:27<01:01,  3.12it/s]Loading train:  28%|██▊       | 74/266 [00:28<00:59,  3.23it/s]Loading train:  28%|██▊       | 75/266 [00:28<00:59,  3.23it/s]Loading train:  29%|██▊       | 76/266 [00:28<00:58,  3.26it/s]Loading train:  29%|██▉       | 77/266 [00:29<00:58,  3.25it/s]Loading train:  29%|██▉       | 78/266 [00:29<01:04,  2.94it/s]Loading train:  30%|██▉       | 79/266 [00:29<01:07,  2.76it/s]Loading train:  30%|███       | 80/266 [00:30<01:06,  2.80it/s]Loading train:  30%|███       | 81/266 [00:30<01:04,  2.87it/s]Loading train:  31%|███       | 82/266 [00:30<01:03,  2.89it/s]Loading train:  31%|███       | 83/266 [00:31<01:02,  2.91it/s]Loading train:  32%|███▏      | 84/266 [00:31<01:04,  2.82it/s]Loading train:  32%|███▏      | 85/266 [00:32<01:05,  2.75it/s]Loading train:  32%|███▏      | 86/266 [00:32<01:08,  2.64it/s]Loading train:  33%|███▎      | 87/266 [00:32<01:08,  2.61it/s]Loading train:  33%|███▎      | 88/266 [00:33<01:14,  2.39it/s]Loading train:  33%|███▎      | 89/266 [00:33<01:18,  2.24it/s]Loading train:  34%|███▍      | 90/266 [00:34<01:19,  2.23it/s]Loading train:  34%|███▍      | 91/266 [00:34<01:16,  2.27it/s]Loading train:  35%|███▍      | 92/266 [00:35<01:14,  2.33it/s]Loading train:  35%|███▍      | 93/266 [00:35<01:14,  2.31it/s]Loading train:  35%|███▌      | 94/266 [00:35<01:12,  2.37it/s]Loading train:  36%|███▌      | 95/266 [00:36<01:13,  2.34it/s]Loading train:  36%|███▌      | 96/266 [00:36<01:12,  2.35it/s]Loading train:  36%|███▋      | 97/266 [00:37<01:17,  2.18it/s]Loading train:  37%|███▋      | 98/266 [00:37<01:14,  2.25it/s]Loading train:  37%|███▋      | 99/266 [00:38<01:12,  2.31it/s]Loading train:  38%|███▊      | 100/266 [00:38<01:08,  2.42it/s]Loading train:  38%|███▊      | 101/266 [00:38<01:09,  2.37it/s]Loading train:  38%|███▊      | 102/266 [00:39<01:06,  2.45it/s]Loading train:  39%|███▊      | 103/266 [00:39<01:04,  2.55it/s]Loading train:  39%|███▉      | 104/266 [00:40<01:02,  2.59it/s]Loading train:  39%|███▉      | 105/266 [00:40<01:02,  2.57it/s]Loading train:  40%|███▉      | 106/266 [00:40<01:00,  2.62it/s]Loading train:  40%|████      | 107/266 [00:41<00:59,  2.66it/s]Loading train:  41%|████      | 108/266 [00:41<00:59,  2.64it/s]Loading train:  41%|████      | 109/266 [00:41<00:59,  2.62it/s]Loading train:  41%|████▏     | 110/266 [00:42<00:58,  2.68it/s]Loading train:  42%|████▏     | 111/266 [00:42<00:58,  2.64it/s]Loading train:  42%|████▏     | 112/266 [00:43<00:59,  2.58it/s]Loading train:  42%|████▏     | 113/266 [00:43<00:57,  2.66it/s]Loading train:  43%|████▎     | 114/266 [00:43<00:58,  2.59it/s]Loading train:  43%|████▎     | 115/266 [00:44<00:59,  2.52it/s]Loading train:  44%|████▎     | 116/266 [00:44<00:58,  2.59it/s]Loading train:  44%|████▍     | 117/266 [00:45<00:58,  2.56it/s]Loading train:  44%|████▍     | 118/266 [00:45<00:56,  2.64it/s]Loading train:  45%|████▍     | 119/266 [00:45<00:57,  2.58it/s]Loading train:  45%|████▌     | 120/266 [00:46<00:58,  2.48it/s]Loading train:  45%|████▌     | 121/266 [00:46<00:58,  2.46it/s]Loading train:  46%|████▌     | 122/266 [00:47<00:57,  2.52it/s]Loading train:  46%|████▌     | 123/266 [00:47<00:58,  2.43it/s]Loading train:  47%|████▋     | 124/266 [00:47<00:58,  2.43it/s]Loading train:  47%|████▋     | 125/266 [00:48<00:57,  2.46it/s]Loading train:  47%|████▋     | 126/266 [00:48<00:59,  2.34it/s]Loading train:  48%|████▊     | 127/266 [00:49<00:59,  2.32it/s]Loading train:  48%|████▊     | 128/266 [00:49<01:02,  2.19it/s]Loading train:  48%|████▊     | 129/266 [00:50<01:01,  2.22it/s]Loading train:  49%|████▉     | 130/266 [00:50<01:02,  2.16it/s]Loading train:  49%|████▉     | 131/266 [00:51<01:01,  2.21it/s]Loading train:  50%|████▉     | 132/266 [00:51<00:58,  2.28it/s]Loading train:  50%|█████     | 133/266 [00:51<00:55,  2.38it/s]Loading train:  50%|█████     | 134/266 [00:52<00:56,  2.33it/s]Loading train:  51%|█████     | 135/266 [00:52<00:55,  2.35it/s]Loading train:  51%|█████     | 136/266 [00:53<00:54,  2.39it/s]Loading train:  52%|█████▏    | 137/266 [00:53<00:50,  2.57it/s]Loading train:  52%|█████▏    | 138/266 [00:53<00:46,  2.73it/s]Loading train:  52%|█████▏    | 139/266 [00:54<00:44,  2.85it/s]Loading train:  53%|█████▎    | 140/266 [00:54<00:45,  2.77it/s]Loading train:  53%|█████▎    | 141/266 [00:54<00:45,  2.76it/s]Loading train:  53%|█████▎    | 142/266 [00:55<00:47,  2.62it/s]Loading train:  54%|█████▍    | 143/266 [00:55<00:47,  2.60it/s]Loading train:  54%|█████▍    | 144/266 [00:56<00:47,  2.57it/s]Loading train:  55%|█████▍    | 145/266 [00:56<00:48,  2.51it/s]Loading train:  55%|█████▍    | 146/266 [00:56<00:46,  2.60it/s]Loading train:  55%|█████▌    | 147/266 [00:57<00:42,  2.77it/s]Loading train:  56%|█████▌    | 148/266 [00:57<00:41,  2.85it/s]Loading train:  56%|█████▌    | 149/266 [00:57<00:42,  2.73it/s]Loading train:  56%|█████▋    | 150/266 [00:58<00:40,  2.84it/s]Loading train:  57%|█████▋    | 151/266 [00:58<00:40,  2.81it/s]Loading train:  57%|█████▋    | 152/266 [00:58<00:39,  2.91it/s]Loading train:  58%|█████▊    | 153/266 [00:59<00:37,  3.01it/s]Loading train:  58%|█████▊    | 154/266 [00:59<00:36,  3.08it/s]Loading train:  58%|█████▊    | 155/266 [00:59<00:34,  3.23it/s]Loading train:  59%|█████▊    | 156/266 [01:00<00:33,  3.32it/s]Loading train:  59%|█████▉    | 157/266 [01:00<00:34,  3.19it/s]Loading train:  59%|█████▉    | 158/266 [01:00<00:34,  3.16it/s]Loading train:  60%|█████▉    | 159/266 [01:01<00:33,  3.18it/s]Loading train:  60%|██████    | 160/266 [01:01<00:33,  3.18it/s]Loading train:  61%|██████    | 161/266 [01:01<00:31,  3.38it/s]Loading train:  61%|██████    | 162/266 [01:01<00:30,  3.46it/s]Loading train:  61%|██████▏   | 163/266 [01:02<00:30,  3.41it/s]Loading train:  62%|██████▏   | 164/266 [01:02<00:28,  3.56it/s]Loading train:  62%|██████▏   | 165/266 [01:02<00:27,  3.68it/s]Loading train:  62%|██████▏   | 166/266 [01:02<00:26,  3.77it/s]Loading train:  63%|██████▎   | 167/266 [01:03<00:27,  3.55it/s]Loading train:  63%|██████▎   | 168/266 [01:03<00:28,  3.49it/s]Loading train:  64%|██████▎   | 169/266 [01:03<00:26,  3.62it/s]Loading train:  64%|██████▍   | 170/266 [01:04<00:26,  3.65it/s]Loading train:  64%|██████▍   | 171/266 [01:04<00:27,  3.48it/s]Loading train:  65%|██████▍   | 172/266 [01:04<00:27,  3.40it/s]Loading train:  65%|██████▌   | 173/266 [01:04<00:27,  3.40it/s]Loading train:  65%|██████▌   | 174/266 [01:05<00:26,  3.45it/s]Loading train:  66%|██████▌   | 175/266 [01:05<00:26,  3.40it/s]Loading train:  66%|██████▌   | 176/266 [01:05<00:27,  3.25it/s]Loading train:  67%|██████▋   | 177/266 [01:06<00:27,  3.29it/s]Loading train:  67%|██████▋   | 178/266 [01:06<00:27,  3.20it/s]Loading train:  67%|██████▋   | 179/266 [01:06<00:26,  3.29it/s]Loading train:  68%|██████▊   | 180/266 [01:07<00:25,  3.37it/s]Loading train:  68%|██████▊   | 181/266 [01:07<00:25,  3.39it/s]Loading train:  68%|██████▊   | 182/266 [01:07<00:24,  3.41it/s]Loading train:  69%|██████▉   | 183/266 [01:07<00:24,  3.44it/s]Loading train:  69%|██████▉   | 184/266 [01:08<00:23,  3.47it/s]Loading train:  70%|██████▉   | 185/266 [01:08<00:23,  3.42it/s]Loading train:  70%|██████▉   | 186/266 [01:08<00:24,  3.32it/s]Loading train:  70%|███████   | 187/266 [01:09<00:25,  3.09it/s]Loading train:  71%|███████   | 188/266 [01:09<00:26,  2.98it/s]Loading train:  71%|███████   | 189/266 [01:09<00:26,  2.90it/s]Loading train:  71%|███████▏  | 190/266 [01:10<00:25,  2.99it/s]Loading train:  72%|███████▏  | 191/266 [01:10<00:26,  2.87it/s]Loading train:  72%|███████▏  | 192/266 [01:11<00:26,  2.82it/s]Loading train:  73%|███████▎  | 193/266 [01:11<00:27,  2.65it/s]Loading train:  73%|███████▎  | 194/266 [01:11<00:27,  2.58it/s]Loading train:  73%|███████▎  | 195/266 [01:12<00:25,  2.79it/s]Loading train:  74%|███████▎  | 196/266 [01:12<00:23,  2.93it/s]Loading train:  74%|███████▍  | 197/266 [01:12<00:23,  2.88it/s]Loading train:  74%|███████▍  | 198/266 [01:13<00:25,  2.64it/s]Loading train:  75%|███████▍  | 199/266 [01:13<00:24,  2.75it/s]Loading train:  75%|███████▌  | 200/266 [01:13<00:22,  2.90it/s]Loading train:  76%|███████▌  | 201/266 [01:14<00:21,  3.01it/s]Loading train:  76%|███████▌  | 202/266 [01:14<00:20,  3.10it/s]Loading train:  76%|███████▋  | 203/266 [01:14<00:19,  3.15it/s]Loading train:  77%|███████▋  | 204/266 [01:15<00:19,  3.20it/s]Loading train:  77%|███████▋  | 205/266 [01:15<00:19,  3.14it/s]Loading train:  77%|███████▋  | 206/266 [01:15<00:19,  3.12it/s]Loading train:  78%|███████▊  | 207/266 [01:16<00:18,  3.21it/s]Loading train:  78%|███████▊  | 208/266 [01:16<00:17,  3.27it/s]Loading train:  79%|███████▊  | 209/266 [01:16<00:17,  3.29it/s]Loading train:  79%|███████▉  | 210/266 [01:16<00:17,  3.25it/s]Loading train:  79%|███████▉  | 211/266 [01:17<00:16,  3.30it/s]Loading train:  80%|███████▉  | 212/266 [01:17<00:16,  3.32it/s]Loading train:  80%|████████  | 213/266 [01:17<00:16,  3.23it/s]Loading train:  80%|████████  | 214/266 [01:18<00:16,  3.22it/s]Loading train:  81%|████████  | 215/266 [01:18<00:15,  3.28it/s]Loading train:  81%|████████  | 216/266 [01:18<00:15,  3.14it/s]Loading train:  82%|████████▏ | 217/266 [01:19<00:15,  3.11it/s]Loading train:  82%|████████▏ | 218/266 [01:19<00:15,  3.08it/s]Loading train:  82%|████████▏ | 219/266 [01:19<00:14,  3.20it/s]Loading train:  83%|████████▎ | 220/266 [01:20<00:14,  3.28it/s]Loading train:  83%|████████▎ | 221/266 [01:20<00:13,  3.23it/s]Loading train:  83%|████████▎ | 222/266 [01:20<00:14,  3.11it/s]Loading train:  84%|████████▍ | 223/266 [01:21<00:14,  3.02it/s]Loading train:  84%|████████▍ | 224/266 [01:21<00:14,  2.93it/s]Loading train:  85%|████████▍ | 225/266 [01:21<00:14,  2.81it/s]Loading train:  85%|████████▍ | 226/266 [01:22<00:14,  2.78it/s]Loading train:  85%|████████▌ | 227/266 [01:22<00:13,  2.90it/s]Loading train:  86%|████████▌ | 228/266 [01:22<00:12,  2.97it/s]Loading train:  86%|████████▌ | 229/266 [01:23<00:11,  3.12it/s]Loading train:  86%|████████▋ | 230/266 [01:23<00:11,  3.08it/s]Loading train:  87%|████████▋ | 231/266 [01:23<00:11,  2.98it/s]Loading train:  87%|████████▋ | 232/266 [01:24<00:11,  2.84it/s]Loading train:  88%|████████▊ | 233/266 [01:24<00:11,  2.98it/s]Loading train:  88%|████████▊ | 234/266 [01:24<00:10,  2.98it/s]Loading train:  88%|████████▊ | 235/266 [01:25<00:10,  2.95it/s]Loading train:  89%|████████▊ | 236/266 [01:25<00:10,  2.90it/s]Loading train:  89%|████████▉ | 237/266 [01:25<00:09,  2.92it/s]Loading train:  89%|████████▉ | 238/266 [01:26<00:09,  3.02it/s]Loading train:  90%|████████▉ | 239/266 [01:26<00:09,  2.95it/s]Loading train:  90%|█████████ | 240/266 [01:26<00:09,  2.72it/s]Loading train:  91%|█████████ | 241/266 [01:27<00:09,  2.75it/s]Loading train:  91%|█████████ | 242/266 [01:27<00:08,  2.76it/s]Loading train:  91%|█████████▏| 243/266 [01:28<00:08,  2.60it/s]Loading train:  92%|█████████▏| 244/266 [01:28<00:08,  2.55it/s]Loading train:  92%|█████████▏| 245/266 [01:28<00:08,  2.62it/s]Loading train:  92%|█████████▏| 246/266 [01:29<00:07,  2.59it/s]Loading train:  93%|█████████▎| 247/266 [01:29<00:07,  2.67it/s]Loading train:  93%|█████████▎| 248/266 [01:30<00:06,  2.70it/s]Loading train:  94%|█████████▎| 249/266 [01:30<00:06,  2.62it/s]Loading train:  94%|█████████▍| 250/266 [01:30<00:06,  2.47it/s]Loading train:  94%|█████████▍| 251/266 [01:31<00:06,  2.45it/s]Loading train:  95%|█████████▍| 252/266 [01:31<00:05,  2.44it/s]Loading train:  95%|█████████▌| 253/266 [01:32<00:05,  2.45it/s]Loading train:  95%|█████████▌| 254/266 [01:32<00:05,  2.37it/s]Loading train:  96%|█████████▌| 255/266 [01:33<00:04,  2.33it/s]Loading train:  96%|█████████▌| 256/266 [01:33<00:04,  2.37it/s]Loading train:  97%|█████████▋| 257/266 [01:33<00:03,  2.48it/s]Loading train:  97%|█████████▋| 258/266 [01:34<00:03,  2.52it/s]Loading train:  97%|█████████▋| 259/266 [01:34<00:02,  2.54it/s]Loading train:  98%|█████████▊| 260/266 [01:34<00:02,  2.51it/s]Loading train:  98%|█████████▊| 261/266 [01:35<00:02,  2.48it/s]Loading train:  98%|█████████▊| 262/266 [01:35<00:01,  2.43it/s]Loading train:  99%|█████████▉| 263/266 [01:36<00:01,  2.32it/s]Loading train:  99%|█████████▉| 264/266 [01:36<00:00,  2.32it/s]Loading train: 100%|█████████▉| 265/266 [01:37<00:00,  2.33it/s]Loading train: 100%|██████████| 266/266 [01:37<00:00,  2.40it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:00, 326.91it/s]concatenating: train:  31%|███       | 82/266 [00:00<00:00, 357.44it/s]concatenating: train:  48%|████▊     | 127/266 [00:00<00:00, 376.03it/s]concatenating: train:  65%|██████▍   | 172/266 [00:00<00:00, 395.04it/s]concatenating: train:  84%|████████▍ | 224/266 [00:00<00:00, 424.29it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 455.42it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  2.71it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  2.72it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  2.65it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  2.44it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 69.29it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<01:47,  2.46it/s]Loading trainS:   1%|          | 2/266 [00:00<01:47,  2.46it/s]Loading trainS:   1%|          | 3/266 [00:01<01:50,  2.38it/s]Loading trainS:   2%|▏         | 4/266 [00:01<01:50,  2.37it/s]Loading trainS:   2%|▏         | 5/266 [00:02<01:50,  2.37it/s]Loading trainS:   2%|▏         | 6/266 [00:02<01:58,  2.19it/s]Loading trainS:   3%|▎         | 7/266 [00:03<02:00,  2.15it/s]Loading trainS:   3%|▎         | 8/266 [00:03<01:52,  2.30it/s]Loading trainS:   3%|▎         | 9/266 [00:03<01:47,  2.40it/s]Loading trainS:   4%|▍         | 10/266 [00:04<01:48,  2.36it/s]Loading trainS:   4%|▍         | 11/266 [00:04<01:53,  2.24it/s]Loading trainS:   5%|▍         | 12/266 [00:05<01:53,  2.24it/s]Loading trainS:   5%|▍         | 13/266 [00:05<01:51,  2.27it/s]Loading trainS:   5%|▌         | 14/266 [00:06<01:54,  2.20it/s]Loading trainS:   6%|▌         | 15/266 [00:06<01:55,  2.17it/s]Loading trainS:   6%|▌         | 16/266 [00:07<01:48,  2.30it/s]Loading trainS:   6%|▋         | 17/266 [00:07<01:45,  2.35it/s]Loading trainS:   7%|▋         | 18/266 [00:07<01:48,  2.28it/s]Loading trainS:   7%|▋         | 19/266 [00:08<01:46,  2.31it/s]Loading trainS:   8%|▊         | 20/266 [00:08<01:46,  2.30it/s]Loading trainS:   8%|▊         | 21/266 [00:09<01:44,  2.34it/s]Loading trainS:   8%|▊         | 22/266 [00:09<01:48,  2.24it/s]Loading trainS:   9%|▊         | 23/266 [00:10<01:45,  2.31it/s]Loading trainS:   9%|▉         | 24/266 [00:10<01:42,  2.35it/s]Loading trainS:   9%|▉         | 25/266 [00:10<01:40,  2.41it/s]Loading trainS:  10%|▉         | 26/266 [00:11<01:33,  2.56it/s]Loading trainS:  10%|█         | 27/266 [00:11<01:31,  2.62it/s]Loading trainS:  11%|█         | 28/266 [00:11<01:28,  2.70it/s]Loading trainS:  11%|█         | 29/266 [00:12<01:31,  2.60it/s]Loading trainS:  11%|█▏        | 30/266 [00:12<01:31,  2.58it/s]Loading trainS:  12%|█▏        | 31/266 [00:13<01:29,  2.64it/s]Loading trainS:  12%|█▏        | 32/266 [00:13<01:25,  2.74it/s]Loading trainS:  12%|█▏        | 33/266 [00:13<01:22,  2.82it/s]Loading trainS:  13%|█▎        | 34/266 [00:14<01:20,  2.89it/s]Loading trainS:  13%|█▎        | 35/266 [00:14<01:19,  2.91it/s]Loading trainS:  14%|█▎        | 36/266 [00:14<01:18,  2.94it/s]Loading trainS:  14%|█▍        | 37/266 [00:15<01:17,  2.96it/s]Loading trainS:  14%|█▍        | 38/266 [00:15<01:20,  2.82it/s]Loading trainS:  15%|█▍        | 39/266 [00:15<01:21,  2.79it/s]Loading trainS:  15%|█▌        | 40/266 [00:16<01:20,  2.80it/s]Loading trainS:  15%|█▌        | 41/266 [00:16<01:18,  2.86it/s]Loading trainS:  16%|█▌        | 42/266 [00:16<01:16,  2.93it/s]Loading trainS:  16%|█▌        | 43/266 [00:17<01:11,  3.12it/s]Loading trainS:  17%|█▋        | 44/266 [00:17<01:08,  3.22it/s]Loading trainS:  17%|█▋        | 45/266 [00:17<01:11,  3.10it/s]Loading trainS:  17%|█▋        | 46/266 [00:18<01:11,  3.06it/s]Loading trainS:  18%|█▊        | 47/266 [00:18<01:11,  3.04it/s]Loading trainS:  18%|█▊        | 48/266 [00:18<01:12,  3.02it/s]Loading trainS:  18%|█▊        | 49/266 [00:19<01:14,  2.93it/s]Loading trainS:  19%|█▉        | 50/266 [00:19<01:13,  2.95it/s]Loading trainS:  19%|█▉        | 51/266 [00:19<01:11,  3.00it/s]Loading trainS:  20%|█▉        | 52/266 [00:20<01:09,  3.08it/s]Loading trainS:  20%|█▉        | 53/266 [00:20<01:06,  3.18it/s]Loading trainS:  20%|██        | 54/266 [00:20<01:07,  3.15it/s]Loading trainS:  21%|██        | 55/266 [00:20<01:04,  3.29it/s]Loading trainS:  21%|██        | 56/266 [00:21<01:02,  3.35it/s]Loading trainS:  21%|██▏       | 57/266 [00:21<01:01,  3.42it/s]Loading trainS:  22%|██▏       | 58/266 [00:21<00:59,  3.48it/s]Loading trainS:  22%|██▏       | 59/266 [00:22<00:59,  3.47it/s]Loading trainS:  23%|██▎       | 60/266 [00:22<01:05,  3.13it/s]Loading trainS:  23%|██▎       | 61/266 [00:22<01:12,  2.85it/s]Loading trainS:  23%|██▎       | 62/266 [00:23<01:08,  2.98it/s]Loading trainS:  24%|██▎       | 63/266 [00:23<01:06,  3.05it/s]Loading trainS:  24%|██▍       | 64/266 [00:23<01:07,  3.00it/s]Loading trainS:  24%|██▍       | 65/266 [00:24<01:04,  3.11it/s]Loading trainS:  25%|██▍       | 66/266 [00:24<01:04,  3.09it/s]Loading trainS:  25%|██▌       | 67/266 [00:24<01:03,  3.14it/s]Loading trainS:  26%|██▌       | 68/266 [00:25<01:02,  3.19it/s]Loading trainS:  26%|██▌       | 69/266 [00:25<01:01,  3.18it/s]Loading trainS:  26%|██▋       | 70/266 [00:25<01:06,  2.93it/s]Loading trainS:  27%|██▋       | 71/266 [00:26<01:09,  2.80it/s]Loading trainS:  27%|██▋       | 72/266 [00:26<01:13,  2.65it/s]Loading trainS:  27%|██▋       | 73/266 [00:27<01:13,  2.62it/s]Loading trainS:  28%|██▊       | 74/266 [00:27<01:08,  2.81it/s]Loading trainS:  28%|██▊       | 75/266 [00:27<01:08,  2.81it/s]Loading trainS:  29%|██▊       | 76/266 [00:28<01:08,  2.78it/s]Loading trainS:  29%|██▉       | 77/266 [00:28<01:10,  2.67it/s]Loading trainS:  29%|██▉       | 78/266 [00:28<01:14,  2.53it/s]Loading trainS:  30%|██▉       | 79/266 [00:29<01:19,  2.36it/s]Loading trainS:  30%|███       | 80/266 [00:29<01:19,  2.33it/s]Loading trainS:  30%|███       | 81/266 [00:30<01:17,  2.39it/s]Loading trainS:  31%|███       | 82/266 [00:30<01:18,  2.35it/s]Loading trainS:  31%|███       | 83/266 [00:31<01:16,  2.39it/s]Loading trainS:  32%|███▏      | 84/266 [00:31<01:14,  2.45it/s]Loading trainS:  32%|███▏      | 85/266 [00:31<01:15,  2.39it/s]Loading trainS:  32%|███▏      | 86/266 [00:32<01:18,  2.29it/s]Loading trainS:  33%|███▎      | 87/266 [00:32<01:15,  2.37it/s]Loading trainS:  33%|███▎      | 88/266 [00:33<01:12,  2.44it/s]Loading trainS:  33%|███▎      | 89/266 [00:33<01:15,  2.34it/s]Loading trainS:  34%|███▍      | 90/266 [00:34<01:15,  2.34it/s]Loading trainS:  34%|███▍      | 91/266 [00:34<01:16,  2.29it/s]Loading trainS:  35%|███▍      | 92/266 [00:34<01:17,  2.25it/s]Loading trainS:  35%|███▍      | 93/266 [00:35<01:14,  2.33it/s]Loading trainS:  35%|███▌      | 94/266 [00:35<01:16,  2.25it/s]Loading trainS:  36%|███▌      | 95/266 [00:36<01:16,  2.24it/s]Loading trainS:  36%|███▌      | 96/266 [00:36<01:11,  2.38it/s]Loading trainS:  36%|███▋      | 97/266 [00:36<01:08,  2.48it/s]Loading trainS:  37%|███▋      | 98/266 [00:37<01:05,  2.56it/s]Loading trainS:  37%|███▋      | 99/266 [00:37<01:02,  2.69it/s]Loading trainS:  38%|███▊      | 100/266 [00:38<01:00,  2.73it/s]Loading trainS:  38%|███▊      | 101/266 [00:38<00:57,  2.86it/s]Loading trainS:  38%|███▊      | 102/266 [00:38<00:57,  2.87it/s]Loading trainS:  39%|███▊      | 103/266 [00:39<00:56,  2.90it/s]Loading trainS:  39%|███▉      | 104/266 [00:39<00:53,  3.05it/s]Loading trainS:  39%|███▉      | 105/266 [00:39<00:50,  3.16it/s]Loading trainS:  40%|███▉      | 106/266 [00:39<00:49,  3.23it/s]Loading trainS:  40%|████      | 107/266 [00:40<00:50,  3.15it/s]Loading trainS:  41%|████      | 108/266 [00:40<00:51,  3.09it/s]Loading trainS:  41%|████      | 109/266 [00:40<00:49,  3.18it/s]Loading trainS:  41%|████▏     | 110/266 [00:41<00:48,  3.22it/s]Loading trainS:  42%|████▏     | 111/266 [00:41<00:48,  3.18it/s]Loading trainS:  42%|████▏     | 112/266 [00:41<00:47,  3.24it/s]Loading trainS:  42%|████▏     | 113/266 [00:42<00:46,  3.30it/s]Loading trainS:  43%|████▎     | 114/266 [00:42<00:45,  3.34it/s]Loading trainS:  43%|████▎     | 115/266 [00:42<00:44,  3.37it/s]Loading trainS:  44%|████▎     | 116/266 [00:42<00:44,  3.39it/s]Loading trainS:  44%|████▍     | 117/266 [00:43<00:43,  3.40it/s]Loading trainS:  44%|████▍     | 118/266 [00:43<00:43,  3.41it/s]Loading trainS:  45%|████▍     | 119/266 [00:43<00:45,  3.24it/s]Loading trainS:  45%|████▌     | 120/266 [00:44<00:48,  3.01it/s]Loading trainS:  45%|████▌     | 121/266 [00:44<00:56,  2.59it/s]Loading trainS:  46%|████▌     | 122/266 [00:45<00:57,  2.50it/s]Loading trainS:  46%|████▌     | 123/266 [00:45<00:58,  2.46it/s]Loading trainS:  47%|████▋     | 124/266 [00:46<00:57,  2.48it/s]Loading trainS:  47%|████▋     | 125/266 [00:46<00:59,  2.36it/s]Loading trainS:  47%|████▋     | 126/266 [00:47<01:03,  2.22it/s]Loading trainS:  48%|████▊     | 127/266 [00:47<01:05,  2.14it/s]Loading trainS:  48%|████▊     | 128/266 [00:47<01:01,  2.24it/s]Loading trainS:  48%|████▊     | 129/266 [00:48<01:00,  2.28it/s]Loading trainS:  49%|████▉     | 130/266 [00:48<00:59,  2.29it/s]Loading trainS:  49%|████▉     | 131/266 [00:49<00:57,  2.33it/s]Loading trainS:  50%|████▉     | 132/266 [00:49<01:00,  2.21it/s]Loading trainS:  50%|█████     | 133/266 [00:50<00:59,  2.24it/s]Loading trainS:  50%|█████     | 134/266 [00:50<00:56,  2.32it/s]Loading trainS:  51%|█████     | 135/266 [00:50<00:56,  2.33it/s]Loading trainS:  51%|█████     | 136/266 [00:51<00:58,  2.24it/s]Loading trainS:  52%|█████▏    | 137/266 [00:51<00:56,  2.28it/s]Loading trainS:  52%|█████▏    | 138/266 [00:52<00:54,  2.36it/s]Loading trainS:  52%|█████▏    | 139/266 [00:52<00:55,  2.31it/s]Loading trainS:  53%|█████▎    | 140/266 [00:53<00:54,  2.29it/s]Loading trainS:  53%|█████▎    | 141/266 [00:53<00:51,  2.42it/s]Loading trainS:  53%|█████▎    | 142/266 [00:53<00:48,  2.54it/s]Loading trainS:  54%|█████▍    | 143/266 [00:54<00:45,  2.70it/s]Loading trainS:  54%|█████▍    | 144/266 [00:54<00:42,  2.84it/s]Loading trainS:  55%|█████▍    | 145/266 [00:54<00:41,  2.90it/s]Loading trainS:  55%|█████▍    | 146/266 [00:55<00:40,  2.96it/s]Loading trainS:  55%|█████▌    | 147/266 [00:55<00:42,  2.81it/s]Loading trainS:  56%|█████▌    | 148/266 [00:55<00:41,  2.85it/s]Loading trainS:  56%|█████▌    | 149/266 [00:56<00:39,  2.94it/s]Loading trainS:  56%|█████▋    | 150/266 [00:56<00:40,  2.88it/s]Loading trainS:  57%|█████▋    | 151/266 [00:56<00:41,  2.80it/s]Loading trainS:  57%|█████▋    | 152/266 [00:57<00:39,  2.90it/s]Loading trainS:  58%|█████▊    | 153/266 [00:57<00:38,  2.93it/s]Loading trainS:  58%|█████▊    | 154/266 [00:57<00:37,  3.01it/s]Loading trainS:  58%|█████▊    | 155/266 [00:58<00:36,  3.04it/s]Loading trainS:  59%|█████▊    | 156/266 [00:58<00:35,  3.08it/s]Loading trainS:  59%|█████▉    | 157/266 [00:58<00:34,  3.12it/s]Loading trainS:  59%|█████▉    | 158/266 [00:59<00:34,  3.14it/s]Loading trainS:  60%|█████▉    | 159/266 [00:59<00:35,  3.05it/s]Loading trainS:  60%|██████    | 160/266 [00:59<00:34,  3.08it/s]Loading trainS:  61%|██████    | 161/266 [01:00<00:32,  3.24it/s]Loading trainS:  61%|██████    | 162/266 [01:00<00:31,  3.32it/s]Loading trainS:  61%|██████▏   | 163/266 [01:00<00:30,  3.40it/s]Loading trainS:  62%|██████▏   | 164/266 [01:00<00:29,  3.43it/s]Loading trainS:  62%|██████▏   | 165/266 [01:01<00:29,  3.46it/s]Loading trainS:  62%|██████▏   | 166/266 [01:01<00:30,  3.33it/s]Loading trainS:  63%|██████▎   | 167/266 [01:01<00:29,  3.31it/s]Loading trainS:  63%|██████▎   | 168/266 [01:02<00:29,  3.35it/s]Loading trainS:  64%|██████▎   | 169/266 [01:02<00:28,  3.38it/s]Loading trainS:  64%|██████▍   | 170/266 [01:02<00:28,  3.39it/s]Loading trainS:  64%|██████▍   | 171/266 [01:03<00:27,  3.39it/s]Loading trainS:  65%|██████▍   | 172/266 [01:03<00:27,  3.41it/s]Loading trainS:  65%|██████▌   | 173/266 [01:03<00:28,  3.28it/s]Loading trainS:  65%|██████▌   | 174/266 [01:03<00:28,  3.26it/s]Loading trainS:  66%|██████▌   | 175/266 [01:04<00:27,  3.28it/s]Loading trainS:  66%|██████▌   | 176/266 [01:04<00:28,  3.12it/s]Loading trainS:  67%|██████▋   | 177/266 [01:04<00:27,  3.23it/s]Loading trainS:  67%|██████▋   | 178/266 [01:05<00:26,  3.27it/s]Loading trainS:  67%|██████▋   | 179/266 [01:05<00:27,  3.22it/s]Loading trainS:  68%|██████▊   | 180/266 [01:05<00:26,  3.28it/s]Loading trainS:  68%|██████▊   | 181/266 [01:06<00:25,  3.34it/s]Loading trainS:  68%|██████▊   | 182/266 [01:06<00:24,  3.36it/s]Loading trainS:  69%|██████▉   | 183/266 [01:06<00:25,  3.24it/s]Loading trainS:  69%|██████▉   | 184/266 [01:07<00:25,  3.20it/s]Loading trainS:  70%|██████▉   | 185/266 [01:07<00:24,  3.28it/s]Loading trainS:  70%|██████▉   | 186/266 [01:07<00:23,  3.34it/s]Loading trainS:  70%|███████   | 187/266 [01:07<00:23,  3.31it/s]Loading trainS:  71%|███████   | 188/266 [01:08<00:24,  3.23it/s]Loading trainS:  71%|███████   | 189/266 [01:08<00:23,  3.30it/s]Loading trainS:  71%|███████▏  | 190/266 [01:08<00:23,  3.20it/s]Loading trainS:  72%|███████▏  | 191/266 [01:09<00:24,  3.08it/s]Loading trainS:  72%|███████▏  | 192/266 [01:09<00:23,  3.20it/s]Loading trainS:  73%|███████▎  | 193/266 [01:09<00:22,  3.22it/s]Loading trainS:  73%|███████▎  | 194/266 [01:10<00:23,  3.03it/s]Loading trainS:  73%|███████▎  | 195/266 [01:10<00:24,  2.92it/s]Loading trainS:  74%|███████▎  | 196/266 [01:10<00:24,  2.81it/s]Loading trainS:  74%|███████▍  | 197/266 [01:11<00:24,  2.79it/s]Loading trainS:  74%|███████▍  | 198/266 [01:11<00:24,  2.79it/s]Loading trainS:  75%|███████▍  | 199/266 [01:12<00:24,  2.70it/s]Loading trainS:  75%|███████▌  | 200/266 [01:12<00:26,  2.50it/s]Loading trainS:  76%|███████▌  | 201/266 [01:12<00:26,  2.44it/s]Loading trainS:  76%|███████▌  | 202/266 [01:13<00:24,  2.64it/s]Loading trainS:  76%|███████▋  | 203/266 [01:13<00:22,  2.79it/s]Loading trainS:  77%|███████▋  | 204/266 [01:13<00:21,  2.83it/s]Loading trainS:  77%|███████▋  | 205/266 [01:14<00:20,  2.96it/s]Loading trainS:  77%|███████▋  | 206/266 [01:14<00:20,  2.95it/s]Loading trainS:  78%|███████▊  | 207/266 [01:14<00:20,  2.94it/s]Loading trainS:  78%|███████▊  | 208/266 [01:15<00:19,  3.02it/s]Loading trainS:  79%|███████▊  | 209/266 [01:15<00:18,  3.09it/s]Loading trainS:  79%|███████▉  | 210/266 [01:15<00:18,  2.99it/s]Loading trainS:  79%|███████▉  | 211/266 [01:16<00:18,  2.95it/s]Loading trainS:  80%|███████▉  | 212/266 [01:16<00:18,  2.95it/s]Loading trainS:  80%|████████  | 213/266 [01:16<00:17,  3.00it/s]Loading trainS:  80%|████████  | 214/266 [01:17<00:16,  3.07it/s]Loading trainS:  81%|████████  | 215/266 [01:17<00:15,  3.21it/s]Loading trainS:  81%|████████  | 216/266 [01:17<00:15,  3.23it/s]Loading trainS:  82%|████████▏ | 217/266 [01:18<00:15,  3.16it/s]Loading trainS:  82%|████████▏ | 218/266 [01:18<00:15,  3.12it/s]Loading trainS:  82%|████████▏ | 219/266 [01:18<00:15,  3.12it/s]Loading trainS:  83%|████████▎ | 220/266 [01:19<00:15,  3.01it/s]Loading trainS:  83%|████████▎ | 221/266 [01:19<00:15,  2.88it/s]Loading trainS:  83%|████████▎ | 222/266 [01:19<00:15,  2.93it/s]Loading trainS:  84%|████████▍ | 223/266 [01:20<00:14,  2.97it/s]Loading trainS:  84%|████████▍ | 224/266 [01:20<00:14,  2.96it/s]Loading trainS:  85%|████████▍ | 225/266 [01:20<00:13,  3.07it/s]Loading trainS:  85%|████████▍ | 226/266 [01:21<00:12,  3.19it/s]Loading trainS:  85%|████████▌ | 227/266 [01:21<00:11,  3.28it/s]Loading trainS:  86%|████████▌ | 228/266 [01:21<00:12,  3.07it/s]Loading trainS:  86%|████████▌ | 229/266 [01:22<00:11,  3.10it/s]Loading trainS:  86%|████████▋ | 230/266 [01:22<00:11,  3.12it/s]Loading trainS:  87%|████████▋ | 231/266 [01:22<00:10,  3.21it/s]Loading trainS:  87%|████████▋ | 232/266 [01:22<00:10,  3.29it/s]Loading trainS:  88%|████████▊ | 233/266 [01:23<00:09,  3.34it/s]Loading trainS:  88%|████████▊ | 234/266 [01:23<00:10,  3.20it/s]Loading trainS:  88%|████████▊ | 235/266 [01:23<00:10,  2.99it/s]Loading trainS:  89%|████████▊ | 236/266 [01:24<00:09,  3.02it/s]Loading trainS:  89%|████████▉ | 237/266 [01:24<00:09,  3.00it/s]Loading trainS:  89%|████████▉ | 238/266 [01:24<00:09,  3.00it/s]Loading trainS:  90%|████████▉ | 239/266 [01:25<00:09,  2.97it/s]Loading trainS:  90%|█████████ | 240/266 [01:25<00:08,  2.94it/s]Loading trainS:  91%|█████████ | 241/266 [01:26<00:08,  2.83it/s]Loading trainS:  91%|█████████ | 242/266 [01:26<00:09,  2.60it/s]Loading trainS:  91%|█████████▏| 243/266 [01:26<00:08,  2.62it/s]Loading trainS:  92%|█████████▏| 244/266 [01:27<00:08,  2.70it/s]Loading trainS:  92%|█████████▏| 245/266 [01:27<00:07,  2.73it/s]Loading trainS:  92%|█████████▏| 246/266 [01:27<00:07,  2.59it/s]Loading trainS:  93%|█████████▎| 247/266 [01:28<00:07,  2.59it/s]Loading trainS:  93%|█████████▎| 248/266 [01:28<00:06,  2.75it/s]Loading trainS:  94%|█████████▎| 249/266 [01:29<00:06,  2.74it/s]Loading trainS:  94%|█████████▍| 250/266 [01:29<00:05,  2.74it/s]Loading trainS:  94%|█████████▍| 251/266 [01:29<00:05,  2.83it/s]Loading trainS:  95%|█████████▍| 252/266 [01:30<00:04,  2.88it/s]Loading trainS:  95%|█████████▌| 253/266 [01:30<00:04,  2.92it/s]Loading trainS:  95%|█████████▌| 254/266 [01:30<00:04,  2.95it/s]Loading trainS:  96%|█████████▌| 255/266 [01:31<00:03,  2.98it/s]Loading trainS:  96%|█████████▌| 256/266 [01:31<00:03,  2.95it/s]Loading trainS:  97%|█████████▋| 257/266 [01:31<00:03,  2.75it/s]Loading trainS:  97%|█████████▋| 258/266 [01:32<00:02,  2.81it/s]Loading trainS:  97%|█████████▋| 259/266 [01:32<00:02,  2.54it/s]Loading trainS:  98%|█████████▊| 260/266 [01:33<00:02,  2.57it/s]Loading trainS:  98%|█████████▊| 261/266 [01:33<00:02,  2.42it/s]Loading trainS:  98%|█████████▊| 262/266 [01:33<00:01,  2.32it/s]Loading trainS:  99%|█████████▉| 263/266 [01:34<00:01,  2.26it/s]Loading trainS:  99%|█████████▉| 264/266 [01:34<00:00,  2.26it/s]Loading trainS: 100%|█████████▉| 265/266 [01:35<00:00,  2.17it/s]Loading trainS: 100%|██████████| 266/266 [01:35<00:00,  2.11it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  2.31it/s]Loading testS:  50%|█████     | 2/4 [00:00<00:00,  2.42it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  2.51it/s]Loading testS: 100%|██████████| 4/4 [00:01<00:00,  2.54it/s]2019-07-28 18:16:54.205562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 18:16:54.205680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 18:16:54.205700: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 18:16:54.205710: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 18:16:54.206159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.16it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.80it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.39it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.34it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.39it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.26it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.74it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.13it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.86it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.14it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.10it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.03it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.69it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.00it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.26it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.46it/s]
Epoch 00058: val_mDice did not improve from 0.64670
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [0.8101306648443867, 0.7096596095735663, 0.5351369412529547, 0.5190321933354763, 0.49560064906316087, 0.509871453244165, 0.47803050832243155, 0.835857623460277, 0.5379632198257952, 0.5043006634080647, 0.4835653423473535, 0.46508443868712873, 0.48161540007749143, 0.4891676263303946, 0.510246588299606, 0.4611336971750323, 0.4518186453951905, 0.4456011037163387, 0.4636719933408775, 0.4563427263537779, 0.46982453714143363, 0.45168555927592396, 0.4564823121424542, 0.4524147660527008, 0.5240961479035434, 0.4452914832443591, 0.4387105079676142, 1.1069594530869793, 0.45497437699741083, 0.5000833012410347, 0.4410193929609084, 0.4309970768082221, 0.4487909729907055, 0.47031761281537693, 0.45357603229434285, 0.57957056737104, 0.43514964556851926, 0.4401505636853098, 0.43297351906631165, 0.42797264358065773, 0.43596176714297163, 0.474516007284455, 0.4201198768931509, 0.4317565122187532, 0.4373191843759145, 0.4283708886594962, 0.5419314957612398, 0.4346823475218767, 0.431063459014261, 0.4283054838117385, 0.4394250452913196, 0.4494388470586562, 0.46026854049291044, 0.4392003606486794, 0.4290834365301574, 0.43308687091663184, 0.4412843770538734, 0.43490113643620976], 'val_acc': [0.9172594570955693, 0.932040362958087, 0.950375087213832, 0.9533164256455883, 0.9504615352643246, 0.9522809015204575, 0.9520064584466795, 0.950898161787071, 0.9438390088397146, 0.948874101338797, 0.9529964963331917, 0.9513772722111632, 0.9529494982681527, 0.949903571842522, 0.953613569799638, 0.9513302792776499, 0.9527418041071355, 0.9529434442520142, 0.9485071972505936, 0.9525492408417708, 0.9519321875066946, 0.9530359143452929, 0.9506783224888985, 0.9529813476745655, 0.9527660442503872, 0.9524416007742976, 0.9513469405521621, 0.9489256534355366, 0.9523491204179675, 0.9452383885320449, 0.9495487840759833, 0.9514606523987473, 0.9519867628615424, 0.9511847322350306, 0.9533315778568091, 0.9533482553153638, 0.9518002733489536, 0.9494471996035797, 0.9527933597564697, 0.9516486545272221, 0.9523946078407843, 0.9454627779145904, 0.9521004620766798, 0.9501885973065105, 0.9515197904694159, 0.9538258227291486, 0.9529965125172344, 0.9496276497051416, 0.9524264394842237, 0.9521201860825748, 0.9500991579712621, 0.9501234020618413, 0.9540926802237302, 0.9516895993655881, 0.9528843172338625, 0.9521080358138937, 0.9522899878735573, 0.9507268386960819], 'val_mDice': [0.4695993780300317, 0.5166423636556461, 0.6095894519856434, 0.6203964451290914, 0.630021332115527, 0.6183709332485072, 0.6361838800228194, 0.5777128090132151, 0.6040918708637061, 0.6170912886297466, 0.6306421875164209, 0.6386016970438673, 0.6269754755575925, 0.6243354042634269, 0.6149444753760533, 0.6390218505796218, 0.6430717493524615, 0.6466997775020978, 0.6317502023368482, 0.6359808294978363, 0.6310607621211879, 0.6377145351953064, 0.6327375078832866, 0.6358443309139732, 0.6077048004857751, 0.6392170853962172, 0.6386053877950504, 0.5441714300225112, 0.6314719749602261, 0.6078191150892649, 0.6359693822481775, 0.6411419798996275, 0.6312554837852125, 0.6297146247712192, 0.6323501961120707, 0.5888800944713567, 0.638116787600991, 0.6332656602985811, 0.6396320481963506, 0.6409597317904037, 0.6387245970846012, 0.6128605430489344, 0.6438700173864301, 0.6359636980966227, 0.6348925118414771, 0.6408591736231418, 0.595336738011695, 0.6347948944331795, 0.6379325066181208, 0.6373156972278823, 0.6318477605352338, 0.6314769091195618, 0.6295304424715358, 0.6359734677321074, 0.639519134894112, 0.6373777294790508, 0.6321667440679689, 0.635953296888743], 'loss': [1.6278990711662322, 0.6104903489699652, 0.5291693474737161, 0.45523679450495486, 0.43198416809703566, 0.41180007283370423, 0.4018448689815192, 0.41080480868684394, 0.4478484738300347, 0.43263736070382885, 0.3902582602562645, 0.37515632873133825, 0.36645387161896315, 0.41154669767508195, 0.3603848881012529, 0.3807500743103562, 0.344142015049877, 0.33741520906505856, 0.3368628057301672, 0.3280080285824136, 0.4345019413887988, 0.3623272129595884, 0.3501316554280781, 0.3668030496726645, 0.38396019610146165, 0.3393200446460434, 0.33931061986816896, 0.3480747423647867, 0.38530738172226164, 0.3808657295887464, 0.3623178713495127, 0.34549650801816273, 0.36698387170365415, 0.36978403893245865, 0.34976921016128154, 0.3410914202506226, 0.38315547537013606, 0.34577403140752144, 0.3446210184865223, 0.3325263691828362, 0.3409723458330639, 0.335681785063955, 0.3294549683317126, 0.3273789474450728, 0.33239682350581584, 0.31382262656658977, 0.3124512641882046, 0.36245542294782623, 0.3349347894646191, 0.32476861755486996, 0.38203272071740163, 0.3438715819874405, 0.32126773676887455, 0.37067954460326835, 0.34578688641513977, 0.3246603989449115, 0.3159254764764277, 0.33653335965275133], 'acc': [0.7915513913446136, 0.9065031888300458, 0.9262625669272162, 0.9360164273085773, 0.9400372254008913, 0.9414863362598852, 0.9427018885554443, 0.9419461597729254, 0.9398402250650344, 0.9407645576979824, 0.9436377239922903, 0.9453138268957875, 0.9464135106929016, 0.9421278993561237, 0.945989053619736, 0.9445269795710678, 0.9473324251075883, 0.9480566584526104, 0.9486414920349718, 0.9485919665062603, 0.9404134906762902, 0.9455996537171704, 0.9465387811258603, 0.9451761723843051, 0.9454498087803577, 0.9477953635233173, 0.9475049173275684, 0.9475924595521045, 0.9435258790751307, 0.9441537256863207, 0.9451602700309193, 0.9467351407708091, 0.9445425282756023, 0.9453989831667201, 0.9469011988216939, 0.9473147736161404, 0.9441622842591623, 0.9474620547067507, 0.9468415917641713, 0.9482793812705242, 0.9481376300409973, 0.9481985857954073, 0.9485679028253258, 0.9488674390547495, 0.9481218821264652, 0.9498260333715182, 0.9498721454215158, 0.9464404922489406, 0.9478953765528338, 0.9488223442684889, 0.9447152873834266, 0.9474108051866762, 0.9490259127240978, 0.9456284071279486, 0.9470485675773717, 0.9486179990004184, 0.9496431199148327, 0.948154882231423], 'mDice': [0.29346965013805903, 0.5369660306807221, 0.5841662049806011, 0.623610249187057, 0.6379639235640158, 0.6498507447961839, 0.6569411731459601, 0.6511115904085165, 0.6305574410440334, 0.6415404936559833, 0.6641672671607077, 0.6741650306611876, 0.6829537080652863, 0.6526561510492644, 0.6845957562694479, 0.6715965539191082, 0.6953591055690856, 0.7004454839939012, 0.7048851492617766, 0.7071939539061735, 0.6406173523284769, 0.682804224869961, 0.6918461408623375, 0.6801044297913931, 0.6765135665433255, 0.6992176501414198, 0.6986583311532893, 0.6954277962901122, 0.6680996761571644, 0.6715622376591189, 0.6827793564845739, 0.6943479318104439, 0.6805542045218992, 0.6797595069527845, 0.6920138879906508, 0.6981563616784059, 0.671281188124678, 0.6985587752299566, 0.6951379554506177, 0.7040120137738625, 0.6993071019661022, 0.7024008526040579, 0.7054866010780415, 0.707337543484946, 0.7037894420895112, 0.7172749737169118, 0.7186218847135291, 0.685270789253828, 0.7026987873106323, 0.7096561628242942, 0.6722727953227358, 0.695860120982044, 0.7119113323066836, 0.6813096917781207, 0.6951035716898509, 0.7095828487275706, 0.7158992467278065, 0.7033356651886916]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 108, 116, 20) 0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 108, 116, 20) 0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 108, 116, 21) 0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 108, 116, 20) 3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 108, 116, 20) 80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 108, 116, 20) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 108, 116, 20) 3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 108, 116, 20) 80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 108, 116, 20) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 54, 58, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 54, 58, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 58, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 54, 58, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 54, 58, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 58, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 54, 58, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 27, 29, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 27, 29, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 27, 29, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 27, 29, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 27, 29, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 27, 29, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 27, 29, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 27, 29, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 54, 58, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 58, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 54, 58, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 54, 58, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 54, 58, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 58, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 54, 58, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 20) 7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 108, 116, 20) 80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 108, 116, 20) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 108, 116, 20) 3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 108, 116, 20) 80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 108, 116, 20) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 108, 116, 60) 0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 108, 116, 60) 0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 108, 116, 20) 10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 108, 116, 20) 80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 108, 116, 20) 0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 108, 116, 20) 0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 108, 116, 20) 3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 108, 116, 20) 80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 108, 116, 20) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 108, 116, 20) 0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 108, 116, 80) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 108, 116, 2)  162         concatenate_8[0][0]              
==================================================================================================
Total params: 245,382
Trainable params: 70,542
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 256 samples
Epoch 1/300
 - 56s - loss: 0.2950 - acc: 0.9716 - mDice: 0.6413 - val_loss: 0.3853 - val_acc: 0.9889 - val_mDice: 0.7438

Epoch 00001: val_mDice improved from -inf to 0.74377, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 51s - loss: 0.1044 - acc: 0.9891 - mDice: 0.8193 - val_loss: 0.3167 - val_acc: 0.9903 - val_mDice: 0.7531

Epoch 00002: val_mDice improved from 0.74377 to 0.75312, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 51s - loss: 0.0889 - acc: 0.9906 - mDice: 0.8424 - val_loss: 0.2809 - val_acc: 0.9916 - val_mDice: 0.7962

Epoch 00003: val_mDice improved from 0.75312 to 0.79622, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 50s - loss: 0.0813 - acc: 0.9913 - mDice: 0.8546 - val_loss: 0.4370 - val_acc: 0.9879 - val_mDice: 0.6221

Epoch 00004: val_mDice did not improve from 0.79622
Epoch 5/300
 - 52s - loss: 0.0768 - acc: 0.9917 - mDice: 0.8620 - val_loss: 0.3368 - val_acc: 0.9910 - val_mDice: 0.8050

Epoch 00005: val_mDice improved from 0.79622 to 0.80500, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 52s - loss: 0.0723 - acc: 0.9921 - mDice: 0.8694 - val_loss: 0.3275 - val_acc: 0.9913 - val_mDice: 0.8057

Epoch 00006: val_mDice improved from 0.80500 to 0.80573, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 53s - loss: 0.0710 - acc: 0.9923 - mDice: 0.8716 - val_loss: 0.2656 - val_acc: 0.9920 - val_mDice: 0.7939

Epoch 00007: val_mDice did not improve from 0.80573
Epoch 8/300
 - 53s - loss: 0.0669 - acc: 0.9926 - mDice: 0.8784 - val_loss: 0.2495 - val_acc: 0.9922 - val_mDice: 0.8049

Epoch 00008: val_mDice did not improve from 0.80573
Epoch 9/300
 - 52s - loss: 0.0656 - acc: 0.9928 - mDice: 0.8807 - val_loss: 0.2633 - val_acc: 0.9928 - val_mDice: 0.8296

Epoch 00009: val_mDice improved from 0.80573 to 0.82963, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 53s - loss: 0.0645 - acc: 0.9929 - mDice: 0.8825 - val_loss: 0.2895 - val_acc: 0.9925 - val_mDice: 0.8295

Epoch 00010: val_mDice did not improve from 0.82963
Epoch 11/300
 - 53s - loss: 0.0617 - acc: 0.9931 - mDice: 0.8874 - val_loss: 0.2363 - val_acc: 0.9930 - val_mDice: 0.8330

Epoch 00011: val_mDice improved from 0.82963 to 0.83298, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 53s - loss: 0.0607 - acc: 0.9932 - mDice: 0.8891 - val_loss: 0.3660 - val_acc: 0.9883 - val_mDice: 0.7739

Epoch 00012: val_mDice did not improve from 0.83298
Epoch 13/300
 - 54s - loss: 0.0593 - acc: 0.9934 - mDice: 0.8915 - val_loss: 0.3657 - val_acc: 0.9871 - val_mDice: 0.7551

Epoch 00013: val_mDice did not improve from 0.83298
Epoch 14/300
 - 54s - loss: 0.0584 - acc: 0.9934 - mDice: 0.8931 - val_loss: 0.3726 - val_acc: 0.9872 - val_mDice: 0.7540

Epoch 00014: val_mDice did not improve from 0.83298
Epoch 15/300
 - 53s - loss: 0.0573 - acc: 0.9935 - mDice: 0.8948 - val_loss: 0.2292 - val_acc: 0.9932 - val_mDice: 0.8255

Epoch 00015: val_mDice did not improve from 0.83298
Epoch 16/300
 - 54s - loss: 0.0564 - acc: 0.9936 - mDice: 0.8965 - val_loss: 0.3129 - val_acc: 0.9912 - val_mDice: 0.8174

Epoch 00016: val_mDice did not improve from 0.83298
Epoch 17/300
 - 53s - loss: 0.0559 - acc: 0.9937 - mDice: 0.8974 - val_loss: 0.2114 - val_acc: 0.9931 - val_mDice: 0.8269

Epoch 00017: val_mDice did not improve from 0.83298
Epoch 18/300
 - 54s - loss: 0.0549 - acc: 0.9938 - mDice: 0.8990 - val_loss: 0.2242 - val_acc: 0.9931 - val_mDice: 0.8320

Epoch 00018: val_mDice did not improve from 0.83298
Epoch 19/300
 - 53s - loss: 0.0546 - acc: 0.9938 - mDice: 0.8996 - val_loss: 0.2732 - val_acc: 0.9919 - val_mDice: 0.8246

Epoch 00019: val_mDice did not improve from 0.83298
Epoch 20/300
 - 63s - loss: 0.0534 - acc: 0.9939 - mDice: 0.9017 - val_loss: 0.2888 - val_acc: 0.9914 - val_mDice: 0.8155

Epoch 00020: val_mDice did not improve from 0.83298
Epoch 21/300
 - 63s - loss: 0.0527 - acc: 0.9940 - mDice: 0.9028 - val_loss: 0.1991 - val_acc: 0.9931 - val_mDice: 0.8422

Epoch 00021: val_mDice improved from 0.83298 to 0.84225, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 53s - loss: 0.0520 - acc: 0.9940 - mDice: 0.9040 - val_loss: 0.2919 - val_acc: 0.9925 - val_mDice: 0.8340

Epoch 00022: val_mDice did not improve from 0.84225
Epoch 23/300
 - 56s - loss: 0.0517 - acc: 0.9941 - mDice: 0.9047 - val_loss: 0.1960 - val_acc: 0.9928 - val_mDice: 0.8353

Epoch 00023: val_mDice did not improve from 0.84225
Epoch 24/300
 - 57s - loss: 0.0518 - acc: 0.9941 - mDice: 0.9045 - val_loss: 0.3171 - val_acc: 0.9896 - val_mDice: 0.7906

Epoch 00024: val_mDice did not improve from 0.84225
Epoch 25/300
 - 53s - loss: 0.0511 - acc: 0.9941 - mDice: 0.9058 - val_loss: 0.8884 - val_acc: 0.9838 - val_mDice: 0.3616

Epoch 00025: val_mDice did not improve from 0.84225
Epoch 26/300
 - 53s - loss: 0.0535 - acc: 0.9939 - mDice: 0.9015 - val_loss: 0.1840 - val_acc: 0.9931 - val_mDice: 0.8269

Epoch 00026: val_mDice did not improve from 0.84225
Epoch 27/300
 - 53s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.2756 - val_acc: 0.9931 - val_mDice: 0.8420

Epoch 00027: val_mDice did not improve from 0.84225
Epoch 28/300
 - 53s - loss: 0.0493 - acc: 0.9943 - mDice: 0.9089 - val_loss: 0.1948 - val_acc: 0.9931 - val_mDice: 0.8207

Epoch 00028: val_mDice did not improve from 0.84225
Epoch 29/300
 - 53s - loss: 0.0491 - acc: 0.9943 - mDice: 0.9093 - val_loss: 0.2641 - val_acc: 0.9923 - val_mDice: 0.8305

Epoch 00029: val_mDice did not improve from 0.84225
Epoch 30/300
 - 53s - loss: 0.0486 - acc: 0.9944 - mDice: 0.9100 - val_loss: 0.3097 - val_acc: 0.9918 - val_mDice: 0.8259

Epoch 00030: val_mDice did not improve from 0.84225
Epoch 31/300
 - 53s - loss: 0.0488 - acc: 0.9943 - mDice: 0.9098 - val_loss: 0.1622 - val_acc: 0.9930 - val_mDice: 0.8414

Epoch 00031: val_mDice did not improve from 0.84225
Epoch 32/300
 - 54s - loss: 0.0480 - acc: 0.9944 - mDice: 0.9111 - val_loss: 0.1742 - val_acc: 0.9934 - val_mDice: 0.8323

Epoch 00032: val_mDice did not improve from 0.84225
Epoch 33/300
 - 54s - loss: 0.0475 - acc: 0.9945 - mDice: 0.9120 - val_loss: 0.1861 - val_acc: 0.9929 - val_mDice: 0.8106

Epoch 00033: val_mDice did not improve from 0.84225
Epoch 34/300
 - 55s - loss: 0.0469 - acc: 0.9945 - mDice: 0.9130 - val_loss: 0.1676 - val_acc: 0.9927 - val_mDice: 0.8344

Epoch 00034: val_mDice did not improve from 0.84225
Epoch 35/300
 - 55s - loss: 0.0472 - acc: 0.9945 - mDice: 0.9125 - val_loss: 0.1641 - val_acc: 0.9931 - val_mDice: 0.8406

Epoch 00035: val_mDice did not improve from 0.84225
Epoch 36/300
 - 53s - loss: 0.0462 - acc: 0.9946 - mDice: 0.9143 - val_loss: 0.2772 - val_acc: 0.9935 - val_mDice: 0.8459

Epoch 00036: val_mDice improved from 0.84225 to 0.84586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 54s - loss: 0.0462 - acc: 0.9946 - mDice: 0.9143 - val_loss: 0.3170 - val_acc: 0.9914 - val_mDice: 0.8170

Epoch 00037: val_mDice did not improve from 0.84586
Epoch 38/300
 - 53s - loss: 0.0459 - acc: 0.9946 - mDice: 0.9148 - val_loss: 0.1640 - val_acc: 0.9936 - val_mDice: 0.8435

Epoch 00038: val_mDice did not improve from 0.84586
Epoch 39/300
 - 53s - loss: 0.0453 - acc: 0.9947 - mDice: 0.9159 - val_loss: 0.3082 - val_acc: 0.9918 - val_mDice: 0.8286

Epoch 00039: val_mDice did not improve from 0.84586
Epoch 40/300
 - 53s - loss: 0.0457 - acc: 0.9947 - mDice: 0.9152 - val_loss: 0.1628 - val_acc: 0.9932 - val_mDice: 0.8287

Epoch 00040: val_mDice did not improve from 0.84586
Epoch 41/300
 - 53s - loss: 0.0445 - acc: 0.9948 - mDice: 0.9173 - val_loss: 0.3164 - val_acc: 0.9909 - val_mDice: 0.8134

Epoch 00041: val_mDice did not improve from 0.84586
Epoch 42/300
 - 52s - loss: 0.0451 - acc: 0.9947 - mDice: 0.9163 - val_loss: 0.1720 - val_acc: 0.9931 - val_mDice: 0.8212

Epoch 00042: val_mDice did not improve from 0.84586
Epoch 43/300
 - 52s - loss: 0.0441 - acc: 0.9948 - mDice: 0.9180 - val_loss: 0.1593 - val_acc: 0.9929 - val_mDice: 0.8235

Epoch 00043: val_mDice did not improve from 0.84586
Epoch 44/300
 - 51s - loss: 0.0439 - acc: 0.9948 - mDice: 0.9184 - val_loss: 0.3046 - val_acc: 0.9922 - val_mDice: 0.8271

Epoch 00044: val_mDice did not improve from 0.84586
Epoch 45/300
 - 51s - loss: 0.0437 - acc: 0.9948 - mDice: 0.9187 - val_loss: 0.1692 - val_acc: 0.9934 - val_mDice: 0.8362

Epoch 00045: val_mDice did not improve from 0.84586
Epoch 46/300
 - 51s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9190 - val_loss: 0.2770 - val_acc: 0.9936 - val_mDice: 0.8473

Epoch 00046: val_mDice improved from 0.84586 to 0.84732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 47/300
 - 51s - loss: 0.0430 - acc: 0.9949 - mDice: 0.9199 - val_loss: 0.2717 - val_acc: 0.9936 - val_mDice: 0.8448

Epoch 00047: val_mDice did not improve from 0.84732
Epoch 48/300
 - 52s - loss: 0.0431 - acc: 0.9949 - mDice: 0.9198 - val_loss: 0.3008 - val_acc: 0.9930 - val_mDice: 0.8300

Epoch 00048: val_mDice did not improve from 0.84732
Epoch 49/300
 - 51s - loss: 0.0434 - acc: 0.9949 - mDice: 0.9194 - val_loss: 0.1603 - val_acc: 0.9933 - val_mDice: 0.8354

Epoch 00049: val_mDice did not improve from 0.84732
Epoch 50/300
 - 52s - loss: 0.0431 - acc: 0.9949 - mDice: 0.9199 - val_loss: 0.2963 - val_acc: 0.9927 - val_mDice: 0.8382

Epoch 00050: val_mDice did not improve from 0.84732
Epoch 51/300
 - 53s - loss: 0.0427 - acc: 0.9949 - mDice: 0.9206 - val_loss: 0.3488 - val_acc: 0.9897 - val_mDice: 0.7960

Epoch 00051: val_mDice did not improve from 0.84732
Epoch 52/300
 - 52s - loss: 0.0423 - acc: 0.9950 - mDice: 0.9213 - val_loss: 0.1391 - val_acc: 0.9934 - val_mDice: 0.8352

Epoch 00052: val_mDice did not improve from 0.84732
Epoch 53/300
 - 53s - loss: 0.0424 - acc: 0.9950 - mDice: 0.9211 - val_loss: 0.3033 - val_acc: 0.9927 - val_mDice: 0.8332

Epoch 00053: val_mDice did not improve from 0.84732
Epoch 54/300
 - 52s - loss: 0.0417 - acc: 0.9950 - mDice: 0.9224 - val_loss: 0.3014 - val_acc: 0.9926 - val_mDice: 0.8345

Epoch 00054: val_mDice did not improve from 0.84732
Epoch 55/300
 - 53s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9226 - val_loss: 0.1498 - val_acc: 0.9932 - val_mDice: 0.8334

Epoch 00055: val_mDice did not improve from 0.84732
Epoch 56/300
 - 52s - loss: 0.0418 - acc: 0.9950 - mDice: 0.9221 - val_loss: 0.2987 - val_acc: 0.9931 - val_mDice: 0.8281

Epoch 00056: val_mDice did not improve from 0.84732
Epoch 57/300
 - 53s - loss: 0.0410 - acc: 0.9951 - mDice: 0.9236 - val_loss: 0.2676 - val_acc: 0.9932 - val_mDice: 0.8393

Epoch 00057: val_mDice did not improve from 0.84732
Epoch 58/300
 - 53s - loss: 0.0410 - acc: 0.9951 - mDice: 0.9236 - val_loss: 0.2860 - val_acc: 0.9919 - val_mDice: 0.8239

Epoch 00058: val_mDice did not improve from 0.84732
Epoch 59/300
 - 53s - loss: 0.0410 - acc: 0.9951 - mDice: 0.9236 - val_loss: 0.2787 - val_acc: 0.9928 - val_mDice: 0.8382

Epoch 00059: val_mDice did not improve from 0.84732
Epoch 60/300
 - 52s - loss: 0.0406 - acc: 0.9951 - mDice: 0.9243 - val_loss: 0.2804 - val_acc: 0.9934 - val_mDice: 0.8450

Epoch 00060: val_mDice did not improve from 0.84732
Epoch 61/300
 - 53s - loss: 0.0409 - acc: 0.9951 - mDice: 0.9238 - val_loss: 0.2853 - val_acc: 0.9933 - val_mDice: 0.8445

Epoch 00061: val_mDice did not improve from 0.84732
Epoch 62/300
 - 52s - loss: 0.0407 - acc: 0.9951 - mDice: 0.9241 - val_loss: 0.2854 - val_acc: 0.9936 - val_mDice: 0.8441

Epoch 00062: val_mDice did not improve from 0.84732
Epoch 63/300
 - 52s - loss: 0.0404 - acc: 0.9952 - mDice: 0.9247 - val_loss: 0.2737 - val_acc: 0.9934 - val_mDice: 0.8416

Epoch 00063: val_mDice did not improve from 0.84732
Epoch 64/300
 - 54s - loss: 0.0403 - acc: 0.9952 - mDice: 0.9249 - val_loss: 0.2715 - val_acc: 0.9935 - val_mDice: 0.8446

Epoch 00064: val_mDice did not improve from 0.84732
Epoch 65/300
 - 54s - loss: 0.0403 - acc: 0.9952 - mDice: 0.9249 - val_loss: 0.2520 - val_acc: 0.9935 - val_mDice: 0.8448

Epoch 00065: val_mDice did not improve from 0.84732
Epoch 66/300
 - 53s - loss: 0.0401 - acc: 0.9952 - mDice: 0.9252 - val_loss: 0.1495 - val_acc: 0.9929 - val_mDice: 0.8348

Epoch 00066: val_mDice did not improve from 0.84732
Epoch 67/300
 - 53s - loss: 0.0400 - acc: 0.9952 - mDice: 0.9254 - val_loss: 0.2775 - val_acc: 0.9935 - val_mDice: 0.8380

Epoch 00067: val_mDice did not improve from 0.84732
Epoch 68/300
 - 53s - loss: 0.0402 - acc: 0.9952 - mDice: 0.9250 - val_loss: 0.2969 - val_acc: 0.9927 - val_mDice: 0.8342

Epoch 00068: val_mDice did not improve from 0.84732
Epoch 69/300
 - 54s - loss: 0.0392 - acc: 0.9953 - mDice: 0.9268 - val_loss: 0.2846 - val_acc: 0.9938 - val_mDice: 0.8414

Epoch 00069: val_mDice did not improve from 0.84732
Epoch 70/300
 - 53s - loss: 0.0393 - acc: 0.9953 - mDice: 0.9266 - val_loss: 0.2953 - val_acc: 0.9927 - val_mDice: 0.8381

Epoch 00070: val_mDice did not improve from 0.84732
Epoch 71/300
 - 53s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.3016 - val_acc: 0.9923 - val_mDice: 0.8312

Epoch 00071: val_mDice did not improve from 0.84732
Epoch 72/300
 - 56s - loss: 0.0392 - acc: 0.9952 - mDice: 0.9268 - val_loss: 0.2984 - val_acc: 0.9925 - val_mDice: 0.8323

Epoch 00072: val_mDice did not improve from 0.84732
Epoch 73/300
 - 56s - loss: 0.0389 - acc: 0.9953 - mDice: 0.9273 - val_loss: 0.3517 - val_acc: 0.9896 - val_mDice: 0.7911

Epoch 00073: val_mDice did not improve from 0.84732
Epoch 74/300
 - 56s - loss: 0.0387 - acc: 0.9953 - mDice: 0.9277 - val_loss: 0.1552 - val_acc: 0.9932 - val_mDice: 0.8305

Epoch 00074: val_mDice did not improve from 0.84732
Epoch 75/300
 - 53s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9275 - val_loss: 0.1228 - val_acc: 0.9934 - val_mDice: 0.8414

Epoch 00075: val_mDice did not improve from 0.84732
Epoch 76/300
 - 53s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9276 - val_loss: 0.2836 - val_acc: 0.9933 - val_mDice: 0.8381

Epoch 00076: val_mDice did not improve from 0.84732
Epoch 77/300
 - 53s - loss: 0.0385 - acc: 0.9953 - mDice: 0.9281 - val_loss: 0.2805 - val_acc: 0.9932 - val_mDice: 0.8385

Epoch 00077: val_mDice did not improve from 0.84732
Epoch 78/300
 - 53s - loss: 0.0389 - acc: 0.9953 - mDice: 0.9274 - val_loss: 0.2875 - val_acc: 0.9935 - val_mDice: 0.8393

Epoch 00078: val_mDice did not improve from 0.84732
Epoch 79/300
 - 52s - loss: 0.0385 - acc: 0.9953 - mDice: 0.9281 - val_loss: 0.2941 - val_acc: 0.9923 - val_mDice: 0.8326

Epoch 00079: val_mDice did not improve from 0.84732
Epoch 80/300
 - 52s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9287 - val_loss: 0.2878 - val_acc: 0.9933 - val_mDice: 0.8394

Epoch 00080: val_mDice did not improve from 0.84732
Epoch 81/300
 - 52s - loss: 0.0383 - acc: 0.9953 - mDice: 0.9285 - val_loss: 0.2866 - val_acc: 0.9933 - val_mDice: 0.8359

Epoch 00081: val_mDice did not improve from 0.84732
Epoch 82/300
 - 53s - loss: 0.0383 - acc: 0.9953 - mDice: 0.9284 - val_loss: 0.3067 - val_acc: 0.9924 - val_mDice: 0.8342

Epoch 00082: val_mDice did not improve from 0.84732
Epoch 83/300
 - 52s - loss: 0.0382 - acc: 0.9954 - mDice: 0.9287 - val_loss: 0.2923 - val_acc: 0.9929 - val_mDice: 0.8392

Epoch 00083: val_mDice did not improve from 0.84732
Epoch 84/300
 - 53s - loss: 0.0382 - acc: 0.9954 - mDice: 0.9287 - val_loss: 0.3095 - val_acc: 0.9926 - val_mDice: 0.8353

Epoch 00084: val_mDice did not improve from 0.84732
Epoch 85/300
 - 52s - loss: 0.0381 - acc: 0.9954 - mDice: 0.9288 - val_loss: 0.2838 - val_acc: 0.9935 - val_mDice: 0.8412

Epoch 00085: val_mDice did not improve from 0.84732
Epoch 86/300
 - 53s - loss: 0.0379 - acc: 0.9954 - mDice: 0.9292 - val_loss: 0.3136 - val_acc: 0.9916 - val_mDice: 0.8240

Epoch 00086: val_mDice did not improve from 0.84732
Restoring model weights from the end of the best epoch
Epoch 00086: early stopping
{'val_loss': [0.38528516417136416, 0.31665504892589524, 0.2809158939635381, 0.4369532289565541, 0.336776816227939, 0.3275105158681981, 0.26556485128821805, 0.24953424255363643, 0.2632562694780063, 0.289544053201098, 0.23633104062173516, 0.36601191211957484, 0.3656836177688092, 0.37255426560295746, 0.22915553115308285, 0.3129143418627791, 0.21139551000669599, 0.22416471832548268, 0.2731783209601417, 0.2887911031139083, 0.19909061511862092, 0.2918678143178113, 0.19602513435529545, 0.3170978920534253, 0.8883750278037041, 0.18401506141526625, 0.2755521842336748, 0.19480608706362545, 0.2641029972292017, 0.30969585612183437, 0.16218492906773463, 0.17424616942298599, 0.18612408169428818, 0.1676372637739405, 0.16408672297257, 0.27724863166804425, 0.3169697576086037, 0.16397161592612974, 0.3082238921779208, 0.16276537900557742, 0.3164105582109187, 0.17198984476272017, 0.15927452308824286, 0.3046010075486265, 0.16915858033462428, 0.27696677678613923, 0.2717090561927762, 0.30077627088758163, 0.1602509914082475, 0.29628432885510847, 0.34884933225112036, 0.1391475485288538, 0.3032671025721356, 0.30142434473964386, 0.14978539504227228, 0.2986500067054294, 0.26761281106155366, 0.2860043453401886, 0.2787292488501407, 0.2804129912692588, 0.2852579089521896, 0.2853705189190805, 0.2737111364258453, 0.2715128976851702, 0.2519970348512288, 0.1495266786077991, 0.27751677969354205, 0.2968644613865763, 0.28457463905215263, 0.2952949025784619, 0.30159907779307105, 0.2984486271161586, 0.35165268840501085, 0.1552127882023342, 0.12275297482847236, 0.28355059810564853, 0.280516148195602, 0.28752847894793376, 0.29406417289283127, 0.287809795641806, 0.28656382561894134, 0.3066587587236427, 0.29229136000503786, 0.3095186085556634, 0.28384727556840517, 0.3136190551740583], 'val_acc': [0.9888733569532633, 0.9902733485214412, 0.9916003900580108, 0.9879176961258054, 0.9910403806716204, 0.9913144647143781, 0.991996365133673, 0.9921927927061915, 0.9928020550869405, 0.9924531574361026, 0.9930246849544346, 0.9883333151228726, 0.9870795696042478, 0.9872229918837547, 0.9932376435026526, 0.9912380576133728, 0.9931045109406114, 0.993090785574168, 0.991927151568234, 0.9913646499626338, 0.9931347439996898, 0.992479354608804, 0.9928295030258596, 0.9895799118094146, 0.983788188546896, 0.99314941233024, 0.9931120071560144, 0.993062112480402, 0.99228321807459, 0.9918211353942752, 0.9929735553450882, 0.9933845130726695, 0.9928669072687626, 0.9926710966974497, 0.993058352265507, 0.9935450749471784, 0.9913842887617648, 0.9935887288302183, 0.9917640849016607, 0.9932385864667594, 0.9908638997003436, 0.9931032536551356, 0.9929021461866796, 0.9921803339384496, 0.9934262712486088, 0.9935756484046578, 0.9935902850702405, 0.9930315557867289, 0.9933246290311217, 0.9927303460426629, 0.9896550546400249, 0.9934209976345301, 0.9926863834261894, 0.9926424166187644, 0.9931871308945119, 0.9930702126584947, 0.9931868202984333, 0.9919340093620121, 0.9928360534831882, 0.9934272230602801, 0.9933093609288335, 0.9936074377037585, 0.9933798206038773, 0.9934861618094146, 0.9934792937710881, 0.9928725301288068, 0.993452169932425, 0.9926511538214982, 0.9937826739624143, 0.9926985488273203, 0.9923309376463294, 0.9925370314158499, 0.9895711787976325, 0.9932395177893341, 0.993414431810379, 0.9932532520033419, 0.9931634394451976, 0.9934624657034874, 0.992267316672951, 0.9932541726157069, 0.9933174694888294, 0.9923808113671839, 0.9928581789135933, 0.9926168569363654, 0.9934649444185197, 0.9916468374431133], 'val_mDice': [0.7437683059833944, 0.7531237904913723, 0.7962177856825292, 0.6221416173502803, 0.8050014730542898, 0.8057338884100318, 0.7939105853438377, 0.8048541145399213, 0.8296295418404043, 0.8295287843793631, 0.832980452105403, 0.773895310703665, 0.7551222224719822, 0.7540008286014199, 0.8254896965809166, 0.8174123824574053, 0.8268579374998808, 0.8319550775922835, 0.8246076526120305, 0.8155166753567755, 0.842249917332083, 0.8339724619872868, 0.8353265468031168, 0.7906117010861635, 0.3616408859670628, 0.8269418845884502, 0.8419662248343229, 0.820702244527638, 0.8305446128360927, 0.8258528774604201, 0.841427082195878, 0.832330621778965, 0.8105677203275263, 0.8344482746906579, 0.8406398934312165, 0.8458577562123537, 0.8169636246748269, 0.8434691000729799, 0.8285949937999249, 0.8287069853395224, 0.8133778930641711, 0.8211545879021287, 0.8234817069023848, 0.827095820568502, 0.8362158550880849, 0.8473228896036744, 0.8447563275694847, 0.8299706852994859, 0.8353782934136689, 0.8382303174585104, 0.7959833252243698, 0.835170061327517, 0.8332303143106401, 0.83449378143996, 0.8334075100719929, 0.8280927548184991, 0.8392610587179661, 0.8239238522946835, 0.8382138796150684, 0.8450131979770958, 0.8445304236374795, 0.8441012701950967, 0.8416010648943484, 0.8446448831818998, 0.8447567815892398, 0.8348416420631111, 0.8380281506106257, 0.8341766893863678, 0.841410702560097, 0.8381441584788263, 0.8311573183164, 0.8322824607603252, 0.7911244058050215, 0.8304705726914108, 0.8413658710196614, 0.8380849263630807, 0.8384630433283746, 0.839275773614645, 0.8325605420395732, 0.8394091157242656, 0.8359029539860785, 0.8341501816175878, 0.8392156683839858, 0.8353196317330003, 0.8411725051701069, 0.8240251452662051], 'loss': [0.2950100133930666, 0.10438705516447377, 0.08887381738706847, 0.08131002109622006, 0.07676619547449007, 0.07230071997090584, 0.07097118423150796, 0.06694869494533738, 0.06562238410106586, 0.06450404043696657, 0.061663650667035816, 0.060670027558024066, 0.05927348942814547, 0.058363912229987686, 0.057346546774671874, 0.05637677924918965, 0.055874541882727224, 0.05494542550968628, 0.05458766387727281, 0.053380866488804316, 0.05272485475813635, 0.052032802789793955, 0.05167317512670543, 0.05180242442203147, 0.05106772836139771, 0.05353020607214973, 0.04980508314383505, 0.049251091235538134, 0.049057069657307904, 0.04863535975785265, 0.04878618241099166, 0.048035255310301915, 0.04752834487987324, 0.04694244228853115, 0.04720408226323, 0.04620383983793693, 0.04618101393858273, 0.04593262774215158, 0.045298318151288076, 0.04573159883681962, 0.04450225310952624, 0.0450748802607755, 0.04414406226411422, 0.04389527740838415, 0.04371224015481979, 0.04357899458386611, 0.0430431447133718, 0.043100698029446494, 0.04336916481719188, 0.0430671250646945, 0.042680194065151375, 0.04229614070282416, 0.042426363193342684, 0.04167511404916234, 0.04154435625970467, 0.04184045581564964, 0.04097132467164545, 0.041023912054129606, 0.041006016712607625, 0.040579729192924095, 0.04086061812174629, 0.040695212388860647, 0.040367190218726985, 0.04028621967070379, 0.04027515608980512, 0.0401098147803768, 0.03997073900891615, 0.040241856368625845, 0.03920723075542499, 0.039349932924079206, 0.039412269638198806, 0.039233136617415065, 0.03894557756691759, 0.0387073284244671, 0.0388161374111669, 0.03875476071219127, 0.03851990199574156, 0.03886415906734371, 0.038506138342007105, 0.038155814325903314, 0.038252878619916934, 0.03832102352992415, 0.038151163553733144, 0.03817327030650571, 0.03810762973534523, 0.03787296775313389], 'acc': [0.9715967051614739, 0.9891023234691134, 0.9906385881748158, 0.9913206934111728, 0.9917461757212825, 0.9921427739197, 0.9922693899606625, 0.9926204481537062, 0.9927699949816986, 0.9928712532040244, 0.9931182775733445, 0.9932352903621378, 0.9933700458892923, 0.9934329039282924, 0.993516544563313, 0.9936240324647748, 0.9936801730388408, 0.9937645066375861, 0.9937831310981018, 0.9939265405520947, 0.9939742964832323, 0.9940346693818102, 0.994065141143236, 0.9940659058236683, 0.9941493307130046, 0.9939353189305504, 0.9942385933187845, 0.9943122466682238, 0.9943173829030254, 0.994380720750067, 0.9943363593127983, 0.9944245731275201, 0.9944603179159571, 0.9945203832069229, 0.994507746585947, 0.9945876187905349, 0.994606276034644, 0.9946355825173006, 0.994692942642426, 0.9946725594536192, 0.9947515323808332, 0.994718014065142, 0.9948033034503703, 0.9948118403978127, 0.9948180159500865, 0.9948450105592211, 0.9948943543893972, 0.9948806481673297, 0.994883226651659, 0.9949039664988154, 0.9949486641375822, 0.9949626640131128, 0.9949620366165748, 0.9950217715854829, 0.9950401975231274, 0.9950293234046417, 0.995101804106967, 0.9950892940082242, 0.9950853839864627, 0.9951368505854743, 0.995103846440349, 0.9951171482898805, 0.9951500854620164, 0.9951611273211443, 0.9951612292799202, 0.9951714061687975, 0.9951868949208482, 0.9951652801658712, 0.9952602036963, 0.9952605852366629, 0.9952442304409657, 0.995249423074074, 0.995290105034281, 0.9953143139243943, 0.9952940214964188, 0.9952968323883091, 0.9953077366865373, 0.9952902153724714, 0.9953012701054269, 0.995347186623515, 0.995343799615718, 0.9953239175435958, 0.9953507833382775, 0.9953573623558944, 0.9953628408793886, 0.9953889569034556], 'mDice': [0.6413404195825577, 0.8193321682731768, 0.842423838966328, 0.8546120937006031, 0.861976700875074, 0.8693696671666841, 0.8716350341765629, 0.8783624150188761, 0.8806731730952306, 0.8825397895952266, 0.8873765067562791, 0.8891050989333935, 0.8915255816123815, 0.8931236321798417, 0.8948117379279616, 0.8964911179425091, 0.8973640275843623, 0.8989803861751781, 0.899583991588831, 0.9016981426606101, 0.9028444533025649, 0.9040404176537523, 0.9046964692061158, 0.9044556588651246, 0.9058046358255223, 0.9015451652380153, 0.9079569497700697, 0.90894080710436, 0.909284659610388, 0.9100229958215352, 0.9097647183141158, 0.9110899746341823, 0.9119579259618257, 0.9130142047746791, 0.9125230141088801, 0.9143082109549686, 0.9143423343336345, 0.9147916092223873, 0.9159154359563325, 0.9151544783940032, 0.91733423226855, 0.916308693462262, 0.9179632558810997, 0.9184129692833086, 0.9187440879325273, 0.9189916036540905, 0.9199314893116114, 0.9198361142969469, 0.9193682824746787, 0.9198972232543703, 0.9205964383686186, 0.9212643659681313, 0.9210555565278262, 0.9223830871733276, 0.9226125283178669, 0.9220832251319628, 0.9236497458534068, 0.9235554996705213, 0.923590779179852, 0.9243448552969539, 0.9238449434266213, 0.9241404319745787, 0.9247278588303183, 0.9248831493798845, 0.9248985645731415, 0.9251879531428334, 0.9254491782166255, 0.9249680852854004, 0.9268204280761416, 0.9265572220602974, 0.9264506879301039, 0.9267670386577437, 0.927284405035356, 0.9277128581318191, 0.9275197571365762, 0.9276447589491336, 0.9280622944164819, 0.927440200018747, 0.9280953608324293, 0.9287184453099201, 0.9285416558975264, 0.9284286719242759, 0.928732006949, 0.9286868639893685, 0.9288093597683685, 0.9292338470056994]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:05,  1.90s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.40s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:01,  1.05s/it]predicting test subjects: 100%|██████████| 4/4 [00:02<00:00,  1.21it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:34,  2.80it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:32,  2.87it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:29,  2.95it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:28,  2.94it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:30,  2.88it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:29,  2.91it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:28,  2.93it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:27,  2.96it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:28,  2.91it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:30,  2.81it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:31,  2.79it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:34,  2.70it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:35,  2.66it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:32,  2.74it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:31,  2.73it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:29,  2.81it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:26,  2.87it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:24,  2.92it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:25,  2.89it/s]predicting train subjects:   8%|▊         | 20/266 [00:06<01:23,  2.94it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:23,  2.92it/s]predicting train subjects:   8%|▊         | 22/266 [00:07<01:25,  2.84it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:26,  2.82it/s]predicting train subjects:   9%|▉         | 24/266 [00:08<01:28,  2.75it/s]predicting train subjects:   9%|▉         | 25/266 [00:08<01:24,  2.84it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:21,  2.94it/s]predicting train subjects:  10%|█         | 27/266 [00:09<01:20,  2.98it/s]predicting train subjects:  11%|█         | 28/266 [00:09<01:18,  3.02it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:18,  3.02it/s]predicting train subjects:  11%|█▏        | 30/266 [00:10<01:16,  3.08it/s]predicting train subjects:  12%|█▏        | 31/266 [00:10<01:18,  3.00it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:16,  3.07it/s]predicting train subjects:  12%|█▏        | 33/266 [00:11<01:15,  3.08it/s]predicting train subjects:  13%|█▎        | 34/266 [00:11<01:17,  2.99it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:18,  2.94it/s]predicting train subjects:  14%|█▎        | 36/266 [00:12<01:16,  3.01it/s]predicting train subjects:  14%|█▍        | 37/266 [00:12<01:16,  3.00it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:15,  3.03it/s]predicting train subjects:  15%|█▍        | 39/266 [00:13<01:15,  3.02it/s]predicting train subjects:  15%|█▌        | 40/266 [00:13<01:15,  2.99it/s]predicting train subjects:  15%|█▌        | 41/266 [00:14<01:13,  3.06it/s]predicting train subjects:  16%|█▌        | 42/266 [00:14<01:11,  3.15it/s]predicting train subjects:  16%|█▌        | 43/266 [00:14<01:11,  3.10it/s]predicting train subjects:  17%|█▋        | 44/266 [00:14<01:07,  3.29it/s]predicting train subjects:  17%|█▋        | 45/266 [00:15<01:05,  3.38it/s]predicting train subjects:  17%|█▋        | 46/266 [00:15<01:02,  3.53it/s]predicting train subjects:  18%|█▊        | 47/266 [00:15<01:00,  3.64it/s]predicting train subjects:  18%|█▊        | 48/266 [00:15<00:58,  3.73it/s]predicting train subjects:  18%|█▊        | 49/266 [00:16<00:57,  3.79it/s]predicting train subjects:  19%|█▉        | 50/266 [00:16<00:58,  3.69it/s]predicting train subjects:  19%|█▉        | 51/266 [00:16<00:57,  3.73it/s]predicting train subjects:  20%|█▉        | 52/266 [00:17<00:57,  3.75it/s]predicting train subjects:  20%|█▉        | 53/266 [00:17<00:57,  3.71it/s]predicting train subjects:  20%|██        | 54/266 [00:17<00:57,  3.68it/s]predicting train subjects:  21%|██        | 55/266 [00:17<00:56,  3.76it/s]predicting train subjects:  21%|██        | 56/266 [00:18<00:55,  3.77it/s]predicting train subjects:  21%|██▏       | 57/266 [00:18<00:55,  3.80it/s]predicting train subjects:  22%|██▏       | 58/266 [00:18<00:57,  3.63it/s]predicting train subjects:  22%|██▏       | 59/266 [00:18<00:55,  3.71it/s]predicting train subjects:  23%|██▎       | 60/266 [00:19<00:54,  3.78it/s]predicting train subjects:  23%|██▎       | 61/266 [00:19<00:53,  3.84it/s]predicting train subjects:  23%|██▎       | 62/266 [00:19<00:52,  3.90it/s]predicting train subjects:  24%|██▎       | 63/266 [00:19<00:51,  3.94it/s]predicting train subjects:  24%|██▍       | 64/266 [00:20<00:51,  3.92it/s]predicting train subjects:  24%|██▍       | 65/266 [00:20<00:53,  3.72it/s]predicting train subjects:  25%|██▍       | 66/266 [00:20<00:55,  3.60it/s]predicting train subjects:  25%|██▌       | 67/266 [00:21<00:56,  3.52it/s]predicting train subjects:  26%|██▌       | 68/266 [00:21<00:57,  3.46it/s]predicting train subjects:  26%|██▌       | 69/266 [00:21<00:54,  3.59it/s]predicting train subjects:  26%|██▋       | 70/266 [00:21<00:55,  3.52it/s]predicting train subjects:  27%|██▋       | 71/266 [00:22<00:54,  3.59it/s]predicting train subjects:  27%|██▋       | 72/266 [00:22<00:55,  3.51it/s]predicting train subjects:  27%|██▋       | 73/266 [00:22<00:54,  3.55it/s]predicting train subjects:  28%|██▊       | 74/266 [00:22<00:51,  3.71it/s]predicting train subjects:  28%|██▊       | 75/266 [00:23<00:52,  3.62it/s]predicting train subjects:  29%|██▊       | 76/266 [00:23<00:52,  3.65it/s]predicting train subjects:  29%|██▉       | 77/266 [00:23<00:50,  3.74it/s]predicting train subjects:  29%|██▉       | 78/266 [00:24<00:54,  3.46it/s]predicting train subjects:  30%|██▉       | 79/266 [00:24<00:55,  3.35it/s]predicting train subjects:  30%|███       | 80/266 [00:24<00:57,  3.24it/s]predicting train subjects:  30%|███       | 81/266 [00:25<00:59,  3.10it/s]predicting train subjects:  31%|███       | 82/266 [00:25<00:59,  3.12it/s]predicting train subjects:  31%|███       | 83/266 [00:25<01:00,  3.02it/s]predicting train subjects:  32%|███▏      | 84/266 [00:26<01:03,  2.89it/s]predicting train subjects:  32%|███▏      | 85/266 [00:26<01:01,  2.95it/s]predicting train subjects:  32%|███▏      | 86/266 [00:26<01:02,  2.88it/s]predicting train subjects:  33%|███▎      | 87/266 [00:27<01:01,  2.89it/s]predicting train subjects:  33%|███▎      | 88/266 [00:27<01:01,  2.91it/s]predicting train subjects:  33%|███▎      | 89/266 [00:27<01:02,  2.85it/s]predicting train subjects:  34%|███▍      | 90/266 [00:28<01:00,  2.93it/s]predicting train subjects:  34%|███▍      | 91/266 [00:28<01:00,  2.90it/s]predicting train subjects:  35%|███▍      | 92/266 [00:28<00:58,  2.98it/s]predicting train subjects:  35%|███▍      | 93/266 [00:29<00:57,  3.02it/s]predicting train subjects:  35%|███▌      | 94/266 [00:29<00:55,  3.07it/s]predicting train subjects:  36%|███▌      | 95/266 [00:29<00:57,  2.98it/s]predicting train subjects:  36%|███▌      | 96/266 [00:30<00:57,  2.96it/s]predicting train subjects:  36%|███▋      | 97/266 [00:30<00:57,  2.93it/s]predicting train subjects:  37%|███▋      | 98/266 [00:30<00:56,  2.99it/s]predicting train subjects:  37%|███▋      | 99/266 [00:31<00:52,  3.20it/s]predicting train subjects:  38%|███▊      | 100/266 [00:31<00:49,  3.35it/s]predicting train subjects:  38%|███▊      | 101/266 [00:31<00:47,  3.44it/s]predicting train subjects:  38%|███▊      | 102/266 [00:32<00:48,  3.38it/s]predicting train subjects:  39%|███▊      | 103/266 [00:32<00:46,  3.47it/s]predicting train subjects:  39%|███▉      | 104/266 [00:32<00:46,  3.47it/s]predicting train subjects:  39%|███▉      | 105/266 [00:32<00:45,  3.51it/s]predicting train subjects:  40%|███▉      | 106/266 [00:33<00:47,  3.39it/s]predicting train subjects:  40%|████      | 107/266 [00:33<00:48,  3.26it/s]predicting train subjects:  41%|████      | 108/266 [00:33<00:46,  3.39it/s]predicting train subjects:  41%|████      | 109/266 [00:34<00:48,  3.22it/s]predicting train subjects:  41%|████▏     | 110/266 [00:34<00:49,  3.16it/s]predicting train subjects:  42%|████▏     | 111/266 [00:34<00:47,  3.28it/s]predicting train subjects:  42%|████▏     | 112/266 [00:35<00:45,  3.40it/s]predicting train subjects:  42%|████▏     | 113/266 [00:35<00:45,  3.34it/s]predicting train subjects:  43%|████▎     | 114/266 [00:35<00:46,  3.28it/s]predicting train subjects:  43%|████▎     | 115/266 [00:35<00:45,  3.35it/s]predicting train subjects:  44%|████▎     | 116/266 [00:36<00:45,  3.31it/s]predicting train subjects:  44%|████▍     | 117/266 [00:36<00:43,  3.40it/s]predicting train subjects:  44%|████▍     | 118/266 [00:36<00:42,  3.46it/s]predicting train subjects:  45%|████▍     | 119/266 [00:37<00:44,  3.30it/s]predicting train subjects:  45%|████▌     | 120/266 [00:37<00:48,  3.01it/s]predicting train subjects:  45%|████▌     | 121/266 [00:37<00:50,  2.89it/s]predicting train subjects:  46%|████▌     | 122/266 [00:38<00:49,  2.94it/s]predicting train subjects:  46%|████▌     | 123/266 [00:38<00:48,  2.97it/s]predicting train subjects:  47%|████▋     | 124/266 [00:38<00:46,  3.03it/s]predicting train subjects:  47%|████▋     | 125/266 [00:39<00:46,  3.01it/s]predicting train subjects:  47%|████▋     | 126/266 [00:39<00:46,  3.03it/s]predicting train subjects:  48%|████▊     | 127/266 [00:39<00:45,  3.05it/s]predicting train subjects:  48%|████▊     | 128/266 [00:40<00:45,  3.01it/s]predicting train subjects:  48%|████▊     | 129/266 [00:40<00:46,  2.98it/s]predicting train subjects:  49%|████▉     | 130/266 [00:40<00:49,  2.77it/s]predicting train subjects:  49%|████▉     | 131/266 [00:41<00:49,  2.75it/s]predicting train subjects:  50%|████▉     | 132/266 [00:41<00:47,  2.85it/s]predicting train subjects:  50%|█████     | 133/266 [00:42<00:46,  2.88it/s]predicting train subjects:  50%|█████     | 134/266 [00:42<00:46,  2.82it/s]predicting train subjects:  51%|█████     | 135/266 [00:42<00:45,  2.89it/s]predicting train subjects:  51%|█████     | 136/266 [00:43<00:44,  2.91it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:43<00:42,  3.02it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:43<00:41,  3.11it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:43<00:39,  3.18it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:44<00:39,  3.21it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:44<00:40,  3.12it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:44<00:39,  3.16it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:45<00:38,  3.16it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:45<00:38,  3.20it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:45<00:37,  3.23it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:46<00:37,  3.24it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:46<00:37,  3.13it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:46<00:37,  3.19it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:47<00:36,  3.23it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:47<00:37,  3.08it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:47<00:36,  3.14it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:48<00:36,  3.16it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:48<00:35,  3.21it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:48<00:34,  3.26it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:48<00:32,  3.40it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:49<00:30,  3.62it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:49<00:28,  3.82it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:49<00:27,  3.93it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:49<00:26,  4.03it/s]predicting train subjects:  60%|██████    | 160/266 [00:50<00:27,  3.90it/s]predicting train subjects:  61%|██████    | 161/266 [00:50<00:28,  3.70it/s]predicting train subjects:  61%|██████    | 162/266 [00:50<00:28,  3.64it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:50<00:28,  3.63it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:51<00:28,  3.61it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:51<00:28,  3.59it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:51<00:27,  3.59it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:52<00:27,  3.60it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:52<00:27,  3.59it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:52<00:27,  3.57it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:52<00:26,  3.57it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:53<00:26,  3.56it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:53<00:26,  3.58it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:53<00:27,  3.43it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:54<00:27,  3.36it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:54<00:27,  3.30it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:54<00:27,  3.33it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:55<00:27,  3.29it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:55<00:26,  3.29it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:55<00:26,  3.26it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:55<00:26,  3.26it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:56<00:26,  3.16it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:56<00:25,  3.26it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:56<00:25,  3.29it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:57<00:24,  3.39it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:57<00:24,  3.31it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:57<00:23,  3.43it/s]predicting train subjects:  70%|███████   | 187/266 [00:58<00:22,  3.50it/s]predicting train subjects:  71%|███████   | 188/266 [00:58<00:21,  3.62it/s]predicting train subjects:  71%|███████   | 189/266 [00:58<00:21,  3.58it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:58<00:21,  3.53it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:59<00:21,  3.48it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:59<00:21,  3.47it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:59<00:20,  3.60it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:00<00:21,  3.39it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:00<00:20,  3.47it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:00<00:19,  3.55it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:00<00:19,  3.52it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:01<00:19,  3.58it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:01<00:18,  3.62it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:01<00:19,  3.35it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:02<00:18,  3.46it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:02<00:18,  3.54it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:02<00:17,  3.62it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:02<00:17,  3.52it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:03<00:18,  3.31it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:03<00:17,  3.40it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:03<00:17,  3.44it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:04<00:16,  3.52it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:04<00:15,  3.59it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:04<00:16,  3.48it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:04<00:15,  3.52it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:05<00:15,  3.48it/s]predicting train subjects:  80%|████████  | 213/266 [01:05<00:14,  3.65it/s]predicting train subjects:  80%|████████  | 214/266 [01:05<00:14,  3.58it/s]predicting train subjects:  81%|████████  | 215/266 [01:05<00:13,  3.72it/s]predicting train subjects:  81%|████████  | 216/266 [01:06<00:13,  3.82it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:06<00:12,  3.87it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:06<00:12,  3.73it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:07<00:13,  3.59it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:07<00:12,  3.65it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:07<00:12,  3.71it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:07<00:11,  3.73it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:08<00:11,  3.63it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:08<00:11,  3.66it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:08<00:11,  3.67it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:08<00:10,  3.72it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:09<00:10,  3.80it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:09<00:09,  3.88it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:09<00:09,  3.93it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:09<00:09,  3.97it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:10<00:09,  3.88it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:10<00:08,  3.88it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:10<00:08,  3.84it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:10<00:08,  3.86it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:11<00:08,  3.86it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:11<00:07,  3.89it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:11<00:07,  3.90it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:11<00:07,  3.89it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:12<00:07,  3.82it/s]predicting train subjects:  90%|█████████ | 240/266 [01:12<00:06,  3.76it/s]predicting train subjects:  91%|█████████ | 241/266 [01:12<00:06,  3.62it/s]predicting train subjects:  91%|█████████ | 242/266 [01:13<00:06,  3.46it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:13<00:06,  3.43it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:13<00:06,  3.35it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:14<00:06,  3.38it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:14<00:05,  3.52it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:14<00:05,  3.46it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:14<00:05,  3.41it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:15<00:05,  3.24it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:15<00:05,  3.16it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:15<00:04,  3.13it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:16<00:04,  3.05it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:16<00:04,  3.10it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:16<00:03,  3.14it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:17<00:03,  3.06it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:17<00:03,  3.06it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:17<00:02,  3.10it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:18<00:02,  3.10it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:18<00:02,  3.11it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:18<00:01,  3.09it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:19<00:01,  3.02it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:19<00:01,  3.00it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:19<00:00,  3.05it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:20<00:00,  3.07it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:20<00:00,  3.12it/s]predicting train subjects: 100%|██████████| 266/266 [01:20<00:00,  3.13it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  3.52it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  3.60it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  3.71it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:01<00:00,  3.62it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:33,  2.83it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:34,  2.81it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<01:30,  2.91it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:23,  3.13it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:23,  3.11it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:02<01:28,  2.93it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:02<01:30,  2.85it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:31,  2.83it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:03<01:32,  2.77it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:03<01:34,  2.72it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:03<01:32,  2.75it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:04<01:32,  2.75it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:04<01:29,  2.83it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:04<01:28,  2.85it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:05<01:28,  2.82it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:05<01:27,  2.84it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:05<01:28,  2.81it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:06<01:34,  2.63it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:06<01:34,  2.61it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:07<01:33,  2.63it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:07<01:32,  2.64it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:07<01:29,  2.72it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:08<01:28,  2.76it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:08<01:28,  2.74it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:08<01:28,  2.73it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:09<01:27,  2.74it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:09<01:23,  2.86it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:09<01:21,  2.94it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:10<01:23,  2.85it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:10<01:21,  2.90it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:11<01:20,  2.93it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:11<01:19,  2.93it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:11<01:19,  2.93it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:12<01:17,  2.98it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:12<01:17,  3.00it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:12<01:21,  2.81it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:13<01:19,  2.89it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:13<01:16,  2.98it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:13<01:15,  3.02it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:14<01:14,  3.03it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:14<01:14,  3.03it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:14<01:09,  3.21it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:14<01:06,  3.33it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:15<01:05,  3.39it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:15<01:08,  3.22it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:15<01:06,  3.32it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:16<01:03,  3.45it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:16<01:00,  3.58it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:16<00:59,  3.67it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:16<01:00,  3.60it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:17<00:58,  3.65it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:17<00:59,  3.59it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:17<00:58,  3.66it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:17<00:57,  3.70it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:18<00:57,  3.68it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:18<00:55,  3.75it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:18<00:56,  3.72it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:19<00:55,  3.72it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:19<00:55,  3.76it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:19<00:56,  3.68it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:19<00:54,  3.73it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:20<00:53,  3.79it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:20<00:52,  3.87it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:20<00:51,  3.92it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:20<00:51,  3.93it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:21<00:50,  3.97it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:21<00:49,  3.99it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:21<00:49,  3.97it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:21<00:49,  3.95it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:22<00:49,  3.95it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:22<00:50,  3.90it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:22<00:52,  3.72it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:22<00:51,  3.71it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:23<00:50,  3.78it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:23<00:50,  3.81it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:23<00:49,  3.80it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:23<00:50,  3.72it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:24<00:54,  3.44it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:24<00:56,  3.30it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:24<00:58,  3.19it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:25<01:01,  3.02it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:25<01:00,  3.02it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:26<01:01,  3.00it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:26<01:01,  2.95it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:26<01:01,  2.96it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:27<01:02,  2.88it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:27<01:02,  2.87it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:27<01:01,  2.89it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:28<01:00,  2.92it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:28<01:01,  2.88it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:28<01:02,  2.79it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:29<01:05,  2.65it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:29<01:04,  2.66it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:29<01:02,  2.75it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:30<01:00,  2.83it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:30<00:56,  3.00it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:30<00:57,  2.96it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:31<00:55,  3.05it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:31<00:50,  3.33it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:31<00:49,  3.37it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:32<00:48,  3.39it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:32<00:47,  3.44it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:32<00:46,  3.51it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:32<00:46,  3.48it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:33<00:45,  3.53it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:33<00:44,  3.56it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:33<00:45,  3.46it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:34<00:46,  3.43it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:34<00:44,  3.51it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:34<00:43,  3.56it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:34<00:44,  3.48it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:35<00:44,  3.48it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:35<00:43,  3.51it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:35<00:43,  3.51it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:36<00:42,  3.57it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:36<00:41,  3.60it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:36<00:42,  3.52it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:36<00:42,  3.48it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:37<00:44,  3.30it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:37<00:45,  3.19it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:37<00:46,  3.13it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:38<00:45,  3.13it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:38<00:45,  3.13it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:38<00:45,  3.10it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:39<00:46,  3.04it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:39<00:48,  2.89it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:39<00:47,  2.93it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:40<00:47,  2.89it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:40<00:47,  2.88it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:41<00:47,  2.85it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:41<00:47,  2.85it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:41<00:46,  2.86it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:42<00:46,  2.86it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:42<00:47,  2.80it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:42<00:47,  2.78it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:43<00:46,  2.79it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:43<00:44,  2.91it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:43<00:43,  2.93it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:44<00:42,  3.01it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:44<00:41,  3.07it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:44<00:40,  3.07it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:45<00:39,  3.14it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:45<00:38,  3.15it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:45<00:38,  3.18it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:46<00:38,  3.12it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:46<00:39,  3.05it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:46<00:38,  3.13it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:46<00:37,  3.13it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:47<00:36,  3.19it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:47<00:37,  3.06it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:47<00:38,  3.00it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:48<00:38,  2.98it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:48<00:36,  3.08it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:49<00:43,  2.55it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:49<00:40,  2.75it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:49<00:35,  3.09it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:49<00:32,  3.39it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:50<00:29,  3.65it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:50<00:28,  3.76it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:50<00:28,  3.72it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:50<00:28,  3.66it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:51<00:27,  3.73it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:51<00:26,  3.88it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:51<00:26,  3.81it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:51<00:26,  3.76it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:52<00:25,  3.93it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:52<00:24,  4.07it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:52<00:23,  4.17it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:52<00:22,  4.25it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:53<00:22,  4.28it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:53<00:21,  4.33it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:53<00:21,  4.36it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:53<00:22,  4.18it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:54<00:23,  3.94it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:54<00:23,  3.93it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:54<00:23,  3.91it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:54<00:23,  3.87it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:55<00:23,  3.83it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:55<00:23,  3.69it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:55<00:23,  3.73it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:55<00:22,  3.78it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:56<00:23,  3.52it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:56<00:22,  3.61it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:56<00:22,  3.63it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:57<00:22,  3.62it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:57<00:22,  3.52it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:57<00:21,  3.62it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:57<00:21,  3.65it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:58<00:22,  3.49it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:58<00:21,  3.50it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:58<00:21,  3.44it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:59<00:20,  3.57it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:59<00:20,  3.54it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:59<00:21,  3.40it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:59<00:20,  3.48it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [01:00<00:19,  3.51it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [01:00<00:19,  3.57it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [01:00<00:18,  3.59it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [01:01<00:18,  3.65it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [01:01<00:17,  3.67it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [01:01<00:17,  3.67it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [01:01<00:17,  3.70it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [01:02<00:18,  3.34it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [01:02<00:18,  3.30it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [01:02<00:18,  3.23it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [01:03<00:17,  3.35it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [01:03<00:17,  3.40it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [01:03<00:17,  3.40it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [01:04<00:16,  3.50it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [01:04<00:16,  3.50it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [01:04<00:15,  3.57it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [01:04<00:14,  3.64it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [01:05<00:14,  3.74it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [01:05<00:13,  3.78it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:05<00:13,  3.68it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:05<00:13,  3.78it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:06<00:12,  3.88it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:06<00:12,  3.87it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:06<00:12,  3.92it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:06<00:11,  3.98it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:07<00:11,  3.90it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:07<00:13,  3.37it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:07<00:12,  3.52it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:08<00:11,  3.68it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:08<00:10,  3.83it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:08<00:10,  3.89it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:08<00:10,  3.86it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:09<00:09,  3.87it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:09<00:09,  3.95it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:09<00:09,  3.94it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:09<00:08,  3.89it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:10<00:09,  3.71it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:10<00:08,  3.79it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:10<00:08,  3.79it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:10<00:08,  3.75it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:11<00:08,  3.70it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:11<00:08,  3.57it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:11<00:08,  3.50it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:12<00:07,  3.62it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:12<00:06,  3.74it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:12<00:06,  3.82it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:12<00:06,  3.85it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:13<00:05,  3.89it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:13<00:05,  3.92it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:13<00:05,  3.93it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:13<00:05,  3.96it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:14<00:05,  3.77it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:14<00:04,  3.61it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:14<00:05,  3.28it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:15<00:05,  3.10it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:15<00:05,  2.90it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:15<00:04,  2.94it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:16<00:04,  2.88it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:16<00:04,  2.88it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:16<00:03,  2.85it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:17<00:03,  2.94it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:17<00:03,  2.99it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:17<00:02,  2.93it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:18<00:02,  3.00it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:18<00:01,  3.02it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:18<00:01,  3.03it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:19<00:01,  3.06it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:19<00:00,  3.07it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:19<00:00,  3.12it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:20<00:00,  3.08it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:20<00:00,  3.10it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 75.05it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:03, 65.47it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 65.04it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 65.09it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 65.34it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 66.34it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 66.35it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 69.44it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 71.98it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 74.85it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 77.26it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 72.49it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 72.94it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 71.58it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 72.53it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 73.12it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 72.27it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 71.57it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 71.46it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 71.54it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 72.88it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 76.16it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 78.67it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 80.29it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 80.96it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 78.98it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 77.38it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:02<00:00, 77.59it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 227/266 [00:03<00:00, 78.76it/s]saving BB  train1-THALAMUS:  89%|████████▊ | 236/266 [00:03<00:00, 80.10it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 245/266 [00:03<00:00, 81.79it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 254/266 [00:03<00:00, 79.03it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 76.67it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 74.52it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 70.93it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 70.10it/s]saving BB  train1-THALAMUS Sagittal:   6%|▌         | 15/266 [00:00<00:03, 68.46it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 22/266 [00:00<00:03, 67.44it/s]saving BB  train1-THALAMUS Sagittal:  11%|█▏        | 30/266 [00:00<00:03, 69.04it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:00<00:03, 69.32it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:00<00:03, 70.85it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 53/266 [00:00<00:02, 72.75it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 60/266 [00:00<00:02, 69.50it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 68/266 [00:00<00:02, 70.38it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 77/266 [00:01<00:02, 73.96it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 85/266 [00:01<00:02, 73.20it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 93/266 [00:01<00:02, 72.64it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 101/266 [00:01<00:02, 72.94it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 109/266 [00:01<00:02, 73.41it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▍     | 117/266 [00:01<00:02, 74.18it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 125/266 [00:01<00:01, 73.64it/s]saving BB  train1-THALAMUS Sagittal:  50%|█████     | 133/266 [00:01<00:01, 73.27it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 141/266 [00:01<00:01, 73.07it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▌    | 149/266 [00:02<00:01, 72.32it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▉    | 157/266 [00:02<00:01, 74.02it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 166/266 [00:02<00:01, 77.52it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 175/266 [00:02<00:01, 80.38it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 184/266 [00:02<00:00, 82.54it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 193/266 [00:02<00:00, 81.75it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▌  | 202/266 [00:02<00:00, 79.90it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 211/266 [00:02<00:00, 78.53it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:02<00:00, 78.91it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 229/266 [00:03<00:00, 79.87it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 238/266 [00:03<00:00, 80.64it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 247/266 [00:03<00:00, 81.08it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 256/266 [00:03<00:00, 78.02it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 264/266 [00:03<00:00, 75.52it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 75.22it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:36,  1.72s/it]Loading train:   1%|          | 2/266 [00:03<07:25,  1.69s/it]Loading train:   1%|          | 3/266 [00:04<06:48,  1.55s/it]Loading train:   2%|▏         | 4/266 [00:05<06:15,  1.43s/it]Loading train:   2%|▏         | 5/266 [00:07<06:17,  1.45s/it]Loading train:   2%|▏         | 6/266 [00:08<05:49,  1.35s/it]Loading train:   3%|▎         | 7/266 [00:09<05:28,  1.27s/it]Loading train:   3%|▎         | 8/266 [00:10<05:15,  1.22s/it]Loading train:   3%|▎         | 9/266 [00:11<04:57,  1.16s/it]Loading train:   4%|▍         | 10/266 [00:12<04:36,  1.08s/it]Loading train:   4%|▍         | 11/266 [00:13<04:36,  1.08s/it]Loading train:   5%|▍         | 12/266 [00:14<04:29,  1.06s/it]Loading train:   5%|▍         | 13/266 [00:15<04:26,  1.05s/it]Loading train:   5%|▌         | 14/266 [00:16<04:26,  1.06s/it]Loading train:   6%|▌         | 15/266 [00:17<04:24,  1.05s/it]Loading train:   6%|▌         | 16/266 [00:18<04:39,  1.12s/it]Loading train:   6%|▋         | 17/266 [00:20<04:35,  1.11s/it]Loading train:   7%|▋         | 18/266 [00:21<04:37,  1.12s/it]Loading train:   7%|▋         | 19/266 [00:22<04:21,  1.06s/it]Loading train:   8%|▊         | 20/266 [00:23<04:14,  1.04s/it]Loading train:   8%|▊         | 21/266 [00:24<04:27,  1.09s/it]Loading train:   8%|▊         | 22/266 [00:25<04:29,  1.10s/it]Loading train:   9%|▊         | 23/266 [00:26<04:44,  1.17s/it]Loading train:   9%|▉         | 24/266 [00:27<04:27,  1.11s/it]Loading train:   9%|▉         | 25/266 [00:28<04:11,  1.04s/it]Loading train:  10%|▉         | 26/266 [00:29<03:59,  1.00it/s]Loading train:  10%|█         | 27/266 [00:30<03:44,  1.06it/s]Loading train:  11%|█         | 28/266 [00:31<03:41,  1.08it/s]Loading train:  11%|█         | 29/266 [00:32<03:46,  1.04it/s]Loading train:  11%|█▏        | 30/266 [00:33<03:43,  1.06it/s]Loading train:  12%|█▏        | 31/266 [00:33<03:34,  1.10it/s]Loading train:  12%|█▏        | 32/266 [00:34<03:30,  1.11it/s]Loading train:  12%|█▏        | 33/266 [00:35<03:33,  1.09it/s]Loading train:  13%|█▎        | 34/266 [00:36<03:27,  1.12it/s]Loading train:  13%|█▎        | 35/266 [00:37<03:35,  1.07it/s]Loading train:  14%|█▎        | 36/266 [00:38<03:33,  1.08it/s]Loading train:  14%|█▍        | 37/266 [00:39<03:29,  1.09it/s]Loading train:  14%|█▍        | 38/266 [00:40<03:29,  1.09it/s]Loading train:  15%|█▍        | 39/266 [00:41<03:25,  1.11it/s]Loading train:  15%|█▌        | 40/266 [00:42<03:20,  1.13it/s]Loading train:  15%|█▌        | 41/266 [00:43<03:24,  1.10it/s]Loading train:  16%|█▌        | 42/266 [00:43<03:11,  1.17it/s]Loading train:  16%|█▌        | 43/266 [00:44<03:04,  1.21it/s]Loading train:  17%|█▋        | 44/266 [00:45<03:03,  1.21it/s]Loading train:  17%|█▋        | 45/266 [00:46<02:58,  1.24it/s]Loading train:  17%|█▋        | 46/266 [00:46<02:53,  1.27it/s]Loading train:  18%|█▊        | 47/266 [00:47<02:54,  1.26it/s]Loading train:  18%|█▊        | 48/266 [00:48<02:52,  1.26it/s]Loading train:  18%|█▊        | 49/266 [00:49<02:49,  1.28it/s]Loading train:  19%|█▉        | 50/266 [00:49<02:46,  1.30it/s]Loading train:  19%|█▉        | 51/266 [00:50<02:50,  1.26it/s]Loading train:  20%|█▉        | 52/266 [00:51<02:46,  1.29it/s]Loading train:  20%|█▉        | 53/266 [00:52<02:43,  1.30it/s]Loading train:  20%|██        | 54/266 [00:53<02:43,  1.30it/s]Loading train:  21%|██        | 55/266 [00:53<02:42,  1.30it/s]Loading train:  21%|██        | 56/266 [00:54<02:45,  1.27it/s]Loading train:  21%|██▏       | 57/266 [00:55<02:42,  1.29it/s]Loading train:  22%|██▏       | 58/266 [00:56<02:46,  1.25it/s]Loading train:  22%|██▏       | 59/266 [00:57<02:54,  1.19it/s]Loading train:  23%|██▎       | 60/266 [00:58<02:48,  1.22it/s]Loading train:  23%|██▎       | 61/266 [00:58<02:38,  1.29it/s]Loading train:  23%|██▎       | 62/266 [00:59<02:32,  1.34it/s]Loading train:  24%|██▎       | 63/266 [00:59<02:23,  1.42it/s]Loading train:  24%|██▍       | 64/266 [01:00<02:22,  1.42it/s]Loading train:  24%|██▍       | 65/266 [01:01<02:17,  1.46it/s]Loading train:  25%|██▍       | 66/266 [01:02<02:23,  1.40it/s]Loading train:  25%|██▌       | 67/266 [01:02<02:22,  1.40it/s]Loading train:  26%|██▌       | 68/266 [01:03<02:27,  1.34it/s]Loading train:  26%|██▌       | 69/266 [01:04<02:29,  1.31it/s]Loading train:  26%|██▋       | 70/266 [01:05<02:25,  1.35it/s]Loading train:  27%|██▋       | 71/266 [01:05<02:26,  1.33it/s]Loading train:  27%|██▋       | 72/266 [01:06<02:23,  1.35it/s]Loading train:  27%|██▋       | 73/266 [01:07<02:21,  1.36it/s]Loading train:  28%|██▊       | 74/266 [01:08<02:26,  1.31it/s]Loading train:  28%|██▊       | 75/266 [01:08<02:19,  1.37it/s]Loading train:  29%|██▊       | 76/266 [01:09<02:16,  1.39it/s]Loading train:  29%|██▉       | 77/266 [01:10<02:13,  1.42it/s]Loading train:  29%|██▉       | 78/266 [01:11<02:28,  1.26it/s]Loading train:  30%|██▉       | 79/266 [01:12<02:40,  1.16it/s]Loading train:  30%|███       | 80/266 [01:13<02:44,  1.13it/s]Loading train:  30%|███       | 81/266 [01:14<02:50,  1.09it/s]Loading train:  31%|███       | 82/266 [01:14<02:46,  1.11it/s]Loading train:  31%|███       | 83/266 [01:15<02:41,  1.13it/s]Loading train:  32%|███▏      | 84/266 [01:16<02:41,  1.13it/s]Loading train:  32%|███▏      | 85/266 [01:17<02:50,  1.06it/s]Loading train:  32%|███▏      | 86/266 [01:18<02:55,  1.03it/s]Loading train:  33%|███▎      | 87/266 [01:19<02:55,  1.02it/s]Loading train:  33%|███▎      | 88/266 [01:20<02:51,  1.04it/s]Loading train:  33%|███▎      | 89/266 [01:21<02:49,  1.04it/s]Loading train:  34%|███▍      | 90/266 [01:22<02:48,  1.05it/s]Loading train:  34%|███▍      | 91/266 [01:23<02:47,  1.04it/s]Loading train:  35%|███▍      | 92/266 [01:24<02:44,  1.05it/s]Loading train:  35%|███▍      | 93/266 [01:25<02:46,  1.04it/s]Loading train:  35%|███▌      | 94/266 [01:26<02:44,  1.05it/s]Loading train:  36%|███▌      | 95/266 [01:27<02:40,  1.07it/s]Loading train:  36%|███▌      | 96/266 [01:28<03:02,  1.07s/it]Loading train:  36%|███▋      | 97/266 [01:30<03:28,  1.23s/it]Loading train:  37%|███▋      | 98/266 [01:31<03:24,  1.22s/it]Loading train:  37%|███▋      | 99/266 [01:32<03:10,  1.14s/it]Loading train:  38%|███▊      | 100/266 [01:33<03:11,  1.16s/it]Loading train:  38%|███▊      | 101/266 [01:34<02:55,  1.06s/it]Loading train:  38%|███▊      | 102/266 [01:35<02:39,  1.03it/s]Loading train:  39%|███▊      | 103/266 [01:36<02:30,  1.08it/s]Loading train:  39%|███▉      | 104/266 [01:36<02:26,  1.10it/s]Loading train:  39%|███▉      | 105/266 [01:37<02:23,  1.12it/s]Loading train:  40%|███▉      | 106/266 [01:38<02:19,  1.15it/s]Loading train:  40%|████      | 107/266 [01:39<02:17,  1.16it/s]Loading train:  41%|████      | 108/266 [01:40<02:12,  1.19it/s]Loading train:  41%|████      | 109/266 [01:41<02:12,  1.18it/s]Loading train:  41%|████▏     | 110/266 [01:42<02:13,  1.17it/s]Loading train:  42%|████▏     | 111/266 [01:42<02:08,  1.21it/s]Loading train:  42%|████▏     | 112/266 [01:43<02:02,  1.26it/s]Loading train:  42%|████▏     | 113/266 [01:44<02:05,  1.22it/s]Loading train:  43%|████▎     | 114/266 [01:45<01:59,  1.28it/s]Loading train:  43%|████▎     | 115/266 [01:46<02:04,  1.22it/s]Loading train:  44%|████▎     | 116/266 [01:46<01:57,  1.28it/s]Loading train:  44%|████▍     | 117/266 [01:47<01:55,  1.29it/s]Loading train:  44%|████▍     | 118/266 [01:48<01:55,  1.28it/s]Loading train:  45%|████▍     | 119/266 [01:49<02:07,  1.16it/s]Loading train:  45%|████▌     | 120/266 [01:50<02:17,  1.06it/s]Loading train:  45%|████▌     | 121/266 [01:51<02:22,  1.02it/s]Loading train:  46%|████▌     | 122/266 [01:52<02:21,  1.02it/s]Loading train:  46%|████▌     | 123/266 [01:53<02:21,  1.01it/s]Loading train:  47%|████▋     | 124/266 [01:54<02:23,  1.01s/it]Loading train:  47%|████▋     | 125/266 [01:55<02:22,  1.01s/it]Loading train:  47%|████▋     | 126/266 [01:56<02:18,  1.01it/s]Loading train:  48%|████▊     | 127/266 [01:57<02:18,  1.00it/s]Loading train:  48%|████▊     | 128/266 [01:58<02:16,  1.01it/s]Loading train:  48%|████▊     | 129/266 [01:59<02:08,  1.06it/s]Loading train:  49%|████▉     | 130/266 [02:00<02:09,  1.05it/s]Loading train:  49%|████▉     | 131/266 [02:01<02:09,  1.04it/s]Loading train:  50%|████▉     | 132/266 [02:02<02:07,  1.05it/s]Loading train:  50%|█████     | 133/266 [02:03<02:06,  1.05it/s]Loading train:  50%|█████     | 134/266 [02:04<02:02,  1.07it/s]Loading train:  51%|█████     | 135/266 [02:04<01:57,  1.11it/s]Loading train:  51%|█████     | 136/266 [02:05<01:55,  1.13it/s]Loading train:  52%|█████▏    | 137/266 [02:06<01:52,  1.15it/s]Loading train:  52%|█████▏    | 138/266 [02:07<01:51,  1.15it/s]Loading train:  52%|█████▏    | 139/266 [02:08<01:52,  1.13it/s]Loading train:  53%|█████▎    | 140/266 [02:09<01:49,  1.15it/s]Loading train:  53%|█████▎    | 141/266 [02:10<01:50,  1.13it/s]Loading train:  53%|█████▎    | 142/266 [02:11<01:51,  1.11it/s]Loading train:  54%|█████▍    | 143/266 [02:11<01:47,  1.15it/s]Loading train:  54%|█████▍    | 144/266 [02:12<01:49,  1.11it/s]Loading train:  55%|█████▍    | 145/266 [02:13<01:49,  1.11it/s]Loading train:  55%|█████▍    | 146/266 [02:14<01:53,  1.06it/s]Loading train:  55%|█████▌    | 147/266 [02:15<01:53,  1.05it/s]Loading train:  56%|█████▌    | 148/266 [02:16<01:58,  1.00s/it]Loading train:  56%|█████▌    | 149/266 [02:17<01:56,  1.00it/s]Loading train:  56%|█████▋    | 150/266 [02:18<01:53,  1.02it/s]Loading train:  57%|█████▋    | 151/266 [02:19<01:55,  1.00s/it]Loading train:  57%|█████▋    | 152/266 [02:20<01:47,  1.06it/s]Loading train:  58%|█████▊    | 153/266 [02:21<01:44,  1.09it/s]Loading train:  58%|█████▊    | 154/266 [02:22<01:40,  1.11it/s]Loading train:  58%|█████▊    | 155/266 [02:23<01:32,  1.20it/s]Loading train:  59%|█████▊    | 156/266 [02:23<01:24,  1.31it/s]Loading train:  59%|█████▉    | 157/266 [02:24<01:20,  1.35it/s]Loading train:  59%|█████▉    | 158/266 [02:24<01:16,  1.41it/s]Loading train:  60%|█████▉    | 159/266 [02:25<01:12,  1.47it/s]Loading train:  60%|██████    | 160/266 [02:26<01:10,  1.51it/s]Loading train:  61%|██████    | 161/266 [02:26<01:08,  1.54it/s]Loading train:  61%|██████    | 162/266 [02:27<01:07,  1.54it/s]Loading train:  61%|██████▏   | 163/266 [02:28<01:05,  1.57it/s]Loading train:  62%|██████▏   | 164/266 [02:28<01:05,  1.56it/s]Loading train:  62%|██████▏   | 165/266 [02:29<01:06,  1.52it/s]Loading train:  62%|██████▏   | 166/266 [02:30<01:08,  1.46it/s]Loading train:  63%|██████▎   | 167/266 [02:30<01:06,  1.48it/s]Loading train:  63%|██████▎   | 168/266 [02:31<01:05,  1.50it/s]Loading train:  64%|██████▎   | 169/266 [02:32<01:06,  1.45it/s]Loading train:  64%|██████▍   | 170/266 [02:32<01:08,  1.41it/s]Loading train:  64%|██████▍   | 171/266 [02:33<01:05,  1.45it/s]Loading train:  65%|██████▍   | 172/266 [02:34<01:03,  1.49it/s]Loading train:  65%|██████▌   | 173/266 [02:35<01:09,  1.34it/s]Loading train:  65%|██████▌   | 174/266 [02:35<01:07,  1.37it/s]Loading train:  66%|██████▌   | 175/266 [02:36<01:09,  1.30it/s]Loading train:  66%|██████▌   | 176/266 [02:37<01:13,  1.23it/s]Loading train:  67%|██████▋   | 177/266 [02:38<01:12,  1.22it/s]Loading train:  67%|██████▋   | 178/266 [02:39<01:09,  1.27it/s]Loading train:  67%|██████▋   | 179/266 [02:39<01:05,  1.33it/s]Loading train:  68%|██████▊   | 180/266 [02:40<01:05,  1.32it/s]Loading train:  68%|██████▊   | 181/266 [02:41<01:07,  1.26it/s]Loading train:  68%|██████▊   | 182/266 [02:42<01:04,  1.30it/s]Loading train:  69%|██████▉   | 183/266 [02:43<01:05,  1.27it/s]Loading train:  69%|██████▉   | 184/266 [02:43<01:04,  1.28it/s]Loading train:  70%|██████▉   | 185/266 [02:44<01:04,  1.25it/s]Loading train:  70%|██████▉   | 186/266 [02:45<01:05,  1.23it/s]Loading train:  70%|███████   | 187/266 [02:46<01:01,  1.29it/s]Loading train:  71%|███████   | 188/266 [02:46<00:57,  1.35it/s]Loading train:  71%|███████   | 189/266 [02:47<00:56,  1.37it/s]Loading train:  71%|███████▏  | 190/266 [02:48<00:56,  1.35it/s]Loading train:  72%|███████▏  | 191/266 [02:49<01:06,  1.13it/s]Loading train:  72%|███████▏  | 192/266 [02:50<01:10,  1.06it/s]Loading train:  73%|███████▎  | 193/266 [02:51<01:15,  1.03s/it]Loading train:  73%|███████▎  | 194/266 [02:53<01:24,  1.17s/it]Loading train:  73%|███████▎  | 195/266 [02:54<01:16,  1.08s/it]Loading train:  74%|███████▎  | 196/266 [02:54<01:09,  1.01it/s]Loading train:  74%|███████▍  | 197/266 [02:55<01:06,  1.04it/s]Loading train:  74%|███████▍  | 198/266 [02:56<01:02,  1.08it/s]Loading train:  75%|███████▍  | 199/266 [02:57<00:59,  1.12it/s]Loading train:  75%|███████▌  | 200/266 [02:58<00:56,  1.16it/s]Loading train:  76%|███████▌  | 201/266 [02:59<01:02,  1.05it/s]Loading train:  76%|███████▌  | 202/266 [03:00<00:58,  1.10it/s]Loading train:  76%|███████▋  | 203/266 [03:01<00:57,  1.10it/s]Loading train:  77%|███████▋  | 204/266 [03:02<00:55,  1.12it/s]Loading train:  77%|███████▋  | 205/266 [03:02<00:54,  1.13it/s]Loading train:  77%|███████▋  | 206/266 [03:03<00:51,  1.17it/s]Loading train:  78%|███████▊  | 207/266 [03:04<00:54,  1.09it/s]Loading train:  78%|███████▊  | 208/266 [03:05<00:54,  1.07it/s]Loading train:  79%|███████▊  | 209/266 [03:06<00:53,  1.07it/s]Loading train:  79%|███████▉  | 210/266 [03:07<00:51,  1.08it/s]Loading train:  79%|███████▉  | 211/266 [03:08<00:49,  1.11it/s]Loading train:  80%|███████▉  | 212/266 [03:09<00:47,  1.13it/s]Loading train:  80%|████████  | 213/266 [03:10<00:54,  1.02s/it]Loading train:  80%|████████  | 214/266 [03:11<00:54,  1.05s/it]Loading train:  81%|████████  | 215/266 [03:12<00:52,  1.02s/it]Loading train:  81%|████████  | 216/266 [03:13<00:53,  1.06s/it]Loading train:  82%|████████▏ | 217/266 [03:15<00:53,  1.10s/it]Loading train:  82%|████████▏ | 218/266 [03:16<00:55,  1.16s/it]Loading train:  82%|████████▏ | 219/266 [03:17<00:52,  1.11s/it]Loading train:  83%|████████▎ | 220/266 [03:18<00:51,  1.12s/it]Loading train:  83%|████████▎ | 221/266 [03:19<00:52,  1.16s/it]Loading train:  83%|████████▎ | 222/266 [03:20<00:49,  1.12s/it]Loading train:  84%|████████▍ | 223/266 [03:21<00:47,  1.10s/it]Loading train:  84%|████████▍ | 224/266 [03:23<00:49,  1.17s/it]Loading train:  85%|████████▍ | 225/266 [03:24<00:46,  1.13s/it]Loading train:  85%|████████▍ | 226/266 [03:25<00:42,  1.05s/it]Loading train:  85%|████████▌ | 227/266 [03:26<00:43,  1.12s/it]Loading train:  86%|████████▌ | 228/266 [03:27<00:41,  1.08s/it]Loading train:  86%|████████▌ | 229/266 [03:28<00:42,  1.16s/it]Loading train:  86%|████████▋ | 230/266 [03:29<00:39,  1.11s/it]Loading train:  87%|████████▋ | 231/266 [03:30<00:41,  1.18s/it]Loading train:  87%|████████▋ | 232/266 [03:32<00:39,  1.17s/it]Loading train:  88%|████████▊ | 233/266 [03:33<00:39,  1.18s/it]Loading train:  88%|████████▊ | 234/266 [03:34<00:37,  1.18s/it]Loading train:  88%|████████▊ | 235/266 [03:35<00:35,  1.13s/it]Loading train:  89%|████████▊ | 236/266 [03:36<00:31,  1.05s/it]Loading train:  89%|████████▉ | 237/266 [03:37<00:31,  1.10s/it]Loading train:  89%|████████▉ | 238/266 [03:38<00:29,  1.06s/it]Loading train:  90%|████████▉ | 239/266 [03:40<00:32,  1.21s/it]Loading train:  90%|█████████ | 240/266 [03:41<00:30,  1.17s/it]Loading train:  91%|█████████ | 241/266 [03:42<00:27,  1.12s/it]Loading train:  91%|█████████ | 242/266 [03:43<00:25,  1.07s/it]Loading train:  91%|█████████▏| 243/266 [03:44<00:24,  1.08s/it]Loading train:  92%|█████████▏| 244/266 [03:45<00:24,  1.11s/it]Loading train:  92%|█████████▏| 245/266 [03:46<00:23,  1.13s/it]Loading train:  92%|█████████▏| 246/266 [03:47<00:21,  1.07s/it]Loading train:  93%|█████████▎| 247/266 [03:48<00:20,  1.06s/it]Loading train:  93%|█████████▎| 248/266 [03:49<00:18,  1.06s/it]Loading train:  94%|█████████▎| 249/266 [03:50<00:18,  1.08s/it]Loading train:  94%|█████████▍| 250/266 [03:51<00:16,  1.04s/it]Loading train:  94%|█████████▍| 251/266 [03:52<00:16,  1.07s/it]Loading train:  95%|█████████▍| 252/266 [03:53<00:14,  1.06s/it]Loading train:  95%|█████████▌| 253/266 [03:55<00:14,  1.12s/it]Loading train:  95%|█████████▌| 254/266 [03:56<00:14,  1.21s/it]Loading train:  96%|█████████▌| 255/266 [03:57<00:12,  1.18s/it]Loading train:  96%|█████████▌| 256/266 [03:58<00:11,  1.18s/it]Loading train:  97%|█████████▋| 257/266 [04:00<00:10,  1.17s/it]Loading train:  97%|█████████▋| 258/266 [04:01<00:09,  1.25s/it]Loading train:  97%|█████████▋| 259/266 [04:02<00:08,  1.24s/it]Loading train:  98%|█████████▊| 260/266 [04:03<00:07,  1.21s/it]Loading train:  98%|█████████▊| 261/266 [04:05<00:06,  1.32s/it]Loading train:  98%|█████████▊| 262/266 [04:06<00:05,  1.30s/it]Loading train:  99%|█████████▉| 263/266 [04:08<00:04,  1.39s/it]Loading train:  99%|█████████▉| 264/266 [04:09<00:02,  1.35s/it]Loading train: 100%|█████████▉| 265/266 [04:10<00:01,  1.28s/it]Loading train: 100%|██████████| 266/266 [04:11<00:00,  1.21s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:04, 63.87it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:03, 72.98it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:03, 74.41it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:03, 75.08it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:02, 74.84it/s]concatenating: train:  20%|█▉        | 52/266 [00:00<00:02, 76.35it/s]concatenating: train:  24%|██▍       | 65/266 [00:00<00:02, 86.43it/s]concatenating: train:  28%|██▊       | 74/266 [00:00<00:02, 82.75it/s]concatenating: train:  31%|███       | 83/266 [00:00<00:02, 81.03it/s]concatenating: train:  36%|███▌      | 95/266 [00:01<00:01, 88.98it/s]concatenating: train:  39%|███▉      | 105/266 [00:01<00:01, 84.54it/s]concatenating: train:  44%|████▍     | 118/266 [00:01<00:01, 92.85it/s]concatenating: train:  49%|████▉     | 130/266 [00:01<00:01, 97.66it/s]concatenating: train:  53%|█████▎    | 141/266 [00:01<00:01, 75.38it/s]concatenating: train:  56%|█████▋    | 150/266 [00:01<00:01, 60.66it/s]concatenating: train:  59%|█████▉    | 158/266 [00:02<00:01, 61.77it/s]concatenating: train:  62%|██████▏   | 166/266 [00:02<00:01, 63.77it/s]concatenating: train:  65%|██████▌   | 173/266 [00:02<00:01, 63.38it/s]concatenating: train:  68%|██████▊   | 180/266 [00:02<00:01, 64.44it/s]concatenating: train:  73%|███████▎  | 193/266 [00:02<00:00, 74.88it/s]concatenating: train:  77%|███████▋  | 206/266 [00:02<00:00, 85.10it/s]concatenating: train:  82%|████████▏ | 219/266 [00:02<00:00, 93.40it/s]concatenating: train:  86%|████████▋ | 230/266 [00:02<00:00, 88.40it/s]concatenating: train:  91%|█████████ | 242/266 [00:02<00:00, 94.98it/s]concatenating: train:  95%|█████████▌| 253/266 [00:03<00:00, 94.06it/s]concatenating: train:  99%|█████████▉| 263/266 [00:03<00:00, 83.23it/s]concatenating: train: 100%|██████████| 266/266 [00:03<00:00, 83.19it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.32s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.37s/it]Loading test:  75%|███████▌  | 3/4 [00:04<00:01,  1.34s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.40s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 56.25it/s]2019-07-28 19:41:03.786132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 19:41:03.786251: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 19:41:03.786268: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 19:41:03.786277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 19:41:03.786738: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.94it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.66it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.23it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.73it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.08it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.46it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.71it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.36it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:06,  3.79it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:04<00:16,  1.49it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:05<00:16,  1.37it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:05<00:10,  1.89it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:05<00:06,  2.48it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:06<00:05,  2.81it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:06<00:03,  3.56it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:06<00:03,  3.78it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:01,  4.97it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  5.61it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:08<00:02,  2.06it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:09<00:02,  1.78it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:10<00:02,  1.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:10<00:00,  4.14it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 84, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 84, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 84, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 84, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 84, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 84, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 84, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 84, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 84, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 42, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 42, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 42, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 42, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 42, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 42, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 42, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 21, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 21, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 21, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 21, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 21, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 21, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 21, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 21, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 42, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 42, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 42, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 42, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 42, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 42, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 42, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 84, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 84, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 84, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 84, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 84, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 84, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 84, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 84, 20)   10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 84, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 84, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 84, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 84, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 84, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 84, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 84, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 84, 80)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 84, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 246,273
Trainable params: 71,433
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.31801167e-02 3.27453772e-02 7.65705610e-02 9.51427723e-03
 2.75364848e-02 7.20414505e-03 8.58509081e-02 1.13852692e-01
 8.93629471e-02 1.35773414e-02 2.89732251e-01 1.90608331e-01
 2.64566685e-04]
Train on 9522 samples, validate on 139 samples
Epoch 1/300
 - 21s - loss: 2.5454 - acc: 0.6429 - mDice: 0.1225 - val_loss: 2.4923 - val_acc: 0.8971 - val_mDice: 0.1575

Epoch 00001: val_mDice improved from -inf to 0.15753, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 1.0663 - acc: 0.8795 - mDice: 0.3333 - val_loss: 0.8931 - val_acc: 0.9145 - val_mDice: 0.4004

Epoch 00002: val_mDice improved from 0.15753 to 0.40044, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.8023 - acc: 0.8862 - mDice: 0.4327 - val_loss: 0.7353 - val_acc: 0.9220 - val_mDice: 0.4873

Epoch 00003: val_mDice improved from 0.40044 to 0.48732, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.6824 - acc: 0.8923 - mDice: 0.4896 - val_loss: 0.8341 - val_acc: 0.9184 - val_mDice: 0.4575

Epoch 00004: val_mDice did not improve from 0.48732
Epoch 5/300
 - 13s - loss: 0.6253 - acc: 0.8975 - mDice: 0.5201 - val_loss: 0.6385 - val_acc: 0.9218 - val_mDice: 0.5165

Epoch 00005: val_mDice improved from 0.48732 to 0.51648, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.5812 - acc: 0.9033 - mDice: 0.5441 - val_loss: 0.5851 - val_acc: 0.9295 - val_mDice: 0.5436

Epoch 00006: val_mDice improved from 0.51648 to 0.54361, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.5521 - acc: 0.9089 - mDice: 0.5606 - val_loss: 0.6201 - val_acc: 0.9306 - val_mDice: 0.5311

Epoch 00007: val_mDice did not improve from 0.54361
Epoch 8/300
 - 13s - loss: 0.5268 - acc: 0.9137 - mDice: 0.5752 - val_loss: 0.6183 - val_acc: 0.9323 - val_mDice: 0.5414

Epoch 00008: val_mDice did not improve from 0.54361
Epoch 9/300
 - 13s - loss: 0.5100 - acc: 0.9177 - mDice: 0.5853 - val_loss: 0.5506 - val_acc: 0.9283 - val_mDice: 0.5642

Epoch 00009: val_mDice improved from 0.54361 to 0.56422, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4948 - acc: 0.9212 - mDice: 0.5942 - val_loss: 0.6351 - val_acc: 0.9118 - val_mDice: 0.5249

Epoch 00010: val_mDice did not improve from 0.56422
Epoch 11/300
 - 13s - loss: 0.4757 - acc: 0.9234 - mDice: 0.6057 - val_loss: 0.5965 - val_acc: 0.9144 - val_mDice: 0.5426

Epoch 00011: val_mDice did not improve from 0.56422
Epoch 12/300
 - 13s - loss: 0.4634 - acc: 0.9246 - mDice: 0.6134 - val_loss: 0.5238 - val_acc: 0.9303 - val_mDice: 0.5808

Epoch 00012: val_mDice improved from 0.56422 to 0.58077, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 13s - loss: 0.4512 - acc: 0.9259 - mDice: 0.6212 - val_loss: 0.5306 - val_acc: 0.9361 - val_mDice: 0.5803

Epoch 00013: val_mDice did not improve from 0.58077
Epoch 14/300
 - 13s - loss: 0.4448 - acc: 0.9269 - mDice: 0.6257 - val_loss: 0.5373 - val_acc: 0.9328 - val_mDice: 0.5768

Epoch 00014: val_mDice did not improve from 0.58077
Epoch 15/300
 - 13s - loss: 0.4303 - acc: 0.9283 - mDice: 0.6349 - val_loss: 0.5383 - val_acc: 0.9390 - val_mDice: 0.5797

Epoch 00015: val_mDice did not improve from 0.58077
Epoch 16/300
 - 13s - loss: 0.4256 - acc: 0.9290 - mDice: 0.6380 - val_loss: 0.5304 - val_acc: 0.9314 - val_mDice: 0.5790

Epoch 00016: val_mDice did not improve from 0.58077
Epoch 17/300
 - 13s - loss: 0.4156 - acc: 0.9298 - mDice: 0.6445 - val_loss: 0.5298 - val_acc: 0.9299 - val_mDice: 0.5782

Epoch 00017: val_mDice did not improve from 0.58077
Epoch 18/300
 - 13s - loss: 0.4101 - acc: 0.9304 - mDice: 0.6481 - val_loss: 0.5455 - val_acc: 0.9309 - val_mDice: 0.5716

Epoch 00018: val_mDice did not improve from 0.58077
Epoch 19/300
 - 13s - loss: 0.4023 - acc: 0.9312 - mDice: 0.6533 - val_loss: 0.5285 - val_acc: 0.9343 - val_mDice: 0.5815

Epoch 00019: val_mDice improved from 0.58077 to 0.58153, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 13s - loss: 0.3987 - acc: 0.9318 - mDice: 0.6559 - val_loss: 0.5275 - val_acc: 0.9308 - val_mDice: 0.5793

Epoch 00020: val_mDice did not improve from 0.58153
Epoch 21/300
 - 13s - loss: 0.3921 - acc: 0.9326 - mDice: 0.6605 - val_loss: 0.5159 - val_acc: 0.9343 - val_mDice: 0.5874

Epoch 00021: val_mDice improved from 0.58153 to 0.58740, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 13s - loss: 0.3883 - acc: 0.9331 - mDice: 0.6631 - val_loss: 0.5451 - val_acc: 0.9282 - val_mDice: 0.5711

Epoch 00022: val_mDice did not improve from 0.58740
Epoch 23/300
 - 13s - loss: 0.3784 - acc: 0.9341 - mDice: 0.6697 - val_loss: 0.5235 - val_acc: 0.9355 - val_mDice: 0.5864

Epoch 00023: val_mDice did not improve from 0.58740
Epoch 24/300
 - 13s - loss: 0.3797 - acc: 0.9341 - mDice: 0.6689 - val_loss: 0.5232 - val_acc: 0.9389 - val_mDice: 0.5899

Epoch 00024: val_mDice improved from 0.58740 to 0.58986, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 13s - loss: 0.3734 - acc: 0.9345 - mDice: 0.6735 - val_loss: 0.5441 - val_acc: 0.9378 - val_mDice: 0.5784

Epoch 00025: val_mDice did not improve from 0.58986
Epoch 26/300
 - 13s - loss: 0.3694 - acc: 0.9351 - mDice: 0.6760 - val_loss: 0.5053 - val_acc: 0.9358 - val_mDice: 0.5937

Epoch 00026: val_mDice improved from 0.58986 to 0.59369, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 13s - loss: 0.3662 - acc: 0.9354 - mDice: 0.6785 - val_loss: 0.5643 - val_acc: 0.9308 - val_mDice: 0.5670

Epoch 00027: val_mDice did not improve from 0.59369
Epoch 28/300
 - 13s - loss: 0.3615 - acc: 0.9360 - mDice: 0.6817 - val_loss: 0.4914 - val_acc: 0.9368 - val_mDice: 0.6004

Epoch 00028: val_mDice improved from 0.59369 to 0.60042, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 13s - loss: 0.3599 - acc: 0.9363 - mDice: 0.6829 - val_loss: 0.5020 - val_acc: 0.9351 - val_mDice: 0.5941

Epoch 00029: val_mDice did not improve from 0.60042
Epoch 30/300
 - 13s - loss: 0.3561 - acc: 0.9367 - mDice: 0.6855 - val_loss: 0.5116 - val_acc: 0.9405 - val_mDice: 0.6020

Epoch 00030: val_mDice improved from 0.60042 to 0.60200, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 13s - loss: 0.3527 - acc: 0.9371 - mDice: 0.6879 - val_loss: 0.4876 - val_acc: 0.9399 - val_mDice: 0.6053

Epoch 00031: val_mDice improved from 0.60200 to 0.60527, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 13s - loss: 0.3482 - acc: 0.9374 - mDice: 0.6911 - val_loss: 0.5138 - val_acc: 0.9302 - val_mDice: 0.5881

Epoch 00032: val_mDice did not improve from 0.60527
Epoch 33/300
 - 13s - loss: 0.3503 - acc: 0.9375 - mDice: 0.6900 - val_loss: 0.4878 - val_acc: 0.9388 - val_mDice: 0.6037

Epoch 00033: val_mDice did not improve from 0.60527
Epoch 34/300
 - 13s - loss: 0.3422 - acc: 0.9380 - mDice: 0.6955 - val_loss: 0.4864 - val_acc: 0.9393 - val_mDice: 0.6035

Epoch 00034: val_mDice did not improve from 0.60527
Epoch 35/300
 - 13s - loss: 0.3647 - acc: 0.9360 - mDice: 0.6807 - val_loss: 0.4999 - val_acc: 0.9374 - val_mDice: 0.5997

Epoch 00035: val_mDice did not improve from 0.60527
Epoch 36/300
 - 13s - loss: 0.3428 - acc: 0.9383 - mDice: 0.6951 - val_loss: 0.4982 - val_acc: 0.9370 - val_mDice: 0.5960

Epoch 00036: val_mDice did not improve from 0.60527
Epoch 37/300
 - 13s - loss: 0.3370 - acc: 0.9385 - mDice: 0.6993 - val_loss: 0.4761 - val_acc: 0.9412 - val_mDice: 0.6127

Epoch 00037: val_mDice improved from 0.60527 to 0.61272, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 38/300
 - 13s - loss: 0.3352 - acc: 0.9390 - mDice: 0.7008 - val_loss: 0.4855 - val_acc: 0.9386 - val_mDice: 0.6076

Epoch 00038: val_mDice did not improve from 0.61272
Epoch 39/300
 - 13s - loss: 0.3316 - acc: 0.9394 - mDice: 0.7032 - val_loss: 0.5113 - val_acc: 0.9402 - val_mDice: 0.5949

Epoch 00039: val_mDice did not improve from 0.61272
Epoch 40/300
 - 13s - loss: 0.3304 - acc: 0.9397 - mDice: 0.7042 - val_loss: 0.5053 - val_acc: 0.9409 - val_mDice: 0.5967

Epoch 00040: val_mDice did not improve from 0.61272
Epoch 41/300
 - 13s - loss: 0.3371 - acc: 0.9392 - mDice: 0.6995 - val_loss: 0.5337 - val_acc: 0.9381 - val_mDice: 0.5864

Epoch 00041: val_mDice did not improve from 0.61272
Epoch 42/300
 - 13s - loss: 0.3281 - acc: 0.9397 - mDice: 0.7058 - val_loss: 0.5625 - val_acc: 0.9351 - val_mDice: 0.5656

Epoch 00042: val_mDice did not improve from 0.61272
Epoch 43/300
 - 13s - loss: 0.3268 - acc: 0.9402 - mDice: 0.7069 - val_loss: 0.5120 - val_acc: 0.9426 - val_mDice: 0.5993

Epoch 00043: val_mDice did not improve from 0.61272
Epoch 44/300
 - 13s - loss: 0.3236 - acc: 0.9403 - mDice: 0.7092 - val_loss: 0.4935 - val_acc: 0.9420 - val_mDice: 0.6061

Epoch 00044: val_mDice did not improve from 0.61272
Epoch 45/300
 - 13s - loss: 0.3222 - acc: 0.9407 - mDice: 0.7103 - val_loss: 0.4778 - val_acc: 0.9434 - val_mDice: 0.6114

Epoch 00045: val_mDice did not improve from 0.61272
Epoch 46/300
 - 13s - loss: 0.3211 - acc: 0.9408 - mDice: 0.7111 - val_loss: 0.4875 - val_acc: 0.9401 - val_mDice: 0.6060

Epoch 00046: val_mDice did not improve from 0.61272
Epoch 47/300
 - 13s - loss: 0.3203 - acc: 0.9408 - mDice: 0.7118 - val_loss: 0.4860 - val_acc: 0.9357 - val_mDice: 0.6016

Epoch 00047: val_mDice did not improve from 0.61272
Epoch 48/300
 - 13s - loss: 0.3204 - acc: 0.9409 - mDice: 0.7140 - val_loss: 0.5244 - val_acc: 0.9347 - val_mDice: 0.5812

Epoch 00048: val_mDice did not improve from 0.61272
Epoch 49/300
 - 13s - loss: 0.3184 - acc: 0.9410 - mDice: 0.7132 - val_loss: 0.5126 - val_acc: 0.9415 - val_mDice: 0.5958

Epoch 00049: val_mDice did not improve from 0.61272
Epoch 50/300
 - 13s - loss: 0.3194 - acc: 0.9410 - mDice: 0.7129 - val_loss: 0.5363 - val_acc: 0.9400 - val_mDice: 0.5851

Epoch 00050: val_mDice did not improve from 0.61272
Epoch 51/300
 - 13s - loss: 0.3132 - acc: 0.9414 - mDice: 0.7169 - val_loss: 0.5078 - val_acc: 0.9414 - val_mDice: 0.5959

Epoch 00051: val_mDice did not improve from 0.61272
Epoch 52/300
 - 13s - loss: 0.3115 - acc: 0.9417 - mDice: 0.7181 - val_loss: 0.4994 - val_acc: 0.9431 - val_mDice: 0.6060

Epoch 00052: val_mDice did not improve from 0.61272
Epoch 53/300
 - 13s - loss: 0.3117 - acc: 0.9416 - mDice: 0.7180 - val_loss: 0.4731 - val_acc: 0.9420 - val_mDice: 0.6144

Epoch 00053: val_mDice improved from 0.61272 to 0.61440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 13s - loss: 0.3088 - acc: 0.9420 - mDice: 0.7203 - val_loss: 0.4896 - val_acc: 0.9394 - val_mDice: 0.6019

Epoch 00054: val_mDice did not improve from 0.61440
Epoch 55/300
 - 13s - loss: 0.3083 - acc: 0.9420 - mDice: 0.7206 - val_loss: 0.4793 - val_acc: 0.9433 - val_mDice: 0.6109

Epoch 00055: val_mDice did not improve from 0.61440
Epoch 56/300
 - 13s - loss: 0.3069 - acc: 0.9422 - mDice: 0.7218 - val_loss: 0.5019 - val_acc: 0.9417 - val_mDice: 0.6030

Epoch 00056: val_mDice did not improve from 0.61440
Epoch 57/300
 - 13s - loss: 0.3071 - acc: 0.9421 - mDice: 0.7216 - val_loss: 0.5274 - val_acc: 0.9414 - val_mDice: 0.5899

Epoch 00057: val_mDice did not improve from 0.61440
Epoch 58/300
 - 13s - loss: 0.3063 - acc: 0.9422 - mDice: 0.7221 - val_loss: 0.4890 - val_acc: 0.9395 - val_mDice: 0.6042

Epoch 00058: val_mDice did not improve from 0.61440
Epoch 59/300
 - 13s - loss: 0.3035 - acc: 0.9426 - mDice: 0.7243 - val_loss: 0.5146 - val_acc: 0.9385 - val_mDice: 0.5920

Epoch 00059: val_mDice did not improve from 0.61440
Epoch 60/300
 - 13s - loss: 0.3036 - acc: 0.9425 - mDice: 0.7241 - val_loss: 0.4776 - val_acc: 0.9416 - val_mDice: 0.6104

Epoch 00060: val_mDice did not improve from 0.61440
Epoch 61/300
 - 13s - loss: 0.3011 - acc: 0.9428 - mDice: 0.7261 - val_loss: 0.4852 - val_acc: 0.9400 - val_mDice: 0.6065

Epoch 00061: val_mDice did not improve from 0.61440
Epoch 62/300
 - 13s - loss: 0.3011 - acc: 0.9427 - mDice: 0.7259 - val_loss: 0.4930 - val_acc: 0.9392 - val_mDice: 0.5999

Epoch 00062: val_mDice did not improve from 0.61440
Epoch 63/300
 - 13s - loss: 0.2987 - acc: 0.9431 - mDice: 0.7278 - val_loss: 0.5084 - val_acc: 0.9347 - val_mDice: 0.5910

Epoch 00063: val_mDice did not improve from 0.61440
Epoch 64/300
 - 13s - loss: 0.2989 - acc: 0.9429 - mDice: 0.7278 - val_loss: 0.4815 - val_acc: 0.9416 - val_mDice: 0.6069

Epoch 00064: val_mDice did not improve from 0.61440
Epoch 65/300
 - 13s - loss: 0.2973 - acc: 0.9432 - mDice: 0.7290 - val_loss: 0.5010 - val_acc: 0.9395 - val_mDice: 0.5978

Epoch 00065: val_mDice did not improve from 0.61440
Epoch 66/300
 - 13s - loss: 0.2966 - acc: 0.9432 - mDice: 0.7296 - val_loss: 0.5040 - val_acc: 0.9381 - val_mDice: 0.5932

Epoch 00066: val_mDice did not improve from 0.61440
Epoch 67/300
 - 13s - loss: 0.2953 - acc: 0.9435 - mDice: 0.7305 - val_loss: 0.4767 - val_acc: 0.9428 - val_mDice: 0.6120

Epoch 00067: val_mDice did not improve from 0.61440
Epoch 68/300
 - 13s - loss: 0.2954 - acc: 0.9434 - mDice: 0.7306 - val_loss: 0.5174 - val_acc: 0.9417 - val_mDice: 0.5943

Epoch 00068: val_mDice did not improve from 0.61440
Epoch 69/300
 - 13s - loss: 0.2945 - acc: 0.9435 - mDice: 0.7311 - val_loss: 0.5141 - val_acc: 0.9366 - val_mDice: 0.5880

Epoch 00069: val_mDice did not improve from 0.61440
Epoch 70/300
 - 13s - loss: 0.2931 - acc: 0.9436 - mDice: 0.7322 - val_loss: 0.5010 - val_acc: 0.9410 - val_mDice: 0.6007

Epoch 00070: val_mDice did not improve from 0.61440
Epoch 71/300
 - 13s - loss: 0.2918 - acc: 0.9438 - mDice: 0.7331 - val_loss: 0.4893 - val_acc: 0.9406 - val_mDice: 0.6024

Epoch 00071: val_mDice did not improve from 0.61440
Epoch 72/300
 - 13s - loss: 0.2919 - acc: 0.9437 - mDice: 0.7331 - val_loss: 0.4787 - val_acc: 0.9417 - val_mDice: 0.6109

Epoch 00072: val_mDice did not improve from 0.61440
Epoch 73/300
 - 13s - loss: 0.2932 - acc: 0.9438 - mDice: 0.7322 - val_loss: 0.4776 - val_acc: 0.9404 - val_mDice: 0.6102

Epoch 00073: val_mDice did not improve from 0.61440
Epoch 74/300
 - 13s - loss: 0.2907 - acc: 0.9440 - mDice: 0.7339 - val_loss: 0.4888 - val_acc: 0.9349 - val_mDice: 0.6015

Epoch 00074: val_mDice did not improve from 0.61440
Epoch 75/300
 - 13s - loss: 0.2884 - acc: 0.9442 - mDice: 0.7358 - val_loss: 0.5132 - val_acc: 0.9425 - val_mDice: 0.5978

Epoch 00075: val_mDice did not improve from 0.61440
Epoch 76/300
 - 13s - loss: 0.2913 - acc: 0.9438 - mDice: 0.7335 - val_loss: 0.4704 - val_acc: 0.9424 - val_mDice: 0.6161

Epoch 00076: val_mDice improved from 0.61440 to 0.61614, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 77/300
 - 13s - loss: 0.2888 - acc: 0.9442 - mDice: 0.7356 - val_loss: 0.5033 - val_acc: 0.9433 - val_mDice: 0.6013

Epoch 00077: val_mDice did not improve from 0.61614
Epoch 78/300
 - 13s - loss: 0.2877 - acc: 0.9443 - mDice: 0.7364 - val_loss: 0.4855 - val_acc: 0.9413 - val_mDice: 0.6064

Epoch 00078: val_mDice did not improve from 0.61614
Epoch 79/300
 - 13s - loss: 0.2867 - acc: 0.9446 - mDice: 0.7384 - val_loss: 0.5652 - val_acc: 0.9285 - val_mDice: 0.5598

Epoch 00079: val_mDice did not improve from 0.61614
Epoch 80/300
 - 13s - loss: 0.3733 - acc: 0.9336 - mDice: 0.6771 - val_loss: 0.5062 - val_acc: 0.9393 - val_mDice: 0.5983

Epoch 00080: val_mDice did not improve from 0.61614
Epoch 81/300
 - 13s - loss: 0.2937 - acc: 0.9433 - mDice: 0.7316 - val_loss: 0.4926 - val_acc: 0.9369 - val_mDice: 0.6023

Epoch 00081: val_mDice did not improve from 0.61614
Epoch 82/300
 - 13s - loss: 0.2893 - acc: 0.9441 - mDice: 0.7351 - val_loss: 0.4875 - val_acc: 0.9403 - val_mDice: 0.6050

Epoch 00082: val_mDice did not improve from 0.61614
Epoch 83/300
 - 13s - loss: 0.2865 - acc: 0.9444 - mDice: 0.7372 - val_loss: 0.4855 - val_acc: 0.9401 - val_mDice: 0.6047

Epoch 00083: val_mDice did not improve from 0.61614
Epoch 84/300
 - 13s - loss: 0.2839 - acc: 0.9446 - mDice: 0.7392 - val_loss: 0.4870 - val_acc: 0.9435 - val_mDice: 0.6092

Epoch 00084: val_mDice did not improve from 0.61614
Epoch 85/300
 - 13s - loss: 0.2817 - acc: 0.9449 - mDice: 0.7409 - val_loss: 0.4685 - val_acc: 0.9429 - val_mDice: 0.6169

Epoch 00085: val_mDice improved from 0.61614 to 0.61688, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 86/300
 - 13s - loss: 0.2800 - acc: 0.9452 - mDice: 0.7423 - val_loss: 0.4890 - val_acc: 0.9387 - val_mDice: 0.6015

Epoch 00086: val_mDice did not improve from 0.61688
Epoch 87/300
 - 13s - loss: 0.2805 - acc: 0.9451 - mDice: 0.7419 - val_loss: 0.4833 - val_acc: 0.9379 - val_mDice: 0.6072

Epoch 00087: val_mDice did not improve from 0.61688
Epoch 88/300
 - 13s - loss: 0.2803 - acc: 0.9451 - mDice: 0.7421 - val_loss: 0.4917 - val_acc: 0.9417 - val_mDice: 0.6037

Epoch 00088: val_mDice did not improve from 0.61688
Epoch 89/300
 - 13s - loss: 0.2792 - acc: 0.9452 - mDice: 0.7429 - val_loss: 0.4918 - val_acc: 0.9407 - val_mDice: 0.6052

Epoch 00089: val_mDice did not improve from 0.61688
Epoch 90/300
 - 13s - loss: 0.2783 - acc: 0.9453 - mDice: 0.7435 - val_loss: 0.4820 - val_acc: 0.9421 - val_mDice: 0.6090

Epoch 00090: val_mDice did not improve from 0.61688
Epoch 91/300
 - 13s - loss: 0.2790 - acc: 0.9453 - mDice: 0.7431 - val_loss: 0.4783 - val_acc: 0.9413 - val_mDice: 0.6106

Epoch 00091: val_mDice did not improve from 0.61688
Epoch 92/300
 - 13s - loss: 0.2798 - acc: 0.9454 - mDice: 0.7438 - val_loss: 0.5646 - val_acc: 0.9333 - val_mDice: 0.5623

Epoch 00092: val_mDice did not improve from 0.61688
Epoch 93/300
 - 13s - loss: 0.2915 - acc: 0.9438 - mDice: 0.7338 - val_loss: 0.4879 - val_acc: 0.9428 - val_mDice: 0.6066

Epoch 00093: val_mDice did not improve from 0.61688
Epoch 94/300
 - 13s - loss: 0.2776 - acc: 0.9455 - mDice: 0.7443 - val_loss: 0.5364 - val_acc: 0.9351 - val_mDice: 0.5788

Epoch 00094: val_mDice did not improve from 0.61688
Epoch 95/300
 - 13s - loss: 0.2847 - acc: 0.9449 - mDice: 0.7388 - val_loss: 0.4758 - val_acc: 0.9438 - val_mDice: 0.6153

Epoch 00095: val_mDice did not improve from 0.61688
Epoch 96/300
 - 13s - loss: 0.2766 - acc: 0.9457 - mDice: 0.7450 - val_loss: 0.5018 - val_acc: 0.9401 - val_mDice: 0.5992

Epoch 00096: val_mDice did not improve from 0.61688
Epoch 97/300
 - 13s - loss: 0.2727 - acc: 0.9460 - mDice: 0.7479 - val_loss: 0.5010 - val_acc: 0.9428 - val_mDice: 0.5998

Epoch 00097: val_mDice did not improve from 0.61688
Epoch 98/300
 - 13s - loss: 0.2762 - acc: 0.9458 - mDice: 0.7452 - val_loss: 0.5364 - val_acc: 0.9351 - val_mDice: 0.5766

Epoch 00098: val_mDice did not improve from 0.61688
Epoch 99/300
 - 13s - loss: 0.2766 - acc: 0.9458 - mDice: 0.7451 - val_loss: 0.5003 - val_acc: 0.9426 - val_mDice: 0.6026

Epoch 00099: val_mDice did not improve from 0.61688
Epoch 100/300
 - 13s - loss: 0.2762 - acc: 0.9457 - mDice: 0.7452 - val_loss: 0.5020 - val_acc: 0.9416 - val_mDice: 0.6025

Epoch 00100: val_mDice did not improve from 0.61688
Epoch 101/300
 - 13s - loss: 0.2748 - acc: 0.9462 - mDice: 0.7488 - val_loss: 0.4912 - val_acc: 0.9402 - val_mDice: 0.6019

Epoch 00101: val_mDice did not improve from 0.61688
Epoch 102/300
 - 13s - loss: 0.2739 - acc: 0.9460 - mDice: 0.7470 - val_loss: 0.4789 - val_acc: 0.9419 - val_mDice: 0.6103

Epoch 00102: val_mDice did not improve from 0.61688
Epoch 103/300
 - 13s - loss: 0.2739 - acc: 0.9460 - mDice: 0.7471 - val_loss: 0.4942 - val_acc: 0.9438 - val_mDice: 0.6065

Epoch 00103: val_mDice did not improve from 0.61688
Epoch 104/300
 - 13s - loss: 0.2731 - acc: 0.9461 - mDice: 0.7477 - val_loss: 0.4894 - val_acc: 0.9423 - val_mDice: 0.6058

Epoch 00104: val_mDice did not improve from 0.61688
Epoch 105/300
 - 13s - loss: 0.2789 - acc: 0.9461 - mDice: 0.7474 - val_loss: 0.7601 - val_acc: 0.9149 - val_mDice: 0.4739

Epoch 00105: val_mDice did not improve from 0.61688
Epoch 106/300
 - 14s - loss: 0.3890 - acc: 0.9331 - mDice: 0.6682 - val_loss: 0.5138 - val_acc: 0.9424 - val_mDice: 0.5960

Epoch 00106: val_mDice did not improve from 0.61688
Epoch 107/300
 - 13s - loss: 0.2910 - acc: 0.9443 - mDice: 0.7338 - val_loss: 0.4951 - val_acc: 0.9441 - val_mDice: 0.6051

Epoch 00107: val_mDice did not improve from 0.61688
Epoch 108/300
 - 13s - loss: 0.2782 - acc: 0.9457 - mDice: 0.7437 - val_loss: 0.4734 - val_acc: 0.9433 - val_mDice: 0.6133

Epoch 00108: val_mDice did not improve from 0.61688
Epoch 109/300
 - 13s - loss: 0.2735 - acc: 0.9460 - mDice: 0.7473 - val_loss: 0.4845 - val_acc: 0.9439 - val_mDice: 0.6117

Epoch 00109: val_mDice did not improve from 0.61688
Epoch 110/300
 - 13s - loss: 0.2713 - acc: 0.9464 - mDice: 0.7490 - val_loss: 0.4822 - val_acc: 0.9403 - val_mDice: 0.6075

Epoch 00110: val_mDice did not improve from 0.61688
Epoch 111/300
 - 13s - loss: 0.2697 - acc: 0.9465 - mDice: 0.7503 - val_loss: 0.4996 - val_acc: 0.9398 - val_mDice: 0.5989

Epoch 00111: val_mDice did not improve from 0.61688
Epoch 112/300
 - 13s - loss: 0.2696 - acc: 0.9465 - mDice: 0.7504 - val_loss: 0.5098 - val_acc: 0.9409 - val_mDice: 0.5977

Epoch 00112: val_mDice did not improve from 0.61688
Epoch 113/300
 - 13s - loss: 0.2687 - acc: 0.9466 - mDice: 0.7510 - val_loss: 0.5015 - val_acc: 0.9395 - val_mDice: 0.5977

Epoch 00113: val_mDice did not improve from 0.61688
Epoch 114/300
 - 13s - loss: 0.4312 - acc: 0.9309 - mDice: 0.6634 - val_loss: 0.8877 - val_acc: 0.8993 - val_mDice: 0.4333

Epoch 00114: val_mDice did not improve from 0.61688
Epoch 115/300
 - 13s - loss: 0.4042 - acc: 0.9314 - mDice: 0.6525 - val_loss: 0.5170 - val_acc: 0.9336 - val_mDice: 0.5866

Epoch 00115: val_mDice did not improve from 0.61688
Epoch 116/300
 - 13s - loss: 0.3428 - acc: 0.9385 - mDice: 0.6951 - val_loss: 0.5048 - val_acc: 0.9359 - val_mDice: 0.5942

Epoch 00116: val_mDice did not improve from 0.61688
Epoch 117/300
 - 13s - loss: 0.3157 - acc: 0.9414 - mDice: 0.7149 - val_loss: 0.5019 - val_acc: 0.9387 - val_mDice: 0.5987

Epoch 00117: val_mDice did not improve from 0.61688
Epoch 118/300
 - 13s - loss: 0.3016 - acc: 0.9429 - mDice: 0.7257 - val_loss: 0.4934 - val_acc: 0.9397 - val_mDice: 0.6029

Epoch 00118: val_mDice did not improve from 0.61688
Epoch 119/300
 - 13s - loss: 0.2934 - acc: 0.9439 - mDice: 0.7319 - val_loss: 0.4826 - val_acc: 0.9421 - val_mDice: 0.6097

Epoch 00119: val_mDice did not improve from 0.61688
Epoch 120/300
 - 13s - loss: 0.2854 - acc: 0.9449 - mDice: 0.7380 - val_loss: 0.4889 - val_acc: 0.9398 - val_mDice: 0.6050

Epoch 00120: val_mDice did not improve from 0.61688
Epoch 121/300
 - 13s - loss: 0.2833 - acc: 0.9453 - mDice: 0.7409 - val_loss: 0.4861 - val_acc: 0.9424 - val_mDice: 0.6085

Epoch 00121: val_mDice did not improve from 0.61688
Epoch 122/300
 - 13s - loss: 0.2791 - acc: 0.9455 - mDice: 0.7430 - val_loss: 0.5014 - val_acc: 0.9394 - val_mDice: 0.5991

Epoch 00122: val_mDice did not improve from 0.61688
Epoch 123/300
 - 13s - loss: 0.2752 - acc: 0.9459 - mDice: 0.7461 - val_loss: 0.4736 - val_acc: 0.9426 - val_mDice: 0.6155

Epoch 00123: val_mDice did not improve from 0.61688
Epoch 124/300
 - 13s - loss: 0.2727 - acc: 0.9463 - mDice: 0.7479 - val_loss: 0.4945 - val_acc: 0.9403 - val_mDice: 0.6033

Epoch 00124: val_mDice did not improve from 0.61688
Epoch 125/300
 - 13s - loss: 0.2715 - acc: 0.9464 - mDice: 0.7489 - val_loss: 0.4810 - val_acc: 0.9432 - val_mDice: 0.6126

Epoch 00125: val_mDice did not improve from 0.61688
Restoring model weights from the end of the best epoch
Epoch 00125: early stopping
{'val_loss': [2.4922555607857464, 0.8930567974666898, 0.7352533031710617, 0.8341204524040222, 0.6385172802767307, 0.5850692438564712, 0.6201260317143776, 0.6183292038149113, 0.5505682868923215, 0.6350732209871142, 0.596543463442823, 0.5237975877394779, 0.5305614634383496, 0.5373396356757596, 0.538340631148798, 0.5303646958560395, 0.5298477391973674, 0.5455490119165654, 0.5285034304042514, 0.5274518608189315, 0.5159396855093592, 0.5451259876755502, 0.5235174660631221, 0.5231940058066691, 0.5441120444870681, 0.5052576118664776, 0.5643130935353341, 0.4913597597921495, 0.5020122832531552, 0.5115690782344599, 0.48760725911572683, 0.513805232888503, 0.48781258918398573, 0.4864206530636163, 0.4999155764528316, 0.4982155229119088, 0.47607059230049736, 0.4854916434922664, 0.5113371451981634, 0.505251871167327, 0.5336970564701574, 0.5625118744030273, 0.5119608044624329, 0.49350266019217404, 0.47776770420211684, 0.48753057409533496, 0.48597420505482514, 0.5243780111237396, 0.5126308037651529, 0.5363399343524905, 0.5078297606903872, 0.4994288878046351, 0.4731396721850196, 0.48960441715425723, 0.47930143526989777, 0.5019209198385691, 0.5274167208791637, 0.48897076853745275, 0.5145766876584335, 0.4775676429271698, 0.4851579052938832, 0.49299252612127675, 0.5084179479012386, 0.4814687113967731, 0.5009808469590523, 0.5039750875757752, 0.47670177675837233, 0.5173575620857074, 0.5140678020689985, 0.5009592544260643, 0.4892643668668733, 0.4786605519785298, 0.47760619362481205, 0.48878534427649684, 0.5131758552232235, 0.4704402417158909, 0.5033125572924991, 0.4855417669248238, 0.5651930737838471, 0.506213024151411, 0.4925518168819894, 0.4875056179736158, 0.48552786017493377, 0.4870098992217359, 0.4685106569056888, 0.4890100728693626, 0.48330807364244255, 0.491651496226839, 0.49176413335388514, 0.48204427657367516, 0.4783437018343013, 0.5645673894624916, 0.48790326907480364, 0.5364406494785556, 0.47581313068060566, 0.5017528986330513, 0.501038881728975, 0.5364439077943349, 0.5003020954217842, 0.5020242702189109, 0.49124669213946776, 0.47885522653730656, 0.49421401804299664, 0.48944601888279266, 0.7601233017530372, 0.5137932152628041, 0.49514965166290886, 0.4733512347979511, 0.48447079924370745, 0.48220490701764607, 0.49959373388359013, 0.5098179898244871, 0.5015374136914452, 0.8877488567674761, 0.5170055074657468, 0.5047578695866701, 0.5019342434063232, 0.49339951585522657, 0.4825561992127261, 0.4889059789317975, 0.48613026502321094, 0.5013977475732351, 0.47364777348024384, 0.49448883962288176, 0.48102582594473586], 'val_acc': [0.8970521371141612, 0.9145255196008751, 0.9219684562237143, 0.918387801098309, 0.9218350674608629, 0.9294921305539797, 0.9305758682086314, 0.9323151304567461, 0.9283457801496382, 0.9118326242021519, 0.9144497801074021, 0.9302991740137553, 0.9361329627551621, 0.9328487832769216, 0.9390185681178416, 0.9314175016588444, 0.9298841129961631, 0.9309069214107322, 0.9343261757342936, 0.9307751501206871, 0.9342652207655873, 0.9282057962829261, 0.9354609752730499, 0.9389411554062109, 0.9378063361421763, 0.9358348529115855, 0.9308212802564497, 0.9367687041810948, 0.9350590950293507, 0.9405058313616745, 0.9398519611187118, 0.9301838694716529, 0.9388324635491955, 0.9392771425007058, 0.9373649268699207, 0.9370026018122117, 0.9412058145879841, 0.9385985834993047, 0.9402159688284071, 0.9408714762694544, 0.9380912986590708, 0.9351480397389089, 0.9425646225325495, 0.9419931104714921, 0.9434177978433294, 0.9401286780405388, 0.9356717934711374, 0.9346638064590289, 0.9414726337082953, 0.9399524331092834, 0.9414314752002414, 0.9431032088163088, 0.9420112229937272, 0.9393973779335296, 0.9433337990328562, 0.9416900765981605, 0.9413870015590311, 0.9395439620498273, 0.9384981196561306, 0.9416241671541612, 0.9399771325879818, 0.9392425666610114, 0.9347379331966098, 0.9415582847252166, 0.939519276721872, 0.9380764643922984, 0.9427771118047427, 0.9416604127815301, 0.9365562277732136, 0.9409505300384631, 0.9405881925452527, 0.9416933587129167, 0.9403675048471355, 0.9349405156622688, 0.9425020393707769, 0.9423851083508499, 0.943287659463265, 0.9412783041274805, 0.9284577807076544, 0.9393331421364983, 0.9369400203656807, 0.9402983107155175, 0.9400891434374473, 0.9435314446044483, 0.9429006182032523, 0.9386908030338424, 0.9378524679931806, 0.9417180641949605, 0.9406656202652471, 0.9420968774411318, 0.9412503049527998, 0.9332605531747392, 0.9427902814295652, 0.9350986279172006, 0.9437982615807073, 0.9400529046710446, 0.9427902831448068, 0.9351332054721365, 0.9426272228467378, 0.9415615848500094, 0.9401632427311629, 0.9419255964189982, 0.9437669721438731, 0.9423044122380319, 0.9148977394584271, 0.9424163832081308, 0.9440963757123878, 0.9433123692334127, 0.9438872032885929, 0.9403493665962768, 0.9397844440645451, 0.9408549927979064, 0.9395390174371733, 0.8993217430526405, 0.9336064209183343, 0.935902370823373, 0.9386627935677123, 0.9397234959568052, 0.9421364094713609, 0.9397811310754406, 0.9423916751532246, 0.9393710382550741, 0.942640398474906, 0.9403164275258565, 0.9432366177332487], 'val_mDice': [0.15753179831470518, 0.40044239720852254, 0.4873157919739648, 0.4575156578057104, 0.5164818617937376, 0.5436093489900767, 0.531139225839711, 0.5413934850006652, 0.5642203529961676, 0.5249350418289789, 0.5426163776315374, 0.5807700423027972, 0.5803188274232604, 0.5767541900813151, 0.5796575855008133, 0.5790012791860017, 0.5781609295941085, 0.5715966151772643, 0.5815254595639895, 0.5792824561647374, 0.5873958318353557, 0.5711497068405151, 0.5863968185383639, 0.5898645245771614, 0.5783846086735348, 0.5936874039739156, 0.5670037170965895, 0.6004186238316324, 0.5940834206642864, 0.6019990491352493, 0.6052692463929704, 0.5881460947956113, 0.6036944676646225, 0.6035223950585016, 0.5996772805563837, 0.5960309556919894, 0.6127204264668252, 0.6076224026062506, 0.5949037036449789, 0.5967185934670538, 0.5863543894651125, 0.5655646105464414, 0.5993172667866988, 0.6060967256696962, 0.6114191254265875, 0.6059564369187939, 0.6015875262322186, 0.5811606096706802, 0.5958177931874776, 0.5850591239311712, 0.5959275467790288, 0.6059716292422452, 0.6144038052867642, 0.6019360384495138, 0.6108514529337986, 0.6030059542587335, 0.5899246558011007, 0.6042082279706172, 0.5919586891750638, 0.6103561379069047, 0.6064986466503829, 0.5998723386860579, 0.5910224811636287, 0.6069495540728672, 0.5977962810358555, 0.5931599581841942, 0.6119580997837534, 0.5942694892128595, 0.5879513737109068, 0.6007369876765519, 0.6023757226175541, 0.6109456805874118, 0.6102167376511388, 0.6015426297839597, 0.5977519330360906, 0.6161378583462118, 0.6012721344721403, 0.6063906010106314, 0.5597671347556354, 0.5982684428743321, 0.6023128530104384, 0.6049820570636997, 0.6047148194244439, 0.6092055602896985, 0.6168784889385854, 0.6015065299521247, 0.6072149122361656, 0.6037077509241996, 0.6051606720300029, 0.6089972862236791, 0.6106030340674969, 0.5623481702461517, 0.6065744976345584, 0.5787987417454342, 0.6152768872624679, 0.5992365329385662, 0.5998175264262467, 0.5765980018986215, 0.6025797463149476, 0.6024979601661078, 0.6018504984944845, 0.6103043363248701, 0.6065154487280537, 0.6058268727158471, 0.4739096705004466, 0.5960409100964773, 0.6050694760658758, 0.6132825814562736, 0.6116914963550705, 0.6075186146249016, 0.5989169319756598, 0.5976855386075356, 0.5977467118407325, 0.4332936695582575, 0.5865697474788418, 0.59423084910825, 0.5987385670058161, 0.602893447275642, 0.6096658706665039, 0.6050382243643562, 0.6084730590847757, 0.5991334349131413, 0.6154972400596673, 0.6032755923785752, 0.6125868936236814], 'loss': [2.545438927879005, 1.0663184989427623, 0.8023085555993216, 0.6823884072586208, 0.6252702954085377, 0.5811544252128016, 0.5520889261794977, 0.5267755748581621, 0.5100460383376763, 0.49482066463307406, 0.4756861593800416, 0.4634048158482478, 0.45118050299454976, 0.444772406307696, 0.4302551838573451, 0.42560668927209516, 0.41559845595343775, 0.410120517134391, 0.40231466280189637, 0.39873073852079755, 0.3921142975226392, 0.38830328726938756, 0.37841051122742125, 0.37973954851726005, 0.373371961367929, 0.3694090863795021, 0.36617615442144796, 0.3614608913979293, 0.3599417258763709, 0.35611010507309393, 0.3527150171578268, 0.3482283691577715, 0.3503012526338277, 0.34220763856912456, 0.36473210169422204, 0.3428459399902277, 0.33697169356249984, 0.3351621708620048, 0.33161296958533737, 0.3304362235588077, 0.33706222226378846, 0.32806246982004383, 0.3268173620796484, 0.32356076102451076, 0.32217969587810197, 0.3210623669564236, 0.32026508713414553, 0.3203669953962205, 0.31836117353040716, 0.3194042198787189, 0.31317665754834834, 0.31150368489505015, 0.31171865200100013, 0.3087773204688589, 0.3082630387113215, 0.30692768664676534, 0.307124858605113, 0.3063488279451119, 0.3034622918198625, 0.30355290740233865, 0.30114417292320084, 0.30113364251890345, 0.29866966269041806, 0.29892426587733567, 0.2972870874970782, 0.2966338982791917, 0.29525962524230276, 0.2953757877874164, 0.29451508894860057, 0.2931272136616722, 0.2918273475372448, 0.29188285836262556, 0.29318166328713413, 0.29071877999131457, 0.288388297162094, 0.29128822450176106, 0.28883114967920076, 0.2877294214000674, 0.286708558408234, 0.37334541928565346, 0.29369614976740915, 0.2893188677147591, 0.2865007165299071, 0.2838928720682415, 0.2817325525876229, 0.27995027272146905, 0.28047849298950706, 0.2802504225360373, 0.27924141817059345, 0.27826465648767, 0.2789997038308424, 0.27978668248132604, 0.29154447689449003, 0.2775775700857649, 0.2846593032443356, 0.2766469240194858, 0.27273668683681934, 0.2762097953823629, 0.27655791819433634, 0.27620185296016186, 0.2748471530914507, 0.27388373354394707, 0.27385713166610653, 0.27308796851656514, 0.27888727213462045, 0.3890379957480732, 0.2910435224369378, 0.27822779238261586, 0.2734902177637451, 0.27129266891339776, 0.2697318403398107, 0.2695775982763206, 0.26868211246856344, 0.4311804194875786, 0.4042421849403429, 0.3427735485341513, 0.31569456418154995, 0.3015577470935761, 0.29337028765022394, 0.28540662834935265, 0.2833009351548015, 0.2791489340932999, 0.27521503259594315, 0.2726830954944554, 0.2714843101121878], 'acc': [0.6429204231887473, 0.8795481486697078, 0.886158466151321, 0.8922940077112643, 0.8975051399965893, 0.9032773429594779, 0.908891198077239, 0.9136864865084101, 0.917702584964241, 0.921232654401871, 0.9233673131533516, 0.9245585745634388, 0.9259434287674762, 0.9268784371776456, 0.928271588107864, 0.9289964374887971, 0.9297536492372755, 0.930417524644042, 0.9311685822536354, 0.9317697992697405, 0.9326072672639818, 0.9330732001148585, 0.9340788949640126, 0.9340532150520945, 0.9345008726005819, 0.9351458032700575, 0.9353962093059618, 0.9360446769934295, 0.9362699106770688, 0.936724611276139, 0.9371486344499714, 0.9373638683746552, 0.9374862941867337, 0.9380428429362003, 0.9359946639641471, 0.9382503829916794, 0.9385441174854678, 0.9389703022509757, 0.9393569161425717, 0.9396899601812749, 0.9391978203787119, 0.9396944765132206, 0.940166515929437, 0.9403453229280411, 0.9406974342184341, 0.9407746616067868, 0.9407976223024794, 0.9409020883374494, 0.940958275874606, 0.9409771503407623, 0.9414289421305089, 0.9417058706058221, 0.9415779881456323, 0.9419696000012449, 0.941968566015272, 0.9422391682731782, 0.942087891321677, 0.9421886535933779, 0.9426135444961609, 0.9425205201993493, 0.9428000710286455, 0.9427333017453204, 0.9431482125320146, 0.942937018089599, 0.9432083198288563, 0.9432063513732563, 0.9435412673433397, 0.9434055207507296, 0.9434644277670182, 0.9436489833525513, 0.9438229085917834, 0.9437262558731755, 0.9438058609998519, 0.9440146992497523, 0.9442379850596095, 0.9437714069487041, 0.944244407287943, 0.9442810967073199, 0.9445949800874325, 0.9335696854227807, 0.9432875662259609, 0.9441072896007129, 0.9444067945652613, 0.944591924588837, 0.9449097506014946, 0.9451645303989403, 0.9450977654473117, 0.945139794696707, 0.945181100778133, 0.9453437957436166, 0.9453089112144788, 0.9453668808316112, 0.9438132189622673, 0.9455371529734002, 0.9449021027909935, 0.945687686200153, 0.9459965182838007, 0.9458271130446851, 0.9457570716779389, 0.9457401483155579, 0.9461676573157436, 0.9459725243658159, 0.945974159506133, 0.9461310158955702, 0.9461292833546785, 0.9330637488914022, 0.9442905928752573, 0.945686915270848, 0.9460372952347267, 0.9463510826539903, 0.9465073114106496, 0.9465099082752276, 0.9465778797921252, 0.9308761925513042, 0.9313805678941902, 0.938471745866308, 0.9413640037651598, 0.942911269346272, 0.9439241765201956, 0.9448689962980803, 0.9453009761223595, 0.9454753627123088, 0.9459377805416986, 0.946266832483889, 0.946367837919004], 'mDice': [0.12247296417105807, 0.3333415923418305, 0.4326709431526266, 0.48955498612921067, 0.5201259465484002, 0.5440666553691715, 0.5605517638828844, 0.5751560068611237, 0.585329324013294, 0.5942389571699268, 0.6056886017259944, 0.6134085746478494, 0.621183346622858, 0.6257451274795107, 0.6348669598318403, 0.6380265808310787, 0.6445154600022245, 0.6480767905173795, 0.653301612215617, 0.6559127535646739, 0.6604827071433056, 0.6630973549380921, 0.6697259464826786, 0.6689297270183928, 0.6734929728022244, 0.6759983123638279, 0.6785144730666886, 0.681705243207907, 0.6828521276767252, 0.6854825926863629, 0.6879053872890067, 0.6910731176998505, 0.6899783873953657, 0.6955076320360148, 0.6806576426002664, 0.6950881631152516, 0.6993001967612196, 0.7007820996960731, 0.7032065689250767, 0.7041630146884538, 0.6995217154266904, 0.7057983720159862, 0.706855853398641, 0.7091911469805869, 0.7103213478827322, 0.711140250150608, 0.7117777007188498, 0.713957269686006, 0.7132084255357721, 0.7129108134850413, 0.7168940100517626, 0.7180754652145505, 0.7180211105233505, 0.7202769205039901, 0.7206219210516528, 0.7217562324458424, 0.7216066038175382, 0.7221423648430805, 0.7242634011977511, 0.7241154151212215, 0.726095532299315, 0.7259456358820269, 0.7278378566782205, 0.7277693494832007, 0.7290014799866599, 0.7295820942272586, 0.7305075358227756, 0.7306217082757155, 0.7310796737720976, 0.7321632963673104, 0.7330755912388756, 0.7331360931958353, 0.7322356199497085, 0.7339122446989017, 0.735774488590315, 0.7334810977872493, 0.73560010618183, 0.7363604920247452, 0.7383787947851829, 0.6770656671788957, 0.7315666285214166, 0.7350652338927144, 0.7371968403881124, 0.7392465150348781, 0.7409167451734329, 0.7422853179324502, 0.7418562214906865, 0.7420550157507536, 0.7428701454990678, 0.7435282535398741, 0.7430818277581153, 0.7437573833341384, 0.7338076265037022, 0.7442666483861863, 0.7387536081714906, 0.7449717089624571, 0.7478991070606958, 0.745205752991298, 0.7450520392476798, 0.7451861256737841, 0.7487603343351877, 0.747021353875757, 0.7470811865230088, 0.7477187061980852, 0.7473512285523394, 0.6682267324923468, 0.7338341019329366, 0.7436508318376852, 0.7473391268188726, 0.749043669677587, 0.7503081524955503, 0.7504215705948101, 0.7510452327470873, 0.6633565930903547, 0.6524926965738941, 0.6951093522221871, 0.7149016376654407, 0.7256572674713423, 0.7319422412559631, 0.7379733736814007, 0.7408616881715077, 0.7429708602222618, 0.7461203171335031, 0.7479471467643494, 0.7489229667164202]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:11,  3.92s/it]predicting test subjects:  50%|█████     | 2/4 [00:06<00:07,  3.53s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:09<00:03,  3.27s/it]predicting test subjects: 100%|██████████| 4/4 [00:12<00:00,  3.24s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<16:28,  3.73s/it]predicting train subjects:   1%|          | 2/266 [00:07<16:03,  3.65s/it]predicting train subjects:   1%|          | 3/266 [00:10<14:55,  3.40s/it]predicting train subjects:   2%|▏         | 4/266 [00:13<14:30,  3.32s/it]predicting train subjects:   2%|▏         | 5/266 [00:16<14:43,  3.38s/it]predicting train subjects:   2%|▏         | 6/266 [00:20<15:15,  3.52s/it]predicting train subjects:   3%|▎         | 7/266 [00:24<15:31,  3.60s/it]predicting train subjects:   3%|▎         | 8/266 [00:27<15:03,  3.50s/it]predicting train subjects:   3%|▎         | 9/266 [00:31<15:07,  3.53s/it]predicting train subjects:   4%|▍         | 10/266 [00:34<15:15,  3.58s/it]predicting train subjects:   4%|▍         | 11/266 [00:38<15:26,  3.63s/it]predicting train subjects:   5%|▍         | 12/266 [00:42<15:21,  3.63s/it]predicting train subjects:   5%|▍         | 13/266 [00:45<15:17,  3.63s/it]predicting train subjects:   5%|▌         | 14/266 [00:49<15:15,  3.63s/it]predicting train subjects:   6%|▌         | 15/266 [00:53<15:15,  3.65s/it]predicting train subjects:   6%|▌         | 16/266 [00:56<14:51,  3.57s/it]predicting train subjects:   6%|▋         | 17/266 [00:59<14:28,  3.49s/it]predicting train subjects:   7%|▋         | 18/266 [01:03<14:10,  3.43s/it]predicting train subjects:   7%|▋         | 19/266 [01:06<13:38,  3.31s/it]predicting train subjects:   8%|▊         | 20/266 [01:09<13:44,  3.35s/it]predicting train subjects:   8%|▊         | 21/266 [01:13<13:51,  3.39s/it]predicting train subjects:   8%|▊         | 22/266 [01:16<13:51,  3.41s/it]predicting train subjects:   9%|▊         | 23/266 [01:19<13:29,  3.33s/it]predicting train subjects:   9%|▉         | 24/266 [01:22<13:00,  3.22s/it]predicting train subjects:   9%|▉         | 25/266 [01:25<12:23,  3.08s/it]predicting train subjects:  10%|▉         | 26/266 [01:28<11:46,  2.94s/it]predicting train subjects:  10%|█         | 27/266 [01:31<11:53,  2.99s/it]predicting train subjects:  11%|█         | 28/266 [01:34<11:49,  2.98s/it]predicting train subjects:  11%|█         | 29/266 [01:37<11:58,  3.03s/it]predicting train subjects:  11%|█▏        | 30/266 [01:40<11:38,  2.96s/it]predicting train subjects:  12%|█▏        | 31/266 [01:42<11:04,  2.83s/it]predicting train subjects:  12%|█▏        | 32/266 [01:45<10:41,  2.74s/it]predicting train subjects:  12%|█▏        | 33/266 [01:47<10:20,  2.67s/it]predicting train subjects:  13%|█▎        | 34/266 [01:50<10:34,  2.73s/it]predicting train subjects:  13%|█▎        | 35/266 [01:53<10:31,  2.74s/it]predicting train subjects:  14%|█▎        | 36/266 [01:55<10:24,  2.71s/it]predicting train subjects:  14%|█▍        | 37/266 [01:58<10:34,  2.77s/it]predicting train subjects:  14%|█▍        | 38/266 [02:01<10:37,  2.80s/it]predicting train subjects:  15%|█▍        | 39/266 [02:04<10:38,  2.81s/it]predicting train subjects:  15%|█▌        | 40/266 [02:07<10:27,  2.78s/it]predicting train subjects:  15%|█▌        | 41/266 [02:09<10:14,  2.73s/it]predicting train subjects:  16%|█▌        | 42/266 [02:12<10:02,  2.69s/it]predicting train subjects:  16%|█▌        | 43/266 [02:14<09:13,  2.48s/it]predicting train subjects:  17%|█▋        | 44/266 [02:16<09:13,  2.49s/it]predicting train subjects:  17%|█▋        | 45/266 [02:19<09:29,  2.58s/it]predicting train subjects:  17%|█▋        | 46/266 [02:21<09:01,  2.46s/it]predicting train subjects:  18%|█▊        | 47/266 [02:24<08:44,  2.40s/it]predicting train subjects:  18%|█▊        | 48/266 [02:26<08:33,  2.35s/it]predicting train subjects:  18%|█▊        | 49/266 [02:29<08:51,  2.45s/it]predicting train subjects:  19%|█▉        | 50/266 [02:31<08:43,  2.43s/it]predicting train subjects:  19%|█▉        | 51/266 [02:33<08:29,  2.37s/it]predicting train subjects:  20%|█▉        | 52/266 [02:35<08:05,  2.27s/it]predicting train subjects:  20%|█▉        | 53/266 [02:38<08:19,  2.35s/it]predicting train subjects:  20%|██        | 54/266 [02:40<08:26,  2.39s/it]predicting train subjects:  21%|██        | 55/266 [02:42<08:07,  2.31s/it]predicting train subjects:  21%|██        | 56/266 [02:44<07:48,  2.23s/it]predicting train subjects:  21%|██▏       | 57/266 [02:47<08:00,  2.30s/it]predicting train subjects:  22%|██▏       | 58/266 [02:49<08:02,  2.32s/it]predicting train subjects:  22%|██▏       | 59/266 [02:52<08:06,  2.35s/it]predicting train subjects:  23%|██▎       | 60/266 [02:54<07:39,  2.23s/it]predicting train subjects:  23%|██▎       | 61/266 [02:56<07:27,  2.18s/it]predicting train subjects:  23%|██▎       | 62/266 [02:58<07:53,  2.32s/it]predicting train subjects:  24%|██▎       | 63/266 [03:00<07:26,  2.20s/it]predicting train subjects:  24%|██▍       | 64/266 [03:02<07:06,  2.11s/it]predicting train subjects:  24%|██▍       | 65/266 [03:04<07:06,  2.12s/it]predicting train subjects:  25%|██▍       | 66/266 [03:07<07:13,  2.17s/it]predicting train subjects:  25%|██▌       | 67/266 [03:09<06:59,  2.11s/it]predicting train subjects:  26%|██▌       | 68/266 [03:11<06:53,  2.09s/it]predicting train subjects:  26%|██▌       | 69/266 [03:13<07:06,  2.17s/it]predicting train subjects:  26%|██▋       | 70/266 [03:15<06:52,  2.10s/it]predicting train subjects:  27%|██▋       | 71/266 [03:17<06:42,  2.06s/it]predicting train subjects:  27%|██▋       | 72/266 [03:19<06:33,  2.03s/it]predicting train subjects:  27%|██▋       | 73/266 [03:21<06:43,  2.09s/it]predicting train subjects:  28%|██▊       | 74/266 [03:23<06:32,  2.04s/it]predicting train subjects:  28%|██▊       | 75/266 [03:25<06:37,  2.08s/it]predicting train subjects:  29%|██▊       | 76/266 [03:28<07:02,  2.22s/it]predicting train subjects:  29%|██▉       | 77/266 [03:30<06:38,  2.11s/it]predicting train subjects:  29%|██▉       | 78/266 [03:32<07:02,  2.25s/it]predicting train subjects:  30%|██▉       | 79/266 [03:35<07:24,  2.38s/it]predicting train subjects:  30%|███       | 80/266 [03:38<07:54,  2.55s/it]predicting train subjects:  30%|███       | 81/266 [03:41<08:19,  2.70s/it]predicting train subjects:  31%|███       | 82/266 [03:44<08:43,  2.84s/it]predicting train subjects:  31%|███       | 83/266 [03:47<08:26,  2.77s/it]predicting train subjects:  32%|███▏      | 84/266 [03:49<08:30,  2.80s/it]predicting train subjects:  32%|███▏      | 85/266 [03:52<08:15,  2.74s/it]predicting train subjects:  32%|███▏      | 86/266 [03:55<08:02,  2.68s/it]predicting train subjects:  33%|███▎      | 87/266 [03:57<07:58,  2.67s/it]predicting train subjects:  33%|███▎      | 88/266 [04:00<08:09,  2.75s/it]predicting train subjects:  33%|███▎      | 89/266 [04:03<08:14,  2.80s/it]predicting train subjects:  34%|███▍      | 90/266 [04:06<08:20,  2.85s/it]predicting train subjects:  34%|███▍      | 91/266 [04:09<08:17,  2.84s/it]predicting train subjects:  35%|███▍      | 92/266 [04:11<07:55,  2.73s/it]predicting train subjects:  35%|███▍      | 93/266 [04:14<07:37,  2.64s/it]predicting train subjects:  35%|███▌      | 94/266 [04:16<07:32,  2.63s/it]predicting train subjects:  36%|███▌      | 95/266 [04:19<07:31,  2.64s/it]predicting train subjects:  36%|███▌      | 96/266 [04:22<07:27,  2.63s/it]predicting train subjects:  36%|███▋      | 97/266 [04:25<07:46,  2.76s/it]predicting train subjects:  37%|███▋      | 98/266 [04:28<07:49,  2.79s/it]predicting train subjects:  37%|███▋      | 99/266 [04:29<07:01,  2.52s/it]predicting train subjects:  38%|███▊      | 100/266 [04:31<06:31,  2.36s/it]predicting train subjects:  38%|███▊      | 101/266 [04:34<06:15,  2.27s/it]predicting train subjects:  38%|███▊      | 102/266 [04:36<06:13,  2.28s/it]predicting train subjects:  39%|███▊      | 103/266 [04:38<06:10,  2.27s/it]predicting train subjects:  39%|███▉      | 104/266 [04:40<06:06,  2.26s/it]predicting train subjects:  39%|███▉      | 105/266 [04:42<05:58,  2.23s/it]predicting train subjects:  40%|███▉      | 106/266 [04:45<05:59,  2.24s/it]predicting train subjects:  40%|████      | 107/266 [04:47<05:52,  2.22s/it]predicting train subjects:  41%|████      | 108/266 [04:49<05:44,  2.18s/it]predicting train subjects:  41%|████      | 109/266 [04:52<06:01,  2.30s/it]predicting train subjects:  41%|████▏     | 110/266 [04:54<05:46,  2.22s/it]predicting train subjects:  42%|████▏     | 111/266 [04:56<05:37,  2.17s/it]predicting train subjects:  42%|████▏     | 112/266 [04:58<05:31,  2.15s/it]predicting train subjects:  42%|████▏     | 113/266 [05:00<05:27,  2.14s/it]predicting train subjects:  43%|████▎     | 114/266 [05:02<05:20,  2.11s/it]predicting train subjects:  43%|████▎     | 115/266 [05:04<05:29,  2.18s/it]predicting train subjects:  44%|████▎     | 116/266 [05:06<05:26,  2.18s/it]predicting train subjects:  44%|████▍     | 117/266 [05:09<05:23,  2.17s/it]predicting train subjects:  44%|████▍     | 118/266 [05:11<05:18,  2.15s/it]predicting train subjects:  45%|████▍     | 119/266 [05:13<05:31,  2.26s/it]predicting train subjects:  45%|████▌     | 120/266 [05:16<05:57,  2.45s/it]predicting train subjects:  45%|████▌     | 121/266 [05:19<06:01,  2.49s/it]predicting train subjects:  46%|████▌     | 122/266 [05:21<06:06,  2.54s/it]predicting train subjects:  46%|████▌     | 123/266 [05:24<06:06,  2.56s/it]predicting train subjects:  47%|████▋     | 124/266 [05:27<06:09,  2.60s/it]predicting train subjects:  47%|████▋     | 125/266 [05:30<06:17,  2.68s/it]predicting train subjects:  47%|████▋     | 126/266 [05:33<06:30,  2.79s/it]predicting train subjects:  48%|████▊     | 127/266 [05:35<06:30,  2.81s/it]predicting train subjects:  48%|████▊     | 128/266 [05:38<06:23,  2.78s/it]predicting train subjects:  48%|████▊     | 129/266 [05:41<06:21,  2.79s/it]predicting train subjects:  49%|████▉     | 130/266 [05:44<06:33,  2.89s/it]predicting train subjects:  49%|████▉     | 131/266 [05:47<06:19,  2.81s/it]predicting train subjects:  50%|████▉     | 132/266 [05:49<06:08,  2.75s/it]predicting train subjects:  50%|█████     | 133/266 [05:52<06:04,  2.74s/it]predicting train subjects:  50%|█████     | 134/266 [05:55<06:07,  2.78s/it]predicting train subjects:  51%|█████     | 135/266 [05:58<06:01,  2.76s/it]predicting train subjects:  51%|█████     | 136/266 [06:01<06:03,  2.80s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:03<06:04,  2.82s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:06<05:54,  2.77s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:08<05:39,  2.67s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:11<05:35,  2.66s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:14<05:27,  2.62s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:16<05:25,  2.63s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:19<05:24,  2.64s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:22<05:24,  2.66s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:24<05:14,  2.60s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:27<05:06,  2.55s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:29<04:59,  2.51s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:31<04:55,  2.50s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:34<05:05,  2.61s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:37<04:55,  2.55s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:40<05:09,  2.70s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:42<05:06,  2.68s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:45<05:02,  2.67s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:47<04:48,  2.58s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:49<04:20,  2.35s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:51<04:02,  2.20s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:53<03:51,  2.13s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:55<03:53,  2.16s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:57<03:44,  2.10s/it]predicting train subjects:  60%|██████    | 160/266 [06:59<03:44,  2.12s/it]predicting train subjects:  61%|██████    | 161/266 [07:01<03:33,  2.04s/it]predicting train subjects:  61%|██████    | 162/266 [07:03<03:31,  2.03s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:05<03:27,  2.01s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:07<03:20,  1.97s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:09<03:20,  1.98s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:11<03:19,  2.00s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:13<03:14,  1.96s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:15<03:13,  1.98s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:17<03:13,  2.00s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:19<03:09,  1.98s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:21<03:08,  1.98s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:23<03:08,  2.00s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:25<03:13,  2.08s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:27<03:12,  2.10s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:29<03:07,  2.06s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:32<03:08,  2.10s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:34<03:08,  2.12s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:36<03:04,  2.09s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:38<03:04,  2.13s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:40<03:11,  2.22s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:42<03:03,  2.16s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:44<02:55,  2.09s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:46<02:52,  2.07s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:48<02:48,  2.06s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:51<02:56,  2.18s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:53<02:50,  2.13s/it]predicting train subjects:  70%|███████   | 187/266 [07:55<02:43,  2.07s/it]predicting train subjects:  71%|███████   | 188/266 [07:57<02:38,  2.04s/it]predicting train subjects:  71%|███████   | 189/266 [07:59<02:34,  2.01s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:01<02:38,  2.09s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:03<02:41,  2.15s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:05<02:32,  2.06s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:07<02:27,  2.03s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:10<02:35,  2.16s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:12<02:35,  2.19s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:14<02:36,  2.24s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:16<02:31,  2.20s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:19<02:35,  2.28s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:21<02:32,  2.27s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:24<02:37,  2.39s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:26<02:41,  2.49s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:29<02:33,  2.40s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:31<02:29,  2.38s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:34<02:31,  2.45s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:36<02:23,  2.36s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:38<02:17,  2.29s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:40<02:12,  2.25s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:42<02:08,  2.21s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:45<02:10,  2.28s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:47<02:04,  2.23s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:49<02:01,  2.21s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:51<01:57,  2.17s/it]predicting train subjects:  80%|████████  | 213/266 [08:53<01:49,  2.06s/it]predicting train subjects:  80%|████████  | 214/266 [08:55<01:43,  2.00s/it]predicting train subjects:  81%|████████  | 215/266 [08:57<01:41,  1.98s/it]predicting train subjects:  81%|████████  | 216/266 [08:58<01:36,  1.93s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:00<01:33,  1.91s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:02<01:30,  1.89s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:04<01:28,  1.89s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:06<01:25,  1.86s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:08<01:24,  1.88s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:10<01:22,  1.87s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:11<01:20,  1.86s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:13<01:17,  1.84s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:15<01:15,  1.83s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:17<01:13,  1.83s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:19<01:10,  1.82s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:20<01:08,  1.81s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:22<01:07,  1.82s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:24<01:05,  1.81s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:26<01:04,  1.84s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:28<01:02,  1.84s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:30<01:01,  1.86s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:32<01:00,  1.88s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:33<00:57,  1.87s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:35<00:55,  1.86s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:37<00:53,  1.85s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:39<00:51,  1.86s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:41<00:50,  1.86s/it]predicting train subjects:  90%|█████████ | 240/266 [09:43<00:48,  1.87s/it]predicting train subjects:  91%|█████████ | 241/266 [09:45<00:46,  1.87s/it]predicting train subjects:  91%|█████████ | 242/266 [09:46<00:44,  1.86s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:48<00:42,  1.84s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:50<00:40,  1.84s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:52<00:38,  1.84s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:54<00:36,  1.84s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:56<00:34,  1.84s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:57<00:33,  1.84s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:00<00:34,  2.01s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:02<00:34,  2.15s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:05<00:35,  2.40s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:08<00:33,  2.42s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:10<00:31,  2.40s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:13<00:28,  2.41s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:15<00:26,  2.40s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:17<00:23,  2.40s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:20<00:21,  2.38s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:22<00:18,  2.37s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:24<00:16,  2.38s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:27<00:14,  2.38s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:29<00:11,  2.38s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:32<00:09,  2.38s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:34<00:07,  2.38s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:36<00:04,  2.42s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:39<00:02,  2.51s/it]predicting train subjects: 100%|██████████| 266/266 [10:42<00:00,  2.60s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:31,  1.75it/s]Loading train:   1%|          | 2/266 [00:01<02:25,  1.82it/s]Loading train:   1%|          | 3/266 [00:01<02:13,  1.97it/s]Loading train:   2%|▏         | 4/266 [00:01<02:12,  1.97it/s]Loading train:   2%|▏         | 5/266 [00:02<02:15,  1.93it/s]Loading train:   2%|▏         | 6/266 [00:03<02:16,  1.91it/s]Loading train:   3%|▎         | 7/266 [00:03<02:16,  1.90it/s]Loading train:   3%|▎         | 8/266 [00:04<02:18,  1.86it/s]Loading train:   3%|▎         | 9/266 [00:04<02:19,  1.84it/s]Loading train:   4%|▍         | 10/266 [00:05<02:16,  1.87it/s]Loading train:   4%|▍         | 11/266 [00:05<02:20,  1.81it/s]Loading train:   5%|▍         | 12/266 [00:06<02:19,  1.82it/s]Loading train:   5%|▍         | 13/266 [00:06<02:11,  1.93it/s]Loading train:   5%|▌         | 14/266 [00:07<02:04,  2.02it/s]Loading train:   6%|▌         | 15/266 [00:07<02:05,  2.00it/s]Loading train:   6%|▌         | 16/266 [00:08<02:06,  1.98it/s]Loading train:   6%|▋         | 17/266 [00:08<02:10,  1.91it/s]Loading train:   7%|▋         | 18/266 [00:09<02:14,  1.84it/s]Loading train:   7%|▋         | 19/266 [00:09<02:13,  1.84it/s]Loading train:   8%|▊         | 20/266 [00:10<02:11,  1.87it/s]Loading train:   8%|▊         | 21/266 [00:10<02:07,  1.92it/s]Loading train:   8%|▊         | 22/266 [00:11<02:06,  1.92it/s]Loading train:   9%|▊         | 23/266 [00:12<02:10,  1.86it/s]Loading train:   9%|▉         | 24/266 [00:12<02:10,  1.86it/s]Loading train:   9%|▉         | 25/266 [00:13<02:15,  1.78it/s]Loading train:  10%|▉         | 26/266 [00:13<02:03,  1.94it/s]Loading train:  10%|█         | 27/266 [00:14<01:56,  2.06it/s]Loading train:  11%|█         | 28/266 [00:14<01:57,  2.02it/s]Loading train:  11%|█         | 29/266 [00:15<02:04,  1.90it/s]Loading train:  11%|█▏        | 30/266 [00:15<02:00,  1.95it/s]Loading train:  12%|█▏        | 31/266 [00:16<01:55,  2.04it/s]Loading train:  12%|█▏        | 32/266 [00:16<01:56,  2.01it/s]Loading train:  12%|█▏        | 33/266 [00:17<01:49,  2.12it/s]Loading train:  13%|█▎        | 34/266 [00:17<01:43,  2.25it/s]Loading train:  13%|█▎        | 35/266 [00:17<01:37,  2.37it/s]Loading train:  14%|█▎        | 36/266 [00:18<01:33,  2.46it/s]Loading train:  14%|█▍        | 37/266 [00:18<01:31,  2.50it/s]Loading train:  14%|█▍        | 38/266 [00:18<01:30,  2.51it/s]Loading train:  15%|█▍        | 39/266 [00:19<01:29,  2.52it/s]Loading train:  15%|█▌        | 40/266 [00:19<01:28,  2.54it/s]Loading train:  15%|█▌        | 41/266 [00:20<01:28,  2.55it/s]Loading train:  16%|█▌        | 42/266 [00:20<01:25,  2.63it/s]Loading train:  16%|█▌        | 43/266 [00:20<01:21,  2.73it/s]Loading train:  17%|█▋        | 44/266 [00:21<01:18,  2.81it/s]Loading train:  17%|█▋        | 45/266 [00:21<01:23,  2.65it/s]Loading train:  17%|█▋        | 46/266 [00:22<01:28,  2.48it/s]Loading train:  18%|█▊        | 47/266 [00:22<01:28,  2.47it/s]Loading train:  18%|█▊        | 48/266 [00:22<01:28,  2.45it/s]Loading train:  18%|█▊        | 49/266 [00:23<01:27,  2.47it/s]Loading train:  19%|█▉        | 50/266 [00:23<01:22,  2.62it/s]Loading train:  19%|█▉        | 51/266 [00:23<01:18,  2.73it/s]Loading train:  20%|█▉        | 52/266 [00:24<01:16,  2.80it/s]Loading train:  20%|█▉        | 53/266 [00:24<01:17,  2.75it/s]Loading train:  20%|██        | 54/266 [00:25<01:25,  2.47it/s]Loading train:  21%|██        | 55/266 [00:25<01:24,  2.49it/s]Loading train:  21%|██        | 56/266 [00:25<01:24,  2.49it/s]Loading train:  21%|██▏       | 57/266 [00:26<01:23,  2.50it/s]Loading train:  22%|██▏       | 58/266 [00:26<01:23,  2.51it/s]Loading train:  22%|██▏       | 59/266 [00:27<01:22,  2.50it/s]Loading train:  23%|██▎       | 60/266 [00:27<01:26,  2.38it/s]Loading train:  23%|██▎       | 61/266 [00:27<01:20,  2.56it/s]Loading train:  23%|██▎       | 62/266 [00:28<01:16,  2.68it/s]Loading train:  24%|██▎       | 63/266 [00:28<01:15,  2.70it/s]Loading train:  24%|██▍       | 64/266 [00:28<01:14,  2.72it/s]Loading train:  24%|██▍       | 65/266 [00:29<01:11,  2.81it/s]Loading train:  25%|██▍       | 66/266 [00:29<01:12,  2.77it/s]Loading train:  25%|██▌       | 67/266 [00:29<01:10,  2.82it/s]Loading train:  26%|██▌       | 68/266 [00:30<01:09,  2.86it/s]Loading train:  26%|██▌       | 69/266 [00:30<01:06,  2.94it/s]Loading train:  26%|██▋       | 70/266 [00:30<01:05,  3.00it/s]Loading train:  27%|██▋       | 71/266 [00:31<01:04,  3.04it/s]Loading train:  27%|██▋       | 72/266 [00:31<01:04,  3.01it/s]Loading train:  27%|██▋       | 73/266 [00:31<01:03,  3.05it/s]Loading train:  28%|██▊       | 74/266 [00:32<01:03,  3.01it/s]Loading train:  28%|██▊       | 75/266 [00:32<01:03,  2.99it/s]Loading train:  29%|██▊       | 76/266 [00:32<01:02,  3.04it/s]Loading train:  29%|██▉       | 77/266 [00:33<01:01,  3.07it/s]Loading train:  29%|██▉       | 78/266 [00:33<01:07,  2.77it/s]Loading train:  30%|██▉       | 79/266 [00:34<01:09,  2.69it/s]Loading train:  30%|███       | 80/266 [00:34<01:10,  2.64it/s]Loading train:  30%|███       | 81/266 [00:34<01:13,  2.53it/s]Loading train:  31%|███       | 82/266 [00:35<01:14,  2.49it/s]Loading train:  31%|███       | 83/266 [00:35<01:14,  2.46it/s]Loading train:  32%|███▏      | 84/266 [00:36<01:18,  2.31it/s]Loading train:  32%|███▏      | 85/266 [00:36<01:19,  2.27it/s]Loading train:  32%|███▏      | 86/266 [00:37<01:17,  2.31it/s]Loading train:  33%|███▎      | 87/266 [00:37<01:17,  2.30it/s]Loading train:  33%|███▎      | 88/266 [00:38<01:20,  2.22it/s]Loading train:  33%|███▎      | 89/266 [00:38<01:20,  2.21it/s]Loading train:  34%|███▍      | 90/266 [00:39<01:23,  2.10it/s]Loading train:  34%|███▍      | 91/266 [00:39<01:20,  2.16it/s]Loading train:  35%|███▍      | 92/266 [00:39<01:18,  2.21it/s]Loading train:  35%|███▍      | 93/266 [00:40<01:15,  2.29it/s]Loading train:  35%|███▌      | 94/266 [00:40<01:18,  2.18it/s]Loading train:  36%|███▌      | 95/266 [00:41<01:15,  2.26it/s]Loading train:  36%|███▌      | 96/266 [00:41<01:15,  2.25it/s]Loading train:  36%|███▋      | 97/266 [00:42<01:14,  2.27it/s]Loading train:  37%|███▋      | 98/266 [00:42<01:14,  2.27it/s]Loading train:  37%|███▋      | 99/266 [00:42<01:11,  2.35it/s]Loading train:  38%|███▊      | 100/266 [00:43<01:14,  2.22it/s]Loading train:  38%|███▊      | 101/266 [00:43<01:12,  2.27it/s]Loading train:  38%|███▊      | 102/266 [00:44<01:11,  2.31it/s]Loading train:  39%|███▊      | 103/266 [00:44<01:07,  2.43it/s]Loading train:  39%|███▉      | 104/266 [00:45<01:09,  2.34it/s]Loading train:  39%|███▉      | 105/266 [00:45<01:07,  2.38it/s]Loading train:  40%|███▉      | 106/266 [00:45<01:05,  2.44it/s]Loading train:  40%|████      | 107/266 [00:46<01:07,  2.34it/s]Loading train:  41%|████      | 108/266 [00:46<01:08,  2.32it/s]Loading train:  41%|████      | 109/266 [00:47<01:08,  2.29it/s]Loading train:  41%|████▏     | 110/266 [00:47<01:08,  2.27it/s]Loading train:  42%|████▏     | 111/266 [00:48<01:14,  2.08it/s]Loading train:  42%|████▏     | 112/266 [00:48<01:13,  2.08it/s]Loading train:  42%|████▏     | 113/266 [00:49<01:17,  1.99it/s]Loading train:  43%|████▎     | 114/266 [00:49<01:15,  2.02it/s]Loading train:  43%|████▎     | 115/266 [00:50<01:12,  2.09it/s]Loading train:  44%|████▎     | 116/266 [00:50<01:10,  2.12it/s]Loading train:  44%|████▍     | 117/266 [00:51<01:12,  2.05it/s]Loading train:  44%|████▍     | 118/266 [00:51<01:10,  2.11it/s]Loading train:  45%|████▍     | 119/266 [00:52<01:08,  2.13it/s]Loading train:  45%|████▌     | 120/266 [00:52<01:08,  2.14it/s]Loading train:  45%|████▌     | 121/266 [00:53<01:07,  2.15it/s]Loading train:  46%|████▌     | 122/266 [00:53<01:07,  2.14it/s]Loading train:  46%|████▌     | 123/266 [00:54<01:13,  1.95it/s]Loading train:  47%|████▋     | 124/266 [00:54<01:13,  1.94it/s]Loading train:  47%|████▋     | 125/266 [00:55<01:12,  1.94it/s]Loading train:  47%|████▋     | 126/266 [00:55<01:14,  1.88it/s]Loading train:  48%|████▊     | 127/266 [00:56<01:08,  2.02it/s]Loading train:  48%|████▊     | 128/266 [00:56<01:04,  2.15it/s]Loading train:  48%|████▊     | 129/266 [00:56<01:04,  2.12it/s]Loading train:  49%|████▉     | 130/266 [00:57<01:07,  2.03it/s]Loading train:  49%|████▉     | 131/266 [00:58<01:09,  1.94it/s]Loading train:  50%|████▉     | 132/266 [00:58<01:05,  2.04it/s]Loading train:  50%|█████     | 133/266 [00:58<01:01,  2.16it/s]Loading train:  50%|█████     | 134/266 [00:59<00:59,  2.21it/s]Loading train:  51%|█████     | 135/266 [00:59<00:59,  2.22it/s]Loading train:  51%|█████     | 136/266 [01:00<00:57,  2.27it/s]Loading train:  52%|█████▏    | 137/266 [01:00<01:00,  2.14it/s]Loading train:  52%|█████▏    | 138/266 [01:01<01:04,  1.99it/s]Loading train:  52%|█████▏    | 139/266 [01:01<01:01,  2.07it/s]Loading train:  53%|█████▎    | 140/266 [01:02<01:01,  2.05it/s]Loading train:  53%|█████▎    | 141/266 [01:02<00:59,  2.12it/s]Loading train:  53%|█████▎    | 142/266 [01:03<01:00,  2.05it/s]Loading train:  54%|█████▍    | 143/266 [01:03<00:59,  2.07it/s]Loading train:  54%|█████▍    | 144/266 [01:04<00:57,  2.12it/s]Loading train:  55%|█████▍    | 145/266 [01:04<00:53,  2.26it/s]Loading train:  55%|█████▍    | 146/266 [01:05<00:55,  2.16it/s]Loading train:  55%|█████▌    | 147/266 [01:05<00:55,  2.14it/s]Loading train:  56%|█████▌    | 148/266 [01:06<00:56,  2.07it/s]Loading train:  56%|█████▌    | 149/266 [01:06<00:52,  2.23it/s]Loading train:  56%|█████▋    | 150/266 [01:06<00:49,  2.35it/s]Loading train:  57%|█████▋    | 151/266 [01:07<00:47,  2.42it/s]Loading train:  57%|█████▋    | 152/266 [01:07<00:46,  2.46it/s]Loading train:  58%|█████▊    | 153/266 [01:07<00:46,  2.42it/s]Loading train:  58%|█████▊    | 154/266 [01:08<00:46,  2.43it/s]Loading train:  58%|█████▊    | 155/266 [01:08<00:43,  2.52it/s]Loading train:  59%|█████▊    | 156/266 [01:09<00:43,  2.54it/s]Loading train:  59%|█████▉    | 157/266 [01:09<00:42,  2.58it/s]Loading train:  59%|█████▉    | 158/266 [01:09<00:40,  2.70it/s]Loading train:  60%|█████▉    | 159/266 [01:10<00:40,  2.66it/s]Loading train:  60%|██████    | 160/266 [01:10<00:39,  2.71it/s]Loading train:  61%|██████    | 161/266 [01:10<00:37,  2.84it/s]Loading train:  61%|██████    | 162/266 [01:11<00:35,  2.91it/s]Loading train:  61%|██████▏   | 163/266 [01:11<00:36,  2.85it/s]Loading train:  62%|██████▏   | 164/266 [01:11<00:34,  2.92it/s]Loading train:  62%|██████▏   | 165/266 [01:12<00:33,  2.99it/s]Loading train:  62%|██████▏   | 166/266 [01:12<00:32,  3.05it/s]Loading train:  63%|██████▎   | 167/266 [01:12<00:32,  3.09it/s]Loading train:  63%|██████▎   | 168/266 [01:13<00:32,  3.02it/s]Loading train:  64%|██████▎   | 169/266 [01:13<00:33,  2.92it/s]Loading train:  64%|██████▍   | 170/266 [01:13<00:32,  2.95it/s]Loading train:  64%|██████▍   | 171/266 [01:14<00:31,  2.97it/s]Loading train:  65%|██████▍   | 172/266 [01:14<00:31,  3.00it/s]Loading train:  65%|██████▌   | 173/266 [01:14<00:31,  2.92it/s]Loading train:  65%|██████▌   | 174/266 [01:15<00:31,  2.90it/s]Loading train:  66%|██████▌   | 175/266 [01:15<00:31,  2.90it/s]Loading train:  66%|██████▌   | 176/266 [01:15<00:31,  2.89it/s]Loading train:  67%|██████▋   | 177/266 [01:16<00:31,  2.86it/s]Loading train:  67%|██████▋   | 178/266 [01:16<00:32,  2.70it/s]Loading train:  67%|██████▋   | 179/266 [01:17<00:32,  2.67it/s]Loading train:  68%|██████▊   | 180/266 [01:17<00:33,  2.55it/s]Loading train:  68%|██████▊   | 181/266 [01:17<00:33,  2.58it/s]Loading train:  68%|██████▊   | 182/266 [01:18<00:35,  2.40it/s]Loading train:  69%|██████▉   | 183/266 [01:18<00:32,  2.53it/s]Loading train:  69%|██████▉   | 184/266 [01:19<00:31,  2.62it/s]Loading train:  70%|██████▉   | 185/266 [01:19<00:30,  2.69it/s]Loading train:  70%|██████▉   | 186/266 [01:19<00:29,  2.73it/s]Loading train:  70%|███████   | 187/266 [01:20<00:30,  2.56it/s]Loading train:  71%|███████   | 188/266 [01:20<00:30,  2.56it/s]Loading train:  71%|███████   | 189/266 [01:21<00:29,  2.60it/s]Loading train:  71%|███████▏  | 190/266 [01:21<00:29,  2.56it/s]Loading train:  72%|███████▏  | 191/266 [01:21<00:31,  2.42it/s]Loading train:  72%|███████▏  | 192/266 [01:22<00:28,  2.58it/s]Loading train:  73%|███████▎  | 193/266 [01:22<00:27,  2.64it/s]Loading train:  73%|███████▎  | 194/266 [01:23<00:29,  2.45it/s]Loading train:  73%|███████▎  | 195/266 [01:23<00:28,  2.47it/s]Loading train:  74%|███████▎  | 196/266 [01:23<00:28,  2.48it/s]Loading train:  74%|███████▍  | 197/266 [01:24<00:26,  2.62it/s]Loading train:  74%|███████▍  | 198/266 [01:24<00:24,  2.73it/s]Loading train:  75%|███████▍  | 199/266 [01:24<00:23,  2.80it/s]Loading train:  75%|███████▌  | 200/266 [01:25<00:23,  2.81it/s]Loading train:  76%|███████▌  | 201/266 [01:25<00:24,  2.63it/s]Loading train:  76%|███████▌  | 202/266 [01:26<00:24,  2.61it/s]Loading train:  76%|███████▋  | 203/266 [01:26<00:25,  2.48it/s]Loading train:  77%|███████▋  | 204/266 [01:26<00:24,  2.50it/s]Loading train:  77%|███████▋  | 205/266 [01:27<00:25,  2.39it/s]Loading train:  77%|███████▋  | 206/266 [01:27<00:26,  2.31it/s]Loading train:  78%|███████▊  | 207/266 [01:28<00:25,  2.29it/s]Loading train:  78%|███████▊  | 208/266 [01:28<00:26,  2.22it/s]Loading train:  79%|███████▊  | 209/266 [01:29<00:26,  2.18it/s]Loading train:  79%|███████▉  | 210/266 [01:29<00:26,  2.14it/s]Loading train:  79%|███████▉  | 211/266 [01:30<00:25,  2.19it/s]Loading train:  80%|███████▉  | 212/266 [01:30<00:24,  2.22it/s]Loading train:  80%|████████  | 213/266 [01:31<00:24,  2.17it/s]Loading train:  80%|████████  | 214/266 [01:31<00:22,  2.28it/s]Loading train:  81%|████████  | 215/266 [01:31<00:23,  2.17it/s]Loading train:  81%|████████  | 216/266 [01:32<00:24,  2.06it/s]Loading train:  82%|████████▏ | 217/266 [01:32<00:23,  2.06it/s]Loading train:  82%|████████▏ | 218/266 [01:33<00:23,  2.01it/s]Loading train:  82%|████████▏ | 219/266 [01:33<00:22,  2.05it/s]Loading train:  83%|████████▎ | 220/266 [01:34<00:21,  2.09it/s]Loading train:  83%|████████▎ | 221/266 [01:34<00:21,  2.14it/s]Loading train:  83%|████████▎ | 222/266 [01:35<00:20,  2.19it/s]Loading train:  84%|████████▍ | 223/266 [01:35<00:18,  2.27it/s]Loading train:  84%|████████▍ | 224/266 [01:36<00:18,  2.30it/s]Loading train:  85%|████████▍ | 225/266 [01:36<00:18,  2.26it/s]Loading train:  85%|████████▍ | 226/266 [01:37<00:17,  2.27it/s]Loading train:  85%|████████▌ | 227/266 [01:37<00:17,  2.27it/s]Loading train:  86%|████████▌ | 228/266 [01:37<00:17,  2.19it/s]Loading train:  86%|████████▌ | 229/266 [01:38<00:15,  2.33it/s]Loading train:  86%|████████▋ | 230/266 [01:38<00:15,  2.38it/s]Loading train:  87%|████████▋ | 231/266 [01:39<00:14,  2.33it/s]Loading train:  87%|████████▋ | 232/266 [01:39<00:15,  2.18it/s]Loading train:  88%|████████▊ | 233/266 [01:40<00:14,  2.29it/s]Loading train:  88%|████████▊ | 234/266 [01:40<00:13,  2.32it/s]Loading train:  88%|████████▊ | 235/266 [01:40<00:12,  2.40it/s]Loading train:  89%|████████▊ | 236/266 [01:41<00:12,  2.32it/s]Loading train:  89%|████████▉ | 237/266 [01:41<00:12,  2.23it/s]Loading train:  89%|████████▉ | 238/266 [01:42<00:12,  2.20it/s]Loading train:  90%|████████▉ | 239/266 [01:42<00:11,  2.25it/s]Loading train:  90%|█████████ | 240/266 [01:43<00:11,  2.23it/s]Loading train:  91%|█████████ | 241/266 [01:43<00:11,  2.20it/s]Loading train:  91%|█████████ | 242/266 [01:44<00:10,  2.25it/s]Loading train:  91%|█████████▏| 243/266 [01:44<00:10,  2.28it/s]Loading train:  92%|█████████▏| 244/266 [01:44<00:09,  2.40it/s]Loading train:  92%|█████████▏| 245/266 [01:45<00:08,  2.40it/s]Loading train:  92%|█████████▏| 246/266 [01:45<00:08,  2.49it/s]Loading train:  93%|█████████▎| 247/266 [01:45<00:07,  2.65it/s]Loading train:  93%|█████████▎| 248/266 [01:46<00:06,  2.65it/s]Loading train:  94%|█████████▎| 249/266 [01:46<00:07,  2.38it/s]Loading train:  94%|█████████▍| 250/266 [01:47<00:07,  2.22it/s]Loading train:  94%|█████████▍| 251/266 [01:47<00:07,  2.09it/s]Loading train:  95%|█████████▍| 252/266 [01:48<00:06,  2.04it/s]Loading train:  95%|█████████▌| 253/266 [01:48<00:06,  1.98it/s]Loading train:  95%|█████████▌| 254/266 [01:49<00:06,  1.87it/s]Loading train:  96%|█████████▌| 255/266 [01:50<00:05,  1.89it/s]Loading train:  96%|█████████▌| 256/266 [01:50<00:05,  1.83it/s]Loading train:  97%|█████████▋| 257/266 [01:51<00:04,  1.82it/s]Loading train:  97%|█████████▋| 258/266 [01:51<00:04,  1.94it/s]Loading train:  97%|█████████▋| 259/266 [01:52<00:03,  2.04it/s]Loading train:  98%|█████████▊| 260/266 [01:52<00:03,  1.99it/s]Loading train:  98%|█████████▊| 261/266 [01:53<00:02,  1.94it/s]Loading train:  98%|█████████▊| 262/266 [01:53<00:02,  1.86it/s]Loading train:  99%|█████████▉| 263/266 [01:54<00:01,  1.71it/s]Loading train:  99%|█████████▉| 264/266 [01:54<00:01,  1.81it/s]Loading train: 100%|█████████▉| 265/266 [01:55<00:00,  1.73it/s]Loading train: 100%|██████████| 266/266 [01:56<00:00,  1.63it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:03, 67.85it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:06, 42.06it/s]concatenating: train:   5%|▌         | 14/266 [00:00<00:07, 35.18it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:08, 29.85it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:10, 22.57it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:11, 21.86it/s]concatenating: train:  11%|█         | 28/266 [00:00<00:09, 25.99it/s]concatenating: train:  12%|█▏        | 31/266 [00:01<00:08, 27.01it/s]concatenating: train:  13%|█▎        | 34/266 [00:01<00:09, 25.56it/s]concatenating: train:  15%|█▍        | 39/266 [00:01<00:07, 29.12it/s]concatenating: train:  19%|█▉        | 51/266 [00:01<00:05, 37.40it/s]concatenating: train:  31%|███       | 82/266 [00:01<00:03, 50.73it/s]concatenating: train:  36%|███▌      | 95/266 [00:02<00:04, 41.24it/s]concatenating: train:  39%|███▉      | 105/266 [00:02<00:03, 44.67it/s]concatenating: train:  49%|████▉     | 131/266 [00:02<00:02, 59.37it/s]concatenating: train:  65%|██████▍   | 172/266 [00:02<00:01, 79.80it/s]concatenating: train:  74%|███████▍  | 197/266 [00:02<00:00, 96.92it/s]concatenating: train:  82%|████████▏ | 219/266 [00:03<00:00, 72.91it/s]concatenating: train: 100%|██████████| 266/266 [00:03<00:00, 85.90it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.43it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.44it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.67it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation:  50%|█████     | 2/4 [00:00<00:00, 15.26it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 17.90it/s]2019-07-28 20:21:43.811048: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 20:21:43.811126: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 20:21:43.811140: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 20:21:43.811147: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 20:21:44.492367: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.20it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.00it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.33it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.43it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.38it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:03<00:16,  1.95it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:04<00:14,  2.14it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:05<00:10,  2.61it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:05<00:08,  2.96it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:05<00:06,  3.57it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:05<00:06,  3.64it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:06<00:04,  4.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:06<00:03,  5.27it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:06<00:03,  5.05it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:06<00:02,  5.62it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:09<00:11,  1.09it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:10<00:06,  1.39it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:10<00:03,  1.86it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:11<00:02,  2.17it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:11<00:01,  2.78it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:11<00:00,  3.11it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:11<00:00,  3.81it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 20)  200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 20)  80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 20)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 76, 108, 20)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 20)  3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 20)  80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 20)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 76, 108, 20)  0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 76, 108, 21)  0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 76, 108, 30)  5700        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 76, 108, 30)  120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 76, 108, 30)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 76, 108, 30)  8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 76, 108, 30)  120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 108, 30)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 38, 54, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 38, 54, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 54, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 38, 54, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 38, 54, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 38, 54, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 38, 54, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 19, 27, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 19, 27, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 19, 27, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 19, 27, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 19, 27, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 19, 27, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 19, 27, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 19, 27, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 54, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 54, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 38, 54, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 38, 54, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 38, 54, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 38, 54, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 38, 54, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 30)  16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 76, 108, 30)  120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 76, 108, 30)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 76, 108, 30)  8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 76, 108, 30)  120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 76, 108, 30)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 76, 108, 90)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 76, 108, 90)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 76, 108, 20)  16220       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 76, 108, 20)  80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 76, 108, 20)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 76, 108, 20)  0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 76, 108, 20)  3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 76, 108, 20)  80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 76, 108, 20)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 76, 108, 20)  0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 76, 108, 110) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 76, 108, 2)   222         concatenate_8[0][0]              
==================================================================================================
Total params: 529,762
Trainable params: 137,382
Non-trainable params: 392,380
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 396 samples
Epoch 1/300
 - 80s - loss: 0.1143 - acc: 0.9896 - mDice: 0.8292 - val_loss: 0.0736 - val_acc: 0.9937 - val_mDice: 0.8671

Epoch 00001: val_mDice improved from -inf to 0.86709, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 73s - loss: 0.0562 - acc: 0.9940 - mDice: 0.8968 - val_loss: 0.0661 - val_acc: 0.9940 - val_mDice: 0.8799

Epoch 00002: val_mDice improved from 0.86709 to 0.87988, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 73s - loss: 0.0497 - acc: 0.9946 - mDice: 0.9081 - val_loss: 0.0665 - val_acc: 0.9940 - val_mDice: 0.8792

Epoch 00003: val_mDice did not improve from 0.87988
Epoch 4/300
 - 73s - loss: 0.0459 - acc: 0.9949 - mDice: 0.9147 - val_loss: 0.0599 - val_acc: 0.9947 - val_mDice: 0.8906

Epoch 00004: val_mDice improved from 0.87988 to 0.89061, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 73s - loss: 0.0429 - acc: 0.9952 - mDice: 0.9200 - val_loss: 0.0641 - val_acc: 0.9943 - val_mDice: 0.8833

Epoch 00005: val_mDice did not improve from 0.89061
Epoch 6/300
 - 73s - loss: 0.0412 - acc: 0.9953 - mDice: 0.9232 - val_loss: 0.0700 - val_acc: 0.9942 - val_mDice: 0.8735

Epoch 00006: val_mDice did not improve from 0.89061
Epoch 7/300
 - 74s - loss: 0.0397 - acc: 0.9955 - mDice: 0.9257 - val_loss: 0.0665 - val_acc: 0.9947 - val_mDice: 0.8795

Epoch 00007: val_mDice did not improve from 0.89061
Epoch 8/300
 - 73s - loss: 0.0382 - acc: 0.9956 - mDice: 0.9285 - val_loss: 0.0691 - val_acc: 0.9947 - val_mDice: 0.8756

Epoch 00008: val_mDice did not improve from 0.89061
Epoch 9/300
 - 75s - loss: 0.0371 - acc: 0.9957 - mDice: 0.9304 - val_loss: 0.0686 - val_acc: 0.9946 - val_mDice: 0.8767

Epoch 00009: val_mDice did not improve from 0.89061
Epoch 10/300
 - 74s - loss: 0.0362 - acc: 0.9958 - mDice: 0.9321 - val_loss: 0.0626 - val_acc: 0.9947 - val_mDice: 0.8858

Epoch 00010: val_mDice did not improve from 0.89061
Epoch 11/300
 - 74s - loss: 0.0356 - acc: 0.9958 - mDice: 0.9333 - val_loss: 0.0673 - val_acc: 0.9944 - val_mDice: 0.8783

Epoch 00011: val_mDice did not improve from 0.89061
Epoch 12/300
 - 72s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9346 - val_loss: 0.0682 - val_acc: 0.9946 - val_mDice: 0.8766

Epoch 00012: val_mDice did not improve from 0.89061
Epoch 13/300
 - 73s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9362 - val_loss: 0.0656 - val_acc: 0.9946 - val_mDice: 0.8808

Epoch 00013: val_mDice did not improve from 0.89061
Epoch 14/300
 - 73s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9370 - val_loss: 0.0637 - val_acc: 0.9947 - val_mDice: 0.8841

Epoch 00014: val_mDice did not improve from 0.89061
Epoch 15/300
 - 74s - loss: 0.0332 - acc: 0.9961 - mDice: 0.9377 - val_loss: 0.0647 - val_acc: 0.9945 - val_mDice: 0.8825

Epoch 00015: val_mDice did not improve from 0.89061
Epoch 16/300
 - 74s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9388 - val_loss: 0.0637 - val_acc: 0.9948 - val_mDice: 0.8842

Epoch 00016: val_mDice did not improve from 0.89061
Epoch 17/300
 - 74s - loss: 0.0319 - acc: 0.9962 - mDice: 0.9400 - val_loss: 0.0628 - val_acc: 0.9948 - val_mDice: 0.8856

Epoch 00017: val_mDice did not improve from 0.89061
Epoch 18/300
 - 74s - loss: 0.0318 - acc: 0.9962 - mDice: 0.9402 - val_loss: 0.0635 - val_acc: 0.9946 - val_mDice: 0.8846

Epoch 00018: val_mDice did not improve from 0.89061
Epoch 19/300
 - 76s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9408 - val_loss: 0.0670 - val_acc: 0.9947 - val_mDice: 0.8787

Epoch 00019: val_mDice did not improve from 0.89061
Epoch 20/300
 - 76s - loss: 0.0311 - acc: 0.9963 - mDice: 0.9414 - val_loss: 0.0647 - val_acc: 0.9945 - val_mDice: 0.8826

Epoch 00020: val_mDice did not improve from 0.89061
Epoch 21/300
 - 77s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9423 - val_loss: 0.0636 - val_acc: 0.9943 - val_mDice: 0.8842

Epoch 00021: val_mDice did not improve from 0.89061
Epoch 22/300
 - 73s - loss: 0.0304 - acc: 0.9963 - mDice: 0.9427 - val_loss: 0.0665 - val_acc: 0.9947 - val_mDice: 0.8794

Epoch 00022: val_mDice did not improve from 0.89061
Epoch 23/300
 - 72s - loss: 0.0301 - acc: 0.9964 - mDice: 0.9433 - val_loss: 0.0632 - val_acc: 0.9947 - val_mDice: 0.8850

Epoch 00023: val_mDice did not improve from 0.89061
Epoch 24/300
 - 72s - loss: 0.0300 - acc: 0.9964 - mDice: 0.9434 - val_loss: 0.0646 - val_acc: 0.9947 - val_mDice: 0.8828

Epoch 00024: val_mDice did not improve from 0.89061
Epoch 25/300
 - 73s - loss: 0.0297 - acc: 0.9964 - mDice: 0.9439 - val_loss: 0.0667 - val_acc: 0.9945 - val_mDice: 0.8793

Epoch 00025: val_mDice did not improve from 0.89061
Epoch 26/300
 - 74s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9442 - val_loss: 0.0692 - val_acc: 0.9945 - val_mDice: 0.8753

Epoch 00026: val_mDice did not improve from 0.89061
Epoch 27/300
 - 74s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9445 - val_loss: 0.0665 - val_acc: 0.9947 - val_mDice: 0.8796

Epoch 00027: val_mDice did not improve from 0.89061
Epoch 28/300
 - 74s - loss: 0.0291 - acc: 0.9965 - mDice: 0.9452 - val_loss: 0.0649 - val_acc: 0.9948 - val_mDice: 0.8823

Epoch 00028: val_mDice did not improve from 0.89061
Epoch 29/300
 - 74s - loss: 0.0288 - acc: 0.9965 - mDice: 0.9456 - val_loss: 0.0636 - val_acc: 0.9946 - val_mDice: 0.8842

Epoch 00029: val_mDice did not improve from 0.89061
Epoch 30/300
 - 76s - loss: 0.0288 - acc: 0.9965 - mDice: 0.9457 - val_loss: 0.0662 - val_acc: 0.9947 - val_mDice: 0.8801

Epoch 00030: val_mDice did not improve from 0.89061
Epoch 31/300
 - 77s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9461 - val_loss: 0.0629 - val_acc: 0.9949 - val_mDice: 0.8855

Epoch 00031: val_mDice did not improve from 0.89061
Epoch 32/300
 - 78s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9464 - val_loss: 0.0650 - val_acc: 0.9946 - val_mDice: 0.8820

Epoch 00032: val_mDice did not improve from 0.89061
Epoch 33/300
 - 79s - loss: 0.0281 - acc: 0.9965 - mDice: 0.9469 - val_loss: 0.0651 - val_acc: 0.9944 - val_mDice: 0.8817

Epoch 00033: val_mDice did not improve from 0.89061
Epoch 34/300
 - 78s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9465 - val_loss: 0.0657 - val_acc: 0.9946 - val_mDice: 0.8807

Epoch 00034: val_mDice did not improve from 0.89061
Epoch 35/300
 - 79s - loss: 0.0279 - acc: 0.9966 - mDice: 0.9473 - val_loss: 0.0656 - val_acc: 0.9944 - val_mDice: 0.8809

Epoch 00035: val_mDice did not improve from 0.89061
Epoch 36/300
 - 79s - loss: 0.0278 - acc: 0.9966 - mDice: 0.9476 - val_loss: 0.0645 - val_acc: 0.9947 - val_mDice: 0.8828

Epoch 00036: val_mDice did not improve from 0.89061
Epoch 37/300
 - 74s - loss: 0.0277 - acc: 0.9966 - mDice: 0.9476 - val_loss: 0.0664 - val_acc: 0.9947 - val_mDice: 0.8798

Epoch 00037: val_mDice did not improve from 0.89061
Epoch 38/300
 - 72s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9478 - val_loss: 0.0691 - val_acc: 0.9946 - val_mDice: 0.8750

Epoch 00038: val_mDice did not improve from 0.89061
Epoch 39/300
 - 73s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9479 - val_loss: 0.0698 - val_acc: 0.9947 - val_mDice: 0.8738

Epoch 00039: val_mDice did not improve from 0.89061
Epoch 40/300
 - 76s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9480 - val_loss: 0.0635 - val_acc: 0.9947 - val_mDice: 0.8847

Epoch 00040: val_mDice did not improve from 0.89061
Epoch 41/300
 - 76s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9487 - val_loss: 0.0645 - val_acc: 0.9947 - val_mDice: 0.8827

Epoch 00041: val_mDice did not improve from 0.89061
Epoch 42/300
 - 77s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9489 - val_loss: 0.0657 - val_acc: 0.9948 - val_mDice: 0.8808

Epoch 00042: val_mDice did not improve from 0.89061
Epoch 43/300
 - 76s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9489 - val_loss: 0.0632 - val_acc: 0.9945 - val_mDice: 0.8850

Epoch 00043: val_mDice did not improve from 0.89061
Epoch 44/300
 - 74s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9488 - val_loss: 0.0650 - val_acc: 0.9946 - val_mDice: 0.8822

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:01<00:02,  1.13s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:01,  1.04s/it]predicting test subjects: 100%|██████████| 4/4 [00:03<00:00,  1.12it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<02:42,  1.63it/s]predicting train subjects:   1%|          | 2/266 [00:01<02:39,  1.65it/s]predicting train subjects:   1%|          | 3/266 [00:01<02:26,  1.80it/s]predicting train subjects:   2%|▏         | 4/266 [00:02<02:13,  1.96it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<02:12,  1.97it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<02:07,  2.03it/s]predicting train subjects:   3%|▎         | 7/266 [00:03<02:10,  1.99it/s]predicting train subjects:   3%|▎         | 8/266 [00:04<02:17,  1.88it/s]predicting train subjects:   3%|▎         | 9/266 [00:04<02:19,  1.85it/s]predicting train subjects:   4%|▍         | 10/266 [00:05<02:15,  1.89it/s]predicting train subjects:   4%|▍         | 11/266 [00:05<02:11,  1.94it/s]predicting train subjects:   5%|▍         | 12/266 [00:06<02:09,  1.96it/s]predicting train subjects:   5%|▍         | 13/266 [00:06<02:06,  2.00it/s]predicting train subjects:   5%|▌         | 14/266 [00:07<02:05,  2.01it/s]predicting train subjects:   6%|▌         | 15/266 [00:07<02:05,  2.00it/s]predicting train subjects:   6%|▌         | 16/266 [00:08<02:10,  1.92it/s]predicting train subjects:   6%|▋         | 17/266 [00:08<02:09,  1.93it/s]predicting train subjects:   7%|▋         | 18/266 [00:09<02:06,  1.96it/s]predicting train subjects:   7%|▋         | 19/266 [00:09<02:03,  2.00it/s]predicting train subjects:   8%|▊         | 20/266 [00:10<02:01,  2.02it/s]predicting train subjects:   8%|▊         | 21/266 [00:10<02:00,  2.04it/s]predicting train subjects:   8%|▊         | 22/266 [00:11<01:59,  2.04it/s]predicting train subjects:   9%|▊         | 23/266 [00:11<01:59,  2.03it/s]predicting train subjects:   9%|▉         | 24/266 [00:12<01:56,  2.08it/s]predicting train subjects:   9%|▉         | 25/266 [00:12<01:59,  2.01it/s]predicting train subjects:  10%|▉         | 26/266 [00:13<02:05,  1.92it/s]predicting train subjects:  10%|█         | 27/266 [00:13<02:13,  1.79it/s]predicting train subjects:  11%|█         | 28/266 [00:14<02:13,  1.79it/s]predicting train subjects:  11%|█         | 29/266 [00:14<01:59,  1.98it/s]predicting train subjects:  11%|█▏        | 30/266 [00:15<01:54,  2.06it/s]predicting train subjects:  12%|█▏        | 31/266 [00:15<02:00,  1.95it/s]predicting train subjects:  12%|█▏        | 32/266 [00:16<01:56,  2.00it/s]predicting train subjects:  12%|█▏        | 33/266 [00:16<01:52,  2.06it/s]predicting train subjects:  13%|█▎        | 34/266 [00:17<01:52,  2.07it/s]predicting train subjects:  13%|█▎        | 35/266 [00:17<01:48,  2.13it/s]predicting train subjects:  14%|█▎        | 36/266 [00:18<01:47,  2.13it/s]predicting train subjects:  14%|█▍        | 37/266 [00:18<01:52,  2.04it/s]predicting train subjects:  14%|█▍        | 38/266 [00:19<01:51,  2.05it/s]predicting train subjects:  15%|█▍        | 39/266 [00:19<01:49,  2.08it/s]predicting train subjects:  15%|█▌        | 40/266 [00:20<01:49,  2.06it/s]predicting train subjects:  15%|█▌        | 41/266 [00:20<01:50,  2.04it/s]predicting train subjects:  16%|█▌        | 42/266 [00:21<01:46,  2.10it/s]predicting train subjects:  16%|█▌        | 43/266 [00:21<01:40,  2.21it/s]predicting train subjects:  17%|█▋        | 44/266 [00:21<01:36,  2.29it/s]predicting train subjects:  17%|█▋        | 45/266 [00:22<01:39,  2.22it/s]predicting train subjects:  17%|█▋        | 46/266 [00:22<01:37,  2.26it/s]predicting train subjects:  18%|█▊        | 47/266 [00:23<01:33,  2.35it/s]predicting train subjects:  18%|█▊        | 48/266 [00:23<01:32,  2.34it/s]predicting train subjects:  18%|█▊        | 49/266 [00:23<01:33,  2.33it/s]predicting train subjects:  19%|█▉        | 50/266 [00:24<01:34,  2.29it/s]predicting train subjects:  19%|█▉        | 51/266 [00:24<01:37,  2.21it/s]predicting train subjects:  20%|█▉        | 52/266 [00:25<01:35,  2.23it/s]predicting train subjects:  20%|█▉        | 53/266 [00:25<01:32,  2.30it/s]predicting train subjects:  20%|██        | 54/266 [00:26<01:26,  2.44it/s]predicting train subjects:  21%|██        | 55/266 [00:26<01:25,  2.46it/s]predicting train subjects:  21%|██        | 56/266 [00:26<01:27,  2.40it/s]predicting train subjects:  21%|██▏       | 57/266 [00:27<01:29,  2.32it/s]predicting train subjects:  22%|██▏       | 58/266 [00:27<01:27,  2.37it/s]predicting train subjects:  22%|██▏       | 59/266 [00:28<01:25,  2.43it/s]predicting train subjects:  23%|██▎       | 60/266 [00:28<01:26,  2.39it/s]predicting train subjects:  23%|██▎       | 61/266 [00:29<01:24,  2.44it/s]predicting train subjects:  23%|██▎       | 62/266 [00:29<01:20,  2.52it/s]predicting train subjects:  24%|██▎       | 63/266 [00:29<01:21,  2.48it/s]predicting train subjects:  24%|██▍       | 64/266 [00:30<01:23,  2.43it/s]predicting train subjects:  24%|██▍       | 65/266 [00:30<01:22,  2.44it/s]predicting train subjects:  25%|██▍       | 66/266 [00:31<01:21,  2.47it/s]predicting train subjects:  25%|██▌       | 67/266 [00:31<01:21,  2.43it/s]predicting train subjects:  26%|██▌       | 68/266 [00:31<01:21,  2.43it/s]predicting train subjects:  26%|██▌       | 69/266 [00:32<01:32,  2.13it/s]predicting train subjects:  26%|██▋       | 70/266 [00:33<01:46,  1.85it/s]predicting train subjects:  27%|██▋       | 71/266 [00:33<01:37,  2.00it/s]predicting train subjects:  27%|██▋       | 72/266 [00:34<01:31,  2.12it/s]predicting train subjects:  27%|██▋       | 73/266 [00:34<01:28,  2.18it/s]predicting train subjects:  28%|██▊       | 74/266 [00:34<01:24,  2.27it/s]predicting train subjects:  28%|██▊       | 75/266 [00:35<01:18,  2.44it/s]predicting train subjects:  29%|██▊       | 76/266 [00:35<01:39,  1.91it/s]predicting train subjects:  29%|██▉       | 77/266 [00:36<01:34,  2.00it/s]predicting train subjects:  29%|██▉       | 78/266 [00:37<01:47,  1.75it/s]predicting train subjects:  30%|██▉       | 79/266 [00:37<01:52,  1.67it/s]predicting train subjects:  30%|███       | 80/266 [00:38<01:54,  1.62it/s]predicting train subjects:  30%|███       | 81/266 [00:39<02:02,  1.51it/s]predicting train subjects:  31%|███       | 82/266 [00:39<01:55,  1.59it/s]predicting train subjects:  31%|███       | 83/266 [00:40<01:50,  1.66it/s]predicting train subjects:  32%|███▏      | 84/266 [00:40<01:50,  1.65it/s]predicting train subjects:  32%|███▏      | 85/266 [00:41<01:42,  1.76it/s]predicting train subjects:  32%|███▏      | 86/266 [00:41<01:37,  1.84it/s]predicting train subjects:  33%|███▎      | 87/266 [00:42<01:37,  1.84it/s]predicting train subjects:  33%|███▎      | 88/266 [00:43<01:36,  1.85it/s]predicting train subjects:  33%|███▎      | 89/266 [00:43<01:34,  1.87it/s]predicting train subjects:  34%|███▍      | 90/266 [00:44<01:32,  1.91it/s]predicting train subjects:  34%|███▍      | 91/266 [00:44<01:35,  1.83it/s]predicting train subjects:  35%|███▍      | 92/266 [00:45<01:44,  1.67it/s]predicting train subjects:  35%|███▍      | 93/266 [00:45<01:37,  1.77it/s]predicting train subjects:  35%|███▌      | 94/266 [00:46<01:32,  1.87it/s]predicting train subjects:  36%|███▌      | 95/266 [00:46<01:29,  1.92it/s]predicting train subjects:  36%|███▌      | 96/266 [00:47<01:26,  1.96it/s]predicting train subjects:  36%|███▋      | 97/266 [00:47<01:25,  1.97it/s]predicting train subjects:  37%|███▋      | 98/266 [00:48<01:24,  2.00it/s]predicting train subjects:  37%|███▋      | 99/266 [00:48<01:20,  2.07it/s]predicting train subjects:  38%|███▊      | 100/266 [00:49<01:16,  2.18it/s]predicting train subjects:  38%|███▊      | 101/266 [00:49<01:17,  2.13it/s]predicting train subjects:  38%|███▊      | 102/266 [00:50<01:16,  2.14it/s]predicting train subjects:  39%|███▊      | 103/266 [00:50<01:19,  2.06it/s]predicting train subjects:  39%|███▉      | 104/266 [00:51<01:16,  2.11it/s]predicting train subjects:  39%|███▉      | 105/266 [00:51<01:14,  2.17it/s]predicting train subjects:  40%|███▉      | 106/266 [00:51<01:12,  2.19it/s]predicting train subjects:  40%|████      | 107/266 [00:52<01:11,  2.21it/s]predicting train subjects:  41%|████      | 108/266 [00:52<01:07,  2.33it/s]predicting train subjects:  41%|████      | 109/266 [00:53<01:09,  2.24it/s]predicting train subjects:  41%|████▏     | 110/266 [00:53<01:08,  2.27it/s]predicting train subjects:  42%|████▏     | 111/266 [00:54<01:09,  2.24it/s]predicting train subjects:  42%|████▏     | 112/266 [00:54<01:07,  2.27it/s]predicting train subjects:  42%|████▏     | 113/266 [00:54<01:04,  2.36it/s]predicting train subjects:  43%|████▎     | 114/266 [00:55<01:04,  2.36it/s]predicting train subjects:  43%|████▎     | 115/266 [00:55<01:02,  2.41it/s]predicting train subjects:  44%|████▎     | 116/266 [00:56<01:03,  2.37it/s]predicting train subjects:  44%|████▍     | 117/266 [00:56<01:02,  2.40it/s]predicting train subjects:  44%|████▍     | 118/266 [00:57<01:06,  2.22it/s]predicting train subjects:  45%|████▍     | 119/266 [00:57<01:08,  2.15it/s]predicting train subjects:  45%|████▌     | 120/266 [00:58<01:07,  2.15it/s]predicting train subjects:  45%|████▌     | 121/266 [00:58<01:09,  2.07it/s]predicting train subjects:  46%|████▌     | 122/266 [00:59<01:10,  2.04it/s]predicting train subjects:  46%|████▌     | 123/266 [00:59<01:08,  2.08it/s]predicting train subjects:  47%|████▋     | 124/266 [01:00<01:07,  2.09it/s]predicting train subjects:  47%|████▋     | 125/266 [01:00<01:07,  2.09it/s]predicting train subjects:  47%|████▋     | 126/266 [01:00<01:04,  2.17it/s]predicting train subjects:  48%|████▊     | 127/266 [01:01<01:06,  2.09it/s]predicting train subjects:  48%|████▊     | 128/266 [01:01<01:05,  2.09it/s]predicting train subjects:  48%|████▊     | 129/266 [01:02<01:05,  2.10it/s]predicting train subjects:  49%|████▉     | 130/266 [01:02<01:03,  2.13it/s]predicting train subjects:  49%|████▉     | 131/266 [01:03<01:06,  2.04it/s]predicting train subjects:  50%|████▉     | 132/266 [01:03<01:05,  2.03it/s]predicting train subjects:  50%|█████     | 133/266 [01:04<01:07,  1.96it/s]predicting train subjects:  50%|█████     | 134/266 [01:04<01:05,  2.02it/s]predicting train subjects:  51%|█████     | 135/266 [01:05<01:04,  2.02it/s]predicting train subjects:  51%|█████     | 136/266 [01:05<01:06,  1.96it/s]predicting train subjects:  52%|█████▏    | 137/266 [01:06<01:06,  1.95it/s]predicting train subjects:  52%|█████▏    | 138/266 [01:07<01:08,  1.88it/s]predicting train subjects:  52%|█████▏    | 139/266 [01:07<01:06,  1.90it/s]predicting train subjects:  53%|█████▎    | 140/266 [01:08<01:05,  1.93it/s]predicting train subjects:  53%|█████▎    | 141/266 [01:08<01:03,  1.97it/s]predicting train subjects:  53%|█████▎    | 142/266 [01:09<01:03,  1.97it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:09<01:01,  1.99it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:10<01:01,  1.99it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:10<01:00,  2.00it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:10<00:59,  2.03it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:11<00:58,  2.02it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:11<00:57,  2.06it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:12<00:56,  2.07it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:12<00:54,  2.11it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:13<00:55,  2.08it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:13<00:54,  2.10it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:14<00:54,  2.09it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:14<00:52,  2.15it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:15<00:50,  2.22it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:15<00:45,  2.41it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:15<00:43,  2.52it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:16<00:42,  2.56it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:16<00:44,  2.42it/s]predicting train subjects:  60%|██████    | 160/266 [01:17<00:45,  2.35it/s]predicting train subjects:  61%|██████    | 161/266 [01:17<00:43,  2.42it/s]predicting train subjects:  61%|██████    | 162/266 [01:17<00:40,  2.54it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:18<00:40,  2.54it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:18<00:40,  2.55it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:19<00:39,  2.55it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:19<00:38,  2.57it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:19<00:38,  2.60it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:20<00:37,  2.62it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:20<00:37,  2.57it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:21<00:38,  2.47it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:21<00:39,  2.43it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:21<00:37,  2.53it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:22<00:37,  2.51it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:22<00:38,  2.38it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:23<00:39,  2.29it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:23<00:40,  2.22it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:24<00:40,  2.20it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:24<00:38,  2.28it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:24<00:37,  2.35it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:25<00:37,  2.28it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:25<00:36,  2.32it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:26<00:35,  2.36it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:26<00:33,  2.45it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:26<00:33,  2.48it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:27<00:33,  2.41it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:27<00:32,  2.43it/s]predicting train subjects:  70%|███████   | 187/266 [01:28<00:32,  2.45it/s]predicting train subjects:  71%|███████   | 188/266 [01:28<00:32,  2.42it/s]predicting train subjects:  71%|███████   | 189/266 [01:29<00:31,  2.45it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:29<00:30,  2.51it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:29<00:30,  2.49it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:30<00:29,  2.48it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:30<00:29,  2.46it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:31<00:30,  2.36it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:31<00:30,  2.37it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:31<00:28,  2.44it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:32<00:28,  2.44it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:32<00:27,  2.50it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:33<00:29,  2.30it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:33<00:28,  2.34it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:34<00:28,  2.25it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:34<00:27,  2.29it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:34<00:27,  2.27it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:35<00:26,  2.34it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:35<00:26,  2.33it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:36<00:25,  2.34it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:36<00:26,  2.25it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:37<00:26,  2.16it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:37<00:25,  2.19it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:38<00:25,  2.16it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:38<00:25,  2.12it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:39<00:26,  2.02it/s]predicting train subjects:  80%|████████  | 213/266 [01:39<00:24,  2.14it/s]predicting train subjects:  80%|████████  | 214/266 [01:40<00:23,  2.21it/s]predicting train subjects:  81%|████████  | 215/266 [01:40<00:23,  2.21it/s]predicting train subjects:  81%|████████  | 216/266 [01:40<00:21,  2.32it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:41<00:20,  2.43it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:41<00:20,  2.34it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:42<00:19,  2.40it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:42<00:19,  2.37it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:42<00:18,  2.46it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:43<00:16,  2.59it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:43<00:15,  2.69it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:43<00:15,  2.65it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:44<00:16,  2.56it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:44<00:15,  2.59it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:45<00:15,  2.51it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:45<00:14,  2.65it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:45<00:13,  2.65it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:46<00:13,  2.66it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:46<00:12,  2.69it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:46<00:12,  2.66it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:47<00:12,  2.66it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:47<00:12,  2.61it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:48<00:11,  2.64it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:48<00:11,  2.64it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:48<00:11,  2.59it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:49<00:11,  2.54it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:49<00:10,  2.50it/s]predicting train subjects:  90%|█████████ | 240/266 [01:50<00:10,  2.45it/s]predicting train subjects:  91%|█████████ | 241/266 [01:50<00:10,  2.33it/s]predicting train subjects:  91%|█████████ | 242/266 [01:51<00:10,  2.20it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:51<00:10,  2.23it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:52<00:09,  2.26it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:52<00:08,  2.37it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:52<00:08,  2.39it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:53<00:07,  2.41it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:53<00:07,  2.32it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:54<00:07,  2.18it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:54<00:08,  1.95it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:55<00:07,  2.01it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:55<00:07,  1.99it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:56<00:06,  2.01it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:56<00:05,  2.05it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:57<00:05,  1.94it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:57<00:04,  2.05it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:58<00:04,  2.09it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:58<00:03,  2.08it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:59<00:03,  2.17it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:59<00:02,  2.17it/s]predicting train subjects:  98%|█████████▊| 261/266 [02:00<00:02,  2.20it/s]predicting train subjects:  98%|█████████▊| 262/266 [02:00<00:01,  2.20it/s]predicting train subjects:  99%|█████████▉| 263/266 [02:01<00:01,  2.10it/s]predicting train subjects:  99%|█████████▉| 264/266 [02:01<00:00,  2.12it/s]predicting train subjects: 100%|█████████▉| 265/266 [02:01<00:00,  2.09it/s]predicting train subjects: 100%|██████████| 266/266 [02:02<00:00,  1.99it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 60.55it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 5/266 [00:00<00:05, 48.37it/s]saving BB  train1-THALAMUS:   4%|▍         | 11/266 [00:00<00:05, 49.84it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:04, 53.12it/s]saving BB  train1-THALAMUS:   9%|▉         | 25/266 [00:00<00:04, 55.60it/s]saving BB  train1-THALAMUS:  12%|█▏        | 32/266 [00:00<00:03, 58.80it/s]saving BB  train1-THALAMUS:  15%|█▍        | 39/266 [00:00<00:03, 61.24it/s]saving BB  train1-THALAMUS:  18%|█▊        | 47/266 [00:00<00:03, 64.94it/s]saving BB  train1-THALAMUS:  20%|██        | 54/266 [00:00<00:03, 64.37it/s]saving BB  train1-THALAMUS:  23%|██▎       | 62/266 [00:00<00:02, 68.15it/s]saving BB  train1-THALAMUS:  27%|██▋       | 71/266 [00:01<00:02, 72.33it/s]saving BB  train1-THALAMUS:  30%|██▉       | 79/266 [00:01<00:02, 74.21it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:02, 73.17it/s]saving BB  train1-THALAMUS:  36%|███▌      | 95/266 [00:01<00:02, 73.06it/s]saving BB  train1-THALAMUS:  39%|███▊      | 103/266 [00:01<00:02, 71.59it/s]saving BB  train1-THALAMUS:  42%|████▏     | 111/266 [00:01<00:02, 72.74it/s]saving BB  train1-THALAMUS:  45%|████▍     | 119/266 [00:01<00:02, 73.35it/s]saving BB  train1-THALAMUS:  48%|████▊     | 127/266 [00:01<00:01, 72.02it/s]saving BB  train1-THALAMUS:  51%|█████     | 135/266 [00:01<00:01, 67.10it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:02<00:01, 67.56it/s]saving BB  train1-THALAMUS:  56%|█████▋    | 150/266 [00:02<00:01, 65.54it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 158/266 [00:02<00:01, 68.14it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 167/266 [00:02<00:01, 73.07it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 176/266 [00:02<00:01, 76.41it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 185/266 [00:02<00:01, 78.44it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 76.88it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 201/266 [00:02<00:00, 74.91it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 209/266 [00:02<00:00, 74.71it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 217/266 [00:03<00:00, 74.13it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:03<00:00, 76.43it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:03<00:00, 77.73it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 244/266 [00:03<00:00, 78.36it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 252/266 [00:03<00:00, 77.21it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:03<00:00, 74.64it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 71.72it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<09:35,  2.17s/it]Loading train:   1%|          | 2/266 [00:04<09:08,  2.08s/it]Loading train:   1%|          | 3/266 [00:05<08:24,  1.92s/it]Loading train:   2%|▏         | 4/266 [00:07<07:59,  1.83s/it]Loading train:   2%|▏         | 5/266 [00:09<08:08,  1.87s/it]Loading train:   2%|▏         | 6/266 [00:10<07:52,  1.82s/it]Loading train:   3%|▎         | 7/266 [00:12<07:59,  1.85s/it]Loading train:   3%|▎         | 8/266 [00:14<07:32,  1.75s/it]Loading train:   3%|▎         | 9/266 [00:15<07:12,  1.68s/it]Loading train:   4%|▍         | 10/266 [00:17<06:55,  1.62s/it]Loading train:   4%|▍         | 11/266 [00:18<06:45,  1.59s/it]Loading train:   5%|▍         | 12/266 [00:20<06:49,  1.61s/it]Loading train:   5%|▍         | 13/266 [00:21<06:31,  1.55s/it]Loading train:   5%|▌         | 14/266 [00:23<07:03,  1.68s/it]Loading train:   6%|▌         | 15/266 [00:25<07:08,  1.71s/it]Loading train:   6%|▌         | 16/266 [00:27<06:55,  1.66s/it]Loading train:   6%|▋         | 17/266 [00:28<06:42,  1.62s/it]Loading train:   7%|▋         | 18/266 [00:30<06:28,  1.57s/it]Loading train:   7%|▋         | 19/266 [00:31<06:25,  1.56s/it]Loading train:   8%|▊         | 20/266 [00:33<06:15,  1.53s/it]Loading train:   8%|▊         | 21/266 [00:34<06:17,  1.54s/it]Loading train:   8%|▊         | 22/266 [00:36<06:28,  1.59s/it]Loading train:   9%|▊         | 23/266 [00:38<06:28,  1.60s/it]Loading train:   9%|▉         | 24/266 [00:39<06:20,  1.57s/it]Loading train:   9%|▉         | 25/266 [00:40<05:48,  1.44s/it]Loading train:  10%|▉         | 26/266 [00:42<05:40,  1.42s/it]Loading train:  10%|█         | 27/266 [00:43<05:34,  1.40s/it]Loading train:  11%|█         | 28/266 [00:44<05:30,  1.39s/it]Loading train:  11%|█         | 29/266 [00:46<05:40,  1.44s/it]Loading train:  11%|█▏        | 30/266 [00:47<05:26,  1.38s/it]Loading train:  12%|█▏        | 31/266 [00:48<05:18,  1.36s/it]Loading train:  12%|█▏        | 32/266 [00:50<05:28,  1.40s/it]Loading train:  12%|█▏        | 33/266 [00:51<05:34,  1.43s/it]Loading train:  13%|█▎        | 34/266 [00:53<05:19,  1.38s/it]Loading train:  13%|█▎        | 35/266 [00:54<05:19,  1.38s/it]Loading train:  14%|█▎        | 36/266 [00:55<05:07,  1.34s/it]Loading train:  14%|█▍        | 37/266 [00:57<05:03,  1.33s/it]Loading train:  14%|█▍        | 38/266 [00:58<05:08,  1.35s/it]Loading train:  15%|█▍        | 39/266 [00:59<05:16,  1.40s/it]Loading train:  15%|█▌        | 40/266 [01:01<05:39,  1.50s/it]Loading train:  15%|█▌        | 41/266 [01:03<05:30,  1.47s/it]Loading train:  16%|█▌        | 42/266 [01:04<05:53,  1.58s/it]Loading train:  16%|█▌        | 43/266 [01:06<05:37,  1.51s/it]Loading train:  17%|█▋        | 44/266 [01:07<05:12,  1.41s/it]Loading train:  17%|█▋        | 45/266 [01:08<04:37,  1.26s/it]Loading train:  17%|█▋        | 46/266 [01:09<04:24,  1.20s/it]Loading train:  18%|█▊        | 47/266 [01:10<04:14,  1.16s/it]Loading train:  18%|█▊        | 48/266 [01:11<04:01,  1.11s/it]Loading train:  18%|█▊        | 49/266 [01:12<04:04,  1.13s/it]Loading train:  19%|█▉        | 50/266 [01:13<04:12,  1.17s/it]Loading train:  19%|█▉        | 51/266 [01:14<04:00,  1.12s/it]Loading train:  20%|█▉        | 52/266 [01:15<03:38,  1.02s/it]Loading train:  20%|█▉        | 53/266 [01:16<03:29,  1.02it/s]Loading train:  20%|██        | 54/266 [01:17<03:18,  1.07it/s]Loading train:  21%|██        | 55/266 [01:18<03:12,  1.10it/s]Loading train:  21%|██        | 56/266 [01:19<03:11,  1.09it/s]Loading train:  21%|██▏       | 57/266 [01:20<03:14,  1.07it/s]Loading train:  22%|██▏       | 58/266 [01:21<03:20,  1.04it/s]Loading train:  22%|██▏       | 59/266 [01:22<03:25,  1.01it/s]Loading train:  23%|██▎       | 60/266 [01:23<03:31,  1.03s/it]Loading train:  23%|██▎       | 61/266 [01:24<03:24,  1.00it/s]Loading train:  23%|██▎       | 62/266 [01:25<03:14,  1.05it/s]Loading train:  24%|██▎       | 63/266 [01:26<03:10,  1.07it/s]Loading train:  24%|██▍       | 64/266 [01:26<03:03,  1.10it/s]Loading train:  24%|██▍       | 65/266 [01:27<02:58,  1.12it/s]Loading train:  25%|██▍       | 66/266 [01:28<02:52,  1.16it/s]Loading train:  25%|██▌       | 67/266 [01:29<02:44,  1.21it/s]Loading train:  26%|██▌       | 68/266 [01:30<02:42,  1.22it/s]Loading train:  26%|██▌       | 69/266 [01:30<02:37,  1.25it/s]Loading train:  26%|██▋       | 70/266 [01:31<02:41,  1.22it/s]Loading train:  27%|██▋       | 71/266 [01:32<02:41,  1.20it/s]Loading train:  27%|██▋       | 72/266 [01:33<02:41,  1.20it/s]Loading train:  27%|██▋       | 73/266 [01:34<02:44,  1.18it/s]Loading train:  28%|██▊       | 74/266 [01:35<02:41,  1.19it/s]Loading train:  28%|██▊       | 75/266 [01:35<02:39,  1.20it/s]Loading train:  29%|██▊       | 76/266 [01:36<02:36,  1.21it/s]Loading train:  29%|██▉       | 77/266 [01:37<02:37,  1.20it/s]Loading train:  29%|██▉       | 78/266 [01:38<02:52,  1.09it/s]Loading train:  30%|██▉       | 79/266 [01:39<03:02,  1.03it/s]Loading train:  30%|███       | 80/266 [01:40<03:07,  1.01s/it]Loading train:  30%|███       | 81/266 [01:42<03:19,  1.08s/it]Loading train:  31%|███       | 82/266 [01:43<03:32,  1.15s/it]Loading train:  31%|███       | 83/266 [01:44<03:31,  1.15s/it]Loading train:  32%|███▏      | 84/266 [01:45<03:33,  1.18s/it]Loading train:  32%|███▏      | 85/266 [01:47<03:30,  1.16s/it]Loading train:  32%|███▏      | 86/266 [01:48<03:34,  1.19s/it]Loading train:  33%|███▎      | 87/266 [01:49<03:23,  1.14s/it]Loading train:  33%|███▎      | 88/266 [01:50<03:11,  1.07s/it]Loading train:  33%|███▎      | 89/266 [01:51<03:07,  1.06s/it]Loading train:  34%|███▍      | 90/266 [01:52<03:03,  1.04s/it]Loading train:  34%|███▍      | 91/266 [01:53<02:59,  1.02s/it]Loading train:  35%|███▍      | 92/266 [01:54<02:57,  1.02s/it]Loading train:  35%|███▍      | 93/266 [01:55<02:52,  1.00it/s]Loading train:  35%|███▌      | 94/266 [01:56<02:48,  1.02it/s]Loading train:  36%|███▌      | 95/266 [01:57<02:45,  1.04it/s]Loading train:  36%|███▌      | 96/266 [01:58<03:07,  1.10s/it]Loading train:  36%|███▋      | 97/266 [02:00<03:32,  1.26s/it]Loading train:  37%|███▋      | 98/266 [02:01<03:35,  1.28s/it]Loading train:  37%|███▋      | 99/266 [02:02<03:24,  1.22s/it]Loading train:  38%|███▊      | 100/266 [02:03<03:25,  1.24s/it]Loading train:  38%|███▊      | 101/266 [02:04<03:13,  1.18s/it]Loading train:  38%|███▊      | 102/266 [02:05<03:08,  1.15s/it]Loading train:  39%|███▊      | 103/266 [02:06<02:57,  1.09s/it]Loading train:  39%|███▉      | 104/266 [02:07<02:48,  1.04s/it]Loading train:  39%|███▉      | 105/266 [02:08<02:38,  1.02it/s]Loading train:  40%|███▉      | 106/266 [02:09<02:32,  1.05it/s]Loading train:  40%|████      | 107/266 [02:10<02:27,  1.08it/s]Loading train:  41%|████      | 108/266 [02:11<02:26,  1.08it/s]Loading train:  41%|████      | 109/266 [02:12<02:33,  1.02it/s]Loading train:  41%|████▏     | 110/266 [02:13<02:33,  1.02it/s]Loading train:  42%|████▏     | 111/266 [02:14<02:36,  1.01s/it]Loading train:  42%|████▏     | 112/266 [02:15<02:39,  1.03s/it]Loading train:  42%|████▏     | 113/266 [02:16<02:44,  1.07s/it]Loading train:  43%|████▎     | 114/266 [02:17<02:39,  1.05s/it]Loading train:  43%|████▎     | 115/266 [02:18<02:29,  1.01it/s]Loading train:  44%|████▎     | 116/266 [02:19<02:33,  1.02s/it]Loading train:  44%|████▍     | 117/266 [02:20<02:34,  1.04s/it]Loading train:  44%|████▍     | 118/266 [02:21<02:27,  1.01it/s]Loading train:  45%|████▍     | 119/266 [02:22<02:27,  1.00s/it]Loading train:  45%|████▌     | 120/266 [02:23<02:24,  1.01it/s]Loading train:  45%|████▌     | 121/266 [02:24<02:21,  1.02it/s]Loading train:  46%|████▌     | 122/266 [02:25<02:20,  1.02it/s]Loading train:  46%|████▌     | 123/266 [02:26<02:17,  1.04it/s]Loading train:  47%|████▋     | 124/266 [02:27<02:13,  1.06it/s]Loading train:  47%|████▋     | 125/266 [02:28<02:12,  1.06it/s]Loading train:  47%|████▋     | 126/266 [02:29<02:16,  1.02it/s]Loading train:  48%|████▊     | 127/266 [02:30<02:13,  1.04it/s]Loading train:  48%|████▊     | 128/266 [02:31<02:11,  1.05it/s]Loading train:  48%|████▊     | 129/266 [02:32<02:09,  1.06it/s]Loading train:  49%|████▉     | 130/266 [02:33<02:10,  1.04it/s]Loading train:  49%|████▉     | 131/266 [02:34<02:15,  1.00s/it]Loading train:  50%|████▉     | 132/266 [02:35<02:20,  1.05s/it]Loading train:  50%|█████     | 133/266 [02:36<02:18,  1.04s/it]Loading train:  50%|█████     | 134/266 [02:37<02:17,  1.04s/it]Loading train:  51%|█████     | 135/266 [02:38<02:13,  1.02s/it]Loading train:  51%|█████     | 136/266 [02:39<02:09,  1.00it/s]Loading train:  52%|█████▏    | 137/266 [02:40<02:12,  1.03s/it]Loading train:  52%|█████▏    | 138/266 [02:41<02:18,  1.08s/it]Loading train:  52%|█████▏    | 139/266 [02:42<02:18,  1.09s/it]Loading train:  53%|█████▎    | 140/266 [02:44<02:24,  1.14s/it]Loading train:  53%|█████▎    | 141/266 [02:45<02:32,  1.22s/it]Loading train:  53%|█████▎    | 142/266 [02:46<02:34,  1.24s/it]Loading train:  54%|█████▍    | 143/266 [02:48<02:42,  1.32s/it]Loading train:  54%|█████▍    | 144/266 [02:49<02:44,  1.35s/it]Loading train:  55%|█████▍    | 145/266 [02:51<02:46,  1.38s/it]Loading train:  55%|█████▍    | 146/266 [02:52<02:47,  1.39s/it]Loading train:  55%|█████▌    | 147/266 [02:54<02:47,  1.41s/it]Loading train:  56%|█████▌    | 148/266 [02:55<02:39,  1.35s/it]Loading train:  56%|█████▌    | 149/266 [02:56<02:43,  1.40s/it]Loading train:  56%|█████▋    | 150/266 [02:58<02:46,  1.43s/it]Loading train:  57%|█████▋    | 151/266 [02:59<02:40,  1.39s/it]Loading train:  57%|█████▋    | 152/266 [03:01<02:47,  1.47s/it]Loading train:  58%|█████▊    | 153/266 [03:02<02:43,  1.45s/it]Loading train:  58%|█████▊    | 154/266 [03:04<02:41,  1.44s/it]Loading train:  58%|█████▊    | 155/266 [03:05<02:30,  1.36s/it]Loading train:  59%|█████▊    | 156/266 [03:06<02:21,  1.28s/it]Loading train:  59%|█████▉    | 157/266 [03:07<02:19,  1.28s/it]Loading train:  59%|█████▉    | 158/266 [03:08<02:20,  1.31s/it]Loading train:  60%|█████▉    | 159/266 [03:10<02:13,  1.25s/it]Loading train:  60%|██████    | 160/266 [03:11<02:20,  1.33s/it]Loading train:  61%|██████    | 161/266 [03:12<02:19,  1.33s/it]Loading train:  61%|██████    | 162/266 [03:14<02:14,  1.29s/it]Loading train:  61%|██████▏   | 163/266 [03:15<02:17,  1.33s/it]Loading train:  62%|██████▏   | 164/266 [03:16<02:12,  1.30s/it]Loading train:  62%|██████▏   | 165/266 [03:18<02:11,  1.30s/it]Loading train:  62%|██████▏   | 166/266 [03:19<02:06,  1.27s/it]Loading train:  63%|██████▎   | 167/266 [03:20<02:06,  1.28s/it]Loading train:  63%|██████▎   | 168/266 [03:21<02:05,  1.28s/it]Loading train:  64%|██████▎   | 169/266 [03:23<02:05,  1.29s/it]Loading train:  64%|██████▍   | 170/266 [03:24<01:59,  1.24s/it]Loading train:  64%|██████▍   | 171/266 [03:25<01:59,  1.26s/it]Loading train:  65%|██████▍   | 172/266 [03:26<01:59,  1.28s/it]Loading train:  65%|██████▌   | 173/266 [03:28<01:54,  1.23s/it]Loading train:  65%|██████▌   | 174/266 [03:29<01:46,  1.16s/it]Loading train:  66%|██████▌   | 175/266 [03:30<01:42,  1.13s/it]Loading train:  66%|██████▌   | 176/266 [03:31<01:41,  1.13s/it]Loading train:  67%|██████▋   | 177/266 [03:32<01:41,  1.14s/it]Loading train:  67%|██████▋   | 178/266 [03:33<01:39,  1.13s/it]Loading train:  67%|██████▋   | 179/266 [03:34<01:39,  1.15s/it]Loading train:  68%|██████▊   | 180/266 [03:35<01:39,  1.15s/it]Loading train:  68%|██████▊   | 181/266 [03:37<01:40,  1.18s/it]Loading train:  68%|██████▊   | 182/266 [03:38<01:35,  1.13s/it]Loading train:  69%|██████▉   | 183/266 [03:39<01:33,  1.13s/it]Loading train:  69%|██████▉   | 184/266 [03:40<01:34,  1.15s/it]Loading train:  70%|██████▉   | 185/266 [03:41<01:30,  1.11s/it]Loading train:  70%|██████▉   | 186/266 [03:42<01:29,  1.12s/it]Loading train:  70%|███████   | 187/266 [03:43<01:28,  1.13s/it]Loading train:  71%|███████   | 188/266 [03:44<01:29,  1.15s/it]Loading train:  71%|███████   | 189/266 [03:45<01:24,  1.10s/it]Loading train:  71%|███████▏  | 190/266 [03:47<01:23,  1.10s/it]Loading train:  72%|███████▏  | 191/266 [03:48<01:32,  1.24s/it]Loading train:  72%|███████▏  | 192/266 [03:50<01:38,  1.34s/it]Loading train:  73%|███████▎  | 193/266 [03:51<01:40,  1.38s/it]Loading train:  73%|███████▎  | 194/266 [03:53<01:46,  1.48s/it]Loading train:  73%|███████▎  | 195/266 [03:54<01:38,  1.39s/it]Loading train:  74%|███████▎  | 196/266 [03:55<01:30,  1.30s/it]Loading train:  74%|███████▍  | 197/266 [03:56<01:26,  1.25s/it]Loading train:  74%|███████▍  | 198/266 [03:58<01:27,  1.28s/it]Loading train:  75%|███████▍  | 199/266 [03:59<01:25,  1.27s/it]Loading train:  75%|███████▌  | 200/266 [04:00<01:21,  1.24s/it]Loading train:  76%|███████▌  | 201/266 [04:01<01:19,  1.22s/it]Loading train:  76%|███████▌  | 202/266 [04:02<01:19,  1.24s/it]Loading train:  76%|███████▋  | 203/266 [04:04<01:20,  1.28s/it]Loading train:  77%|███████▋  | 204/266 [04:05<01:16,  1.24s/it]Loading train:  77%|███████▋  | 205/266 [04:06<01:12,  1.20s/it]Loading train:  77%|███████▋  | 206/266 [04:07<01:11,  1.19s/it]Loading train:  78%|███████▊  | 207/266 [04:09<01:17,  1.32s/it]Loading train:  78%|███████▊  | 208/266 [04:10<01:13,  1.27s/it]Loading train:  79%|███████▊  | 209/266 [04:11<01:09,  1.22s/it]Loading train:  79%|███████▉  | 210/266 [04:12<01:06,  1.18s/it]Loading train:  79%|███████▉  | 211/266 [04:13<01:06,  1.20s/it]Loading train:  80%|███████▉  | 212/266 [04:15<01:05,  1.20s/it]Loading train:  80%|████████  | 213/266 [04:16<01:03,  1.20s/it]Loading train:  80%|████████  | 214/266 [04:17<01:01,  1.18s/it]Loading train:  81%|████████  | 215/266 [04:18<00:58,  1.15s/it]Loading train:  81%|████████  | 216/266 [04:19<00:55,  1.12s/it]Loading train:  82%|████████▏ | 217/266 [04:20<00:56,  1.15s/it]Loading train:  82%|████████▏ | 218/266 [04:22<00:55,  1.16s/it]Loading train:  82%|████████▏ | 219/266 [04:23<00:56,  1.21s/it]Loading train:  83%|████████▎ | 220/266 [04:24<00:53,  1.16s/it]Loading train:  83%|████████▎ | 221/266 [04:25<00:51,  1.15s/it]Loading train:  83%|████████▎ | 222/266 [04:26<00:52,  1.18s/it]Loading train:  84%|████████▍ | 223/266 [04:27<00:50,  1.17s/it]Loading train:  84%|████████▍ | 224/266 [04:29<00:48,  1.15s/it]Loading train:  85%|████████▍ | 225/266 [04:30<00:47,  1.16s/it]Loading train:  85%|████████▍ | 226/266 [04:31<00:47,  1.19s/it]Loading train:  85%|████████▌ | 227/266 [04:32<00:47,  1.22s/it]Loading train:  86%|████████▌ | 228/266 [04:33<00:46,  1.22s/it]Loading train:  86%|████████▌ | 229/266 [04:35<00:46,  1.27s/it]Loading train:  86%|████████▋ | 230/266 [04:36<00:48,  1.35s/it]Loading train:  87%|████████▋ | 231/266 [04:38<00:45,  1.30s/it]Loading train:  87%|████████▋ | 232/266 [04:39<00:44,  1.32s/it]Loading train:  88%|████████▊ | 233/266 [04:40<00:41,  1.26s/it]Loading train:  88%|████████▊ | 234/266 [04:41<00:39,  1.24s/it]Loading train:  88%|████████▊ | 235/266 [04:42<00:37,  1.20s/it]Loading train:  89%|████████▊ | 236/266 [04:44<00:36,  1.22s/it]Loading train:  89%|████████▉ | 237/266 [04:45<00:34,  1.19s/it]Loading train:  89%|████████▉ | 238/266 [04:46<00:31,  1.14s/it]Loading train:  90%|████████▉ | 239/266 [04:47<00:30,  1.13s/it]Loading train:  90%|█████████ | 240/266 [04:48<00:33,  1.27s/it]Loading train:  91%|█████████ | 241/266 [04:50<00:30,  1.23s/it]Loading train:  91%|█████████ | 242/266 [04:51<00:28,  1.18s/it]Loading train:  91%|█████████▏| 243/266 [04:52<00:29,  1.30s/it]Loading train:  92%|█████████▏| 244/266 [04:53<00:27,  1.25s/it]Loading train:  92%|█████████▏| 245/266 [04:55<00:25,  1.22s/it]Loading train:  92%|█████████▏| 246/266 [04:56<00:23,  1.16s/it]Loading train:  93%|█████████▎| 247/266 [04:57<00:21,  1.14s/it]Loading train:  93%|█████████▎| 248/266 [04:58<00:20,  1.13s/it]Loading train:  94%|█████████▎| 249/266 [04:59<00:20,  1.21s/it]Loading train:  94%|█████████▍| 250/266 [05:00<00:19,  1.20s/it]Loading train:  94%|█████████▍| 251/266 [05:02<00:19,  1.27s/it]Loading train:  95%|█████████▍| 252/266 [05:03<00:18,  1.33s/it]Loading train:  95%|█████████▌| 253/266 [05:05<00:17,  1.33s/it]Loading train:  95%|█████████▌| 254/266 [05:06<00:15,  1.33s/it]Loading train:  96%|█████████▌| 255/266 [05:07<00:14,  1.33s/it]Loading train:  96%|█████████▌| 256/266 [05:09<00:13,  1.32s/it]Loading train:  97%|█████████▋| 257/266 [05:10<00:12,  1.35s/it]Loading train:  97%|█████████▋| 258/266 [05:11<00:10,  1.33s/it]Loading train:  97%|█████████▋| 259/266 [05:13<00:09,  1.32s/it]Loading train:  98%|█████████▊| 260/266 [05:14<00:08,  1.35s/it]Loading train:  98%|█████████▊| 261/266 [05:15<00:06,  1.32s/it]Loading train:  98%|█████████▊| 262/266 [05:17<00:05,  1.38s/it]Loading train:  99%|█████████▉| 263/266 [05:18<00:04,  1.43s/it]Loading train:  99%|█████████▉| 264/266 [05:20<00:02,  1.44s/it]Loading train: 100%|█████████▉| 265/266 [05:21<00:01,  1.47s/it]Loading train: 100%|██████████| 266/266 [05:23<00:00,  1.59s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 54.47it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:04, 54.06it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 52.07it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:05, 46.29it/s]concatenating: train:  11%|█         | 28/266 [00:00<00:05, 46.76it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 50.63it/s]concatenating: train:  15%|█▌        | 40/266 [00:00<00:04, 50.42it/s]concatenating: train:  18%|█▊        | 49/266 [00:00<00:03, 58.04it/s]concatenating: train:  21%|██        | 56/266 [00:01<00:03, 60.00it/s]concatenating: train:  24%|██▎       | 63/266 [00:01<00:03, 62.61it/s]concatenating: train:  28%|██▊       | 75/266 [00:01<00:02, 73.10it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:02, 70.95it/s]concatenating: train:  36%|███▌      | 95/266 [00:01<00:02, 79.33it/s]concatenating: train:  39%|███▉      | 104/266 [00:01<00:01, 82.25it/s]concatenating: train:  44%|████▎     | 116/266 [00:01<00:01, 90.00it/s]concatenating: train:  47%|████▋     | 126/266 [00:01<00:01, 81.95it/s]concatenating: train:  51%|█████     | 135/266 [00:02<00:02, 64.62it/s]concatenating: train:  54%|█████▍    | 143/266 [00:02<00:01, 62.76it/s]concatenating: train:  56%|█████▋    | 150/266 [00:02<00:02, 55.52it/s]concatenating: train:  61%|██████    | 161/266 [00:02<00:01, 64.70it/s]concatenating: train:  65%|██████▌   | 173/266 [00:02<00:01, 74.53it/s]concatenating: train:  69%|██████▉   | 183/266 [00:02<00:01, 78.49it/s]concatenating: train:  73%|███████▎  | 195/266 [00:02<00:00, 85.99it/s]concatenating: train:  77%|███████▋  | 205/266 [00:02<00:00, 83.56it/s]concatenating: train:  80%|████████  | 214/266 [00:03<00:00, 71.55it/s]concatenating: train:  83%|████████▎ | 222/266 [00:03<00:00, 58.88it/s]concatenating: train:  86%|████████▌ | 229/266 [00:03<00:00, 59.92it/s]concatenating: train:  89%|████████▊ | 236/266 [00:03<00:00, 61.96it/s]concatenating: train:  91%|█████████▏| 243/266 [00:03<00:00, 62.12it/s]concatenating: train:  94%|█████████▍| 250/266 [00:03<00:00, 62.24it/s]concatenating: train:  97%|█████████▋| 257/266 [00:03<00:00, 61.01it/s]concatenating: train:  99%|█████████▉| 264/266 [00:03<00:00, 61.45it/s]concatenating: train: 100%|██████████| 266/266 [00:03<00:00, 67.75it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:05,  1.86s/it]Loading test:  50%|█████     | 2/4 [00:03<00:03,  1.80s/it]Loading test:  75%|███████▌  | 3/4 [00:04<00:01,  1.68s/it]Loading test: 100%|██████████| 4/4 [00:06<00:00,  1.66s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 65.77it/s]2019-07-28 21:25:02.096113: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 21:25:02.096204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 21:25:02.096222: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 21:25:02.096235: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 21:25:02.096717: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.65it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.99it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.57it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.58it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.01it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.85it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:07,  4.56it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.80it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.05it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.65it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.84it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:02,  6.28it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.01it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.88it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.99it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.27it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.65it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  4.89it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  4.74it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.64it/s]
Epoch 00044: val_mDice did not improve from 0.89061
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [0.07357922425926333, 0.0660905074892622, 0.0665174535278118, 0.05991340656247404, 0.06412994272705883, 0.07000887130547051, 0.06654511060979632, 0.06905503830674922, 0.0686006039343398, 0.0625820668470679, 0.06729987948530852, 0.06818291114059964, 0.06561132908017948, 0.06371822808351782, 0.0647399535383841, 0.06372396668626203, 0.0628365839671607, 0.06345807333862541, 0.06696107567786569, 0.06468128939770688, 0.06363783503948438, 0.06648218750276348, 0.06317794415159057, 0.06464610958114417, 0.06673832213261513, 0.0692374064126099, 0.06649479262455545, 0.06486575521829754, 0.06357409808822352, 0.06616925480164061, 0.06288073424513292, 0.06499561915795009, 0.06510793741303261, 0.06574388339438221, 0.06559461535829486, 0.06451877152001617, 0.06641687742537922, 0.06912409993961002, 0.06979936841085102, 0.06354483582004151, 0.06451162297015238, 0.06571146567361523, 0.06321160077597156, 0.06499603116000542], 'val_acc': [0.9937326989390634, 0.9940111351133597, 0.9939791484914645, 0.9947485962901452, 0.9943280325393484, 0.9942197242770532, 0.9946836784030452, 0.9947353694776092, 0.9945710671670509, 0.9947476676016143, 0.9944347883715774, 0.9945695430341394, 0.9945802941466823, 0.9946621409570328, 0.9945261604858168, 0.9948098244089069, 0.994759971445257, 0.994609223170714, 0.9947372018688857, 0.9945261559703134, 0.9943178849990921, 0.9947045960209586, 0.9947288960519464, 0.9947064515918193, 0.994504623942905, 0.9945353898737166, 0.9946609154494122, 0.9947928939804886, 0.9946329033736027, 0.9946778287189175, 0.9948827365432122, 0.9946126049817211, 0.9943729458433209, 0.9945547692101411, 0.9943818657687216, 0.9947101389518892, 0.9947298322663163, 0.9946344509871319, 0.9946550639590832, 0.994738127547081, 0.9947442918112783, 0.9948064347710273, 0.994549542364448, 0.9945975346396668], 'val_mDice': [0.8670930928654141, 0.879876250269437, 0.8791851690321257, 0.8906146730437423, 0.8833237145886277, 0.8735346794128418, 0.8795036218985163, 0.8755565767336373, 0.8767185331595064, 0.8858072664400544, 0.8782753541012003, 0.8765609586479688, 0.8808282478289171, 0.8841420225422791, 0.882468393956772, 0.8841808630962564, 0.8855588821449665, 0.884577852909011, 0.8787197037176653, 0.8825834194819132, 0.884190911295438, 0.8793773259779419, 0.8850092478472777, 0.8828385141160753, 0.8792835552283008, 0.8752851155069139, 0.8795700157531584, 0.8822894767679349, 0.884213760344669, 0.8800582060910235, 0.8854798740810819, 0.8819613646377217, 0.8817489601746954, 0.880721471526406, 0.8809380982861374, 0.882829363598968, 0.8797726739536632, 0.8750084096735175, 0.8738238787410235, 0.884707604092781, 0.8826777498529415, 0.8807623268979968, 0.884990761075357, 0.8821766779880331], 'loss': [0.11431375280497551, 0.05616916144666647, 0.04965173193425718, 0.04592005303061336, 0.042930360433835926, 0.04115990236881811, 0.03973807535958294, 0.03821590072696166, 0.03713361236122736, 0.03624021474730037, 0.0355610573622312, 0.03483827953784353, 0.0339337109797432, 0.03349783620386959, 0.03315214307331645, 0.03251595657747305, 0.03189472409250946, 0.031761237450390466, 0.03145167525701551, 0.031087487371975246, 0.03059297490521707, 0.030381930170465407, 0.03007176188385942, 0.030038950906041334, 0.029736423163548686, 0.029563138309955238, 0.029437217419495787, 0.02906759772463708, 0.028814190913484396, 0.028785226470407287, 0.02857528466983017, 0.028384282835197675, 0.028149189804523078, 0.028359378731663505, 0.027934763514206404, 0.027754732775306736, 0.027735735837857465, 0.02762401229687128, 0.027594875986427448, 0.02752769113653968, 0.02716869391549135, 0.027036337720813035, 0.027030984563776634, 0.02710798418285588], 'acc': [0.9896266540326025, 0.9939514654099368, 0.994576859747639, 0.9949301422360021, 0.9951830530603646, 0.9953396759087895, 0.995484257807544, 0.9956135480555622, 0.9957025866759451, 0.9957849372258314, 0.9958430641984771, 0.9959008709476339, 0.9959948867954497, 0.9960198731362281, 0.996078239918164, 0.9961301423999263, 0.9961860641029422, 0.9962013991511076, 0.9962342368060081, 0.9962656570962334, 0.9963224709947619, 0.9963261504182138, 0.9963531076480037, 0.996375493086321, 0.9964031710495037, 0.99641198989607, 0.9964338632907268, 0.996460862197127, 0.9964635666490014, 0.9964946645306387, 0.9965069894026163, 0.9965236222313357, 0.9965467109414216, 0.9965173453428007, 0.9965595236761494, 0.9965775457017866, 0.9965912057991626, 0.9965955723617077, 0.9966049303484401, 0.9966083484204221, 0.9966341970404504, 0.9966445099367404, 0.9966430482205187, 0.9966434222600568], 'mDice': [0.8291780897733138, 0.89678295705975, 0.9080926236472687, 0.9146752471827905, 0.9200029865476435, 0.9231741031415593, 0.925724570046336, 0.9284730944495648, 0.9304327899144555, 0.9320524265584946, 0.9332896392926503, 0.9346046382307422, 0.9362456765201956, 0.9370449268941852, 0.9376672809562802, 0.9388299421698955, 0.9399682120434847, 0.9402141381840053, 0.9407772025899471, 0.9414458128593016, 0.9423452168282458, 0.9427431648718981, 0.943312714717675, 0.9433653972201457, 0.943924234147436, 0.9442436902832362, 0.9444727237748406, 0.9451547814713809, 0.9456285164960818, 0.945672922045888, 0.9460623744480794, 0.9464156659345354, 0.9468513555702563, 0.9464646801924865, 0.9472527420929264, 0.9475810419291968, 0.9476139284549224, 0.9478228551809796, 0.9478751476219827, 0.9479992785403365, 0.948668579814237, 0.9489142854152294, 0.948925019654404, 0.9487777374034978]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 30)   5700        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 30)   25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 30)   8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 90)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 20)   16220       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 52, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 52, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 52, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 110)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 52, 13)   1443        concatenate_8[0][0]              
==================================================================================================
Total params: 530,983
Trainable params: 138,603
Non-trainable params: 392,380
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34771339e-02 3.28993171e-02 7.69305283e-02 9.55900497e-03
 2.76659371e-02 7.23808858e-03 8.42797958e-02 1.14344565e-01
 8.97830529e-02 1.36411701e-02 2.91094317e-01 1.88847951e-01
 2.39138919e-04]
Train on 16882 samples, validate on 241 samples
Epoch 1/300
 - 27s - loss: 1.0295 - acc: 0.8692 - mDice: 0.4645 - val_loss: 1.4493 - val_acc: 0.9366 - val_mDice: 0.4416

Epoch 00001: val_mDice improved from -inf to 0.44162, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 20s - loss: 0.4476 - acc: 0.9412 - mDice: 0.6385 - val_loss: 1.0417 - val_acc: 0.9530 - val_mDice: 0.5689

Epoch 00002: val_mDice improved from 0.44162 to 0.56887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 20s - loss: 0.3919 - acc: 0.9461 - mDice: 0.6679 - val_loss: 0.6573 - val_acc: 0.9514 - val_mDice: 0.5998

Epoch 00003: val_mDice improved from 0.56887 to 0.59975, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 20s - loss: 0.3560 - acc: 0.9487 - mDice: 0.6911 - val_loss: 0.4736 - val_acc: 0.9542 - val_mDice: 0.6244

Epoch 00004: val_mDice improved from 0.59975 to 0.62435, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 20s - loss: 0.3603 - acc: 0.9485 - mDice: 0.6909 - val_loss: 0.4870 - val_acc: 0.9505 - val_mDice: 0.6198

Epoch 00005: val_mDice did not improve from 0.62435
Epoch 6/300
 - 20s - loss: 0.3574 - acc: 0.9494 - mDice: 0.6958 - val_loss: 0.9446 - val_acc: 0.9493 - val_mDice: 0.5491

Epoch 00006: val_mDice did not improve from 0.62435
Epoch 7/300
 - 19s - loss: 0.3389 - acc: 0.9501 - mDice: 0.7039 - val_loss: 0.5391 - val_acc: 0.9540 - val_mDice: 0.6176

Epoch 00007: val_mDice did not improve from 0.62435
Epoch 8/300
 - 19s - loss: 0.3389 - acc: 0.9504 - mDice: 0.7070 - val_loss: 0.4942 - val_acc: 0.9558 - val_mDice: 0.6201

Epoch 00008: val_mDice did not improve from 0.62435
Epoch 9/300
 - 20s - loss: 0.4102 - acc: 0.9450 - mDice: 0.6637 - val_loss: 0.4666 - val_acc: 0.9521 - val_mDice: 0.6229

Epoch 00009: val_mDice did not improve from 0.62435
Epoch 10/300
 - 20s - loss: 0.3271 - acc: 0.9506 - mDice: 0.7098 - val_loss: 1.1213 - val_acc: 0.9398 - val_mDice: 0.4555

Epoch 00010: val_mDice did not improve from 0.62435
Epoch 11/300
 - 20s - loss: 0.3690 - acc: 0.9480 - mDice: 0.6905 - val_loss: 0.7713 - val_acc: 0.9528 - val_mDice: 0.5912

Epoch 00011: val_mDice did not improve from 0.62435
Epoch 12/300
 - 19s - loss: 0.3304 - acc: 0.9510 - mDice: 0.7146 - val_loss: 0.4705 - val_acc: 0.9552 - val_mDice: 0.6280

Epoch 00012: val_mDice improved from 0.62435 to 0.62804, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 19s - loss: 0.3111 - acc: 0.9523 - mDice: 0.7270 - val_loss: 0.4827 - val_acc: 0.9537 - val_mDice: 0.6200

Epoch 00013: val_mDice did not improve from 0.62804
Epoch 14/300
 - 19s - loss: 0.2961 - acc: 0.9529 - mDice: 0.7342 - val_loss: 0.5576 - val_acc: 0.9535 - val_mDice: 0.5891

Epoch 00014: val_mDice did not improve from 0.62804
Epoch 15/300
 - 20s - loss: 0.3401 - acc: 0.9505 - mDice: 0.7111 - val_loss: 0.4811 - val_acc: 0.9540 - val_mDice: 0.6237

Epoch 00015: val_mDice did not improve from 0.62804
Epoch 16/300
 - 19s - loss: 0.2978 - acc: 0.9532 - mDice: 0.7356 - val_loss: 0.6849 - val_acc: 0.9559 - val_mDice: 0.6210

Epoch 00016: val_mDice did not improve from 0.62804
Epoch 17/300
 - 19s - loss: 0.3099 - acc: 0.9521 - mDice: 0.7246 - val_loss: 0.8895 - val_acc: 0.9486 - val_mDice: 0.5455

Epoch 00017: val_mDice did not improve from 0.62804
Epoch 18/300
 - 19s - loss: 0.3136 - acc: 0.9518 - mDice: 0.7236 - val_loss: 0.4929 - val_acc: 0.9498 - val_mDice: 0.6124

Epoch 00018: val_mDice did not improve from 0.62804
Epoch 19/300
 - 19s - loss: 0.2902 - acc: 0.9535 - mDice: 0.7387 - val_loss: 0.4597 - val_acc: 0.9543 - val_mDice: 0.6291

Epoch 00019: val_mDice improved from 0.62804 to 0.62911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 20s - loss: 0.3191 - acc: 0.9515 - mDice: 0.7203 - val_loss: 0.4911 - val_acc: 0.9541 - val_mDice: 0.6230

Epoch 00020: val_mDice did not improve from 0.62911
Epoch 21/300
 - 19s - loss: 0.2790 - acc: 0.9542 - mDice: 0.7446 - val_loss: 0.5455 - val_acc: 0.9539 - val_mDice: 0.6159

Epoch 00021: val_mDice did not improve from 0.62911
Epoch 22/300
 - 19s - loss: 0.3088 - acc: 0.9527 - mDice: 0.7313 - val_loss: 0.7917 - val_acc: 0.9504 - val_mDice: 0.6091

Epoch 00022: val_mDice did not improve from 0.62911
Epoch 23/300
 - 19s - loss: 0.2868 - acc: 0.9541 - mDice: 0.7445 - val_loss: 0.7764 - val_acc: 0.9560 - val_mDice: 0.6146

Epoch 00023: val_mDice did not improve from 0.62911
Epoch 24/300
 - 19s - loss: 0.2638 - acc: 0.9551 - mDice: 0.7561 - val_loss: 0.6747 - val_acc: 0.9559 - val_mDice: 0.6153

Epoch 00024: val_mDice did not improve from 0.62911
Epoch 25/300
 - 20s - loss: 0.2792 - acc: 0.9547 - mDice: 0.7513 - val_loss: 0.7125 - val_acc: 0.9541 - val_mDice: 0.6025

Epoch 00025: val_mDice did not improve from 0.62911
Epoch 26/300
 - 19s - loss: 0.2889 - acc: 0.9539 - mDice: 0.7424 - val_loss: 1.7848 - val_acc: 0.9523 - val_mDice: 0.5422

Epoch 00026: val_mDice did not improve from 0.62911
Epoch 27/300
 - 19s - loss: 0.2787 - acc: 0.9544 - mDice: 0.7489 - val_loss: 0.6095 - val_acc: 0.9565 - val_mDice: 0.6216

Epoch 00027: val_mDice did not improve from 0.62911
Epoch 28/300
 - 19s - loss: 0.2625 - acc: 0.9552 - mDice: 0.7573 - val_loss: 0.4775 - val_acc: 0.9549 - val_mDice: 0.6240

Epoch 00028: val_mDice did not improve from 0.62911
Epoch 29/300
 - 20s - loss: 0.2680 - acc: 0.9550 - mDice: 0.7556 - val_loss: 0.8173 - val_acc: 0.9542 - val_mDice: 0.5953

Epoch 00029: val_mDice did not improve from 0.62911
Epoch 30/300
 - 19s - loss: 0.2912 - acc: 0.9538 - mDice: 0.7424 - val_loss: 0.4795 - val_acc: 0.9533 - val_mDice: 0.6176

Epoch 00030: val_mDice did not improve from 0.62911
Epoch 31/300
 - 19s - loss: 0.2716 - acc: 0.9550 - mDice: 0.7544 - val_loss: 0.7641 - val_acc: 0.9551 - val_mDice: 0.6062

Epoch 00031: val_mDice did not improve from 0.62911
Epoch 32/300
 - 19s - loss: 0.2511 - acc: 0.9562 - mDice: 0.7665 - val_loss: 0.5650 - val_acc: 0.9543 - val_mDice: 0.6249

Epoch 00032: val_mDice did not improve from 0.62911
Epoch 33/300
 - 19s - loss: 0.2546 - acc: 0.9558 - mDice: 0.7646 - val_loss: 0.5491 - val_acc: 0.9560 - val_mDice: 0.6260

Epoch 00033: val_mDice did not improve from 0.62911
Epoch 34/300
 - 20s - loss: 0.2648 - acc: 0.9556 - mDice: 0.7609 - val_loss: 0.4685 - val_acc: 0.9526 - val_mDice: 0.6248

Epoch 00034: val_mDice did not improve from 0.62911
Epoch 35/300
 - 20s - loss: 0.2517 - acc: 0.9563 - mDice: 0.7683 - val_loss: 0.7865 - val_acc: 0.9544 - val_mDice: 0.6106

Epoch 00035: val_mDice did not improve from 0.62911
Epoch 36/300
 - 19s - loss: 0.2502 - acc: 0.9564 - mDice: 0.7677 - val_loss: 0.7780 - val_acc: 0.9543 - val_mDice: 0.6182

Epoch 00036: val_mDice did not improve from 0.62911
Epoch 37/300
 - 19s - loss: 0.2897 - acc: 0.9540 - mDice: 0.7441 - val_loss: 0.7651 - val_acc: 0.9549 - val_mDice: 0.6187

Epoch 00037: val_mDice did not improve from 0.62911
Epoch 38/300
 - 19s - loss: 0.2676 - acc: 0.9553 - mDice: 0.7568 - val_loss: 0.5073 - val_acc: 0.9553 - val_mDice: 0.6199

Epoch 00038: val_mDice did not improve from 0.62911
Epoch 39/300
 - 20s - loss: 0.2641 - acc: 0.9560 - mDice: 0.7648 - val_loss: 0.7759 - val_acc: 0.9536 - val_mDice: 0.5604

Epoch 00039: val_mDice did not improve from 0.62911
Epoch 40/300
 - 20s - loss: 0.2516 - acc: 0.9559 - mDice: 0.7658 - val_loss: 0.5260 - val_acc: 0.9535 - val_mDice: 0.6212

Epoch 00040: val_mDice did not improve from 0.62911
Epoch 41/300
 - 19s - loss: 0.2687 - acc: 0.9559 - mDice: 0.7617 - val_loss: 1.1022 - val_acc: 0.9531 - val_mDice: 0.5727

Epoch 00041: val_mDice did not improve from 0.62911
Epoch 42/300
 - 19s - loss: 0.2662 - acc: 0.9556 - mDice: 0.7594 - val_loss: 0.8812 - val_acc: 0.9553 - val_mDice: 0.5793

Epoch 00042: val_mDice did not improve from 0.62911
Epoch 43/300
 - 19s - loss: 0.2621 - acc: 0.9561 - mDice: 0.7634 - val_loss: 0.7573 - val_acc: 0.9544 - val_mDice: 0.6234

Epoch 00043: val_mDice did not improve from 0.62911
Epoch 44/300
 - 19s - loss: 0.2548 - acc: 0.9564 - mDice: 0.7706 - val_loss: 0.5225 - val_acc: 0.9534 - val_mDice: 0.6247

Epoch 00044: val_mDice did not improve from 0.62911
Epoch 45/300
 - 20s - loss: 0.2667 - acc: 0.9558 - mDice: 0.7630 - val_loss: 0.7687 - val_acc: 0.9554 - val_mDice: 0.6180

Epoch 00045: val_mDice did not improve from 0.62911
Epoch 46/300
 - 19s - loss: 0.2515 - acc: 0.9567 - mDice: 0.7708 - val_loss: 0.4953 - val_acc: 0.9547 - val_mDice: 0.6207

Epoch 00046: val_mDice did not improve from 0.62911
Epoch 47/300
 - 19s - loss: 0.2318 - acc: 0.9575 - mDice: 0.7815 - val_loss: 0.7634 - val_acc: 0.9557 - val_mDice: 0.6179

Epoch 00047: val_mDice did not improve from 0.62911
Epoch 48/300
 - 19s - loss: 0.2340 - acc: 0.9578 - mDice: 0.7828 - val_loss: 0.6616 - val_acc: 0.9537 - val_mDice: 0.6250

Epoch 00048: val_mDice did not improve from 0.62911
Epoch 49/300
 - 19s - loss: 0.2374 - acc: 0.9577 - mDice: 0.7807 - val_loss: 0.4946 - val_acc: 0.9556 - val_mDice: 0.6194

Epoch 00049: val_mDice did not improve from 0.62911
Epoch 50/300
 - 19s - loss: 0.2606 - acc: 0.9560 - mDice: 0.7646 - val_loss: 0.7641 - val_acc: 0.9538 - val_mDice: 0.6182

Epoch 00050: val_mDice did not improve from 0.62911
Epoch 51/300
 - 19s - loss: 0.2461 - acc: 0.9570 - mDice: 0.7756 - val_loss: 0.7756 - val_acc: 0.9520 - val_mDice: 0.6118

Epoch 00051: val_mDice did not improve from 0.62911
Epoch 52/300
 - 19s - loss: 0.2416 - acc: 0.9574 - mDice: 0.7791 - val_loss: 0.7775 - val_acc: 0.9539 - val_mDice: 0.6175

Epoch 00052: val_mDice did not improve from 0.62911
Epoch 53/300
 - 19s - loss: 0.2495 - acc: 0.9573 - mDice: 0.7777 - val_loss: 0.7152 - val_acc: 0.9566 - val_mDice: 0.6204

Epoch 00053: val_mDice did not improve from 0.62911
Epoch 54/300
 - 19s - loss: 0.2465 - acc: 0.9571 - mDice: 0.7762 - val_loss: 0.6953 - val_acc: 0.9565 - val_mDice: 0.6175

Epoch 00054: val_mDice did not improve from 0.62911
Epoch 55/300
 - 19s - loss: 0.2643 - acc: 0.9550 - mDice: 0.7577 - val_loss: 0.7717 - val_acc: 0.9541 - val_mDice: 0.6159

Epoch 00055: val_mDice did not improve from 0.62911
Epoch 56/300
 - 20s - loss: 0.2331 - acc: 0.9575 - mDice: 0.7825 - val_loss: 0.7946 - val_acc: 0.9558 - val_mDice: 0.6122

Epoch 00056: val_mDice did not improve from 0.62911
Epoch 57/300
 - 19s - loss: 0.2469 - acc: 0.9566 - mDice: 0.7735 - val_loss: 0.7639 - val_acc: 0.9554 - val_mDice: 0.6221

Epoch 00057: val_mDice did not improve from 0.62911
Epoch 58/300
 - 20s - loss: 0.2393 - acc: 0.9577 - mDice: 0.7836 - val_loss: 0.7653 - val_acc: 0.9563 - val_mDice: 0.6184

Epoch 00058: val_mDice did not improve from 0.62911
Epoch 59/300
 - 19s - loss: 0.2480 - acc: 0.9569 - mDice: 0.7743 - val_loss: 0.7636 - val_acc: 0.9547 - val_mDice: 0.6191

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.22s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:05,  2.90s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:07<00:02,  2.67s/it]predicting test subjects: 100%|██████████| 4/4 [00:10<00:00,  2.62s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<13:00,  2.94s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:39,  2.88s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:08,  2.77s/it]predicting train subjects:   2%|▏         | 4/266 [00:10<11:15,  2.58s/it]predicting train subjects:   2%|▏         | 5/266 [00:13<11:24,  2.62s/it]predicting train subjects:   2%|▏         | 6/266 [00:16<11:50,  2.73s/it]predicting train subjects:   3%|▎         | 7/266 [00:18<11:59,  2.78s/it]predicting train subjects:   3%|▎         | 8/266 [00:21<12:17,  2.86s/it]predicting train subjects:   3%|▎         | 9/266 [00:24<12:18,  2.87s/it]predicting train subjects:   4%|▍         | 10/266 [00:27<12:17,  2.88s/it]predicting train subjects:   4%|▍         | 11/266 [00:30<12:20,  2.90s/it]predicting train subjects:   5%|▍         | 12/266 [00:33<12:07,  2.87s/it]predicting train subjects:   5%|▍         | 13/266 [00:36<12:04,  2.86s/it]predicting train subjects:   5%|▌         | 14/266 [00:39<11:54,  2.84s/it]predicting train subjects:   6%|▌         | 15/266 [00:41<11:51,  2.84s/it]predicting train subjects:   6%|▌         | 16/266 [00:44<11:54,  2.86s/it]predicting train subjects:   6%|▋         | 17/266 [00:47<12:04,  2.91s/it]predicting train subjects:   7%|▋         | 18/266 [00:50<12:13,  2.96s/it]predicting train subjects:   7%|▋         | 19/266 [00:53<12:06,  2.94s/it]predicting train subjects:   8%|▊         | 20/266 [00:56<12:01,  2.93s/it]predicting train subjects:   8%|▊         | 21/266 [00:59<11:58,  2.93s/it]predicting train subjects:   8%|▊         | 22/266 [01:02<11:51,  2.91s/it]predicting train subjects:   9%|▊         | 23/266 [01:05<11:44,  2.90s/it]predicting train subjects:   9%|▉         | 24/266 [01:08<11:26,  2.84s/it]predicting train subjects:   9%|▉         | 25/266 [01:10<11:11,  2.79s/it]predicting train subjects:  10%|▉         | 26/266 [01:13<10:55,  2.73s/it]predicting train subjects:  10%|█         | 27/266 [01:16<10:43,  2.69s/it]predicting train subjects:  11%|█         | 28/266 [01:18<10:29,  2.64s/it]predicting train subjects:  11%|█         | 29/266 [01:21<10:19,  2.62s/it]predicting train subjects:  11%|█▏        | 30/266 [01:23<10:15,  2.61s/it]predicting train subjects:  12%|█▏        | 31/266 [01:26<10:15,  2.62s/it]predicting train subjects:  12%|█▏        | 32/266 [01:29<10:26,  2.68s/it]predicting train subjects:  12%|█▏        | 33/266 [01:31<10:11,  2.62s/it]predicting train subjects:  13%|█▎        | 34/266 [01:34<10:01,  2.59s/it]predicting train subjects:  13%|█▎        | 35/266 [01:36<09:54,  2.57s/it]predicting train subjects:  14%|█▎        | 36/266 [01:39<09:56,  2.59s/it]predicting train subjects:  14%|█▍        | 37/266 [01:42<10:04,  2.64s/it]predicting train subjects:  14%|█▍        | 38/266 [01:44<09:59,  2.63s/it]predicting train subjects:  15%|█▍        | 39/266 [01:47<09:48,  2.59s/it]predicting train subjects:  15%|█▌        | 40/266 [01:49<09:49,  2.61s/it]predicting train subjects:  15%|█▌        | 41/266 [01:52<09:56,  2.65s/it]predicting train subjects:  16%|█▌        | 42/266 [01:54<09:22,  2.51s/it]predicting train subjects:  16%|█▌        | 43/266 [01:56<08:57,  2.41s/it]predicting train subjects:  17%|█▋        | 44/266 [01:59<08:36,  2.33s/it]predicting train subjects:  17%|█▋        | 45/266 [02:01<08:24,  2.28s/it]predicting train subjects:  17%|█▋        | 46/266 [02:03<08:29,  2.32s/it]predicting train subjects:  18%|█▊        | 47/266 [02:05<08:26,  2.31s/it]predicting train subjects:  18%|█▊        | 48/266 [02:08<08:16,  2.28s/it]predicting train subjects:  18%|█▊        | 49/266 [02:10<08:07,  2.25s/it]predicting train subjects:  19%|█▉        | 50/266 [02:12<08:03,  2.24s/it]predicting train subjects:  19%|█▉        | 51/266 [02:14<08:07,  2.27s/it]predicting train subjects:  20%|█▉        | 52/266 [02:17<07:58,  2.24s/it]predicting train subjects:  20%|█▉        | 53/266 [02:19<07:57,  2.24s/it]predicting train subjects:  20%|██        | 54/266 [02:21<07:56,  2.25s/it]predicting train subjects:  21%|██        | 55/266 [02:23<08:05,  2.30s/it]predicting train subjects:  21%|██        | 56/266 [02:26<08:01,  2.30s/it]predicting train subjects:  21%|██▏       | 57/266 [02:28<08:05,  2.32s/it]predicting train subjects:  22%|██▏       | 58/266 [02:30<07:57,  2.30s/it]predicting train subjects:  22%|██▏       | 59/266 [02:33<07:48,  2.26s/it]predicting train subjects:  23%|██▎       | 60/266 [02:35<07:31,  2.19s/it]predicting train subjects:  23%|██▎       | 61/266 [02:37<07:17,  2.13s/it]predicting train subjects:  23%|██▎       | 62/266 [02:39<07:16,  2.14s/it]predicting train subjects:  24%|██▎       | 63/266 [02:41<07:04,  2.09s/it]predicting train subjects:  24%|██▍       | 64/266 [02:43<06:52,  2.04s/it]predicting train subjects:  24%|██▍       | 65/266 [02:45<06:56,  2.07s/it]predicting train subjects:  25%|██▍       | 66/266 [02:47<06:51,  2.06s/it]predicting train subjects:  25%|██▌       | 67/266 [02:49<06:48,  2.05s/it]predicting train subjects:  26%|██▌       | 68/266 [02:51<06:45,  2.05s/it]predicting train subjects:  26%|██▌       | 69/266 [02:53<06:44,  2.05s/it]predicting train subjects:  26%|██▋       | 70/266 [02:55<06:50,  2.09s/it]predicting train subjects:  27%|██▋       | 71/266 [02:57<06:55,  2.13s/it]predicting train subjects:  27%|██▋       | 72/266 [02:59<06:46,  2.10s/it]predicting train subjects:  27%|██▋       | 73/266 [03:01<06:37,  2.06s/it]predicting train subjects:  28%|██▊       | 74/266 [03:04<06:44,  2.11s/it]predicting train subjects:  28%|██▊       | 75/266 [03:06<06:42,  2.11s/it]predicting train subjects:  29%|██▊       | 76/266 [03:08<06:35,  2.08s/it]predicting train subjects:  29%|██▉       | 77/266 [03:10<06:25,  2.04s/it]predicting train subjects:  29%|██▉       | 78/266 [03:12<07:03,  2.25s/it]predicting train subjects:  30%|██▉       | 79/266 [03:15<07:25,  2.38s/it]predicting train subjects:  30%|███       | 80/266 [03:18<07:50,  2.53s/it]predicting train subjects:  30%|███       | 81/266 [03:21<07:50,  2.54s/it]predicting train subjects:  31%|███       | 82/266 [03:23<07:46,  2.54s/it]predicting train subjects:  31%|███       | 83/266 [03:26<07:53,  2.59s/it]predicting train subjects:  32%|███▏      | 84/266 [03:29<08:00,  2.64s/it]predicting train subjects:  32%|███▏      | 85/266 [03:31<08:08,  2.70s/it]predicting train subjects:  32%|███▏      | 86/266 [03:34<08:02,  2.68s/it]predicting train subjects:  33%|███▎      | 87/266 [03:37<07:57,  2.67s/it]predicting train subjects:  33%|███▎      | 88/266 [03:39<07:50,  2.64s/it]predicting train subjects:  33%|███▎      | 89/266 [03:42<07:52,  2.67s/it]predicting train subjects:  34%|███▍      | 90/266 [03:45<07:48,  2.66s/it]predicting train subjects:  34%|███▍      | 91/266 [03:47<07:51,  2.70s/it]predicting train subjects:  35%|███▍      | 92/266 [03:50<07:49,  2.70s/it]predicting train subjects:  35%|███▍      | 93/266 [03:53<07:47,  2.70s/it]predicting train subjects:  35%|███▌      | 94/266 [03:56<07:47,  2.72s/it]predicting train subjects:  36%|███▌      | 95/266 [03:58<07:44,  2.72s/it]predicting train subjects:  36%|███▌      | 96/266 [04:01<07:26,  2.62s/it]predicting train subjects:  36%|███▋      | 97/266 [04:03<07:24,  2.63s/it]predicting train subjects:  37%|███▋      | 98/266 [04:06<07:37,  2.73s/it]predicting train subjects:  37%|███▋      | 99/266 [04:08<06:56,  2.49s/it]predicting train subjects:  38%|███▊      | 100/266 [04:10<06:35,  2.38s/it]predicting train subjects:  38%|███▊      | 101/266 [04:13<06:31,  2.37s/it]predicting train subjects:  38%|███▊      | 102/266 [04:15<06:26,  2.36s/it]predicting train subjects:  39%|███▊      | 103/266 [04:17<06:28,  2.38s/it]predicting train subjects:  39%|███▉      | 104/266 [04:20<06:23,  2.37s/it]predicting train subjects:  39%|███▉      | 105/266 [04:22<06:20,  2.36s/it]predicting train subjects:  40%|███▉      | 106/266 [04:25<06:26,  2.42s/it]predicting train subjects:  40%|████      | 107/266 [04:27<06:25,  2.43s/it]predicting train subjects:  41%|████      | 108/266 [04:29<06:18,  2.39s/it]predicting train subjects:  41%|████      | 109/266 [04:32<06:15,  2.39s/it]predicting train subjects:  41%|████▏     | 110/266 [04:34<06:11,  2.38s/it]predicting train subjects:  42%|████▏     | 111/266 [04:37<06:05,  2.36s/it]predicting train subjects:  42%|████▏     | 112/266 [04:39<06:04,  2.36s/it]predicting train subjects:  42%|████▏     | 113/266 [04:41<06:01,  2.36s/it]predicting train subjects:  43%|████▎     | 114/266 [04:44<05:54,  2.33s/it]predicting train subjects:  43%|████▎     | 115/266 [04:46<05:51,  2.33s/it]predicting train subjects:  44%|████▎     | 116/266 [04:48<05:47,  2.31s/it]predicting train subjects:  44%|████▍     | 117/266 [04:50<05:39,  2.28s/it]predicting train subjects:  44%|████▍     | 118/266 [04:53<05:34,  2.26s/it]predicting train subjects:  45%|████▍     | 119/266 [04:55<05:45,  2.35s/it]predicting train subjects:  45%|████▌     | 120/266 [04:58<06:05,  2.50s/it]predicting train subjects:  45%|████▌     | 121/266 [05:01<06:08,  2.54s/it]predicting train subjects:  46%|████▌     | 122/266 [05:03<06:13,  2.60s/it]predicting train subjects:  46%|████▌     | 123/266 [05:06<06:13,  2.61s/it]predicting train subjects:  47%|████▋     | 124/266 [05:09<06:09,  2.60s/it]predicting train subjects:  47%|████▋     | 125/266 [05:11<06:04,  2.59s/it]predicting train subjects:  47%|████▋     | 126/266 [05:14<05:59,  2.57s/it]predicting train subjects:  48%|████▊     | 127/266 [05:16<06:02,  2.61s/it]predicting train subjects:  48%|████▊     | 128/266 [05:19<05:57,  2.59s/it]predicting train subjects:  48%|████▊     | 129/266 [05:21<05:54,  2.59s/it]predicting train subjects:  49%|████▉     | 130/266 [05:24<05:49,  2.57s/it]predicting train subjects:  49%|████▉     | 131/266 [05:27<05:48,  2.58s/it]predicting train subjects:  50%|████▉     | 132/266 [05:29<05:46,  2.58s/it]predicting train subjects:  50%|█████     | 133/266 [05:32<05:43,  2.58s/it]predicting train subjects:  50%|█████     | 134/266 [05:34<05:45,  2.61s/it]predicting train subjects:  51%|█████     | 135/266 [05:37<05:41,  2.61s/it]predicting train subjects:  51%|█████     | 136/266 [05:40<05:45,  2.66s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:42<05:39,  2.63s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:45<05:34,  2.61s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:48<05:31,  2.61s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:50<05:33,  2.65s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:53<05:28,  2.62s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:55<05:22,  2.60s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:58<05:16,  2.57s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:00<05:10,  2.55s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:03<05:06,  2.53s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:05<05:05,  2.55s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:08<05:01,  2.53s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:11<05:01,  2.56s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:13<05:04,  2.60s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:16<05:04,  2.63s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:19<05:01,  2.62s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:21<04:59,  2.63s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:24<04:53,  2.60s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:26<04:47,  2.57s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:28<04:23,  2.37s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:30<04:05,  2.23s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:32<03:56,  2.17s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:34<03:47,  2.11s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:36<03:39,  2.05s/it]predicting train subjects:  60%|██████    | 160/266 [06:38<03:32,  2.00s/it]predicting train subjects:  61%|██████    | 161/266 [06:40<03:26,  1.97s/it]predicting train subjects:  61%|██████    | 162/266 [06:42<03:22,  1.95s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:44<03:21,  1.96s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:46<03:18,  1.95s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:48<03:17,  1.95s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:49<03:14,  1.94s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:51<03:11,  1.93s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:53<03:08,  1.93s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:55<03:04,  1.90s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:57<03:02,  1.90s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:59<03:03,  1.93s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:01<03:01,  1.93s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:03<03:03,  1.97s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:05<03:08,  2.05s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:07<03:10,  2.09s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:09<03:07,  2.08s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:11<03:03,  2.06s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:14<03:03,  2.09s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:16<03:04,  2.12s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:18<03:01,  2.11s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:20<02:57,  2.09s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:22<02:52,  2.05s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:24<02:52,  2.07s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:26<02:49,  2.06s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:28<02:47,  2.07s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:30<02:47,  2.09s/it]predicting train subjects:  70%|███████   | 187/266 [07:32<02:45,  2.10s/it]predicting train subjects:  71%|███████   | 188/266 [07:34<02:42,  2.08s/it]predicting train subjects:  71%|███████   | 189/266 [07:37<02:39,  2.07s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:39<02:38,  2.08s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:41<02:39,  2.13s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:43<02:34,  2.08s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:45<02:29,  2.05s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:47<02:40,  2.23s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:50<02:36,  2.20s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:52<02:34,  2.20s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:54<02:32,  2.20s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:56<02:30,  2.21s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:58<02:29,  2.23s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:01<02:25,  2.20s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:03<02:24,  2.22s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:05<02:21,  2.22s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:07<02:21,  2.25s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:10<02:18,  2.24s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:12<02:16,  2.23s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:14<02:15,  2.25s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:16<02:14,  2.27s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:19<02:21,  2.43s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:22<02:15,  2.37s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:24<02:13,  2.38s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:26<02:09,  2.35s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:28<02:05,  2.32s/it]predicting train subjects:  80%|████████  | 213/266 [08:30<01:57,  2.21s/it]predicting train subjects:  80%|████████  | 214/266 [08:32<01:51,  2.15s/it]predicting train subjects:  81%|████████  | 215/266 [08:34<01:47,  2.11s/it]predicting train subjects:  81%|████████  | 216/266 [08:36<01:44,  2.08s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:38<01:40,  2.05s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:40<01:37,  2.02s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:42<01:34,  2.01s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:44<01:31,  1.99s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:46<01:30,  2.00s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:48<01:28,  2.01s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:50<01:26,  2.02s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:52<01:24,  2.01s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:54<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:56<01:21,  2.03s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:58<01:17,  1.98s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:00<01:15,  2.00s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:02<01:14,  2.02s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:04<01:12,  2.01s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:07<01:11,  2.04s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:09<01:09,  2.05s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:11<01:07,  2.04s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:13<01:05,  2.05s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:15<01:03,  2.05s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:17<01:00,  2.03s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:19<00:58,  2.03s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:21<00:57,  2.04s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:23<00:54,  2.02s/it]predicting train subjects:  90%|█████████ | 240/266 [09:25<00:52,  2.03s/it]predicting train subjects:  91%|█████████ | 241/266 [09:27<00:50,  2.01s/it]predicting train subjects:  91%|█████████ | 242/266 [09:29<00:47,  1.99s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:31<00:46,  2.00s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:33<00:44,  2.00s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:35<00:41,  2.00s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:37<00:39,  1.99s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:39<00:37,  1.99s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:41<00:36,  2.01s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:43<00:36,  2.18s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:46<00:37,  2.35s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:49<00:36,  2.46s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:52<00:35,  2.53s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:54<00:33,  2.61s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:57<00:31,  2.60s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:00<00:28,  2.62s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:02<00:26,  2.62s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:05<00:23,  2.64s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:08<00:21,  2.66s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:10<00:18,  2.64s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:13<00:15,  2.63s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:15<00:13,  2.61s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:18<00:10,  2.63s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:21<00:07,  2.62s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:23<00:05,  2.62s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:26<00:02,  2.63s/it]predicting train subjects: 100%|██████████| 266/266 [10:29<00:00,  2.63s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:12,  1.86s/it]Loading train:   1%|          | 2/266 [00:03<08:17,  1.89s/it]Loading train:   1%|          | 3/266 [00:05<07:49,  1.79s/it]Loading train:   2%|▏         | 4/266 [00:06<07:23,  1.69s/it]Loading train:   2%|▏         | 5/266 [00:08<07:42,  1.77s/it]Loading train:   2%|▏         | 6/266 [00:10<07:27,  1.72s/it]Loading train:   3%|▎         | 7/266 [00:11<07:14,  1.68s/it]Loading train:   3%|▎         | 8/266 [00:13<07:09,  1.67s/it]Loading train:   3%|▎         | 9/266 [00:15<07:38,  1.78s/it]Loading train:   4%|▍         | 10/266 [00:17<07:11,  1.69s/it]Loading train:   4%|▍         | 11/266 [00:18<07:11,  1.69s/it]Loading train:   5%|▍         | 12/266 [00:20<06:54,  1.63s/it]Loading train:   5%|▍         | 13/266 [00:21<06:41,  1.59s/it]Loading train:   5%|▌         | 14/266 [00:23<06:41,  1.59s/it]Loading train:   6%|▌         | 15/266 [00:24<06:31,  1.56s/it]Loading train:   6%|▌         | 16/266 [00:26<06:31,  1.56s/it]Loading train:   6%|▋         | 17/266 [00:27<06:25,  1.55s/it]Loading train:   7%|▋         | 18/266 [00:29<06:16,  1.52s/it]Loading train:   7%|▋         | 19/266 [00:30<06:07,  1.49s/it]Loading train:   8%|▊         | 20/266 [00:32<05:55,  1.45s/it]Loading train:   8%|▊         | 21/266 [00:33<05:49,  1.43s/it]Loading train:   8%|▊         | 22/266 [00:35<06:04,  1.49s/it]Loading train:   9%|▊         | 23/266 [00:36<05:59,  1.48s/it]Loading train:   9%|▉         | 24/266 [00:37<05:44,  1.42s/it]Loading train:   9%|▉         | 25/266 [00:39<05:51,  1.46s/it]Loading train:  10%|▉         | 26/266 [00:41<05:53,  1.47s/it]Loading train:  10%|█         | 27/266 [00:42<05:32,  1.39s/it]Loading train:  11%|█         | 28/266 [00:43<05:29,  1.38s/it]Loading train:  11%|█         | 29/266 [00:45<05:43,  1.45s/it]Loading train:  11%|█▏        | 30/266 [00:46<05:57,  1.52s/it]Loading train:  12%|█▏        | 31/266 [00:48<05:50,  1.49s/it]Loading train:  12%|█▏        | 32/266 [00:49<05:39,  1.45s/it]Loading train:  12%|█▏        | 33/266 [00:50<05:24,  1.39s/it]Loading train:  13%|█▎        | 34/266 [00:52<05:27,  1.41s/it]Loading train:  13%|█▎        | 35/266 [00:53<05:17,  1.37s/it]Loading train:  14%|█▎        | 36/266 [00:55<05:16,  1.38s/it]Loading train:  14%|█▍        | 37/266 [00:56<05:17,  1.39s/it]Loading train:  14%|█▍        | 38/266 [00:57<05:17,  1.39s/it]Loading train:  15%|█▍        | 39/266 [00:59<05:06,  1.35s/it]Loading train:  15%|█▌        | 40/266 [01:00<04:58,  1.32s/it]Loading train:  15%|█▌        | 41/266 [01:01<04:54,  1.31s/it]Loading train:  16%|█▌        | 42/266 [01:02<04:50,  1.30s/it]Loading train:  16%|█▌        | 43/266 [01:04<04:43,  1.27s/it]Loading train:  17%|█▋        | 44/266 [01:05<04:43,  1.28s/it]Loading train:  17%|█▋        | 45/266 [01:06<04:33,  1.24s/it]Loading train:  17%|█▋        | 46/266 [01:07<04:34,  1.25s/it]Loading train:  18%|█▊        | 47/266 [01:08<04:17,  1.18s/it]Loading train:  18%|█▊        | 48/266 [01:10<04:20,  1.19s/it]Loading train:  18%|█▊        | 49/266 [01:11<04:13,  1.17s/it]Loading train:  19%|█▉        | 50/266 [01:12<04:13,  1.17s/it]Loading train:  19%|█▉        | 51/266 [01:13<04:14,  1.18s/it]Loading train:  20%|█▉        | 52/266 [01:14<04:07,  1.16s/it]Loading train:  20%|█▉        | 53/266 [01:16<04:31,  1.27s/it]Loading train:  20%|██        | 54/266 [01:17<04:27,  1.26s/it]Loading train:  21%|██        | 55/266 [01:18<04:35,  1.31s/it]Loading train:  21%|██        | 56/266 [01:20<04:27,  1.27s/it]Loading train:  21%|██▏       | 57/266 [01:21<04:35,  1.32s/it]Loading train:  22%|██▏       | 58/266 [01:22<04:23,  1.27s/it]Loading train:  22%|██▏       | 59/266 [01:23<04:08,  1.20s/it]Loading train:  23%|██▎       | 60/266 [01:24<04:05,  1.19s/it]Loading train:  23%|██▎       | 61/266 [01:25<03:51,  1.13s/it]Loading train:  23%|██▎       | 62/266 [01:26<03:45,  1.10s/it]Loading train:  24%|██▎       | 63/266 [01:27<03:42,  1.10s/it]Loading train:  24%|██▍       | 64/266 [01:28<03:36,  1.07s/it]Loading train:  24%|██▍       | 65/266 [01:30<03:49,  1.14s/it]Loading train:  25%|██▍       | 66/266 [01:31<03:46,  1.13s/it]Loading train:  25%|██▌       | 67/266 [01:32<04:04,  1.23s/it]Loading train:  26%|██▌       | 68/266 [01:34<04:02,  1.22s/it]Loading train:  26%|██▌       | 69/266 [01:35<04:05,  1.24s/it]Loading train:  26%|██▋       | 70/266 [01:36<03:59,  1.22s/it]Loading train:  27%|██▋       | 71/266 [01:37<04:01,  1.24s/it]Loading train:  27%|██▋       | 72/266 [01:38<03:55,  1.21s/it]Loading train:  27%|██▋       | 73/266 [01:40<03:49,  1.19s/it]Loading train:  28%|██▊       | 74/266 [01:41<03:47,  1.18s/it]Loading train:  28%|██▊       | 75/266 [01:42<03:56,  1.24s/it]Loading train:  29%|██▊       | 76/266 [01:43<04:02,  1.28s/it]Loading train:  29%|██▉       | 77/266 [01:45<03:57,  1.26s/it]Loading train:  29%|██▉       | 78/266 [01:46<04:11,  1.34s/it]Loading train:  30%|██▉       | 79/266 [01:48<04:17,  1.38s/it]Loading train:  30%|███       | 80/266 [01:49<04:19,  1.39s/it]Loading train:  30%|███       | 81/266 [01:51<04:21,  1.41s/it]Loading train:  31%|███       | 82/266 [01:52<04:28,  1.46s/it]Loading train:  31%|███       | 83/266 [01:53<04:21,  1.43s/it]Loading train:  32%|███▏      | 84/266 [01:55<04:20,  1.43s/it]Loading train:  32%|███▏      | 85/266 [01:56<04:19,  1.43s/it]Loading train:  32%|███▏      | 86/266 [01:58<04:17,  1.43s/it]Loading train:  33%|███▎      | 87/266 [01:59<04:22,  1.46s/it]Loading train:  33%|███▎      | 88/266 [02:01<04:16,  1.44s/it]Loading train:  33%|███▎      | 89/266 [02:02<04:07,  1.40s/it]Loading train:  34%|███▍      | 90/266 [02:04<04:11,  1.43s/it]Loading train:  34%|███▍      | 91/266 [02:05<04:04,  1.40s/it]Loading train:  35%|███▍      | 92/266 [02:06<04:03,  1.40s/it]Loading train:  35%|███▍      | 93/266 [02:08<04:36,  1.60s/it]Loading train:  35%|███▌      | 94/266 [02:10<04:53,  1.71s/it]Loading train:  36%|███▌      | 95/266 [02:12<04:48,  1.69s/it]Loading train:  36%|███▌      | 96/266 [02:14<04:51,  1.72s/it]Loading train:  36%|███▋      | 97/266 [02:16<04:58,  1.77s/it]
Epoch 00059: val_mDice did not improve from 0.62911
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [1.4492948052794112, 1.0416695734029984, 0.6573321053843281, 0.47363327004602834, 0.4869738010944667, 0.9445649270447458, 0.5391423454917813, 0.4941527136133914, 0.46664419102470905, 1.121346025546062, 0.7713154016441329, 0.47052977317596373, 0.48265733622416424, 0.5575547354349951, 0.4811073855740401, 0.6849165030782154, 0.8895240826725466, 0.4929149931149859, 0.4597131147424215, 0.49113638692871664, 0.5454514740166327, 0.7916952088413397, 0.7763942285939371, 0.6746710444881708, 0.7124651015052162, 1.7847768117778033, 0.6095209521129418, 0.4775038837644569, 0.8172649532185551, 0.4795379134134633, 0.7640978802783855, 0.5649847278209148, 0.5491485481934923, 0.46846987276156415, 0.7864569775543767, 0.7780339482908921, 0.7650970274976675, 0.5072801626322181, 0.775904996884809, 0.5260114473178673, 1.1022005729160862, 0.881201667657037, 0.7572980363586631, 0.5225060318762831, 0.7686593411374388, 0.49531473893347616, 0.7634489303802554, 0.6616303082323668, 0.49459187235080354, 0.7640765287074806, 0.7756227014965041, 0.7774958736668979, 0.7151903439606868, 0.6953065130720495, 0.7716737575056147, 0.7945579691051943, 0.7639165746967822, 0.7652699425507383, 0.7636336769553141], 'val_acc': [0.936590011436415, 0.952983442431169, 0.9513737062200965, 0.9542049241263837, 0.950546606695009, 0.9493466081460976, 0.953980884364037, 0.9557670780237285, 0.9520995473465979, 0.9397818542615012, 0.9527532562180674, 0.9551609351427228, 0.9536647821363077, 0.9535113216930405, 0.954029974848403, 0.9558745006802666, 0.9485900728534367, 0.9498023586154478, 0.9543445792930255, 0.954057595541863, 0.9539210366015612, 0.9504376536088366, 0.9559588978894024, 0.9559190016069847, 0.9540606739610062, 0.9523420089013349, 0.9565450927528603, 0.9548831992624212, 0.9542294753042989, 0.9533348377809485, 0.9550611915924737, 0.9542954747112955, 0.956038697873903, 0.9526166819437906, 0.9544013444318811, 0.954301599645021, 0.9549338379836181, 0.955326680078546, 0.9536478954726729, 0.9534622181005993, 0.9531245985961059, 0.9552576099193937, 0.9544412515964745, 0.9534345991383945, 0.9554156725337396, 0.9547251336802091, 0.9557333217616892, 0.9537062063751379, 0.9555860156834868, 0.9537629858586798, 0.9519629745562541, 0.9539256536119707, 0.9566463612916558, 0.9565420336248469, 0.954115919057759, 0.9557532569184838, 0.9554156750069615, 0.9563302568380269, 0.9546545442209204], 'val_mDice': [0.4416237463594967, 0.56886805884571, 0.5997523583811843, 0.6243546137671253, 0.6197971446880166, 0.5491077385502732, 0.617565240108126, 0.620142986912945, 0.6228671289083869, 0.45545986999614607, 0.5912260024874042, 0.6280446242989346, 0.620019250143613, 0.5890899253584042, 0.6236681804617411, 0.620983823453737, 0.5455136266981417, 0.6124421902217311, 0.6291141203330266, 0.6230459153899514, 0.615916826912971, 0.6090531094440286, 0.6145636565457736, 0.6153366961419829, 0.6025036390391623, 0.5421794353679008, 0.6216381808039558, 0.6240261068482617, 0.5953148996681593, 0.6176158961418753, 0.6061782473350461, 0.624932085330061, 0.6260164293510785, 0.624763811772295, 0.610569119206108, 0.6181886821861584, 0.6186980127793624, 0.6198732402809428, 0.5604080406956653, 0.6211553782348316, 0.5727150774101004, 0.5792849679705513, 0.6234370870708925, 0.6247405397446818, 0.6180431167614411, 0.6207081524662952, 0.6179219274105373, 0.6249671716907707, 0.6194295279712598, 0.6181555241964665, 0.6118266567649683, 0.6175382636889383, 0.6203720609182144, 0.6174929797402061, 0.6159316714373861, 0.6122340359628448, 0.6220523791689101, 0.6184191008821068, 0.6190701342222602], 'loss': [1.0295066562023452, 0.4475981988636835, 0.3919321359679705, 0.3559806514564474, 0.3603367375764021, 0.3573591581362286, 0.3388549286689878, 0.33890511276823354, 0.41015940797638234, 0.3270545563996085, 0.3690014098855983, 0.3304218355936541, 0.31109381290482563, 0.29614221190879475, 0.340101561290282, 0.2977983161706436, 0.30990294923419115, 0.31362148093366604, 0.29018946079200314, 0.31911232621589836, 0.27895036445679705, 0.3087659556232856, 0.28681839026308587, 0.26381789889292984, 0.2792421630873328, 0.2888969295755154, 0.2787046541133603, 0.26247444209216714, 0.2680083332119247, 0.29124031821679564, 0.2715566921306156, 0.2511176355372898, 0.25458252529173775, 0.2647675268423528, 0.25169310530502215, 0.25021777628701297, 0.289746811732821, 0.26759425356954125, 0.26410636928794423, 0.25160129932328545, 0.2686554665828737, 0.2661861495647, 0.2620744489370795, 0.25475798438346975, 0.266689863744865, 0.2514645888502882, 0.23177050044540545, 0.2340235668747025, 0.23735146958523487, 0.2606348528841945, 0.2460772947647351, 0.24162528665374203, 0.24954498856959645, 0.24647472958939856, 0.26434875113988654, 0.23306580817843484, 0.246856512639311, 0.2392862454319774, 0.24797347518995522], 'acc': [0.86920023771587, 0.9411845766188847, 0.9460839692442752, 0.9487342184265846, 0.9485159643791451, 0.9493767089957296, 0.9500554531420764, 0.950443699000896, 0.9450035721766216, 0.9506043161053381, 0.9479910675036852, 0.9510472171143635, 0.9523348067555576, 0.9529473057517422, 0.9504588171989767, 0.9531865873024399, 0.9521052938560615, 0.9518361308467062, 0.9534658738863777, 0.9515283247218738, 0.9541984853438328, 0.9527058566002156, 0.9541224495040737, 0.9550876204626578, 0.9547487507639246, 0.9538633183779952, 0.9544154243607076, 0.9552345659873762, 0.9550235901535892, 0.9538195513390969, 0.9550488255145694, 0.9562195202084376, 0.9557872870326847, 0.9555804690271316, 0.9563228317154991, 0.9563554921374475, 0.9540210897401955, 0.9552883033206743, 0.956032155164821, 0.955946940026172, 0.9558844407818468, 0.9555536778302798, 0.956083283670394, 0.9563842323376887, 0.9558068279504861, 0.9567247671604213, 0.9574944663917746, 0.95776113219177, 0.9576857097128276, 0.956020239277652, 0.9570160326114863, 0.9573779044847835, 0.957321364949374, 0.957147163804455, 0.9549693467563086, 0.9574951457971645, 0.9566270413662554, 0.9576688196517579, 0.9569403467874874], 'mDice': [0.4645462526818774, 0.6385244971880231, 0.6678519996474273, 0.6910832326370681, 0.6908965656619235, 0.6958485430005235, 0.7039086649858787, 0.7069551272988813, 0.6637078372346975, 0.709758354185204, 0.6905480675145979, 0.7145658036767413, 0.7270009523671804, 0.7341613067847379, 0.711099832222623, 0.7355538850047552, 0.7245526695375745, 0.7235720687858189, 0.7387414070303273, 0.7202614624767758, 0.744593413318733, 0.7312946401844514, 0.7445225990675818, 0.7560884022286204, 0.7512845003185447, 0.7423898395366711, 0.7489348337020711, 0.7573380691789646, 0.7555955380233116, 0.7423533278892227, 0.754383585341747, 0.7664846125096454, 0.7646174392574786, 0.7609300023570839, 0.7682901237152465, 0.7676560143669724, 0.7441341669310073, 0.7567776585413288, 0.7648459673563376, 0.7658352430377183, 0.7616655707655889, 0.7594321908621465, 0.7633873109935571, 0.7706337291091953, 0.7629869464674969, 0.7708083295084941, 0.7815138857563219, 0.7827623061497705, 0.7807252629788167, 0.7646426781703053, 0.7756460772039709, 0.7791426418700669, 0.7776692002859885, 0.7762232341552823, 0.7577032306340898, 0.782531282543331, 0.7734834880021607, 0.7835877098301098, 0.7742805486323638]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 maxLoading train:  37%|███▋      | 98/266 [02:17<04:55,  1.76s/it]Loading train:  37%|███▋      | 99/266 [02:19<04:35,  1.65s/it]Loading train:  38%|███▊      | 100/266 [02:20<04:31,  1.63s/it]Loading train:  38%|███▊      | 101/266 [02:22<04:35,  1.67s/it]Loading train:  38%|███▊      | 102/266 [02:23<04:04,  1.49s/it]Loading train:  39%|███▊      | 103/266 [02:25<04:03,  1.49s/it]Loading train:  39%|███▉      | 104/266 [02:26<03:43,  1.38s/it]Loading train:  39%|███▉      | 105/266 [02:27<03:34,  1.33s/it]Loading train:  40%|███▉      | 106/266 [02:28<03:30,  1.32s/it]Loading train:  40%|████      | 107/266 [02:30<03:32,  1.33s/it]Loading train:  41%|████      | 108/266 [02:31<03:23,  1.29s/it]Loading train:  41%|████      | 109/266 [02:32<03:12,  1.22s/it]Loading train:  41%|████▏     | 110/266 [02:33<03:26,  1.33s/it]Loading train:  42%|████▏     | 111/266 [02:35<03:15,  1.26s/it]Loading train:  42%|████▏     | 112/266 [02:36<03:05,  1.21s/it]Loading train:  42%|████▏     | 113/266 [02:37<03:03,  1.20s/it]Loading train:  43%|████▎     | 114/266 [02:38<03:04,  1.22s/it]Loading train:  43%|████▎     | 115/266 [02:39<03:03,  1.21s/it]Loading train:  44%|████▎     | 116/266 [02:41<03:03,  1.22s/it]Loading train:  44%|████▍     | 117/266 [02:42<03:06,  1.25s/it]Loading train:  44%|████▍     | 118/266 [02:43<03:07,  1.26s/it]Loading train:  45%|████▍     | 119/266 [02:45<03:14,  1.32s/it]Loading train:  45%|████▌     | 120/266 [02:47<03:47,  1.56s/it]Loading train:  45%|████▌     | 121/266 [02:48<03:43,  1.54s/it]Loading train:  46%|████▌     | 122/266 [02:50<03:47,  1.58s/it]Loading train:  46%|████▌     | 123/266 [02:51<03:42,  1.56s/it]Loading train:  47%|████▋     | 124/266 [02:53<03:44,  1.58s/it]Loading train:  47%|████▋     | 125/266 [02:54<03:37,  1.54s/it]Loading train:  47%|████▋     | 126/266 [02:56<03:26,  1.48s/it]Loading train:  48%|████▊     | 127/266 [02:57<03:31,  1.52s/it]Loading train:  48%|████▊     | 128/266 [02:59<03:18,  1.44s/it]Loading train:  48%|████▊     | 129/266 [03:00<03:13,  1.41s/it]Loading train:  49%|████▉     | 130/266 [03:01<03:01,  1.34s/it]Loading train:  49%|████▉     | 131/266 [03:03<03:06,  1.38s/it]Loading train:  50%|████▉     | 132/266 [03:04<03:03,  1.37s/it]Loading train:  50%|█████     | 133/266 [03:05<03:06,  1.40s/it]Loading train:  50%|█████     | 134/266 [03:07<03:02,  1.38s/it]Loading train:  51%|█████     | 135/266 [03:09<03:13,  1.48s/it]Loading train:  51%|█████     | 136/266 [03:10<03:10,  1.46s/it]Loading train:  52%|█████▏    | 137/266 [03:11<03:08,  1.46s/it]Loading train:  52%|█████▏    | 138/266 [03:13<03:13,  1.51s/it]Loading train:  52%|█████▏    | 139/266 [03:14<03:07,  1.47s/it]Loading train:  53%|█████▎    | 140/266 [03:16<02:58,  1.42s/it]Loading train:  53%|█████▎    | 141/266 [03:17<02:53,  1.39s/it]Loading train:  53%|█████▎    | 142/266 [03:18<02:47,  1.35s/it]Loading train:  54%|█████▍    | 143/266 [03:20<03:01,  1.48s/it]Loading train:  54%|█████▍    | 144/266 [03:21<02:53,  1.42s/it]Loading train:  55%|█████▍    | 145/266 [03:23<02:48,  1.40s/it]Loading train:  55%|█████▍    | 146/266 [03:24<02:44,  1.37s/it]Loading train:  55%|█████▌    | 147/266 [03:26<02:57,  1.49s/it]Loading train:  56%|█████▌    | 148/266 [03:27<02:53,  1.47s/it]Loading train:  56%|█████▌    | 149/266 [03:28<02:44,  1.41s/it]Loading train:  56%|█████▋    | 150/266 [03:30<02:42,  1.40s/it]Loading train:  57%|█████▋    | 151/266 [03:31<02:40,  1.39s/it]Loading train:  57%|█████▋    | 152/266 [03:33<02:38,  1.39s/it]Loading train:  58%|█████▊    | 153/266 [03:34<02:30,  1.33s/it]Loading train:  58%|█████▊    | 154/266 [03:35<02:26,  1.30s/it]Loading train:  58%|█████▊    | 155/266 [03:36<02:15,  1.22s/it]Loading train:  59%|█████▊    | 156/266 [03:37<02:10,  1.19s/it]Loading train:  59%|█████▉    | 157/266 [03:38<02:04,  1.14s/it]Loading train:  59%|█████▉    | 158/266 [03:39<02:06,  1.17s/it]Loading train:  60%|█████▉    | 159/266 [03:41<02:10,  1.22s/it]Loading train:  60%|██████    | 160/266 [03:42<02:06,  1.19s/it]Loading train:  61%|██████    | 161/266 [03:43<02:03,  1.18s/it]Loading train:  61%|██████    | 162/266 [03:44<01:55,  1.12s/it]Loading train:  61%|██████▏   | 163/266 [03:45<02:01,  1.18s/it]Loading train:  62%|██████▏   | 164/266 [03:47<02:00,  1.19s/it]Loading train:  62%|██████▏   | 165/266 [03:48<02:04,  1.24s/it]Loading train:  62%|██████▏   | 166/266 [03:49<02:05,  1.26s/it]Loading train:  63%|██████▎   | 167/266 [03:51<02:06,  1.28s/it]Loading train:  63%|██████▎   | 168/266 [03:52<02:01,  1.24s/it]Loading train:  64%|██████▎   | 169/266 [03:53<01:59,  1.23s/it]Loading train:  64%|██████▍   | 170/266 [03:54<01:54,  1.20s/it]Loading train:  64%|██████▍   | 171/266 [03:55<01:52,  1.18s/it]Loading train:  65%|██████▍   | 172/266 [03:56<01:50,  1.17s/it]Loading train:  65%|██████▌   | 173/266 [03:58<01:54,  1.23s/it]Loading train:  65%|██████▌   | 174/266 [03:59<01:52,  1.22s/it]Loading train:  66%|██████▌   | 175/266 [04:00<01:46,  1.17s/it]Loading train:  66%|██████▌   | 176/266 [04:01<01:47,  1.19s/it]Loading train:  67%|██████▋   | 177/266 [04:02<01:43,  1.16s/it]Loading train:  67%|██████▋   | 178/266 [04:03<01:42,  1.16s/it]Loading train:  67%|██████▋   | 179/266 [04:05<01:43,  1.19s/it]Loading train:  68%|██████▊   | 180/266 [04:06<01:45,  1.23s/it]Loading train:  68%|██████▊   | 181/266 [04:07<01:46,  1.25s/it]Loading train:  68%|██████▊   | 182/266 [04:08<01:43,  1.23s/it]Loading train:  69%|██████▉   | 183/266 [04:10<01:39,  1.20s/it]Loading train:  69%|██████▉   | 184/266 [04:11<01:37,  1.19s/it]Loading train:  70%|██████▉   | 185/266 [04:12<01:38,  1.21s/it]Loading train:  70%|██████▉   | 186/266 [04:13<01:37,  1.22s/it]Loading train:  70%|███████   | 187/266 [04:14<01:30,  1.15s/it]Loading train:  71%|███████   | 188/266 [04:15<01:30,  1.16s/it]Loading train:  71%|███████   | 189/266 [04:17<01:30,  1.18s/it]Loading train:  71%|███████▏  | 190/266 [04:18<01:28,  1.17s/it]Loading train:  72%|███████▏  | 191/266 [04:19<01:36,  1.29s/it]Loading train:  72%|███████▏  | 192/266 [04:21<01:41,  1.37s/it]Loading train:  73%|███████▎  | 193/266 [04:23<01:50,  1.52s/it]Loading train:  73%|███████▎  | 194/266 [04:25<01:57,  1.63s/it]Loading train:  73%|███████▎  | 195/266 [04:26<01:52,  1.59s/it]Loading train:  74%|███████▎  | 196/266 [04:27<01:45,  1.51s/it]Loading train:  74%|███████▍  | 197/266 [04:29<01:37,  1.41s/it]Loading train:  74%|███████▍  | 198/266 [04:30<01:38,  1.45s/it]Loading train:  75%|███████▍  | 199/266 [04:32<01:37,  1.46s/it]Loading train:  75%|███████▌  | 200/266 [04:33<01:30,  1.36s/it]Loading train:  76%|███████▌  | 201/266 [04:34<01:34,  1.45s/it]Loading train:  76%|███████▌  | 202/266 [04:36<01:35,  1.49s/it]Loading train:  76%|███████▋  | 203/266 [04:37<01:27,  1.39s/it]Loading train:  77%|███████▋  | 204/266 [04:38<01:22,  1.33s/it]Loading train:  77%|███████▋  | 205/266 [04:40<01:19,  1.31s/it]Loading train:  77%|███████▋  | 206/266 [04:41<01:19,  1.33s/it]Loading train:  78%|███████▊  | 207/266 [04:43<01:20,  1.37s/it]Loading train:  78%|███████▊  | 208/266 [04:44<01:24,  1.45s/it]Loading train:  79%|███████▊  | 209/266 [04:45<01:18,  1.38s/it]Loading train:  79%|███████▉  | 210/266 [04:47<01:14,  1.33s/it]Loading train:  79%|███████▉  | 211/266 [04:48<01:11,  1.30s/it]Loading train:  80%|███████▉  | 212/266 [04:49<01:07,  1.24s/it]Loading train:  80%|████████  | 213/266 [04:50<01:05,  1.23s/it]Loading train:  80%|████████  | 214/266 [04:51<01:05,  1.26s/it]Loading train:  81%|████████  | 215/266 [04:53<01:05,  1.28s/it]Loading train:  81%|████████  | 216/266 [04:54<01:01,  1.24s/it]Loading train:  82%|████████▏ | 217/266 [04:55<01:01,  1.25s/it]Loading train:  82%|████████▏ | 218/266 [04:57<01:01,  1.29s/it]Loading train:  82%|████████▏ | 219/266 [04:58<01:02,  1.34s/it]Loading train:  83%|████████▎ | 220/266 [04:59<01:02,  1.35s/it]Loading train:  83%|████████▎ | 221/266 [05:01<01:04,  1.44s/it]Loading train:  83%|████████▎ | 222/266 [05:03<01:10,  1.59s/it]Loading train:  84%|████████▍ | 223/266 [05:05<01:09,  1.61s/it]Loading train:  84%|████████▍ | 224/266 [05:06<01:07,  1.61s/it]Loading train:  85%|████████▍ | 225/266 [05:08<01:05,  1.60s/it]Loading train:  85%|████████▍ | 226/266 [05:09<01:01,  1.53s/it]Loading train:  85%|████████▌ | 227/266 [05:11<00:58,  1.50s/it]Loading train:  86%|████████▌ | 228/266 [05:12<00:54,  1.44s/it]Loading train:  86%|████████▌ | 229/266 [05:13<00:51,  1.40s/it]Loading train:  86%|████████▋ | 230/266 [05:15<00:53,  1.49s/it]Loading train:  87%|████████▋ | 231/266 [05:16<00:50,  1.43s/it]Loading train:  87%|████████▋ | 232/266 [05:17<00:45,  1.34s/it]Loading train:  88%|████████▊ | 233/266 [05:19<00:45,  1.39s/it]Loading train:  88%|████████▊ | 234/266 [05:20<00:44,  1.38s/it]Loading train:  88%|████████▊ | 235/266 [05:21<00:39,  1.28s/it]Loading train:  89%|████████▊ | 236/266 [05:23<00:39,  1.31s/it]Loading train:  89%|████████▉ | 237/266 [05:24<00:38,  1.34s/it]Loading train:  89%|████████▉ | 238/266 [05:25<00:34,  1.25s/it]Loading train:  90%|████████▉ | 239/266 [05:26<00:31,  1.16s/it]Loading train:  90%|█████████ | 240/266 [05:28<00:33,  1.28s/it]Loading train:  91%|█████████ | 241/266 [05:29<00:29,  1.18s/it]Loading train:  91%|█████████ | 242/266 [05:30<00:30,  1.25s/it]Loading train:  91%|█████████▏| 243/266 [05:31<00:28,  1.22s/it]Loading train:  92%|█████████▏| 244/266 [05:32<00:27,  1.26s/it]Loading train:  92%|█████████▏| 245/266 [05:34<00:30,  1.47s/it]Loading train:  92%|█████████▏| 246/266 [05:36<00:27,  1.39s/it]Loading train:  93%|█████████▎| 247/266 [05:37<00:25,  1.36s/it]Loading train:  93%|█████████▎| 248/266 [05:38<00:24,  1.37s/it]Loading train:  94%|█████████▎| 249/266 [05:40<00:24,  1.43s/it]Loading train:  94%|█████████▍| 250/266 [05:42<00:25,  1.60s/it]Loading train:  94%|█████████▍| 251/266 [05:44<00:25,  1.72s/it]Loading train:  95%|█████████▍| 252/266 [05:45<00:22,  1.62s/it]Loading train:  95%|█████████▌| 253/266 [05:47<00:20,  1.60s/it]Loading train:  95%|█████████▌| 254/266 [05:49<00:19,  1.64s/it]Loading train:  96%|█████████▌| 255/266 [05:50<00:17,  1.57s/it]Loading train:  96%|█████████▌| 256/266 [05:51<00:15,  1.51s/it]Loading train:  97%|█████████▋| 257/266 [05:54<00:15,  1.74s/it]Loading train:  97%|█████████▋| 258/266 [05:55<00:13,  1.75s/it]Loading train:  97%|█████████▋| 259/266 [05:57<00:12,  1.77s/it]Loading train:  98%|█████████▊| 260/266 [05:59<00:09,  1.66s/it]Loading train:  98%|█████████▊| 261/266 [06:00<00:07,  1.53s/it]Loading train:  98%|█████████▊| 262/266 [06:01<00:06,  1.52s/it]Loading train:  99%|█████████▉| 263/266 [06:03<00:04,  1.54s/it]Loading train:  99%|█████████▉| 264/266 [06:05<00:03,  1.60s/it]Loading train: 100%|█████████▉| 265/266 [06:06<00:01,  1.58s/it]Loading train: 100%|██████████| 266/266 [06:07<00:00,  1.44s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 53.61it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:04, 57.53it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:04, 59.58it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:04, 56.34it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:04, 53.58it/s]concatenating: train:  14%|█▍        | 38/266 [00:00<00:04, 54.50it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:03, 57.41it/s]concatenating: train:  21%|██        | 55/266 [00:00<00:03, 65.81it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:03, 66.34it/s]concatenating: train:  26%|██▌       | 69/266 [00:01<00:03, 61.84it/s]concatenating: train:  29%|██▊       | 76/266 [00:01<00:03, 61.89it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:03, 58.28it/s]concatenating: train:  35%|███▍      | 93/266 [00:01<00:02, 66.49it/s]concatenating: train:  38%|███▊      | 101/266 [00:01<00:02, 64.21it/s]concatenating: train:  41%|████      | 108/266 [00:01<00:02, 65.10it/s]concatenating: train:  43%|████▎     | 115/266 [00:01<00:02, 65.76it/s]concatenating: train:  46%|████▌     | 122/266 [00:01<00:02, 64.75it/s]concatenating: train:  50%|████▉     | 132/266 [00:02<00:02, 66.04it/s]concatenating: train:  54%|█████▍    | 143/266 [00:02<00:01, 74.42it/s]concatenating: train:  58%|█████▊    | 153/266 [00:02<00:01, 79.07it/s]concatenating: train:  61%|██████    | 162/266 [00:02<00:01, 81.15it/s]concatenating: train:  65%|██████▌   | 174/266 [00:02<00:01, 88.28it/s]concatenating: train:  70%|███████   | 187/266 [00:02<00:00, 96.01it/s]concatenating: train:  75%|███████▍  | 199/266 [00:02<00:00, 101.07it/s]concatenating: train:  79%|███████▉  | 211/266 [00:02<00:00, 103.89it/s]concatenating: train:  83%|████████▎ | 222/266 [00:02<00:00, 97.75it/s] concatenating: train:  88%|████████▊ | 235/266 [00:03<00:00, 104.61it/s]concatenating: train:  92%|█████████▏| 246/266 [00:03<00:00, 100.32it/s]concatenating: train:  97%|█████████▋| 257/266 [00:03<00:00, 100.81it/s]concatenating: train: 100%|██████████| 266/266 [00:03<00:00, 77.69it/s] 
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.42s/it]Loading test:  75%|███████▌  | 3/4 [00:04<00:01,  1.46s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.51s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 41.84it/s]2019-07-28 22:01:53.501280: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 22:01:53.501358: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 22:01:53.501372: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 22:01:53.501380: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 22:01:53.504154: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:13,  3.15it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  3.86it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.85it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.89it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.48it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  4.93it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:07,  4.45it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.73it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:05,  5.02it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.41it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:04,  4.83it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.97it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.29it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:03,  5.22it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.99it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.11it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.25it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  6.43it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.53it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  4.77it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  3.73it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  7.14it/s] 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 84, 48, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 84, 48, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 48, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 84, 48, 40)   7600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 84, 48, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 84, 48, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 84, 48, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 84, 48, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 84, 48, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 42, 24, 80)   28880       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 42, 24, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 42, 24, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 42, 24, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 42, 24, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 42, 24, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 24, 120)  0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 21, 12, 160)  172960      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 21, 12, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 21, 12, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 21, 12, 160)  230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 21, 12, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 21, 12, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 12, 280)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 21, 12, 280)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 42, 24, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 42, 24, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 42, 24, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 42, 24, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 42, 24, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 24, 280)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 42, 24, 280)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 40)   28840       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 84, 48, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 84, 48, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 84, 48, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 84, 48, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 84, 48, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 48, 120)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 84, 48, 120)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 84, 48, 20)   21620       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 84, 48, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 84, 48, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 84, 48, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 84, 48, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 84, 48, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 84, 48, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 84, 48, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 84, 48, 140)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 84, 48, 13)   1833        concatenate_8[0][0]              
==================================================================================================
Total params: 926,093
Trainable params: 229,373
Non-trainable params: 696,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33565320e-02 3.28368109e-02 7.67843660e-02 9.54084357e-03
 2.76133739e-02 7.22430966e-03 8.45433913e-02 1.14127319e-01
 8.96124718e-02 1.36152529e-02 2.90541259e-01 1.89930952e-01
 2.73117818e-04]
Train on 10059 samples, validate on 149 samples
Epoch 1/300
 - 29s - loss: 1.6936 - acc: 0.7839 - mDice: 0.2586 - val_loss: 1.0229 - val_acc: 0.9114 - val_mDice: 0.3887

Epoch 00001: val_mDice improved from -inf to 0.38865, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 20s - loss: 0.6938 - acc: 0.8928 - mDice: 0.4902 - val_loss: 0.9796 - val_acc: 0.9186 - val_mDice: 0.4290

Epoch 00002: val_mDice improved from 0.38865 to 0.42898, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 0.5568 - acc: 0.9134 - mDice: 0.5612 - val_loss: 0.5508 - val_acc: 0.9349 - val_mDice: 0.5664

Epoch 00003: val_mDice improved from 0.42898 to 0.56643, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 0.5111 - acc: 0.9231 - mDice: 0.5866 - val_loss: 0.5230 - val_acc: 0.9345 - val_mDice: 0.5824

Epoch 00004: val_mDice improved from 0.56643 to 0.58241, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 20s - loss: 0.4536 - acc: 0.9289 - mDice: 0.6217 - val_loss: 0.5304 - val_acc: 0.9378 - val_mDice: 0.5832

Epoch 00005: val_mDice improved from 0.58241 to 0.58319, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 19s - loss: 0.4323 - acc: 0.9312 - mDice: 0.6360 - val_loss: 0.5094 - val_acc: 0.9351 - val_mDice: 0.5922

Epoch 00006: val_mDice improved from 0.58319 to 0.59223, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 0.4016 - acc: 0.9338 - mDice: 0.6550 - val_loss: 0.5140 - val_acc: 0.9354 - val_mDice: 0.5900

Epoch 00007: val_mDice did not improve from 0.59223
Epoch 8/300
 - 19s - loss: 0.3867 - acc: 0.9355 - mDice: 0.6660 - val_loss: 0.5662 - val_acc: 0.9358 - val_mDice: 0.5614

Epoch 00008: val_mDice did not improve from 0.59223
Epoch 9/300
 - 20s - loss: 0.3789 - acc: 0.9360 - mDice: 0.6713 - val_loss: 0.5066 - val_acc: 0.9360 - val_mDice: 0.5946

Epoch 00009: val_mDice improved from 0.59223 to 0.59463, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 19s - loss: 0.3710 - acc: 0.9371 - mDice: 0.6766 - val_loss: 0.4514 - val_acc: 0.9420 - val_mDice: 0.6265

Epoch 00010: val_mDice improved from 0.59463 to 0.62655, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 19s - loss: 0.3541 - acc: 0.9386 - mDice: 0.6880 - val_loss: 0.5689 - val_acc: 0.9309 - val_mDice: 0.5611

Epoch 00011: val_mDice did not improve from 0.62655
Epoch 12/300
 - 19s - loss: 0.3396 - acc: 0.9402 - mDice: 0.6989 - val_loss: 0.8766 - val_acc: 0.9367 - val_mDice: 0.5036

Epoch 00012: val_mDice did not improve from 0.62655
Epoch 13/300
 - 19s - loss: 0.3623 - acc: 0.9381 - mDice: 0.6835 - val_loss: 0.4546 - val_acc: 0.9419 - val_mDice: 0.6239

Epoch 00013: val_mDice did not improve from 0.62655
Epoch 14/300
 - 20s - loss: 0.3274 - acc: 0.9412 - mDice: 0.7071 - val_loss: 0.4767 - val_acc: 0.9390 - val_mDice: 0.6120

Epoch 00014: val_mDice did not improve from 0.62655
Epoch 15/300
 - 19s - loss: 0.3219 - acc: 0.9420 - mDice: 0.7125 - val_loss: 0.4521 - val_acc: 0.9419 - val_mDice: 0.6250

Epoch 00015: val_mDice did not improve from 0.62655
Epoch 16/300
 - 19s - loss: 0.3305 - acc: 0.9412 - mDice: 0.7057 - val_loss: 0.4603 - val_acc: 0.9440 - val_mDice: 0.6216

Epoch 00016: val_mDice did not improve from 0.62655
Epoch 17/300
 - 19s - loss: 0.3115 - acc: 0.9427 - mDice: 0.7198 - val_loss: 0.5080 - val_acc: 0.9444 - val_mDice: 0.6024

Epoch 00017: val_mDice did not improve from 0.62655
Epoch 18/300
 - 19s - loss: 0.3075 - acc: 0.9434 - mDice: 0.7232 - val_loss: 0.5948 - val_acc: 0.9345 - val_mDice: 0.5514

Epoch 00018: val_mDice did not improve from 0.62655
Epoch 19/300
 - 19s - loss: 0.3493 - acc: 0.9393 - mDice: 0.6936 - val_loss: 0.4660 - val_acc: 0.9411 - val_mDice: 0.6164

Epoch 00019: val_mDice did not improve from 0.62655
Epoch 20/300
 - 19s - loss: 0.3386 - acc: 0.9406 - mDice: 0.7001 - val_loss: 0.4460 - val_acc: 0.9443 - val_mDice: 0.6308

Epoch 00020: val_mDice improved from 0.62655 to 0.63078, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 19s - loss: 0.3217 - acc: 0.9423 - mDice: 0.7123 - val_loss: 0.4518 - val_acc: 0.9448 - val_mDice: 0.6262

Epoch 00021: val_mDice did not improve from 0.63078
Epoch 22/300
 - 19s - loss: 0.3033 - acc: 0.9438 - mDice: 0.7249 - val_loss: 0.4835 - val_acc: 0.9415 - val_mDice: 0.6068

Epoch 00022: val_mDice did not improve from 0.63078
Epoch 23/300
 - 19s - loss: 0.2923 - acc: 0.9448 - mDice: 0.7333 - val_loss: 0.4680 - val_acc: 0.9434 - val_mDice: 0.6172

Epoch 00023: val_mDice did not improve from 0.63078
Epoch 24/300
 - 19s - loss: 0.2862 - acc: 0.9454 - mDice: 0.7385 - val_loss: 0.5731 - val_acc: 0.9347 - val_mDice: 0.5634

Epoch 00024: val_mDice did not improve from 0.63078
Epoch 25/300
 - 19s - loss: 0.3612 - acc: 0.9390 - mDice: 0.6911 - val_loss: 0.5369 - val_acc: 0.9354 - val_mDice: 0.5788

Epoch 00025: val_mDice did not improve from 0.63078
Epoch 26/300
 - 19s - loss: 0.3538 - acc: 0.9400 - mDice: 0.6911 - val_loss: 0.4637 - val_acc: 0.9433 - val_mDice: 0.6193

Epoch 00026: val_mDice did not improve from 0.63078
Epoch 27/300
 - 19s - loss: 0.3395 - acc: 0.9406 - mDice: 0.6993 - val_loss: 0.4867 - val_acc: 0.9425 - val_mDice: 0.6099

Epoch 00027: val_mDice did not improve from 0.63078
Epoch 28/300
 - 19s - loss: 0.2997 - acc: 0.9441 - mDice: 0.7280 - val_loss: 0.6193 - val_acc: 0.9310 - val_mDice: 0.5460

Epoch 00028: val_mDice did not improve from 0.63078
Epoch 29/300
 - 19s - loss: 0.3533 - acc: 0.9396 - mDice: 0.6895 - val_loss: 0.4691 - val_acc: 0.9431 - val_mDice: 0.6154

Epoch 00029: val_mDice did not improve from 0.63078
Epoch 30/300
 - 19s - loss: 0.3021 - acc: 0.9441 - mDice: 0.7275 - val_loss: 0.8229 - val_acc: 0.9410 - val_mDice: 0.5705

Epoch 00030: val_mDice did not improve from 0.63078
Epoch 31/300
 - 19s - loss: 0.3186 - acc: 0.9427 - mDice: 0.7157 - val_loss: 0.4675 - val_acc: 0.9430 - val_mDice: 0.6163

Epoch 00031: val_mDice did not improve from 0.63078
Epoch 32/300
 - 19s - loss: 0.2957 - acc: 0.9453 - mDice: 0.7362 - val_loss: 0.4683 - val_acc: 0.9460 - val_mDice: 0.6176

Epoch 00032: val_mDice did not improve from 0.63078
Epoch 33/300
 - 19s - loss: 0.2980 - acc: 0.9438 - mDice: 0.7289 - val_loss: 0.4979 - val_acc: 0.9401 - val_mDice: 0.5997

Epoch 00033: val_mDice did not improve from 0.63078
Epoch 34/300
 - 21s - loss: 0.3540 - acc: 0.9403 - mDice: 0.6983 - val_loss: 0.4894 - val_acc: 0.9370 - val_mDice: 0.5998

Epoch 00034: val_mDice did not improve from 0.63078
Epoch 35/300
 - 22s - loss: 0.2895 - acc: 0.9451 - mDice: 0.7351 - val_loss: 0.4682 - val_acc: 0.9423 - val_mDice: 0.6151

Epoch 00035: val_mDice did not improve from 0.63078
Epoch 36/300
 - 22s - loss: 0.2815 - acc: 0.9460 - mDice: 0.7423 - val_loss: 0.4755 - val_acc: 0.9437 - val_mDice: 0.6120

Epoch 00036: val_mDice did not improve from 0.63078
Epoch 37/300
 - 22s - loss: 0.2881 - acc: 0.9455 - mDice: 0.7375 - val_loss: 0.5503 - val_acc: 0.9367 - val_mDice: 0.5723

Epoch 00037: val_mDice did not improve from 0.63078
Epoch 38/300
 - 22s - loss: 0.3147 - acc: 0.9424 - mDice: 0.7176 - val_loss: 0.4883 - val_acc: 0.9418 - val_mDice: 0.6053

Epoch 00038: val_mDice did not improve from 0.63078
Epoch 39/300
 - 21s - loss: 0.2793 - acc: 0.9462 - mDice: 0.7438 - val_loss: 0.4549 - val_acc: 0.9445 - val_mDice: 0.6269

Epoch 00039: val_mDice did not improve from 0.63078
Epoch 40/300
 - 21s - loss: 0.2823 - acc: 0.9458 - mDice: 0.7409 - val_loss: 0.4648 - val_acc: 0.9450 - val_mDice: 0.6180

Epoch 00040: val_mDice did not improve from 0.63078
Epoch 41/300
 - 21s - loss: 0.2677 - acc: 0.9472 - mDice: 0.7523 - val_loss: 0.4673 - val_acc: 0.9428 - val_mDice: 0.6158

Epoch 00041: val_mDice did not improve from 0.63078
Epoch 42/300
 - 20s - loss: 0.2656 - acc: 0.9475 - mDice: 0.7548 - val_loss: 0.5037 - val_acc: 0.9389 - val_mDice: 0.5954

Epoch 00042: val_mDice did not improve from 0.63078
Epoch 43/300
 - 20s - loss: 0.3215 - acc: 0.9426 - mDice: 0.7142 - val_loss: 0.4822 - val_acc: 0.9397 - val_mDice: 0.6066

Epoch 00043: val_mDice did not improve from 0.63078
Epoch 44/300
 - 20s - loss: 0.2888 - acc: 0.9456 - mDice: 0.7373 - val_loss: 0.5179 - val_acc: 0.9356 - val_mDice: 0.5879

Epoch 00044: val_mDice did not improve from 0.63078
Epoch 45/300
 - 20s - loss: 0.3006 - acc: 0.9447 - mDice: 0.7323 - val_loss: 0.4719 - val_acc: 0.9423 - val_mDice: 0.6149

Epoch 00045: val_mDice did not improve from 0.63078
Epoch 46/300
 - 19s - loss: 0.2663 - acc: 0.9473 - mDice: 0.7536 - val_loss: 0.6486 - val_acc: 0.9289 - val_mDice: 0.5354

Epoch 00046: val_mDice did not improve from 0.63078
Epoch 47/300
 - 19s - loss: 0.4104 - acc: 0.9340 - mDice: 0.6629 - val_loss: 0.4937 - val_acc: 0.9453 - val_mDice: 0.6088

Epoch 00047: val_mDice did not improve from 0.63078
Epoch 48/300
 - 19s - loss: 0.3314 - acc: 0.9411 - mDice: 0.7072 - val_loss: 0.4672 - val_acc: 0.9430 - val_mDice: 0.6165

Epoch 00048: val_mDice did not improve from 0.63078
Epoch 49/300
 - 19s - loss: 0.2928 - acc: 0.9451 - mDice: 0.7345 - val_loss: 0.4615 - val_acc: 0.9458 - val_mDice: 0.6206

Epoch 00049: val_mDice did not improve from 0.63078
Epoch 50/300
 - 19s - loss: 0.3016 - acc: 0.9447 - mDice: 0.7282 - val_loss: 0.4520 - val_acc: 0.9439 - val_mDice: 0.6267

Epoch 00050: val_mDice did not improve from 0.63078
Epoch 51/300
 - 20s - loss: 0.2750 - acc: 0.9466 - mDice: 0.7464 - val_loss: 0.4501 - val_acc: 0.9458 - val_mDice: 0.6278

Epoch 00051: val_mDice did not improve from 0.63078
Epoch 52/300
 - 21s - loss: 0.2673 - acc: 0.9475 - mDice: 0.7527 - val_loss: 0.4600 - val_acc: 0.9438 - val_mDice: 0.6201

Epoch 00052: val_mDice did not improve from 0.63078
Epoch 53/300
 - 21s - loss: 0.2677 - acc: 0.9477 - mDice: 0.7555 - val_loss: 0.9591 - val_acc: 0.9432 - val_mDice: 0.5857

Epoch 00053: val_mDice did not improve from 0.63078
Epoch 54/300
 - 21s - loss: 0.3440 - acc: 0.9404 - mDice: 0.6997 - val_loss: 0.5089 - val_acc: 0.9363 - val_mDice: 0.5934

Epoch 00054: val_mDice did not improve from 0.63078
Epoch 55/300
 - 22s - loss: 0.2946 - acc: 0.9447 - mDice: 0.7335 - val_loss: 0.5076 - val_acc: 0.9383 - val_mDice: 0.5959

Epoch 00055: val_mDice did not improve from 0.63078
Epoch 56/300
 - 22s - loss: 0.2864 - acc: 0.9457 - mDice: 0.7380 - val_loss: 0.4657 - val_acc: 0.9445 - val_mDice: 0.6181

Epoch 00056: val_mDice did not improve from 0.63078
Epoch 57/300
 - 21s - loss: 0.2657 - acc: 0.9477 - mDice: 0.7548 - val_loss: 0.4924 - val_acc: 0.9437 - val_mDice: 0.6028

Epoch 00057: val_mDice did not improve from 0.63078
Epoch 58/300
 - 22s - loss: 0.2769 - acc: 0.9467 - mDice: 0.7472 - val_loss: 0.4870 - val_acc: 0.9391 - val_mDice: 0.6063

Epoch 00058: val_mDice did not improve from 0.63078
Epoch 59/300
 - 22s - loss: 0.2581 - acc: 0.9482 - mDice: 0.7605 - val_loss: 0.4700 - val_acc: 0.9451 - val_mDice: 0.6168

Epoch 00059: val_mDice did not improve from 0.63078
Epoch 60/300
 - 21s - loss: 0.2561 - acc: 0.9485 - mDice: 0.7630 - val_loss: 0.5250 - val_acc: 0.9431 - val_mDice: 0.5856

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:10,  3.62s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:06,  3.23s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:08<00:02,  2.95s/it]predicting test subjects: 100%|██████████| 4/4 [00:11<00:00,  3.05s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:15,  3.23s/it]predicting train subjects:   1%|          | 2/266 [00:06<13:53,  3.16s/it]predicting train subjects:   1%|          | 3/266 [00:09<13:24,  3.06s/it]predicting train subjects:   2%|▏         | 4/266 [00:11<12:30,  2.86s/it]predicting train subjects:   2%|▏         | 5/266 [00:14<13:14,  3.04s/it]predicting train subjects:   2%|▏         | 6/266 [00:18<13:19,  3.07s/it]predicting train subjects:   3%|▎         | 7/266 [00:21<13:30,  3.13s/it]predicting train subjects:   3%|▎         | 8/266 [00:24<13:59,  3.25s/it]predicting train subjects:   3%|▎         | 9/266 [00:28<13:55,  3.25s/it]predicting train subjects:   4%|▍         | 10/266 [00:31<14:12,  3.33s/it]predicting train subjects:   4%|▍         | 11/266 [00:35<14:20,  3.37s/it]predicting train subjects:   5%|▍         | 12/266 [00:38<14:07,  3.34s/it]predicting train subjects:   5%|▍         | 13/266 [00:41<13:50,  3.28s/it]predicting train subjects:   5%|▌         | 14/266 [00:44<13:51,  3.30s/it]predicting train subjects:   6%|▌         | 15/266 [00:48<13:47,  3.30s/it]predicting train subjects:   6%|▌         | 16/266 [00:51<13:51,  3.33s/it]predicting train subjects:   6%|▋         | 17/266 [00:54<13:38,  3.29s/it]predicting train subjects:   7%|▋         | 18/266 [00:57<13:28,  3.26s/it]predicting train subjects:   7%|▋         | 19/266 [01:01<13:17,  3.23s/it]predicting train subjects:   8%|▊         | 20/266 [01:04<13:21,  3.26s/it]predicting train subjects:   8%|▊         | 21/266 [01:07<13:14,  3.24s/it]predicting train subjects:   8%|▊         | 22/266 [01:10<13:05,  3.22s/it]predicting train subjects:   9%|▊         | 23/266 [01:14<13:16,  3.28s/it]predicting train subjects:   9%|▉         | 24/266 [01:17<12:56,  3.21s/it]predicting train subjects:   9%|▉         | 25/266 [01:20<12:48,  3.19s/it]predicting train subjects:  10%|▉         | 26/266 [01:23<12:38,  3.16s/it]predicting train subjects:  10%|█         | 27/266 [01:26<12:30,  3.14s/it]predicting train subjects:  11%|█         | 28/266 [01:29<12:18,  3.10s/it]predicting train subjects:  11%|█         | 29/266 [01:32<11:52,  3.01s/it]predicting train subjects:  11%|█▏        | 30/266 [01:35<11:51,  3.01s/it]predicting train subjects:  12%|█▏        | 31/266 [01:38<12:01,  3.07s/it]predicting train subjects:  12%|█▏        | 32/266 [01:41<12:01,  3.08s/it]predicting train subjects:  12%|█▏        | 33/266 [01:44<11:47,  3.03s/it]predicting train subjects:  13%|█▎        | 34/266 [01:47<12:00,  3.11s/it]predicting train subjects:  13%|█▎        | 35/266 [01:50<11:53,  3.09s/it]predicting train subjects:  14%|█▎        | 36/266 [01:53<11:37,  3.03s/it]predicting train subjects:  14%|█▍        | 37/266 [01:56<11:29,  3.01s/it]predicting train subjects:  14%|█▍        | 38/266 [02:00<11:38,  3.07s/it]predicting train subjects:  15%|█▍        | 39/266 [02:02<11:23,  3.01s/it]predicting train subjects:  15%|█▌        | 40/266 [02:05<11:22,  3.02s/it]predicting train subjects:  15%|█▌        | 41/266 [02:09<11:30,  3.07s/it]predicting train subjects:  16%|█▌        | 42/266 [02:11<11:00,  2.95s/it]predicting train subjects:  16%|█▌        | 43/266 [02:14<10:35,  2.85s/it]predicting train subjects:  17%|█▋        | 44/266 [02:17<10:19,  2.79s/it]predicting train subjects:  17%|█▋        | 45/266 [02:19<10:10,  2.76s/it]predicting train subjects:  17%|█▋        | 46/266 [02:22<09:55,  2.71s/it]predicting train subjects:  18%|█▊        | 47/266 [02:24<09:46,  2.68s/it]predicting train subjects:  18%|█▊        | 48/266 [02:27<09:30,  2.62s/it]predicting train subjects:  18%|█▊        | 49/266 [02:29<09:20,  2.58s/it]predicting train subjects:  19%|█▉        | 50/266 [02:32<09:20,  2.59s/it]predicting train subjects:  19%|█▉        | 51/266 [02:35<09:17,  2.59s/it]predicting train subjects:  20%|█▉        | 52/266 [02:37<09:22,  2.63s/it]predicting train subjects:  20%|█▉        | 53/266 [02:40<09:16,  2.61s/it]predicting train subjects:  20%|██        | 54/266 [02:43<09:21,  2.65s/it]predicting train subjects:  21%|██        | 55/266 [02:45<09:17,  2.64s/it]predicting train subjects:  21%|██        | 56/266 [02:48<09:03,  2.59s/it]predicting train subjects:  21%|██▏       | 57/266 [02:50<08:54,  2.56s/it]predicting train subjects:  22%|██▏       | 58/266 [02:53<09:04,  2.62s/it]predicting train subjects:  22%|██▏       | 59/266 [02:56<08:55,  2.59s/it]predicting train subjects:  23%|██▎       | 60/266 [02:58<08:29,  2.47s/it]predicting train subjects:  23%|██▎       | 61/266 [03:00<08:19,  2.43s/it]predicting train subjects:  23%|██▎       | 62/266 [03:03<08:17,  2.44s/it]predicting train subjects:  24%|██▎       | 63/266 [03:05<07:56,  2.35s/it]predicting train subjects:  24%|██▍       | 64/266 [03:07<08:13,  2.44s/it]predicting train subjects:  24%|██▍       | 65/266 [03:10<08:13,  2.45s/it]predicting train subjects:  25%|██▍       | 66/266 [03:12<08:07,  2.44s/it]predicting train subjects:  25%|██▌       | 67/266 [03:15<08:12,  2.48s/it]predicting train subjects:  26%|██▌       | 68/266 [03:17<07:57,  2.41s/it]predicting train subjects:  26%|██▌       | 69/266 [03:20<08:01,  2.44s/it]predicting train subjects:  26%|██▋       | 70/266 [03:22<07:46,  2.38s/it]predicting train subjects:  27%|██▋       | 71/266 [03:24<07:30,  2.31s/it]predicting train subjects:  27%|██▋       | 72/266 [03:26<07:22,  2.28s/it]predicting train subjects:  27%|██▋       | 73/266 [03:29<07:27,  2.32s/it]predicting train subjects:  28%|██▊       | 74/266 [03:31<07:32,  2.36s/it]predicting train subjects:  28%|██▊       | 75/266 [03:33<07:17,  2.29s/it]predicting train subjects:  29%|██▊       | 76/266 [03:35<07:17,  2.30s/it]predicting train subjects:  29%|██▉       | 77/266 [03:38<07:56,  2.52s/it]predicting train subjects:  29%|██▉       | 78/266 [03:42<08:31,  2.72s/it]predicting train subjects:  30%|██▉       | 79/266 [03:45<09:23,  3.01s/it]predicting train subjects:  30%|███       | 80/266 [03:49<10:03,  3.25s/it]predicting train subjects:  30%|███       | 81/266 [03:53<10:10,  3.30s/it]predicting train subjects:  31%|███       | 82/266 [03:56<10:15,  3.35s/it]predicting train subjects:  31%|███       | 83/266 [03:59<10:11,  3.34s/it]predicting train subjects:  32%|███▏      | 84/266 [04:02<09:21,  3.09s/it]predicting train subjects:  32%|███▏      | 85/266 [04:04<08:45,  2.90s/it]predicting train subjects:  32%|███▏      | 86/266 [04:07<08:21,  2.79s/it]predicting train subjects:  33%|███▎      | 87/266 [04:09<08:06,  2.72s/it]predicting train subjects:  33%|███▎      | 88/266 [04:12<07:55,  2.67s/it]predicting train subjects:  33%|███▎      | 89/266 [04:15<07:47,  2.64s/it]predicting train subjects:  34%|███▍      | 90/266 [04:17<07:52,  2.69s/it]predicting train subjects:  34%|███▍      | 91/266 [04:20<07:46,  2.67s/it]predicting train subjects:  35%|███▍      | 92/266 [04:23<07:40,  2.64s/it]predicting train subjects:  35%|███▍      | 93/266 [04:25<07:30,  2.61s/it]predicting train subjects:  35%|███▌      | 94/266 [04:28<07:22,  2.57s/it]predicting train subjects:  36%|███▌      | 95/266 [04:30<07:18,  2.57s/it]predicting train subjects:  36%|███▌      | 96/266 [04:32<07:01,  2.48s/it]predicting train subjects:  36%|███▋      | 97/266 [04:35<06:58,  2.48s/it]predicting train subjects:  37%|███▋      | 98/266 [04:37<07:01,  2.51s/it]predicting train subjects:  37%|███▋      | 99/266 [04:39<06:25,  2.31s/it]predicting train subjects:  38%|███▊      | 100/266 [04:41<06:08,  2.22s/it]predicting train subjects:  38%|███▊      | 101/266 [04:43<06:02,  2.19s/it]predicting train subjects:  38%|███▊      | 102/266 [04:46<05:57,  2.18s/it]predicting train subjects:  39%|███▊      | 103/266 [04:48<05:55,  2.18s/it]predicting train subjects:  39%|███▉      | 104/266 [04:50<05:52,  2.17s/it]predicting train subjects:  39%|███▉      | 105/266 [04:52<05:57,  2.22s/it]predicting train subjects:  40%|███▉      | 106/266 [04:55<05:58,  2.24s/it]predicting train subjects:  40%|████      | 107/266 [04:57<05:56,  2.24s/it]predicting train subjects:  41%|████      | 108/266 [04:59<05:49,  2.21s/it]predicting train subjects:  41%|████      | 109/266 [05:01<05:44,  2.20s/it]predicting train subjects:  41%|████▏     | 110/266 [05:03<05:41,  2.19s/it]predicting train subjects:  42%|████▏     | 111/266 [05:05<05:41,  2.20s/it]predicting train subjects:  42%|████▏     | 112/266 [05:08<05:34,  2.18s/it]predicting train subjects:  42%|████▏     | 113/266 [05:10<05:32,  2.18s/it]predicting train subjects:  43%|████▎     | 114/266 [05:12<05:27,  2.15s/it]predicting train subjects:  43%|████▎     | 115/266 [05:14<05:25,  2.16s/it]predicting train subjects:  44%|████▎     | 116/266 [05:16<05:28,  2.19s/it]predicting train subjects:  44%|████▍     | 117/266 [05:19<05:29,  2.21s/it]predicting train subjects:  44%|████▍     | 118/266 [05:21<05:25,  2.20s/it]predicting train subjects:  45%|████▍     | 119/266 [05:23<05:43,  2.34s/it]predicting train subjects:  45%|████▌     | 120/266 [05:26<05:54,  2.42s/it]predicting train subjects:  45%|████▌     | 121/266 [05:29<05:55,  2.45s/it]predicting train subjects:  46%|████▌     | 122/266 [05:31<05:56,  2.48s/it]predicting train subjects:  46%|████▌     | 123/266 [05:34<05:56,  2.49s/it]predicting train subjects:  47%|████▋     | 124/266 [05:36<05:55,  2.50s/it]predicting train subjects:  47%|████▋     | 125/266 [05:39<05:58,  2.54s/it]predicting train subjects:  47%|████▋     | 126/266 [05:41<06:02,  2.59s/it]predicting train subjects:  48%|████▊     | 127/266 [05:44<05:57,  2.57s/it]predicting train subjects:  48%|████▊     | 128/266 [05:47<05:54,  2.57s/it]predicting train subjects:  48%|████▊     | 129/266 [05:49<05:54,  2.59s/it]predicting train subjects:  49%|████▉     | 130/266 [05:52<05:50,  2.58s/it]predicting train subjects:  49%|████▉     | 131/266 [05:54<05:45,  2.56s/it]predicting train subjects:  50%|████▉     | 132/266 [05:57<05:45,  2.58s/it]predicting train subjects:  50%|█████     | 133/266 [05:59<05:44,  2.59s/it]predicting train subjects:  50%|█████     | 134/266 [06:02<05:39,  2.57s/it]predicting train subjects:  51%|█████     | 135/266 [06:05<05:37,  2.57s/it]predicting train subjects:  51%|█████     | 136/266 [06:07<05:37,  2.60s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:10<05:35,  2.60s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:12<05:33,  2.61s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:15<05:33,  2.63s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:18<05:26,  2.59s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:20<05:28,  2.63s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:23<05:20,  2.58s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:25<05:15,  2.56s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:28<05:08,  2.53s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:30<05:07,  2.54s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:33<05:08,  2.57s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:36<05:04,  2.56s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:38<05:02,  2.57s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:41<04:54,  2.52s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:43<04:55,  2.54s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:46<04:55,  2.57s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:48<04:49,  2.54s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:51<04:46,  2.54s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:53<04:44,  2.54s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:55<04:18,  2.33s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:57<04:00,  2.19s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:59<03:45,  2.07s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:01<03:34,  1.99s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:02<03:27,  1.94s/it]predicting train subjects:  60%|██████    | 160/266 [07:04<03:22,  1.91s/it]predicting train subjects:  61%|██████    | 161/266 [07:06<03:17,  1.88s/it]predicting train subjects:  61%|██████    | 162/266 [07:08<03:12,  1.85s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:10<03:08,  1.83s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:11<03:05,  1.82s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:13<03:03,  1.82s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:15<03:03,  1.84s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:17<02:59,  1.82s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:19<03:02,  1.87s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:21<03:00,  1.86s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:23<02:57,  1.85s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:24<02:55,  1.85s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:26<02:55,  1.87s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:29<03:02,  1.96s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:31<03:04,  2.00s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:33<03:03,  2.02s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:35<03:03,  2.04s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:37<03:01,  2.04s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:39<03:00,  2.05s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:41<02:56,  2.03s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:43<02:54,  2.03s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:45<02:54,  2.06s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:47<02:54,  2.08s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:49<02:52,  2.08s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:51<02:50,  2.07s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:53<02:46,  2.05s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:55<02:43,  2.04s/it]predicting train subjects:  70%|███████   | 187/266 [07:57<02:40,  2.03s/it]predicting train subjects:  71%|███████   | 188/266 [07:59<02:39,  2.05s/it]predicting train subjects:  71%|███████   | 189/266 [08:01<02:37,  2.04s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:03<02:35,  2.05s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:06<02:38,  2.11s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:08<02:35,  2.10s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:10<02:31,  2.08s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:13<02:45,  2.30s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:15<02:46,  2.34s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:17<02:40,  2.30s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:20<02:41,  2.34s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:22<02:38,  2.34s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:24<02:34,  2.31s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:27<02:30,  2.28s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:29<02:27,  2.27s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:31<02:27,  2.30s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:33<02:23,  2.27s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:36<02:19,  2.25s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:38<02:16,  2.24s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:40<02:19,  2.32s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:43<02:16,  2.32s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:45<02:11,  2.27s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:47<02:08,  2.25s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:49<02:10,  2.32s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:52<02:07,  2.32s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:54<02:02,  2.27s/it]predicting train subjects:  80%|████████  | 213/266 [08:56<01:55,  2.17s/it]predicting train subjects:  80%|████████  | 214/266 [08:58<01:50,  2.13s/it]predicting train subjects:  81%|████████  | 215/266 [09:00<01:45,  2.07s/it]predicting train subjects:  81%|████████  | 216/266 [09:02<01:43,  2.07s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:04<01:40,  2.05s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:06<01:39,  2.08s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:08<01:35,  2.04s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:10<01:32,  2.00s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:12<01:32,  2.05s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:14<01:28,  2.02s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:16<01:26,  2.00s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:18<01:24,  2.01s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:20<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:22<01:19,  1.99s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:24<01:16,  1.97s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:26<01:16,  2.02s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:28<01:13,  2.00s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:30<01:11,  1.98s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:32<01:10,  2.03s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:34<01:10,  2.06s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:36<01:06,  2.02s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:38<01:03,  1.99s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:40<01:01,  1.98s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:42<00:59,  1.98s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:44<00:56,  1.96s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:46<00:54,  1.96s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:48<00:53,  1.97s/it]predicting train subjects:  90%|█████████ | 240/266 [09:50<00:51,  1.97s/it]predicting train subjects:  91%|█████████ | 241/266 [09:52<00:49,  1.97s/it]predicting train subjects:  91%|█████████ | 242/266 [09:54<00:48,  2.00s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:56<00:46,  2.03s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:58<00:44,  2.04s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:00<00:42,  2.00s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:02<00:39,  2.00s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:04<00:38,  2.01s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:06<00:35,  1.98s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:09<00:37,  2.22s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:11<00:36,  2.29s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:14<00:35,  2.39s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:16<00:34,  2.47s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:19<00:32,  2.48s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:21<00:29,  2.49s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:24<00:28,  2.55s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:27<00:25,  2.52s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:29<00:22,  2.53s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:32<00:20,  2.52s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:34<00:17,  2.52s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:37<00:15,  2.51s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:39<00:12,  2.50s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:41<00:09,  2.48s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:44<00:07,  2.48s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:46<00:04,  2.48s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:49<00:02,  2.46s/it]predicting train subjects: 100%|██████████| 266/266 [10:51<00:00,  2.46s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:45,  1.60it/s]Loading train:   1%|          | 2/266 [00:01<02:31,  1.74it/s]Loading train:   1%|          | 3/266 [00:01<02:16,  1.93it/s]Loading train:   2%|▏         | 4/266 [00:01<02:05,  2.08it/s]Loading train:   2%|▏         | 5/266 [00:02<02:06,  2.07it/s]Loading train:   2%|▏         | 6/266 [00:02<02:05,  2.07it/s]Loading train:   3%|▎         | 7/266 [00:03<01:58,  2.18it/s]Loading train:   3%|▎         | 8/266 [00:03<01:51,  2.32it/s]Loading train:   3%|▎         | 9/266 [00:03<01:45,  2.44it/s]Loading train:   4%|▍         | 10/266 [00:04<01:53,  2.25it/s]Loading train:   4%|▍         | 11/266 [00:04<01:51,  2.29it/s]Loading train:   5%|▍         | 12/266 [00:05<01:48,  2.34it/s]Loading train:   5%|▍         | 13/266 [00:05<01:42,  2.46it/s]Loading train:   5%|▌         | 14/266 [00:06<01:37,  2.58it/s]Loading train:   6%|▌         | 15/266 [00:06<01:43,  2.43it/s]Loading train:   6%|▌         | 16/266 [00:06<01:49,  2.29it/s]Loading train:   6%|▋         | 17/266 [00:07<01:54,  2.17it/s]Loading train:   7%|▋         | 18/266 [00:07<01:48,  2.29it/s]Loading train:   7%|▋         | 19/266 [00:08<01:42,  2.40it/s]Loading train:   8%|▊         | 20/266 [00:08<01:36,  2.54it/s]Loading train:   8%|▊         | 21/266 [00:08<01:34,  2.60it/s]Loading train:   8%|▊         | 22/266 [00:09<01:35,  2.56it/s]Loading train:   9%|▊         | 23/266 [00:09<01:39,  2.43it/s]Loading train:   9%|▉         | 24/266 [00:10<01:42,  2.36it/s]Loading train:   9%|▉         | 25/266 [00:10<01:39,  2.42it/s]Loading train:  10%|▉         | 26/266 [00:10<01:33,  2.58it/s]Loading train:  10%|█         | 27/266 [00:11<01:28,  2.70it/s]Loading train:  11%|█         | 28/266 [00:11<01:26,  2.74it/s]Loading train:  11%|█         | 29/266 [00:12<01:30,  2.62it/s]Loading train:  11%|█▏        | 30/266 [00:12<01:38,  2.40it/s]Loading train:  12%|█▏        | 31/266 [00:13<01:40,  2.34it/s]Loading train:  12%|█▏        | 32/266 [00:13<01:39,  2.35it/s]Loading train:  12%|█▏        | 33/266 [00:13<01:34,  2.46it/s]Loading train:  13%|█▎        | 34/266 [00:14<01:36,  2.40it/s]Loading train:  13%|█▎        | 35/266 [00:14<01:35,  2.41it/s]Loading train:  14%|█▎        | 36/266 [00:15<01:34,  2.44it/s]Loading train:  14%|█▍        | 37/266 [00:15<01:35,  2.39it/s]Loading train:  14%|█▍        | 38/266 [00:15<01:36,  2.35it/s]Loading train:  15%|█▍        | 39/266 [00:16<01:38,  2.29it/s]Loading train:  15%|█▌        | 40/266 [00:16<01:41,  2.22it/s]Loading train:  15%|█▌        | 41/266 [00:17<01:41,  2.21it/s]Loading train:  16%|█▌        | 42/266 [00:17<01:38,  2.27it/s]Loading train:  16%|█▌        | 43/266 [00:18<01:36,  2.31it/s]Loading train:  17%|█▋        | 44/266 [00:18<01:30,  2.45it/s]Loading train:  17%|█▋        | 45/266 [00:18<01:25,  2.59it/s]Loading train:  17%|█▋        | 46/266 [00:19<01:21,  2.71it/s]Loading train:  18%|█▊        | 47/266 [00:19<01:18,  2.80it/s]Loading train:  18%|█▊        | 48/266 [00:19<01:20,  2.70it/s]Loading train:  18%|█▊        | 49/266 [00:20<01:21,  2.67it/s]Loading train:  19%|█▉        | 50/266 [00:20<01:15,  2.86it/s]Loading train:  19%|█▉        | 51/266 [00:20<01:16,  2.80it/s]Loading train:  20%|█▉        | 52/266 [00:21<01:15,  2.84it/s]Loading train:  20%|█▉        | 53/266 [00:21<01:16,  2.77it/s]Loading train:  20%|██        | 54/266 [00:22<01:20,  2.63it/s]Loading train:  21%|██        | 55/266 [00:22<01:19,  2.66it/s]Loading train:  21%|██        | 56/266 [00:22<01:15,  2.79it/s]Loading train:  21%|██▏       | 57/266 [00:23<01:15,  2.76it/s]Loading train:  22%|██▏       | 58/266 [00:23<01:15,  2.74it/s]Loading train:  22%|██▏       | 59/266 [00:23<01:18,  2.64it/s]Loading train:  23%|██▎       | 60/266 [00:24<01:19,  2.59it/s]Loading train:  23%|██▎       | 61/266 [00:24<01:28,  2.32it/s]Loading train:  23%|██▎       | 62/266 [00:25<01:31,  2.24it/s]Loading train:  24%|██▎       | 63/266 [00:25<01:29,  2.27it/s]Loading train:  24%|██▍       | 64/266 [00:26<01:22,  2.43it/s]Loading train:  24%|██▍       | 65/266 [00:26<01:22,  2.45it/s]Loading train:  25%|██▍       | 66/266 [00:26<01:18,  2.54it/s]Loading train:  25%|██▌       | 67/266 [00:27<01:16,  2.59it/s]Loading train:  26%|██▌       | 68/266 [00:27<01:19,  2.50it/s]Loading train:  26%|██▌       | 69/266 [00:28<01:19,  2.47it/s]Loading train:  26%|██▋       | 70/266 [00:28<01:23,  2.36it/s]Loading train:  27%|██▋       | 71/266 [00:29<01:27,  2.23it/s]Loading train:  27%|██▋       | 72/266 [00:29<01:26,  2.24it/s]Loading train:  27%|██▋       | 73/266 [00:30<01:27,  2.19it/s]Loading train:  28%|██▊       | 74/266 [00:30<01:22,  2.34it/s]Loading train:  28%|██▊       | 75/266 [00:30<01:27,  2.19it/s]Loading train:  29%|██▊       | 76/266 [00:31<01:26,  2.20it/s]Loading train:  29%|██▉       | 77/266 [00:31<01:27,  2.17it/s]Loading train:  29%|██▉       | 78/266 [00:32<01:22,  2.28it/s]Loading train:  30%|██▉       | 79/266 [00:32<01:26,  2.17it/s]Loading train:  30%|███       | 80/266 [00:33<01:26,  2.15it/s]Loading train:  30%|███       | 81/266 [00:33<01:30,  2.03it/s]Loading train:  31%|███       | 82/266 [00:34<01:33,  1.96it/s]Loading train:  31%|███       | 83/266 [00:34<01:34,  1.93it/s]Loading train:  32%|███▏      | 84/266 [00:35<01:32,  1.96it/s]Loading train:  32%|███▏      | 85/266 [00:35<01:29,  2.02it/s]Loading train:  32%|███▏      | 86/266 [00:36<01:29,  2.00it/s]Loading train:  33%|███▎      | 87/266 [00:36<01:27,  2.05it/s]Loading train:  33%|███▎      | 88/266 [00:37<01:24,  2.11it/s]Loading train:  33%|███▎      | 89/266 [00:37<01:26,  2.05it/s]Loading train:  34%|███▍      | 90/266 [00:38<01:22,  2.13it/s]Loading train:  34%|███▍      | 91/266 [00:38<01:25,  2.04it/s]Loading train:  35%|███▍      | 92/266 [00:39<01:27,  1.99it/s]Loading train:  35%|███▍      | 93/266 [00:39<01:23,  2.08it/s]Loading train:  35%|███▌      | 94/266 [00:40<01:21,  2.11it/s]Loading train:  36%|███▌      | 95/266 [00:40<01:22,  2.06it/s]Loading train:  36%|███▌      | 96/266 [00:41<01:24,  2.02it/s]Loading train:  36%|███▋      | 97/266 [00:41<01:25,  1.98it/s]Loading train:  37%|███▋      | 98/266 [00:42<01:21,  2.07it/s]Loading train:  37%|███▋      | 99/266 [00:42<01:10,  2.36it/s]Loading train:  38%|███▊      | 100/266 [00:42<01:05,  2.54it/s]Loading train:  38%|███▊      | 101/266 [00:43<01:00,  2.74it/s]Loading train:  38%|███▊      | 102/266 [00:43<00:56,  2.88it/s]Loading train:  39%|███▊      | 103/266 [00:43<00:55,  2.92it/s]Loading train:  39%|███▉      | 104/266 [00:43<00:54,  2.96it/s]Loading train:  39%|███▉      | 105/266 [00:44<00:58,  2.73it/s]Loading train:  40%|███▉      | 106/266 [00:44<00:57,  2.78it/s]Loading train:  40%|████      | 107/266 [00:45<00:59,  2.68it/s]Loading train:  41%|████      | 108/266 [00:45<00:58,  2.68it/s]Loading train:  41%|████      | 109/266 [00:46<01:03,  2.47it/s]Loading train:  41%|████▏     | 110/266 [00:46<01:02,  2.50it/s]Loading train:  42%|████▏     | 111/266 [00:46<01:01,  2.50it/s]Loading train:  42%|████▏     | 112/266 [00:47<00:59,  2.57it/s]Loading train:  42%|████▏     | 113/266 [00:47<00:58,  2.62it/s]Loading train:  43%|████▎     | 114/266 [00:47<00:58,  2.61it/s]Loading train:  43%|████▎     | 115/266 [00:48<00:56,  2.65it/s]Loading train:  44%|████▎     | 116/266 [00:48<00:59,  2.53it/s]Loading train:  44%|████▍     | 117/266 [00:49<00:57,  2.61it/s]Loading train:  44%|████▍     | 118/266 [00:49<00:56,  2.63it/s]Loading train:  45%|████▍     | 119/266 [00:49<00:57,  2.54it/s]Loading train:  45%|████▌     | 120/266 [00:50<00:59,  2.46it/s]Loading train:  45%|████▌     | 121/266 [00:50<01:00,  2.40it/s]Loading train:  46%|████▌     | 122/266 [00:51<00:59,  2.41it/s]Loading train:  46%|████▌     | 123/266 [00:51<00:59,  2.41it/s]Loading train:  47%|████▋     | 124/266 [00:52<01:00,  2.35it/s]Loading train:  47%|████▋     | 125/266 [00:52<01:01,  2.29it/s]Loading train:  47%|████▋     | 126/266 [00:52<00:59,  2.34it/s]Loading train:  48%|████▊     | 127/266 [00:53<00:59,  2.35it/s]Loading train:  48%|████▊     | 128/266 [00:53<01:00,  2.29it/s]Loading train:  48%|████▊     | 129/266 [00:54<01:01,  2.21it/s]Loading train:  49%|████▉     | 130/266 [00:54<01:01,  2.23it/s]Loading train:  49%|████▉     | 131/266 [00:55<00:59,  2.27it/s]Loading train:  50%|████▉     | 132/266 [00:55<01:00,  2.22it/s]Loading train:  50%|█████     | 133/266 [00:56<00:58,  2.27it/s]Loading train:  50%|█████     | 134/266 [00:56<01:00,  2.19it/s]Loading train:  51%|█████     | 135/266 [00:56<00:58,  2.24it/s]Loading train:  51%|█████     | 136/266 [00:57<00:58,  2.23it/s]Loading train:  52%|█████▏    | 137/266 [00:57<00:56,  2.28it/s]Loading train:  52%|█████▏    | 138/266 [00:58<00:53,  2.39it/s]Loading train:  52%|█████▏    | 139/266 [00:58<00:54,  2.34it/s]Loading train:  53%|█████▎    | 140/266 [00:58<00:51,  2.44it/s]Loading train:  53%|█████▎    | 141/266 [00:59<00:54,  2.28it/s]Loading train:  53%|█████▎    | 142/266 [00:59<00:55,  2.22it/s]Loading train:  54%|█████▍    | 143/266 [01:00<00:52,  2.35it/s]Loading train:  54%|█████▍    | 144/266 [01:00<00:49,  2.44it/s]Loading train:  55%|█████▍    | 145/266 [01:01<00:51,  2.37it/s]Loading train:  55%|█████▍    | 146/266 [01:01<00:49,  2.41it/s]Loading train:  55%|█████▌    | 147/266 [01:01<00:48,  2.47it/s]Loading train:  56%|█████▌    | 148/266 [01:02<00:45,  2.58it/s]Loading train:  56%|█████▌    | 149/266 [01:02<00:42,  2.75it/s]Loading train:  56%|█████▋    | 150/266 [01:02<00:40,  2.88it/s]Loading train:  57%|█████▋    | 151/266 [01:03<00:39,  2.90it/s]Loading train:  57%|█████▋    | 152/266 [01:03<00:38,  2.98it/s]Loading train:  58%|█████▊    | 153/266 [01:03<00:37,  3.00it/s]Loading train:  58%|█████▊    | 154/266 [01:04<00:37,  2.96it/s]Loading train:  58%|█████▊    | 155/266 [01:04<00:35,  3.14it/s]Loading train:  59%|█████▊    | 156/266 [01:04<00:32,  3.34it/s]Loading train:  59%|█████▉    | 157/266 [01:05<00:33,  3.30it/s]Loading train:  59%|█████▉    | 158/266 [01:05<00:33,  3.21it/s]Loading train:  60%|█████▉    | 159/266 [01:05<00:31,  3.39it/s]Loading train:  60%|██████    | 160/266 [01:05<00:29,  3.54it/s]Loading train:  61%|██████    | 161/266 [01:06<00:28,  3.65it/s]Loading train:  61%|██████    | 162/266 [01:06<00:29,  3.49it/s]Loading train:  61%|██████▏   | 163/266 [01:06<00:30,  3.39it/s]Loading train:  62%|██████▏   | 164/266 [01:07<00:29,  3.40it/s]Loading train:  62%|██████▏   | 165/266 [01:07<00:28,  3.56it/s]Loading train:  62%|██████▏   | 166/266 [01:07<00:27,  3.65it/s]Loading train:  63%|██████▎   | 167/266 [01:07<00:27,  3.67it/s]Loading train:  63%|██████▎   | 168/266 [01:08<00:28,  3.47it/s]Loading train:  64%|██████▎   | 169/266 [01:08<00:29,  3.29it/s]Loading train:  64%|██████▍   | 170/266 [01:08<00:30,  3.19it/s]Loading train:  64%|██████▍   | 171/266 [01:09<00:30,  3.09it/s]Loading train:  65%|██████▍   | 172/266 [01:09<00:29,  3.19it/s]Loading train:  65%|██████▌   | 173/266 [01:09<00:29,  3.19it/s]Loading train:  65%|██████▌   | 174/266 [01:10<00:28,  3.22it/s]Loading train:  66%|██████▌   | 175/266 [01:10<00:28,  3.24it/s]Loading train:  66%|██████▌   | 176/266 [01:10<00:29,  3.08it/s]Loading train:  67%|██████▋   | 177/266 [01:11<00:29,  3.01it/s]Loading train:  67%|██████▋   | 178/266 [01:11<00:28,  3.11it/s]Loading train:  67%|██████▋   | 179/266 [01:11<00:27,  3.18it/s]Loading train:  68%|██████▊   | 180/266 [01:12<00:26,  3.23it/s]Loading train:  68%|██████▊   | 181/266 [01:12<00:27,  3.07it/s]Loading train:  68%|██████▊   | 182/266 [01:12<00:27,  3.02it/s]Loading train:  69%|██████▉   | 183/266 [01:13<00:26,  3.10it/s]Loading train:  69%|██████▉   | 184/266 [01:13<00:26,  3.12it/s]Loading train:  70%|██████▉   | 185/266 [01:13<00:25,  3.18it/s]Loading train:  70%|██████▉   | 186/266 [01:13<00:24,  3.23it/s]Loading train:  70%|███████   | 187/266 [01:14<00:24,  3.27it/s]Loading train:  71%|███████   | 188/266 [01:14<00:23,  3.29it/s]Loading train:  71%|███████   | 189/266 [01:14<00:24,  3.16it/s]Loading train:  71%|███████▏  | 190/266 [01:15<00:24,  3.04it/s]Loading train:  72%|███████▏  | 191/266 [01:15<00:27,  2.72it/s]Loading train:  72%|███████▏  | 192/266 [01:16<00:29,  2.53it/s]Loading train:  73%|███████▎  | 193/266 [01:16<00:28,  2.57it/s]Loading train:  73%|███████▎  | 194/266 [01:16<00:28,  2.49it/s]Loading train:  73%|███████▎  | 195/266 [01:17<00:27,  2.59it/s]Loading train:  74%|███████▎  | 196/266 [01:17<00:27,  2.54it/s]Loading train:  74%|███████▍  | 197/266 [01:18<00:27,  2.54it/s]Loading train:  74%|███████▍  | 198/266 [01:18<00:27,  2.46it/s]Loading train:  75%|███████▍  | 199/266 [01:18<00:26,  2.52it/s]Loading train:  75%|███████▌  | 200/266 [01:19<00:24,  2.72it/s]Loading train:  76%|███████▌  | 201/266 [01:19<00:24,  2.70it/s]Loading train:  76%|███████▌  | 202/266 [01:19<00:23,  2.73it/s]Loading train:  76%|███████▋  | 203/266 [01:20<00:23,  2.64it/s]Loading train:  77%|███████▋  | 204/266 [01:20<00:24,  2.58it/s]Loading train:  77%|███████▋  | 205/266 [01:21<00:22,  2.66it/s]Loading train:  77%|███████▋  | 206/266 [01:21<00:22,  2.67it/s]Loading train:  78%|███████▊  | 207/266 [01:21<00:22,  2.64it/s]Loading train:  78%|███████▊  | 208/266 [01:22<00:22,  2.58it/s]Loading train:  79%|███████▊  | 209/266 [01:22<00:21,  2.68it/s]Loading train:  79%|███████▉  | 210/266 [01:22<00:19,  2.87it/s]Loading train:  79%|███████▉  | 211/266 [01:23<00:18,  3.02it/s]Loading train:  80%|███████▉  | 212/266 [01:23<00:17,  3.13it/s]Loading train:  80%|████████  | 213/266 [01:23<00:16,  3.15it/s]Loading train:  80%|████████  | 214/266 [01:24<00:16,  3.17it/s]Loading train:  81%|████████  | 215/266 [01:24<00:15,  3.29it/s]Loading train:  81%|████████  | 216/266 [01:24<00:14,  3.39it/s]Loading train:  82%|████████▏ | 217/266 [01:24<00:14,  3.41it/s]Loading train:  82%|████████▏ | 218/266 [01:25<00:14,  3.28it/s]Loading train:  82%|████████▏ | 219/266 [01:25<00:14,  3.24it/s]Loading train:  83%|████████▎ | 220/266 [01:25<00:13,  3.32it/s]Loading train:  83%|████████▎ | 221/266 [01:26<00:13,  3.23it/s]Loading train:  83%|████████▎ | 222/266 [01:26<00:13,  3.34it/s]Loading train:  84%|████████▍ | 223/266 [01:26<00:12,  3.43it/s]Loading train:  84%|████████▍ | 224/266 [01:27<00:12,  3.33it/s]Loading train:  85%|████████▍ | 225/266 [01:27<00:12,  3.35it/s]Loading train:  85%|████████▍ | 226/266 [01:27<00:11,  3.36it/s]Loading train:  85%|████████▌ | 227/266 [01:28<00:11,  3.29it/s]Loading train:  86%|████████▌ | 228/266 [01:28<00:11,  3.34it/s]Loading train:  86%|████████▌ | 229/266 [01:28<00:11,  3.23it/s]Loading train:  86%|████████▋ | 230/266 [01:28<00:11,  3.14it/s]Loading train:  87%|████████▋ | 231/266 [01:29<00:11,  3.04it/s]Loading train:  87%|████████▋ | 232/266 [01:29<00:12,  2.83it/s]Loading train:  88%|████████▊ | 233/266 [01:30<00:11,  2.82it/s]Loading train:  88%|████████▊ | 234/266 [01:30<00:11,  2.80it/s]Loading train:  88%|████████▊ | 235/266 [01:30<00:11,  2.71it/s]Loading train:  89%|████████▊ | 236/266 [01:31<00:10,  2.74it/s]Loading train:  89%|████████▉ | 237/266 [01:31<00:10,  2.70it/s]Loading train:  89%|████████▉ | 238/266 [01:31<00:10,  2.73it/s]Loading train:  90%|████████▉ | 239/266 [01:32<00:09,  2.91it/s]Loading train:  90%|█████████ | 240/266 [01:32<00:08,  2.91it/s]Loading train:  91%|█████████ | 241/266 [01:32<00:08,  2.89it/s]Loading train:  91%|█████████ | 242/266 [01:33<00:08,  2.80it/s]Loading train:  91%|█████████▏| 243/266 [01:33<00:08,  2.81it/s]Loading train:  92%|█████████▏| 244/266 [01:34<00:08,  2.72it/s]Loading train:  92%|█████████▏| 245/266 [01:34<00:07,  2.76it/s]Loading train:  92%|█████████▏| 246/266 [01:34<00:07,  2.82it/s]Loading train:  93%|█████████▎| 247/266 [01:35<00:06,  2.75it/s]Loading train:  93%|█████████▎| 248/266 [01:35<00:06,  2.76it/s]Loading train:  94%|█████████▎| 249/266 [01:35<00:06,  2.66it/s]Loading train:  94%|█████████▍| 250/266 [01:36<00:06,  2.47it/s]Loading train:  94%|█████████▍| 251/266 [01:36<00:06,  2.46it/s]Loading train:  95%|█████████▍| 252/266 [01:37<00:05,  2.37it/s]Loading train:  95%|█████████▌| 253/266 [01:37<00:05,  2.44it/s]Loading train:  95%|█████████▌| 254/266 [01:38<00:04,  2.49it/s]Loading train:  96%|█████████▌| 255/266 [01:38<00:04,  2.51it/s]Loading train:  96%|█████████▌| 256/266 [01:38<00:03,  2.55it/s]Loading train:  97%|█████████▋| 257/266 [01:39<00:03,  2.58it/s]Loading train:  97%|█████████▋| 258/266 [01:39<00:03,  2.58it/s]Loading train:  97%|█████████▋| 259/266 [01:39<00:02,  2.60it/s]Loading train:  98%|█████████▊| 260/266 [01:40<00:02,  2.60it/s]Loading train:  98%|█████████▊| 261/266 [01:40<00:01,  2.61it/s]Loading train:  98%|█████████▊| 262/266 [01:41<00:01,  2.51it/s]Loading train:  99%|█████████▉| 263/266 [01:41<00:01,  2.54it/s]Loading train:  99%|█████████▉| 264/266 [01:41<00:00,  2.57it/s]Loading train: 100%|█████████▉| 265/266 [01:42<00:00,  2.59it/s]Loading train: 100%|██████████| 266/266 [01:42<00:00,  2.61it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:01, 209.80it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:00, 224.18it/s]concatenating: train:  32%|███▏      | 85/266 [00:00<00:00, 253.81it/s]concatenating: train:  45%|████▌     | 121/266 [00:00<00:00, 276.17it/s]concatenating: train:  57%|█████▋    | 152/266 [00:00<00:00, 283.26it/s]concatenating: train:  69%|██████▉   | 183/266 [00:00<00:00, 288.55it/s]concatenating: train:  83%|████████▎ | 221/266 [00:00<00:00, 310.50it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 339.04it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  2.41it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  2.57it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  2.60it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  2.49it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 501.67it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<02:02,  2.16it/s]Loading trainS:   1%|          | 2/266 [00:00<01:59,  2.20it/s]Loading trainS:   1%|          | 3/266 [00:01<01:51,  2.35it/s]Loading trainS:   2%|▏         | 4/266 [00:01<01:53,  2.30it/s]Loading trainS:   2%|▏         | 5/266 [00:02<01:56,  2.25it/s]Loading trainS:   2%|▏         | 6/266 [00:02<01:53,  2.29it/s]Loading trainS:   3%|▎         | 7/266 [00:03<01:50,  2.34it/s]Loading trainS:   3%|▎         | 8/266 [00:03<01:55,  2.24it/s]Loading trainS:   3%|▎         | 9/266 [00:03<01:58,  2.18it/s]Loading trainS:   4%|▍         | 10/266 [00:04<01:56,  2.20it/s]Loading trainS:   4%|▍         | 11/266 [00:04<01:55,  2.20it/s]Loading trainS:   5%|▍         | 12/266 [00:05<01:53,  2.24it/s]Loading trainS:   5%|▍         | 13/266 [00:05<01:58,  2.14it/s]Loading trainS:   5%|▌         | 14/266 [00:06<01:58,  2.13it/s]Loading trainS:   6%|▌         | 15/266 [00:06<01:54,  2.19it/s]Loading trainS:   6%|▌         | 16/266 [00:07<01:50,  2.25it/s]Loading trainS:   6%|▋         | 17/266 [00:07<01:46,  2.34it/s]Loading trainS:   7%|▋         | 18/266 [00:07<01:44,  2.38it/s]Loading trainS:   7%|▋         | 19/266 [00:08<01:43,  2.38it/s]Loading trainS:   8%|▊         | 20/266 [00:08<01:38,  2.49it/s]Loading trainS:   8%|▊         | 21/266 [00:09<01:45,  2.31it/s]Loading trainS:   8%|▊         | 22/266 [00:09<01:44,  2.33it/s]Loading trainS:   9%|▊         | 23/266 [00:10<01:41,  2.39it/s]Loading trainS:   9%|▉         | 24/266 [00:10<01:35,  2.52it/s]Loading trainS:   9%|▉         | 25/266 [00:10<01:31,  2.64it/s]Loading trainS:  10%|▉         | 26/266 [00:11<01:28,  2.73it/s]Loading trainS:  10%|█         | 27/266 [00:11<01:25,  2.80it/s]Loading trainS:  11%|█         | 28/266 [00:11<01:26,  2.75it/s]Loading trainS:  11%|█         | 29/266 [00:12<01:25,  2.76it/s]Loading trainS:  11%|█▏        | 30/266 [00:12<01:23,  2.82it/s]Loading trainS:  12%|█▏        | 31/266 [00:12<01:22,  2.86it/s]Loading trainS:  12%|█▏        | 32/266 [00:13<01:20,  2.89it/s]Loading trainS:  12%|█▏        | 33/266 [00:13<01:19,  2.92it/s]Loading trainS:  13%|█▎        | 34/266 [00:13<01:25,  2.72it/s]Loading trainS:  13%|█▎        | 35/266 [00:14<01:26,  2.68it/s]Loading trainS:  14%|█▎        | 36/266 [00:14<01:23,  2.75it/s]Loading trainS:  14%|█▍        | 37/266 [00:14<01:21,  2.82it/s]Loading trainS:  14%|█▍        | 38/266 [00:15<01:19,  2.87it/s]Loading trainS:  15%|█▍        | 39/266 [00:15<01:18,  2.91it/s]Loading trainS:  15%|█▌        | 40/266 [00:15<01:18,  2.86it/s]Loading trainS:  15%|█▌        | 41/266 [00:16<01:21,  2.76it/s]Loading trainS:  16%|█▌        | 42/266 [00:16<01:22,  2.73it/s]Loading trainS:  16%|█▌        | 43/266 [00:17<01:17,  2.87it/s]Loading trainS:  17%|█▋        | 44/266 [00:17<01:16,  2.90it/s]Loading trainS:  17%|█▋        | 45/266 [00:17<01:14,  2.98it/s]Loading trainS:  17%|█▋        | 46/266 [00:17<01:09,  3.15it/s]Loading trainS:  18%|█▊        | 47/266 [00:18<01:07,  3.23it/s]Loading trainS:  18%|█▊        | 48/266 [00:18<01:05,  3.33it/s]Loading trainS:  18%|█▊        | 49/266 [00:18<01:03,  3.42it/s]Loading trainS:  19%|█▉        | 50/266 [00:19<01:02,  3.48it/s]Loading trainS:  19%|█▉        | 51/266 [00:19<01:01,  3.52it/s]Loading trainS:  20%|█▉        | 52/266 [00:19<01:00,  3.53it/s]Loading trainS:  20%|█▉        | 53/266 [00:19<00:59,  3.59it/s]Loading trainS:  20%|██        | 54/266 [00:20<00:59,  3.57it/s]Loading trainS:  21%|██        | 55/266 [00:20<00:58,  3.59it/s]Loading trainS:  21%|██        | 56/266 [00:20<00:58,  3.57it/s]Loading trainS:  21%|██▏       | 57/266 [00:21<00:58,  3.59it/s]Loading trainS:  22%|██▏       | 58/266 [00:21<00:57,  3.59it/s]Loading trainS:  22%|██▏       | 59/266 [00:21<00:58,  3.51it/s]Loading trainS:  23%|██▎       | 60/266 [00:21<00:59,  3.47it/s]Loading trainS:  23%|██▎       | 61/266 [00:22<00:59,  3.47it/s]Loading trainS:  23%|██▎       | 62/266 [00:22<00:58,  3.47it/s]Loading trainS:  24%|██▎       | 63/266 [00:22<01:01,  3.32it/s]Loading trainS:  24%|██▍       | 64/266 [00:23<01:05,  3.09it/s]Loading trainS:  24%|██▍       | 65/266 [00:23<01:08,  2.95it/s]Loading trainS:  25%|██▍       | 66/266 [00:24<01:12,  2.75it/s]Loading trainS:  25%|██▌       | 67/266 [00:24<01:11,  2.77it/s]Loading trainS:  26%|██▌       | 68/266 [00:24<01:12,  2.72it/s]Loading trainS:  26%|██▌       | 69/266 [00:25<01:09,  2.85it/s]Loading trainS:  26%|██▋       | 70/266 [00:25<01:10,  2.77it/s]Loading trainS:  27%|██▋       | 71/266 [00:25<01:10,  2.76it/s]Loading trainS:  27%|██▋       | 72/266 [00:26<01:09,  2.79it/s]Loading trainS:  27%|██▋       | 73/266 [00:26<01:04,  2.98it/s]Loading trainS:  28%|██▊       | 74/266 [00:26<01:02,  3.08it/s]Loading trainS:  28%|██▊       | 75/266 [00:27<01:03,  3.01it/s]Loading trainS:  29%|██▊       | 76/266 [00:27<01:02,  3.05it/s]Loading trainS:  29%|██▉       | 77/266 [00:27<00:59,  3.15it/s]Loading trainS:  29%|██▉       | 78/266 [00:28<01:00,  3.08it/s]Loading trainS:  30%|██▉       | 79/266 [00:28<01:01,  3.06it/s]Loading trainS:  30%|███       | 80/266 [00:28<01:01,  3.04it/s]Loading trainS:  30%|███       | 81/266 [00:29<01:01,  3.03it/s]Loading trainS:  31%|███       | 82/266 [00:29<01:00,  3.03it/s]Loading trainS:  31%|███       | 83/266 [00:29<01:02,  2.91it/s]Loading trainS:  32%|███▏      | 84/266 [00:30<01:05,  2.79it/s]Loading trainS:  32%|███▏      | 85/266 [00:30<01:10,  2.58it/s]Loading trainS:  32%|███▏      | 86/266 [00:31<01:13,  2.45it/s]Loading trainS:  33%|███▎      | 87/266 [00:31<01:11,  2.49it/s]Loading trainS:  33%|███▎      | 88/266 [00:31<01:10,  2.52it/s]Loading trainS:  33%|███▎      | 89/266 [00:32<01:09,  2.55it/s]Loading trainS:  34%|███▍      | 90/266 [00:32<01:12,  2.42it/s]Loading trainS:  34%|███▍      | 91/266 [00:33<01:10,  2.48it/s]Loading trainS:  35%|███▍      | 92/266 [00:33<01:09,  2.49it/s]Loading trainS:  35%|███▍      | 93/266 [00:33<01:08,  2.52it/s]Loading trainS:  35%|███▌      | 94/266 [00:34<01:07,  2.54it/s]Loading trainS:  36%|███▌      | 95/266 [00:34<01:06,  2.57it/s]Loading trainS:  36%|███▌      | 96/266 [00:34<01:05,  2.58it/s]Loading trainS:  36%|███▋      | 97/266 [00:35<01:07,  2.51it/s]Loading trainS:  37%|███▋      | 98/266 [00:35<01:07,  2.49it/s]Loading trainS:  37%|███▋      | 99/266 [00:36<01:04,  2.57it/s]Loading trainS:  38%|███▊      | 100/266 [00:36<01:03,  2.61it/s]Loading trainS:  38%|███▊      | 101/266 [00:36<01:01,  2.69it/s]Loading trainS:  38%|███▊      | 102/266 [00:37<01:00,  2.70it/s]Loading trainS:  39%|███▊      | 103/266 [00:37<00:59,  2.75it/s]Loading trainS:  39%|███▉      | 104/266 [00:37<01:00,  2.70it/s]Loading trainS:  39%|███▉      | 105/266 [00:38<00:58,  2.73it/s]Loading trainS:  40%|███▉      | 106/266 [00:38<00:56,  2.85it/s]Loading trainS:  40%|████      | 107/266 [00:38<00:53,  2.98it/s]Loading trainS:  41%|████      | 108/266 [00:39<00:55,  2.86it/s]Loading trainS:  41%|████      | 109/266 [00:39<00:55,  2.82it/s]Loading trainS:  41%|████▏     | 110/266 [00:40<00:55,  2.81it/s]Loading trainS:  42%|████▏     | 111/266 [00:40<00:54,  2.82it/s]Loading trainS:  42%|████▏     | 112/266 [00:40<00:51,  2.98it/s]Loading trainS:  42%|████▏     | 113/266 [00:40<00:49,  3.10it/s]Loading trainS:  43%|████▎     | 114/266 [00:41<00:48,  3.15it/s]Loading trainS:  43%|████▎     | 115/266 [00:41<00:49,  3.06it/s]Loading trainS:  44%|████▎     | 116/266 [00:41<00:48,  3.06it/s]Loading trainS:  44%|████▍     | 117/266 [00:42<00:48,  3.06it/s]Loading trainS:  44%|████▍     | 118/266 [00:42<00:47,  3.14it/s]Loading trainS:  45%|████▍     | 119/266 [00:43<00:50,  2.89it/s]Loading trainS:  45%|████▌     | 120/266 [00:43<00:54,  2.69it/s]Loading trainS:  45%|████▌     | 121/266 [00:43<00:55,  2.62it/s]Loading trainS:  46%|████▌     | 122/266 [00:44<00:54,  2.66it/s]Loading trainS:  46%|████▌     | 123/266 [00:44<00:52,  2.75it/s]Loading trainS:  47%|████▋     | 124/266 [00:44<00:50,  2.79it/s]Loading trainS:  47%|████▋     | 125/266 [00:45<00:49,  2.83it/s]Loading trainS:  47%|████▋     | 126/266 [00:45<00:54,  2.56it/s]Loading trainS:  48%|████▊     | 127/266 [00:46<00:55,  2.52it/s]Loading trainS:  48%|████▊     | 128/266 [00:46<00:52,  2.63it/s]Loading trainS:  48%|████▊     | 129/266 [00:46<00:50,  2.73it/s]Loading trainS:  49%|████▉     | 130/266 [00:47<00:48,  2.78it/s]Loading trainS:  49%|████▉     | 131/266 [00:47<00:49,  2.74it/s]Loading trainS:  50%|████▉     | 132/266 [00:47<00:53,  2.53it/s]Loading trainS:  50%|█████     | 133/266 [00:48<00:52,  2.52it/s]Loading trainS:  50%|█████     | 134/266 [00:48<00:51,  2.55it/s]Loading trainS:  51%|█████     | 135/266 [00:49<00:50,  2.59it/s]Loading trainS:  51%|█████     | 136/266 [00:49<00:50,  2.59it/s]Loading trainS:  52%|█████▏    | 137/266 [00:49<00:47,  2.69it/s]Loading trainS:  52%|█████▏    | 138/266 [00:50<00:47,  2.68it/s]Loading trainS:  52%|█████▏    | 139/266 [00:50<00:46,  2.73it/s]Loading trainS:  53%|█████▎    | 140/266 [00:50<00:46,  2.73it/s]Loading trainS:  53%|█████▎    | 141/266 [00:51<00:49,  2.55it/s]Loading trainS:  53%|█████▎    | 142/266 [00:51<00:47,  2.60it/s]Loading trainS:  54%|█████▍    | 143/266 [00:52<00:45,  2.68it/s]Loading trainS:  54%|█████▍    | 144/266 [00:52<00:44,  2.73it/s]Loading trainS:  55%|█████▍    | 145/266 [00:52<00:43,  2.79it/s]Loading trainS:  55%|█████▍    | 146/266 [00:53<00:42,  2.84it/s]Loading trainS:  55%|█████▌    | 147/266 [00:53<00:43,  2.76it/s]Loading trainS:  56%|█████▌    | 148/266 [00:53<00:42,  2.75it/s]Loading trainS:  56%|█████▌    | 149/266 [00:54<00:44,  2.63it/s]Loading trainS:  56%|█████▋    | 150/266 [00:54<00:43,  2.65it/s]Loading trainS:  57%|█████▋    | 151/266 [00:55<00:43,  2.67it/s]Loading trainS:  57%|█████▋    | 152/266 [00:55<00:41,  2.73it/s]Loading trainS:  58%|█████▊    | 153/266 [00:55<00:39,  2.86it/s]Loading trainS:  58%|█████▊    | 154/266 [00:56<00:37,  2.95it/s]Loading trainS:  58%|█████▊    | 155/266 [00:56<00:35,  3.12it/s]Loading trainS:  59%|█████▊    | 156/266 [00:56<00:33,  3.33it/s]Loading trainS:  59%|█████▉    | 157/266 [00:56<00:33,  3.29it/s]Loading trainS:  59%|█████▉    | 158/266 [00:57<00:32,  3.33it/s]Loading trainS:  60%|█████▉    | 159/266 [00:57<00:30,  3.47it/s]Loading trainS:  60%|██████    | 160/266 [00:57<00:29,  3.58it/s]Loading trainS:  61%|██████    | 161/266 [00:57<00:30,  3.46it/s]Loading trainS:  61%|██████    | 162/266 [00:58<00:30,  3.37it/s]Loading trainS:  61%|██████▏   | 163/266 [00:58<00:32,  3.21it/s]Loading trainS:  62%|██████▏   | 164/266 [00:58<00:31,  3.22it/s]Loading trainS:  62%|██████▏   | 165/266 [00:59<00:32,  3.15it/s]Loading trainS:  62%|██████▏   | 166/266 [00:59<00:32,  3.07it/s]Loading trainS:  63%|██████▎   | 167/266 [00:59<00:31,  3.13it/s]Loading trainS:  63%|██████▎   | 168/266 [01:00<00:29,  3.34it/s]Loading trainS:  64%|██████▎   | 169/266 [01:00<00:28,  3.46it/s]Loading trainS:  64%|██████▍   | 170/266 [01:00<00:28,  3.39it/s]Loading trainS:  64%|██████▍   | 171/266 [01:01<00:28,  3.36it/s]Loading trainS:  65%|██████▍   | 172/266 [01:01<00:29,  3.23it/s]Loading trainS:  65%|██████▌   | 173/266 [01:01<00:30,  3.02it/s]Loading trainS:  65%|██████▌   | 174/266 [01:02<00:30,  2.97it/s]Loading trainS:  66%|██████▌   | 175/266 [01:02<00:29,  3.09it/s]Loading trainS:  66%|██████▌   | 176/266 [01:02<00:28,  3.14it/s]Loading trainS:  67%|██████▋   | 177/266 [01:03<00:29,  3.03it/s]Loading trainS:  67%|██████▋   | 178/266 [01:03<00:30,  2.92it/s]Loading trainS:  67%|██████▋   | 179/266 [01:03<00:31,  2.79it/s]Loading trainS:  68%|██████▊   | 180/266 [01:04<00:30,  2.81it/s]Loading trainS:  68%|██████▊   | 181/266 [01:04<00:28,  2.93it/s]Loading trainS:  68%|██████▊   | 182/266 [01:04<00:27,  3.07it/s]Loading trainS:  69%|██████▉   | 183/266 [01:05<00:27,  3.00it/s]Loading trainS:  69%|██████▉   | 184/266 [01:05<00:29,  2.79it/s]Loading trainS:  70%|██████▉   | 185/266 [01:05<00:29,  2.71it/s]Loading trainS:  70%|██████▉   | 186/266 [01:06<00:27,  2.92it/s]Loading trainS:  70%|███████   | 187/266 [01:06<00:26,  3.01it/s]Loading trainS:  71%|███████   | 188/266 [01:06<00:26,  2.98it/s]Loading trainS:  71%|███████   | 189/266 [01:07<00:26,  2.92it/s]Loading trainS:  71%|███████▏  | 190/266 [01:07<00:26,  2.92it/s]Loading trainS:  72%|███████▏  | 191/266 [01:07<00:25,  2.94it/s]Loading trainS:  72%|███████▏  | 192/266 [01:08<00:24,  2.96it/s]Loading trainS:  73%|███████▎  | 193/266 [01:08<00:23,  3.05it/s]Loading trainS:  73%|███████▎  | 194/266 [01:08<00:24,  2.99it/s]Loading trainS:  73%|███████▎  | 195/266 [01:09<00:23,  3.05it/s]Loading trainS:  74%|███████▎  | 196/266 [01:09<00:24,  2.87it/s]Loading trainS:  74%|███████▍  | 197/266 [01:10<00:25,  2.74it/s]Loading trainS:  74%|███████▍  | 198/266 [01:10<00:26,  2.60it/s]Loading trainS:  75%|███████▍  | 199/266 [01:10<00:24,  2.70it/s]Loading trainS:  75%|███████▌  | 200/266 [01:11<00:22,  2.90it/s]Loading trainS:  76%|███████▌  | 201/266 [01:11<00:21,  3.00it/s]Loading trainS:  76%|███████▌  | 202/266 [01:11<00:20,  3.06it/s]Loading trainS:  76%|███████▋  | 203/266 [01:12<00:20,  3.10it/s]Loading trainS:  77%|███████▋  | 204/266 [01:12<00:19,  3.14it/s]Loading trainS:  77%|███████▋  | 205/266 [01:12<00:19,  3.16it/s]Loading trainS:  77%|███████▋  | 206/266 [01:12<00:18,  3.23it/s]Loading trainS:  78%|███████▊  | 207/266 [01:13<00:18,  3.11it/s]Loading trainS:  78%|███████▊  | 208/266 [01:13<00:18,  3.15it/s]Loading trainS:  79%|███████▊  | 209/266 [01:13<00:18,  3.14it/s]Loading trainS:  79%|███████▉  | 210/266 [01:14<00:18,  3.08it/s]Loading trainS:  79%|███████▉  | 211/266 [01:14<00:18,  3.01it/s]Loading trainS:  80%|███████▉  | 212/266 [01:14<00:17,  3.06it/s]Loading trainS:  80%|████████  | 213/266 [01:15<00:16,  3.16it/s]Loading trainS:  80%|████████  | 214/266 [01:15<00:16,  3.12it/s]Loading trainS:  81%|████████  | 215/266 [01:15<00:16,  3.15it/s]Loading trainS:  81%|████████  | 216/266 [01:16<00:16,  3.10it/s]Loading trainS:  82%|████████▏ | 217/266 [01:16<00:14,  3.27it/s]Loading trainS:  82%|████████▏ | 218/266 [01:16<00:15,  3.07it/s]Loading trainS:  82%|████████▏ | 219/266 [01:17<00:15,  3.06it/s]Loading trainS:  83%|████████▎ | 220/266 [01:17<00:14,  3.13it/s]Loading trainS:  83%|████████▎ | 221/266 [01:17<00:14,  3.21it/s]Loading trainS:  83%|████████▎ | 222/266 [01:18<00:13,  3.28it/s]Loading trainS:  84%|████████▍ | 223/266 [01:18<00:12,  3.36it/s]Loading trainS:  84%|████████▍ | 224/266 [01:18<00:13,  3.22it/s]Loading trainS:  85%|████████▍ | 225/266 [01:19<00:14,  2.81it/s]Loading trainS:  85%|████████▍ | 226/266 [01:19<00:15,  2.58it/s]Loading trainS:  85%|████████▌ | 227/266 [01:19<00:15,  2.59it/s]Loading trainS:  86%|████████▌ | 228/266 [01:20<00:13,  2.75it/s]Loading trainS:  86%|████████▌ | 229/266 [01:20<00:12,  2.91it/s]Loading trainS:  86%|████████▋ | 230/266 [01:20<00:12,  2.92it/s]Loading trainS:  87%|████████▋ | 231/266 [01:21<00:13,  2.67it/s]Loading trainS:  87%|████████▋ | 232/266 [01:21<00:12,  2.75it/s]Loading trainS:  88%|████████▊ | 233/266 [01:21<00:11,  2.95it/s]Loading trainS:  88%|████████▊ | 234/266 [01:22<00:10,  3.06it/s]Loading trainS:  88%|████████▊ | 235/266 [01:22<00:09,  3.15it/s]Loading trainS:  89%|████████▊ | 236/266 [01:22<00:09,  3.16it/s]Loading trainS:  89%|████████▉ | 237/266 [01:23<00:09,  2.97it/s]Loading trainS:  89%|████████▉ | 238/266 [01:23<00:09,  2.83it/s]Loading trainS:  90%|████████▉ | 239/266 [01:23<00:08,  3.01it/s]Loading trainS:  90%|█████████ | 240/266 [01:24<00:08,  3.09it/s]Loading trainS:  91%|█████████ | 241/266 [01:24<00:08,  3.06it/s]Loading trainS:  91%|█████████ | 242/266 [01:24<00:07,  3.14it/s]Loading trainS:  91%|█████████▏| 243/266 [01:25<00:07,  3.25it/s]Loading trainS:  92%|█████████▏| 244/266 [01:25<00:06,  3.29it/s]Loading trainS:  92%|█████████▏| 245/266 [01:25<00:06,  3.36it/s]Loading trainS:  92%|█████████▏| 246/266 [01:26<00:05,  3.37it/s]Loading trainS:  93%|█████████▎| 247/266 [01:26<00:05,  3.39it/s]Loading trainS:  93%|█████████▎| 248/266 [01:26<00:05,  3.21it/s]Loading trainS:  94%|█████████▎| 249/266 [01:27<00:05,  2.99it/s]Loading trainS:  94%|█████████▍| 250/266 [01:27<00:05,  2.71it/s]Loading trainS:  94%|█████████▍| 251/266 [01:27<00:05,  2.69it/s]Loading trainS:  95%|█████████▍| 252/266 [01:28<00:05,  2.65it/s]Loading trainS:  95%|█████████▌| 253/266 [01:28<00:05,  2.55it/s]Loading trainS:  95%|█████████▌| 254/266 [01:29<00:04,  2.53it/s]Loading trainS:  96%|█████████▌| 255/266 [01:29<00:04,  2.57it/s]Loading trainS:  96%|█████████▌| 256/266 [01:29<00:04,  2.45it/s]Loading trainS:  97%|█████████▋| 257/266 [01:30<00:03,  2.37it/s]Loading trainS:  97%|█████████▋| 258/266 [01:30<00:03,  2.39it/s]Loading trainS:  97%|█████████▋| 259/266 [01:31<00:02,  2.49it/s]Loading trainS:  98%|█████████▊| 260/266 [01:31<00:02,  2.53it/s]Loading trainS:  98%|█████████▊| 261/266 [01:31<00:01,  2.67it/s]Loading trainS:  98%|█████████▊| 262/266 [01:32<00:01,  2.64it/s]Loading trainS:  99%|█████████▉| 263/266 [01:32<00:01,  2.60it/s]Loading trainS:  99%|█████████▉| 264/266 [01:33<00:00,  2.45it/s]Loading trainS: 100%|█████████▉| 265/266 [01:33<00:00,  2.33it/s]Loading trainS: 100%|██████████| 266/266 [01:34<00:00,  2.29it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  2.51it/s]Loading testS:  50%|█████     | 2/4 [00:00<00:00,  2.53it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  2.54it/s]Loading testS: 100%|██████████| 4/4 [00:01<00:00,  2.58it/s]2019-07-28 22:36:57.179718: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-28 22:36:57.179793: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-28 22:36:57.179807: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-28 22:36:57.179815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-28 22:36:57.180176: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

Epoch 00060: val_mDice did not improve from 0.63078
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
{'val_loss': [1.0229092212331374, 0.979552961435894, 0.5507550247563612, 0.5229888308368273, 0.5304301835146527, 0.509390176742669, 0.5139501156822947, 0.5661902611687679, 0.5065590059197189, 0.451377133795079, 0.568879566936685, 0.8766371771793238, 0.45463343074657775, 0.476708290360918, 0.45209710770005346, 0.4602611908976664, 0.5080365008555803, 0.5947791041943851, 0.46596332504445276, 0.4460401919064106, 0.4518429620954014, 0.483517924811216, 0.46799106245872957, 0.5731176269934481, 0.5369266375599292, 0.4636911263801908, 0.4867257613863721, 0.6193396513094038, 0.46910258247548303, 0.8228727359099676, 0.46753297036126157, 0.46829485953254185, 0.497863902541615, 0.4893707461005089, 0.4681768855392533, 0.47547510686336747, 0.5502513889098327, 0.48831212240577543, 0.4549247420474187, 0.4648306263773233, 0.46727183961228236, 0.5036680266361109, 0.4821886610264746, 0.5179460380701411, 0.47186583140552446, 0.648641188672725, 0.493681427616401, 0.46719328009042166, 0.461475889954791, 0.4520244406373709, 0.4501314487233258, 0.4600400244629623, 0.9590897072081598, 0.5089443620019312, 0.5076019207903203, 0.465745870899034, 0.49244791049285225, 0.486990601824434, 0.47004910263439154, 0.5250184892007969], 'val_acc': [0.9113634568732857, 0.918554256426408, 0.9349399561049955, 0.9345254754060067, 0.9378478863095278, 0.9350597790423656, 0.9353577322607872, 0.9358038550255282, 0.935975293585118, 0.9419992450099663, 0.9308901229160744, 0.9366643972844886, 0.9419210141137142, 0.9389731351961226, 0.9419393031389122, 0.9440033187802206, 0.9443878459450382, 0.9344572336881752, 0.9411070490843497, 0.9442879721622339, 0.9448322733776682, 0.9414865598582581, 0.9433558339240568, 0.9347451885274592, 0.9353610545196789, 0.9432792635572037, 0.9424802820954546, 0.9309783389904355, 0.9430712105443814, 0.9410371368363399, 0.942963004912306, 0.9460374180902571, 0.9401283208155792, 0.9370073064061619, 0.9422589160451953, 0.943685411606859, 0.936659408095699, 0.9417745346991008, 0.9445143438025609, 0.9449804173219924, 0.9428049001917743, 0.938938153270107, 0.939650579186894, 0.9355857804317602, 0.9422705393509577, 0.928917641607707, 0.9452700418913924, 0.9429513512041745, 0.9458027070000667, 0.9439134709787049, 0.9458143619082918, 0.943788600447994, 0.9432176899589948, 0.9362798969217595, 0.9383073129109888, 0.9445110255439809, 0.9437020585040918, 0.9391129400906146, 0.9451169155588086, 0.9431094727260154], 'val_mDice': [0.3886523210762331, 0.42897853935324903, 0.5664278128803176, 0.582406851669286, 0.583190538739198, 0.5922327953697051, 0.589986001085115, 0.5613816768531031, 0.5946254990244871, 0.6265452252138382, 0.5610659826521905, 0.5035635588953159, 0.6238923764868871, 0.6120207325724147, 0.6249740099746909, 0.621571299213691, 0.6023830167399157, 0.5513994721758285, 0.6163747886683317, 0.6307828778388517, 0.6261651547963187, 0.6067621395891944, 0.6171640845753202, 0.5634249016742578, 0.578782014798798, 0.6193185096619113, 0.6098716931055056, 0.5460236792596395, 0.6154413891318661, 0.5705255470019859, 0.616295802513225, 0.6175690805351974, 0.5997006773148608, 0.5997737198067992, 0.6150924255383895, 0.6120075795474469, 0.5722838660214571, 0.6052961373489175, 0.6268595853107888, 0.6180180223196144, 0.6158488332825219, 0.5954261690178173, 0.6065684064922717, 0.5878998961224652, 0.6148543085827923, 0.5354113970826936, 0.6088220281088912, 0.6164843716077356, 0.6206326464678618, 0.6267172898222136, 0.6277531709447003, 0.6201095209025697, 0.5857251822548425, 0.59341163123214, 0.5958738047004546, 0.6180758732277275, 0.6027931487000229, 0.606285414839751, 0.6168057294499955, 0.5856104357130576], 'loss': [1.693592281746383, 0.6937859289593293, 0.5568494297114432, 0.5111090587223367, 0.4536470528897548, 0.4323265975957268, 0.40163678736700453, 0.38667427366468893, 0.37890028221752503, 0.3710451695006272, 0.3540711113402568, 0.33962599053654496, 0.3622968658169383, 0.32738314634621385, 0.3219489266258761, 0.33053782416665184, 0.31149141886134973, 0.3075430793664555, 0.3492679706457915, 0.338616903727234, 0.3216850590203389, 0.303305603973386, 0.29233132324833583, 0.28617904973511243, 0.36124751637524505, 0.3537510305788257, 0.33947855072379857, 0.29974338510351944, 0.3533394032722084, 0.3021423011582679, 0.31859349437115003, 0.2956670058782111, 0.2980179775068141, 0.35401686056315135, 0.2895064405672521, 0.28148844573568643, 0.28812763448654627, 0.3146644887025651, 0.27930820502880754, 0.28232255259545236, 0.2676802704112408, 0.2656379500112354, 0.32146222749137066, 0.2887869754881896, 0.30055218319945504, 0.2662984320160788, 0.41035608537676604, 0.3313656342955135, 0.29280170576391573, 0.3016121454588022, 0.27497752311393486, 0.2672743349808184, 0.2676564351543421, 0.3439552512518726, 0.2945829160775919, 0.2864439814278449, 0.26569527172819496, 0.2768642157271767, 0.25814175271279227, 0.2560698811043706], 'acc': [0.783878785449997, 0.8928133028557813, 0.9134150898317916, 0.9231143636333266, 0.9289209287639925, 0.9312340182840427, 0.933782595463, 0.9355402811583995, 0.9360431183319535, 0.9371340062499982, 0.9386012403660899, 0.9401671992629124, 0.938082723668987, 0.9412107951646534, 0.941971630358722, 0.9411820446488539, 0.9427231781370586, 0.9433552833743047, 0.9392652321388001, 0.9405774524807041, 0.9423453468773472, 0.9438144044428605, 0.944804964974287, 0.9454099056391039, 0.9390084380325615, 0.9400082673973397, 0.9406024073497333, 0.9441154821573924, 0.9395647531345477, 0.9441442578091799, 0.9426790167067324, 0.9453434095028108, 0.9438260701307306, 0.940267354276619, 0.9451038243164065, 0.9460430007791979, 0.9454504146243151, 0.9424154923774931, 0.9461782379526779, 0.9458167792042085, 0.9471949086901279, 0.9475350394757608, 0.9425542836504981, 0.9456198270177021, 0.9447121855657752, 0.9473432639280623, 0.9340036637397419, 0.9411443208579171, 0.9450653610758996, 0.9446858789589215, 0.94658232352667, 0.9474546106722758, 0.9477362089086473, 0.9403536994055022, 0.9447208400547226, 0.9457256750067845, 0.9477055593043675, 0.9467109831596111, 0.9482155242844644, 0.9485053815357205], 'mDice': [0.2586027956770931, 0.49023191495590673, 0.5612441437276887, 0.5865806592294124, 0.6217346314538224, 0.6359682890894589, 0.6549931956885267, 0.6659606640364258, 0.6712971533111578, 0.6766223912685146, 0.6880461801910438, 0.6989045658587034, 0.6835091742384634, 0.7071128003354787, 0.7124962903287375, 0.7056655727474267, 0.719801036900798, 0.7232197067682827, 0.6936099540524815, 0.7000526654482101, 0.7122881438637576, 0.7248890381208268, 0.7332718324822428, 0.7385244030153222, 0.691133449157956, 0.6911350102556879, 0.6992799281149596, 0.7279730728943242, 0.6895096495381666, 0.7274540467579401, 0.7156598696783103, 0.7362340181837832, 0.7289036602916579, 0.6983039319272283, 0.7350539336302655, 0.7422881909103632, 0.737452323518035, 0.717601077636486, 0.7438488373736025, 0.7409019487872845, 0.752267656879499, 0.7548210614125053, 0.7142028606593318, 0.7373376812514402, 0.7322768006010479, 0.7535556817353394, 0.6629346885895893, 0.70724148930559, 0.7344730169259479, 0.7282437142753165, 0.7464413155036557, 0.7526821007203814, 0.7554967134334728, 0.6996650340626072, 0.733468245601948, 0.7379657521626148, 0.7548207990015604, 0.7472086425021458, 0.7605076145492949, 0.7630299716930122]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.20it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.08it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.97it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.34it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.91it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.84it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.25it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.03it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.39it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.91it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.51it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.82it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.96it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.22it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.94it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.21it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.36it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.19it/s]
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 30) 300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 30) 120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 30) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 108, 116, 30) 0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 30) 8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 30) 120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 30) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 108, 116, 30) 0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 108, 116, 31) 0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 108, 116, 20) 5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 108, 116, 20) 80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 108, 116, 20) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 108, 116, 20) 3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 108, 116, 20) 80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 108, 116, 20) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 54, 58, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 54, 58, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 58, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 54, 58, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 54, 58, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 58, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 54, 58, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 27, 29, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 27, 29, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 27, 29, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 27, 29, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 27, 29, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 27, 29, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 27, 29, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 27, 29, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 54, 58, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 58, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 54, 58, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 54, 58, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 54, 58, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 58, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 54, 58, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 20) 7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 108, 116, 20) 80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 108, 116, 20) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 108, 116, 20) 3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 108, 116, 20) 80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 108, 116, 20) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 108, 116, 60) 0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 108, 116, 60) 0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 108, 116, 30) 16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 108, 116, 30) 120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 108, 116, 30) 0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 108, 116, 30) 0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 108, 116, 30) 8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 108, 116, 30) 120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 108, 116, 30) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 108, 116, 30) 0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 108, 116, 90) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 108, 116, 2)  182         concatenate_8[0][0]              
==================================================================================================
Total params: 261,892
Trainable params: 86,972
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 256 samples
Epoch 1/300
 - 62s - loss: 0.2801 - acc: 0.9640 - mDice: 0.6623 - val_loss: 0.3728 - val_acc: 0.9894 - val_mDice: 0.7635

Epoch 00001: val_mDice improved from -inf to 0.76354, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 57s - loss: 0.1010 - acc: 0.9896 - mDice: 0.8239 - val_loss: 0.3684 - val_acc: 0.9897 - val_mDice: 0.7755

Epoch 00002: val_mDice improved from 0.76354 to 0.77546, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 57s - loss: 0.0838 - acc: 0.9911 - mDice: 0.8508 - val_loss: 0.3207 - val_acc: 0.9917 - val_mDice: 0.7953

Epoch 00003: val_mDice improved from 0.77546 to 0.79534, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 56s - loss: 0.0767 - acc: 0.9917 - mDice: 0.8623 - val_loss: 0.3917 - val_acc: 0.9876 - val_mDice: 0.7580

Epoch 00004: val_mDice did not improve from 0.79534
Epoch 5/300
 - 58s - loss: 0.0703 - acc: 0.9923 - mDice: 0.8728 - val_loss: 0.3268 - val_acc: 0.9913 - val_mDice: 0.8040

Epoch 00005: val_mDice improved from 0.79534 to 0.80404, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 63s - loss: 0.0675 - acc: 0.9925 - mDice: 0.8775 - val_loss: 0.2334 - val_acc: 0.9928 - val_mDice: 0.8289

Epoch 00006: val_mDice improved from 0.80404 to 0.82893, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 67s - loss: 0.0639 - acc: 0.9929 - mDice: 0.8836 - val_loss: 0.2323 - val_acc: 0.9929 - val_mDice: 0.8274

Epoch 00007: val_mDice did not improve from 0.82893
Epoch 8/300
 - 68s - loss: 0.0631 - acc: 0.9929 - mDice: 0.8849 - val_loss: 0.2279 - val_acc: 0.9927 - val_mDice: 0.8279

Epoch 00008: val_mDice did not improve from 0.82893
Epoch 9/300
 - 68s - loss: 0.0607 - acc: 0.9932 - mDice: 0.8891 - val_loss: 0.2514 - val_acc: 0.9918 - val_mDice: 0.7859

Epoch 00009: val_mDice did not improve from 0.82893
Epoch 10/300
 - 68s - loss: 0.0597 - acc: 0.9933 - mDice: 0.8908 - val_loss: 0.2253 - val_acc: 0.9926 - val_mDice: 0.8140

Epoch 00010: val_mDice did not improve from 0.82893
Epoch 11/300
 - 68s - loss: 0.0577 - acc: 0.9935 - mDice: 0.8943 - val_loss: 0.1996 - val_acc: 0.9929 - val_mDice: 0.8294

Epoch 00011: val_mDice improved from 0.82893 to 0.82936, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 67s - loss: 0.0565 - acc: 0.9936 - mDice: 0.8963 - val_loss: 0.4171 - val_acc: 0.9852 - val_mDice: 0.7301

Epoch 00012: val_mDice did not improve from 0.82936
Epoch 13/300
 - 68s - loss: 0.0557 - acc: 0.9936 - mDice: 0.8976 - val_loss: 0.3155 - val_acc: 0.9916 - val_mDice: 0.8090

Epoch 00013: val_mDice did not improve from 0.82936
Epoch 14/300
 - 67s - loss: 0.0555 - acc: 0.9937 - mDice: 0.8981 - val_loss: 0.1993 - val_acc: 0.9930 - val_mDice: 0.8333

Epoch 00014: val_mDice improved from 0.82936 to 0.83327, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 64s - loss: 0.0539 - acc: 0.9938 - mDice: 0.9008 - val_loss: 0.2486 - val_acc: 0.9918 - val_mDice: 0.7670

Epoch 00015: val_mDice did not improve from 0.83327
Epoch 16/300
 - 63s - loss: 0.0530 - acc: 0.9939 - mDice: 0.9023 - val_loss: 0.2137 - val_acc: 0.9930 - val_mDice: 0.8298

Epoch 00016: val_mDice did not improve from 0.83327
Epoch 17/300
 - 64s - loss: 0.0528 - acc: 0.9939 - mDice: 0.9027 - val_loss: 0.2128 - val_acc: 0.9933 - val_mDice: 0.8264

Epoch 00017: val_mDice did not improve from 0.83327
Epoch 18/300
 - 66s - loss: 0.0520 - acc: 0.9940 - mDice: 0.9042 - val_loss: 0.2139 - val_acc: 0.9930 - val_mDice: 0.8261

Epoch 00018: val_mDice did not improve from 0.83327
Epoch 19/300
 - 65s - loss: 0.0510 - acc: 0.9941 - mDice: 0.9058 - val_loss: 0.2004 - val_acc: 0.9926 - val_mDice: 0.8292

Epoch 00019: val_mDice did not improve from 0.83327
Epoch 20/300
 - 65s - loss: 0.0503 - acc: 0.9942 - mDice: 0.9071 - val_loss: 0.1928 - val_acc: 0.9932 - val_mDice: 0.8308

Epoch 00020: val_mDice did not improve from 0.83327
Epoch 21/300
 - 65s - loss: 0.0498 - acc: 0.9942 - mDice: 0.9080 - val_loss: 0.1944 - val_acc: 0.9933 - val_mDice: 0.8320

Epoch 00021: val_mDice did not improve from 0.83327
Epoch 22/300
 - 68s - loss: 0.0489 - acc: 0.9943 - mDice: 0.9095 - val_loss: 0.1762 - val_acc: 0.9934 - val_mDice: 0.8364

Epoch 00022: val_mDice improved from 0.83327 to 0.83644, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 68s - loss: 0.0491 - acc: 0.9943 - mDice: 0.9093 - val_loss: 0.5149 - val_acc: 0.9729 - val_mDice: 0.6195

Epoch 00023: val_mDice did not improve from 0.83644
Epoch 24/300
 - 69s - loss: 0.0481 - acc: 0.9944 - mDice: 0.9110 - val_loss: 0.2260 - val_acc: 0.9935 - val_mDice: 0.8399

Epoch 00024: val_mDice improved from 0.83644 to 0.83993, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 68s - loss: 0.0477 - acc: 0.9944 - mDice: 0.9117 - val_loss: 0.1919 - val_acc: 0.9934 - val_mDice: 0.8380

Epoch 00025: val_mDice did not improve from 0.83993
Epoch 26/300
 - 69s - loss: 0.0469 - acc: 0.9945 - mDice: 0.9131 - val_loss: 0.1883 - val_acc: 0.9935 - val_mDice: 0.8418

Epoch 00026: val_mDice improved from 0.83993 to 0.84178, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 69s - loss: 0.0467 - acc: 0.9945 - mDice: 0.9135 - val_loss: 0.1802 - val_acc: 0.9934 - val_mDice: 0.8396

Epoch 00027: val_mDice did not improve from 0.84178
Epoch 28/300
 - 68s - loss: 0.0462 - acc: 0.9946 - mDice: 0.9143 - val_loss: 0.3293 - val_acc: 0.9915 - val_mDice: 0.8174

Epoch 00028: val_mDice did not improve from 0.84178
Epoch 29/300
 - 68s - loss: 0.0462 - acc: 0.9946 - mDice: 0.9144 - val_loss: 0.1812 - val_acc: 0.9925 - val_mDice: 0.8306

Epoch 00029: val_mDice did not improve from 0.84178
Epoch 30/300
 - 68s - loss: 0.0453 - acc: 0.9947 - mDice: 0.9160 - val_loss: 0.1859 - val_acc: 0.9933 - val_mDice: 0.8266

Epoch 00030: val_mDice did not improve from 0.84178
Epoch 31/300
 - 67s - loss: 0.0447 - acc: 0.9947 - mDice: 0.9169 - val_loss: 0.2866 - val_acc: 0.9933 - val_mDice: 0.8416

Epoch 00031: val_mDice did not improve from 0.84178
Epoch 32/300
 - 68s - loss: 0.0444 - acc: 0.9947 - mDice: 0.9175 - val_loss: 0.1645 - val_acc: 0.9936 - val_mDice: 0.8410

Epoch 00032: val_mDice did not improve from 0.84178
Epoch 33/300
 - 63s - loss: 0.0443 - acc: 0.9947 - mDice: 0.9176 - val_loss: 0.1723 - val_acc: 0.9926 - val_mDice: 0.8379

Epoch 00033: val_mDice did not improve from 0.84178
Epoch 34/300
 - 58s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9195 - val_loss: 0.3011 - val_acc: 0.9932 - val_mDice: 0.8437

Epoch 00034: val_mDice improved from 0.84178 to 0.84367, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 35/300
 - 59s - loss: 0.0433 - acc: 0.9948 - mDice: 0.9195 - val_loss: 0.1605 - val_acc: 0.9936 - val_mDice: 0.8414

Epoch 00035: val_mDice did not improve from 0.84367
Epoch 36/300
 - 58s - loss: 0.0431 - acc: 0.9949 - mDice: 0.9199 - val_loss: 0.3038 - val_acc: 0.9927 - val_mDice: 0.8365

Epoch 00036: val_mDice did not improve from 0.84367
Epoch 37/300
 - 58s - loss: 0.0430 - acc: 0.9949 - mDice: 0.9200 - val_loss: 0.3665 - val_acc: 0.9896 - val_mDice: 0.7952

Epoch 00037: val_mDice did not improve from 0.84367
Epoch 38/300
 - 58s - loss: 0.0418 - acc: 0.9950 - mDice: 0.9222 - val_loss: 0.1509 - val_acc: 0.9936 - val_mDice: 0.8468

Epoch 00038: val_mDice improved from 0.84367 to 0.84676, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 58s - loss: 0.0422 - acc: 0.9949 - mDice: 0.9215 - val_loss: 0.2955 - val_acc: 0.9926 - val_mDice: 0.8371

Epoch 00039: val_mDice did not improve from 0.84676
Epoch 40/300
 - 58s - loss: 0.0424 - acc: 0.9949 - mDice: 0.9210 - val_loss: 0.2909 - val_acc: 0.9925 - val_mDice: 0.8348

Epoch 00040: val_mDice did not improve from 0.84676
Epoch 41/300
 - 58s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9228 - val_loss: 0.3195 - val_acc: 0.9885 - val_mDice: 0.6363

Epoch 00041: val_mDice did not improve from 0.84676
Epoch 42/300
 - 59s - loss: 0.0415 - acc: 0.9950 - mDice: 0.9227 - val_loss: 0.1397 - val_acc: 0.9938 - val_mDice: 0.8498

Epoch 00042: val_mDice improved from 0.84676 to 0.84982, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 58s - loss: 0.0412 - acc: 0.9950 - mDice: 0.9233 - val_loss: 0.3281 - val_acc: 0.9917 - val_mDice: 0.8235

Epoch 00043: val_mDice did not improve from 0.84982
Epoch 44/300
 - 59s - loss: 0.0414 - acc: 0.9950 - mDice: 0.9229 - val_loss: 0.2680 - val_acc: 0.9934 - val_mDice: 0.8480

Epoch 00044: val_mDice did not improve from 0.84982
Epoch 45/300
 - 58s - loss: 0.0409 - acc: 0.9951 - mDice: 0.9238 - val_loss: 0.3329 - val_acc: 0.9921 - val_mDice: 0.8305

Epoch 00045: val_mDice did not improve from 0.84982
Epoch 46/300
 - 59s - loss: 0.0410 - acc: 0.9951 - mDice: 0.9236 - val_loss: 0.3462 - val_acc: 0.9910 - val_mDice: 0.8139

Epoch 00046: val_mDice did not improve from 0.84982
Epoch 47/300
 - 57s - loss: 0.0403 - acc: 0.9952 - mDice: 0.9249 - val_loss: 0.3557 - val_acc: 0.9902 - val_mDice: 0.8025

Epoch 00047: val_mDice did not improve from 0.84982
Epoch 48/300
 - 57s - loss: 0.0413 - acc: 0.9951 - mDice: 0.9231 - val_loss: 0.1190 - val_acc: 0.9936 - val_mDice: 0.8418

Epoch 00048: val_mDice did not improve from 0.84982
Epoch 49/300
 - 57s - loss: 0.0401 - acc: 0.9952 - mDice: 0.9252 - val_loss: 0.1256 - val_acc: 0.9937 - val_mDice: 0.8442

Epoch 00049: val_mDice did not improve from 0.84982
Epoch 50/300
 - 56s - loss: 0.0399 - acc: 0.9952 - mDice: 0.9256 - val_loss: 0.1254 - val_acc: 0.9936 - val_mDice: 0.8403

Epoch 00050: val_mDice did not improve from 0.84982
Epoch 51/300
 - 57s - loss: 0.0406 - acc: 0.9951 - mDice: 0.9243 - val_loss: 0.1274 - val_acc: 0.9933 - val_mDice: 0.8427

Epoch 00051: val_mDice did not improve from 0.84982
Epoch 52/300
 - 56s - loss: 0.0398 - acc: 0.9952 - mDice: 0.9258 - val_loss: 0.2729 - val_acc: 0.9935 - val_mDice: 0.8525

Epoch 00052: val_mDice improved from 0.84982 to 0.85252, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 53/300
 - 57s - loss: 0.0394 - acc: 0.9952 - mDice: 0.9265 - val_loss: 0.2626 - val_acc: 0.9935 - val_mDice: 0.8388

Epoch 00053: val_mDice did not improve from 0.85252
Epoch 54/300
 - 56s - loss: 0.0390 - acc: 0.9952 - mDice: 0.9272 - val_loss: 0.1464 - val_acc: 0.9934 - val_mDice: 0.8412

Epoch 00054: val_mDice did not improve from 0.85252
Epoch 55/300
 - 56s - loss: 0.0390 - acc: 0.9953 - mDice: 0.9271 - val_loss: 0.1623 - val_acc: 0.9933 - val_mDice: 0.8399

Epoch 00055: val_mDice did not improve from 0.85252
Epoch 56/300
 - 57s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9276 - val_loss: 0.3419 - val_acc: 0.9915 - val_mDice: 0.8213

Epoch 00056: val_mDice did not improve from 0.85252
Epoch 57/300
 - 58s - loss: 0.0389 - acc: 0.9953 - mDice: 0.9275 - val_loss: 0.3472 - val_acc: 0.9910 - val_mDice: 0.8138

Epoch 00057: val_mDice did not improve from 0.85252
Epoch 58/300
 - 58s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9276 - val_loss: 0.3328 - val_acc: 0.9915 - val_mDice: 0.8191

Epoch 00058: val_mDice did not improve from 0.85252
Epoch 59/300
 - 59s - loss: 0.0388 - acc: 0.9953 - mDice: 0.9275 - val_loss: 0.2761 - val_acc: 0.9932 - val_mDice: 0.8438

Epoch 00059: val_mDice did not improve from 0.85252
Epoch 60/300
 - 57s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9286 - val_loss: 0.2579 - val_acc: 0.9933 - val_mDice: 0.8474

Epoch 00060: val_mDice did not improve from 0.85252
Epoch 61/300
 - 58s - loss: 0.0380 - acc: 0.9954 - mDice: 0.9290 - val_loss: 0.2534 - val_acc: 0.9936 - val_mDice: 0.8491

Epoch 00061: val_mDice did not improve from 0.85252
Epoch 62/300
 - 58s - loss: 0.0386 - acc: 0.9953 - mDice: 0.9280 - val_loss: 0.3120 - val_acc: 0.9929 - val_mDice: 0.8378

Epoch 00062: val_mDice did not improve from 0.85252
Epoch 63/300
 - 57s - loss: 0.0382 - acc: 0.9953 - mDice: 0.9286 - val_loss: 0.2732 - val_acc: 0.9935 - val_mDice: 0.8477

Epoch 00063: val_mDice did not improve from 0.85252
Epoch 64/300
 - 58s - loss: 0.0378 - acc: 0.9954 - mDice: 0.9294 - val_loss: 0.3579 - val_acc: 0.9906 - val_mDice: 0.8083

Epoch 00064: val_mDice did not improve from 0.85252
Epoch 65/300
 - 58s - loss: 0.0381 - acc: 0.9954 - mDice: 0.9289 - val_loss: 0.2744 - val_acc: 0.9932 - val_mDice: 0.8427

Epoch 00065: val_mDice did not improve from 0.85252
Epoch 66/300
 - 58s - loss: 0.0380 - acc: 0.9954 - mDice: 0.9294 - val_loss: 0.3067 - val_acc: 0.9908 - val_mDice: 0.8086

Epoch 00066: val_mDice did not improve from 0.85252
Epoch 67/300
 - 58s - loss: 0.0478 - acc: 0.9945 - mDice: 0.9120 - val_loss: 0.0852 - val_acc: 0.9930 - val_mDice: 0.8202

Epoch 00067: val_mDice did not improve from 0.85252
Epoch 68/300
 - 58s - loss: 0.0381 - acc: 0.9953 - mDice: 0.9288 - val_loss: 0.3126 - val_acc: 0.9928 - val_mDice: 0.8386

Epoch 00068: val_mDice did not improve from 0.85252
Epoch 69/300
 - 58s - loss: 0.0374 - acc: 0.9954 - mDice: 0.9302 - val_loss: 0.2582 - val_acc: 0.9937 - val_mDice: 0.8463

Epoch 00069: val_mDice did not improve from 0.85252
Epoch 70/300
 - 58s - loss: 0.0374 - acc: 0.9954 - mDice: 0.9300 - val_loss: 0.3128 - val_acc: 0.9929 - val_mDice: 0.8379

Epoch 00070: val_mDice did not improve from 0.85252
Epoch 71/300
 - 58s - loss: 0.0368 - acc: 0.9954 - mDice: 0.9313 - val_loss: 0.3019 - val_acc: 0.9935 - val_mDice: 0.8478

Epoch 00071: val_mDice did not improve from 0.85252
Epoch 72/300
 - 58s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9312 - val_loss: 0.2006 - val_acc: 0.9938 - val_mDice: 0.8502

Epoch 00072: val_mDice did not improve from 0.85252
Epoch 73/300
 - 59s - loss: 0.0366 - acc: 0.9955 - mDice: 0.9315 - val_loss: 0.3083 - val_acc: 0.9928 - val_mDice: 0.8377

Epoch 00073: val_mDice did not improve from 0.85252
Epoch 74/300
 - 59s - loss: 0.0369 - acc: 0.9955 - mDice: 0.9310 - val_loss: 0.2998 - val_acc: 0.9932 - val_mDice: 0.8385

Epoch 00074: val_mDice did not improve from 0.85252
Epoch 75/300
 - 59s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.1155 - val_acc: 0.9934 - val_mDice: 0.8296

Epoch 00075: val_mDice did not improve from 0.85252
Epoch 76/300
 - 59s - loss: 0.0369 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.1165 - val_acc: 0.9936 - val_mDice: 0.8472

Epoch 00076: val_mDice did not improve from 0.85252
Epoch 77/300
 - 58s - loss: 0.0367 - acc: 0.9955 - mDice: 0.9314 - val_loss: 0.3139 - val_acc: 0.9927 - val_mDice: 0.8331

Epoch 00077: val_mDice did not improve from 0.85252
Epoch 78/300
 - 58s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9312 - val_loss: 0.1002 - val_acc: 0.9937 - val_mDice: 0.8475

Epoch 00078: val_mDice did not improve from 0.85252
Epoch 79/300
 - 58s - loss: 0.0364 - acc: 0.9955 - mDice: 0.9319 - val_loss: 0.1076 - val_acc: 0.9936 - val_mDice: 0.8452

Epoch 00079: val_mDice did not improve from 0.85252
Epoch 80/300
 - 57s - loss: 0.0364 - acc: 0.9955 - mDice: 0.9319 - val_loss: 0.3148 - val_acc: 0.9927 - val_mDice: 0.8379

Epoch 00080: val_mDice did not improve from 0.85252
Epoch 81/300
 - 57s - loss: 0.0362 - acc: 0.9955 - mDice: 0.9322 - val_loss: 0.2296 - val_acc: 0.9932 - val_mDice: 0.8370

Epoch 00081: val_mDice did not improve from 0.85252
Epoch 82/300
 - 58s - loss: 0.0366 - acc: 0.9955 - mDice: 0.9315 - val_loss: 0.1021 - val_acc: 0.9939 - val_mDice: 0.8472

Epoch 00082: val_mDice did not improve from 0.85252
Epoch 83/300
 - 57s - loss: 0.0361 - acc: 0.9955 - mDice: 0.9325 - val_loss: 0.3094 - val_acc: 0.9928 - val_mDice: 0.8372

Epoch 00083: val_mDice did not improve from 0.85252
Epoch 84/300
 - 59s - loss: 0.0361 - acc: 0.9955 - mDice: 0.9325 - val_loss: 0.2736 - val_acc: 0.9937 - val_mDice: 0.8456

Epoch 00084: val_mDice did not improve from 0.85252
Epoch 85/300
 - 59s - loss: 0.0362 - acc: 0.9955 - mDice: 0.9322 - val_loss: 0.2888 - val_acc: 0.9935 - val_mDice: 0.8422

Epoch 00085: val_mDice did not improve from 0.85252
Epoch 86/300
 - 59s - loss: 0.0358 - acc: 0.9956 - mDice: 0.9330 - val_loss: 0.3063 - val_acc: 0.9928 - val_mDice: 0.8388

Epoch 00086: val_mDice did not improve from 0.85252
Epoch 87/300
 - 60s - loss: 0.0357 - acc: 0.9956 - mDice: 0.9332 - val_loss: 0.3168 - val_acc: 0.9930 - val_mDice: 0.8399

Epoch 00087: val_mDice did not improve from 0.85252
Epoch 88/300
 - 61s - loss: 0.0357 - acc: 0.9956 - mDice: 0.9332 - val_loss: 0.1543 - val_acc: 0.9924 - val_mDice: 0.7994

Epoch 00088: val_mDice did not improve from 0.85252
Epoch 89/300
 - 60s - loss: 0.0356 - acc: 0.9956 - mDice: 0.9333 - val_loss: 0.2934 - val_acc: 0.9931 - val_mDice: 0.8415

Epoch 00089: val_mDice did not improve from 0.85252
Epoch 90/300
 - 58s - loss: 0.0357 - acc: 0.9956 - mDice: 0.9331 - val_loss: 0.1742 - val_acc: 0.9918 - val_mDice: 0.7749

Epoch 00090: val_mDice did not improve from 0.85252
Epoch 91/300
 - 59s - loss: 0.0356 - acc: 0.9956 - mDice: 0.9334 - val_loss: 0.2914 - val_acc: 0.9929 - val_mDice: 0.8323

Epoch 00091: val_mDice did not improve from 0.85252
Epoch 92/300
 - 59s - loss: 0.0353 - acc: 0.9956 - mDice: 0.9339 - val_loss: 0.1140 - val_acc: 0.9934 - val_mDice: 0.8365

Epoch 00092: val_mDice did not improve from 0.85252
Restoring model weights from the end of the best epoch
Epoch 00092: early stopping
{'val_loss': [0.3727547668386251, 0.36843579809647053, 0.3206850501592271, 0.3917105876025744, 0.32679349632235244, 0.2334272380103357, 0.2322528171353042, 0.22793872945476323, 0.25141489051748067, 0.22525910037802532, 0.19959271245170385, 0.417051279975567, 0.3155487762996927, 0.19932401113328524, 0.24860013357829303, 0.2137154549418483, 0.21283241600031033, 0.21385967289097607, 0.2003700980276335, 0.19276518109836616, 0.1944407082046382, 0.17624948246520944, 0.5149402549723163, 0.2260275832086336, 0.1918832988885697, 0.18830851936945692, 0.18023157675634138, 0.32927644049050286, 0.1811787203187123, 0.18594545067753643, 0.28656558532384224, 0.16454063850687817, 0.17228371984674595, 0.3010745265055448, 0.160549076681491, 0.30381652526557446, 0.3664788191090338, 0.150872324971715, 0.29553568272967823, 0.29088148195296526, 0.31947458049398847, 0.13973050148342736, 0.3280522239510901, 0.2680136021517683, 0.3328881046909373, 0.34620008131605573, 0.355696807266213, 0.11899783165426925, 0.1255992827937007, 0.12539544492028654, 0.12736467449576594, 0.2728952420584392, 0.262631810415769, 0.14644652212155052, 0.16227406915277243, 0.3418857959914021, 0.3472110925940797, 0.33278472829260863, 0.27609926150762476, 0.25794568116543815, 0.25344105911790393, 0.3120489591092337, 0.27321192077943124, 0.3578643550281413, 0.2743926393450238, 0.30667651662952267, 0.08520820451667532, 0.31262696522753686, 0.25820662145270035, 0.3128097588487435, 0.3019030065916013, 0.20058187501854263, 0.3083030768320896, 0.2997833537228871, 0.11545962511445396, 0.11646099927020259, 0.31388896532007493, 0.1001613883418031, 0.10761284286854789, 0.3148492126201745, 0.22964234472601674, 0.10210690254461952, 0.3094137165462598, 0.27360948905698024, 0.2887767802749295, 0.30628024926409125, 0.31679623608943075, 0.15429356857202947, 0.2933921781659592, 0.17422964781871997, 0.2914449370582588, 0.11399395790067501], 'val_acc': [0.9893678831867874, 0.9897068031132221, 0.991674579679966, 0.9875744013115764, 0.9913487415760756, 0.9928263830952346, 0.9928734730929136, 0.9927418888546526, 0.9917915090918541, 0.9926290242001414, 0.9929018435068429, 0.9851523148827255, 0.9915991411544383, 0.993038410320878, 0.9918070971034467, 0.9930374789983034, 0.9933068756945431, 0.9930144054815173, 0.9925819225609303, 0.9932273640297353, 0.9932657112367451, 0.9933820101432502, 0.9728545602411032, 0.9935432132333517, 0.9933916726149619, 0.993464641738683, 0.9934038263745606, 0.9915043381042778, 0.9924777774140239, 0.9932675738818944, 0.9932728805579245, 0.9936124193482101, 0.992586299777031, 0.9932304690591991, 0.9936302076093853, 0.9926779665984213, 0.9896466229110956, 0.9935506959445775, 0.9926333739422262, 0.9925242569297552, 0.9884633463807404, 0.993809184525162, 0.9917307109571993, 0.9934334503486753, 0.992133857216686, 0.990952136926353, 0.9902134891599417, 0.9935868545435369, 0.9936682404950261, 0.9936408014036715, 0.9933290062472224, 0.9935316820628941, 0.9934668140485883, 0.9933717190288007, 0.9932794133201241, 0.9915442373603582, 0.9909970560111105, 0.9915352128446102, 0.9931974257342517, 0.9933293275535107, 0.9935550568625331, 0.9928765743970871, 0.9935213816352189, 0.9905630210414529, 0.9932413911446929, 0.9908109046518803, 0.9929987941868603, 0.9927571485750377, 0.9936894583515823, 0.9928541383706033, 0.9934537257067859, 0.993834437802434, 0.9928014343604445, 0.9931939928792417, 0.9933561193756759, 0.9936411157250404, 0.9926938605494797, 0.9936595209874213, 0.993558507412672, 0.992728482466191, 0.9931702883914113, 0.9938805820420384, 0.9927923851646483, 0.993657018058002, 0.9934721114113927, 0.9928307440131903, 0.9929520427249372, 0.9924091971479356, 0.9931285250931978, 0.9917618813924491, 0.9928890592418611, 0.9933536513708532], 'val_mDice': [0.763544300571084, 0.7754583959467709, 0.7953385123983026, 0.7580217672511935, 0.8040391025133431, 0.8289295132271945, 0.8274392341263592, 0.8279354427941144, 0.7858689525164664, 0.8139809826388955, 0.8293572347611189, 0.7301258738152683, 0.8090331684798002, 0.8332677069120109, 0.7669983198866248, 0.829822348896414, 0.8263976429589093, 0.8260564878582954, 0.8291741367429495, 0.8308110758662224, 0.8319503394886851, 0.8364360081031919, 0.6195360037963837, 0.8399348706007004, 0.8379696751944721, 0.8417790522798896, 0.8396380580961704, 0.8174232207238674, 0.8306351373903453, 0.8266427204944193, 0.8416248019784689, 0.8409552625380456, 0.8379178820177913, 0.843666447326541, 0.8414274081587791, 0.8364874869585037, 0.7951991981826723, 0.8467634208500385, 0.8371418924070895, 0.8347739698365331, 0.6363012013025582, 0.8498227689415216, 0.8234674227423966, 0.8479985175654292, 0.8305033436045051, 0.8139311103150249, 0.8025070070289075, 0.8417520672082901, 0.8442140300758183, 0.8402565843425691, 0.8426550077274442, 0.8525224402546883, 0.8388141286559403, 0.8411879767663777, 0.8398531819693744, 0.8212597807869315, 0.8138154400512576, 0.8191319764591753, 0.8437600336037576, 0.8473639260046184, 0.8490653824992478, 0.8378331433050334, 0.8477019495330751, 0.808345596306026, 0.8427481632679701, 0.8086125948466361, 0.8201881661079824, 0.8385572931729257, 0.8462745579890907, 0.8379023871384561, 0.8478220202960074, 0.8502422366291285, 0.8376601152122021, 0.8385378052480519, 0.8296045707538724, 0.8472238550893962, 0.8331324672326446, 0.8474859641864896, 0.8451885776594281, 0.8379191742278636, 0.837035127915442, 0.8472381625324488, 0.8372284006327391, 0.8456030860543251, 0.8422420360147953, 0.8387844311073422, 0.8399305632337928, 0.7993510342203081, 0.841476081404835, 0.7749391254037619, 0.8322503766976297, 0.8364984998479486], 'loss': [0.28012079994143463, 0.10102750632993723, 0.08378104442987858, 0.07666223177339428, 0.07034013700205453, 0.06753382013217558, 0.06391874612835458, 0.06314097578728518, 0.06073077461606841, 0.05970698036058683, 0.05765132836268638, 0.056527507325747545, 0.055742767427916916, 0.05548317707227583, 0.05394844965628593, 0.053045779858332025, 0.05282850819193515, 0.05195316188734237, 0.05104918365117993, 0.05031953484903745, 0.04979985655288989, 0.04893241179461012, 0.04908755087976784, 0.04810804412966962, 0.04770837632926884, 0.04691969027561608, 0.046657205668492394, 0.04622715734836115, 0.04616665806800068, 0.0452548290766361, 0.044727440242408545, 0.04441963944749036, 0.044342094470749084, 0.0432712820045753, 0.043310203045334804, 0.043062305422003115, 0.04300789849403512, 0.041762423127339084, 0.042205017224296995, 0.04243693057223903, 0.0414519329303539, 0.04149221858386034, 0.04117645877092623, 0.04140894867257331, 0.040888529079364085, 0.04097567911248901, 0.04028716539106878, 0.041284091111246174, 0.04013660392202753, 0.03987528527190361, 0.04059579778162704, 0.039792561629836645, 0.03938177562955746, 0.03899262624842421, 0.03903617543282306, 0.03878285381256966, 0.038858572587689426, 0.03875587537903756, 0.038836687761934024, 0.03824462110149198, 0.03799058228667963, 0.03856264262096494, 0.038247586938970124, 0.03777626671409467, 0.03805256087388798, 0.03799339388536669, 0.04780669667911375, 0.03814704854470263, 0.03735195305940719, 0.03743869753471578, 0.03675538535147951, 0.03677292444972719, 0.03661985326750091, 0.036885972359727674, 0.03683003619424908, 0.03685187763489365, 0.036695980180915785, 0.036782644999415755, 0.03640409973524126, 0.03639862599615036, 0.03624668697993958, 0.03663907635645804, 0.03605326289551051, 0.036081646864365324, 0.03623291237951295, 0.03577279272922395, 0.035671229834028956, 0.03566611656059756, 0.03561328727575812, 0.03572578787084301, 0.03558513250185061, 0.035315186070522614], 'acc': [0.9639983806818415, 0.9895650909671915, 0.9910663883694653, 0.9917299275519029, 0.9923017239811612, 0.9925458557696878, 0.9928571677407391, 0.9929493607039289, 0.993183508503239, 0.9932679944896, 0.9934530805264448, 0.9935825579643138, 0.9936448109126388, 0.9937010859105179, 0.993830048152901, 0.9939136654917643, 0.9939322102924416, 0.9940180813613857, 0.9940840498528802, 0.9941769980852427, 0.994218203163291, 0.9943034860596669, 0.9942973412411462, 0.9943778539169288, 0.9944346851624996, 0.9945112645411389, 0.9945398261700272, 0.994571568666192, 0.9945776782496211, 0.9946777848010696, 0.99473105765558, 0.9947372538239834, 0.9947444050794308, 0.9948460422590439, 0.9948332191233825, 0.9948818154890141, 0.9948783404211888, 0.9949831416746237, 0.994941614501579, 0.9949369915163003, 0.9950206006281022, 0.9950221358337814, 0.9950456193713094, 0.9950159694088369, 0.9950671249445936, 0.9950846076925776, 0.995152344122794, 0.9950597932201043, 0.9951544341772874, 0.9951832306998607, 0.9951027198730895, 0.9952047744998952, 0.9952362030588737, 0.9952429493669989, 0.9952532159502365, 0.9952768472978653, 0.9952845345242065, 0.9952779039489527, 0.9952922119791809, 0.9953377732239466, 0.9953656917847143, 0.9952926275219612, 0.9953370118537292, 0.9953867106802222, 0.9953528932055848, 0.9953778019153076, 0.994459023171772, 0.9953143601981524, 0.9954005432375441, 0.9954152612565937, 0.9954478074701818, 0.9954566078151686, 0.9954707139776852, 0.9954776174309944, 0.9954717993542364, 0.9954573130363841, 0.9954727795725987, 0.9954657262870489, 0.9954949052848785, 0.9954905253787953, 0.9955278335512896, 0.9954856931228345, 0.9955345189251439, 0.9955389247935617, 0.9955030814188898, 0.9955622961438878, 0.9955611931428657, 0.9955544869451278, 0.995555136924534, 0.9955536428195364, 0.9955511294799606, 0.9955852989384809], 'mDice': [0.6622598318817433, 0.8238514272596302, 0.8508162803803363, 0.8623361834821017, 0.8728362400453931, 0.8775149022742017, 0.8836170969780028, 0.8849493162105955, 0.8890504424852044, 0.8908259345704813, 0.8943428116918399, 0.896284816814131, 0.8976450057011441, 0.8980879902950463, 0.9007705046045554, 0.9023328496283239, 0.9027041617248122, 0.9042310383215424, 0.9058164090690289, 0.907094715502227, 0.9079980628407623, 0.9095353595509933, 0.9092569171212007, 0.9109648041599399, 0.9116958515339645, 0.913062913057432, 0.9135494294365455, 0.914282827305575, 0.9143925333142183, 0.9160230048264834, 0.9169422580457057, 0.9174889667227776, 0.917630733091324, 0.9195347416133599, 0.919481050092833, 0.9199184901597706, 0.920020593227902, 0.9222415523605506, 0.921453082666755, 0.9210251901738941, 0.9227892685340952, 0.9227365186450732, 0.9232977508141269, 0.9228830632950712, 0.9238043169921542, 0.9236483377655222, 0.9248954558380807, 0.9231008517003938, 0.9251696153136929, 0.9256224732054392, 0.9243427381305532, 0.9257670670377263, 0.9265153569613958, 0.9272173730576649, 0.9271317651646609, 0.9275905065272236, 0.927454065754395, 0.9276425708624161, 0.9274890271091317, 0.9285671343104798, 0.9290129333696424, 0.9279972880341193, 0.9285502071453745, 0.9294087549209927, 0.9289171468634022, 0.9293921996460734, 0.9120012102565298, 0.9287512169505323, 0.9301742173742581, 0.930013107847666, 0.931263715877092, 0.9312313083116499, 0.9314996880203558, 0.9310185801169869, 0.9311359784350213, 0.9310835154336048, 0.931363319892203, 0.9312151007235666, 0.931894252534886, 0.9318992121440962, 0.9321729392419228, 0.9314638242788593, 0.932525438188717, 0.9324833649133049, 0.9322075278719945, 0.933032453357931, 0.9332144663380153, 0.9332322299902871, 0.9333309619853593, 0.9331213116881267, 0.9333775003044755, 0.9338672709850064]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.50s/it]predicting test subjects:  50%|█████     | 2/4 [00:01<00:02,  1.15s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:00,  1.11it/s]predicting test subjects: 100%|██████████| 4/4 [00:02<00:00,  1.24it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<02:15,  1.96it/s]predicting train subjects:   1%|          | 2/266 [00:01<02:34,  1.71it/s]predicting train subjects:   1%|          | 3/266 [00:01<02:26,  1.79it/s]predicting train subjects:   2%|▏         | 4/266 [00:02<02:18,  1.90it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<02:32,  1.71it/s]predicting train subjects:   2%|▏         | 6/266 [00:03<02:20,  1.85it/s]predicting train subjects:   3%|▎         | 7/266 [00:03<02:16,  1.89it/s]predicting train subjects:   3%|▎         | 8/266 [00:04<02:24,  1.78it/s]predicting train subjects:   3%|▎         | 9/266 [00:04<02:14,  1.91it/s]predicting train subjects:   4%|▍         | 10/266 [00:05<02:20,  1.82it/s]predicting train subjects:   4%|▍         | 11/266 [00:06<02:15,  1.89it/s]predicting train subjects:   5%|▍         | 12/266 [00:06<02:07,  1.99it/s]predicting train subjects:   5%|▍         | 13/266 [00:07<02:10,  1.94it/s]predicting train subjects:   5%|▌         | 14/266 [00:07<02:02,  2.06it/s]predicting train subjects:   6%|▌         | 15/266 [00:08<02:16,  1.84it/s]predicting train subjects:   6%|▌         | 16/266 [00:08<02:24,  1.72it/s]predicting train subjects:   6%|▋         | 17/266 [00:09<02:20,  1.77it/s]predicting train subjects:   7%|▋         | 18/266 [00:09<02:16,  1.81it/s]predicting train subjects:   7%|▋         | 19/266 [00:10<02:12,  1.87it/s]predicting train subjects:   8%|▊         | 20/266 [00:10<02:17,  1.79it/s]predicting train subjects:   8%|▊         | 21/266 [00:11<02:18,  1.76it/s]predicting train subjects:   8%|▊         | 22/266 [00:12<02:11,  1.85it/s]predicting train subjects:   9%|▊         | 23/266 [00:12<02:06,  1.92it/s]predicting train subjects:   9%|▉         | 24/266 [00:12<01:59,  2.03it/s]predicting train subjects:   9%|▉         | 25/266 [00:13<02:15,  1.78it/s]predicting train subjects:  10%|▉         | 26/266 [00:14<02:05,  1.91it/s]predicting train subjects:  10%|█         | 27/266 [00:14<02:14,  1.77it/s]predicting train subjects:  11%|█         | 28/266 [00:15<02:05,  1.89it/s]predicting train subjects:  11%|█         | 29/266 [00:15<02:11,  1.80it/s]predicting train subjects:  11%|█▏        | 30/266 [00:16<02:13,  1.76it/s]predicting train subjects:  12%|█▏        | 31/266 [00:16<02:04,  1.89it/s]predicting train subjects:  12%|█▏        | 32/266 [00:17<02:00,  1.94it/s]predicting train subjects:  12%|█▏        | 33/266 [00:17<01:54,  2.03it/s]predicting train subjects:  13%|█▎        | 34/266 [00:18<02:07,  1.82it/s]predicting train subjects:  13%|█▎        | 35/266 [00:18<02:02,  1.89it/s]predicting train subjects:  14%|█▎        | 36/266 [00:19<01:53,  2.03it/s]predicting train subjects:  14%|█▍        | 37/266 [00:19<01:54,  2.00it/s]predicting train subjects:  14%|█▍        | 38/266 [00:20<01:50,  2.06it/s]predicting train subjects:  15%|█▍        | 39/266 [00:20<01:50,  2.06it/s]predicting train subjects:  15%|█▌        | 40/266 [00:21<01:51,  2.03it/s]predicting train subjects:  15%|█▌        | 41/266 [00:21<01:47,  2.10it/s]predicting train subjects:  16%|█▌        | 42/266 [00:22<01:42,  2.19it/s]predicting train subjects:  16%|█▌        | 43/266 [00:22<01:53,  1.97it/s]predicting train subjects:  17%|█▋        | 44/266 [00:23<01:43,  2.14it/s]predicting train subjects:  17%|█▋        | 45/266 [00:23<01:45,  2.10it/s]predicting train subjects:  17%|█▋        | 46/266 [00:24<01:48,  2.03it/s]predicting train subjects:  18%|█▊        | 47/266 [00:24<01:44,  2.09it/s]predicting train subjects:  18%|█▊        | 48/266 [00:24<01:38,  2.22it/s]predicting train subjects:  18%|█▊        | 49/266 [00:25<01:37,  2.22it/s]predicting train subjects:  19%|█▉        | 50/266 [00:26<01:45,  2.06it/s]predicting train subjects:  19%|█▉        | 51/266 [00:26<01:49,  1.97it/s]predicting train subjects:  20%|█▉        | 52/266 [00:26<01:36,  2.22it/s]predicting train subjects:  20%|█▉        | 53/266 [00:27<01:37,  2.19it/s]predicting train subjects:  20%|██        | 54/266 [00:27<01:45,  2.02it/s]predicting train subjects:  21%|██        | 55/266 [00:28<01:41,  2.07it/s]predicting train subjects:  21%|██        | 56/266 [00:28<01:36,  2.17it/s]predicting train subjects:  21%|██▏       | 57/266 [00:29<01:45,  1.99it/s]predicting train subjects:  22%|██▏       | 58/266 [00:29<01:35,  2.18it/s]predicting train subjects:  22%|██▏       | 59/266 [00:30<01:35,  2.16it/s]predicting train subjects:  23%|██▎       | 60/266 [00:30<01:35,  2.16it/s]predicting train subjects:  23%|██▎       | 61/266 [00:31<01:25,  2.39it/s]predicting train subjects:  23%|██▎       | 62/266 [00:31<01:29,  2.27it/s]predicting train subjects:  24%|██▎       | 63/266 [00:32<01:35,  2.13it/s]predicting train subjects:  24%|██▍       | 64/266 [00:32<01:27,  2.31it/s]predicting train subjects:  24%|██▍       | 65/266 [00:32<01:29,  2.25it/s]predicting train subjects:  25%|██▍       | 66/266 [00:33<01:28,  2.25it/s]predicting train subjects:  25%|██▌       | 67/266 [00:33<01:21,  2.45it/s]predicting train subjects:  26%|██▌       | 68/266 [00:33<01:14,  2.64it/s]predicting train subjects:  26%|██▌       | 69/266 [00:34<01:16,  2.59it/s]predicting train subjects:  26%|██▋       | 70/266 [00:34<01:22,  2.37it/s]predicting train subjects:  27%|██▋       | 71/266 [00:35<01:24,  2.31it/s]predicting train subjects:  27%|██▋       | 72/266 [00:35<01:21,  2.39it/s]predicting train subjects:  27%|██▋       | 73/266 [00:36<01:24,  2.29it/s]predicting train subjects:  28%|██▊       | 74/266 [00:36<01:26,  2.23it/s]predicting train subjects:  28%|██▊       | 75/266 [00:37<01:26,  2.20it/s]predicting train subjects:  29%|██▊       | 76/266 [00:37<01:25,  2.22it/s]predicting train subjects:  29%|██▉       | 77/266 [00:37<01:22,  2.28it/s]predicting train subjects:  29%|██▉       | 78/266 [00:38<01:28,  2.12it/s]predicting train subjects:  30%|██▉       | 79/266 [00:39<01:37,  1.92it/s]predicting train subjects:  30%|███       | 80/266 [00:39<01:32,  2.00it/s]predicting train subjects:  30%|███       | 81/266 [00:40<01:30,  2.04it/s]predicting train subjects:  31%|███       | 82/266 [00:40<01:33,  1.97it/s]predicting train subjects:  31%|███       | 83/266 [00:41<01:37,  1.87it/s]predicting train subjects:  32%|███▏      | 84/266 [00:41<01:32,  1.96it/s]predicting train subjects:  32%|███▏      | 85/266 [00:42<01:38,  1.84it/s]predicting train subjects:  32%|███▏      | 86/266 [00:42<01:41,  1.77it/s]predicting train subjects:  33%|███▎      | 87/266 [00:43<01:39,  1.80it/s]predicting train subjects:  33%|███▎      | 88/266 [00:43<01:26,  2.05it/s]predicting train subjects:  33%|███▎      | 89/266 [00:44<01:25,  2.07it/s]predicting train subjects:  34%|███▍      | 90/266 [00:44<01:31,  1.92it/s]predicting train subjects:  34%|███▍      | 91/266 [00:45<01:27,  2.01it/s]predicting train subjects:  35%|███▍      | 92/266 [00:45<01:25,  2.03it/s]predicting train subjects:  35%|███▍      | 93/266 [00:46<01:20,  2.14it/s]predicting train subjects:  35%|███▌      | 94/266 [00:46<01:28,  1.93it/s]predicting train subjects:  36%|███▌      | 95/266 [00:47<01:31,  1.87it/s]predicting train subjects:  36%|███▌      | 96/266 [00:47<01:25,  1.99it/s]predicting train subjects:  36%|███▋      | 97/266 [00:48<01:26,  1.96it/s]predicting train subjects:  37%|███▋      | 98/266 [00:48<01:23,  2.01it/s]predicting train subjects:  37%|███▋      | 99/266 [00:49<01:28,  1.89it/s]predicting train subjects:  38%|███▊      | 100/266 [00:49<01:18,  2.11it/s]predicting train subjects:  38%|███▊      | 101/266 [00:50<01:14,  2.23it/s]predicting train subjects:  38%|███▊      | 102/266 [00:50<01:13,  2.23it/s]predicting train subjects:  39%|███▊      | 103/266 [00:51<01:18,  2.08it/s]predicting train subjects:  39%|███▉      | 104/266 [00:51<01:19,  2.04it/s]predicting train subjects:  39%|███▉      | 105/266 [00:52<01:15,  2.14it/s]predicting train subjects:  40%|███▉      | 106/266 [00:52<01:20,  1.98it/s]predicting train subjects:  40%|████      | 107/266 [00:53<01:19,  2.01it/s]predicting train subjects:  41%|████      | 108/266 [00:53<01:20,  1.96it/s]predicting train subjects:  41%|████      | 109/266 [00:54<01:13,  2.14it/s]predicting train subjects:  41%|████▏     | 110/266 [00:54<01:18,  1.99it/s]predicting train subjects:  42%|████▏     | 111/266 [00:55<01:22,  1.88it/s]predicting train subjects:  42%|████▏     | 112/266 [00:55<01:22,  1.87it/s]predicting train subjects:  42%|████▏     | 113/266 [00:56<01:14,  2.06it/s]predicting train subjects:  43%|████▎     | 114/266 [00:56<01:13,  2.08it/s]predicting train subjects:  43%|████▎     | 115/266 [00:57<01:17,  1.96it/s]predicting train subjects:  44%|████▎     | 116/266 [00:57<01:18,  1.92it/s]predicting train subjects:  44%|████▍     | 117/266 [00:58<01:12,  2.07it/s]predicting train subjects:  44%|████▍     | 118/266 [00:58<01:08,  2.15it/s]predicting train subjects:  45%|████▍     | 119/266 [00:59<01:17,  1.89it/s]predicting train subjects:  45%|████▌     | 120/266 [00:59<01:20,  1.82it/s]predicting train subjects:  45%|████▌     | 121/266 [01:00<01:22,  1.77it/s]predicting train subjects:  46%|████▌     | 122/266 [01:01<01:23,  1.72it/s]predicting train subjects:  46%|████▌     | 123/266 [01:01<01:17,  1.85it/s]predicting train subjects:  47%|████▋     | 124/266 [01:02<01:17,  1.84it/s]predicting train subjects:  47%|████▋     | 125/266 [01:02<01:20,  1.76it/s]predicting train subjects:  47%|████▋     | 126/266 [01:03<01:14,  1.88it/s]predicting train subjects:  48%|████▊     | 127/266 [01:03<01:15,  1.85it/s]predicting train subjects:  48%|████▊     | 128/266 [01:04<01:18,  1.75it/s]predicting train subjects:  48%|████▊     | 129/266 [01:04<01:12,  1.88it/s]predicting train subjects:  49%|████▉     | 130/266 [01:05<01:17,  1.75it/s]predicting train subjects:  49%|████▉     | 131/266 [01:06<01:16,  1.75it/s]predicting train subjects:  50%|████▉     | 132/266 [01:06<01:12,  1.86it/s]predicting train subjects:  50%|█████     | 133/266 [01:07<01:14,  1.78it/s]predicting train subjects:  50%|█████     | 134/266 [01:07<01:13,  1.80it/s]predicting train subjects:  51%|█████     | 135/266 [01:08<01:08,  1.90it/s]predicting train subjects:  51%|█████     | 136/266 [01:08<01:07,  1.92it/s]predicting train subjects:  52%|█████▏    | 137/266 [01:09<01:07,  1.91it/s]predicting train subjects:  52%|█████▏    | 138/266 [01:09<01:04,  1.98it/s]predicting train subjects:  52%|█████▏    | 139/266 [01:09<00:59,  2.13it/s]predicting train subjects:  53%|█████▎    | 140/266 [01:10<01:03,  1.98it/s]predicting train subjects:  53%|█████▎    | 141/266 [01:11<01:04,  1.95it/s]predicting train subjects:  53%|█████▎    | 142/266 [01:11<01:00,  2.03it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:12<01:01,  1.99it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:12<01:01,  2.00it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:13<01:00,  1.99it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:13<01:00,  2.00it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:14<01:00,  1.96it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:14<00:58,  2.00it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:14<00:54,  2.14it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:15<01:00,  1.92it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:16<01:00,  1.91it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:16<00:55,  2.04it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:16<00:52,  2.15it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:17<00:55,  2.02it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:18<00:55,  1.99it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:18<00:47,  2.31it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:18<00:44,  2.45it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:19<00:46,  2.33it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:19<00:48,  2.19it/s]predicting train subjects:  60%|██████    | 160/266 [01:20<00:47,  2.22it/s]predicting train subjects:  61%|██████    | 161/266 [01:20<00:43,  2.41it/s]predicting train subjects:  61%|██████    | 162/266 [01:20<00:37,  2.77it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:21<00:39,  2.59it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:21<00:39,  2.56it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:22<00:43,  2.31it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:22<00:43,  2.30it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:22<00:37,  2.62it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:23<00:39,  2.48it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:23<00:39,  2.47it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:24<00:39,  2.46it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:24<00:38,  2.48it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:24<00:36,  2.54it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:25<00:39,  2.36it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:25<00:41,  2.21it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:26<00:44,  2.07it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:26<00:40,  2.24it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:27<00:40,  2.17it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:27<00:39,  2.26it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:28<00:42,  2.02it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:28<00:38,  2.21it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:28<00:34,  2.44it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:29<00:38,  2.16it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:30<00:40,  2.04it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:30<00:39,  2.09it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:30<00:36,  2.21it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:31<00:38,  2.10it/s]predicting train subjects:  70%|███████   | 187/266 [01:32<00:41,  1.91it/s]predicting train subjects:  71%|███████   | 188/266 [01:32<00:38,  2.01it/s]predicting train subjects:  71%|███████   | 189/266 [01:32<00:33,  2.31it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:33<00:34,  2.19it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:33<00:34,  2.17it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:34<00:35,  2.06it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:34<00:32,  2.27it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:35<00:33,  2.17it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:35<00:33,  2.14it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:36<00:34,  2.03it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:36<00:30,  2.26it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:36<00:28,  2.36it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:37<00:30,  2.18it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:37<00:31,  2.11it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:38<00:30,  2.11it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:38<00:28,  2.28it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:39<00:27,  2.32it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:39<00:29,  2.08it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:40<00:30,  2.03it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:40<00:27,  2.20it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:41<00:25,  2.27it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:41<00:24,  2.35it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:41<00:25,  2.27it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:42<00:24,  2.33it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:42<00:23,  2.30it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:43<00:24,  2.17it/s]predicting train subjects:  80%|████████  | 213/266 [01:43<00:23,  2.25it/s]predicting train subjects:  80%|████████  | 214/266 [01:44<00:21,  2.41it/s]predicting train subjects:  81%|████████  | 215/266 [01:44<00:22,  2.24it/s]predicting train subjects:  81%|████████  | 216/266 [01:45<00:24,  2.01it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:45<00:21,  2.25it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:45<00:21,  2.22it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:46<00:23,  2.03it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:47<00:23,  1.96it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:47<00:21,  2.12it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:48<00:21,  2.07it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:48<00:22,  1.94it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:49<00:21,  1.99it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:49<00:18,  2.16it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:49<00:18,  2.16it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:50<00:19,  2.03it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:50<00:18,  2.04it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:51<00:16,  2.30it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:51<00:14,  2.48it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:52<00:19,  1.84it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:53<00:19,  1.78it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:53<00:17,  1.85it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:54<00:18,  1.75it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:54<00:17,  1.74it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:55<00:15,  1.94it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:55<00:14,  1.99it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:56<00:14,  1.91it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:56<00:13,  1.99it/s]predicting train subjects:  90%|█████████ | 240/266 [01:57<00:12,  2.15it/s]predicting train subjects:  91%|█████████ | 241/266 [01:57<00:13,  1.79it/s]predicting train subjects:  91%|█████████ | 242/266 [01:58<00:12,  1.89it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:58<00:11,  1.97it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:59<00:10,  2.19it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:59<00:11,  1.90it/s]predicting train subjects:  92%|█████████▏| 246/266 [02:00<00:10,  1.93it/s]predicting train subjects:  93%|█████████▎| 247/266 [02:00<00:08,  2.15it/s]predicting train subjects:  93%|█████████▎| 248/266 [02:01<00:10,  1.78it/s]predicting train subjects:  94%|█████████▎| 249/266 [02:02<00:10,  1.59it/s]predicting train subjects:  94%|█████████▍| 250/266 [02:02<00:09,  1.75it/s]predicting train subjects:  94%|█████████▍| 251/266 [02:03<00:08,  1.73it/s]predicting train subjects:  95%|█████████▍| 252/266 [02:03<00:07,  1.80it/s]predicting train subjects:  95%|█████████▌| 253/266 [02:04<00:07,  1.74it/s]predicting train subjects:  95%|█████████▌| 254/266 [02:04<00:06,  1.87it/s]predicting train subjects:  96%|█████████▌| 255/266 [02:05<00:05,  1.86it/s]predicting train subjects:  96%|█████████▌| 256/266 [02:05<00:05,  1.77it/s]predicting train subjects:  97%|█████████▋| 257/266 [02:06<00:05,  1.76it/s]predicting train subjects:  97%|█████████▋| 258/266 [02:07<00:04,  1.73it/s]predicting train subjects:  97%|█████████▋| 259/266 [02:07<00:04,  1.65it/s]predicting train subjects:  98%|█████████▊| 260/266 [02:08<00:03,  1.79it/s]predicting train subjects:  98%|█████████▊| 261/266 [02:08<00:02,  1.79it/s]predicting train subjects:  98%|█████████▊| 262/266 [02:09<00:02,  1.74it/s]predicting train subjects:  99%|█████████▉| 263/266 [02:09<00:01,  1.82it/s]predicting train subjects:  99%|█████████▉| 264/266 [02:10<00:01,  1.72it/s]predicting train subjects: 100%|█████████▉| 265/266 [02:11<00:00,  1.48it/s]predicting train subjects: 100%|██████████| 266/266 [02:11<00:00,  1.58it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:01,  1.68it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:01<00:01,  1.67it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:01<00:00,  1.92it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:02<00:00,  1.83it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<02:32,  1.74it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:01<02:26,  1.81it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<02:20,  1.88it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:02<02:28,  1.76it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:02<02:20,  1.86it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:03<02:30,  1.73it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:03<02:30,  1.72it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:04<02:17,  1.88it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:04<02:17,  1.87it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:05<02:11,  1.95it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:06<02:22,  1.79it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:06<02:21,  1.80it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:07<02:32,  1.66it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:07<02:27,  1.71it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:08<02:22,  1.76it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:09<02:44,  1.52it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:09<02:35,  1.60it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:10<02:28,  1.67it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:10<02:31,  1.63it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:11<02:23,  1.72it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:12<02:28,  1.64it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:12<02:31,  1.61it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:13<02:26,  1.66it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:13<02:25,  1.66it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:14<02:17,  1.75it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:14<02:12,  1.82it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:15<02:10,  1.84it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:16<02:22,  1.67it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:17<02:41,  1.47it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:17<02:26,  1.61it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:18<02:28,  1.58it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:18<02:18,  1.69it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:19<02:21,  1.65it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:20<02:25,  1.59it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:20<02:14,  1.71it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:21<02:15,  1.70it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:21<02:14,  1.71it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:22<02:12,  1.72it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:22<02:04,  1.82it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:23<02:00,  1.88it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:24<02:19,  1.61it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:24<02:09,  1.73it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:25<02:14,  1.66it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:25<02:05,  1.77it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:26<01:53,  1.95it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:26<01:53,  1.93it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:27<01:58,  1.85it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:27<02:01,  1.79it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:28<01:45,  2.06it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:28<01:45,  2.04it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:29<01:56,  1.85it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:29<01:53,  1.88it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:30<01:55,  1.85it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:30<02:00,  1.76it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:31<01:45,  2.00it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:31<01:51,  1.88it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:32<01:59,  1.75it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:32<01:49,  1.90it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:33<01:51,  1.85it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:34<01:54,  1.79it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:34<01:52,  1.82it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:35<01:41,  2.02it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:35<01:48,  1.87it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:36<01:55,  1.75it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:36<01:51,  1.80it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:37<01:41,  1.97it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:37<01:45,  1.89it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:38<01:48,  1.83it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:38<01:40,  1.95it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:39<01:39,  1.97it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:40<01:54,  1.71it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:40<01:40,  1.92it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:40<01:35,  2.03it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:41<01:39,  1.92it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:42<01:43,  1.84it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:42<01:38,  1.94it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:42<01:32,  2.04it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:43<01:40,  1.88it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:44<01:35,  1.95it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:44<01:48,  1.72it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:45<01:50,  1.67it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:45<01:44,  1.77it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:46<01:51,  1.65it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:47<01:48,  1.68it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:47<01:44,  1.74it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:48<01:57,  1.53it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:49<01:56,  1.54it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:49<01:44,  1.70it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:50<01:47,  1.65it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:50<01:49,  1.61it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:51<01:40,  1.74it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:52<01:41,  1.72it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:52<01:42,  1.68it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:53<01:38,  1.74it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:53<01:37,  1.75it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:54<01:47,  1.59it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:55<01:39,  1.70it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:55<01:31,  1.84it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:55<01:29,  1.87it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:56<01:27,  1.89it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:56<01:25,  1.93it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:57<01:17,  2.12it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:57<01:22,  1.98it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:58<01:25,  1.90it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:58<01:19,  2.02it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:59<01:13,  2.16it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:59<01:13,  2.15it/s]predicting train subjects sagittal:  41%|████      | 108/266 [01:00<01:14,  2.12it/s]predicting train subjects sagittal:  41%|████      | 109/266 [01:00<01:12,  2.16it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [01:01<01:08,  2.27it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [01:01<01:10,  2.19it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [01:02<01:15,  2.03it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [01:02<01:11,  2.14it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [01:03<01:14,  2.03it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [01:03<01:29,  1.70it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [01:04<01:17,  1.93it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [01:04<01:17,  1.93it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [01:05<01:20,  1.85it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [01:06<01:24,  1.73it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [01:06<01:24,  1.74it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [01:07<01:26,  1.68it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [01:07<01:24,  1.70it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [01:08<01:18,  1.83it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [01:08<01:12,  1.96it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [01:09<01:16,  1.85it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [01:09<01:18,  1.78it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [01:10<01:14,  1.86it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [01:10<01:13,  1.89it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [01:11<01:13,  1.85it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [01:12<01:15,  1.81it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [01:12<01:09,  1.94it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [01:13<01:17,  1.73it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [01:13<01:14,  1.79it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [01:14<01:17,  1.70it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [01:15<01:25,  1.53it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [01:15<01:17,  1.68it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [01:16<01:19,  1.61it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [01:16<01:17,  1.64it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [01:17<01:18,  1.61it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [01:18<01:13,  1.72it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [01:18<01:09,  1.79it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [01:19<01:04,  1.94it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [01:19<01:09,  1.77it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [01:20<01:07,  1.81it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [01:20<01:02,  1.93it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [01:21<01:06,  1.79it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [01:21<01:03,  1.87it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [01:22<01:00,  1.95it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [01:22<01:06,  1.76it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [01:23<01:06,  1.73it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [01:24<01:10,  1.63it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [01:24<01:08,  1.67it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [01:25<01:16,  1.48it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [01:26<01:09,  1.60it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [01:26<01:06,  1.67it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [01:27<01:02,  1.75it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [01:27<00:59,  1.84it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [01:28<00:53,  2.02it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [01:28<00:54,  1.96it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [01:29<00:56,  1.88it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [01:29<00:49,  2.13it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [01:29<00:46,  2.24it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [01:30<00:54,  1.89it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [01:31<00:50,  2.02it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [01:31<00:46,  2.18it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [01:31<00:46,  2.15it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [01:32<00:49,  1.98it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [01:32<00:44,  2.19it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [01:33<00:39,  2.45it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [01:33<00:44,  2.17it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [01:34<00:42,  2.23it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [01:34<00:41,  2.28it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [01:35<00:41,  2.26it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [01:35<00:44,  2.08it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [01:36<00:47,  1.92it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [01:36<00:48,  1.84it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [01:37<00:49,  1.78it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [01:37<00:44,  1.97it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [01:38<00:42,  2.04it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [01:38<00:41,  2.09it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [01:39<00:42,  2.00it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [01:39<00:44,  1.90it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [01:40<00:40,  2.02it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [01:40<00:38,  2.13it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [01:41<00:40,  1.99it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [01:41<00:41,  1.95it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [01:42<00:39,  1.99it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [01:42<00:36,  2.13it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [01:43<00:37,  2.04it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [01:43<00:40,  1.87it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [01:44<00:42,  1.78it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [01:44<00:37,  1.98it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [01:45<00:39,  1.86it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [01:46<00:41,  1.72it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [01:46<00:36,  1.94it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [01:46<00:35,  1.99it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [01:47<00:35,  1.95it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [01:47<00:32,  2.07it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [01:48<00:34,  1.95it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [01:49<00:39,  1.68it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [01:49<00:34,  1.88it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [01:50<00:37,  1.72it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [01:50<00:38,  1.65it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [01:51<00:31,  1.95it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [01:51<00:31,  1.94it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [01:52<00:35,  1.71it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [01:52<00:30,  1.93it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [01:53<00:32,  1.79it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [01:54<00:31,  1.84it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [01:54<00:28,  1.97it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [01:54<00:27,  2.00it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [01:55<00:26,  2.00it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [01:56<00:27,  1.93it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [01:56<00:26,  1.95it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:57<00:26,  1.95it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:57<00:26,  1.92it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:58<00:25,  1.94it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:58<00:24,  1.98it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:59<00:22,  2.09it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:59<00:24,  1.91it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [02:00<00:24,  1.84it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [02:00<00:22,  1.92it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [02:01<00:22,  1.95it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [02:01<00:24,  1.68it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [02:02<00:23,  1.74it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [02:02<00:20,  1.98it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [02:03<00:18,  2.11it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [02:03<00:19,  1.96it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [02:04<00:17,  2.08it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [02:04<00:18,  1.98it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [02:05<00:19,  1.76it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [02:05<00:17,  1.89it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [02:06<00:16,  1.98it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [02:06<00:15,  2.04it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [02:07<00:14,  2.09it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [02:07<00:13,  2.27it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [02:08<00:12,  2.29it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [02:08<00:13,  2.06it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [02:09<00:13,  1.99it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [02:09<00:12,  2.14it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [02:10<00:11,  2.10it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [02:10<00:11,  2.06it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [02:11<00:11,  2.09it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [02:11<00:10,  2.09it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [02:12<00:10,  2.08it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [02:12<00:09,  2.09it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [02:12<00:08,  2.13it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [02:13<00:08,  2.08it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [02:14<00:09,  1.81it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [02:14<00:09,  1.75it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [02:15<00:09,  1.66it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [02:15<00:07,  1.76it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [02:16<00:07,  1.81it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [02:16<00:06,  1.87it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [02:17<00:06,  1.77it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [02:18<00:06,  1.67it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [02:18<00:04,  1.85it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [02:19<00:04,  1.86it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [02:20<00:04,  1.64it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [02:20<00:03,  1.63it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [02:21<00:03,  1.55it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [02:21<00:02,  1.66it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [02:22<00:01,  1.59it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [02:23<00:01,  1.62it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [02:23<00:00,  1.76it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [02:24<00:00,  1.77it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS:  75%|███████▌  | 3/4 [00:00<00:00, 27.51it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 21.43it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   1%|          | 3/266 [00:00<00:09, 28.98it/s]saving BB  train1-THALAMUS:   4%|▍         | 10/266 [00:00<00:07, 34.55it/s]saving BB  train1-THALAMUS:   6%|▌         | 16/266 [00:00<00:06, 38.11it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:06, 38.96it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:05, 42.63it/s]saving BB  train1-THALAMUS:  12%|█▏        | 32/266 [00:00<00:05, 43.19it/s]saving BB  train1-THALAMUS:  14%|█▍        | 37/266 [00:00<00:05, 44.92it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:04, 45.02it/s]saving BB  train1-THALAMUS:  18%|█▊        | 49/266 [00:00<00:04, 49.52it/s]saving BB  train1-THALAMUS:  21%|██▏       | 57/266 [00:01<00:03, 54.87it/s]saving BB  train1-THALAMUS:  24%|██▍       | 65/266 [00:01<00:03, 60.09it/s]saving BB  train1-THALAMUS:  27%|██▋       | 72/266 [00:01<00:03, 57.97it/s]saving BB  train1-THALAMUS:  30%|██▉       | 79/266 [00:01<00:03, 55.52it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:03, 52.60it/s]saving BB  train1-THALAMUS:  34%|███▍      | 91/266 [00:01<00:03, 50.76it/s]saving BB  train1-THALAMUS:  36%|███▋      | 97/266 [00:01<00:03, 48.30it/s]saving BB  train1-THALAMUS:  38%|███▊      | 102/266 [00:01<00:03, 48.02it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:02<00:03, 46.03it/s]saving BB  train1-THALAMUS:  43%|████▎     | 115/266 [00:02<00:02, 51.81it/s]saving BB  train1-THALAMUS:  45%|████▌     | 121/266 [00:02<00:02, 51.15it/s]saving BB  train1-THALAMUS:  48%|████▊     | 127/266 [00:02<00:02, 48.42it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:02<00:02, 45.91it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 139/266 [00:02<00:02, 46.95it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 144/266 [00:02<00:02, 45.47it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:02, 45.56it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 154/266 [00:03<00:02, 42.88it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:03<00:02, 47.97it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 170/266 [00:03<00:01, 55.11it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 179/266 [00:03<00:01, 60.27it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:03<00:01, 59.15it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:03<00:01, 59.32it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 200/266 [00:03<00:01, 55.76it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 206/266 [00:03<00:01, 56.06it/s]saving BB  train1-THALAMUS:  80%|███████▉  | 212/266 [00:04<00:01, 44.61it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:04<00:01, 47.74it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:04<00:00, 53.93it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 233/266 [00:04<00:00, 57.67it/s]saving BB  train1-THALAMUS:  90%|█████████ | 240/266 [00:04<00:00, 56.39it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 246/266 [00:04<00:00, 56.81it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 252/266 [00:04<00:00, 54.60it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 259/266 [00:04<00:00, 56.51it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 265/266 [00:05<00:00, 53.04it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:05<00:00, 52.74it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 45.61it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   2%|▏         | 5/266 [00:00<00:05, 44.85it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 9/266 [00:00<00:06, 41.91it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:05, 42.64it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:05, 47.16it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 28/266 [00:00<00:04, 52.24it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 34/266 [00:00<00:04, 51.91it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 39/266 [00:00<00:04, 50.66it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 44/266 [00:00<00:04, 49.45it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▉        | 50/266 [00:00<00:04, 51.48it/s]saving BB  train1-THALAMUS Sagittal:  21%|██▏       | 57/266 [00:01<00:03, 55.58it/s]saving BB  train1-THALAMUS Sagittal:  24%|██▍       | 64/266 [00:01<00:03, 56.96it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:01<00:04, 48.70it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 78/266 [00:01<00:03, 54.34it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 86/266 [00:01<00:03, 57.94it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 93/266 [00:01<00:03, 53.68it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 99/266 [00:01<00:03, 50.37it/s]saving BB  train1-THALAMUS Sagittal:  40%|███▉      | 106/266 [00:01<00:02, 53.46it/s]saving BB  train1-THALAMUS Sagittal:  43%|████▎     | 114/266 [00:02<00:02, 58.67it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 121/266 [00:02<00:02, 60.33it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 128/266 [00:02<00:02, 57.61it/s]saving BB  train1-THALAMUS Sagittal:  50%|█████     | 134/266 [00:02<00:02, 54.40it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 141/266 [00:02<00:02, 58.23it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▌    | 149/266 [00:02<00:01, 61.56it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▉    | 157/266 [00:02<00:01, 65.13it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 164/266 [00:02<00:01, 61.17it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 171/266 [00:03<00:01, 58.63it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 178/266 [00:03<00:01, 57.15it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 184/266 [00:03<00:01, 55.01it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████▏  | 190/266 [00:03<00:01, 50.15it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 197/266 [00:03<00:01, 54.56it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 204/266 [00:03<00:01, 58.10it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 211/266 [00:03<00:00, 55.22it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 217/266 [00:03<00:00, 51.18it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 223/266 [00:04<00:00, 51.07it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 229/266 [00:04<00:00, 50.91it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 235/266 [00:04<00:00, 43.95it/s]saving BB  train1-THALAMUS Sagittal:  90%|█████████ | 240/266 [00:04<00:00, 45.33it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 248/266 [00:04<00:00, 52.01it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 255/266 [00:04<00:00, 54.53it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 261/266 [00:04<00:00, 52.71it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:04<00:00, 54.62it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<09:43,  2.20s/it]Loading train:   1%|          | 2/266 [00:05<10:35,  2.41s/it]Loading train:   1%|          | 3/266 [00:07<10:25,  2.38s/it]Loading train:   2%|▏         | 4/266 [00:08<09:21,  2.14s/it]Loading train:   2%|▏         | 5/266 [00:11<09:45,  2.24s/it]Loading train:   2%|▏         | 6/266 [00:14<10:12,  2.35s/it]Loading train:   3%|▎         | 7/266 [00:16<09:38,  2.23s/it]Loading train:   3%|▎         | 8/266 [00:17<08:47,  2.05s/it]Loading train:   3%|▎         | 9/266 [00:19<08:15,  1.93s/it]Loading train:   4%|▍         | 10/266 [00:21<08:50,  2.07s/it]Loading train:   4%|▍         | 11/266 [00:23<08:28,  2.00s/it]Loading train:   5%|▍         | 12/266 [00:25<08:17,  1.96s/it]Loading train:   5%|▍         | 13/266 [00:27<08:06,  1.92s/it]Loading train:   5%|▌         | 14/266 [00:28<07:18,  1.74s/it]Loading train:   6%|▌         | 15/266 [00:30<07:46,  1.86s/it]Loading train:   6%|▌         | 16/266 [00:32<08:10,  1.96s/it]Loading train:   6%|▋         | 17/266 [00:35<08:35,  2.07s/it]Loading train:   7%|▋         | 18/266 [00:37<08:31,  2.06s/it]Loading train:   7%|▋         | 19/266 [00:39<08:32,  2.08s/it]Loading train:   8%|▊         | 20/266 [00:41<08:12,  2.00s/it]Loading train:   8%|▊         | 21/266 [00:43<08:08,  1.99s/it]Loading train:   8%|▊         | 22/266 [00:45<08:46,  2.16s/it]Loading train:   9%|▊         | 23/266 [00:47<08:44,  2.16s/it]Loading train:   9%|▉         | 24/266 [00:49<08:35,  2.13s/it]Loading train:   9%|▉         | 25/266 [00:51<08:14,  2.05s/it]Loading train:  10%|▉         | 26/266 [00:53<08:04,  2.02s/it]Loading train:  10%|█         | 27/266 [00:56<08:27,  2.12s/it]Loading train:  11%|█         | 28/266 [00:57<07:47,  1.96s/it]Loading train:  11%|█         | 29/266 [00:59<07:37,  1.93s/it]Loading train:  11%|█▏        | 30/266 [01:01<07:14,  1.84s/it]Loading train:  12%|█▏        | 31/266 [01:03<07:23,  1.89s/it]Loading train:  12%|█▏        | 32/266 [01:05<07:20,  1.88s/it]Loading train:  12%|█▏        | 33/266 [01:06<06:56,  1.79s/it]Loading train:  13%|█▎        | 34/266 [01:08<07:22,  1.91s/it]Loading train:  13%|█▎        | 35/266 [01:10<07:18,  1.90s/it]Loading train:  14%|█▎        | 36/266 [01:12<07:21,  1.92s/it]Loading train:  14%|█▍        | 37/266 [01:14<07:28,  1.96s/it]Loading train:  14%|█▍        | 38/266 [01:16<06:51,  1.80s/it]Loading train:  15%|█▍        | 39/266 [01:17<06:36,  1.74s/it]Loading train:  15%|█▌        | 40/266 [01:19<06:44,  1.79s/it]Loading train:  15%|█▌        | 41/266 [01:21<07:12,  1.92s/it]Loading train:  16%|█▌        | 42/266 [01:23<07:07,  1.91s/it]Loading train:  16%|█▌        | 43/266 [01:25<07:06,  1.91s/it]Loading train:  17%|█▋        | 44/266 [01:27<06:38,  1.79s/it]Loading train:  17%|█▋        | 45/266 [01:28<05:57,  1.62s/it]Loading train:  17%|█▋        | 46/266 [01:30<06:04,  1.66s/it]Loading train:  18%|█▊        | 47/266 [01:31<05:44,  1.57s/it]Loading train:  18%|█▊        | 48/266 [01:33<05:52,  1.62s/it]Loading train:  18%|█▊        | 49/266 [01:34<05:47,  1.60s/it]Loading train:  19%|█▉        | 50/266 [01:36<06:10,  1.72s/it]Loading train:  19%|█▉        | 51/266 [01:38<05:47,  1.62s/it]Loading train:  20%|█▉        | 52/266 [01:39<05:54,  1.66s/it]Loading train:  20%|█▉        | 53/266 [01:41<05:57,  1.68s/it]Loading train:  20%|██        | 54/266 [01:43<05:59,  1.70s/it]Loading train:  21%|██        | 55/266 [01:44<05:29,  1.56s/it]Loading train:  21%|██        | 56/266 [01:45<05:03,  1.44s/it]Loading train:  21%|██▏       | 57/266 [01:47<05:24,  1.55s/it]Loading train:  22%|██▏       | 58/266 [01:48<05:10,  1.49s/it]Loading train:  22%|██▏       | 59/266 [01:50<05:20,  1.55s/it]Loading train:  23%|██▎       | 60/266 [01:52<05:08,  1.50s/it]Loading train:  23%|██▎       | 61/266 [01:53<05:22,  1.57s/it]Loading train:  23%|██▎       | 62/266 [01:55<05:07,  1.51s/it]Loading train:  24%|██▎       | 63/266 [01:56<05:17,  1.57s/it]Loading train:  24%|██▍       | 64/266 [01:58<05:29,  1.63s/it]Loading train:  24%|██▍       | 65/266 [02:00<05:48,  1.74s/it]Loading train:  25%|██▍       | 66/266 [02:02<05:45,  1.73s/it]Loading train:  25%|██▌       | 67/266 [02:03<05:31,  1.66s/it]Loading train:  26%|██▌       | 68/266 [02:05<05:32,  1.68s/it]Loading train:  26%|██▌       | 69/266 [02:07<05:19,  1.62s/it]Loading train:  26%|██▋       | 70/266 [02:08<05:13,  1.60s/it]Loading train:  27%|██▋       | 71/266 [02:09<04:58,  1.53s/it]Loading train:  27%|██▋       | 72/266 [02:11<04:50,  1.50s/it]Loading train:  27%|██▋       | 73/266 [02:13<05:30,  1.72s/it]Loading train:  28%|██▊       | 74/266 [02:15<05:43,  1.79s/it]Loading train:  28%|██▊       | 75/266 [02:17<05:50,  1.83s/it]Loading train:  29%|██▊       | 76/266 [02:19<05:32,  1.75s/it]Loading train:  29%|██▉       | 77/266 [02:20<05:25,  1.72s/it]Loading train:  29%|██▉       | 78/266 [02:23<06:14,  1.99s/it]Loading train:  30%|██▉       | 79/266 [02:25<06:11,  1.99s/it]Loading train:  30%|███       | 80/266 [02:27<06:32,  2.11s/it]Loading train:  30%|███       | 81/266 [02:29<06:36,  2.15s/it]Loading train:  31%|███       | 82/266 [02:31<06:19,  2.06s/it]Loading train:  31%|███       | 83/266 [02:33<06:08,  2.01s/it]Loading train:  32%|███▏      | 84/266 [02:35<06:03,  1.99s/it]Loading train:  32%|███▏      | 85/266 [02:37<06:13,  2.06s/it]Loading train:  32%|███▏      | 86/266 [02:39<05:44,  1.92s/it]Loading train:  33%|███▎      | 87/266 [02:41<05:28,  1.83s/it]Loading train:  33%|███▎      | 88/266 [02:43<05:42,  1.93s/it]Loading train:  33%|███▎      | 89/266 [02:45<05:37,  1.91s/it]Loading train:  34%|███▍      | 90/266 [02:47<05:42,  1.94s/it]Loading train:  34%|███▍      | 91/266 [02:48<05:31,  1.90s/it]Loading train:  35%|███▍      | 92/266 [02:50<05:04,  1.75s/it]Loading train:  35%|███▍      | 93/266 [02:51<04:46,  1.66s/it]Loading train:  35%|███▌      | 94/266 [02:53<04:44,  1.66s/it]Loading train:  36%|███▌      | 95/266 [02:55<04:58,  1.74s/it]Loading train:  36%|███▌      | 96/266 [02:57<04:54,  1.73s/it]Loading train:  36%|███▋      | 97/266 [02:59<05:48,  2.06s/it]Loading train:  37%|███▋      | 98/266 [03:02<06:30,  2.32s/it]Loading train:  37%|███▋      | 99/266 [03:05<06:29,  2.33s/it]Loading train:  38%|███▊      | 100/266 [03:07<06:36,  2.39s/it]Loading train:  38%|███▊      | 101/266 [03:09<06:12,  2.26s/it]Loading train:  38%|███▊      | 102/266 [03:10<05:23,  1.97s/it]Loading train:  39%|███▊      | 103/266 [03:12<04:59,  1.83s/it]Loading train:  39%|███▉      | 104/266 [03:14<04:43,  1.75s/it]Loading train:  39%|███▉      | 105/266 [03:15<04:16,  1.60s/it]Loading train:  40%|███▉      | 106/266 [03:16<04:15,  1.60s/it]Loading train:  40%|████      | 107/266 [03:18<04:21,  1.64s/it]Loading train:  41%|████      | 108/266 [03:20<04:27,  1.69s/it]Loading train:  41%|████      | 109/266 [03:22<04:31,  1.73s/it]Loading train:  41%|████▏     | 110/266 [03:24<04:35,  1.77s/it]Loading train:  42%|████▏     | 111/266 [03:25<04:24,  1.71s/it]Loading train:  42%|████▏     | 112/266 [03:27<04:20,  1.69s/it]Loading train:  42%|████▏     | 113/266 [03:28<04:19,  1.69s/it]Loading train:  43%|████▎     | 114/266 [03:31<04:41,  1.85s/it]Loading train:  43%|████▎     | 115/266 [03:33<05:05,  2.02s/it]Loading train:  44%|████▎     | 116/266 [03:34<04:26,  1.78s/it]Loading train:  44%|████▍     | 117/266 [03:36<04:14,  1.70s/it]Loading train:  44%|████▍     | 118/266 [03:37<04:06,  1.66s/it]Loading train:  45%|████▍     | 119/266 [03:40<04:27,  1.82s/it]Loading train:  45%|████▌     | 120/266 [03:42<04:28,  1.84s/it]Loading train:  45%|████▌     | 121/266 [03:44<04:36,  1.91s/it]Loading train:  46%|████▌     | 122/266 [03:46<04:43,  1.97s/it]Loading train:  46%|████▌     | 123/266 [03:48<04:45,  1.99s/it]Loading train:  47%|████▋     | 124/266 [03:50<04:37,  1.96s/it]Loading train:  47%|████▋     | 125/266 [03:51<04:09,  1.77s/it]Loading train:  47%|████▋     | 126/266 [03:53<04:00,  1.72s/it]Loading train:  48%|████▊     | 127/266 [03:55<04:14,  1.83s/it]Loading train:  48%|████▊     | 128/266 [03:56<03:47,  1.65s/it]Loading train:  48%|████▊     | 129/266 [03:58<03:48,  1.67s/it]Loading train:  49%|████▉     | 130/266 [03:59<03:42,  1.64s/it]Loading train:  49%|████▉     | 131/266 [04:01<03:35,  1.60s/it]Loading train:  50%|████▉     | 132/266 [04:03<03:47,  1.70s/it]Loading train:  50%|█████     | 133/266 [04:04<03:46,  1.70s/it]Loading train:  50%|█████     | 134/266 [04:06<03:53,  1.77s/it]Loading train:  51%|█████     | 135/266 [04:08<03:55,  1.80s/it]Loading train:  51%|█████     | 136/266 [04:10<04:05,  1.89s/it]Loading train:  52%|█████▏    | 137/266 [04:12<04:07,  1.92s/it]Loading train:  52%|█████▏    | 138/266 [04:14<03:49,  1.80s/it]Loading train:  52%|█████▏    | 139/266 [04:15<03:32,  1.67s/it]Loading train:  53%|█████▎    | 140/266 [04:17<03:23,  1.61s/it]Loading train:  53%|█████▎    | 141/266 [04:18<03:10,  1.52s/it]Loading train:  53%|█████▎    | 142/266 [04:19<03:11,  1.54s/it]Loading train:  54%|█████▍    | 143/266 [04:21<03:11,  1.56s/it]Loading train:  54%|█████▍    | 144/266 [04:22<03:01,  1.49s/it]Loading train:  55%|█████▍    | 145/266 [04:24<02:55,  1.45s/it]Loading train:  55%|█████▍    | 146/266 [04:25<02:55,  1.46s/it]Loading train:  55%|█████▌    | 147/266 [04:27<03:03,  1.54s/it]Loading train:  56%|█████▌    | 148/266 [04:29<03:05,  1.58s/it]Loading train:  56%|█████▌    | 149/266 [04:30<03:15,  1.67s/it]Loading train:  56%|█████▋    | 150/266 [04:33<03:27,  1.79s/it]Loading train:  57%|█████▋    | 151/266 [04:34<03:30,  1.83s/it]Loading train:  57%|█████▋    | 152/266 [04:36<03:28,  1.83s/it]Loading train:  58%|█████▊    | 153/266 [04:38<03:32,  1.88s/it]Loading train:  58%|█████▊    | 154/266 [04:40<03:20,  1.79s/it]Loading train:  58%|█████▊    | 155/266 [04:42<03:18,  1.78s/it]Loading train:  59%|█████▊    | 156/266 [04:43<03:12,  1.75s/it]Loading train:  59%|█████▉    | 157/266 [04:45<03:00,  1.65s/it]Loading train:  59%|█████▉    | 158/266 [04:46<02:41,  1.49s/it]Loading train:  60%|█████▉    | 159/266 [04:47<02:27,  1.37s/it]Loading train:  60%|██████    | 160/266 [04:48<02:28,  1.40s/it]Loading train:  61%|██████    | 161/266 [04:50<02:25,  1.38s/it]Loading train:  61%|██████    | 162/266 [04:51<02:22,  1.37s/it]Loading train:  61%|██████▏   | 163/266 [04:53<02:29,  1.45s/it]Loading train:  62%|██████▏   | 164/266 [04:54<02:27,  1.44s/it]Loading train:  62%|██████▏   | 165/266 [04:57<02:53,  1.72s/it]Loading train:  62%|██████▏   | 166/266 [04:59<03:03,  1.84s/it]Loading train:  63%|██████▎   | 167/266 [05:00<02:52,  1.75s/it]Loading train:  63%|██████▎   | 168/266 [05:02<02:47,  1.70s/it]Loading train:  64%|██████▎   | 169/266 [05:03<02:39,  1.65s/it]Loading train:  64%|██████▍   | 170/266 [05:05<02:38,  1.65s/it]Loading train:  64%|██████▍   | 171/266 [05:07<02:41,  1.70s/it]Loading train:  65%|██████▍   | 172/266 [05:09<02:51,  1.83s/it]Loading train:  65%|██████▌   | 173/266 [05:11<02:53,  1.86s/it]Loading train:  65%|██████▌   | 174/266 [05:12<02:42,  1.77s/it]Loading train:  66%|██████▌   | 175/266 [05:14<02:40,  1.76s/it]Loading train:  66%|██████▌   | 176/266 [05:16<02:29,  1.66s/it]Loading train:  67%|██████▋   | 177/266 [05:17<02:19,  1.57s/it]Loading train:  67%|██████▋   | 178/266 [05:19<02:29,  1.70s/it]Loading train:  67%|██████▋   | 179/266 [05:21<02:31,  1.74s/it]Loading train:  68%|██████▊   | 180/266 [05:23<02:38,  1.84s/it]Loading train:  68%|██████▊   | 181/266 [05:24<02:25,  1.71s/it]Loading train:  68%|██████▊   | 182/266 [05:26<02:21,  1.68s/it]Loading train:  69%|██████▉   | 183/266 [05:28<02:25,  1.75s/it]Loading train:  69%|██████▉   | 184/266 [05:30<02:36,  1.90s/it]Loading train:  70%|██████▉   | 185/266 [05:33<02:51,  2.12s/it]Loading train:  70%|██████▉   | 186/266 [05:35<03:03,  2.29s/it]Loading train:  70%|███████   | 187/266 [05:38<03:09,  2.40s/it]Loading train:  71%|███████   | 188/266 [05:40<03:04,  2.37s/it]Loading train:  71%|███████   | 189/266 [05:42<02:50,  2.21s/it]Loading train:  71%|███████▏  | 190/266 [05:43<02:28,  1.95s/it]Loading train:  72%|███████▏  | 191/266 [05:45<02:20,  1.88s/it]Loading train:  72%|███████▏  | 192/266 [05:47<02:10,  1.76s/it]Loading train:  73%|███████▎  | 193/266 [05:49<02:18,  1.90s/it]Loading train:  73%|███████▎  | 194/266 [05:52<02:37,  2.19s/it]Loading train:  73%|███████▎  | 195/266 [05:54<02:32,  2.15s/it]Loading train:  74%|███████▎  | 196/266 [05:56<02:29,  2.14s/it]Loading train:  74%|███████▍  | 197/266 [05:58<02:24,  2.10s/it]Loading train:  74%|███████▍  | 198/266 [06:00<02:27,  2.17s/it]Loading train:  75%|███████▍  | 199/266 [06:02<02:22,  2.13s/it]Loading train:  75%|███████▌  | 200/266 [06:05<02:22,  2.16s/it]Loading train:  76%|███████▌  | 201/266 [06:07<02:17,  2.12s/it]Loading train:  76%|███████▌  | 202/266 [06:08<02:10,  2.03s/it]Loading train:  76%|███████▋  | 203/266 [06:10<01:56,  1.86s/it]Loading train:  77%|███████▋  | 204/266 [06:11<01:46,  1.72s/it]Loading train:  77%|███████▋  | 205/266 [06:13<01:36,  1.58s/it]Loading train:  77%|███████▋  | 206/266 [06:14<01:29,  1.50s/it]Loading train:  78%|███████▊  | 207/266 [06:15<01:25,  1.46s/it]Loading train:  78%|███████▊  | 208/266 [06:16<01:21,  1.41s/it]Loading train:  79%|███████▊  | 209/266 [06:18<01:17,  1.36s/it]Loading train:  79%|███████▉  | 210/266 [06:19<01:15,  1.35s/it]Loading train:  79%|███████▉  | 211/266 [06:20<01:12,  1.33s/it]Loading train:  80%|███████▉  | 212/266 [06:22<01:12,  1.35s/it]Loading train:  80%|████████  | 213/266 [06:23<01:10,  1.32s/it]Loading train:  80%|████████  | 214/266 [06:24<01:07,  1.29s/it]Loading train:  81%|████████  | 215/266 [06:26<01:08,  1.34s/it]Loading train:  81%|████████  | 216/266 [06:27<01:04,  1.29s/it]Loading train:  82%|████████▏ | 217/266 [06:28<00:59,  1.21s/it]Loading train:  82%|████████▏ | 218/266 [06:29<00:58,  1.22s/it]Loading train:  82%|████████▏ | 219/266 [06:30<00:56,  1.19s/it]Loading train:  83%|████████▎ | 220/266 [06:31<00:53,  1.16s/it]Loading train:  83%|████████▎ | 221/266 [06:32<00:51,  1.15s/it]Loading train:  83%|████████▎ | 222/266 [06:34<00:51,  1.17s/it]Loading train:  84%|████████▍ | 223/266 [06:35<00:51,  1.19s/it]Loading train:  84%|████████▍ | 224/266 [06:37<00:55,  1.32s/it]Loading train:  85%|████████▍ | 225/266 [06:38<00:50,  1.23s/it]Loading train:  85%|████████▍ | 226/266 [06:39<00:49,  1.23s/it]Loading train:  85%|████████▌ | 227/266 [06:40<00:46,  1.20s/it]Loading train:  86%|████████▌ | 228/266 [06:41<00:41,  1.10s/it]Loading train:  86%|████████▌ | 229/266 [06:42<00:40,  1.09s/it]Loading train:  86%|████████▋ | 230/266 [06:43<00:37,  1.04s/it]Loading train:  87%|████████▋ | 231/266 [06:44<00:36,  1.04s/it]Loading train:  87%|████████▋ | 232/266 [06:45<00:35,  1.05s/it]Loading train:  88%|████████▊ | 233/266 [06:46<00:35,  1.06s/it]Loading train:  88%|████████▊ | 234/266 [06:47<00:36,  1.15s/it]Loading train:  88%|████████▊ | 235/266 [06:48<00:34,  1.12s/it]Loading train:  89%|████████▊ | 236/266 [06:50<00:33,  1.12s/it]Loading train:  89%|████████▉ | 237/266 [06:51<00:31,  1.08s/it]Loading train:  89%|████████▉ | 238/266 [06:52<00:30,  1.09s/it]Loading train:  90%|████████▉ | 239/266 [06:53<00:29,  1.09s/it]Loading train:  90%|█████████ | 240/266 [06:54<00:28,  1.10s/it]Loading train:  91%|█████████ | 241/266 [06:55<00:26,  1.05s/it]Loading train:  91%|█████████ | 242/266 [06:56<00:24,  1.03s/it]Loading train:  91%|█████████▏| 243/266 [06:57<00:24,  1.08s/it]Loading train:  92%|█████████▏| 244/266 [06:58<00:22,  1.03s/it]Loading train:  92%|█████████▏| 245/266 [06:59<00:22,  1.09s/it]Loading train:  92%|█████████▏| 246/266 [07:00<00:23,  1.17s/it]Loading train:  93%|█████████▎| 247/266 [07:02<00:24,  1.28s/it]Loading train:  93%|█████████▎| 248/266 [07:03<00:20,  1.15s/it]Loading train:  94%|█████████▎| 249/266 [07:04<00:20,  1.21s/it]Loading train:  94%|█████████▍| 250/266 [07:05<00:19,  1.22s/it]Loading train:  94%|█████████▍| 251/266 [07:07<00:19,  1.28s/it]Loading train:  95%|█████████▍| 252/266 [07:08<00:17,  1.22s/it]Loading train:  95%|█████████▌| 253/266 [07:09<00:16,  1.24s/it]Loading train:  95%|█████████▌| 254/266 [07:10<00:14,  1.24s/it]Loading train:  96%|█████████▌| 255/266 [07:12<00:13,  1.24s/it]Loading train:  96%|█████████▌| 256/266 [07:13<00:11,  1.19s/it]Loading train:  97%|█████████▋| 257/266 [07:14<00:10,  1.17s/it]Loading train:  97%|█████████▋| 258/266 [07:15<00:09,  1.24s/it]Loading train:  97%|█████████▋| 259/266 [07:17<00:08,  1.28s/it]Loading train:  98%|█████████▊| 260/266 [07:18<00:08,  1.34s/it]Loading train:  98%|█████████▊| 261/266 [07:19<00:06,  1.34s/it]Loading train:  98%|█████████▊| 262/266 [07:21<00:05,  1.37s/it]Loading train:  99%|█████████▉| 263/266 [07:22<00:04,  1.42s/it]Loading train:  99%|█████████▉| 264/266 [07:24<00:02,  1.40s/it]Loading train: 100%|█████████▉| 265/266 [07:25<00:01,  1.40s/it]Loading train: 100%|██████████| 266/266 [07:26<00:00,  1.33s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:03, 74.64it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:02, 83.40it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:02, 90.70it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:02, 95.06it/s]concatenating: train:  23%|██▎       | 61/266 [00:00<00:01, 109.14it/s]concatenating: train:  28%|██▊       | 75/266 [00:00<00:01, 115.71it/s]concatenating: train:  33%|███▎      | 88/266 [00:00<00:01, 118.31it/s]concatenating: train:  38%|███▊      | 101/266 [00:00<00:01, 115.12it/s]concatenating: train:  42%|████▏     | 113/266 [00:01<00:01, 100.17it/s]concatenating: train:  47%|████▋     | 126/266 [00:01<00:01, 106.55it/s]concatenating: train:  52%|█████▏    | 139/266 [00:01<00:01, 111.00it/s]concatenating: train:  62%|██████▏   | 164/266 [00:01<00:00, 133.01it/s]concatenating: train:  71%|███████   | 189/266 [00:01<00:00, 154.38it/s]concatenating: train:  78%|███████▊  | 208/266 [00:01<00:00, 153.97it/s]concatenating: train:  85%|████████▍ | 226/266 [00:01<00:00, 143.96it/s]concatenating: train:  96%|█████████▌| 255/266 [00:01<00:00, 168.50it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 144.62it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.43s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.43s/it]Loading test:  75%|███████▌  | 3/4 [00:04<00:01,  1.36s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.39s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 119.30it/s]2019-07-29 00:23:08.187509: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 00:23:08.187596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 00:23:08.187612: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 00:23:08.187620: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 00:23:08.188020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.76it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.61it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.27it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.78it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.92it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.39it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.84it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.41it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.86it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.54it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.15it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.41it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.48it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.69it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.71it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.20it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.66it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  7.41it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.40it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.41it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 84, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 84, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 84, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 84, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 84, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 84, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 84, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 84, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 84, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 42, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 42, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 42, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 42, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 42, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 42, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 42, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 21, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 21, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 21, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 21, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 21, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 21, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 21, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 21, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 42, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 42, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 42, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 42, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 42, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 42, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 42, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 84, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 84, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 84, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 84, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 84, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 84, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 84, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 84, 30)   16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 84, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 84, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 84, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 84, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 84, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 84, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 84, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 84, 90)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 84, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 262,893
Trainable params: 87,973
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33683650e-02 3.28429437e-02 7.67987068e-02 9.54262550e-03
 2.76185311e-02 7.22561016e-03 8.43061607e-02 1.14148634e-01
 8.96292085e-02 1.36177957e-02 2.90595523e-01 1.90048853e-01
 2.57042600e-04]
Train on 9792 samples, validate on 144 samples
Epoch 1/300
 - 21s - loss: 2.0214 - acc: 0.7253 - mDice: 0.2184 - val_loss: 0.8395 - val_acc: 0.9110 - val_mDice: 0.4247

Epoch 00001: val_mDice improved from -inf to 0.42472, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.7181 - acc: 0.8935 - mDice: 0.4792 - val_loss: 0.6779 - val_acc: 0.9253 - val_mDice: 0.5117

Epoch 00002: val_mDice improved from 0.42472 to 0.51170, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.6418 - acc: 0.9093 - mDice: 0.5193 - val_loss: 0.7514 - val_acc: 0.9312 - val_mDice: 0.4999

Epoch 00003: val_mDice did not improve from 0.51170
Epoch 4/300
 - 14s - loss: 0.5442 - acc: 0.9209 - mDice: 0.5680 - val_loss: 0.5060 - val_acc: 0.9376 - val_mDice: 0.5909

Epoch 00004: val_mDice improved from 0.51170 to 0.59093, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.5081 - acc: 0.9248 - mDice: 0.5886 - val_loss: 0.5036 - val_acc: 0.9434 - val_mDice: 0.5976

Epoch 00005: val_mDice improved from 0.59093 to 0.59761, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.4754 - acc: 0.9287 - mDice: 0.6078 - val_loss: 0.4900 - val_acc: 0.9437 - val_mDice: 0.6028

Epoch 00006: val_mDice improved from 0.59761 to 0.60283, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.4551 - acc: 0.9312 - mDice: 0.6208 - val_loss: 0.4906 - val_acc: 0.9453 - val_mDice: 0.6065

Epoch 00007: val_mDice improved from 0.60283 to 0.60649, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.4544 - acc: 0.9319 - mDice: 0.6233 - val_loss: 0.4667 - val_acc: 0.9411 - val_mDice: 0.6136

Epoch 00008: val_mDice improved from 0.60649 to 0.61357, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.4284 - acc: 0.9342 - mDice: 0.6379 - val_loss: 0.4681 - val_acc: 0.9448 - val_mDice: 0.6149

Epoch 00009: val_mDice improved from 0.61357 to 0.61487, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.4167 - acc: 0.9353 - mDice: 0.6451 - val_loss: 0.4559 - val_acc: 0.9471 - val_mDice: 0.6232

Epoch 00010: val_mDice improved from 0.61487 to 0.62324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.4044 - acc: 0.9367 - mDice: 0.6533 - val_loss: 0.4549 - val_acc: 0.9470 - val_mDice: 0.6244

Epoch 00011: val_mDice improved from 0.62324 to 0.62440, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 15s - loss: 0.3937 - acc: 0.9380 - mDice: 0.6606 - val_loss: 0.4643 - val_acc: 0.9458 - val_mDice: 0.6196

Epoch 00012: val_mDice did not improve from 0.62440
Epoch 13/300
 - 14s - loss: 0.3871 - acc: 0.9384 - mDice: 0.6649 - val_loss: 0.4480 - val_acc: 0.9480 - val_mDice: 0.6283

Epoch 00013: val_mDice improved from 0.62440 to 0.62831, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 14s - loss: 0.3832 - acc: 0.9391 - mDice: 0.6682 - val_loss: 0.4691 - val_acc: 0.9408 - val_mDice: 0.6132

Epoch 00014: val_mDice did not improve from 0.62831
Epoch 15/300
 - 14s - loss: 0.3753 - acc: 0.9399 - mDice: 0.6733 - val_loss: 0.4538 - val_acc: 0.9480 - val_mDice: 0.6263

Epoch 00015: val_mDice did not improve from 0.62831
Epoch 16/300
 - 14s - loss: 0.3685 - acc: 0.9405 - mDice: 0.6778 - val_loss: 0.4502 - val_acc: 0.9460 - val_mDice: 0.6279

Epoch 00016: val_mDice did not improve from 0.62831
Epoch 17/300
 - 14s - loss: 0.3763 - acc: 0.9401 - mDice: 0.6732 - val_loss: 0.4441 - val_acc: 0.9503 - val_mDice: 0.6331

Epoch 00017: val_mDice improved from 0.62831 to 0.63306, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 14s - loss: 0.3567 - acc: 0.9418 - mDice: 0.6860 - val_loss: 0.4395 - val_acc: 0.9499 - val_mDice: 0.6367

Epoch 00018: val_mDice improved from 0.63306 to 0.63673, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 15s - loss: 0.3532 - acc: 0.9420 - mDice: 0.6886 - val_loss: 0.4488 - val_acc: 0.9503 - val_mDice: 0.6325

Epoch 00019: val_mDice did not improve from 0.63673
Epoch 20/300
 - 14s - loss: 0.3485 - acc: 0.9426 - mDice: 0.6919 - val_loss: 0.4484 - val_acc: 0.9502 - val_mDice: 0.6329

Epoch 00020: val_mDice did not improve from 0.63673
Epoch 21/300
 - 14s - loss: 0.3446 - acc: 0.9427 - mDice: 0.6947 - val_loss: 0.4415 - val_acc: 0.9488 - val_mDice: 0.6346

Epoch 00021: val_mDice did not improve from 0.63673
Epoch 22/300
 - 14s - loss: 0.3406 - acc: 0.9432 - mDice: 0.6975 - val_loss: 0.4417 - val_acc: 0.9485 - val_mDice: 0.6337

Epoch 00022: val_mDice did not improve from 0.63673
Epoch 23/300
 - 14s - loss: 0.3367 - acc: 0.9436 - mDice: 0.7004 - val_loss: 0.4582 - val_acc: 0.9477 - val_mDice: 0.6249

Epoch 00023: val_mDice did not improve from 0.63673
Epoch 24/300
 - 14s - loss: 0.3609 - acc: 0.9412 - mDice: 0.6847 - val_loss: 0.4420 - val_acc: 0.9498 - val_mDice: 0.6336

Epoch 00024: val_mDice did not improve from 0.63673
Epoch 25/300
 - 14s - loss: 0.3353 - acc: 0.9438 - mDice: 0.7015 - val_loss: 0.4378 - val_acc: 0.9510 - val_mDice: 0.6374

Epoch 00025: val_mDice improved from 0.63673 to 0.63737, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 14s - loss: 0.3303 - acc: 0.9444 - mDice: 0.7051 - val_loss: 0.4566 - val_acc: 0.9492 - val_mDice: 0.6258

Epoch 00026: val_mDice did not improve from 0.63737
Epoch 27/300
 - 15s - loss: 0.3290 - acc: 0.9444 - mDice: 0.7060 - val_loss: 0.4790 - val_acc: 0.9497 - val_mDice: 0.6186

Epoch 00027: val_mDice did not improve from 0.63737
Epoch 28/300
 - 14s - loss: 0.3281 - acc: 0.9446 - mDice: 0.7071 - val_loss: 0.4500 - val_acc: 0.9495 - val_mDice: 0.6307

Epoch 00028: val_mDice did not improve from 0.63737
Epoch 29/300
 - 14s - loss: 0.3225 - acc: 0.9449 - mDice: 0.7108 - val_loss: 0.4573 - val_acc: 0.9436 - val_mDice: 0.6212

Epoch 00029: val_mDice did not improve from 0.63737
Epoch 30/300
 - 14s - loss: 0.3193 - acc: 0.9453 - mDice: 0.7133 - val_loss: 0.4544 - val_acc: 0.9499 - val_mDice: 0.6285

Epoch 00030: val_mDice did not improve from 0.63737
Epoch 31/300
 - 14s - loss: 0.3190 - acc: 0.9454 - mDice: 0.7138 - val_loss: 0.4669 - val_acc: 0.9482 - val_mDice: 0.6223

Epoch 00031: val_mDice did not improve from 0.63737
Epoch 32/300
 - 14s - loss: 0.3131 - acc: 0.9458 - mDice: 0.7177 - val_loss: 0.4394 - val_acc: 0.9492 - val_mDice: 0.6347

Epoch 00032: val_mDice did not improve from 0.63737
Epoch 33/300
 - 14s - loss: 0.3111 - acc: 0.9459 - mDice: 0.7192 - val_loss: 0.4435 - val_acc: 0.9516 - val_mDice: 0.6350

Epoch 00033: val_mDice did not improve from 0.63737
Epoch 34/300
 - 15s - loss: 0.3099 - acc: 0.9461 - mDice: 0.7200 - val_loss: 0.4637 - val_acc: 0.9499 - val_mDice: 0.6267

Epoch 00034: val_mDice did not improve from 0.63737
Epoch 35/300
 - 14s - loss: 0.3104 - acc: 0.9459 - mDice: 0.7196 - val_loss: 0.4360 - val_acc: 0.9499 - val_mDice: 0.6386

Epoch 00035: val_mDice improved from 0.63737 to 0.63859, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 14s - loss: 0.3081 - acc: 0.9463 - mDice: 0.7214 - val_loss: 0.4433 - val_acc: 0.9492 - val_mDice: 0.6350

Epoch 00036: val_mDice did not improve from 0.63859
Epoch 37/300
 - 14s - loss: 0.3035 - acc: 0.9466 - mDice: 0.7249 - val_loss: 0.4437 - val_acc: 0.9486 - val_mDice: 0.6324

Epoch 00037: val_mDice did not improve from 0.63859
Epoch 38/300
 - 14s - loss: 0.3030 - acc: 0.9467 - mDice: 0.7251 - val_loss: 0.4585 - val_acc: 0.9451 - val_mDice: 0.6230

Epoch 00038: val_mDice did not improve from 0.63859
Epoch 39/300
 - 14s - loss: 0.2998 - acc: 0.9469 - mDice: 0.7276 - val_loss: 0.4417 - val_acc: 0.9501 - val_mDice: 0.6356

Epoch 00039: val_mDice did not improve from 0.63859
Epoch 40/300
 - 14s - loss: 0.3113 - acc: 0.9465 - mDice: 0.7240 - val_loss: 0.4555 - val_acc: 0.9459 - val_mDice: 0.6245

Epoch 00040: val_mDice did not improve from 0.63859
Epoch 41/300
 - 15s - loss: 0.2980 - acc: 0.9470 - mDice: 0.7288 - val_loss: 0.4351 - val_acc: 0.9518 - val_mDice: 0.6413

Epoch 00041: val_mDice improved from 0.63859 to 0.64134, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 42/300
 - 14s - loss: 0.2960 - acc: 0.9473 - mDice: 0.7304 - val_loss: 0.4464 - val_acc: 0.9489 - val_mDice: 0.6335

Epoch 00042: val_mDice did not improve from 0.64134
Epoch 43/300
 - 14s - loss: 0.3025 - acc: 0.9475 - mDice: 0.7310 - val_loss: 0.4443 - val_acc: 0.9488 - val_mDice: 0.6320

Epoch 00043: val_mDice did not improve from 0.64134
Epoch 44/300
 - 14s - loss: 0.2921 - acc: 0.9477 - mDice: 0.7334 - val_loss: 0.4427 - val_acc: 0.9497 - val_mDice: 0.6341

Epoch 00044: val_mDice did not improve from 0.64134
Epoch 45/300
 - 14s - loss: 0.2932 - acc: 0.9477 - mDice: 0.7326 - val_loss: 0.4451 - val_acc: 0.9460 - val_mDice: 0.6302

Epoch 00045: val_mDice did not improve from 0.64134
Epoch 46/300
 - 14s - loss: 0.2901 - acc: 0.9478 - mDice: 0.7350 - val_loss: 0.4539 - val_acc: 0.9519 - val_mDice: 0.6307

Epoch 00046: val_mDice did not improve from 0.64134
Epoch 47/300
 - 14s - loss: 0.2902 - acc: 0.9479 - mDice: 0.7347 - val_loss: 0.4718 - val_acc: 0.9458 - val_mDice: 0.6204

Epoch 00047: val_mDice did not improve from 0.64134
Epoch 48/300
 - 14s - loss: 0.2869 - acc: 0.9481 - mDice: 0.7373 - val_loss: 0.4403 - val_acc: 0.9476 - val_mDice: 0.6355

Epoch 00048: val_mDice did not improve from 0.64134
Epoch 49/300
 - 15s - loss: 0.2984 - acc: 0.9469 - mDice: 0.7291 - val_loss: 0.4536 - val_acc: 0.9509 - val_mDice: 0.6328

Epoch 00049: val_mDice did not improve from 0.64134
Epoch 50/300
 - 14s - loss: 0.2832 - acc: 0.9484 - mDice: 0.7401 - val_loss: 0.4463 - val_acc: 0.9513 - val_mDice: 0.6342

Epoch 00050: val_mDice did not improve from 0.64134
Epoch 51/300
 - 14s - loss: 0.3271 - acc: 0.9440 - mDice: 0.7102 - val_loss: 0.4506 - val_acc: 0.9483 - val_mDice: 0.6296

Epoch 00051: val_mDice did not improve from 0.64134
Epoch 52/300
 - 14s - loss: 0.2943 - acc: 0.9474 - mDice: 0.7317 - val_loss: 0.4478 - val_acc: 0.9473 - val_mDice: 0.6309

Epoch 00052: val_mDice did not improve from 0.64134
Epoch 53/300
 - 14s - loss: 0.2852 - acc: 0.9483 - mDice: 0.7388 - val_loss: 0.4389 - val_acc: 0.9516 - val_mDice: 0.6369

Epoch 00053: val_mDice did not improve from 0.64134
Epoch 54/300
 - 14s - loss: 0.2822 - acc: 0.9484 - mDice: 0.7409 - val_loss: 0.4354 - val_acc: 0.9486 - val_mDice: 0.6382

Epoch 00054: val_mDice did not improve from 0.64134
Epoch 55/300
 - 14s - loss: 0.2800 - acc: 0.9487 - mDice: 0.7426 - val_loss: 0.4432 - val_acc: 0.9504 - val_mDice: 0.6359

Epoch 00055: val_mDice did not improve from 0.64134
Epoch 56/300
 - 14s - loss: 0.2776 - acc: 0.9489 - mDice: 0.7444 - val_loss: 0.4529 - val_acc: 0.9502 - val_mDice: 0.6305

Epoch 00056: val_mDice did not improve from 0.64134
Epoch 57/300
 - 15s - loss: 0.2772 - acc: 0.9489 - mDice: 0.7446 - val_loss: 0.4405 - val_acc: 0.9454 - val_mDice: 0.6328

Epoch 00057: val_mDice did not improve from 0.64134
Epoch 58/300
 - 14s - loss: 0.2762 - acc: 0.9491 - mDice: 0.7456 - val_loss: 0.4345 - val_acc: 0.9493 - val_mDice: 0.6386

Epoch 00058: val_mDice did not improve from 0.64134
Epoch 59/300
 - 14s - loss: 0.2776 - acc: 0.9490 - mDice: 0.7446 - val_loss: 0.4407 - val_acc: 0.9495 - val_mDice: 0.6361

Epoch 00059: val_mDice did not improve from 0.64134
Epoch 60/300
 - 14s - loss: 0.2824 - acc: 0.9492 - mDice: 0.7460 - val_loss: 0.4267 - val_acc: 0.9497 - val_mDice: 0.6437

Epoch 00060: val_mDice improved from 0.64134 to 0.64370, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 61/300
 - 14s - loss: 0.2740 - acc: 0.9492 - mDice: 0.7472 - val_loss: 0.4574 - val_acc: 0.9495 - val_mDice: 0.6275

Epoch 00061: val_mDice did not improve from 0.64370
Epoch 62/300
 - 14s - loss: 0.2750 - acc: 0.9493 - mDice: 0.7465 - val_loss: 0.4314 - val_acc: 0.9514 - val_mDice: 0.6407

Epoch 00062: val_mDice did not improve from 0.64370
Epoch 63/300
 - 14s - loss: 0.2726 - acc: 0.9494 - mDice: 0.7484 - val_loss: 0.4485 - val_acc: 0.9503 - val_mDice: 0.6329

Epoch 00063: val_mDice did not improve from 0.64370
Epoch 64/300
 - 14s - loss: 0.2720 - acc: 0.9494 - mDice: 0.7488 - val_loss: 0.4453 - val_acc: 0.9461 - val_mDice: 0.6315

Epoch 00064: val_mDice did not improve from 0.64370
Epoch 65/300
 - 15s - loss: 0.2728 - acc: 0.9495 - mDice: 0.7484 - val_loss: 0.4364 - val_acc: 0.9518 - val_mDice: 0.6388

Epoch 00065: val_mDice did not improve from 0.64370
Epoch 66/300
 - 15s - loss: 0.2708 - acc: 0.9495 - mDice: 0.7497 - val_loss: 0.4254 - val_acc: 0.9520 - val_mDice: 0.6448

Epoch 00066: val_mDice improved from 0.64370 to 0.64475, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 67/300
 - 17s - loss: 0.3283 - acc: 0.9438 - mDice: 0.7189 - val_loss: 0.5188 - val_acc: 0.9405 - val_mDice: 0.5879

Epoch 00067: val_mDice did not improve from 0.64475
Epoch 68/300
 - 17s - loss: 0.3043 - acc: 0.9464 - mDice: 0.7245 - val_loss: 0.4339 - val_acc: 0.9508 - val_mDice: 0.6401

Epoch 00068: val_mDice did not improve from 0.64475
Epoch 69/300
 - 17s - loss: 0.2816 - acc: 0.9486 - mDice: 0.7414 - val_loss: 0.4359 - val_acc: 0.9524 - val_mDice: 0.6396

Epoch 00069: val_mDice did not improve from 0.64475
Epoch 70/300
 - 18s - loss: 0.2733 - acc: 0.9493 - mDice: 0.7477 - val_loss: 0.4297 - val_acc: 0.9505 - val_mDice: 0.6418

Epoch 00070: val_mDice did not improve from 0.64475
Epoch 71/300
 - 15s - loss: 0.2699 - acc: 0.9496 - mDice: 0.7503 - val_loss: 0.4196 - val_acc: 0.9500 - val_mDice: 0.6462

Epoch 00071: val_mDice improved from 0.64475 to 0.64618, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 72/300
 - 15s - loss: 0.2680 - acc: 0.9497 - mDice: 0.7519 - val_loss: 0.4226 - val_acc: 0.9512 - val_mDice: 0.6449

Epoch 00072: val_mDice did not improve from 0.64618
Epoch 73/300
 - 16s - loss: 0.2671 - acc: 0.9499 - mDice: 0.7526 - val_loss: 0.4277 - val_acc: 0.9501 - val_mDice: 0.6418

Epoch 00073: val_mDice did not improve from 0.64618
Epoch 74/300
 - 15s - loss: 0.2656 - acc: 0.9499 - mDice: 0.7538 - val_loss: 0.4309 - val_acc: 0.9512 - val_mDice: 0.6402

Epoch 00074: val_mDice did not improve from 0.64618
Epoch 75/300
 - 15s - loss: 0.2668 - acc: 0.9499 - mDice: 0.7529 - val_loss: 0.4522 - val_acc: 0.9470 - val_mDice: 0.6266

Epoch 00075: val_mDice did not improve from 0.64618
Epoch 76/300
 - 15s - loss: 0.2654 - acc: 0.9501 - mDice: 0.7543 - val_loss: 0.4343 - val_acc: 0.9524 - val_mDice: 0.6395

Epoch 00076: val_mDice did not improve from 0.64618
Epoch 77/300
 - 15s - loss: 0.2633 - acc: 0.9501 - mDice: 0.7555 - val_loss: 0.4462 - val_acc: 0.9512 - val_mDice: 0.6329

Epoch 00077: val_mDice did not improve from 0.64618
Epoch 78/300
 - 16s - loss: 0.2629 - acc: 0.9502 - mDice: 0.7559 - val_loss: 0.4287 - val_acc: 0.9509 - val_mDice: 0.6425

Epoch 00078: val_mDice did not improve from 0.64618
Epoch 79/300
 - 15s - loss: 0.2624 - acc: 0.9503 - mDice: 0.7564 - val_loss: 0.4401 - val_acc: 0.9510 - val_mDice: 0.6368

Epoch 00079: val_mDice did not improve from 0.64618
Epoch 80/300
 - 15s - loss: 0.2632 - acc: 0.9501 - mDice: 0.7558 - val_loss: 0.4299 - val_acc: 0.9517 - val_mDice: 0.6408

Epoch 00080: val_mDice did not improve from 0.64618
Epoch 81/300
 - 16s - loss: 0.2688 - acc: 0.9499 - mDice: 0.7515 - val_loss: 0.4207 - val_acc: 0.9493 - val_mDice: 0.6461

Epoch 00081: val_mDice did not improve from 0.64618
Epoch 82/300
 - 16s - loss: 0.2613 - acc: 0.9503 - mDice: 0.7572 - val_loss: 0.4274 - val_acc: 0.9527 - val_mDice: 0.6452

Epoch 00082: val_mDice did not improve from 0.64618
Epoch 83/300
 - 15s - loss: 0.2610 - acc: 0.9504 - mDice: 0.7574 - val_loss: 0.4307 - val_acc: 0.9509 - val_mDice: 0.6411

Epoch 00083: val_mDice did not improve from 0.64618
Epoch 84/300
 - 16s - loss: 0.2594 - acc: 0.9504 - mDice: 0.7587 - val_loss: 0.4398 - val_acc: 0.9496 - val_mDice: 0.6347

Epoch 00084: val_mDice did not improve from 0.64618
Epoch 85/300
 - 16s - loss: 0.2592 - acc: 0.9505 - mDice: 0.7589 - val_loss: 0.4321 - val_acc: 0.9493 - val_mDice: 0.6394

Epoch 00085: val_mDice did not improve from 0.64618
Epoch 86/300
 - 16s - loss: 0.2597 - acc: 0.9504 - mDice: 0.7585 - val_loss: 0.4469 - val_acc: 0.9491 - val_mDice: 0.6319

Epoch 00086: val_mDice did not improve from 0.64618
Epoch 87/300
 - 16s - loss: 0.2570 - acc: 0.9506 - mDice: 0.7605 - val_loss: 0.4301 - val_acc: 0.9513 - val_mDice: 0.6421

Epoch 00087: val_mDice did not improve from 0.64618
Epoch 88/300
 - 16s - loss: 0.2578 - acc: 0.9506 - mDice: 0.7601 - val_loss: 0.4435 - val_acc: 0.9520 - val_mDice: 0.6353

Epoch 00088: val_mDice did not improve from 0.64618
Epoch 89/300
 - 16s - loss: 0.2643 - acc: 0.9507 - mDice: 0.7599 - val_loss: 0.4371 - val_acc: 0.9511 - val_mDice: 0.6388

Epoch 00089: val_mDice did not improve from 0.64618
Epoch 90/300
 - 16s - loss: 0.2561 - acc: 0.9507 - mDice: 0.7613 - val_loss: 0.4433 - val_acc: 0.9512 - val_mDice: 0.6356

Epoch 00090: val_mDice did not improve from 0.64618
Epoch 91/300
 - 15s - loss: 0.2560 - acc: 0.9507 - mDice: 0.7614 - val_loss: 0.4235 - val_acc: 0.9511 - val_mDice: 0.6455

Epoch 00091: val_mDice did not improve from 0.64618
Epoch 92/300
 - 16s - loss: 0.2558 - acc: 0.9508 - mDice: 0.7615 - val_loss: 0.4332 - val_acc: 0.9486 - val_mDice: 0.6388

Epoch 00092: val_mDice did not improve from 0.64618
Epoch 93/300
 - 16s - loss: 0.2545 - acc: 0.9510 - mDice: 0.7626 - val_loss: 0.4327 - val_acc: 0.9513 - val_mDice: 0.6394

Epoch 00093: val_mDice did not improve from 0.64618
Epoch 94/300
 - 15s - loss: 0.2573 - acc: 0.9508 - mDice: 0.7604 - val_loss: 0.4299 - val_acc: 0.9505 - val_mDice: 0.6401

Epoch 00094: val_mDice did not improve from 0.64618
Epoch 95/300
 - 15s - loss: 0.2536 - acc: 0.9508 - mDice: 0.7632 - val_loss: 0.4296 - val_acc: 0.9504 - val_mDice: 0.6410

Epoch 00095: val_mDice did not improve from 0.64618
Epoch 96/300
 - 14s - loss: 0.2537 - acc: 0.9510 - mDice: 0.7632 - val_loss: 0.4341 - val_acc: 0.9514 - val_mDice: 0.6397

Epoch 00096: val_mDice did not improve from 0.64618
Epoch 97/300
 - 14s - loss: 0.2528 - acc: 0.9511 - mDice: 0.7638 - val_loss: 0.4266 - val_acc: 0.9518 - val_mDice: 0.6441

Epoch 00097: val_mDice did not improve from 0.64618
Epoch 98/300
 - 15s - loss: 0.2519 - acc: 0.9511 - mDice: 0.7646 - val_loss: 0.4373 - val_acc: 0.9498 - val_mDice: 0.6362

Epoch 00098: val_mDice did not improve from 0.64618
Epoch 99/300
 - 14s - loss: 0.2519 - acc: 0.9511 - mDice: 0.7647 - val_loss: 0.4310 - val_acc: 0.9500 - val_mDice: 0.6392

Epoch 00099: val_mDice did not improve from 0.64618
Epoch 100/300
 - 14s - loss: 0.2523 - acc: 0.9512 - mDice: 0.7643 - val_loss: 0.4282 - val_acc: 0.9502 - val_mDice: 0.6414

Epoch 00100: val_mDice did not improve from 0.64618
Epoch 101/300
 - 14s - loss: 0.2503 - acc: 0.9513 - mDice: 0.7659 - val_loss: 0.4336 - val_acc: 0.9487 - val_mDice: 0.6382

Epoch 00101: val_mDice did not improve from 0.64618
Epoch 102/300
 - 14s - loss: 0.2513 - acc: 0.9512 - mDice: 0.7652 - val_loss: 0.4470 - val_acc: 0.9510 - val_mDice: 0.6321

Epoch 00102: val_mDice did not improve from 0.64618
Epoch 103/300
 - 15s - loss: 0.2492 - acc: 0.9514 - mDice: 0.7668 - val_loss: 0.4300 - val_acc: 0.9508 - val_mDice: 0.6416

Epoch 00103: val_mDice did not improve from 0.64618
Epoch 104/300
 - 14s - loss: 0.2504 - acc: 0.9513 - mDice: 0.7658 - val_loss: 0.4191 - val_acc: 0.9514 - val_mDice: 0.6488

Epoch 00104: val_mDice improved from 0.64618 to 0.64880, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 105/300
 - 14s - loss: 0.2509 - acc: 0.9514 - mDice: 0.7654 - val_loss: 0.4276 - val_acc: 0.9513 - val_mDice: 0.6430

Epoch 00105: val_mDice did not improve from 0.64880
Epoch 106/300
 - 14s - loss: 0.2490 - acc: 0.9514 - mDice: 0.7670 - val_loss: 0.4345 - val_acc: 0.9519 - val_mDice: 0.6391

Epoch 00106: val_mDice did not improve from 0.64880
Epoch 107/300
 - 14s - loss: 0.2481 - acc: 0.9514 - mDice: 0.7676 - val_loss: 0.4388 - val_acc: 0.9498 - val_mDice: 0.6357

Epoch 00107: val_mDice did not improve from 0.64880
Epoch 108/300
 - 14s - loss: 0.2481 - acc: 0.9514 - mDice: 0.7677 - val_loss: 0.4477 - val_acc: 0.9484 - val_mDice: 0.6309

Epoch 00108: val_mDice did not improve from 0.64880
Epoch 109/300
 - 15s - loss: 0.2477 - acc: 0.9515 - mDice: 0.7680 - val_loss: 0.4218 - val_acc: 0.9510 - val_mDice: 0.6464

Epoch 00109: val_mDice did not improve from 0.64880
Epoch 110/300
 - 15s - loss: 0.2460 - acc: 0.9516 - mDice: 0.7693 - val_loss: 0.4435 - val_acc: 0.9493 - val_mDice: 0.6329

Epoch 00110: val_mDice did not improve from 0.64880
Epoch 111/300
 - 14s - loss: 0.2465 - acc: 0.9514 - mDice: 0.7690 - val_loss: 0.4323 - val_acc: 0.9502 - val_mDice: 0.6398

Epoch 00111: val_mDice did not improve from 0.64880
Epoch 112/300
 - 14s - loss: 0.2459 - acc: 0.9518 - mDice: 0.7695 - val_loss: 0.4429 - val_acc: 0.9504 - val_mDice: 0.6348

Epoch 00112: val_mDice did not improve from 0.64880
Epoch 113/300
 - 14s - loss: 0.2462 - acc: 0.9518 - mDice: 0.7692 - val_loss: 0.4494 - val_acc: 0.9530 - val_mDice: 0.6331

Epoch 00113: val_mDice did not improve from 0.64880
Epoch 114/300
 - 14s - loss: 0.2473 - acc: 0.9517 - mDice: 0.7684 - val_loss: 0.4422 - val_acc: 0.9483 - val_mDice: 0.6336

Epoch 00114: val_mDice did not improve from 0.64880
Epoch 115/300
 - 14s - loss: 0.2445 - acc: 0.9518 - mDice: 0.7706 - val_loss: 0.4450 - val_acc: 0.9470 - val_mDice: 0.6308

Epoch 00115: val_mDice did not improve from 0.64880
Epoch 116/300
 - 14s - loss: 0.2455 - acc: 0.9518 - mDice: 0.7699 - val_loss: 0.4409 - val_acc: 0.9494 - val_mDice: 0.6356

Epoch 00116: val_mDice did not improve from 0.64880
Epoch 117/300
 - 15s - loss: 0.2446 - acc: 0.9519 - mDice: 0.7706 - val_loss: 0.4388 - val_acc: 0.9495 - val_mDice: 0.6354

Epoch 00117: val_mDice did not improve from 0.64880
Epoch 118/300
 - 14s - loss: 0.2435 - acc: 0.9519 - mDice: 0.7714 - val_loss: 0.4286 - val_acc: 0.9508 - val_mDice: 0.6421

Epoch 00118: val_mDice did not improve from 0.64880
Epoch 119/300
 - 14s - loss: 0.2447 - acc: 0.9517 - mDice: 0.7705 - val_loss: 0.4420 - val_acc: 0.9509 - val_mDice: 0.6349

Epoch 00119: val_mDice did not improve from 0.64880
Epoch 120/300
 - 14s - loss: 0.2420 - acc: 0.9520 - mDice: 0.7726 - val_loss: 0.4548 - val_acc: 0.9493 - val_mDice: 0.6282

Epoch 00120: val_mDice did not improve from 0.64880
Epoch 121/300
 - 14s - loss: 0.2418 - acc: 0.9520 - mDice: 0.7727 - val_loss: 0.4437 - val_acc: 0.9494 - val_mDice: 0.6325

Epoch 00121: val_mDice did not improve from 0.64880
Epoch 122/300
 - 14s - loss: 0.2451 - acc: 0.9519 - mDice: 0.7702 - val_loss: 0.4395 - val_acc: 0.9484 - val_mDice: 0.6349

Epoch 00122: val_mDice did not improve from 0.64880
Epoch 123/300
 - 14s - loss: 0.2427 - acc: 0.9518 - mDice: 0.7720 - val_loss: 0.4275 - val_acc: 0.9528 - val_mDice: 0.6441

Epoch 00123: val_mDice did not improve from 0.64880
Epoch 124/300
 - 14s - loss: 0.2407 - acc: 0.9521 - mDice: 0.7736 - val_loss: 0.4246 - val_acc: 0.9497 - val_mDice: 0.6434

Epoch 00124: val_mDice did not improve from 0.64880
Epoch 125/300
 - 15s - loss: 0.2405 - acc: 0.9522 - mDice: 0.7739 - val_loss: 0.4479 - val_acc: 0.9503 - val_mDice: 0.6315

Epoch 00125: val_mDice did not improve from 0.64880
Epoch 126/300
 - 14s - loss: 0.2409 - acc: 0.9522 - mDice: 0.7735 - val_loss: 0.4466 - val_acc: 0.9500 - val_mDice: 0.6318

Epoch 00126: val_mDice did not improve from 0.64880
Epoch 127/300
 - 14s - loss: 0.2400 - acc: 0.9521 - mDice: 0.7743 - val_loss: 0.4219 - val_acc: 0.9509 - val_mDice: 0.6468

Epoch 00127: val_mDice did not improve from 0.64880
Epoch 128/300
 - 14s - loss: 0.2416 - acc: 0.9521 - mDice: 0.7730 - val_loss: 0.4239 - val_acc: 0.9503 - val_mDice: 0.6449

Epoch 00128: val_mDice did not improve from 0.64880
Epoch 129/300
 - 15s - loss: 0.2381 - acc: 0.9524 - mDice: 0.7758 - val_loss: 0.4238 - val_acc: 0.9506 - val_mDice: 0.6446

Epoch 00129: val_mDice did not improve from 0.64880
Epoch 130/300
 - 15s - loss: 0.2403 - acc: 0.9522 - mDice: 0.7740 - val_loss: 0.4341 - val_acc: 0.9480 - val_mDice: 0.6372

Epoch 00130: val_mDice did not improve from 0.64880
Epoch 131/300
 - 14s - loss: 0.2383 - acc: 0.9524 - mDice: 0.7756 - val_loss: 0.4205 - val_acc: 0.9526 - val_mDice: 0.6471

Epoch 00131: val_mDice did not improve from 0.64880
Epoch 132/300
 - 14s - loss: 0.2393 - acc: 0.9522 - mDice: 0.7749 - val_loss: 0.4589 - val_acc: 0.9506 - val_mDice: 0.6261

Epoch 00132: val_mDice did not improve from 0.64880
Epoch 133/300
 - 14s - loss: 0.2402 - acc: 0.9522 - mDice: 0.7741 - val_loss: 0.4303 - val_acc: 0.9496 - val_mDice: 0.6405

Epoch 00133: val_mDice did not improve from 0.64880
Epoch 134/300
 - 15s - loss: 0.2390 - acc: 0.9524 - mDice: 0.7750 - val_loss: 0.4489 - val_acc: 0.9509 - val_mDice: 0.6312

Epoch 00134: val_mDice did not improve from 0.64880
Epoch 135/300
 - 14s - loss: 0.2417 - acc: 0.9522 - mDice: 0.7732 - val_loss: 0.4272 - val_acc: 0.9502 - val_mDice: 0.6434

Epoch 00135: val_mDice did not improve from 0.64880
Epoch 136/300
 - 14s - loss: 0.2387 - acc: 0.9525 - mDice: 0.7753 - val_loss: 0.4343 - val_acc: 0.9495 - val_mDice: 0.6393

Epoch 00136: val_mDice did not improve from 0.64880
Epoch 137/300
 - 14s - loss: 0.2370 - acc: 0.9525 - mDice: 0.7766 - val_loss: 0.4423 - val_acc: 0.9516 - val_mDice: 0.6363

Epoch 00137: val_mDice did not improve from 0.64880
Epoch 138/300
 - 14s - loss: 0.2378 - acc: 0.9525 - mDice: 0.7760 - val_loss: 0.4476 - val_acc: 0.9499 - val_mDice: 0.6324

Epoch 00138: val_mDice did not improve from 0.64880
Epoch 139/300
 - 14s - loss: 0.2375 - acc: 0.9525 - mDice: 0.7762 - val_loss: 0.4385 - val_acc: 0.9488 - val_mDice: 0.6362

Epoch 00139: val_mDice did not improve from 0.64880
Epoch 140/300
 - 15s - loss: 0.2380 - acc: 0.9525 - mDice: 0.7759 - val_loss: 0.4254 - val_acc: 0.9516 - val_mDice: 0.6445

Epoch 00140: val_mDice did not improve from 0.64880
Epoch 141/300
 - 14s - loss: 0.2368 - acc: 0.9526 - mDice: 0.7769 - val_loss: 0.4412 - val_acc: 0.9524 - val_mDice: 0.6380

Epoch 00141: val_mDice did not improve from 0.64880
Epoch 142/300
 - 14s - loss: 0.2344 - acc: 0.9527 - mDice: 0.7787 - val_loss: 0.4499 - val_acc: 0.9516 - val_mDice: 0.6315

Epoch 00142: val_mDice did not improve from 0.64880
Epoch 143/300
 - 14s - loss: 0.2340 - acc: 0.9528 - mDice: 0.7791 - val_loss: 0.4457 - val_acc: 0.9497 - val_mDice: 0.6321

Epoch 00143: val_mDice did not improve from 0.64880
Epoch 144/300
 - 14s - loss: 0.2350 - acc: 0.9526 - mDice: 0.7783 - val_loss: 0.4377 - val_acc: 0.9507 - val_mDice: 0.6370

Epoch 00144: val_mDice did not improve from 0.64880
Restoring model weights from the end of the best epoch
Epoch 00144: early stopping
{'val_loss': [0.8395409070783191, 0.6779317913783921, 0.7513823774125841, 0.5059755730132262, 0.5035719391372468, 0.49002478561467594, 0.49060123455193305, 0.4666618886921141, 0.46813762022389305, 0.45591281685564256, 0.454858241809739, 0.46425358744131195, 0.44799383357167244, 0.4691269513633516, 0.4538430952363544, 0.4502302172283332, 0.44408831207288635, 0.4394507710304525, 0.44881946676307255, 0.4484073192709022, 0.4415091748038928, 0.4416845159398185, 0.45819369206825894, 0.44195540125171345, 0.4377827209730943, 0.45658185250229305, 0.4790108572277758, 0.4499904505080647, 0.45731746446755195, 0.4544198136362765, 0.46690741885039544, 0.4394362469514211, 0.44350378173920846, 0.4637455956803428, 0.43599449056718087, 0.44327717439995873, 0.4436750118103292, 0.4584737494587898, 0.4416908162335555, 0.45554184044400853, 0.43512841107116806, 0.4464377202093601, 0.44429335329267716, 0.44270018943481976, 0.44507211446762085, 0.45394402535425293, 0.4717542839546998, 0.4403415119482411, 0.4536315898100535, 0.44629959099822575, 0.4505797036819988, 0.4477597052852313, 0.43889884899059933, 0.4354369305074215, 0.44321439498000675, 0.4529324012498061, 0.44054432875580257, 0.4345220381187068, 0.44074314791295266, 0.42668618137637776, 0.4573894172079033, 0.4314083543916543, 0.4484652384287781, 0.44526689416832393, 0.4363786064916187, 0.42538556084036827, 0.518792788601584, 0.43392689733041656, 0.4358989807466666, 0.42969734138912624, 0.41956671327352524, 0.42257826154430705, 0.42769630377491313, 0.43087375743521583, 0.45219693415694767, 0.4342846969763438, 0.44616824719640946, 0.42868741270568633, 0.44007927800218266, 0.42986036961277324, 0.42066406541400486, 0.4274417960809337, 0.4307000897824764, 0.4398332755598757, 0.4321475798885028, 0.44693777296278214, 0.4301452914045917, 0.44347743400269085, 0.4371408758064111, 0.4432937225533856, 0.42351652847396004, 0.4331762550605668, 0.43265730722082985, 0.42991523030731416, 0.42956090966860455, 0.4340683010717233, 0.4265695984164874, 0.4373214402132564, 0.43100840722521144, 0.42822272785835797, 0.43360234714216656, 0.4470485858619213, 0.43002354602018994, 0.41907201955715817, 0.4275841067234675, 0.4345105393893189, 0.43884749379422927, 0.44773494866159225, 0.4217904615733359, 0.4435490725768937, 0.4323097575041983, 0.44292472013168865, 0.44940437914596665, 0.44223638955089783, 0.44504334818985725, 0.4408594336774614, 0.4388217425180806, 0.42857491225004196, 0.44204334997468525, 0.4547725170850754, 0.443747579637501, 0.439512906389104, 0.42750027154882747, 0.4246249679062102, 0.44788489904668594, 0.44657701295283103, 0.4218713752925396, 0.4238918506436878, 0.4238267056643963, 0.43408433306548333, 0.4205374274816778, 0.4588756730986966, 0.43029745295643806, 0.44891789307196933, 0.42719822087221676, 0.43427513622575337, 0.44232741619149846, 0.4475776408281591, 0.4384893969529205, 0.4253978013164467, 0.4412399162020948, 0.44989991146657204, 0.445691569811768, 0.43770330564843285], 'val_acc': [0.9110099814004369, 0.9252979440821542, 0.9312312420871522, 0.9376287940475676, 0.94337766783105, 0.9437464947501818, 0.9452934430705177, 0.941120081477695, 0.9447862563861741, 0.947099486986796, 0.9470295260349909, 0.9458403214812279, 0.9480375034941567, 0.9407623708248138, 0.9479723125696182, 0.9460486049453417, 0.9503395797477828, 0.9498928487300873, 0.950342767768436, 0.9501567574010955, 0.9487783693604999, 0.9485160402125783, 0.9477465351422628, 0.9498101539081998, 0.9509930122229788, 0.949188522166676, 0.9496829931934675, 0.9495240135325326, 0.9436336250768768, 0.9499103294478523, 0.9481742307543755, 0.9492283024721675, 0.951608287791411, 0.9499198777808083, 0.9498801165156894, 0.9491805906097094, 0.9486193814211421, 0.9450803771615028, 0.9500979309280714, 0.9458721263541116, 0.9518229332235124, 0.9488976101080576, 0.9487831327650282, 0.9496782140599357, 0.9459532002607981, 0.9519183047943645, 0.9457735518614451, 0.9475907410184542, 0.9509453309906853, 0.9513078067037795, 0.9483189152346717, 0.9472823143005371, 0.9515939926107725, 0.9485939335491922, 0.9503952430354224, 0.950217179954052, 0.945425383746624, 0.9493157226178381, 0.9495192286041048, 0.9497386059827275, 0.9494524465666877, 0.9513761690921254, 0.9502680442399449, 0.9461312707927492, 0.9518404089742236, 0.9519532811310556, 0.9405048224661086, 0.9508117652601666, 0.9524143263697624, 0.950457240972254, 0.9500232173336877, 0.9511774215433333, 0.9500677237908045, 0.951186971531974, 0.9469865982731184, 0.9523825521270434, 0.9511806203259362, 0.9508594597379366, 0.9509644028213289, 0.9516544085409906, 0.949263271358278, 0.9526575803756714, 0.9508992243144248, 0.9495669197705057, 0.9493284391032325, 0.9490804407331679, 0.951253765159183, 0.9520184819897016, 0.9510613820619054, 0.951212416920397, 0.9510741002029843, 0.9485987035764588, 0.9513300673829185, 0.9505367229382197, 0.950353908042113, 0.9513952607909838, 0.9517672798699803, 0.9497735997041067, 0.9499961675869094, 0.9502394199371338, 0.948694098326895, 0.9509707581665781, 0.9507879291971525, 0.951355497042338, 0.9513300748334991, 0.9518674355414178, 0.9498101729485724, 0.9484413224789832, 0.9510439063111941, 0.9493045922782686, 0.9502473821242651, 0.9503650309311019, 0.9530295994546678, 0.9483475246363215, 0.9470327115721173, 0.9494238545497259, 0.9495319450894991, 0.9507974626289474, 0.9509182828995917, 0.9493300608462758, 0.9494031618038813, 0.9484111203087701, 0.9528451843394173, 0.9497259043984942, 0.9503062028023932, 0.9500009682443407, 0.9509055763483047, 0.9502775851223204, 0.9506448499030538, 0.9479611871971024, 0.9526035288969675, 0.9506352982587285, 0.9496464249160554, 0.9508769619796011, 0.9501790296700265, 0.94952399449216, 0.951648029188315, 0.9498626614610354, 0.9487704137961069, 0.9516066941950057, 0.952420691649119, 0.9516146456201872, 0.9497434000174204, 0.9507052650054296], 'val_mDice': [0.4247174561023712, 0.5117042710383733, 0.49985934586988556, 0.5909281414416101, 0.597609657380316, 0.6028324688474337, 0.6064916600783666, 0.6135677024722099, 0.6148713719513681, 0.6232362803485658, 0.6244012200170093, 0.6195816944042841, 0.6283055014080472, 0.6132255180014504, 0.6263479474518034, 0.6279426299863391, 0.633057134019004, 0.6367344218823645, 0.6325321710771985, 0.6329216932257017, 0.6346220937040117, 0.6337050067053901, 0.624915189213223, 0.6336259419719378, 0.6373724010255601, 0.6257611024710867, 0.618550167315536, 0.6306735508971744, 0.6211615585618548, 0.6284880696071519, 0.6223125830292702, 0.6347072132759624, 0.6350233025021024, 0.6267270553443167, 0.6385940288503965, 0.6349547050065465, 0.6324139129784372, 0.6230324192179574, 0.6356384547220336, 0.6245167098111577, 0.6413434189226892, 0.6335466421312757, 0.6319927896062533, 0.6340858745906088, 0.6301581313212713, 0.6307314758499464, 0.6204419781764349, 0.6354847227533659, 0.6327808143364059, 0.6342338422934214, 0.6295790150761604, 0.6309144579701953, 0.6368545376592212, 0.6382418523232142, 0.6358839703930749, 0.6305089170734087, 0.6327627566125658, 0.6385676082637575, 0.636106063094404, 0.6436963114473555, 0.6275169352690378, 0.640687575770749, 0.6329031255510118, 0.6315234493878152, 0.6387630303700765, 0.6447541705436177, 0.5878676705890231, 0.6401272747251723, 0.6396362458666166, 0.6417945408158832, 0.6461750467618307, 0.644945562713676, 0.6418040303720368, 0.6401739435063468, 0.6265743523836136, 0.6394767976469464, 0.6329240302244822, 0.6424936710132493, 0.6368237700727251, 0.6408036053180695, 0.6460923635297351, 0.6452131246527036, 0.641059122979641, 0.634666882455349, 0.639379663599862, 0.6319062958161036, 0.6420816464556588, 0.6352610215544701, 0.6387556675407622, 0.6355781083305677, 0.6454866967267461, 0.638821172217528, 0.6394422931803597, 0.6400644671585825, 0.6409905271397697, 0.6397203695442941, 0.6440993282530043, 0.6362127703097131, 0.6391911117566956, 0.6413670132557551, 0.6381777193811204, 0.6321246276299158, 0.6415947700540224, 0.6487982819477717, 0.6429551252060466, 0.6390532288286421, 0.6356500519646539, 0.6309147046671973, 0.6464315760466788, 0.6328843219412698, 0.6398396690686544, 0.6348467162913747, 0.6331461254093382, 0.633559080461661, 0.6307781032390065, 0.63560065958235, 0.6353960086901983, 0.6420957470933596, 0.6348613773783048, 0.628225117093987, 0.6325372929374377, 0.6349257578452429, 0.6441429762376679, 0.6433618350161446, 0.6314744916227129, 0.6317539827691184, 0.64680308683051, 0.6448615905311372, 0.644553430378437, 0.6372495806879468, 0.6471430609623591, 0.6260780708657371, 0.6405393390191926, 0.6311527523729537, 0.643393435411983, 0.6393076628446579, 0.6362854093313217, 0.6323923865954081, 0.6362128117018275, 0.6445320323109627, 0.6379756414228015, 0.631476127439075, 0.6321098109086355, 0.6370303059617678], 'loss': [2.02140495915185, 0.7180802116620969, 0.6418064974151017, 0.544171386958386, 0.5081467635235658, 0.4754455891784792, 0.4550500868277904, 0.4544136662864023, 0.4283996976278966, 0.41674912638134426, 0.404433726680045, 0.3937392815813617, 0.38712732627184365, 0.3832463069569344, 0.37526074438995005, 0.36850835637986856, 0.3763020768627719, 0.3567065137188906, 0.353205724461065, 0.3484775152276544, 0.3445863347999703, 0.3405586443658845, 0.3366855683438236, 0.360859512814071, 0.3352875387892614, 0.3302666832102475, 0.32902405426831416, 0.3280585413141286, 0.32252648099039505, 0.31925638432133624, 0.319016195109321, 0.3130839093363071, 0.31110086200113585, 0.30991966742413496, 0.31043029634367214, 0.3080533690190588, 0.3034913727246663, 0.3029823534531531, 0.2997552802652315, 0.3112884873122561, 0.2979979953862532, 0.2960111249688696, 0.3024740925825694, 0.29208397477244336, 0.2931817213889041, 0.29006911469684316, 0.2902186144739876, 0.2869409554686665, 0.2984125321621404, 0.28319809401066964, 0.32712452399112235, 0.29434419135423073, 0.28515821784199064, 0.2822166974199753, 0.280042379154075, 0.2776189941876367, 0.27722306018147397, 0.2762414172285669, 0.27755553017559104, 0.28244309077416757, 0.27397923611007097, 0.2750205178532043, 0.2726397557074533, 0.27195762756457126, 0.2727740098801411, 0.27081074521517734, 0.32828152755555373, 0.3042612491400754, 0.28164729413886863, 0.2733006104887798, 0.2699234240408378, 0.26804761199000615, 0.26712317479275216, 0.26560871464997726, 0.266811643711906, 0.26538589230610754, 0.2632724216506129, 0.26290759013576154, 0.2624157535222669, 0.2631872308050934, 0.26882757429106563, 0.2612944881468281, 0.26101346276213533, 0.25940443375117445, 0.2592140580405743, 0.2596906973201222, 0.25695987050634583, 0.25779652681347787, 0.2642899877087402, 0.25612343775924123, 0.2560004069640307, 0.2557653245254377, 0.25449434323297215, 0.25734187822082855, 0.253646446102804, 0.2537342883110826, 0.2528446491631174, 0.2518807099614706, 0.2518516103980539, 0.25228434914625647, 0.25027339378968366, 0.2512800402245393, 0.24917797878798512, 0.25039609760545145, 0.2508917492418702, 0.24895875495280217, 0.24814140274085933, 0.24805517773770916, 0.24766697848422659, 0.24603231944557694, 0.24649274588739073, 0.2459062051174103, 0.24620397845770117, 0.24731960700325717, 0.24445500410180174, 0.24547403600079074, 0.244593411461858, 0.24354896996949427, 0.24468760008260218, 0.24199367072007139, 0.2418097798755161, 0.24513207894013403, 0.24273998526478904, 0.24073623112567208, 0.24051402116291762, 0.24086341069207765, 0.23995056924915392, 0.24163180716287078, 0.2380836581646958, 0.24029921832208345, 0.23833163992008743, 0.23931799135383924, 0.2402077190109279, 0.23901750974880617, 0.2417300450859068, 0.2387251190055965, 0.2370058917592651, 0.23784021829297536, 0.2375101893379359, 0.23799616804200352, 0.23675912219629275, 0.23442323752100658, 0.23403901767496968, 0.23499869787152491], 'acc': [0.7253349763280377, 0.8934766911822402, 0.9093188223325543, 0.9209135409834144, 0.9248346392235725, 0.9286813841390065, 0.9311842466369759, 0.9318902069714918, 0.9342097239386217, 0.9352747528552036, 0.9366938313164936, 0.9379618718027095, 0.9384406262314787, 0.9390623024451772, 0.9399347323072113, 0.9404774548400656, 0.9401148515053435, 0.9418078507935884, 0.9420048261511754, 0.9425720525479394, 0.9427002202475967, 0.9432131569296901, 0.9435632709486812, 0.9412386855171397, 0.9438142100945602, 0.9444197551803846, 0.9444172077757471, 0.9445860816372765, 0.9449480290895973, 0.9453256144949229, 0.9454482932471566, 0.9458034576641189, 0.9459428975200341, 0.9461345678816239, 0.9459076870987618, 0.9463159500262122, 0.9466479703467461, 0.9467257080490098, 0.9468900010208873, 0.946539182459412, 0.9470252307631026, 0.947331813060575, 0.9474728875763081, 0.9476629688581025, 0.9476512305901136, 0.9478206921709713, 0.947860087712411, 0.9480890716529555, 0.9468846941987673, 0.9483876568843531, 0.944048242521734, 0.9474381943251572, 0.9483031856346559, 0.9484495468729851, 0.9487239571129964, 0.9488647762759059, 0.9489496454012161, 0.9490930608114581, 0.948972275395409, 0.9492352545699653, 0.9491759410821924, 0.9493185834216527, 0.9494013235070347, 0.9494069609912782, 0.9495148123820233, 0.9495284647674732, 0.9438198471892308, 0.9464360299745417, 0.9485569060506189, 0.9492529794525087, 0.9495711128769162, 0.9497029507057924, 0.949860041644546, 0.949909232970741, 0.9498897817935429, 0.9500509405910385, 0.9500879057457828, 0.9502325778449673, 0.9502950070024121, 0.9500739946474437, 0.9498761541459685, 0.9503273627799905, 0.9503736075476493, 0.9503726763224679, 0.9504827944062699, 0.9503509294168622, 0.9506026848761084, 0.9506213901430564, 0.9506513182731235, 0.9507471303412922, 0.950713787873099, 0.9507620216292494, 0.9510469800896115, 0.9508129451423883, 0.9508349196437527, 0.9510060153244173, 0.951118734744347, 0.9510731888581919, 0.9511368278827932, 0.9511683219495941, 0.951274606466196, 0.9511711987745918, 0.9514277687941501, 0.9512501979989358, 0.9513611374605521, 0.951401956488981, 0.9513672382686458, 0.951391039172711, 0.9515242354055635, 0.9516249818033448, 0.9514453291917354, 0.9518001939906598, 0.9517534302754534, 0.9517024185240658, 0.9518494781204103, 0.9517642316572806, 0.9518762015634112, 0.9518962131533163, 0.9517344025517601, 0.9519842151503742, 0.952006590948288, 0.9518898310979792, 0.9518481204955797, 0.9521485068196175, 0.9522132231957383, 0.9521738053390792, 0.9521217614631442, 0.9520593144827418, 0.9523770010184034, 0.9522172462657775, 0.9523933196769041, 0.9521787854678491, 0.9521841382108678, 0.9524155074937476, 0.9521680289721177, 0.9524673664564985, 0.9524847585829644, 0.9524525650259521, 0.9524964247556293, 0.9524745214000052, 0.952588357165261, 0.952693544912572, 0.9528039473358517, 0.9526430874015965], 'mDice': [0.2183728271374765, 0.4791581806258049, 0.5193301222828868, 0.5679547036906668, 0.5886044737219421, 0.6078409035903176, 0.6208256593010589, 0.6232586806652203, 0.6379012440763463, 0.6451313420643214, 0.6533450541981295, 0.6605570719279106, 0.6649242138940524, 0.6681636053021827, 0.6733299390674611, 0.6778416560074083, 0.6732277502640595, 0.6860277629609591, 0.6886152851401396, 0.6919145451651679, 0.6946614953427533, 0.6975380918558907, 0.7004346881743545, 0.6847161426531528, 0.7014736400466729, 0.7051154096653454, 0.7060431811495934, 0.7070892265833476, 0.7107633442733607, 0.7132662409076503, 0.7137982835323592, 0.7176723102825919, 0.7192126704026865, 0.7200209164225003, 0.7196356431623689, 0.7214008836696545, 0.7248993196153368, 0.7251403600196628, 0.7275625358950468, 0.7240486574036623, 0.7288064821653701, 0.7304152365092164, 0.7310093442842461, 0.7333979256134602, 0.7326196792955492, 0.7349577649965201, 0.7347204287846884, 0.7372766345544578, 0.7290628048183482, 0.7400865216124681, 0.7102090630655974, 0.731744987464029, 0.7387563118138929, 0.7408807433265097, 0.7425774170536231, 0.7444337126525009, 0.7446164272579492, 0.7455940396567575, 0.744574851143399, 0.7460087660480949, 0.7471685332605262, 0.7464647930894607, 0.748416450799875, 0.7487916992429424, 0.7483809528129748, 0.7497198679210508, 0.7189168258162301, 0.7245332266818854, 0.7414215394947069, 0.7477444238303339, 0.750299844330822, 0.751869823211451, 0.7526499550253932, 0.7537568803219235, 0.7529405612693308, 0.7543072637438385, 0.7555128065564858, 0.7558589875089382, 0.7563522876502057, 0.7557607314677215, 0.7514638308240892, 0.7571855514657264, 0.757438288514618, 0.7586636473759522, 0.7589253631049122, 0.7585382482243909, 0.7605383347939042, 0.7600501097276126, 0.7598578355889889, 0.7613051020923782, 0.7613644469164166, 0.7615416119593421, 0.7626422643296275, 0.7604337467818089, 0.7632239611174156, 0.7631582736944645, 0.7638448660499325, 0.7646072819780291, 0.7646508238893124, 0.7642973879583521, 0.7658955996941312, 0.7652227159199956, 0.7668140574169704, 0.7658238565196204, 0.7654491744058973, 0.7670367486361, 0.7676179453097527, 0.7677118377212215, 0.7680015944407071, 0.7693323971691475, 0.7689825024187954, 0.7695428011878058, 0.7691886106542513, 0.7683830709239237, 0.7705510246987436, 0.7698522327114748, 0.7705755753479168, 0.7713752140966701, 0.7704591648957504, 0.7725784210427329, 0.772659474472497, 0.7701888644179098, 0.7720053650901403, 0.7735915283970778, 0.7738615379979213, 0.7734778188899452, 0.7742506075236533, 0.7729786214071745, 0.7757544940812331, 0.7740262874761243, 0.775559691127901, 0.7748538867199148, 0.774107596100448, 0.7750086572776044, 0.7732478724123021, 0.7753239895515387, 0.7766340551228305, 0.7760434399657195, 0.7762457216828088, 0.7759371626805636, 0.776887135738446, 0.7787152033031376, 0.7791223290796373, 0.7782911064310206]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:11,  3.86s/it]predicting test subjects:  50%|█████     | 2/4 [00:06<00:07,  3.61s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:09<00:03,  3.38s/it]predicting test subjects: 100%|██████████| 4/4 [00:12<00:00,  3.32s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<16:28,  3.73s/it]predicting train subjects:   1%|          | 2/266 [00:07<16:06,  3.66s/it]predicting train subjects:   1%|          | 3/266 [00:10<15:07,  3.45s/it]predicting train subjects:   2%|▏         | 4/266 [00:12<13:41,  3.13s/it]predicting train subjects:   2%|▏         | 5/266 [00:15<13:22,  3.08s/it]predicting train subjects:   2%|▏         | 6/266 [00:18<13:46,  3.18s/it]predicting train subjects:   3%|▎         | 7/266 [00:22<13:51,  3.21s/it]predicting train subjects:   3%|▎         | 8/266 [00:25<13:40,  3.18s/it]predicting train subjects:   3%|▎         | 9/266 [00:28<13:37,  3.18s/it]predicting train subjects:   4%|▍         | 10/266 [00:31<13:29,  3.16s/it]predicting train subjects:   4%|▍         | 11/266 [00:34<13:35,  3.20s/it]predicting train subjects:   5%|▍         | 12/266 [00:37<13:07,  3.10s/it]predicting train subjects:   5%|▍         | 13/266 [00:41<13:15,  3.15s/it]predicting train subjects:   5%|▌         | 14/266 [00:44<13:08,  3.13s/it]predicting train subjects:   6%|▌         | 15/266 [00:47<13:07,  3.14s/it]predicting train subjects:   6%|▌         | 16/266 [00:50<13:06,  3.15s/it]predicting train subjects:   6%|▋         | 17/266 [00:53<13:02,  3.14s/it]predicting train subjects:   7%|▋         | 18/266 [00:56<13:06,  3.17s/it]predicting train subjects:   7%|▋         | 19/266 [01:00<13:12,  3.21s/it]predicting train subjects:   8%|▊         | 20/266 [01:03<13:19,  3.25s/it]predicting train subjects:   8%|▊         | 21/266 [01:06<12:51,  3.15s/it]predicting train subjects:   8%|▊         | 22/266 [01:09<12:47,  3.14s/it]predicting train subjects:   9%|▊         | 23/266 [01:12<12:48,  3.16s/it]predicting train subjects:   9%|▉         | 24/266 [01:16<12:56,  3.21s/it]predicting train subjects:   9%|▉         | 25/266 [01:19<12:34,  3.13s/it]predicting train subjects:  10%|▉         | 26/266 [01:22<12:30,  3.13s/it]predicting train subjects:  10%|█         | 27/266 [01:25<12:38,  3.17s/it]predicting train subjects:  11%|█         | 28/266 [01:28<12:13,  3.08s/it]predicting train subjects:  11%|█         | 29/266 [01:31<12:04,  3.06s/it]predicting train subjects:  11%|█▏        | 30/266 [01:34<11:52,  3.02s/it]predicting train subjects:  12%|█▏        | 31/266 [01:37<12:06,  3.09s/it]predicting train subjects:  12%|█▏        | 32/266 [01:40<12:22,  3.17s/it]predicting train subjects:  12%|█▏        | 33/266 [01:43<12:12,  3.14s/it]predicting train subjects:  13%|█▎        | 34/266 [01:46<12:04,  3.12s/it]predicting train subjects:  13%|█▎        | 35/266 [01:50<12:13,  3.18s/it]predicting train subjects:  14%|█▎        | 36/266 [01:53<12:03,  3.14s/it]predicting train subjects:  14%|█▍        | 37/266 [01:56<11:54,  3.12s/it]predicting train subjects:  14%|█▍        | 38/266 [01:59<11:37,  3.06s/it]predicting train subjects:  15%|█▍        | 39/266 [02:02<11:17,  2.99s/it]predicting train subjects:  15%|█▌        | 40/266 [02:05<11:16,  2.99s/it]predicting train subjects:  15%|█▌        | 41/266 [02:08<11:46,  3.14s/it]predicting train subjects:  16%|█▌        | 42/266 [02:11<11:29,  3.08s/it]predicting train subjects:  16%|█▌        | 43/266 [02:14<11:16,  3.03s/it]predicting train subjects:  17%|█▋        | 44/266 [02:17<11:12,  3.03s/it]predicting train subjects:  17%|█▋        | 45/266 [02:20<11:09,  3.03s/it]predicting train subjects:  17%|█▋        | 46/266 [02:23<10:43,  2.93s/it]predicting train subjects:  18%|█▊        | 47/266 [02:26<11:09,  3.05s/it]predicting train subjects:  18%|█▊        | 48/266 [02:29<11:03,  3.04s/it]predicting train subjects:  18%|█▊        | 49/266 [02:32<11:00,  3.04s/it]predicting train subjects:  19%|█▉        | 50/266 [02:35<10:42,  2.97s/it]predicting train subjects:  19%|█▉        | 51/266 [02:38<10:35,  2.96s/it]predicting train subjects:  20%|█▉        | 52/266 [02:41<10:36,  2.97s/it]predicting train subjects:  20%|█▉        | 53/266 [02:44<10:48,  3.04s/it]predicting train subjects:  20%|██        | 54/266 [02:47<10:40,  3.02s/it]predicting train subjects:  21%|██        | 55/266 [02:50<10:56,  3.11s/it]predicting train subjects:  21%|██        | 56/266 [02:53<10:47,  3.08s/it]predicting train subjects:  21%|██▏       | 57/266 [02:56<10:24,  2.99s/it]predicting train subjects:  22%|██▏       | 58/266 [02:59<10:30,  3.03s/it]predicting train subjects:  22%|██▏       | 59/266 [03:02<10:14,  2.97s/it]predicting train subjects:  23%|██▎       | 60/266 [03:05<09:57,  2.90s/it]predicting train subjects:  23%|██▎       | 61/266 [03:08<09:53,  2.90s/it]predicting train subjects:  23%|██▎       | 62/266 [03:11<09:49,  2.89s/it]predicting train subjects:  24%|██▎       | 63/266 [03:14<09:49,  2.91s/it]predicting train subjects:  24%|██▍       | 64/266 [03:16<09:25,  2.80s/it]predicting train subjects:  24%|██▍       | 65/266 [03:19<09:27,  2.82s/it]predicting train subjects:  25%|██▍       | 66/266 [03:22<09:27,  2.84s/it]predicting train subjects:  25%|██▌       | 67/266 [03:25<09:25,  2.84s/it]predicting train subjects:  26%|██▌       | 68/266 [03:27<09:10,  2.78s/it]predicting train subjects:  26%|██▌       | 69/266 [03:30<09:05,  2.77s/it]predicting train subjects:  26%|██▋       | 70/266 [03:33<09:05,  2.79s/it]predicting train subjects:  27%|██▋       | 71/266 [03:36<09:03,  2.79s/it]predicting train subjects:  27%|██▋       | 72/266 [03:38<08:47,  2.72s/it]predicting train subjects:  27%|██▋       | 73/266 [03:41<08:34,  2.67s/it]predicting train subjects:  28%|██▊       | 74/266 [03:44<08:49,  2.76s/it]predicting train subjects:  28%|██▊       | 75/266 [03:46<08:42,  2.73s/it]predicting train subjects:  29%|██▊       | 76/266 [03:49<08:41,  2.75s/it]predicting train subjects:  29%|██▉       | 77/266 [03:52<08:29,  2.69s/it]predicting train subjects:  29%|██▉       | 78/266 [03:55<09:03,  2.89s/it]predicting train subjects:  30%|██▉       | 79/266 [03:59<09:43,  3.12s/it]predicting train subjects:  30%|███       | 80/266 [04:02<09:58,  3.22s/it]predicting train subjects:  30%|███       | 81/266 [04:06<10:24,  3.37s/it]predicting train subjects:  31%|███       | 82/266 [04:10<10:44,  3.50s/it]predicting train subjects:  31%|███       | 83/266 [04:14<10:59,  3.61s/it]predicting train subjects:  32%|███▏      | 84/266 [04:18<11:19,  3.73s/it]predicting train subjects:  32%|███▏      | 85/266 [04:21<11:05,  3.68s/it]predicting train subjects:  32%|███▏      | 86/266 [04:25<11:15,  3.75s/it]predicting train subjects:  33%|███▎      | 87/266 [04:29<11:13,  3.76s/it]predicting train subjects:  33%|███▎      | 88/266 [04:33<11:03,  3.72s/it]predicting train subjects:  33%|███▎      | 89/266 [04:36<11:01,  3.74s/it]predicting train subjects:  34%|███▍      | 90/266 [04:41<11:39,  3.97s/it]predicting train subjects:  34%|███▍      | 91/266 [04:45<11:55,  4.09s/it]predicting train subjects:  35%|███▍      | 92/266 [04:49<11:51,  4.09s/it]predicting train subjects:  35%|███▍      | 93/266 [04:53<11:37,  4.03s/it]predicting train subjects:  35%|███▌      | 94/266 [04:57<11:44,  4.09s/it]predicting train subjects:  36%|███▌      | 95/266 [05:02<12:07,  4.25s/it]predicting train subjects:  36%|███▌      | 96/266 [05:06<11:41,  4.13s/it]predicting train subjects:  36%|███▋      | 97/266 [05:10<11:20,  4.03s/it]predicting train subjects:  37%|███▋      | 98/266 [05:14<11:21,  4.06s/it]predicting train subjects:  37%|███▋      | 99/266 [05:17<10:15,  3.69s/it]predicting train subjects:  38%|███▊      | 100/266 [05:20<10:05,  3.65s/it]predicting train subjects:  38%|███▊      | 101/266 [05:24<10:21,  3.76s/it]predicting train subjects:  38%|███▊      | 102/266 [05:28<10:25,  3.81s/it]predicting train subjects:  39%|███▊      | 103/266 [05:32<10:05,  3.72s/it]predicting train subjects:  39%|███▉      | 104/266 [05:36<10:11,  3.78s/it]predicting train subjects:  39%|███▉      | 105/266 [05:39<10:06,  3.77s/it]predicting train subjects:  40%|███▉      | 106/266 [05:43<10:13,  3.83s/it]predicting train subjects:  40%|████      | 107/266 [05:47<10:18,  3.89s/it]predicting train subjects:  41%|████      | 108/266 [05:51<10:10,  3.86s/it]predicting train subjects:  41%|████      | 109/266 [05:54<09:39,  3.69s/it]predicting train subjects:  41%|████▏     | 110/266 [05:58<09:44,  3.74s/it]predicting train subjects:  42%|████▏     | 111/266 [06:02<09:42,  3.76s/it]predicting train subjects:  42%|████▏     | 112/266 [06:06<09:57,  3.88s/it]predicting train subjects:  42%|████▏     | 113/266 [06:10<09:26,  3.71s/it]predicting train subjects:  43%|████▎     | 114/266 [06:13<09:26,  3.73s/it]predicting train subjects:  43%|████▎     | 115/266 [06:17<09:33,  3.80s/it]predicting train subjects:  44%|████▎     | 116/266 [06:21<09:43,  3.89s/it]predicting train subjects:  44%|████▍     | 117/266 [06:26<09:51,  3.97s/it]predicting train subjects:  44%|████▍     | 118/266 [06:30<09:49,  3.98s/it]predicting train subjects:  45%|████▍     | 119/266 [06:34<09:54,  4.04s/it]predicting train subjects:  45%|████▌     | 120/266 [06:38<10:18,  4.24s/it]predicting train subjects:  45%|████▌     | 121/266 [06:42<10:03,  4.16s/it]predicting train subjects:  46%|████▌     | 122/266 [06:47<10:16,  4.28s/it]predicting train subjects:  46%|████▌     | 123/266 [06:51<10:19,  4.33s/it]predicting train subjects:  47%|████▋     | 124/266 [06:56<10:19,  4.36s/it]predicting train subjects:  47%|████▋     | 125/266 [07:00<10:01,  4.27s/it]predicting train subjects:  47%|████▋     | 126/266 [07:04<09:41,  4.15s/it]predicting train subjects:  48%|████▊     | 127/266 [07:08<09:44,  4.20s/it]predicting train subjects:  48%|████▊     | 128/266 [07:12<09:27,  4.11s/it]predicting train subjects:  48%|████▊     | 129/266 [07:16<09:04,  3.97s/it]predicting train subjects:  49%|████▉     | 130/266 [07:20<09:12,  4.06s/it]predicting train subjects:  49%|████▉     | 131/266 [07:24<09:06,  4.05s/it]predicting train subjects:  50%|████▉     | 132/266 [07:28<09:01,  4.04s/it]predicting train subjects:  50%|█████     | 133/266 [07:32<09:12,  4.15s/it]predicting train subjects:  50%|█████     | 134/266 [07:36<09:00,  4.10s/it]predicting train subjects:  51%|█████     | 135/266 [07:40<08:57,  4.11s/it]predicting train subjects:  51%|█████     | 136/266 [07:45<08:51,  4.09s/it]predicting train subjects:  52%|█████▏    | 137/266 [07:49<08:55,  4.15s/it]predicting train subjects:  52%|█████▏    | 138/266 [07:53<08:58,  4.21s/it]predicting train subjects:  52%|█████▏    | 139/266 [07:57<08:57,  4.23s/it]predicting train subjects:  53%|█████▎    | 140/266 [08:02<08:57,  4.26s/it]predicting train subjects:  53%|█████▎    | 141/266 [08:05<08:31,  4.09s/it]predicting train subjects:  53%|█████▎    | 142/266 [08:10<08:31,  4.12s/it]predicting train subjects:  54%|█████▍    | 143/266 [08:14<08:34,  4.19s/it]predicting train subjects:  54%|█████▍    | 144/266 [08:18<08:13,  4.05s/it]predicting train subjects:  55%|█████▍    | 145/266 [08:22<08:03,  4.00s/it]predicting train subjects:  55%|█████▍    | 146/266 [08:25<07:51,  3.93s/it]predicting train subjects:  55%|█████▌    | 147/266 [08:30<08:11,  4.13s/it]predicting train subjects:  56%|█████▌    | 148/266 [08:35<08:20,  4.25s/it]predicting train subjects:  56%|█████▌    | 149/266 [08:39<08:12,  4.21s/it]predicting train subjects:  56%|█████▋    | 150/266 [08:43<08:23,  4.34s/it]predicting train subjects:  57%|█████▋    | 151/266 [08:47<08:03,  4.21s/it]predicting train subjects:  57%|█████▋    | 152/266 [08:51<07:54,  4.17s/it]predicting train subjects:  58%|█████▊    | 153/266 [08:56<08:03,  4.28s/it]predicting train subjects:  58%|█████▊    | 154/266 [09:00<07:55,  4.24s/it]predicting train subjects:  58%|█████▊    | 155/266 [09:03<07:18,  3.95s/it]predicting train subjects:  59%|█████▊    | 156/266 [09:06<06:38,  3.63s/it]predicting train subjects:  59%|█████▉    | 157/266 [09:10<06:44,  3.71s/it]predicting train subjects:  59%|█████▉    | 158/266 [09:13<06:29,  3.61s/it]predicting train subjects:  60%|█████▉    | 159/266 [09:17<06:23,  3.59s/it]predicting train subjects:  60%|██████    | 160/266 [09:20<06:01,  3.41s/it]predicting train subjects:  61%|██████    | 161/266 [09:23<05:47,  3.31s/it]predicting train subjects:  61%|██████    | 162/266 [09:26<05:40,  3.27s/it]predicting train subjects:  61%|██████▏   | 163/266 [09:29<05:28,  3.19s/it]predicting train subjects:  62%|██████▏   | 164/266 [09:33<05:35,  3.29s/it]predicting train subjects:  62%|██████▏   | 165/266 [09:36<05:26,  3.23s/it]predicting train subjects:  62%|██████▏   | 166/266 [09:39<05:25,  3.26s/it]predicting train subjects:  63%|██████▎   | 167/266 [09:42<05:10,  3.14s/it]predicting train subjects:  63%|██████▎   | 168/266 [09:45<05:01,  3.08s/it]predicting train subjects:  64%|██████▎   | 169/266 [09:48<04:58,  3.07s/it]predicting train subjects:  64%|██████▍   | 170/266 [09:52<05:12,  3.25s/it]predicting train subjects:  64%|██████▍   | 171/266 [09:55<05:06,  3.22s/it]predicting train subjects:  65%|██████▍   | 172/266 [09:58<04:54,  3.13s/it]predicting train subjects:  65%|██████▌   | 173/266 [10:01<04:58,  3.20s/it]predicting train subjects:  65%|██████▌   | 174/266 [10:04<05:00,  3.26s/it]predicting train subjects:  66%|██████▌   | 175/266 [10:08<05:01,  3.31s/it]predicting train subjects:  66%|██████▌   | 176/266 [10:12<05:11,  3.46s/it]predicting train subjects:  67%|██████▋   | 177/266 [10:16<05:17,  3.57s/it]predicting train subjects:  67%|██████▋   | 178/266 [10:19<05:07,  3.49s/it]predicting train subjects:  67%|██████▋   | 179/266 [10:22<04:58,  3.43s/it]predicting train subjects:  68%|██████▊   | 180/266 [10:25<04:51,  3.39s/it]predicting train subjects:  68%|██████▊   | 181/266 [10:29<04:58,  3.51s/it]predicting train subjects:  68%|██████▊   | 182/266 [10:33<04:57,  3.55s/it]predicting train subjects:  69%|██████▉   | 183/266 [10:36<04:51,  3.51s/it]predicting train subjects:  69%|██████▉   | 184/266 [10:40<04:52,  3.56s/it]predicting train subjects:  70%|██████▉   | 185/266 [10:44<04:56,  3.67s/it]predicting train subjects:  70%|██████▉   | 186/266 [10:47<04:52,  3.66s/it]predicting train subjects:  70%|███████   | 187/266 [10:51<04:51,  3.69s/it]predicting train subjects:  71%|███████   | 188/266 [10:55<04:37,  3.56s/it]predicting train subjects:  71%|███████   | 189/266 [10:58<04:36,  3.60s/it]predicting train subjects:  71%|███████▏  | 190/266 [11:02<04:37,  3.65s/it]predicting train subjects:  72%|███████▏  | 191/266 [11:06<04:35,  3.67s/it]predicting train subjects:  72%|███████▏  | 192/266 [11:09<04:24,  3.58s/it]predicting train subjects:  73%|███████▎  | 193/266 [11:13<04:19,  3.56s/it]predicting train subjects:  73%|███████▎  | 194/266 [11:16<04:24,  3.67s/it]predicting train subjects:  73%|███████▎  | 195/266 [11:20<04:20,  3.67s/it]predicting train subjects:  74%|███████▎  | 196/266 [11:24<04:15,  3.64s/it]predicting train subjects:  74%|███████▍  | 197/266 [11:27<04:10,  3.63s/it]predicting train subjects:  74%|███████▍  | 198/266 [11:31<04:12,  3.72s/it]predicting train subjects:  75%|███████▍  | 199/266 [11:35<04:10,  3.75s/it]predicting train subjects:  75%|███████▌  | 200/266 [11:39<04:13,  3.84s/it]predicting train subjects:  76%|███████▌  | 201/266 [11:43<04:12,  3.88s/it]predicting train subjects:  76%|███████▌  | 202/266 [11:47<04:08,  3.88s/it]predicting train subjects:  76%|███████▋  | 203/266 [11:51<04:01,  3.84s/it]predicting train subjects:  77%|███████▋  | 204/266 [11:55<03:59,  3.86s/it]predicting train subjects:  77%|███████▋  | 205/266 [11:59<04:06,  4.05s/it]predicting train subjects:  77%|███████▋  | 206/266 [12:03<03:59,  3.99s/it]predicting train subjects:  78%|███████▊  | 207/266 [12:07<04:02,  4.12s/it]predicting train subjects:  78%|███████▊  | 208/266 [12:11<03:58,  4.11s/it]predicting train subjects:  79%|███████▊  | 209/266 [12:15<03:48,  4.02s/it]predicting train subjects:  79%|███████▉  | 210/266 [12:19<03:35,  3.86s/it]predicting train subjects:  79%|███████▉  | 211/266 [12:23<03:35,  3.93s/it]predicting train subjects:  80%|███████▉  | 212/266 [12:27<03:35,  3.99s/it]predicting train subjects:  80%|████████  | 213/266 [12:30<03:17,  3.73s/it]predicting train subjects:  80%|████████  | 214/266 [12:33<03:05,  3.58s/it]predicting train subjects:  81%|████████  | 215/266 [12:37<02:56,  3.47s/it]predicting train subjects:  81%|████████  | 216/266 [12:40<02:55,  3.50s/it]predicting train subjects:  82%|████████▏ | 217/266 [12:43<02:49,  3.46s/it]predicting train subjects:  82%|████████▏ | 218/266 [12:47<02:47,  3.50s/it]predicting train subjects:  82%|████████▏ | 219/266 [12:51<02:45,  3.52s/it]predicting train subjects:  83%|████████▎ | 220/266 [12:54<02:36,  3.40s/it]predicting train subjects:  83%|████████▎ | 221/266 [12:57<02:37,  3.50s/it]predicting train subjects:  83%|████████▎ | 222/266 [13:01<02:32,  3.46s/it]predicting train subjects:  84%|████████▍ | 223/266 [13:05<02:34,  3.59s/it]predicting train subjects:  84%|████████▍ | 224/266 [13:09<02:33,  3.66s/it]predicting train subjects:  85%|████████▍ | 225/266 [13:12<02:29,  3.65s/it]predicting train subjects:  85%|████████▍ | 226/266 [13:16<02:26,  3.66s/it]predicting train subjects:  85%|████████▌ | 227/266 [13:20<02:25,  3.72s/it]predicting train subjects:  86%|████████▌ | 228/266 [13:23<02:19,  3.68s/it]predicting train subjects:  86%|████████▌ | 229/266 [13:27<02:16,  3.68s/it]predicting train subjects:  86%|████████▋ | 230/266 [13:31<02:14,  3.73s/it]predicting train subjects:  87%|████████▋ | 231/266 [13:35<02:10,  3.74s/it]predicting train subjects:  87%|████████▋ | 232/266 [13:38<02:03,  3.63s/it]predicting train subjects:  88%|████████▊ | 233/266 [13:42<01:59,  3.62s/it]predicting train subjects:  88%|████████▊ | 234/266 [13:45<01:56,  3.63s/it]predicting train subjects:  88%|████████▊ | 235/266 [13:48<01:48,  3.50s/it]predicting train subjects:  89%|████████▊ | 236/266 [13:52<01:45,  3.52s/it]predicting train subjects:  89%|████████▉ | 237/266 [13:56<01:42,  3.52s/it]predicting train subjects:  89%|████████▉ | 238/266 [13:59<01:39,  3.55s/it]predicting train subjects:  90%|████████▉ | 239/266 [14:03<01:36,  3.58s/it]predicting train subjects:  90%|█████████ | 240/266 [14:07<01:34,  3.62s/it]predicting train subjects:  91%|█████████ | 241/266 [14:11<01:34,  3.78s/it]predicting train subjects:  91%|█████████ | 242/266 [14:14<01:29,  3.72s/it]predicting train subjects:  91%|█████████▏| 243/266 [14:17<01:21,  3.53s/it]predicting train subjects:  92%|█████████▏| 244/266 [14:21<01:18,  3.55s/it]predicting train subjects:  92%|█████████▏| 245/266 [14:25<01:15,  3.60s/it]predicting train subjects:  92%|█████████▏| 246/266 [14:28<01:12,  3.63s/it]predicting train subjects:  93%|█████████▎| 247/266 [14:32<01:09,  3.67s/it]predicting train subjects:  93%|█████████▎| 248/266 [14:36<01:07,  3.75s/it]predicting train subjects:  94%|█████████▎| 249/266 [14:41<01:07,  3.96s/it]predicting train subjects:  94%|█████████▍| 250/266 [14:45<01:06,  4.16s/it]predicting train subjects:  94%|█████████▍| 251/266 [14:50<01:03,  4.26s/it]predicting train subjects:  95%|█████████▍| 252/266 [14:54<01:01,  4.37s/it]predicting train subjects:  95%|█████████▌| 253/266 [14:59<00:56,  4.37s/it]predicting train subjects:  95%|█████████▌| 254/266 [15:03<00:52,  4.35s/it]predicting train subjects:  96%|█████████▌| 255/266 [15:08<00:49,  4.49s/it]predicting train subjects:  96%|█████████▌| 256/266 [15:12<00:44,  4.48s/it]predicting train subjects:  97%|█████████▋| 257/266 [15:16<00:39,  4.40s/it]predicting train subjects:  97%|█████████▋| 258/266 [15:21<00:36,  4.51s/it]predicting train subjects:  97%|█████████▋| 259/266 [15:25<00:29,  4.28s/it]predicting train subjects:  98%|█████████▊| 260/266 [15:29<00:25,  4.27s/it]predicting train subjects:  98%|█████████▊| 261/266 [15:33<00:20,  4.17s/it]predicting train subjects:  98%|█████████▊| 262/266 [15:37<00:16,  4.19s/it]predicting train subjects:  99%|█████████▉| 263/266 [15:41<00:12,  4.15s/it]predicting train subjects:  99%|█████████▉| 264/266 [15:45<00:08,  4.13s/it]predicting train subjects: 100%|█████████▉| 265/266 [15:50<00:04,  4.20s/it]predicting train subjects: 100%|██████████| 266/266 [15:54<00:00,  4.28s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<05:14,  1.19s/it]Loading train:   1%|          | 2/266 [00:02<04:47,  1.09s/it]Loading train:   1%|          | 3/266 [00:02<04:33,  1.04s/it]Loading train:   2%|▏         | 4/266 [00:03<04:02,  1.08it/s]Loading train:   2%|▏         | 5/266 [00:04<04:01,  1.08it/s]Loading train:   2%|▏         | 6/266 [00:05<03:59,  1.08it/s]Loading train:   3%|▎         | 7/266 [00:06<03:55,  1.10it/s]Loading train:   3%|▎         | 8/266 [00:07<03:51,  1.11it/s]Loading train:   3%|▎         | 9/266 [00:07<03:38,  1.17it/s]Loading train:   4%|▍         | 10/266 [00:09<03:52,  1.10it/s]Loading train:   4%|▍         | 11/266 [00:09<03:55,  1.08it/s]Loading train:   5%|▍         | 12/266 [00:11<04:19,  1.02s/it]Loading train:   5%|▍         | 13/266 [00:12<04:06,  1.02it/s]Loading train:   5%|▌         | 14/266 [00:12<03:54,  1.08it/s]Loading train:   6%|▌         | 15/266 [00:13<03:39,  1.15it/s]Loading train:   6%|▌         | 16/266 [00:14<03:28,  1.20it/s]Loading train:   6%|▋         | 17/266 [00:15<03:27,  1.20it/s]Loading train:   7%|▋         | 18/266 [00:16<03:40,  1.12it/s]Loading train:   7%|▋         | 19/266 [00:16<03:28,  1.18it/s]Loading train:   8%|▊         | 20/266 [00:17<03:25,  1.20it/s]Loading train:   8%|▊         | 21/266 [00:18<03:42,  1.10it/s]Loading train:   8%|▊         | 22/266 [00:19<03:35,  1.13it/s]Loading train:   9%|▊         | 23/266 [00:20<03:48,  1.07it/s]Loading train:   9%|▉         | 24/266 [00:21<03:59,  1.01it/s]Loading train:   9%|▉         | 25/266 [00:22<03:50,  1.04it/s]Loading train:  10%|▉         | 26/266 [00:23<03:44,  1.07it/s]Loading train:  10%|█         | 27/266 [00:24<03:41,  1.08it/s]Loading train:  11%|█         | 28/266 [00:25<03:51,  1.03it/s]Loading train:  11%|█         | 29/266 [00:26<03:46,  1.05it/s]Loading train:  11%|█▏        | 30/266 [00:27<03:40,  1.07it/s]Loading train:  12%|█▏        | 31/266 [00:28<03:29,  1.12it/s]Loading train:  12%|█▏        | 32/266 [00:29<03:38,  1.07it/s]Loading train:  12%|█▏        | 33/266 [00:30<03:28,  1.12it/s]Loading train:  13%|█▎        | 34/266 [00:31<03:38,  1.06it/s]Loading train:  13%|█▎        | 35/266 [00:31<03:34,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:32<03:32,  1.08it/s]Loading train:  14%|█▍        | 37/266 [00:33<03:38,  1.05it/s]Loading train:  14%|█▍        | 38/266 [00:34<03:40,  1.03it/s]Loading train:  15%|█▍        | 39/266 [00:35<03:32,  1.07it/s]Loading train:  15%|█▌        | 40/266 [00:36<03:32,  1.06it/s]Loading train:  15%|█▌        | 41/266 [00:37<03:32,  1.06it/s]Loading train:  16%|█▌        | 42/266 [00:38<03:12,  1.16it/s]Loading train:  16%|█▌        | 43/266 [00:39<03:02,  1.22it/s]Loading train:  17%|█▋        | 44/266 [00:39<02:57,  1.25it/s]Loading train:  17%|█▋        | 45/266 [00:40<02:53,  1.28it/s]Loading train:  17%|█▋        | 46/266 [00:41<02:53,  1.27it/s]Loading train:  18%|█▊        | 47/266 [00:42<03:01,  1.21it/s]Loading train:  18%|█▊        | 48/266 [00:43<02:57,  1.22it/s]Loading train:  18%|█▊        | 49/266 [00:44<03:06,  1.16it/s]Loading train:  19%|█▉        | 50/266 [00:44<03:04,  1.17it/s]Loading train:  19%|█▉        | 51/266 [00:45<02:58,  1.21it/s]Loading train:  20%|█▉        | 52/266 [00:46<02:50,  1.26it/s]Loading train:  20%|█▉        | 53/266 [00:47<02:51,  1.24it/s]Loading train:  20%|██        | 54/266 [00:48<02:57,  1.19it/s]Loading train:  21%|██        | 55/266 [00:48<02:58,  1.18it/s]Loading train:  21%|██        | 56/266 [00:49<02:51,  1.22it/s]Loading train:  21%|██▏       | 57/266 [00:50<02:44,  1.27it/s]Loading train:  22%|██▏       | 58/266 [00:51<02:43,  1.27it/s]Loading train:  22%|██▏       | 59/266 [00:51<02:39,  1.30it/s]Loading train:  23%|██▎       | 60/266 [00:52<02:31,  1.36it/s]Loading train:  23%|██▎       | 61/266 [00:53<02:29,  1.37it/s]Loading train:  23%|██▎       | 62/266 [00:54<02:33,  1.33it/s]Loading train:  24%|██▎       | 63/266 [00:55<02:41,  1.25it/s]Loading train:  24%|██▍       | 64/266 [00:55<02:47,  1.21it/s]Loading train:  24%|██▍       | 65/266 [00:56<02:41,  1.25it/s]Loading train:  25%|██▍       | 66/266 [00:57<02:34,  1.29it/s]Loading train:  25%|██▌       | 67/266 [00:58<02:43,  1.21it/s]Loading train:  26%|██▌       | 68/266 [00:59<02:40,  1.24it/s]Loading train:  26%|██▌       | 69/266 [00:59<02:35,  1.27it/s]Loading train:  26%|██▋       | 70/266 [01:00<02:44,  1.19it/s]Loading train:  27%|██▋       | 71/266 [01:01<02:42,  1.20it/s]Loading train:  27%|██▋       | 72/266 [01:02<02:41,  1.20it/s]Loading train:  27%|██▋       | 73/266 [01:03<02:33,  1.26it/s]Loading train:  28%|██▊       | 74/266 [01:03<02:28,  1.29it/s]Loading train:  28%|██▊       | 75/266 [01:04<02:24,  1.32it/s]Loading train:  29%|██▊       | 76/266 [01:05<02:23,  1.32it/s]Loading train:  29%|██▉       | 77/266 [01:06<02:23,  1.32it/s]Loading train:  29%|██▉       | 78/266 [01:06<02:27,  1.27it/s]Loading train:  30%|██▉       | 79/266 [01:07<02:36,  1.20it/s]Loading train:  30%|███       | 80/266 [01:08<02:44,  1.13it/s]Loading train:  30%|███       | 81/266 [01:10<02:55,  1.06it/s]Loading train:  31%|███       | 82/266 [01:10<02:45,  1.11it/s]Loading train:  31%|███       | 83/266 [01:11<02:52,  1.06it/s]Loading train:  32%|███▏      | 84/266 [01:12<02:42,  1.12it/s]Loading train:  32%|███▏      | 85/266 [01:13<02:38,  1.14it/s]Loading train:  32%|███▏      | 86/266 [01:14<02:38,  1.14it/s]Loading train:  33%|███▎      | 87/266 [01:15<02:31,  1.18it/s]Loading train:  33%|███▎      | 88/266 [01:16<02:36,  1.14it/s]Loading train:  33%|███▎      | 89/266 [01:16<02:36,  1.13it/s]Loading train:  34%|███▍      | 90/266 [01:17<02:39,  1.10it/s]Loading train:  34%|███▍      | 91/266 [01:18<02:36,  1.12it/s]Loading train:  35%|███▍      | 92/266 [01:19<02:44,  1.06it/s]Loading train:  35%|███▍      | 93/266 [01:20<02:34,  1.12it/s]Loading train:  35%|███▌      | 94/266 [01:21<02:26,  1.17it/s]Loading train:  36%|███▌      | 95/266 [01:22<02:34,  1.10it/s]Loading train:  36%|███▌      | 96/266 [01:23<02:26,  1.16it/s]Loading train:  36%|███▋      | 97/266 [01:24<02:27,  1.15it/s]Loading train:  37%|███▋      | 98/266 [01:25<02:39,  1.05it/s]Loading train:  37%|███▋      | 99/266 [01:26<02:39,  1.05it/s]Loading train:  38%|███▊      | 100/266 [01:27<02:41,  1.03it/s]Loading train:  38%|███▊      | 101/266 [01:27<02:29,  1.10it/s]Loading train:  38%|███▊      | 102/266 [01:28<02:22,  1.15it/s]Loading train:  39%|███▊      | 103/266 [01:29<02:16,  1.19it/s]Loading train:  39%|███▉      | 104/266 [01:30<02:10,  1.24it/s]Loading train:  39%|███▉      | 105/266 [01:31<02:22,  1.13it/s]Loading train:  40%|███▉      | 106/266 [01:32<02:22,  1.12it/s]Loading train:  40%|████      | 107/266 [01:33<02:23,  1.11it/s]Loading train:  41%|████      | 108/266 [01:33<02:19,  1.13it/s]Loading train:  41%|████      | 109/266 [01:34<02:16,  1.15it/s]Loading train:  41%|████▏     | 110/266 [01:35<02:10,  1.19it/s]Loading train:  42%|████▏     | 111/266 [01:36<02:02,  1.26it/s]Loading train:  42%|████▏     | 112/266 [01:36<01:57,  1.31it/s]Loading train:  42%|████▏     | 113/266 [01:38<02:10,  1.17it/s]Loading train:  43%|████▎     | 114/266 [01:38<02:07,  1.19it/s]Loading train:  43%|████▎     | 115/266 [01:39<02:09,  1.16it/s]Loading train:  44%|████▎     | 116/266 [01:40<02:05,  1.19it/s]Loading train:  44%|████▍     | 117/266 [01:41<02:16,  1.09it/s]Loading train:  44%|████▍     | 118/266 [01:42<02:21,  1.04it/s]Loading train:  45%|████▍     | 119/266 [01:43<02:19,  1.05it/s]Loading train:  45%|████▌     | 120/266 [01:44<02:15,  1.08it/s]Loading train:  45%|████▌     | 121/266 [01:45<02:15,  1.07it/s]Loading train:  46%|████▌     | 122/266 [01:46<02:11,  1.10it/s]Loading train:  46%|████▌     | 123/266 [01:47<02:10,  1.09it/s]Loading train:  47%|████▋     | 124/266 [01:48<02:11,  1.08it/s]Loading train:  47%|████▋     | 125/266 [01:48<02:05,  1.12it/s]Loading train:  47%|████▋     | 126/266 [01:49<02:06,  1.11it/s]Loading train:  48%|████▊     | 127/266 [01:50<02:03,  1.12it/s]Loading train:  48%|████▊     | 128/266 [01:51<02:07,  1.08it/s]Loading train:  48%|████▊     | 129/266 [01:52<02:08,  1.07it/s]Loading train:  49%|████▉     | 130/266 [01:53<02:08,  1.06it/s]Loading train:  49%|████▉     | 131/266 [01:54<02:04,  1.08it/s]Loading train:  50%|████▉     | 132/266 [01:55<01:59,  1.12it/s]Loading train:  50%|█████     | 133/266 [01:56<01:58,  1.12it/s]Loading train:  50%|█████     | 134/266 [01:57<01:59,  1.10it/s]Loading train:  51%|█████     | 135/266 [01:58<01:56,  1.13it/s]Loading train:  51%|█████     | 136/266 [01:59<02:02,  1.06it/s]Loading train:  52%|█████▏    | 137/266 [02:00<01:58,  1.09it/s]Loading train:  52%|█████▏    | 138/266 [02:00<01:53,  1.13it/s]Loading train:  52%|█████▏    | 139/266 [02:01<01:54,  1.11it/s]Loading train:  53%|█████▎    | 140/266 [02:02<01:48,  1.16it/s]Loading train:  53%|█████▎    | 141/266 [02:03<01:49,  1.15it/s]Loading train:  53%|█████▎    | 142/266 [02:04<01:42,  1.20it/s]Loading train:  54%|█████▍    | 143/266 [02:05<01:48,  1.14it/s]Loading train:  54%|█████▍    | 144/266 [02:06<01:47,  1.14it/s]Loading train:  55%|█████▍    | 145/266 [02:06<01:47,  1.12it/s]Loading train:  55%|█████▍    | 146/266 [02:07<01:44,  1.15it/s]Loading train:  55%|█████▌    | 147/266 [02:08<01:41,  1.17it/s]Loading train:  56%|█████▌    | 148/266 [02:09<01:42,  1.15it/s]Loading train:  56%|█████▌    | 149/266 [02:10<01:44,  1.12it/s]Loading train:  56%|█████▋    | 150/266 [02:11<01:38,  1.18it/s]Loading train:  57%|█████▋    | 151/266 [02:11<01:33,  1.24it/s]Loading train:  57%|█████▋    | 152/266 [02:12<01:36,  1.19it/s]Loading train:  58%|█████▊    | 153/266 [02:13<01:36,  1.17it/s]Loading train:  58%|█████▊    | 154/266 [02:14<01:43,  1.09it/s]Loading train:  58%|█████▊    | 155/266 [02:15<01:39,  1.12it/s]Loading train:  59%|█████▊    | 156/266 [02:16<01:32,  1.19it/s]Loading train:  59%|█████▉    | 157/266 [02:17<01:37,  1.12it/s]Loading train:  59%|█████▉    | 158/266 [02:18<01:33,  1.15it/s]Loading train:  60%|█████▉    | 159/266 [02:19<01:34,  1.13it/s]Loading train:  60%|██████    | 160/266 [02:19<01:34,  1.12it/s]Loading train:  61%|██████    | 161/266 [02:20<01:32,  1.14it/s]Loading train:  61%|██████    | 162/266 [02:21<01:30,  1.15it/s]Loading train:  61%|██████▏   | 163/266 [02:22<01:28,  1.17it/s]Loading train:  62%|██████▏   | 164/266 [02:23<01:23,  1.22it/s]Loading train:  62%|██████▏   | 165/266 [02:24<01:20,  1.25it/s]Loading train:  62%|██████▏   | 166/266 [02:25<01:27,  1.15it/s]Loading train:  63%|██████▎   | 167/266 [02:25<01:26,  1.15it/s]Loading train:  63%|██████▎   | 168/266 [02:26<01:23,  1.18it/s]Loading train:  64%|██████▎   | 169/266 [02:27<01:18,  1.23it/s]Loading train:  64%|██████▍   | 170/266 [02:28<01:20,  1.20it/s]Loading train:  64%|██████▍   | 171/266 [02:28<01:13,  1.29it/s]Loading train:  65%|██████▍   | 172/266 [02:29<01:14,  1.26it/s]Loading train:  65%|██████▌   | 173/266 [02:30<01:06,  1.39it/s]Loading train:  65%|██████▌   | 174/266 [02:31<01:11,  1.28it/s]Loading train:  66%|██████▌   | 175/266 [02:32<01:12,  1.26it/s]Loading train:  66%|██████▌   | 176/266 [02:32<01:11,  1.25it/s]Loading train:  67%|██████▋   | 177/266 [02:33<01:09,  1.28it/s]Loading train:  67%|██████▋   | 178/266 [02:34<01:09,  1.27it/s]Loading train:  67%|██████▋   | 179/266 [02:35<01:10,  1.23it/s]Loading train:  68%|██████▊   | 180/266 [02:36<01:11,  1.20it/s]Loading train:  68%|██████▊   | 181/266 [02:37<01:15,  1.12it/s]Loading train:  68%|██████▊   | 182/266 [02:37<01:10,  1.20it/s]Loading train:  69%|██████▉   | 183/266 [02:38<01:06,  1.24it/s]Loading train:  69%|██████▉   | 184/266 [02:39<01:04,  1.26it/s]Loading train:  70%|██████▉   | 185/266 [02:40<01:05,  1.24it/s]Loading train:  70%|██████▉   | 186/266 [02:40<01:03,  1.27it/s]Loading train:  70%|███████   | 187/266 [02:41<01:03,  1.25it/s]Loading train:  71%|███████   | 188/266 [02:42<01:04,  1.21it/s]Loading train:  71%|███████   | 189/266 [02:43<01:01,  1.25it/s]Loading train:  71%|███████▏  | 190/266 [02:44<01:05,  1.16it/s]Loading train:  72%|███████▏  | 191/266 [02:45<01:05,  1.15it/s]Loading train:  72%|███████▏  | 192/266 [02:46<01:01,  1.21it/s]Loading train:  73%|███████▎  | 193/266 [02:46<01:02,  1.17it/s]Loading train:  73%|███████▎  | 194/266 [02:47<01:01,  1.17it/s]Loading train:  73%|███████▎  | 195/266 [02:48<01:02,  1.13it/s]Loading train:  74%|███████▎  | 196/266 [02:49<00:55,  1.26it/s]Loading train:  74%|███████▍  | 197/266 [02:50<00:52,  1.31it/s]Loading train:  74%|███████▍  | 198/266 [02:50<00:51,  1.31it/s]Loading train:  75%|███████▍  | 199/266 [02:51<00:54,  1.23it/s]Loading train:  75%|███████▌  | 200/266 [02:52<00:52,  1.26it/s]Loading train:  76%|███████▌  | 201/266 [02:53<00:52,  1.23it/s]Loading train:  76%|███████▌  | 202/266 [02:54<00:55,  1.16it/s]Loading train:  76%|███████▋  | 203/266 [02:55<00:55,  1.14it/s]Loading train:  77%|███████▋  | 204/266 [02:56<00:53,  1.17it/s]Loading train:  77%|███████▋  | 205/266 [02:56<00:51,  1.20it/s]Loading train:  77%|███████▋  | 206/266 [02:57<00:48,  1.25it/s]Loading train:  78%|███████▊  | 207/266 [02:58<00:48,  1.23it/s]Loading train:  78%|███████▊  | 208/266 [02:59<00:44,  1.30it/s]Loading train:  79%|███████▊  | 209/266 [03:00<00:47,  1.20it/s]Loading train:  79%|███████▉  | 210/266 [03:00<00:47,  1.18it/s]Loading train:  79%|███████▉  | 211/266 [03:01<00:47,  1.16it/s]Loading train:  80%|███████▉  | 212/266 [03:02<00:47,  1.13it/s]Loading train:  80%|████████  | 213/266 [03:03<00:45,  1.15it/s]Loading train:  80%|████████  | 214/266 [03:04<00:46,  1.11it/s]Loading train:  81%|████████  | 215/266 [03:05<00:42,  1.21it/s]Loading train:  81%|████████  | 216/266 [03:06<00:42,  1.17it/s]Loading train:  82%|████████▏ | 217/266 [03:06<00:38,  1.26it/s]Loading train:  82%|████████▏ | 218/266 [03:07<00:43,  1.11it/s]Loading train:  82%|████████▏ | 219/266 [03:08<00:41,  1.13it/s]Loading train:  83%|████████▎ | 220/266 [03:09<00:38,  1.20it/s]Loading train:  83%|████████▎ | 221/266 [03:10<00:37,  1.19it/s]Loading train:  83%|████████▎ | 222/266 [03:11<00:38,  1.15it/s]Loading train:  84%|████████▍ | 223/266 [03:12<00:36,  1.17it/s]Loading train:  84%|████████▍ | 224/266 [03:12<00:34,  1.20it/s]Loading train:  85%|████████▍ | 225/266 [03:13<00:36,  1.12it/s]Loading train:  85%|████████▍ | 226/266 [03:14<00:34,  1.17it/s]Loading train:  85%|████████▌ | 227/266 [03:15<00:32,  1.19it/s]Loading train:  86%|████████▌ | 228/266 [03:16<00:32,  1.18it/s]Loading train:  86%|████████▌ | 229/266 [03:17<00:30,  1.22it/s]Loading train:  86%|████████▋ | 230/266 [03:17<00:29,  1.21it/s]Loading train:  87%|████████▋ | 231/266 [03:18<00:28,  1.24it/s]Loading train:  87%|████████▋ | 232/266 [03:19<00:26,  1.26it/s]Loading train:  88%|████████▊ | 233/266 [03:20<00:25,  1.28it/s]Loading train:  88%|████████▊ | 234/266 [03:21<00:24,  1.30it/s]Loading train:  88%|████████▊ | 235/266 [03:21<00:21,  1.43it/s]Loading train:  89%|████████▊ | 236/266 [03:22<00:19,  1.54it/s]Loading train:  89%|████████▉ | 237/266 [03:22<00:17,  1.64it/s]Loading train:  89%|████████▉ | 238/266 [03:23<00:16,  1.66it/s]Loading train:  90%|████████▉ | 239/266 [03:23<00:17,  1.51it/s]Loading train:  90%|█████████ | 240/266 [03:24<00:18,  1.39it/s]Loading train:  91%|█████████ | 241/266 [03:25<00:19,  1.29it/s]Loading train:  91%|█████████ | 242/266 [03:26<00:18,  1.31it/s]Loading train:  91%|█████████▏| 243/266 [03:27<00:17,  1.31it/s]Loading train:  92%|█████████▏| 244/266 [03:27<00:16,  1.33it/s]Loading train:  92%|█████████▏| 245/266 [03:28<00:15,  1.35it/s]Loading train:  92%|█████████▏| 246/266 [03:29<00:14,  1.35it/s]Loading train:  93%|█████████▎| 247/266 [03:30<00:15,  1.23it/s]Loading train:  93%|█████████▎| 248/266 [03:31<00:14,  1.24it/s]Loading train:  94%|█████████▎| 249/266 [03:32<00:14,  1.20it/s]Loading train:  94%|█████████▍| 250/266 [03:32<00:13,  1.21it/s]Loading train:  94%|█████████▍| 251/266 [03:33<00:12,  1.23it/s]Loading train:  95%|█████████▍| 252/266 [03:34<00:12,  1.09it/s]Loading train:  95%|█████████▌| 253/266 [03:35<00:11,  1.13it/s]Loading train:  95%|█████████▌| 254/266 [03:36<00:10,  1.10it/s]Loading train:  96%|█████████▌| 255/266 [03:37<00:09,  1.21it/s]Loading train:  96%|█████████▌| 256/266 [03:38<00:08,  1.21it/s]Loading train:  97%|█████████▋| 257/266 [03:38<00:07,  1.24it/s]Loading train:  97%|█████████▋| 258/266 [03:39<00:06,  1.30it/s]Loading train:  97%|█████████▋| 259/266 [03:40<00:05,  1.32it/s]Loading train:  98%|█████████▊| 260/266 [03:41<00:04,  1.30it/s]Loading train:  98%|█████████▊| 261/266 [03:41<00:04,  1.25it/s]Loading train:  98%|█████████▊| 262/266 [03:42<00:03,  1.27it/s]Loading train:  99%|█████████▉| 263/266 [03:43<00:02,  1.17it/s]Loading train:  99%|█████████▉| 264/266 [03:44<00:01,  1.15it/s]Loading train: 100%|█████████▉| 265/266 [03:45<00:00,  1.13it/s]Loading train: 100%|██████████| 266/266 [03:46<00:00,  1.09it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 48.07it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:05, 50.75it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:07, 33.16it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:09, 27.24it/s]concatenating: train:   8%|▊         | 21/266 [00:00<00:12, 19.96it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:11, 21.97it/s]concatenating: train:  13%|█▎        | 35/266 [00:01<00:08, 28.30it/s]concatenating: train:  15%|█▌        | 40/266 [00:01<00:09, 22.64it/s]concatenating: train:  17%|█▋        | 44/266 [00:01<00:10, 20.56it/s]concatenating: train:  21%|██        | 55/266 [00:01<00:07, 26.64it/s]concatenating: train:  23%|██▎       | 60/266 [00:01<00:08, 24.43it/s]concatenating: train:  24%|██▍       | 64/266 [00:02<00:10, 19.67it/s]concatenating: train:  26%|██▌       | 68/266 [00:02<00:09, 21.42it/s]concatenating: train:  27%|██▋       | 71/266 [00:02<00:08, 23.00it/s]concatenating: train:  29%|██▊       | 76/266 [00:02<00:06, 27.25it/s]concatenating: train:  31%|███       | 83/266 [00:02<00:05, 32.62it/s]concatenating: train:  33%|███▎      | 88/266 [00:02<00:05, 31.49it/s]concatenating: train:  35%|███▍      | 92/266 [00:03<00:06, 28.71it/s]concatenating: train:  36%|███▌      | 96/266 [00:03<00:07, 22.79it/s]concatenating: train:  38%|███▊      | 100/266 [00:03<00:06, 25.56it/s]concatenating: train:  39%|███▉      | 104/266 [00:03<00:06, 26.61it/s]concatenating: train:  41%|████      | 108/266 [00:03<00:07, 22.57it/s]concatenating: train:  42%|████▏     | 111/266 [00:03<00:07, 21.64it/s]concatenating: train:  43%|████▎     | 114/266 [00:04<00:07, 20.35it/s]concatenating: train:  44%|████▍     | 118/266 [00:04<00:06, 23.68it/s]concatenating: train:  47%|████▋     | 124/266 [00:04<00:04, 28.62it/s]concatenating: train:  48%|████▊     | 128/266 [00:04<00:04, 29.36it/s]concatenating: train:  50%|████▉     | 132/266 [00:04<00:04, 29.90it/s]concatenating: train:  51%|█████     | 136/266 [00:05<00:07, 17.54it/s]concatenating: train:  52%|█████▏    | 139/266 [00:05<00:08, 14.22it/s]concatenating: train:  53%|█████▎    | 142/266 [00:05<00:08, 15.34it/s]concatenating: train:  55%|█████▍    | 145/266 [00:05<00:07, 16.12it/s]concatenating: train:  57%|█████▋    | 151/266 [00:05<00:05, 20.65it/s]concatenating: train:  59%|█████▊    | 156/266 [00:05<00:04, 24.76it/s]concatenating: train:  60%|██████    | 160/266 [00:06<00:04, 26.41it/s]concatenating: train:  74%|███████▎  | 196/266 [00:06<00:01, 36.18it/s]concatenating: train:  78%|███████▊  | 207/266 [00:06<00:01, 31.14it/s]concatenating: train:  81%|████████  | 215/266 [00:06<00:01, 36.05it/s]concatenating: train:  85%|████████▍ | 225/266 [00:06<00:00, 42.14it/s]concatenating: train:  88%|████████▊ | 233/266 [00:07<00:00, 36.09it/s]concatenating: train:  90%|████████▉ | 239/266 [00:07<00:00, 28.57it/s]concatenating: train:  92%|█████████▏| 244/266 [00:07<00:00, 28.90it/s]concatenating: train:  94%|█████████▎| 249/266 [00:07<00:00, 32.57it/s]concatenating: train:  98%|█████████▊| 261/266 [00:07<00:00, 41.00it/s]concatenating: train: 100%|██████████| 266/266 [00:07<00:00, 33.28it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.06s/it]Loading test:  50%|█████     | 2/4 [00:01<00:02,  1.00s/it]Loading test:  75%|███████▌  | 3/4 [00:02<00:00,  1.09it/s]Loading test: 100%|██████████| 4/4 [00:03<00:00,  1.14it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation:  50%|█████     | 2/4 [00:00<00:00, 16.17it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 20.86it/s]2019-07-29 01:19:02.580833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 01:19:02.580933: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 01:19:02.580951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 01:19:02.580964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 01:19:02.581458: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:15,  2.82it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:11,  3.48it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:12,  3.31it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:08,  4.39it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.53it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:08,  4.08it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.74it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  4.96it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:06,  4.11it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:04,  4.85it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:06,  3.83it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  4.92it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:03,  5.02it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.36it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:03,  4.49it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  4.19it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.20it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.73it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.80it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.12it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.34it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.67it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 76, 108, 30)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 76, 108, 30)  0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 76, 108, 31)  0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 76, 108, 30)  8400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 76, 108, 30)  120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 76, 108, 30)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 76, 108, 30)  8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 76, 108, 30)  120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 108, 30)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 38, 54, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 38, 54, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 54, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 38, 54, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 38, 54, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 38, 54, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 38, 54, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 19, 27, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 19, 27, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 19, 27, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 19, 27, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 19, 27, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 19, 27, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 19, 27, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 19, 27, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 54, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 54, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 38, 54, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 38, 54, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 38, 54, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 38, 54, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 38, 54, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 30)  16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 76, 108, 30)  120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 76, 108, 30)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 76, 108, 30)  8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 76, 108, 30)  120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 76, 108, 30)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 76, 108, 90)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 76, 108, 90)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 76, 108, 30)  24330       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 76, 108, 30)  120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 76, 108, 30)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 76, 108, 30)  0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 76, 108, 30)  8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 76, 108, 30)  120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 76, 108, 30)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 76, 108, 30)  0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 76, 108, 120) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 76, 108, 2)   242         concatenate_8[0][0]              
==================================================================================================
Total params: 549,872
Trainable params: 157,412
Non-trainable params: 392,460
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 396 samples
Epoch 1/300
 - 88s - loss: 0.1008 - acc: 0.9892 - mDice: 0.8501 - val_loss: 0.0633 - val_acc: 0.9946 - val_mDice: 0.8842

Epoch 00001: val_mDice improved from -inf to 0.88420, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 81s - loss: 0.0521 - acc: 0.9944 - mDice: 0.9038 - val_loss: 0.0633 - val_acc: 0.9945 - val_mDice: 0.8843

Epoch 00002: val_mDice improved from 0.88420 to 0.88434, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 81s - loss: 0.0468 - acc: 0.9949 - mDice: 0.9132 - val_loss: 0.0635 - val_acc: 0.9945 - val_mDice: 0.8842

Epoch 00003: val_mDice did not improve from 0.88434
Epoch 4/300
 - 80s - loss: 0.0433 - acc: 0.9952 - mDice: 0.9193 - val_loss: 0.0598 - val_acc: 0.9947 - val_mDice: 0.8906

Epoch 00004: val_mDice improved from 0.88434 to 0.89059, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 80s - loss: 0.0409 - acc: 0.9954 - mDice: 0.9237 - val_loss: 0.0627 - val_acc: 0.9944 - val_mDice: 0.8860

Epoch 00005: val_mDice did not improve from 0.89059
Epoch 6/300
 - 79s - loss: 0.0395 - acc: 0.9955 - mDice: 0.9262 - val_loss: 0.0672 - val_acc: 0.9946 - val_mDice: 0.8785

Epoch 00006: val_mDice did not improve from 0.89059
Epoch 7/300
 - 80s - loss: 0.0381 - acc: 0.9957 - mDice: 0.9286 - val_loss: 0.0620 - val_acc: 0.9948 - val_mDice: 0.8871

Epoch 00007: val_mDice did not improve from 0.89059
Epoch 8/300
 - 77s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9308 - val_loss: 0.0606 - val_acc: 0.9947 - val_mDice: 0.8894

Epoch 00008: val_mDice did not improve from 0.89059
Epoch 9/300
 - 76s - loss: 0.0357 - acc: 0.9959 - mDice: 0.9330 - val_loss: 0.0644 - val_acc: 0.9945 - val_mDice: 0.8830

Epoch 00009: val_mDice did not improve from 0.89059
Epoch 10/300
 - 77s - loss: 0.0348 - acc: 0.9959 - mDice: 0.9346 - val_loss: 0.0645 - val_acc: 0.9944 - val_mDice: 0.8829

Epoch 00010: val_mDice did not improve from 0.89059
Epoch 11/300
 - 78s - loss: 0.0341 - acc: 0.9960 - mDice: 0.9358 - val_loss: 0.0674 - val_acc: 0.9947 - val_mDice: 0.8782

Epoch 00011: val_mDice did not improve from 0.89059
Epoch 12/300
 - 78s - loss: 0.0334 - acc: 0.9961 - mDice: 0.9373 - val_loss: 0.0701 - val_acc: 0.9946 - val_mDice: 0.8737

Epoch 00012: val_mDice did not improve from 0.89059
Epoch 13/300
 - 78s - loss: 0.0330 - acc: 0.9961 - mDice: 0.9380 - val_loss: 0.0664 - val_acc: 0.9948 - val_mDice: 0.8797

Epoch 00013: val_mDice did not improve from 0.89059
Epoch 14/300
 - 78s - loss: 0.0323 - acc: 0.9962 - mDice: 0.9392 - val_loss: 0.0672 - val_acc: 0.9946 - val_mDice: 0.8785

Epoch 00014: val_mDice did not improve from 0.89059
Epoch 15/300
 - 78s - loss: 0.0317 - acc: 0.9962 - mDice: 0.9403 - val_loss: 0.0637 - val_acc: 0.9947 - val_mDice: 0.8842

Epoch 00015: val_mDice did not improve from 0.89059
Epoch 16/300
 - 78s - loss: 0.0314 - acc: 0.9963 - mDice: 0.9408 - val_loss: 0.0674 - val_acc: 0.9944 - val_mDice: 0.8783

Epoch 00016: val_mDice did not improve from 0.89059
Epoch 17/300
 - 78s - loss: 0.0309 - acc: 0.9963 - mDice: 0.9418 - val_loss: 0.0636 - val_acc: 0.9947 - val_mDice: 0.8846

Epoch 00017: val_mDice did not improve from 0.89059
Epoch 18/300
 - 77s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9423 - val_loss: 0.0702 - val_acc: 0.9946 - val_mDice: 0.8738

Epoch 00018: val_mDice did not improve from 0.89059
Epoch 19/300
 - 78s - loss: 0.0302 - acc: 0.9964 - mDice: 0.9430 - val_loss: 0.0652 - val_acc: 0.9946 - val_mDice: 0.8820

Epoch 00019: val_mDice did not improve from 0.89059
Epoch 20/300
 - 78s - loss: 0.0300 - acc: 0.9964 - mDice: 0.9435 - val_loss: 0.0657 - val_acc: 0.9947 - val_mDice: 0.8811

Epoch 00020: val_mDice did not improve from 0.89059
Epoch 21/300
 - 78s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9436 - val_loss: 0.0703 - val_acc: 0.9944 - val_mDice: 0.8732

Epoch 00021: val_mDice did not improve from 0.89059
Epoch 22/300
 - 78s - loss: 0.0296 - acc: 0.9964 - mDice: 0.9441 - val_loss: 0.0660 - val_acc: 0.9943 - val_mDice: 0.8809

Epoch 00022: val_mDice did not improve from 0.89059
Epoch 23/300
 - 78s - loss: 0.0293 - acc: 0.9965 - mDice: 0.9448 - val_loss: 0.0681 - val_acc: 0.9942 - val_mDice: 0.8770

Epoch 00023: val_mDice did not improve from 0.89059
Epoch 24/300
 - 79s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9455 - val_loss: 0.0664 - val_acc: 0.9944 - val_mDice: 0.8797

Epoch 00024: val_mDice did not improve from 0.89059
Epoch 25/300
 - 78s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9454 - val_loss: 0.0650 - val_acc: 0.9946 - val_mDice: 0.8824

Epoch 00025: val_mDice did not improve from 0.89059
Epoch 26/300
 - 78s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9460 - val_loss: 0.0669 - val_acc: 0.9947 - val_mDice: 0.8791

Epoch 00026: val_mDice did not improve from 0.89059
Epoch 27/300
 - 78s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9465 - val_loss: 0.0653 - val_acc: 0.9946 - val_mDice: 0.8819

Epoch 00027: val_mDice did not improve from 0.89059
Epoch 28/300
 - 78s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9465 - val_loss: 0.0707 - val_acc: 0.9947 - val_mDice: 0.8731

Epoch 00028: val_mDice did not improve from 0.89059
Epoch 29/300
 - 78s - loss: 0.0279 - acc: 0.9966 - mDice: 0.9473 - val_loss: 0.0681 - val_acc: 0.9942 - val_mDice: 0.8771

Epoch 00029: val_mDice did not improve from 0.89059
Epoch 30/300
 - 78s - loss: 0.0278 - acc: 0.9966 - mDice: 0.9474 - val_loss: 0.0669 - val_acc: 0.9946 - val_mDice: 0.8792

Epoch 00030: val_mDice did not improve from 0.89059
Epoch 31/300
 - 78s - loss: 0.0277 - acc: 0.9966 - mDice: 0.9477 - val_loss: 0.0649 - val_acc: 0.9944 - val_mDice: 0.8827

Epoch 00031: val_mDice did not improve from 0.89059
Epoch 32/300
 - 78s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9482 - val_loss: 0.0653 - val_acc: 0.9943 - val_mDice: 0.8818

Epoch 00032: val_mDice did not improve from 0.89059
Epoch 33/300
 - 77s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9483 - val_loss: 0.0679 - val_acc: 0.9943 - val_mDice: 0.8778

Epoch 00033: val_mDice did not improve from 0.89059
Epoch 34/300
 - 77s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9484 - val_loss: 0.0690 - val_acc: 0.9947 - val_mDice: 0.8755

Epoch 00034: val_mDice did not improve from 0.89059
Epoch 35/300
 - 76s - loss: 0.0271 - acc: 0.9967 - mDice: 0.9487 - val_loss: 0.0668 - val_acc: 0.9944 - val_mDice: 0.8792

Epoch 00035: val_mDice did not improve from 0.89059
Epoch 36/300
 - 77s - loss: 0.0270 - acc: 0.9967 - mDice: 0.9491 - val_loss: 0.0632 - val_acc: 0.9945 - val_mDice: 0.8852

Epoch 00036: val_mDice did not improve from 0.89059
Epoch 37/300
 - 77s - loss: 0.0269 - acc: 0.9967 - mDice: 0.9492 - val_loss: 0.0655 - val_acc: 0.9946 - val_mDice: 0.8814

Epoch 00037: val_mDice did not improve from 0.89059
Epoch 38/300
 - 77s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9494 - val_loss: 0.0690 - val_acc: 0.9945 - val_mDice: 0.8756

Epoch 00038: val_mDice did not improve from 0.89059
Epoch 39/300
 - 77s - loss: 0.0267 - acc: 0.9967 - mDice: 0.9495 - val_loss: 0.0667 - val_acc: 0.9944 - val_mDice: 0.8794

Epoch 00039: val_mDice did not improve from 0.89059
Epoch 40/300
 - 76s - loss: 0.0265 - acc: 0.9967 - mDice: 0.9498 - val_loss: 0.0651 - val_acc: 0.9944 - val_mDice: 0.8824

Epoch 00040: val_mDice did not improve from 0.89059
Epoch 41/300
 - 76s - loss: 0.0264 - acc: 0.9967 - mDice: 0.9502 - val_loss: 0.0697 - val_acc: 0.9945 - val_mDice: 0.8744

Epoch 00041: val_mDice did not improve from 0.89059
Epoch 42/300
 - 77s - loss: 0.0264 - acc: 0.9967 - mDice: 0.9501 - val_loss: 0.0663 - val_acc: 0.9945 - val_mDice: 0.8799

Epoch 00042: val_mDice did not improve from 0.89059
Epoch 43/300
 - 78s - loss: 0.0263 - acc: 0.9967 - mDice: 0.9503 - val_loss: 0.0653 - val_acc: 0.9948 - val_mDice: 0.8820

Epoch 00043: val_mDice did not improve from 0.89059
Epoch 44/300
 - 79s - loss: 0.0262 - acc: 0.9967 - mDice: 0.9504 - val_loss: 0.0652 - val_acc: 0.9944 - val_mDice: 0.8819

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:03,  1.20s/it]predicting test subjects:  50%|█████     | 2/4 [00:01<00:01,  1.05it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  1.32it/s]predicting test subjects: 100%|██████████| 4/4 [00:02<00:00,  1.54it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:55,  2.30it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:54,  2.31it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:43,  2.54it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:36,  2.73it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:41,  2.58it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:46,  2.44it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:46,  2.43it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:48,  2.37it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:45,  2.43it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:43,  2.48it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:43,  2.46it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:44,  2.44it/s]predicting train subjects:   5%|▍         | 13/266 [00:05<01:43,  2.45it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:45,  2.39it/s]predicting train subjects:   6%|▌         | 15/266 [00:06<01:42,  2.44it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:43,  2.42it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:43,  2.40it/s]predicting train subjects:   7%|▋         | 18/266 [00:07<01:40,  2.48it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:40,  2.47it/s]predicting train subjects:   8%|▊         | 20/266 [00:08<01:41,  2.43it/s]predicting train subjects:   8%|▊         | 21/266 [00:08<01:43,  2.38it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:39,  2.45it/s]predicting train subjects:   9%|▊         | 23/266 [00:09<01:37,  2.48it/s]predicting train subjects:   9%|▉         | 24/266 [00:09<01:35,  2.53it/s]predicting train subjects:   9%|▉         | 25/266 [00:10<01:32,  2.61it/s]predicting train subjects:  10%|▉         | 26/266 [00:10<01:30,  2.66it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:33,  2.57it/s]predicting train subjects:  11%|█         | 28/266 [00:11<01:30,  2.63it/s]predicting train subjects:  11%|█         | 29/266 [00:11<01:28,  2.69it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:27,  2.69it/s]predicting train subjects:  12%|█▏        | 31/266 [00:12<01:28,  2.66it/s]predicting train subjects:  12%|█▏        | 32/266 [00:12<01:28,  2.64it/s]predicting train subjects:  12%|█▏        | 33/266 [00:13<01:27,  2.65it/s]predicting train subjects:  13%|█▎        | 34/266 [00:13<01:27,  2.66it/s]predicting train subjects:  13%|█▎        | 35/266 [00:13<01:25,  2.70it/s]predicting train subjects:  14%|█▎        | 36/266 [00:14<01:25,  2.68it/s]predicting train subjects:  14%|█▍        | 37/266 [00:14<01:25,  2.68it/s]predicting train subjects:  14%|█▍        | 38/266 [00:14<01:23,  2.72it/s]predicting train subjects:  15%|█▍        | 39/266 [00:15<01:21,  2.77it/s]predicting train subjects:  15%|█▌        | 40/266 [00:15<01:21,  2.76it/s]predicting train subjects:  15%|█▌        | 41/266 [00:15<01:21,  2.77it/s]predicting train subjects:  16%|█▌        | 42/266 [00:16<01:17,  2.89it/s]predicting train subjects:  16%|█▌        | 43/266 [00:16<01:16,  2.93it/s]predicting train subjects:  17%|█▋        | 44/266 [00:16<01:13,  3.04it/s]predicting train subjects:  17%|█▋        | 45/266 [00:17<01:13,  3.02it/s]predicting train subjects:  17%|█▋        | 46/266 [00:17<01:11,  3.10it/s]predicting train subjects:  18%|█▊        | 47/266 [00:17<01:09,  3.14it/s]predicting train subjects:  18%|█▊        | 48/266 [00:18<01:08,  3.17it/s]predicting train subjects:  18%|█▊        | 49/266 [00:18<01:09,  3.11it/s]predicting train subjects:  19%|█▉        | 50/266 [00:18<01:08,  3.18it/s]predicting train subjects:  19%|█▉        | 51/266 [00:19<01:09,  3.08it/s]predicting train subjects:  20%|█▉        | 52/266 [00:19<01:07,  3.16it/s]predicting train subjects:  20%|█▉        | 53/266 [00:19<01:06,  3.19it/s]predicting train subjects:  20%|██        | 54/266 [00:20<01:05,  3.21it/s]predicting train subjects:  21%|██        | 55/266 [00:20<01:05,  3.25it/s]predicting train subjects:  21%|██        | 56/266 [00:20<01:04,  3.26it/s]predicting train subjects:  21%|██▏       | 57/266 [00:20<01:03,  3.28it/s]predicting train subjects:  22%|██▏       | 58/266 [00:21<01:03,  3.29it/s]predicting train subjects:  22%|██▏       | 59/266 [00:21<01:05,  3.17it/s]predicting train subjects:  23%|██▎       | 60/266 [00:21<01:03,  3.24it/s]predicting train subjects:  23%|██▎       | 61/266 [00:22<01:06,  3.09it/s]predicting train subjects:  23%|██▎       | 62/266 [00:22<01:03,  3.20it/s]predicting train subjects:  24%|██▎       | 63/266 [00:22<01:06,  3.05it/s]predicting train subjects:  24%|██▍       | 64/266 [00:23<01:07,  3.01it/s]predicting train subjects:  24%|██▍       | 65/266 [00:23<01:05,  3.05it/s]predicting train subjects:  25%|██▍       | 66/266 [00:23<01:02,  3.18it/s]predicting train subjects:  25%|██▌       | 67/266 [00:24<01:01,  3.25it/s]predicting train subjects:  26%|██▌       | 68/266 [00:24<01:00,  3.25it/s]predicting train subjects:  26%|██▌       | 69/266 [00:24<00:59,  3.32it/s]predicting train subjects:  26%|██▋       | 70/266 [00:25<01:00,  3.25it/s]predicting train subjects:  27%|██▋       | 71/266 [00:25<01:00,  3.20it/s]predicting train subjects:  27%|██▋       | 72/266 [00:25<01:01,  3.14it/s]predicting train subjects:  27%|██▋       | 73/266 [00:26<01:00,  3.18it/s]predicting train subjects:  28%|██▊       | 74/266 [00:26<00:58,  3.26it/s]predicting train subjects:  28%|██▊       | 75/266 [00:26<00:57,  3.30it/s]predicting train subjects:  29%|██▊       | 76/266 [00:26<00:57,  3.29it/s]predicting train subjects:  29%|██▉       | 77/266 [00:27<00:58,  3.25it/s]predicting train subjects:  29%|██▉       | 78/266 [00:27<01:04,  2.92it/s]predicting train subjects:  30%|██▉       | 79/266 [00:28<01:07,  2.76it/s]predicting train subjects:  30%|███       | 80/266 [00:28<01:09,  2.67it/s]predicting train subjects:  30%|███       | 81/266 [00:28<01:09,  2.65it/s]predicting train subjects:  31%|███       | 82/266 [00:29<01:10,  2.62it/s]predicting train subjects:  31%|███       | 83/266 [00:29<01:10,  2.60it/s]predicting train subjects:  32%|███▏      | 84/266 [00:30<01:09,  2.62it/s]predicting train subjects:  32%|███▏      | 85/266 [00:30<01:09,  2.62it/s]predicting train subjects:  32%|███▏      | 86/266 [00:30<01:08,  2.64it/s]predicting train subjects:  33%|███▎      | 87/266 [00:31<01:07,  2.65it/s]predicting train subjects:  33%|███▎      | 88/266 [00:31<01:06,  2.67it/s]predicting train subjects:  33%|███▎      | 89/266 [00:31<01:05,  2.69it/s]predicting train subjects:  34%|███▍      | 90/266 [00:32<01:04,  2.71it/s]predicting train subjects:  34%|███▍      | 91/266 [00:32<01:07,  2.60it/s]predicting train subjects:  35%|███▍      | 92/266 [00:33<01:07,  2.58it/s]predicting train subjects:  35%|███▍      | 93/266 [00:33<01:08,  2.51it/s]predicting train subjects:  35%|███▌      | 94/266 [00:33<01:06,  2.60it/s]predicting train subjects:  36%|███▌      | 95/266 [00:34<01:04,  2.63it/s]predicting train subjects:  36%|███▌      | 96/266 [00:34<01:05,  2.61it/s]predicting train subjects:  36%|███▋      | 97/266 [00:35<01:07,  2.52it/s]predicting train subjects:  37%|███▋      | 98/266 [00:35<01:08,  2.47it/s]predicting train subjects:  37%|███▋      | 99/266 [00:35<01:04,  2.59it/s]predicting train subjects:  38%|███▊      | 100/266 [00:36<01:01,  2.69it/s]predicting train subjects:  38%|███▊      | 101/266 [00:36<00:59,  2.79it/s]predicting train subjects:  38%|███▊      | 102/266 [00:36<00:59,  2.76it/s]predicting train subjects:  39%|███▊      | 103/266 [00:37<00:58,  2.79it/s]predicting train subjects:  39%|███▉      | 104/266 [00:37<00:56,  2.88it/s]predicting train subjects:  39%|███▉      | 105/266 [00:37<00:56,  2.85it/s]predicting train subjects:  40%|███▉      | 106/266 [00:38<00:57,  2.80it/s]predicting train subjects:  40%|████      | 107/266 [00:38<00:56,  2.79it/s]predicting train subjects:  41%|████      | 108/266 [00:38<00:55,  2.85it/s]predicting train subjects:  41%|████      | 109/266 [00:39<00:53,  2.92it/s]predicting train subjects:  41%|████▏     | 110/266 [00:39<00:52,  2.99it/s]predicting train subjects:  42%|████▏     | 111/266 [00:39<00:50,  3.04it/s]predicting train subjects:  42%|████▏     | 112/266 [00:40<00:50,  3.02it/s]predicting train subjects:  42%|████▏     | 113/266 [00:40<00:50,  3.03it/s]predicting train subjects:  43%|████▎     | 114/266 [00:40<00:50,  2.99it/s]predicting train subjects:  43%|████▎     | 115/266 [00:41<00:51,  2.94it/s]predicting train subjects:  44%|████▎     | 116/266 [00:41<00:49,  3.02it/s]predicting train subjects:  44%|████▍     | 117/266 [00:41<00:49,  3.01it/s]predicting train subjects:  44%|████▍     | 118/266 [00:42<00:49,  3.00it/s]predicting train subjects:  45%|████▍     | 119/266 [00:42<00:52,  2.79it/s]predicting train subjects:  45%|████▌     | 120/266 [00:43<00:55,  2.61it/s]predicting train subjects:  45%|████▌     | 121/266 [00:43<00:56,  2.57it/s]predicting train subjects:  46%|████▌     | 122/266 [00:43<00:55,  2.60it/s]predicting train subjects:  46%|████▌     | 123/266 [00:44<00:55,  2.59it/s]predicting train subjects:  47%|████▋     | 124/266 [00:44<00:54,  2.62it/s]predicting train subjects:  47%|████▋     | 125/266 [00:44<00:53,  2.65it/s]predicting train subjects:  47%|████▋     | 126/266 [00:45<00:52,  2.67it/s]predicting train subjects:  48%|████▊     | 127/266 [00:45<00:53,  2.62it/s]predicting train subjects:  48%|████▊     | 128/266 [00:46<00:53,  2.60it/s]predicting train subjects:  48%|████▊     | 129/266 [00:46<00:56,  2.44it/s]predicting train subjects:  49%|████▉     | 130/266 [00:46<00:53,  2.53it/s]predicting train subjects:  49%|████▉     | 131/266 [00:47<00:52,  2.58it/s]predicting train subjects:  50%|████▉     | 132/266 [00:47<00:51,  2.59it/s]predicting train subjects:  50%|█████     | 133/266 [00:48<00:52,  2.53it/s]predicting train subjects:  50%|█████     | 134/266 [00:48<00:52,  2.53it/s]predicting train subjects:  51%|█████     | 135/266 [00:48<00:50,  2.59it/s]predicting train subjects:  51%|█████     | 136/266 [00:49<00:49,  2.61it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:49<00:47,  2.69it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:49<00:46,  2.77it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:50<00:45,  2.82it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:50<00:43,  2.87it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:50<00:44,  2.82it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:51<00:45,  2.75it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:51<00:45,  2.71it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:52<00:43,  2.78it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:52<00:44,  2.73it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:52<00:42,  2.80it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:53<00:42,  2.80it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:53<00:41,  2.83it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:53<00:42,  2.77it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:54<00:42,  2.75it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:54<00:41,  2.79it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:54<00:40,  2.84it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:55<00:39,  2.86it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:55<00:39,  2.87it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:55<00:37,  2.93it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:56<00:35,  3.14it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:56<00:34,  3.18it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:56<00:32,  3.30it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:57<00:31,  3.40it/s]predicting train subjects:  60%|██████    | 160/266 [00:57<00:30,  3.49it/s]predicting train subjects:  61%|██████    | 161/266 [00:57<00:29,  3.52it/s]predicting train subjects:  61%|██████    | 162/266 [00:57<00:28,  3.59it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:58<00:28,  3.62it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:58<00:27,  3.65it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:58<00:27,  3.68it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:58<00:26,  3.72it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:59<00:26,  3.74it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:59<00:26,  3.75it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:59<00:25,  3.73it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:00<00:25,  3.73it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:00<00:26,  3.64it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:00<00:25,  3.69it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:00<00:26,  3.55it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:01<00:26,  3.51it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:01<00:26,  3.44it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:01<00:26,  3.43it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:02<00:26,  3.41it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:02<00:26,  3.34it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:02<00:26,  3.23it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:03<00:26,  3.21it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:03<00:26,  3.17it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:03<00:27,  3.11it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:03<00:25,  3.20it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:04<00:25,  3.18it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:04<00:25,  3.23it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:05<00:27,  2.90it/s]predicting train subjects:  70%|███████   | 187/266 [01:05<00:26,  2.97it/s]predicting train subjects:  71%|███████   | 188/266 [01:05<00:25,  3.07it/s]predicting train subjects:  71%|███████   | 189/266 [01:05<00:25,  3.03it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:06<00:24,  3.09it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:06<00:24,  3.01it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:06<00:24,  3.01it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:07<00:23,  3.15it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:07<00:24,  2.94it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:07<00:23,  3.05it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:08<00:22,  3.10it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:08<00:21,  3.15it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:08<00:22,  3.03it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:09<00:21,  3.11it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:09<00:20,  3.16it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:09<00:21,  3.05it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:10<00:20,  3.13it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:10<00:19,  3.19it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:10<00:19,  3.24it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:11<00:19,  3.16it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:11<00:19,  3.14it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:11<00:18,  3.20it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:12<00:17,  3.24it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:12<00:17,  3.25it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:12<00:17,  3.22it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:12<00:17,  3.20it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:13<00:17,  3.09it/s]predicting train subjects:  80%|████████  | 213/266 [01:13<00:17,  3.12it/s]predicting train subjects:  80%|████████  | 214/266 [01:13<00:16,  3.16it/s]predicting train subjects:  81%|████████  | 215/266 [01:14<00:15,  3.29it/s]predicting train subjects:  81%|████████  | 216/266 [01:14<00:15,  3.33it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:14<00:14,  3.29it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:15<00:14,  3.24it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:15<00:14,  3.33it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:15<00:13,  3.32it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:16<00:13,  3.31it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:16<00:13,  3.31it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:16<00:12,  3.44it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:16<00:12,  3.38it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:17<00:11,  3.42it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:17<00:11,  3.35it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:17<00:11,  3.31it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:18<00:11,  3.41it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:18<00:10,  3.51it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:18<00:10,  3.58it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:18<00:10,  3.42it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:19<00:09,  3.41it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:19<00:10,  3.28it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:19<00:09,  3.36it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:20<00:09,  3.34it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:20<00:09,  3.28it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:20<00:08,  3.31it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:21<00:08,  3.37it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:21<00:08,  3.36it/s]predicting train subjects:  90%|█████████ | 240/266 [01:21<00:07,  3.35it/s]predicting train subjects:  91%|█████████ | 241/266 [01:21<00:07,  3.40it/s]predicting train subjects:  91%|█████████ | 242/266 [01:22<00:07,  3.40it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:22<00:07,  3.28it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:22<00:06,  3.26it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:23<00:06,  3.26it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:23<00:06,  3.28it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:23<00:05,  3.32it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:24<00:05,  3.36it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:24<00:05,  3.05it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:24<00:05,  2.87it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:25<00:05,  2.81it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:25<00:04,  2.80it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:25<00:04,  2.78it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:26<00:04,  2.80it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:26<00:04,  2.72it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:27<00:03,  2.76it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:27<00:03,  2.66it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:27<00:03,  2.57it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:28<00:02,  2.57it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:28<00:02,  2.65it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:29<00:01,  2.64it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:29<00:01,  2.68it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:29<00:01,  2.74it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:30<00:00,  2.70it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:30<00:00,  2.75it/s]predicting train subjects: 100%|██████████| 266/266 [01:30<00:00,  2.75it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 67.49it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 62.69it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 64.04it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 65.20it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 66.40it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 67.92it/s]saving BB  train1-THALAMUS:  17%|█▋        | 44/266 [00:00<00:03, 69.60it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 68.08it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 71.15it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 75.08it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 77.85it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 76.15it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 74.98it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 72.94it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 74.05it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:01, 74.59it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 74.40it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 73.42it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 72.85it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 72.31it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 73.15it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 75.89it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 78.56it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 80.05it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 79.66it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 201/266 [00:02<00:00, 76.99it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 209/266 [00:02<00:00, 76.00it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 217/266 [00:02<00:00, 76.88it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:03<00:00, 78.41it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:03<00:00, 79.40it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 244/266 [00:03<00:00, 80.96it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 253/266 [00:03<00:00, 79.89it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 77.62it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 74.84it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:33,  1.94s/it]Loading train:   1%|          | 2/266 [00:03<08:10,  1.86s/it]Loading train:   1%|          | 3/266 [00:05<07:34,  1.73s/it]Loading train:   2%|▏         | 4/266 [00:06<07:00,  1.60s/it]Loading train:   2%|▏         | 5/266 [00:08<07:04,  1.63s/it]Loading train:   2%|▏         | 6/266 [00:09<06:43,  1.55s/it]Loading train:   3%|▎         | 7/266 [00:10<06:08,  1.42s/it]Loading train:   3%|▎         | 8/266 [00:11<05:44,  1.33s/it]Loading train:   3%|▎         | 9/266 [00:12<05:26,  1.27s/it]Loading train:   4%|▍         | 10/266 [00:13<05:19,  1.25s/it]Loading train:   4%|▍         | 11/266 [00:15<05:04,  1.20s/it]Loading train:   5%|▍         | 12/266 [00:16<04:56,  1.17s/it]Loading train:   5%|▍         | 13/266 [00:17<04:47,  1.13s/it]Loading train:   5%|▌         | 14/266 [00:18<04:49,  1.15s/it]Loading train:   6%|▌         | 15/266 [00:19<04:47,  1.15s/it]Loading train:   6%|▌         | 16/266 [00:20<04:48,  1.15s/it]Loading train:   6%|▋         | 17/266 [00:21<04:42,  1.13s/it]Loading train:   7%|▋         | 18/266 [00:22<04:36,  1.11s/it]Loading train:   7%|▋         | 19/266 [00:24<04:41,  1.14s/it]Loading train:   8%|▊         | 20/266 [00:25<04:48,  1.17s/it]Loading train:   8%|▊         | 21/266 [00:26<04:53,  1.20s/it]Loading train:   8%|▊         | 22/266 [00:27<04:43,  1.16s/it]Loading train:   9%|▊         | 23/266 [00:28<04:44,  1.17s/it]Loading train:   9%|▉         | 24/266 [00:29<04:35,  1.14s/it]Loading train:   9%|▉         | 25/266 [00:30<04:19,  1.08s/it]Loading train:  10%|▉         | 26/266 [00:31<04:04,  1.02s/it]Loading train:  10%|█         | 27/266 [00:32<04:00,  1.00s/it]Loading train:  11%|█         | 28/266 [00:33<03:59,  1.01s/it]Loading train:  11%|█         | 29/266 [00:34<04:00,  1.01s/it]Loading train:  11%|█▏        | 30/266 [00:35<04:02,  1.03s/it]Loading train:  12%|█▏        | 31/266 [00:36<03:55,  1.00s/it]Loading train:  12%|█▏        | 32/266 [00:37<03:52,  1.01it/s]Loading train:  12%|█▏        | 33/266 [00:38<03:58,  1.02s/it]Loading train:  13%|█▎        | 34/266 [00:39<03:58,  1.03s/it]Loading train:  13%|█▎        | 35/266 [00:40<03:50,  1.00it/s]Loading train:  14%|█▎        | 36/266 [00:41<03:43,  1.03it/s]Loading train:  14%|█▍        | 37/266 [00:42<03:40,  1.04it/s]Loading train:  14%|█▍        | 38/266 [00:43<03:41,  1.03it/s]Loading train:  15%|█▍        | 39/266 [00:44<03:39,  1.03it/s]Loading train:  15%|█▌        | 40/266 [00:45<03:36,  1.04it/s]Loading train:  15%|█▌        | 41/266 [00:46<03:34,  1.05it/s]Loading train:  16%|█▌        | 42/266 [00:47<03:33,  1.05it/s]Loading train:  16%|█▌        | 43/266 [00:48<03:30,  1.06it/s]Loading train:  17%|█▋        | 44/266 [00:49<03:30,  1.05it/s]Loading train:  17%|█▋        | 45/266 [00:50<03:22,  1.09it/s]Loading train:  17%|█▋        | 46/266 [00:51<03:30,  1.05it/s]Loading train:  18%|█▊        | 47/266 [00:51<03:18,  1.10it/s]Loading train:  18%|█▊        | 48/266 [00:52<03:15,  1.11it/s]Loading train:  18%|█▊        | 49/266 [00:53<03:12,  1.13it/s]Loading train:  19%|█▉        | 50/266 [00:54<03:09,  1.14it/s]Loading train:  19%|█▉        | 51/266 [00:55<03:09,  1.14it/s]Loading train:  20%|█▉        | 52/266 [00:56<03:12,  1.11it/s]Loading train:  20%|█▉        | 53/266 [00:57<03:12,  1.11it/s]Loading train:  20%|██        | 54/266 [00:58<03:13,  1.10it/s]Loading train:  21%|██        | 55/266 [00:59<03:14,  1.08it/s]Loading train:  21%|██        | 56/266 [01:00<03:10,  1.10it/s]Loading train:  21%|██▏       | 57/266 [01:01<03:23,  1.03it/s]Loading train:  22%|██▏       | 58/266 [01:02<03:32,  1.02s/it]Loading train:  22%|██▏       | 59/266 [01:03<03:26,  1.00it/s]Loading train:  23%|██▎       | 60/266 [01:04<03:14,  1.06it/s]Loading train:  23%|██▎       | 61/266 [01:04<03:00,  1.14it/s]Loading train:  23%|██▎       | 62/266 [01:05<02:57,  1.15it/s]Loading train:  24%|██▎       | 63/266 [01:06<02:56,  1.15it/s]Loading train:  24%|██▍       | 64/266 [01:07<02:55,  1.15it/s]Loading train:  24%|██▍       | 65/266 [01:08<02:53,  1.16it/s]Loading train:  25%|██▍       | 66/266 [01:08<02:46,  1.20it/s]Loading train:  25%|██▌       | 67/266 [01:09<02:47,  1.18it/s]Loading train:  26%|██▌       | 68/266 [01:10<02:51,  1.16it/s]Loading train:  26%|██▌       | 69/266 [01:11<02:48,  1.17it/s]Loading train:  26%|██▋       | 70/266 [01:12<02:46,  1.17it/s]Loading train:  27%|██▋       | 71/266 [01:13<02:42,  1.20it/s]Loading train:  27%|██▋       | 72/266 [01:14<02:40,  1.21it/s]Loading train:  27%|██▋       | 73/266 [01:14<02:40,  1.20it/s]Loading train:  28%|██▊       | 74/266 [01:15<02:34,  1.24it/s]Loading train:  28%|██▊       | 75/266 [01:16<02:31,  1.26it/s]Loading train:  29%|██▊       | 76/266 [01:17<02:35,  1.22it/s]Loading train:  29%|██▉       | 77/266 [01:18<02:45,  1.14it/s]Loading train:  29%|██▉       | 78/266 [01:19<02:56,  1.07it/s]Loading train:  30%|██▉       | 79/266 [01:20<02:53,  1.08it/s]Loading train:  30%|███       | 80/266 [01:21<02:55,  1.06it/s]Loading train:  30%|███       | 81/266 [01:22<02:57,  1.04it/s]Loading train:  31%|███       | 82/266 [01:23<02:58,  1.03it/s]Loading train:  31%|███       | 83/266 [01:24<03:00,  1.02it/s]Loading train:  32%|███▏      | 84/266 [01:25<02:59,  1.02it/s]Loading train:  32%|███▏      | 85/266 [01:26<03:03,  1.01s/it]Loading train:  32%|███▏      | 86/266 [01:27<03:01,  1.01s/it]Loading train:  33%|███▎      | 87/266 [01:28<03:04,  1.03s/it]Loading train:  33%|███▎      | 88/266 [01:29<03:06,  1.05s/it]Loading train:  33%|███▎      | 89/266 [01:30<03:04,  1.04s/it]Loading train:  34%|███▍      | 90/266 [01:31<03:00,  1.03s/it]Loading train:  34%|███▍      | 91/266 [01:32<02:57,  1.02s/it]Loading train:  35%|███▍      | 92/266 [01:33<02:53,  1.00it/s]Loading train:  35%|███▍      | 93/266 [01:34<02:49,  1.02it/s]Loading train:  35%|███▌      | 94/266 [01:35<02:48,  1.02it/s]Loading train:  36%|███▌      | 95/266 [01:36<02:47,  1.02it/s]Loading train:  36%|███▌      | 96/266 [01:37<03:05,  1.09s/it]Loading train:  36%|███▋      | 97/266 [01:39<03:28,  1.23s/it]Loading train:  37%|███▋      | 98/266 [01:40<03:33,  1.27s/it]Loading train:  37%|███▋      | 99/266 [01:41<03:28,  1.25s/it]Loading train:  38%|███▊      | 100/266 [01:43<03:28,  1.25s/it]Loading train:  38%|███▊      | 101/266 [01:43<03:10,  1.15s/it]Loading train:  38%|███▊      | 102/266 [01:44<02:56,  1.08s/it]Loading train:  39%|███▊      | 103/266 [01:45<02:48,  1.03s/it]Loading train:  39%|███▉      | 104/266 [01:46<02:45,  1.02s/it]Loading train:  39%|███▉      | 105/266 [01:47<02:42,  1.01s/it]Loading train:  40%|███▉      | 106/266 [01:48<02:38,  1.01it/s]Loading train:  40%|████      | 107/266 [01:49<02:31,  1.05it/s]Loading train:  41%|████      | 108/266 [01:50<02:29,  1.06it/s]Loading train:  41%|████      | 109/266 [01:51<02:27,  1.06it/s]Loading train:  41%|████▏     | 110/266 [01:52<02:24,  1.08it/s]Loading train:  42%|████▏     | 111/266 [01:53<02:26,  1.06it/s]Loading train:  42%|████▏     | 112/266 [01:54<02:24,  1.06it/s]Loading train:  42%|████▏     | 113/266 [01:55<02:23,  1.07it/s]Loading train:  43%|████▎     | 114/266 [01:56<02:18,  1.10it/s]Loading train:  43%|████▎     | 115/266 [01:56<02:17,  1.10it/s]Loading train:  44%|████▎     | 116/266 [01:57<02:19,  1.07it/s]Loading train:  44%|████▍     | 117/266 [01:58<02:18,  1.07it/s]Loading train:  44%|████▍     | 118/266 [01:59<02:17,  1.08it/s]Loading train:  45%|████▍     | 119/266 [02:00<02:25,  1.01it/s]Loading train:  45%|████▌     | 120/266 [02:02<02:29,  1.02s/it]Loading train:  45%|████▌     | 121/266 [02:03<02:28,  1.03s/it]Loading train:  46%|████▌     | 122/266 [02:04<02:26,  1.02s/it]Loading train:  46%|████▌     | 123/266 [02:05<02:26,  1.02s/it]Loading train:  47%|████▋     | 124/266 [02:06<02:22,  1.00s/it]Loading train:  47%|████▋     | 125/266 [02:07<02:20,  1.01it/s]Loading train:  47%|████▋     | 126/266 [02:07<02:17,  1.02it/s]Loading train:  48%|████▊     | 127/266 [02:08<02:17,  1.01it/s]Loading train:  48%|████▊     | 128/266 [02:10<02:22,  1.03s/it]Loading train:  48%|████▊     | 129/266 [02:11<02:24,  1.06s/it]Loading train:  49%|████▉     | 130/266 [02:12<02:22,  1.05s/it]Loading train:  49%|████▉     | 131/266 [02:13<02:23,  1.06s/it]Loading train:  50%|████▉     | 132/266 [02:14<02:20,  1.05s/it]Loading train:  50%|█████     | 133/266 [02:15<02:19,  1.05s/it]Loading train:  50%|█████     | 134/266 [02:16<02:16,  1.04s/it]Loading train:  51%|█████     | 135/266 [02:17<02:15,  1.04s/it]Loading train:  51%|█████     | 136/266 [02:18<02:14,  1.03s/it]Loading train:  52%|█████▏    | 137/266 [02:19<02:12,  1.03s/it]Loading train:  52%|█████▏    | 138/266 [02:20<02:14,  1.05s/it]Loading train:  52%|█████▏    | 139/266 [02:21<02:13,  1.05s/it]Loading train:  53%|█████▎    | 140/266 [02:22<02:06,  1.01s/it]Loading train:  53%|█████▎    | 141/266 [02:23<02:06,  1.01s/it]Loading train:  53%|█████▎    | 142/266 [02:24<02:07,  1.03s/it]Loading train:  54%|█████▍    | 143/266 [02:25<02:05,  1.02s/it]Loading train:  54%|█████▍    | 144/266 [02:26<02:03,  1.01s/it]Loading train:  55%|█████▍    | 145/266 [02:27<02:01,  1.00s/it]Loading train:  55%|█████▍    | 146/266 [02:28<01:55,  1.03it/s]Loading train:  55%|█████▌    | 147/266 [02:29<01:52,  1.06it/s]Loading train:  56%|█████▌    | 148/266 [02:30<01:51,  1.06it/s]Loading train:  56%|█████▌    | 149/266 [02:31<01:46,  1.10it/s]Loading train:  56%|█████▋    | 150/266 [02:32<01:47,  1.08it/s]Loading train:  57%|█████▋    | 151/266 [02:33<01:47,  1.07it/s]Loading train:  57%|█████▋    | 152/266 [02:34<01:47,  1.06it/s]Loading train:  58%|█████▊    | 153/266 [02:35<01:48,  1.04it/s]Loading train:  58%|█████▊    | 154/266 [02:36<01:49,  1.03it/s]Loading train:  58%|█████▊    | 155/266 [02:36<01:46,  1.05it/s]Loading train:  59%|█████▊    | 156/266 [02:37<01:42,  1.07it/s]Loading train:  59%|█████▉    | 157/266 [02:38<01:34,  1.15it/s]Loading train:  59%|█████▉    | 158/266 [02:39<01:34,  1.14it/s]Loading train:  60%|█████▉    | 159/266 [02:40<01:29,  1.19it/s]Loading train:  60%|██████    | 160/266 [02:41<01:28,  1.20it/s]Loading train:  61%|██████    | 161/266 [02:41<01:27,  1.20it/s]Loading train:  61%|██████    | 162/266 [02:42<01:24,  1.23it/s]Loading train:  61%|██████▏   | 163/266 [02:43<01:25,  1.21it/s]Loading train:  62%|██████▏   | 164/266 [02:44<01:25,  1.19it/s]Loading train:  62%|██████▏   | 165/266 [02:45<01:25,  1.18it/s]Loading train:  62%|██████▏   | 166/266 [02:46<01:28,  1.13it/s]Loading train:  63%|██████▎   | 167/266 [02:47<01:25,  1.16it/s]Loading train:  63%|██████▎   | 168/266 [02:47<01:22,  1.18it/s]Loading train:  64%|██████▎   | 169/266 [02:48<01:20,  1.20it/s]Loading train:  64%|██████▍   | 170/266 [02:49<01:18,  1.22it/s]Loading train:  64%|██████▍   | 171/266 [02:50<01:21,  1.17it/s]Loading train:  65%|██████▍   | 172/266 [02:51<01:18,  1.20it/s]Loading train:  65%|██████▌   | 173/266 [02:52<01:23,  1.12it/s]Loading train:  65%|██████▌   | 174/266 [02:52<01:18,  1.17it/s]Loading train:  66%|██████▌   | 175/266 [02:53<01:17,  1.17it/s]Loading train:  66%|██████▌   | 176/266 [02:54<01:16,  1.17it/s]Loading train:  67%|██████▋   | 177/266 [02:55<01:15,  1.19it/s]Loading train:  67%|██████▋   | 178/266 [02:56<01:11,  1.23it/s]Loading train:  67%|██████▋   | 179/266 [02:57<01:11,  1.22it/s]Loading train:  68%|██████▊   | 180/266 [02:57<01:11,  1.21it/s]Loading train:  68%|██████▊   | 181/266 [02:58<01:09,  1.22it/s]Loading train:  68%|██████▊   | 182/266 [02:59<01:11,  1.18it/s]Loading train:  69%|██████▉   | 183/266 [03:00<01:08,  1.20it/s]Loading train:  69%|██████▉   | 184/266 [03:01<01:07,  1.22it/s]Loading train:  70%|██████▉   | 185/266 [03:02<01:06,  1.22it/s]Loading train:  70%|██████▉   | 186/266 [03:02<01:05,  1.22it/s]Loading train:  70%|███████   | 187/266 [03:03<01:03,  1.24it/s]Loading train:  71%|███████   | 188/266 [03:04<01:04,  1.21it/s]Loading train:  71%|███████   | 189/266 [03:05<01:01,  1.25it/s]Loading train:  71%|███████▏  | 190/266 [03:06<01:00,  1.25it/s]Loading train:  72%|███████▏  | 191/266 [03:07<01:15,  1.00s/it]Loading train:  72%|███████▏  | 192/266 [03:08<01:18,  1.06s/it]Loading train:  73%|███████▎  | 193/266 [03:09<01:20,  1.10s/it]Loading train:  73%|███████▎  | 194/266 [03:11<01:31,  1.28s/it]Loading train:  73%|███████▎  | 195/266 [03:12<01:24,  1.19s/it]Loading train:  74%|███████▎  | 196/266 [03:13<01:16,  1.09s/it]Loading train:  74%|███████▍  | 197/266 [03:14<01:12,  1.05s/it]Loading train:  74%|███████▍  | 198/266 [03:15<01:06,  1.02it/s]Loading train:  75%|███████▍  | 199/266 [03:16<01:03,  1.06it/s]Loading train:  75%|███████▌  | 200/266 [03:17<01:02,  1.05it/s]Loading train:  76%|███████▌  | 201/266 [03:17<01:01,  1.06it/s]Loading train:  76%|███████▌  | 202/266 [03:18<00:58,  1.09it/s]Loading train:  76%|███████▋  | 203/266 [03:19<00:55,  1.13it/s]Loading train:  77%|███████▋  | 204/266 [03:20<00:55,  1.11it/s]Loading train:  77%|███████▋  | 205/266 [03:21<00:54,  1.12it/s]Loading train:  77%|███████▋  | 206/266 [03:22<00:51,  1.16it/s]Loading train:  78%|███████▊  | 207/266 [03:23<00:50,  1.18it/s]Loading train:  78%|███████▊  | 208/266 [03:23<00:50,  1.15it/s]Loading train:  79%|███████▊  | 209/266 [03:24<00:49,  1.16it/s]Loading train:  79%|███████▉  | 210/266 [03:25<00:47,  1.17it/s]Loading train:  79%|███████▉  | 211/266 [03:26<00:48,  1.14it/s]Loading train:  80%|███████▉  | 212/266 [03:27<00:47,  1.14it/s]Loading train:  80%|████████  | 213/266 [03:28<00:45,  1.16it/s]Loading train:  80%|████████  | 214/266 [03:29<00:44,  1.18it/s]Loading train:  81%|████████  | 215/266 [03:29<00:43,  1.16it/s]Loading train:  81%|████████  | 216/266 [03:30<00:42,  1.17it/s]Loading train:  82%|████████▏ | 217/266 [03:31<00:42,  1.16it/s]Loading train:  82%|████████▏ | 218/266 [03:32<00:41,  1.16it/s]Loading train:  82%|████████▏ | 219/266 [03:33<00:39,  1.20it/s]Loading train:  83%|████████▎ | 220/266 [03:34<00:39,  1.17it/s]Loading train:  83%|████████▎ | 221/266 [03:35<00:37,  1.19it/s]Loading train:  83%|████████▎ | 222/266 [03:35<00:37,  1.19it/s]Loading train:  84%|████████▍ | 223/266 [03:36<00:36,  1.19it/s]Loading train:  84%|████████▍ | 224/266 [03:37<00:35,  1.17it/s]Loading train:  85%|████████▍ | 225/266 [03:38<00:34,  1.18it/s]Loading train:  85%|████████▍ | 226/266 [03:39<00:34,  1.14it/s]Loading train:  85%|████████▌ | 227/266 [03:40<00:34,  1.13it/s]Loading train:  86%|████████▌ | 228/266 [03:41<00:33,  1.12it/s]Loading train:  86%|████████▌ | 229/266 [03:42<00:32,  1.12it/s]Loading train:  86%|████████▋ | 230/266 [03:42<00:31,  1.15it/s]Loading train:  87%|████████▋ | 231/266 [03:43<00:29,  1.20it/s]Loading train:  87%|████████▋ | 232/266 [03:44<00:27,  1.24it/s]Loading train:  88%|████████▊ | 233/266 [03:45<00:25,  1.27it/s]Loading train:  88%|████████▊ | 234/266 [03:45<00:24,  1.29it/s]Loading train:  88%|████████▊ | 235/266 [03:46<00:24,  1.28it/s]Loading train:  89%|████████▊ | 236/266 [03:47<00:23,  1.27it/s]Loading train:  89%|████████▉ | 237/266 [03:48<00:22,  1.31it/s]Loading train:  89%|████████▉ | 238/266 [03:49<00:21,  1.29it/s]Loading train:  90%|████████▉ | 239/266 [03:49<00:21,  1.26it/s]Loading train:  90%|█████████ | 240/266 [03:50<00:20,  1.27it/s]Loading train:  91%|█████████ | 241/266 [03:51<00:19,  1.27it/s]Loading train:  91%|█████████ | 242/266 [03:52<00:19,  1.22it/s]Loading train:  91%|█████████▏| 243/266 [03:53<00:19,  1.19it/s]Loading train:  92%|█████████▏| 244/266 [03:54<00:18,  1.19it/s]Loading train:  92%|█████████▏| 245/266 [03:54<00:18,  1.16it/s]Loading train:  92%|█████████▏| 246/266 [03:55<00:17,  1.13it/s]Loading train:  93%|█████████▎| 247/266 [03:56<00:16,  1.14it/s]Loading train:  93%|█████████▎| 248/266 [03:57<00:15,  1.17it/s]Loading train:  94%|█████████▎| 249/266 [03:58<00:15,  1.09it/s]Loading train:  94%|█████████▍| 250/266 [03:59<00:15,  1.04it/s]Loading train:  94%|█████████▍| 251/266 [04:00<00:15,  1.00s/it]Loading train:  95%|█████████▍| 252/266 [04:01<00:14,  1.04s/it]Loading train:  95%|█████████▌| 253/266 [04:02<00:13,  1.03s/it]Loading train:  95%|█████████▌| 254/266 [04:03<00:12,  1.03s/it]Loading train:  96%|█████████▌| 255/266 [04:04<00:11,  1.01s/it]Loading train:  96%|█████████▌| 256/266 [04:05<00:10,  1.02s/it]Loading train:  97%|█████████▋| 257/266 [04:07<00:09,  1.06s/it]Loading train:  97%|█████████▋| 258/266 [04:08<00:08,  1.10s/it]Loading train:  97%|█████████▋| 259/266 [04:09<00:07,  1.08s/it]Loading train:  98%|█████████▊| 260/266 [04:10<00:06,  1.05s/it]Loading train:  98%|█████████▊| 261/266 [04:11<00:05,  1.01s/it]Loading train:  98%|█████████▊| 262/266 [04:12<00:03,  1.02it/s]Loading train:  99%|█████████▉| 263/266 [04:13<00:02,  1.03it/s]Loading train:  99%|█████████▉| 264/266 [04:14<00:01,  1.04it/s]Loading train: 100%|█████████▉| 265/266 [04:14<00:00,  1.05it/s]Loading train: 100%|██████████| 266/266 [04:15<00:00,  1.04it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/266 [00:00<00:03, 79.84it/s]concatenating: train:  12%|█▏        | 33/266 [00:00<00:02, 100.16it/s]concatenating: train:  24%|██▎       | 63/266 [00:00<00:01, 124.97it/s]concatenating: train:  36%|███▋      | 97/266 [00:00<00:01, 153.63it/s]concatenating: train:  48%|████▊     | 127/266 [00:00<00:00, 179.56it/s]concatenating: train:  59%|█████▊    | 156/266 [00:00<00:00, 202.11it/s]concatenating: train:  70%|██████▉   | 186/266 [00:00<00:00, 223.36it/s]concatenating: train:  82%|████████▏ | 217/266 [00:00<00:00, 243.04it/s]concatenating: train:  93%|█████████▎| 248/266 [00:00<00:00, 258.41it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 267.83it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.28s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.24s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.31s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 140.20it/s]2019-07-29 02:23:00.721205: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 02:23:00.721281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 02:23:00.721295: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 02:23:00.721304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 02:23:00.723988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.66it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.54it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.20it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.61it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.89it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.72it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.02it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.74it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.22it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.89it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.59it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.81it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.04it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.33it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.08it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.35it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.15it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.10it/s]
Epoch 00044: val_mDice did not improve from 0.89059
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [0.06327528559198284, 0.06333155602668271, 0.06347492357922925, 0.059838167551641515, 0.06267560467199244, 0.06717976543939475, 0.061993296305188024, 0.060643189991212855, 0.0644247822952692, 0.06451475012558278, 0.0673963725566864, 0.07010543122511319, 0.06639380421903399, 0.06724472059821239, 0.06365210512144999, 0.06742748388587827, 0.06355721612620835, 0.07021654051060629, 0.06515807109047668, 0.06570478965236683, 0.07031163821617763, 0.06595121514089781, 0.06807941089224334, 0.06638726972118773, 0.06501530093902891, 0.06690013228040753, 0.0653246467688469, 0.07071083496240052, 0.06814163069080825, 0.06688176650516313, 0.0648684220557863, 0.06528364466221044, 0.06790314872532782, 0.06899413398721001, 0.06679144210059836, 0.06320561839248796, 0.06553985020427992, 0.06900884487637968, 0.06674900299145116, 0.0650602232175644, 0.06965417984985944, 0.0663131841956967, 0.06527861045918079, 0.06521335204668118], 'val_acc': [0.9945726117702446, 0.99447786476877, 0.9944895436667432, 0.9947424320259479, 0.9943797169911741, 0.9945720097031256, 0.9947528995648779, 0.9946516716119015, 0.9944633928814319, 0.9944449356108, 0.9947116874685191, 0.9946326011359089, 0.9947938262814223, 0.9945938421620263, 0.9947012075872133, 0.9943754082978374, 0.9946661380806354, 0.9946169142771248, 0.9946236893384144, 0.9946701493528154, 0.994442181153731, 0.9943363308304488, 0.9941711224088765, 0.9944003266517563, 0.9946307627239612, 0.9946932103296723, 0.9945655432012346, 0.9946959837518558, 0.9941886530982124, 0.9946172249437583, 0.9943695613230118, 0.9943237151160385, 0.9942871142517437, 0.994654138882955, 0.994419396224648, 0.9944858538984048, 0.9945722938788057, 0.9944649299587867, 0.9943750904063986, 0.9943923245776783, 0.9945181584117389, 0.9944843198313857, 0.9947676773023124, 0.9944252597563195], 'val_mDice': [0.8841964665687445, 0.8843441768126055, 0.8841791505163367, 0.8905892676175243, 0.885965766930821, 0.8784768190046753, 0.8871162076189061, 0.8893901296336242, 0.8830186038306265, 0.8828672778726828, 0.8781601801665142, 0.8737456115207287, 0.8797015936085673, 0.8784817923801114, 0.8842196211670384, 0.8782940813989351, 0.8846385150846808, 0.8737943350064634, 0.8819913596215875, 0.8811330412975465, 0.8732065669815949, 0.8808560473750336, 0.8769722996336041, 0.8797472278879146, 0.8824173461909246, 0.8790780098149271, 0.8818550215225027, 0.873122364282608, 0.8771193608491108, 0.8792293712948308, 0.8826632382291736, 0.8818160181093697, 0.8777995690552876, 0.8754930219264946, 0.8792456319235792, 0.8852412270175086, 0.8814147093681374, 0.8756322463353475, 0.8794263836109277, 0.882356424223293, 0.8743645413355394, 0.879898856083552, 0.8820067123331204, 0.8819466374739252], 'loss': [0.10084933370144676, 0.05207282268372099, 0.04676273878017273, 0.043308503645208905, 0.040878764774812594, 0.039486540511730214, 0.03812141526681726, 0.036898924352680836, 0.03568926762280883, 0.03484943859787894, 0.03414648181019107, 0.03335362543371682, 0.03296290269834919, 0.032286337516209185, 0.03170804322411739, 0.03141317370120031, 0.030892940984653727, 0.030612161619898274, 0.03024104818905133, 0.02997124468169697, 0.02990202604699404, 0.029648471821124678, 0.02926751451538397, 0.028883781281564807, 0.02893078652188471, 0.028612446314050768, 0.02832834083569228, 0.028338056602635244, 0.027933365383420415, 0.02783839255162724, 0.02770591926354227, 0.027435644090936472, 0.027342027112935846, 0.027302815818904716, 0.027134161756186957, 0.02695576531892613, 0.026872543065884952, 0.026796903020164912, 0.026719795848119912, 0.026546089387622155, 0.026361332238601664, 0.026374190805235165, 0.026307312264936263, 0.02622107383180956], 'acc': [0.9892119188232387, 0.9943758525955556, 0.9948785575732679, 0.9951971096765378, 0.995408504001239, 0.9955428126315176, 0.9956558392132816, 0.9957676929932092, 0.9958667711978701, 0.9959414417828787, 0.9960133815627817, 0.9960787237919373, 0.996117785520295, 0.9961888937699338, 0.9962329701514013, 0.9962623928245524, 0.9963030774382852, 0.9963297927886909, 0.9963727293918553, 0.9963816831842575, 0.9964000794261999, 0.9964256547832002, 0.99645880402768, 0.99649023322229, 0.9964923056310859, 0.9965157825604263, 0.9965484179381998, 0.9965450366806634, 0.9965820387636737, 0.9965947181967143, 0.9966110771660824, 0.996625717118498, 0.9966489333863997, 0.9966417589929448, 0.9966586188653762, 0.996669815572447, 0.9966628497877948, 0.9966712987456593, 0.9966741725128896, 0.9967070824549539, 0.9967150702632227, 0.9967137369141129, 0.9967264115744373, 0.9967279029939491], 'mDice': [0.8501321529133589, 0.9038314258472565, 0.9131572282692966, 0.9193016165969209, 0.9236570838056807, 0.9261585701319951, 0.928630817589041, 0.9308396343373535, 0.9330440823060759, 0.9345696470053134, 0.9358467679849736, 0.9372939630119893, 0.9380071272560223, 0.9392415697233774, 0.9403049022190381, 0.9408462906729717, 0.9418013738266298, 0.9423143323004409, 0.9429954714205512, 0.9434994069689207, 0.943621993137291, 0.9440897118986903, 0.9447932459940314, 0.9455011423370925, 0.9454123473616366, 0.9459988529153902, 0.9465204330763727, 0.946508518870963, 0.9472515959659096, 0.9474260924491749, 0.9476734290732258, 0.9481739413211356, 0.9483440906990336, 0.9484210278471894, 0.9487315938459714, 0.9490637614501525, 0.9492230933016765, 0.9493624711869831, 0.949504526044308, 0.9498210243483288, 0.9501685730517432, 0.9501461900434434, 0.9502662200783254, 0.9504295872113676]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 48, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 48, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 48, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 48, 52, 30)   8400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 48, 52, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 48, 52, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 48, 52, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 48, 52, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 48, 52, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 24, 26, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 24, 26, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 24, 26, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 24, 26, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 24, 26, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 24, 26, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 24, 26, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 12, 13, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 12, 13, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 12, 13, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 12, 13, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 12, 13, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 12, 13, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 12, 13, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 13, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 24, 26, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 26, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 24, 26, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 24, 26, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 26, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 24, 26, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 26, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 48, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 48, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 48, 52, 30)   8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 48, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 48, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 48, 52, 90)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 48, 52, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 48, 52, 30)   24330       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 48, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 48, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 48, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 48, 52, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 48, 52, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 48, 52, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 48, 52, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 48, 52, 120)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 48, 52, 13)   1573        concatenate_8[0][0]              
==================================================================================================
Total params: 551,203
Trainable params: 158,743
Non-trainable params: 392,460
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34788796e-02 3.29002219e-02 7.69326440e-02 9.55926786e-03
 2.76666979e-02 7.23828764e-03 8.42821136e-02 1.14347710e-01
 8.97855221e-02 1.36415452e-02 2.91102322e-01 1.88797737e-01
 2.67050886e-04]
Train on 16599 samples, validate on 238 samples
Epoch 1/300
 - 25s - loss: 1.2798 - acc: 0.8328 - mDice: 0.3808 - val_loss: 0.9902 - val_acc: 0.9152 - val_mDice: 0.5158

Epoch 00001: val_mDice improved from -inf to 0.51585, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 0.5433 - acc: 0.8960 - mDice: 0.5750 - val_loss: 0.8949 - val_acc: 0.9352 - val_mDice: 0.5662

Epoch 00002: val_mDice improved from 0.51585 to 0.56623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 0.4679 - acc: 0.9272 - mDice: 0.6210 - val_loss: 0.7248 - val_acc: 0.9432 - val_mDice: 0.5801

Epoch 00003: val_mDice improved from 0.56623 to 0.58008, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 18s - loss: 0.4321 - acc: 0.9353 - mDice: 0.6410 - val_loss: 0.8559 - val_acc: 0.9422 - val_mDice: 0.5634

Epoch 00004: val_mDice did not improve from 0.58008
Epoch 5/300
 - 18s - loss: 0.3972 - acc: 0.9381 - mDice: 0.6633 - val_loss: 0.9259 - val_acc: 0.9435 - val_mDice: 0.5822

Epoch 00005: val_mDice improved from 0.58008 to 0.58220, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 18s - loss: 0.4065 - acc: 0.9376 - mDice: 0.6613 - val_loss: 0.7170 - val_acc: 0.9421 - val_mDice: 0.5864

Epoch 00006: val_mDice improved from 0.58220 to 0.58644, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 19s - loss: 0.3579 - acc: 0.9415 - mDice: 0.6877 - val_loss: 0.8151 - val_acc: 0.9458 - val_mDice: 0.5936

Epoch 00007: val_mDice improved from 0.58644 to 0.59358, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 18s - loss: 0.3392 - acc: 0.9431 - mDice: 0.7001 - val_loss: 0.8695 - val_acc: 0.9455 - val_mDice: 0.5258

Epoch 00008: val_mDice did not improve from 0.59358
Epoch 9/300
 - 18s - loss: 0.3848 - acc: 0.9398 - mDice: 0.6760 - val_loss: 1.3121 - val_acc: 0.9344 - val_mDice: 0.4746

Epoch 00009: val_mDice did not improve from 0.59358
Epoch 10/300
 - 18s - loss: 0.3689 - acc: 0.9411 - mDice: 0.6833 - val_loss: 0.8985 - val_acc: 0.9464 - val_mDice: 0.5919

Epoch 00010: val_mDice did not improve from 0.59358
Epoch 11/300
 - 18s - loss: 0.3350 - acc: 0.9441 - mDice: 0.7062 - val_loss: 0.9507 - val_acc: 0.9439 - val_mDice: 0.5884

Epoch 00011: val_mDice did not improve from 0.59358
Epoch 12/300
 - 19s - loss: 0.3264 - acc: 0.9452 - mDice: 0.7135 - val_loss: 0.9328 - val_acc: 0.9458 - val_mDice: 0.5958

Epoch 00012: val_mDice improved from 0.59358 to 0.59578, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 18s - loss: 0.3220 - acc: 0.9458 - mDice: 0.7190 - val_loss: 0.8808 - val_acc: 0.9416 - val_mDice: 0.5774

Epoch 00013: val_mDice did not improve from 0.59578
Epoch 14/300
 - 18s - loss: 0.3057 - acc: 0.9471 - mDice: 0.7289 - val_loss: 1.2065 - val_acc: 0.9476 - val_mDice: 0.5706

Epoch 00014: val_mDice did not improve from 0.59578
Epoch 15/300
 - 18s - loss: 0.3239 - acc: 0.9452 - mDice: 0.7159 - val_loss: 0.8000 - val_acc: 0.9476 - val_mDice: 0.6019

Epoch 00015: val_mDice improved from 0.59578 to 0.60191, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 18s - loss: 0.3037 - acc: 0.9467 - mDice: 0.7267 - val_loss: 1.0020 - val_acc: 0.9467 - val_mDice: 0.5500

Epoch 00016: val_mDice did not improve from 0.60191
Epoch 17/300
 - 18s - loss: 0.3121 - acc: 0.9461 - mDice: 0.7219 - val_loss: 0.9494 - val_acc: 0.9445 - val_mDice: 0.5900

Epoch 00017: val_mDice did not improve from 0.60191
Epoch 18/300
 - 19s - loss: 0.2974 - acc: 0.9478 - mDice: 0.7343 - val_loss: 1.1534 - val_acc: 0.9459 - val_mDice: 0.5811

Epoch 00018: val_mDice did not improve from 0.60191
Epoch 19/300
 - 18s - loss: 0.2973 - acc: 0.9482 - mDice: 0.7382 - val_loss: 1.0795 - val_acc: 0.9467 - val_mDice: 0.5960

Epoch 00019: val_mDice did not improve from 0.60191
Epoch 20/300
 - 18s - loss: 0.2721 - acc: 0.9494 - mDice: 0.7499 - val_loss: 0.8664 - val_acc: 0.9475 - val_mDice: 0.5868

Epoch 00020: val_mDice did not improve from 0.60191
Epoch 21/300
 - 18s - loss: 0.2721 - acc: 0.9496 - mDice: 0.7507 - val_loss: 0.9107 - val_acc: 0.9489 - val_mDice: 0.5890

Epoch 00021: val_mDice did not improve from 0.60191
Epoch 22/300
 - 18s - loss: 0.2741 - acc: 0.9498 - mDice: 0.7524 - val_loss: 0.9478 - val_acc: 0.9455 - val_mDice: 0.5808

Epoch 00022: val_mDice did not improve from 0.60191
Epoch 23/300
 - 19s - loss: 0.2784 - acc: 0.9494 - mDice: 0.7499 - val_loss: 0.9102 - val_acc: 0.9476 - val_mDice: 0.5887

Epoch 00023: val_mDice did not improve from 0.60191
Epoch 24/300
 - 18s - loss: 0.2869 - acc: 0.9482 - mDice: 0.7401 - val_loss: 0.9631 - val_acc: 0.9469 - val_mDice: 0.5949

Epoch 00024: val_mDice did not improve from 0.60191
Epoch 25/300
 - 18s - loss: 0.2732 - acc: 0.9495 - mDice: 0.7524 - val_loss: 1.0229 - val_acc: 0.9480 - val_mDice: 0.5831

Epoch 00025: val_mDice did not improve from 0.60191
Epoch 26/300
 - 18s - loss: 0.2555 - acc: 0.9509 - mDice: 0.7628 - val_loss: 0.9538 - val_acc: 0.9470 - val_mDice: 0.5939

Epoch 00026: val_mDice did not improve from 0.60191
Epoch 27/300
 - 18s - loss: 0.2697 - acc: 0.9499 - mDice: 0.7540 - val_loss: 0.8783 - val_acc: 0.9462 - val_mDice: 0.5936

Epoch 00027: val_mDice did not improve from 0.60191
Epoch 28/300
 - 18s - loss: 0.2785 - acc: 0.9495 - mDice: 0.7504 - val_loss: 0.8405 - val_acc: 0.9444 - val_mDice: 0.5745

Epoch 00028: val_mDice did not improve from 0.60191
Epoch 29/300
 - 19s - loss: 0.3026 - acc: 0.9480 - mDice: 0.7331 - val_loss: 1.0732 - val_acc: 0.9464 - val_mDice: 0.5679

Epoch 00029: val_mDice did not improve from 0.60191
Epoch 30/300
 - 18s - loss: 0.2695 - acc: 0.9504 - mDice: 0.7576 - val_loss: 1.1345 - val_acc: 0.9475 - val_mDice: 0.5844

Epoch 00030: val_mDice did not improve from 0.60191
Epoch 31/300
 - 18s - loss: 0.2508 - acc: 0.9515 - mDice: 0.7682 - val_loss: 0.8969 - val_acc: 0.9479 - val_mDice: 0.5914

Epoch 00031: val_mDice did not improve from 0.60191
Epoch 32/300
 - 18s - loss: 0.2421 - acc: 0.9520 - mDice: 0.7736 - val_loss: 1.1588 - val_acc: 0.9471 - val_mDice: 0.5874

Epoch 00032: val_mDice did not improve from 0.60191
Epoch 33/300
 - 18s - loss: 0.2380 - acc: 0.9525 - mDice: 0.7776 - val_loss: 1.2156 - val_acc: 0.9475 - val_mDice: 0.5798

Epoch 00033: val_mDice did not improve from 0.60191
Epoch 34/300
 - 19s - loss: 0.2525 - acc: 0.9523 - mDice: 0.7746 - val_loss: 1.0406 - val_acc: 0.9476 - val_mDice: 0.5765

Epoch 00034: val_mDice did not improve from 0.60191
Epoch 35/300
 - 19s - loss: 0.2334 - acc: 0.9529 - mDice: 0.7804 - val_loss: 1.0463 - val_acc: 0.9474 - val_mDice: 0.5857

Epoch 00035: val_mDice did not improve from 0.60191
Epoch 36/300
 - 20s - loss: 0.2504 - acc: 0.9520 - mDice: 0.7703 - val_loss: 1.0519 - val_acc: 0.9476 - val_mDice: 0.5848

Epoch 00036: val_mDice did not improve from 0.60191
Epoch 37/300
 - 20s - loss: 0.2348 - acc: 0.9529 - mDice: 0.7796 - val_loss: 1.0920 - val_acc: 0.9472 - val_mDice: 0.5807

Epoch 00037: val_mDice did not improve from 0.60191
Epoch 38/300
 - 20s - loss: 0.2821 - acc: 0.9490 - mDice: 0.7492 - val_loss: 1.3823 - val_acc: 0.9207 - val_mDice: 0.4583

Epoch 00038: val_mDice did not improve from 0.60191
Epoch 39/300
 - 19s - loss: 0.3015 - acc: 0.9479 - mDice: 0.7379 - val_loss: 1.0982 - val_acc: 0.9456 - val_mDice: 0.5806

Epoch 00039: val_mDice did not improve from 0.60191
Epoch 40/300
 - 19s - loss: 0.2542 - acc: 0.9511 - mDice: 0.7640 - val_loss: 1.0936 - val_acc: 0.9476 - val_mDice: 0.5945

Epoch 00040: val_mDice did not improve from 0.60191
Epoch 41/300
 - 19s - loss: 0.2497 - acc: 0.9518 - mDice: 0.7704 - val_loss: 0.9274 - val_acc: 0.9475 - val_mDice: 0.5976

Epoch 00041: val_mDice did not improve from 0.60191
Epoch 42/300
 - 18s - loss: 0.2459 - acc: 0.9522 - mDice: 0.7738 - val_loss: 1.0009 - val_acc: 0.9439 - val_mDice: 0.5721

Epoch 00042: val_mDice did not improve from 0.60191
Epoch 43/300
 - 19s - loss: 0.2315 - acc: 0.9530 - mDice: 0.7820 - val_loss: 1.1925 - val_acc: 0.9485 - val_mDice: 0.5915

Epoch 00043: val_mDice did not improve from 0.60191
Epoch 44/300
 - 18s - loss: 0.2534 - acc: 0.9516 - mDice: 0.7662 - val_loss: 0.9989 - val_acc: 0.9482 - val_mDice: 0.5907

Epoch 00044: val_mDice did not improve from 0.60191
Epoch 45/300
 - 18s - loss: 0.2288 - acc: 0.9533 - mDice: 0.7840 - val_loss: 0.9989 - val_acc: 0.9461 - val_mDice: 0.5878

Epoch 00045: val_mDice did not improve from 0.60191
Epoch 46/300
 - 19s - loss: 0.2439 - acc: 0.9528 - mDice: 0.7778 - val_loss: 1.3152 - val_acc: 0.9465 - val_mDice: 0.5739

Epoch 00046: val_mDice did not improve from 0.60191
Epoch 47/300
 - 19s - loss: 0.2359 - acc: 0.9531 - mDice: 0.7814 - val_loss: 0.9698 - val_acc: 0.9473 - val_mDice: 0.5917

Epoch 00047: val_mDice did not improve from 0.60191
Epoch 48/300
 - 18s - loss: 0.2629 - acc: 0.9513 - mDice: 0.7646 - val_loss: 1.1530 - val_acc: 0.9462 - val_mDice: 0.5801

Epoch 00048: val_mDice did not improve from 0.60191
Epoch 49/300
 - 18s - loss: 0.2627 - acc: 0.9513 - mDice: 0.7639 - val_loss: 1.0126 - val_acc: 0.9475 - val_mDice: 0.5957

Epoch 00049: val_mDice did not improve from 0.60191
Epoch 50/300
 - 18s - loss: 0.2569 - acc: 0.9516 - mDice: 0.7671 - val_loss: 1.1847 - val_acc: 0.9470 - val_mDice: 0.5942

Epoch 00050: val_mDice did not improve from 0.60191
Epoch 51/300
 - 19s - loss: 0.2394 - acc: 0.9532 - mDice: 0.7824 - val_loss: 1.0529 - val_acc: 0.9478 - val_mDice: 0.5947

Epoch 00051: val_mDice did not improve from 0.60191
Epoch 52/300
 - 18s - loss: 0.2376 - acc: 0.9536 - mDice: 0.7854 - val_loss: 1.1721 - val_acc: 0.9458 - val_mDice: 0.5955

Epoch 00052: val_mDice did not improve from 0.60191
Epoch 53/300
 - 18s - loss: 0.2316 - acc: 0.9532 - mDice: 0.7825 - val_loss: 1.0189 - val_acc: 0.9463 - val_mDice: 0.5839

Epoch 00053: val_mDice did not improve from 0.60191
Epoch 54/300
 - 18s - loss: 0.2320 - acc: 0.9539 - mDice: 0.7880 - val_loss: 2.7586 - val_acc: 0.9213 - val_mDice: 0.3800

Epoch 00054: val_mDice did not improve from 0.60191
Epoch 55/300
 - 18s - loss: 0.2324 - acc: 0.9531 - mDice: 0.7815 - val_loss: 1.0716 - val_acc: 0.9477 - val_mDice: 0.5878

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:02<00:08,  2.98s/it]predicting test subjects:  50%|█████     | 2/4 [00:04<00:05,  2.69s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:07<00:02,  2.52s/it]predicting test subjects: 100%|██████████| 4/4 [00:09<00:00,  2.47s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:36,  2.85s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:17,  2.79s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:28,  2.62s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:42,  2.45s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:51,  2.49s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:16,  2.60s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:27,  2.65s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:41,  2.72s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:44,  2.74s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:50,  2.77s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:54,  2.80s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<11:48,  2.79s/it]predicting train subjects:   5%|▍         | 13/266 [00:34<11:39,  2.76s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:34,  2.76s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<11:39,  2.79s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:28,  2.75s/it]predicting train subjects:   6%|▋         | 17/266 [00:45<11:28,  2.76s/it]predicting train subjects:   7%|▋         | 18/266 [00:48<11:30,  2.78s/it]predicting train subjects:   7%|▋         | 19/266 [00:51<11:21,  2.76s/it]predicting train subjects:   8%|▊         | 20/266 [00:54<11:20,  2.77s/it]predicting train subjects:   8%|▊         | 21/266 [00:57<11:23,  2.79s/it]predicting train subjects:   8%|▊         | 22/266 [00:59<11:20,  2.79s/it]predicting train subjects:   9%|▊         | 23/266 [01:02<11:18,  2.79s/it]predicting train subjects:   9%|▉         | 24/266 [01:05<11:00,  2.73s/it]predicting train subjects:   9%|▉         | 25/266 [01:07<10:45,  2.68s/it]predicting train subjects:  10%|▉         | 26/266 [01:10<10:47,  2.70s/it]predicting train subjects:  10%|█         | 27/266 [01:13<10:30,  2.64s/it]predicting train subjects:  11%|█         | 28/266 [01:15<10:16,  2.59s/it]predicting train subjects:  11%|█         | 29/266 [01:18<10:11,  2.58s/it]predicting train subjects:  11%|█▏        | 30/266 [01:20<10:07,  2.57s/it]predicting train subjects:  12%|█▏        | 31/266 [01:23<10:03,  2.57s/it]predicting train subjects:  12%|█▏        | 32/266 [01:25<10:02,  2.58s/it]predicting train subjects:  12%|█▏        | 33/266 [01:28<09:55,  2.55s/it]predicting train subjects:  13%|█▎        | 34/266 [01:30<09:49,  2.54s/it]predicting train subjects:  13%|█▎        | 35/266 [01:33<09:49,  2.55s/it]predicting train subjects:  14%|█▎        | 36/266 [01:35<09:42,  2.53s/it]predicting train subjects:  14%|█▍        | 37/266 [01:38<09:41,  2.54s/it]predicting train subjects:  14%|█▍        | 38/266 [01:40<09:40,  2.55s/it]predicting train subjects:  15%|█▍        | 39/266 [01:43<09:37,  2.54s/it]predicting train subjects:  15%|█▌        | 40/266 [01:46<09:35,  2.55s/it]predicting train subjects:  15%|█▌        | 41/266 [01:48<09:27,  2.52s/it]predicting train subjects:  16%|█▌        | 42/266 [01:50<08:57,  2.40s/it]predicting train subjects:  16%|█▌        | 43/266 [01:52<08:33,  2.30s/it]predicting train subjects:  17%|█▋        | 44/266 [01:54<08:14,  2.23s/it]predicting train subjects:  17%|█▋        | 45/266 [01:56<08:01,  2.18s/it]predicting train subjects:  17%|█▋        | 46/266 [01:58<07:51,  2.14s/it]predicting train subjects:  18%|█▊        | 47/266 [02:01<07:52,  2.16s/it]predicting train subjects:  18%|█▊        | 48/266 [02:03<07:50,  2.16s/it]predicting train subjects:  18%|█▊        | 49/266 [02:05<07:49,  2.16s/it]predicting train subjects:  19%|█▉        | 50/266 [02:07<07:44,  2.15s/it]predicting train subjects:  19%|█▉        | 51/266 [02:09<07:44,  2.16s/it]predicting train subjects:  20%|█▉        | 52/266 [02:11<07:43,  2.17s/it]predicting train subjects:  20%|█▉        | 53/266 [02:14<07:40,  2.16s/it]predicting train subjects:  20%|██        | 54/266 [02:16<07:40,  2.17s/it]predicting train subjects:  21%|██        | 55/266 [02:18<07:44,  2.20s/it]predicting train subjects:  21%|██        | 56/266 [02:20<07:42,  2.20s/it]predicting train subjects:  21%|██▏       | 57/266 [02:22<07:37,  2.19s/it]predicting train subjects:  22%|██▏       | 58/266 [02:25<07:32,  2.18s/it]predicting train subjects:  22%|██▏       | 59/266 [02:27<07:28,  2.17s/it]predicting train subjects:  23%|██▎       | 60/266 [02:29<07:15,  2.11s/it]predicting train subjects:  23%|██▎       | 61/266 [02:31<07:07,  2.08s/it]predicting train subjects:  23%|██▎       | 62/266 [02:33<06:57,  2.05s/it]predicting train subjects:  24%|██▎       | 63/266 [02:35<06:52,  2.03s/it]predicting train subjects:  24%|██▍       | 64/266 [02:37<06:49,  2.03s/it]predicting train subjects:  24%|██▍       | 65/266 [02:39<06:46,  2.02s/it]predicting train subjects:  25%|██▍       | 66/266 [02:41<06:44,  2.02s/it]predicting train subjects:  25%|██▌       | 67/266 [02:43<06:40,  2.01s/it]predicting train subjects:  26%|██▌       | 68/266 [02:45<06:40,  2.02s/it]predicting train subjects:  26%|██▌       | 69/266 [02:47<06:40,  2.03s/it]predicting train subjects:  26%|██▋       | 70/266 [02:49<06:39,  2.04s/it]predicting train subjects:  27%|██▋       | 71/266 [02:51<06:37,  2.04s/it]predicting train subjects:  27%|██▋       | 72/266 [02:53<06:36,  2.04s/it]predicting train subjects:  27%|██▋       | 73/266 [02:55<06:30,  2.02s/it]predicting train subjects:  28%|██▊       | 74/266 [02:57<06:24,  2.00s/it]predicting train subjects:  28%|██▊       | 75/266 [02:59<06:22,  2.00s/it]predicting train subjects:  29%|██▊       | 76/266 [03:01<06:16,  1.98s/it]predicting train subjects:  29%|██▉       | 77/266 [03:03<06:13,  1.98s/it]predicting train subjects:  29%|██▉       | 78/266 [03:05<06:44,  2.15s/it]predicting train subjects:  30%|██▉       | 79/266 [03:08<07:08,  2.29s/it]predicting train subjects:  30%|███       | 80/266 [03:11<07:22,  2.38s/it]predicting train subjects:  30%|███       | 81/266 [03:13<07:31,  2.44s/it]predicting train subjects:  31%|███       | 82/266 [03:16<07:35,  2.48s/it]predicting train subjects:  31%|███       | 83/266 [03:18<07:38,  2.51s/it]predicting train subjects:  32%|███▏      | 84/266 [03:21<07:40,  2.53s/it]predicting train subjects:  32%|███▏      | 85/266 [03:23<07:42,  2.56s/it]predicting train subjects:  32%|███▏      | 86/266 [03:26<07:39,  2.55s/it]predicting train subjects:  33%|███▎      | 87/266 [03:29<07:39,  2.57s/it]predicting train subjects:  33%|███▎      | 88/266 [03:31<07:37,  2.57s/it]predicting train subjects:  33%|███▎      | 89/266 [03:34<07:35,  2.57s/it]predicting train subjects:  34%|███▍      | 90/266 [03:36<07:34,  2.58s/it]predicting train subjects:  34%|███▍      | 91/266 [03:39<07:30,  2.57s/it]predicting train subjects:  35%|███▍      | 92/266 [03:41<07:22,  2.54s/it]predicting train subjects:  35%|███▍      | 93/266 [03:44<07:17,  2.53s/it]predicting train subjects:  35%|███▌      | 94/266 [03:46<07:14,  2.52s/it]predicting train subjects:  36%|███▌      | 95/266 [03:49<07:14,  2.54s/it]predicting train subjects:  36%|███▌      | 96/266 [03:51<06:56,  2.45s/it]predicting train subjects:  36%|███▋      | 97/266 [03:54<06:57,  2.47s/it]predicting train subjects:  37%|███▋      | 98/266 [03:56<06:52,  2.46s/it]predicting train subjects:  37%|███▋      | 99/266 [03:58<06:21,  2.29s/it]predicting train subjects:  38%|███▊      | 100/266 [04:00<06:09,  2.23s/it]predicting train subjects:  38%|███▊      | 101/266 [04:02<06:10,  2.25s/it]predicting train subjects:  38%|███▊      | 102/266 [04:05<06:09,  2.25s/it]predicting train subjects:  39%|███▊      | 103/266 [04:07<06:08,  2.26s/it]predicting train subjects:  39%|███▉      | 104/266 [04:09<06:07,  2.27s/it]predicting train subjects:  39%|███▉      | 105/266 [04:11<06:03,  2.25s/it]predicting train subjects:  40%|███▉      | 106/266 [04:14<05:59,  2.25s/it]predicting train subjects:  40%|████      | 107/266 [04:16<05:59,  2.26s/it]predicting train subjects:  41%|████      | 108/266 [04:18<05:59,  2.28s/it]predicting train subjects:  41%|████      | 109/266 [04:21<05:55,  2.27s/it]predicting train subjects:  41%|████▏     | 110/266 [04:23<05:54,  2.27s/it]predicting train subjects:  42%|████▏     | 111/266 [04:25<05:53,  2.28s/it]predicting train subjects:  42%|████▏     | 112/266 [04:28<05:54,  2.30s/it]predicting train subjects:  42%|████▏     | 113/266 [04:30<05:48,  2.28s/it]predicting train subjects:  43%|████▎     | 114/266 [04:32<05:43,  2.26s/it]predicting train subjects:  43%|████▎     | 115/266 [04:34<05:43,  2.27s/it]predicting train subjects:  44%|████▎     | 116/266 [04:37<05:40,  2.27s/it]predicting train subjects:  44%|████▍     | 117/266 [04:39<05:37,  2.26s/it]predicting train subjects:  44%|████▍     | 118/266 [04:41<05:33,  2.25s/it]predicting train subjects:  45%|████▍     | 119/266 [04:44<05:45,  2.35s/it]predicting train subjects:  45%|████▌     | 120/266 [04:46<05:52,  2.41s/it]predicting train subjects:  45%|████▌     | 121/266 [04:49<05:53,  2.44s/it]predicting train subjects:  46%|████▌     | 122/266 [04:51<05:55,  2.47s/it]predicting train subjects:  46%|████▌     | 123/266 [04:54<05:57,  2.50s/it]predicting train subjects:  47%|████▋     | 124/266 [04:56<05:55,  2.51s/it]predicting train subjects:  47%|████▋     | 125/266 [04:59<05:54,  2.52s/it]predicting train subjects:  47%|████▋     | 126/266 [05:01<05:56,  2.54s/it]predicting train subjects:  48%|████▊     | 127/266 [05:04<05:59,  2.58s/it]predicting train subjects:  48%|████▊     | 128/266 [05:07<05:57,  2.59s/it]predicting train subjects:  48%|████▊     | 129/266 [05:09<05:51,  2.56s/it]predicting train subjects:  49%|████▉     | 130/266 [05:12<05:46,  2.55s/it]predicting train subjects:  49%|████▉     | 131/266 [05:14<05:46,  2.57s/it]predicting train subjects:  50%|████▉     | 132/266 [05:17<05:41,  2.55s/it]predicting train subjects:  50%|█████     | 133/266 [05:19<05:40,  2.56s/it]predicting train subjects:  50%|█████     | 134/266 [05:22<05:39,  2.57s/it]predicting train subjects:  51%|█████     | 135/266 [05:25<05:37,  2.58s/it]predicting train subjects:  51%|█████     | 136/266 [05:27<05:34,  2.57s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:30<05:26,  2.53s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:32<05:23,  2.53s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:35<05:20,  2.53s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:37<05:15,  2.50s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:40<05:11,  2.49s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:42<05:04,  2.46s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:44<05:02,  2.46s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:47<05:00,  2.46s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:49<04:56,  2.45s/it]predicting train subjects:  55%|█████▍    | 146/266 [05:52<04:54,  2.45s/it]predicting train subjects:  55%|█████▌    | 147/266 [05:54<04:50,  2.45s/it]predicting train subjects:  56%|█████▌    | 148/266 [05:57<04:49,  2.45s/it]predicting train subjects:  56%|█████▌    | 149/266 [05:59<04:59,  2.56s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:02<04:56,  2.56s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:04<04:48,  2.51s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:07<04:43,  2.49s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:09<04:41,  2.49s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:12<04:38,  2.48s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:14<04:13,  2.29s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:16<03:58,  2.17s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:17<03:46,  2.08s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:19<03:36,  2.00s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:21<03:29,  1.96s/it]predicting train subjects:  60%|██████    | 160/266 [06:23<03:28,  1.97s/it]predicting train subjects:  61%|██████    | 161/266 [06:25<03:23,  1.94s/it]predicting train subjects:  61%|██████    | 162/266 [06:27<03:18,  1.91s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:29<03:14,  1.89s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:30<03:12,  1.89s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:32<03:10,  1.88s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:34<03:08,  1.88s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:36<03:06,  1.88s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:38<03:04,  1.88s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:40<03:02,  1.88s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:42<03:05,  1.93s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:44<03:04,  1.94s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:46<03:01,  1.93s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:48<03:05,  1.99s/it]predicting train subjects:  65%|██████▌   | 174/266 [06:50<03:05,  2.02s/it]predicting train subjects:  66%|██████▌   | 175/266 [06:52<03:06,  2.05s/it]predicting train subjects:  66%|██████▌   | 176/266 [06:54<03:04,  2.05s/it]predicting train subjects:  67%|██████▋   | 177/266 [06:56<03:05,  2.08s/it]predicting train subjects:  67%|██████▋   | 178/266 [06:58<03:01,  2.06s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:00<02:58,  2.05s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:02<02:56,  2.06s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:05<02:54,  2.06s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:07<02:53,  2.07s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:09<02:53,  2.09s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:11<02:48,  2.05s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:13<02:45,  2.04s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:15<02:44,  2.05s/it]predicting train subjects:  70%|███████   | 187/266 [07:17<02:43,  2.07s/it]predicting train subjects:  71%|███████   | 188/266 [07:19<02:40,  2.05s/it]predicting train subjects:  71%|███████   | 189/266 [07:21<02:36,  2.04s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:23<02:36,  2.05s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:25<02:39,  2.13s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:27<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:29<02:31,  2.08s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:32<02:40,  2.23s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:34<02:37,  2.22s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:37<02:39,  2.28s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:39<02:35,  2.25s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:41<02:33,  2.25s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:43<02:28,  2.22s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:45<02:25,  2.21s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:48<02:23,  2.21s/it]predicting train subjects:  76%|███████▌  | 202/266 [07:50<02:21,  2.21s/it]predicting train subjects:  76%|███████▋  | 203/266 [07:52<02:18,  2.20s/it]predicting train subjects:  77%|███████▋  | 204/266 [07:54<02:15,  2.19s/it]predicting train subjects:  77%|███████▋  | 205/266 [07:56<02:14,  2.20s/it]predicting train subjects:  77%|███████▋  | 206/266 [07:59<02:11,  2.20s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:01<02:09,  2.20s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:03<02:07,  2.20s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:05<02:05,  2.20s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:07<02:02,  2.19s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:09<02:00,  2.18s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:12<01:59,  2.21s/it]predicting train subjects:  80%|████████  | 213/266 [08:14<01:54,  2.15s/it]predicting train subjects:  80%|████████  | 214/266 [08:16<01:49,  2.10s/it]predicting train subjects:  81%|████████  | 215/266 [08:18<01:44,  2.04s/it]predicting train subjects:  81%|████████  | 216/266 [08:20<01:41,  2.02s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:22<01:38,  2.00s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:24<01:36,  2.00s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:26<01:34,  2.01s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:28<01:32,  2.00s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:30<01:29,  1.98s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:32<01:27,  1.98s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:33<01:24,  1.96s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:35<01:22,  1.96s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:37<01:19,  1.94s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:39<01:17,  1.95s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:41<01:15,  1.94s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:43<01:14,  1.97s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:45<01:14,  2.01s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:47<01:12,  2.02s/it]predicting train subjects:  87%|████████▋ | 231/266 [08:49<01:11,  2.04s/it]predicting train subjects:  87%|████████▋ | 232/266 [08:52<01:13,  2.17s/it]predicting train subjects:  88%|████████▊ | 233/266 [08:54<01:11,  2.17s/it]predicting train subjects:  88%|████████▊ | 234/266 [08:56<01:08,  2.16s/it]predicting train subjects:  88%|████████▊ | 235/266 [08:58<01:06,  2.14s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:00<01:03,  2.10s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:02<01:00,  2.07s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:04<00:57,  2.05s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:06<00:55,  2.04s/it]predicting train subjects:  90%|█████████ | 240/266 [09:09<00:54,  2.08s/it]predicting train subjects:  91%|█████████ | 241/266 [09:11<00:51,  2.06s/it]predicting train subjects:  91%|█████████ | 242/266 [09:13<00:49,  2.07s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:15<00:47,  2.06s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:17<00:45,  2.07s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:19<00:43,  2.07s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:21<00:41,  2.07s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:23<00:39,  2.08s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:25<00:38,  2.11s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:28<00:38,  2.27s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:31<00:38,  2.40s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:33<00:36,  2.46s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:36<00:34,  2.49s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:38<00:32,  2.52s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:41<00:30,  2.58s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:44<00:28,  2.59s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:46<00:25,  2.58s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:49<00:23,  2.57s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:51<00:20,  2.60s/it]predicting train subjects:  97%|█████████▋| 259/266 [09:54<00:18,  2.63s/it]predicting train subjects:  98%|█████████▊| 260/266 [09:57<00:15,  2.65s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:00<00:13,  2.67s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:02<00:10,  2.68s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:05<00:07,  2.65s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:07<00:05,  2.63s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:10<00:02,  2.61s/it]predicting train subjects: 100%|██████████| 266/266 [10:13<00:00,  2.62s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:39,  1.73s/it]Loading train:   1%|          | 2/266 [00:03<07:32,  1.71s/it]Loading train:   1%|          | 3/266 [00:04<07:07,  1.63s/it]Loading train:   2%|▏         | 4/266 [00:06<06:38,  1.52s/it]Loading train:   2%|▏         | 5/266 [00:07<06:44,  1.55s/it]Loading train:   2%|▏         | 6/266 [00:09<06:24,  1.48s/it]Loading train:   3%|▎         | 7/266 [00:10<06:01,  1.39s/it]Loading train:   3%|▎         | 8/266 [00:11<05:41,  1.33s/it]Loading train:   3%|▎         | 9/266 [00:12<05:32,  1.29s/it]Loading train:   4%|▍         | 10/266 [00:13<05:32,  1.30s/it]Loading train:   4%|▍         | 11/266 [00:15<05:14,  1.23s/it]Loading train:   5%|▍         | 12/266 [00:16<05:07,  1.21s/it]Loading train:   5%|▍         | 13/266 [00:17<05:01,  1.19s/it]Loading train:   5%|▌         | 14/266 [00:18<04:48,  1.14s/it]Loading train:   6%|▌         | 15/266 [00:19<04:45,  1.14s/it]Loading train:   6%|▌         | 16/266 [00:20<04:42,  1.13s/it]Loading train:   6%|▋         | 17/266 [00:21<04:43,  1.14s/it]Loading train:   7%|▋         | 18/266 [00:22<04:44,  1.15s/it]Loading train:   7%|▋         | 19/266 [00:23<04:34,  1.11s/it]Loading train:   8%|▊         | 20/266 [00:25<04:32,  1.11s/it]Loading train:   8%|▊         | 21/266 [00:26<04:32,  1.11s/it]Loading train:   8%|▊         | 22/266 [00:27<04:25,  1.09s/it]Loading train:   9%|▊         | 23/266 [00:28<04:14,  1.05s/it]Loading train:   9%|▉         | 24/266 [00:29<04:25,  1.10s/it]Loading train:   9%|▉         | 25/266 [00:30<04:28,  1.11s/it]Loading train:  10%|▉         | 26/266 [00:31<04:36,  1.15s/it]Loading train:  10%|█         | 27/266 [00:32<04:35,  1.15s/it]Loading train:  11%|█         | 28/266 [00:34<04:33,  1.15s/it]Loading train:  11%|█         | 29/266 [00:35<04:31,  1.15s/it]Loading train:  11%|█▏        | 30/266 [00:36<04:28,  1.14s/it]Loading train:  12%|█▏        | 31/266 [00:37<04:48,  1.23s/it]Loading train:  12%|█▏        | 32/266 [00:38<04:46,  1.22s/it]Loading train:  12%|█▏        | 33/266 [00:40<04:39,  1.20s/it]Loading train:  13%|█▎        | 34/266 [00:41<04:29,  1.16s/it]Loading train:  13%|█▎        | 35/266 [00:42<04:18,  1.12s/it]Loading train:  14%|█▎        | 36/266 [00:43<04:28,  1.17s/it]Loading train:  14%|█▍        | 37/266 [00:44<04:27,  1.17s/it]Loading train:  14%|█▍        | 38/266 [00:45<04:29,  1.18s/it]Loading train:  15%|█▍        | 39/266 [00:47<04:32,  1.20s/it]Loading train:  15%|█▌        | 40/266 [00:48<04:32,  1.20s/it]Loading train:  15%|█▌        | 41/266 [00:49<04:26,  1.18s/it]Loading train:  16%|█▌        | 42/266 [00:50<04:24,  1.18s/it]Loading train:  16%|█▌        | 43/266 [00:51<04:14,  1.14s/it]Loading train:  17%|█▋        | 44/266 [00:52<03:54,  1.06s/it]Loading train:  17%|█▋        | 45/266 [00:53<03:53,  1.06s/it]Loading train:  17%|█▋        | 46/266 [00:54<04:05,  1.12s/it]Loading train:  18%|█▊        | 47/266 [00:56<04:15,  1.16s/it]Loading train:  18%|█▊        | 48/266 [00:57<04:09,  1.14s/it]Loading train:  18%|█▊        | 49/266 [00:58<03:54,  1.08s/it]Loading train:  19%|█▉        | 50/266 [00:59<03:52,  1.08s/it]Loading train:  19%|█▉        | 51/266 [01:00<03:39,  1.02s/it]Loading train:  20%|█▉        | 52/266 [01:01<03:39,  1.03s/it]Loading train:  20%|█▉        | 53/266 [01:02<03:40,  1.03s/it]Loading train:  20%|██        | 54/266 [01:03<03:41,  1.04s/it]Loading train:  21%|██        | 55/266 [01:04<03:42,  1.05s/it]Loading train:  21%|██        | 56/266 [01:05<03:38,  1.04s/it]Loading train:  21%|██▏       | 57/266 [01:06<03:47,  1.09s/it]Loading train:  22%|██▏       | 58/266 [01:07<03:38,  1.05s/it]Loading train:  22%|██▏       | 59/266 [01:08<03:39,  1.06s/it]Loading train:  23%|██▎       | 60/266 [01:09<03:32,  1.03s/it]Loading train:  23%|██▎       | 61/266 [01:10<03:25,  1.00s/it]Loading train:  23%|██▎       | 62/266 [01:11<03:25,  1.01s/it]Loading train:  24%|██▎       | 63/266 [01:12<03:21,  1.01it/s]Loading train:  24%|██▍       | 64/266 [01:13<03:25,  1.02s/it]Loading train:  24%|██▍       | 65/266 [01:14<03:17,  1.02it/s]Loading train:  25%|██▍       | 66/266 [01:15<03:17,  1.01it/s]Loading train:  25%|██▌       | 67/266 [01:16<03:03,  1.08it/s]Loading train:  26%|██▌       | 68/266 [01:17<03:07,  1.06it/s]Loading train:  26%|██▌       | 69/266 [01:18<03:13,  1.02it/s]Loading train:  26%|██▋       | 70/266 [01:19<03:08,  1.04it/s]Loading train:  27%|██▋       | 71/266 [01:20<03:10,  1.02it/s]Loading train:  27%|██▋       | 72/266 [01:21<03:16,  1.01s/it]Loading train:  27%|██▋       | 73/266 [01:22<03:19,  1.03s/it]Loading train:  28%|██▊       | 74/266 [01:23<03:17,  1.03s/it]Loading train:  28%|██▊       | 75/266 [01:24<03:18,  1.04s/it]Loading train:  29%|██▊       | 76/266 [01:25<03:07,  1.01it/s]Loading train:  29%|██▉       | 77/266 [01:26<03:09,  1.00s/it]Loading train:  29%|██▉       | 78/266 [01:27<03:34,  1.14s/it]Loading train:  30%|██▉       | 79/266 [01:29<03:35,  1.15s/it]Loading train:  30%|███       | 80/266 [01:30<03:26,  1.11s/it]Loading train:  30%|███       | 81/266 [01:31<03:34,  1.16s/it]Loading train:  31%|███       | 82/266 [01:32<03:35,  1.17s/it]Loading train:  31%|███       | 83/266 [01:33<03:33,  1.17s/it]Loading train:  32%|███▏      | 84/266 [01:34<03:41,  1.22s/it]Loading train:  32%|███▏      | 85/266 [01:36<03:37,  1.20s/it]Loading train:  32%|███▏      | 86/266 [01:37<03:32,  1.18s/it]Loading train:  33%|███▎      | 87/266 [01:38<03:32,  1.19s/it]Loading train:  33%|███▎      | 88/266 [01:39<03:35,  1.21s/it]Loading train:  33%|███▎      | 89/266 [01:40<03:32,  1.20s/it]Loading train:  34%|███▍      | 90/266 [01:41<03:23,  1.16s/it]Loading train:  34%|███▍      | 91/266 [01:43<03:29,  1.20s/it]Loading train:  35%|███▍      | 92/266 [01:44<03:32,  1.22s/it]Loading train:  35%|███▍      | 93/266 [01:45<03:31,  1.22s/it]Loading train:  35%|███▌      | 94/266 [01:46<03:30,  1.22s/it]Loading train:  36%|███▌      | 95/266 [01:48<03:34,  1.26s/it]Loading train:  36%|███▌      | 96/266 [01:49<03:43,  1.31s/it]Loading train:  36%|███▋      | 97/266 [01:51<04:08,  1.47s/it]Loading train:  37%|███▋      | 98/266 [01:53<04:18,  1.54s/it]
Epoch 00055: val_mDice did not improve from 0.60191
Restoring model weights from the end of the best epoch
Epoch 00055: early stopping
{'val_loss': [0.9902428789299076, 0.8948501361017468, 0.724765029274115, 0.8559171572452834, 0.9258982494097798, 0.7170173681082845, 0.815148906046603, 0.8694990442580536, 1.3121462399218262, 0.8985414630224725, 0.9507409830053314, 0.9328091259764022, 0.8808016098347031, 1.2065426469350062, 0.8000017564837673, 1.0020303548384113, 0.9494250922643838, 1.153445449947309, 1.0795229846189003, 0.8664348070361033, 0.9107128228960919, 0.9478363394737244, 0.9101875216520133, 0.9631467812201556, 1.0228769283334749, 0.9537648588669401, 0.8782744004445917, 0.8404690836157117, 1.0732170273275936, 1.1345209063602095, 0.8969299402557501, 1.1587567815259725, 1.2155509723835634, 1.0405703046742607, 1.0463339160470402, 1.0519364027916884, 1.0920127585154622, 1.3823008356975908, 1.0981617377084845, 1.0935756155923635, 0.9273843840390694, 1.0008756227853919, 1.192529414882179, 0.9989312303667309, 0.9989090732165745, 1.3152121603488922, 0.9697738457627657, 1.1529993399852465, 1.0126259912963675, 1.18474470191643, 1.0529456416598888, 1.1721470929494424, 1.0189084383119054, 2.758587564740862, 1.0715981283608604], 'val_acc': [0.9151735155522323, 0.9351500262733267, 0.9432419648691386, 0.942208372244314, 0.9434944681760644, 0.9421410510519973, 0.9458377140910685, 0.9455178725619277, 0.9343857865373627, 0.9463679630215428, 0.9439388708908016, 0.9458292928062567, 0.9416494930491728, 0.9476422607397833, 0.947580002436117, 0.9467399981843323, 0.9445465672917727, 0.9458949430650022, 0.9467046376035995, 0.9475379145445944, 0.9489384749356438, 0.9454808270230013, 0.947553053623488, 0.9469066477623307, 0.9479671646566952, 0.9470379462763041, 0.9461710082382715, 0.9444135863240025, 0.9463646091332957, 0.9475463263126982, 0.9478930765841188, 0.9471389516061094, 0.947484040961546, 0.9476035587927875, 0.9473998766987264, 0.9476153399763989, 0.9472466937634123, 0.9207033780442566, 0.9456003533691919, 0.9475665107494643, 0.9474722447515536, 0.9439102636665857, 0.9484519848302633, 0.948167491359871, 0.9460952572461938, 0.9465396639679661, 0.9472601463814744, 0.9461996405064559, 0.9475463117871966, 0.9470110159962117, 0.9477803101058767, 0.9458040399711674, 0.9462838002613613, 0.9213194776983822, 0.947711294939538], 'val_mDice': [0.515845450783978, 0.5662251029695783, 0.5800786889901682, 0.5634328497558081, 0.5822007220332363, 0.586436806105766, 0.5935845279893955, 0.5258024542772469, 0.47458867515836445, 0.5919396296268752, 0.5883908251754376, 0.5957817305035952, 0.5774065857174016, 0.5705814967636301, 0.6019102500266388, 0.550015854234455, 0.5899909920051318, 0.5810534483244439, 0.5959786978088507, 0.5868204576628548, 0.5889565308554834, 0.5807814723303338, 0.5887433045050677, 0.5949325927165376, 0.5830606813190364, 0.5938956467043451, 0.5936057612675578, 0.5745447984262675, 0.5678875230941451, 0.5844430021879052, 0.5913743602127588, 0.5874124429806942, 0.5797652792529899, 0.5764611328349394, 0.585678929040412, 0.584848519633798, 0.5806696404929922, 0.4582978141408007, 0.5806002707040611, 0.5945229615483966, 0.5976081250094566, 0.5721260940327364, 0.5914787539914876, 0.5906622800506464, 0.5877728061515743, 0.5738546282303434, 0.5916584349479996, 0.5800530449682925, 0.595678298914132, 0.5942419882582015, 0.5947485435910586, 0.5955000735130631, 0.5838675273566687, 0.38003402998467456, 0.5877626322898544], 'loss': [1.2797664547980612, 0.5432634547795364, 0.4678729354753517, 0.43208082259523634, 0.39716485377908994, 0.40649685725058926, 0.3579483183473483, 0.33922745982159536, 0.3848433059858654, 0.3689160924861572, 0.3349817857910218, 0.32636761585986285, 0.3219796463742128, 0.30574540724502397, 0.32392266300243244, 0.30372497115848196, 0.31206288300506235, 0.29740561023233336, 0.2972753942515507, 0.2720541210014839, 0.272112736975445, 0.2740790369521567, 0.2783896052497677, 0.2868631585702615, 0.27321806862610093, 0.2554978501603534, 0.2697379050003318, 0.27853666341364386, 0.3025559614427018, 0.26952961552153154, 0.2508250841457619, 0.24208539811607815, 0.2380137678662857, 0.25249970121027165, 0.2333653791926483, 0.25039480453234453, 0.23479195252887686, 0.28211696679437437, 0.30153046438037445, 0.25417721324120957, 0.24969573504246534, 0.2458927787382981, 0.23153888885318044, 0.25335206150294026, 0.22884995638390565, 0.24393392112630125, 0.23587663182275642, 0.2628549481129113, 0.2627284190361597, 0.25688485854364634, 0.2393741598024563, 0.23759701979275935, 0.231562742499876, 0.23203847021056598, 0.23244046359397869], 'acc': [0.8328317047903442, 0.8959899790617808, 0.9271778049214187, 0.9353401965747088, 0.9381224064232606, 0.9376327995327813, 0.941461154327126, 0.9431479322033421, 0.9398130435413306, 0.9410630951581845, 0.9441259162089459, 0.9452075418258792, 0.9458491375083068, 0.9470519068528531, 0.9451716752740028, 0.9466548368179466, 0.9461249479637627, 0.9477541804263387, 0.9482081872783904, 0.9493753995993919, 0.9495532868051968, 0.9497566136353504, 0.9494016134521316, 0.9481562456385731, 0.9495180234563474, 0.9509335063122735, 0.9498868772434724, 0.9495219850232783, 0.9479942162810079, 0.950424033199795, 0.95145948758807, 0.9520358182420299, 0.9524586650325387, 0.9523344824770731, 0.9529322239496426, 0.9519721934849817, 0.952862008927608, 0.948964042303483, 0.9478677902690502, 0.9510595697373883, 0.9517639452911686, 0.952246889119206, 0.9530406202837045, 0.9515881126447933, 0.9532793761269214, 0.9528157162561468, 0.9530577072142635, 0.9513158272480317, 0.9513061742580355, 0.9516317030594819, 0.9532036854241352, 0.9535974474928237, 0.9531904098764803, 0.9538838737190067, 0.9531394581283688], 'mDice': [0.380808910639884, 0.5750217703934413, 0.6209774598406556, 0.6409829224769706, 0.6632866829272832, 0.6612763677895, 0.6877237505543353, 0.7001050323799106, 0.6760264119295278, 0.683256781541466, 0.7062493742205334, 0.7134621198065734, 0.7190403596407908, 0.7288814545956079, 0.7158835835575778, 0.726715718746846, 0.7219028558362801, 0.7342547912383354, 0.7382134216378572, 0.7498828249492159, 0.7506888823894443, 0.752388616173129, 0.7499387384329986, 0.7401209776678304, 0.7523609169226568, 0.7627855858872314, 0.7540382856281057, 0.7504386258553335, 0.7331236144477857, 0.7575611569190702, 0.768202218110105, 0.7735796727698369, 0.7775857817574404, 0.7746286407437151, 0.7804266077523145, 0.7703063480681243, 0.7795526542515057, 0.7491881333422148, 0.7379109452730116, 0.7639764138600705, 0.7703796780370101, 0.77382699220509, 0.7819564332839373, 0.7661946579464747, 0.7839969195395436, 0.7778169930796356, 0.7813531356559071, 0.764550851981276, 0.7639240392597837, 0.7671050602890324, 0.7824261043867338, 0.7854231052947652, 0.7825343415308978, 0.7880371733597729, 0.7814659309233518]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label valuesLoading train:  37%|███▋      | 99/266 [01:54<03:58,  1.43s/it]Loading train:  38%|███▊      | 100/266 [01:55<03:55,  1.42s/it]Loading train:  38%|███▊      | 101/266 [01:56<03:30,  1.27s/it]Loading train:  38%|███▊      | 102/266 [01:57<03:08,  1.15s/it]Loading train:  39%|███▊      | 103/266 [01:58<02:54,  1.07s/it]Loading train:  39%|███▉      | 104/266 [01:59<02:54,  1.08s/it]Loading train:  39%|███▉      | 105/266 [02:00<02:47,  1.04s/it]Loading train:  40%|███▉      | 106/266 [02:01<02:46,  1.04s/it]Loading train:  40%|████      | 107/266 [02:02<02:43,  1.03s/it]Loading train:  41%|████      | 108/266 [02:03<02:50,  1.08s/it]Loading train:  41%|████      | 109/266 [02:04<02:48,  1.07s/it]Loading train:  41%|████▏     | 110/266 [02:05<02:47,  1.07s/it]Loading train:  42%|████▏     | 111/266 [02:07<02:43,  1.06s/it]Loading train:  42%|████▏     | 112/266 [02:08<02:42,  1.06s/it]Loading train:  42%|████▏     | 113/266 [02:08<02:36,  1.02s/it]Loading train:  43%|████▎     | 114/266 [02:10<02:34,  1.01s/it]Loading train:  43%|████▎     | 115/266 [02:11<02:33,  1.01s/it]Loading train:  44%|████▎     | 116/266 [02:11<02:25,  1.03it/s]Loading train:  44%|████▍     | 117/266 [02:12<02:24,  1.03it/s]Loading train:  44%|████▍     | 118/266 [02:13<02:24,  1.02it/s]Loading train:  45%|████▍     | 119/266 [02:15<02:32,  1.04s/it]Loading train:  45%|████▌     | 120/266 [02:16<02:39,  1.09s/it]Loading train:  45%|████▌     | 121/266 [02:17<02:34,  1.06s/it]Loading train:  46%|████▌     | 122/266 [02:18<02:40,  1.11s/it]Loading train:  46%|████▌     | 123/266 [02:19<02:38,  1.11s/it]Loading train:  47%|████▋     | 124/266 [02:20<02:38,  1.12s/it]Loading train:  47%|████▋     | 125/266 [02:21<02:35,  1.11s/it]Loading train:  47%|████▋     | 126/266 [02:22<02:36,  1.12s/it]Loading train:  48%|████▊     | 127/266 [02:24<02:38,  1.14s/it]Loading train:  48%|████▊     | 128/266 [02:25<02:41,  1.17s/it]Loading train:  48%|████▊     | 129/266 [02:26<02:36,  1.14s/it]Loading train:  49%|████▉     | 130/266 [02:27<02:38,  1.16s/it]Loading train:  49%|████▉     | 131/266 [02:28<02:39,  1.18s/it]Loading train:  50%|████▉     | 132/266 [02:29<02:32,  1.14s/it]Loading train:  50%|█████     | 133/266 [02:31<02:34,  1.16s/it]Loading train:  50%|█████     | 134/266 [02:32<02:30,  1.14s/it]Loading train:  51%|█████     | 135/266 [02:33<02:32,  1.17s/it]Loading train:  51%|█████     | 136/266 [02:34<02:31,  1.17s/it]Loading train:  52%|█████▏    | 137/266 [02:35<02:32,  1.18s/it]Loading train:  52%|█████▏    | 138/266 [02:36<02:26,  1.15s/it]Loading train:  52%|█████▏    | 139/266 [02:38<02:26,  1.15s/it]Loading train:  53%|█████▎    | 140/266 [02:39<02:31,  1.20s/it]Loading train:  53%|█████▎    | 141/266 [02:40<02:32,  1.22s/it]Loading train:  53%|█████▎    | 142/266 [02:41<02:35,  1.26s/it]Loading train:  54%|█████▍    | 143/266 [02:42<02:25,  1.18s/it]Loading train:  54%|█████▍    | 144/266 [02:44<02:23,  1.17s/it]Loading train:  55%|█████▍    | 145/266 [02:45<02:21,  1.17s/it]Loading train:  55%|█████▍    | 146/266 [02:46<02:31,  1.26s/it]Loading train:  55%|█████▌    | 147/266 [02:48<02:32,  1.28s/it]Loading train:  56%|█████▌    | 148/266 [02:49<02:28,  1.26s/it]Loading train:  56%|█████▌    | 149/266 [02:50<02:20,  1.20s/it]Loading train:  56%|█████▋    | 150/266 [02:51<02:21,  1.22s/it]Loading train:  57%|█████▋    | 151/266 [02:52<02:16,  1.19s/it]Loading train:  57%|█████▋    | 152/266 [02:53<02:11,  1.16s/it]Loading train:  58%|█████▊    | 153/266 [02:55<02:10,  1.16s/it]Loading train:  58%|█████▊    | 154/266 [02:56<02:08,  1.15s/it]Loading train:  58%|█████▊    | 155/266 [02:57<02:03,  1.12s/it]Loading train:  59%|█████▊    | 156/266 [02:58<01:58,  1.08s/it]Loading train:  59%|█████▉    | 157/266 [02:59<01:56,  1.06s/it]Loading train:  59%|█████▉    | 158/266 [03:00<01:57,  1.09s/it]Loading train:  60%|█████▉    | 159/266 [03:01<01:52,  1.05s/it]Loading train:  60%|██████    | 160/266 [03:02<01:48,  1.02s/it]Loading train:  61%|██████    | 161/266 [03:03<01:46,  1.01s/it]Loading train:  61%|██████    | 162/266 [03:04<01:39,  1.04it/s]Loading train:  61%|██████▏   | 163/266 [03:05<01:43,  1.01s/it]Loading train:  62%|██████▏   | 164/266 [03:06<01:45,  1.03s/it]Loading train:  62%|██████▏   | 165/266 [03:07<01:39,  1.01it/s]Loading train:  62%|██████▏   | 166/266 [03:08<01:39,  1.00it/s]Loading train:  63%|██████▎   | 167/266 [03:09<01:37,  1.02it/s]Loading train:  63%|██████▎   | 168/266 [03:10<01:39,  1.01s/it]Loading train:  64%|██████▎   | 169/266 [03:11<01:35,  1.02it/s]Loading train:  64%|██████▍   | 170/266 [03:12<01:34,  1.02it/s]Loading train:  64%|██████▍   | 171/266 [03:13<01:33,  1.01it/s]Loading train:  65%|██████▍   | 172/266 [03:14<01:34,  1.00s/it]Loading train:  65%|██████▌   | 173/266 [03:15<01:33,  1.00s/it]Loading train:  65%|██████▌   | 174/266 [03:16<01:34,  1.02s/it]Loading train:  66%|██████▌   | 175/266 [03:17<01:31,  1.01s/it]Loading train:  66%|██████▌   | 176/266 [03:18<01:25,  1.05it/s]Loading train:  67%|██████▋   | 177/266 [03:18<01:24,  1.05it/s]Loading train:  67%|██████▋   | 178/266 [03:20<01:30,  1.02s/it]Loading train:  67%|██████▋   | 179/266 [03:21<01:24,  1.03it/s]Loading train:  68%|██████▊   | 180/266 [03:22<01:27,  1.02s/it]Loading train:  68%|██████▊   | 181/266 [03:23<01:26,  1.02s/it]Loading train:  68%|██████▊   | 182/266 [03:24<01:26,  1.03s/it]Loading train:  69%|██████▉   | 183/266 [03:25<01:25,  1.03s/it]Loading train:  69%|██████▉   | 184/266 [03:26<01:23,  1.02s/it]Loading train:  70%|██████▉   | 185/266 [03:27<01:25,  1.06s/it]Loading train:  70%|██████▉   | 186/266 [03:28<01:25,  1.07s/it]Loading train:  70%|███████   | 187/266 [03:29<01:21,  1.03s/it]Loading train:  71%|███████   | 188/266 [03:30<01:26,  1.11s/it]Loading train:  71%|███████   | 189/266 [03:31<01:23,  1.09s/it]Loading train:  71%|███████▏  | 190/266 [03:32<01:21,  1.07s/it]Loading train:  72%|███████▏  | 191/266 [03:34<01:29,  1.19s/it]Loading train:  72%|███████▏  | 192/266 [03:35<01:31,  1.24s/it]Loading train:  73%|███████▎  | 193/266 [03:36<01:33,  1.28s/it]Loading train:  73%|███████▎  | 194/266 [03:38<01:40,  1.40s/it]Loading train:  73%|███████▎  | 195/266 [03:39<01:34,  1.34s/it]Loading train:  74%|███████▎  | 196/266 [03:40<01:26,  1.24s/it]Loading train:  74%|███████▍  | 197/266 [03:42<01:29,  1.30s/it]Loading train:  74%|███████▍  | 198/266 [03:43<01:22,  1.22s/it]Loading train:  75%|███████▍  | 199/266 [03:44<01:17,  1.15s/it]Loading train:  75%|███████▌  | 200/266 [03:45<01:13,  1.11s/it]Loading train:  76%|███████▌  | 201/266 [03:46<01:09,  1.07s/it]Loading train:  76%|███████▌  | 202/266 [03:47<01:07,  1.06s/it]Loading train:  76%|███████▋  | 203/266 [03:48<01:06,  1.05s/it]Loading train:  77%|███████▋  | 204/266 [03:49<01:08,  1.10s/it]Loading train:  77%|███████▋  | 205/266 [03:50<01:11,  1.17s/it]Loading train:  77%|███████▋  | 206/266 [03:51<01:05,  1.09s/it]Loading train:  78%|███████▊  | 207/266 [03:52<01:01,  1.05s/it]Loading train:  78%|███████▊  | 208/266 [03:53<01:00,  1.04s/it]Loading train:  79%|███████▊  | 209/266 [03:54<00:59,  1.05s/it]Loading train:  79%|███████▉  | 210/266 [03:55<00:59,  1.06s/it]Loading train:  79%|███████▉  | 211/266 [03:57<00:58,  1.06s/it]Loading train:  80%|███████▉  | 212/266 [03:58<00:56,  1.05s/it]Loading train:  80%|████████  | 213/266 [03:59<00:55,  1.06s/it]Loading train:  80%|████████  | 214/266 [04:00<00:53,  1.03s/it]Loading train:  81%|████████  | 215/266 [04:01<00:52,  1.02s/it]Loading train:  81%|████████  | 216/266 [04:02<00:49,  1.01it/s]Loading train:  82%|████████▏ | 217/266 [04:02<00:46,  1.04it/s]Loading train:  82%|████████▏ | 218/266 [04:03<00:47,  1.00it/s]Loading train:  82%|████████▏ | 219/266 [04:05<00:47,  1.00s/it]Loading train:  83%|████████▎ | 220/266 [04:06<00:46,  1.00s/it]Loading train:  83%|████████▎ | 221/266 [04:06<00:44,  1.00it/s]Loading train:  83%|████████▎ | 222/266 [04:08<00:44,  1.02s/it]Loading train:  84%|████████▍ | 223/266 [04:09<00:45,  1.07s/it]Loading train:  84%|████████▍ | 224/266 [04:10<00:45,  1.08s/it]Loading train:  85%|████████▍ | 225/266 [04:11<00:43,  1.07s/it]Loading train:  85%|████████▍ | 226/266 [04:12<00:41,  1.05s/it]Loading train:  85%|████████▌ | 227/266 [04:13<00:40,  1.05s/it]Loading train:  86%|████████▌ | 228/266 [04:14<00:39,  1.03s/it]Loading train:  86%|████████▌ | 229/266 [04:15<00:38,  1.03s/it]Loading train:  86%|████████▋ | 230/266 [04:16<00:36,  1.02s/it]Loading train:  87%|████████▋ | 231/266 [04:17<00:34,  1.00it/s]Loading train:  87%|████████▋ | 232/266 [04:18<00:34,  1.02s/it]Loading train:  88%|████████▊ | 233/266 [04:19<00:34,  1.04s/it]Loading train:  88%|████████▊ | 234/266 [04:20<00:32,  1.02s/it]Loading train:  88%|████████▊ | 235/266 [04:21<00:31,  1.02s/it]Loading train:  89%|████████▊ | 236/266 [04:22<00:30,  1.02s/it]Loading train:  89%|████████▉ | 237/266 [04:23<00:28,  1.00it/s]Loading train:  89%|████████▉ | 238/266 [04:24<00:28,  1.01s/it]Loading train:  90%|████████▉ | 239/266 [04:25<00:27,  1.02s/it]Loading train:  90%|█████████ | 240/266 [04:26<00:26,  1.02s/it]Loading train:  91%|█████████ | 241/266 [04:27<00:25,  1.01s/it]Loading train:  91%|█████████ | 242/266 [04:28<00:25,  1.05s/it]Loading train:  91%|█████████▏| 243/266 [04:29<00:24,  1.04s/it]Loading train:  92%|█████████▏| 244/266 [04:31<00:24,  1.11s/it]Loading train:  92%|█████████▏| 245/266 [04:32<00:23,  1.14s/it]Loading train:  92%|█████████▏| 246/266 [04:33<00:22,  1.10s/it]Loading train:  93%|█████████▎| 247/266 [04:34<00:20,  1.07s/it]Loading train:  93%|█████████▎| 248/266 [04:35<00:18,  1.05s/it]Loading train:  94%|█████████▎| 249/266 [04:36<00:18,  1.10s/it]Loading train:  94%|█████████▍| 250/266 [04:37<00:17,  1.12s/it]Loading train:  94%|█████████▍| 251/266 [04:38<00:16,  1.12s/it]Loading train:  95%|█████████▍| 252/266 [04:39<00:15,  1.12s/it]Loading train:  95%|█████████▌| 253/266 [04:41<00:14,  1.11s/it]Loading train:  95%|█████████▌| 254/266 [04:42<00:13,  1.14s/it]Loading train:  96%|█████████▌| 255/266 [04:43<00:11,  1.09s/it]Loading train:  96%|█████████▌| 256/266 [04:44<00:10,  1.05s/it]Loading train:  97%|█████████▋| 257/266 [04:45<00:10,  1.17s/it]Loading train:  97%|█████████▋| 258/266 [04:47<00:10,  1.29s/it]Loading train:  97%|█████████▋| 259/266 [04:48<00:09,  1.32s/it]Loading train:  98%|█████████▊| 260/266 [04:49<00:07,  1.22s/it]Loading train:  98%|█████████▊| 261/266 [04:50<00:06,  1.26s/it]Loading train:  98%|█████████▊| 262/266 [04:52<00:04,  1.23s/it]Loading train:  99%|█████████▉| 263/266 [04:53<00:03,  1.26s/it]Loading train:  99%|█████████▉| 264/266 [04:54<00:02,  1.27s/it]Loading train: 100%|█████████▉| 265/266 [04:55<00:01,  1.26s/it]Loading train: 100%|██████████| 266/266 [04:56<00:00,  1.20s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:06, 39.55it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 43.67it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:05, 48.01it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:04, 51.15it/s]concatenating: train:  12%|█▏        | 31/266 [00:00<00:04, 55.06it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:03, 65.30it/s]concatenating: train:  21%|██        | 56/266 [00:00<00:02, 76.22it/s]concatenating: train:  26%|██▌       | 69/266 [00:00<00:02, 86.33it/s]concatenating: train:  31%|███       | 83/266 [00:00<00:01, 95.95it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:01, 103.15it/s]concatenating: train:  41%|████      | 109/266 [00:01<00:01, 108.85it/s]concatenating: train:  45%|████▌     | 121/266 [00:01<00:01, 109.52it/s]concatenating: train:  50%|█████     | 134/266 [00:01<00:01, 114.96it/s]concatenating: train:  55%|█████▌    | 147/266 [00:01<00:01, 117.76it/s]concatenating: train:  60%|██████    | 160/266 [00:01<00:00, 119.87it/s]concatenating: train:  65%|██████▌   | 173/266 [00:01<00:00, 121.37it/s]concatenating: train:  70%|██████▉   | 186/266 [00:01<00:00, 122.45it/s]concatenating: train:  75%|███████▍  | 199/266 [00:01<00:00, 123.17it/s]concatenating: train:  80%|███████▉  | 212/266 [00:01<00:00, 123.71it/s]concatenating: train:  85%|████████▍ | 225/266 [00:02<00:00, 124.10it/s]concatenating: train:  89%|████████▉ | 238/266 [00:02<00:00, 124.39it/s]concatenating: train:  94%|█████████▍| 251/266 [00:02<00:00, 124.57it/s]concatenating: train:  99%|█████████▉| 264/266 [00:02<00:00, 124.75it/s]concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 109.32it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:05,  1.84s/it]Loading test:  50%|█████     | 2/4 [00:03<00:03,  1.69s/it]Loading test:  75%|███████▌  | 3/4 [00:04<00:01,  1.53s/it]Loading test: 100%|██████████| 4/4 [00:06<00:00,  1.59s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 46.48it/s]2019-07-29 02:56:05.742054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 02:56:05.742131: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 02:56:05.742146: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 02:56:05.742155: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 02:56:05.742532: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.07it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.82it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.09it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.57it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.15it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.66it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.27it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.55it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.49it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.05it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.44it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.79it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.19it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.87it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.84it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.80it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.91it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.55it/s] min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 84, 48, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 84, 48, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 48, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 84, 48, 40)   11200       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 84, 48, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 84, 48, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 84, 48, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 84, 48, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 84, 48, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 42, 24, 80)   28880       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 42, 24, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 42, 24, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 42, 24, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 42, 24, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 42, 24, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 24, 120)  0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 21, 12, 160)  172960      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 21, 12, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 21, 12, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 21, 12, 160)  230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 21, 12, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 21, 12, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 12, 280)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 21, 12, 280)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 42, 24, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 42, 24, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 42, 24, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 42, 24, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 42, 24, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 24, 280)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 42, 24, 280)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 40)   28840       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 84, 48, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 84, 48, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 84, 48, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 84, 48, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 84, 48, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 48, 120)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 84, 48, 120)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 84, 48, 30)   32430       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 84, 48, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 84, 48, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 84, 48, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 84, 48, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 84, 48, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 84, 48, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 84, 48, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 84, 48, 150)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 84, 48, 13)   1963        concatenate_8[0][0]              
==================================================================================================
Total params: 949,913
Trainable params: 253,113
Non-trainable params: 696,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34165109e-02 3.28678971e-02 7.68570569e-02 9.54987578e-03
 2.76395151e-02 7.23110003e-03 8.44448362e-02 1.14235362e-01
 8.96973069e-02 1.36281423e-02 2.90816311e-01 1.89352958e-01
 2.63127942e-04]
Train on 10400 samples, validate on 151 samples
Epoch 1/300
 - 27s - loss: 1.4835 - acc: 0.8225 - mDice: 0.3365 - val_loss: 0.7397 - val_acc: 0.9413 - val_mDice: 0.5334

Epoch 00001: val_mDice improved from -inf to 0.53341, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 21s - loss: 0.4810 - acc: 0.9294 - mDice: 0.6074 - val_loss: 0.5804 - val_acc: 0.9341 - val_mDice: 0.5851

Epoch 00002: val_mDice improved from 0.53341 to 0.58514, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 20s - loss: 0.3962 - acc: 0.9389 - mDice: 0.6598 - val_loss: 0.5153 - val_acc: 0.9450 - val_mDice: 0.6245

Epoch 00003: val_mDice improved from 0.58514 to 0.62446, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 21s - loss: 0.3628 - acc: 0.9419 - mDice: 0.6825 - val_loss: 0.4843 - val_acc: 0.9487 - val_mDice: 0.6412

Epoch 00004: val_mDice improved from 0.62446 to 0.64120, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 21s - loss: 0.3591 - acc: 0.9427 - mDice: 0.6890 - val_loss: 0.4860 - val_acc: 0.9450 - val_mDice: 0.6344

Epoch 00005: val_mDice did not improve from 0.64120
Epoch 6/300
 - 21s - loss: 0.3401 - acc: 0.9439 - mDice: 0.6988 - val_loss: 0.5373 - val_acc: 0.9437 - val_mDice: 0.6153

Epoch 00006: val_mDice did not improve from 0.64120
Epoch 7/300
 - 21s - loss: 0.3197 - acc: 0.9455 - mDice: 0.7131 - val_loss: 0.4701 - val_acc: 0.9521 - val_mDice: 0.6484

Epoch 00007: val_mDice improved from 0.64120 to 0.64837, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 21s - loss: 0.3134 - acc: 0.9466 - mDice: 0.7218 - val_loss: 0.4787 - val_acc: 0.9512 - val_mDice: 0.6411

Epoch 00008: val_mDice did not improve from 0.64837
Epoch 9/300
 - 21s - loss: 0.3019 - acc: 0.9472 - mDice: 0.7285 - val_loss: 0.5610 - val_acc: 0.9484 - val_mDice: 0.6008

Epoch 00009: val_mDice did not improve from 0.64837
Epoch 10/300
 - 21s - loss: 0.3100 - acc: 0.9461 - mDice: 0.7205 - val_loss: 0.4898 - val_acc: 0.9497 - val_mDice: 0.6335

Epoch 00010: val_mDice did not improve from 0.64837
Epoch 11/300
 - 21s - loss: 0.2890 - acc: 0.9481 - mDice: 0.7360 - val_loss: 0.4898 - val_acc: 0.9513 - val_mDice: 0.6346

Epoch 00011: val_mDice did not improve from 0.64837
Epoch 12/300
 - 21s - loss: 0.2796 - acc: 0.9489 - mDice: 0.7432 - val_loss: 0.4791 - val_acc: 0.9490 - val_mDice: 0.6386

Epoch 00012: val_mDice did not improve from 0.64837
Epoch 13/300
 - 21s - loss: 0.2751 - acc: 0.9493 - mDice: 0.7466 - val_loss: 0.4821 - val_acc: 0.9501 - val_mDice: 0.6387

Epoch 00013: val_mDice did not improve from 0.64837
Epoch 14/300
 - 21s - loss: 0.2682 - acc: 0.9498 - mDice: 0.7520 - val_loss: 0.4736 - val_acc: 0.9510 - val_mDice: 0.6403

Epoch 00014: val_mDice did not improve from 0.64837
Epoch 15/300
 - 21s - loss: 0.2630 - acc: 0.9503 - mDice: 0.7561 - val_loss: 0.4746 - val_acc: 0.9511 - val_mDice: 0.6396

Epoch 00015: val_mDice did not improve from 0.64837
Epoch 16/300
 - 20s - loss: 0.2603 - acc: 0.9507 - mDice: 0.7581 - val_loss: 0.4887 - val_acc: 0.9503 - val_mDice: 0.6358

Epoch 00016: val_mDice did not improve from 0.64837
Epoch 17/300
 - 21s - loss: 0.2553 - acc: 0.9511 - mDice: 0.7622 - val_loss: 0.4681 - val_acc: 0.9504 - val_mDice: 0.6465

Epoch 00017: val_mDice did not improve from 0.64837
Epoch 18/300
 - 21s - loss: 0.3221 - acc: 0.9451 - mDice: 0.7219 - val_loss: 4.8322 - val_acc: 0.9151 - val_mDice: 0.2667

Epoch 00018: val_mDice did not improve from 0.64837
Epoch 19/300
 - 21s - loss: 0.3556 - acc: 0.9418 - mDice: 0.6880 - val_loss: 0.5074 - val_acc: 0.9412 - val_mDice: 0.6216

Epoch 00019: val_mDice did not improve from 0.64837
Epoch 20/300
 - 21s - loss: 0.2979 - acc: 0.9472 - mDice: 0.7294 - val_loss: 0.4943 - val_acc: 0.9459 - val_mDice: 0.6265

Epoch 00020: val_mDice did not improve from 0.64837
Epoch 21/300
 - 21s - loss: 0.2780 - acc: 0.9491 - mDice: 0.7448 - val_loss: 0.4806 - val_acc: 0.9499 - val_mDice: 0.6349

Epoch 00021: val_mDice did not improve from 0.64837
Epoch 22/300
 - 21s - loss: 0.2665 - acc: 0.9501 - mDice: 0.7533 - val_loss: 0.4659 - val_acc: 0.9514 - val_mDice: 0.6427

Epoch 00022: val_mDice did not improve from 0.64837
Epoch 23/300
 - 21s - loss: 0.2927 - acc: 0.9486 - mDice: 0.7385 - val_loss: 0.5040 - val_acc: 0.9481 - val_mDice: 0.6059

Epoch 00023: val_mDice did not improve from 0.64837
Epoch 24/300
 - 21s - loss: 0.2684 - acc: 0.9500 - mDice: 0.7517 - val_loss: 0.4763 - val_acc: 0.9500 - val_mDice: 0.6401

Epoch 00024: val_mDice did not improve from 0.64837
Epoch 25/300
 - 21s - loss: 0.2528 - acc: 0.9514 - mDice: 0.7640 - val_loss: 0.4676 - val_acc: 0.9501 - val_mDice: 0.6406

Epoch 00025: val_mDice did not improve from 0.64837
Epoch 26/300
 - 21s - loss: 0.2470 - acc: 0.9519 - mDice: 0.7687 - val_loss: 0.4668 - val_acc: 0.9494 - val_mDice: 0.6401

Epoch 00026: val_mDice did not improve from 0.64837
Epoch 27/300
 - 21s - loss: 0.2645 - acc: 0.9513 - mDice: 0.7621 - val_loss: 0.4803 - val_acc: 0.9474 - val_mDice: 0.6387

Epoch 00027: val_mDice did not improve from 0.64837
Epoch 28/300
 - 21s - loss: 0.2468 - acc: 0.9519 - mDice: 0.7690 - val_loss: 0.4763 - val_acc: 0.9496 - val_mDice: 0.6365

Epoch 00028: val_mDice did not improve from 0.64837
Epoch 29/300
 - 21s - loss: 0.2406 - acc: 0.9526 - mDice: 0.7740 - val_loss: 0.4794 - val_acc: 0.9476 - val_mDice: 0.6335

Epoch 00029: val_mDice did not improve from 0.64837
Epoch 30/300
 - 21s - loss: 0.2372 - acc: 0.9529 - mDice: 0.7767 - val_loss: 0.4789 - val_acc: 0.9509 - val_mDice: 0.6351

Epoch 00030: val_mDice did not improve from 0.64837
Epoch 31/300
 - 21s - loss: 0.2510 - acc: 0.9522 - mDice: 0.7703 - val_loss: 0.4578 - val_acc: 0.9498 - val_mDice: 0.6443

Epoch 00031: val_mDice did not improve from 0.64837
Epoch 32/300
 - 21s - loss: 0.2330 - acc: 0.9532 - mDice: 0.7801 - val_loss: 0.4599 - val_acc: 0.9513 - val_mDice: 0.6415

Epoch 00032: val_mDice did not improve from 0.64837
Epoch 33/300
 - 21s - loss: 0.2308 - acc: 0.9535 - mDice: 0.7820 - val_loss: 0.4684 - val_acc: 0.9481 - val_mDice: 0.6375

Epoch 00033: val_mDice did not improve from 0.64837
Epoch 34/300
 - 21s - loss: 0.2279 - acc: 0.9537 - mDice: 0.7844 - val_loss: 0.4678 - val_acc: 0.9485 - val_mDice: 0.6357

Epoch 00034: val_mDice did not improve from 0.64837
Epoch 35/300
 - 21s - loss: 0.2264 - acc: 0.9538 - mDice: 0.7855 - val_loss: 0.4809 - val_acc: 0.9493 - val_mDice: 0.6279

Epoch 00035: val_mDice did not improve from 0.64837
Epoch 36/300
 - 21s - loss: 0.2259 - acc: 0.9539 - mDice: 0.7861 - val_loss: 0.5215 - val_acc: 0.9445 - val_mDice: 0.6137

Epoch 00036: val_mDice did not improve from 0.64837
Epoch 37/300
 - 21s - loss: 0.2227 - acc: 0.9542 - mDice: 0.7886 - val_loss: 0.4654 - val_acc: 0.9503 - val_mDice: 0.6357

Epoch 00037: val_mDice did not improve from 0.64837
Epoch 38/300
 - 21s - loss: 0.2219 - acc: 0.9543 - mDice: 0.7893 - val_loss: 0.4793 - val_acc: 0.9482 - val_mDice: 0.6280

Epoch 00038: val_mDice did not improve from 0.64837
Epoch 39/300
 - 21s - loss: 0.2236 - acc: 0.9544 - mDice: 0.7906 - val_loss: 0.4899 - val_acc: 0.9481 - val_mDice: 0.6178

Epoch 00039: val_mDice did not improve from 0.64837
Epoch 40/300
 - 21s - loss: 0.2482 - acc: 0.9522 - mDice: 0.7715 - val_loss: 0.5072 - val_acc: 0.9443 - val_mDice: 0.6177

Epoch 00040: val_mDice did not improve from 0.64837
Epoch 41/300
 - 21s - loss: 0.2336 - acc: 0.9531 - mDice: 0.7796 - val_loss: 0.4687 - val_acc: 0.9485 - val_mDice: 0.6304

Epoch 00041: val_mDice did not improve from 0.64837
Epoch 42/300
 - 21s - loss: 0.2221 - acc: 0.9541 - mDice: 0.7890 - val_loss: 0.4552 - val_acc: 0.9496 - val_mDice: 0.6361

Epoch 00042: val_mDice did not improve from 0.64837
Epoch 43/300
 - 21s - loss: 0.2186 - acc: 0.9545 - mDice: 0.7920 - val_loss: 0.4558 - val_acc: 0.9488 - val_mDice: 0.6359

Epoch 00043: val_mDice did not improve from 0.64837
Epoch 44/300
 - 21s - loss: 0.2160 - acc: 0.9548 - mDice: 0.7942 - val_loss: 0.4718 - val_acc: 0.9493 - val_mDice: 0.6279

Epoch 00044: val_mDice did not improve from 0.64837
Epoch 45/300
 - 21s - loss: 0.2136 - acc: 0.9549 - mDice: 0.7961 - val_loss: 0.4792 - val_acc: 0.9485 - val_mDice: 0.6235

Epoch 00045: val_mDice did not improve from 0.64837
Epoch 46/300
 - 21s - loss: 0.2129 - acc: 0.9550 - mDice: 0.7968 - val_loss: 0.4777 - val_acc: 0.9504 - val_mDice: 0.6286

Epoch 00046: val_mDice did not improve from 0.64837
Epoch 47/300
 - 21s - loss: 0.2111 - acc: 0.9552 - mDice: 0.7982 - val_loss: 0.4646 - val_acc: 0.9475 - val_mDice: 0.6260

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:09,  3.26s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:05,  2.90s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:07<00:02,  2.62s/it]predicting test subjects: 100%|██████████| 4/4 [00:09<00:00,  2.58s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<13:36,  3.08s/it]predicting train subjects:   1%|          | 2/266 [00:05<13:10,  2.99s/it]predicting train subjects:   1%|          | 3/266 [00:08<12:22,  2.82s/it]predicting train subjects:   2%|▏         | 4/266 [00:10<11:36,  2.66s/it]predicting train subjects:   2%|▏         | 5/266 [00:13<12:16,  2.82s/it]predicting train subjects:   2%|▏         | 6/266 [00:17<13:19,  3.08s/it]predicting train subjects:   3%|▎         | 7/266 [00:20<13:14,  3.07s/it]predicting train subjects:   3%|▎         | 8/266 [00:23<13:16,  3.09s/it]predicting train subjects:   3%|▎         | 9/266 [00:26<13:35,  3.17s/it]predicting train subjects:   4%|▍         | 10/266 [00:30<13:50,  3.24s/it]predicting train subjects:   4%|▍         | 11/266 [00:33<13:39,  3.21s/it]predicting train subjects:   5%|▍         | 12/266 [00:36<13:37,  3.22s/it]predicting train subjects:   5%|▍         | 13/266 [00:39<13:25,  3.18s/it]predicting train subjects:   5%|▌         | 14/266 [00:43<13:33,  3.23s/it]predicting train subjects:   6%|▌         | 15/266 [00:46<13:40,  3.27s/it]predicting train subjects:   6%|▌         | 16/266 [00:50<13:50,  3.32s/it]predicting train subjects:   6%|▋         | 17/266 [00:53<13:43,  3.31s/it]predicting train subjects:   7%|▋         | 18/266 [00:56<13:44,  3.33s/it]predicting train subjects:   7%|▋         | 19/266 [01:00<13:46,  3.34s/it]predicting train subjects:   8%|▊         | 20/266 [01:03<13:42,  3.34s/it]predicting train subjects:   8%|▊         | 21/266 [01:06<13:36,  3.33s/it]predicting train subjects:   8%|▊         | 22/266 [01:10<13:41,  3.37s/it]predicting train subjects:   9%|▊         | 23/266 [01:13<13:32,  3.34s/it]predicting train subjects:   9%|▉         | 24/266 [01:16<13:13,  3.28s/it]predicting train subjects:   9%|▉         | 25/266 [01:19<12:47,  3.19s/it]predicting train subjects:  10%|▉         | 26/266 [01:22<12:46,  3.19s/it]predicting train subjects:  10%|█         | 27/266 [01:25<12:17,  3.08s/it]predicting train subjects:  11%|█         | 28/266 [01:28<12:02,  3.03s/it]predicting train subjects:  11%|█         | 29/266 [01:31<12:08,  3.07s/it]predicting train subjects:  11%|█▏        | 30/266 [01:34<11:23,  2.90s/it]predicting train subjects:  12%|█▏        | 31/266 [01:36<10:53,  2.78s/it]predicting train subjects:  12%|█▏        | 32/266 [01:39<10:39,  2.73s/it]predicting train subjects:  12%|█▏        | 33/266 [01:41<10:32,  2.72s/it]predicting train subjects:  13%|█▎        | 34/266 [01:44<10:18,  2.66s/it]predicting train subjects:  13%|█▎        | 35/266 [01:47<10:06,  2.63s/it]predicting train subjects:  14%|█▎        | 36/266 [01:49<10:07,  2.64s/it]predicting train subjects:  14%|█▍        | 37/266 [01:52<09:55,  2.60s/it]predicting train subjects:  14%|█▍        | 38/266 [01:54<09:43,  2.56s/it]predicting train subjects:  15%|█▍        | 39/266 [01:57<09:39,  2.55s/it]predicting train subjects:  15%|█▌        | 40/266 [01:59<09:51,  2.62s/it]predicting train subjects:  15%|█▌        | 41/266 [02:02<09:43,  2.59s/it]predicting train subjects:  16%|█▌        | 42/266 [02:04<09:11,  2.46s/it]predicting train subjects:  16%|█▌        | 43/266 [02:06<08:45,  2.36s/it]predicting train subjects:  17%|█▋        | 44/266 [02:08<08:26,  2.28s/it]predicting train subjects:  17%|█▋        | 45/266 [02:10<08:11,  2.23s/it]predicting train subjects:  17%|█▋        | 46/266 [02:13<08:04,  2.20s/it]predicting train subjects:  18%|█▊        | 47/266 [02:15<08:00,  2.19s/it]predicting train subjects:  18%|█▊        | 48/266 [02:17<07:55,  2.18s/it]predicting train subjects:  18%|█▊        | 49/266 [02:19<07:50,  2.17s/it]predicting train subjects:  19%|█▉        | 50/266 [02:21<07:45,  2.16s/it]predicting train subjects:  19%|█▉        | 51/266 [02:23<07:38,  2.13s/it]predicting train subjects:  20%|█▉        | 52/266 [02:26<07:45,  2.18s/it]predicting train subjects:  20%|█▉        | 53/266 [02:28<07:39,  2.16s/it]predicting train subjects:  20%|██        | 54/266 [02:30<07:31,  2.13s/it]predicting train subjects:  21%|██        | 55/266 [02:32<07:28,  2.13s/it]predicting train subjects:  21%|██        | 56/266 [02:34<07:24,  2.12s/it]predicting train subjects:  21%|██▏       | 57/266 [02:36<07:23,  2.12s/it]predicting train subjects:  22%|██▏       | 58/266 [02:38<07:22,  2.13s/it]predicting train subjects:  22%|██▏       | 59/266 [02:40<07:18,  2.12s/it]predicting train subjects:  23%|██▎       | 60/266 [02:42<07:04,  2.06s/it]predicting train subjects:  23%|██▎       | 61/266 [02:44<06:55,  2.03s/it]predicting train subjects:  23%|██▎       | 62/266 [02:46<06:44,  1.98s/it]predicting train subjects:  24%|██▎       | 63/266 [02:48<06:40,  1.97s/it]predicting train subjects:  24%|██▍       | 64/266 [02:50<06:37,  1.97s/it]predicting train subjects:  24%|██▍       | 65/266 [02:52<06:30,  1.95s/it]predicting train subjects:  25%|██▍       | 66/266 [02:54<06:39,  2.00s/it]predicting train subjects:  25%|██▌       | 67/266 [02:56<06:33,  1.98s/it]predicting train subjects:  26%|██▌       | 68/266 [02:58<06:26,  1.95s/it]predicting train subjects:  26%|██▌       | 69/266 [03:00<06:32,  1.99s/it]predicting train subjects:  26%|██▋       | 70/266 [03:02<06:27,  1.98s/it]predicting train subjects:  27%|██▋       | 71/266 [03:04<06:31,  2.01s/it]predicting train subjects:  27%|██▋       | 72/266 [03:06<06:29,  2.01s/it]predicting train subjects:  27%|██▋       | 73/266 [03:08<06:19,  1.97s/it]predicting train subjects:  28%|██▊       | 74/266 [03:10<06:21,  1.99s/it]predicting train subjects:  28%|██▊       | 75/266 [03:12<06:26,  2.02s/it]predicting train subjects:  29%|██▊       | 76/266 [03:14<06:19,  2.00s/it]predicting train subjects:  29%|██▉       | 77/266 [03:16<06:14,  1.98s/it]predicting train subjects:  29%|██▉       | 78/266 [03:18<06:37,  2.12s/it]predicting train subjects:  30%|██▉       | 79/266 [03:21<06:57,  2.23s/it]predicting train subjects:  30%|███       | 80/266 [03:23<07:09,  2.31s/it]predicting train subjects:  30%|███       | 81/266 [03:26<07:19,  2.37s/it]predicting train subjects:  31%|███       | 82/266 [03:28<07:28,  2.44s/it]predicting train subjects:  31%|███       | 83/266 [03:31<07:28,  2.45s/it]predicting train subjects:  32%|███▏      | 84/266 [03:33<07:29,  2.47s/it]predicting train subjects:  32%|███▏      | 85/266 [03:36<07:27,  2.47s/it]predicting train subjects:  32%|███▏      | 86/266 [03:38<07:25,  2.48s/it]predicting train subjects:  33%|███▎      | 87/266 [03:41<07:22,  2.47s/it]predicting train subjects:  33%|███▎      | 88/266 [03:43<07:24,  2.50s/it]predicting train subjects:  33%|███▎      | 89/266 [03:46<07:20,  2.49s/it]predicting train subjects:  34%|███▍      | 90/266 [03:48<07:16,  2.48s/it]predicting train subjects:  34%|███▍      | 91/266 [03:51<07:23,  2.53s/it]predicting train subjects:  35%|███▍      | 92/266 [03:53<07:18,  2.52s/it]predicting train subjects:  35%|███▍      | 93/266 [03:56<07:13,  2.51s/it]predicting train subjects:  35%|███▌      | 94/266 [03:58<07:08,  2.49s/it]predicting train subjects:  36%|███▌      | 95/266 [04:01<07:03,  2.48s/it]predicting train subjects:  36%|███▌      | 96/266 [04:03<06:44,  2.38s/it]predicting train subjects:  36%|███▋      | 97/266 [04:05<06:46,  2.41s/it]predicting train subjects:  37%|███▋      | 98/266 [04:08<06:43,  2.40s/it]predicting train subjects:  37%|███▋      | 99/266 [04:10<06:09,  2.21s/it]predicting train subjects:  38%|███▊      | 100/266 [04:12<05:56,  2.15s/it]predicting train subjects:  38%|███▊      | 101/266 [04:14<05:53,  2.14s/it]predicting train subjects:  38%|███▊      | 102/266 [04:16<05:53,  2.15s/it]predicting train subjects:  39%|███▊      | 103/266 [04:18<05:49,  2.15s/it]predicting train subjects:  39%|███▉      | 104/266 [04:20<05:48,  2.15s/it]predicting train subjects:  39%|███▉      | 105/266 [04:22<05:44,  2.14s/it]predicting train subjects:  40%|███▉      | 106/266 [04:24<05:39,  2.12s/it]predicting train subjects:  40%|████      | 107/266 [04:27<05:38,  2.13s/it]predicting train subjects:  41%|████      | 108/266 [04:29<05:39,  2.15s/it]predicting train subjects:  41%|████      | 109/266 [04:31<05:45,  2.20s/it]predicting train subjects:  41%|████▏     | 110/266 [04:33<05:39,  2.18s/it]predicting train subjects:  42%|████▏     | 111/266 [04:35<05:34,  2.16s/it]predicting train subjects:  42%|████▏     | 112/266 [04:37<05:30,  2.15s/it]predicting train subjects:  42%|████▏     | 113/266 [04:40<05:28,  2.14s/it]predicting train subjects:  43%|████▎     | 114/266 [04:42<05:26,  2.15s/it]predicting train subjects:  43%|████▎     | 115/266 [04:44<05:23,  2.14s/it]predicting train subjects:  44%|████▎     | 116/266 [04:46<05:20,  2.14s/it]predicting train subjects:  44%|████▍     | 117/266 [04:48<05:21,  2.15s/it]predicting train subjects:  44%|████▍     | 118/266 [04:50<05:18,  2.15s/it]predicting train subjects:  45%|████▍     | 119/266 [04:53<05:29,  2.24s/it]predicting train subjects:  45%|████▌     | 120/266 [04:55<05:43,  2.35s/it]predicting train subjects:  45%|████▌     | 121/266 [04:58<05:53,  2.44s/it]predicting train subjects:  46%|████▌     | 122/266 [05:00<05:53,  2.45s/it]predicting train subjects:  46%|████▌     | 123/266 [05:03<05:50,  2.45s/it]predicting train subjects:  47%|████▋     | 124/266 [05:05<05:47,  2.44s/it]predicting train subjects:  47%|████▋     | 125/266 [05:08<05:50,  2.49s/it]predicting train subjects:  47%|████▋     | 126/266 [05:10<05:43,  2.45s/it]predicting train subjects:  48%|████▊     | 127/266 [05:13<05:45,  2.49s/it]predicting train subjects:  48%|████▊     | 128/266 [05:15<05:45,  2.50s/it]predicting train subjects:  48%|████▊     | 129/266 [05:18<05:41,  2.49s/it]predicting train subjects:  49%|████▉     | 130/266 [05:20<05:39,  2.50s/it]predicting train subjects:  49%|████▉     | 131/266 [05:23<05:42,  2.54s/it]predicting train subjects:  50%|████▉     | 132/266 [05:26<05:45,  2.58s/it]predicting train subjects:  50%|█████     | 133/266 [05:28<05:41,  2.57s/it]predicting train subjects:  50%|█████     | 134/266 [05:31<05:44,  2.61s/it]predicting train subjects:  51%|█████     | 135/266 [05:34<05:44,  2.63s/it]predicting train subjects:  51%|█████     | 136/266 [05:36<05:37,  2.59s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:39<05:33,  2.59s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:41<05:29,  2.57s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:44<05:25,  2.56s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:46<05:19,  2.54s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:49<05:23,  2.58s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:51<05:16,  2.56s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:54<05:13,  2.55s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:56<05:08,  2.53s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:59<05:09,  2.56s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:02<05:06,  2.55s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:04<05:07,  2.59s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:07<05:03,  2.57s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:09<05:03,  2.59s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:12<05:07,  2.65s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:15<05:04,  2.65s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:18<05:01,  2.65s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:20<04:57,  2.63s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:23<04:55,  2.64s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:25<04:28,  2.42s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:26<04:04,  2.22s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:28<03:50,  2.12s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:30<03:38,  2.02s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:32<03:31,  1.98s/it]predicting train subjects:  60%|██████    | 160/266 [06:34<03:24,  1.92s/it]predicting train subjects:  61%|██████    | 161/266 [06:36<03:18,  1.89s/it]predicting train subjects:  61%|██████    | 162/266 [06:37<03:14,  1.87s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:39<03:11,  1.86s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:41<03:06,  1.83s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:43<03:06,  1.85s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:45<03:03,  1.84s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:47<03:03,  1.85s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:48<03:01,  1.85s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:50<02:57,  1.83s/it]predicting train subjects:  64%|██████▍   | 170/266 [06:52<02:55,  1.83s/it]predicting train subjects:  64%|██████▍   | 171/266 [06:54<02:53,  1.83s/it]predicting train subjects:  65%|██████▍   | 172/266 [06:56<02:50,  1.81s/it]predicting train subjects:  65%|██████▌   | 173/266 [06:58<03:00,  1.94s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:00<03:00,  1.97s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:02<03:01,  2.00s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:04<03:02,  2.03s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:06<03:01,  2.04s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:08<03:01,  2.06s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:10<02:59,  2.06s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:12<02:58,  2.07s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:15<03:00,  2.12s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:17<02:55,  2.09s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:19<02:54,  2.10s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:21<02:50,  2.08s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:23<02:49,  2.09s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:25<02:47,  2.09s/it]predicting train subjects:  70%|███████   | 187/266 [07:27<02:44,  2.08s/it]predicting train subjects:  71%|███████   | 188/266 [07:29<02:41,  2.07s/it]predicting train subjects:  71%|███████   | 189/266 [07:31<02:38,  2.06s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:33<02:35,  2.05s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:35<02:37,  2.10s/it]predicting train subjects:  72%|███████▏  | 192/266 [07:37<02:33,  2.07s/it]predicting train subjects:  73%|███████▎  | 193/266 [07:40<02:30,  2.06s/it]predicting train subjects:  73%|███████▎  | 194/266 [07:42<02:39,  2.22s/it]predicting train subjects:  73%|███████▎  | 195/266 [07:44<02:36,  2.20s/it]predicting train subjects:  74%|███████▎  | 196/266 [07:46<02:33,  2.20s/it]predicting train subjects:  74%|███████▍  | 197/266 [07:49<02:33,  2.22s/it]predicting train subjects:  74%|███████▍  | 198/266 [07:51<02:29,  2.20s/it]predicting train subjects:  75%|███████▍  | 199/266 [07:53<02:26,  2.19s/it]predicting train subjects:  75%|███████▌  | 200/266 [07:55<02:25,  2.21s/it]predicting train subjects:  76%|███████▌  | 201/266 [07:58<02:25,  2.24s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:00<02:23,  2.25s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:02<02:19,  2.22s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:04<02:17,  2.22s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:07<02:16,  2.23s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:09<02:14,  2.24s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:11<02:11,  2.23s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:13<02:08,  2.21s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:15<02:07,  2.24s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:18<02:04,  2.22s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:20<02:01,  2.20s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:22<01:57,  2.18s/it]predicting train subjects:  80%|████████  | 213/266 [08:24<01:51,  2.11s/it]predicting train subjects:  80%|████████  | 214/266 [08:26<01:47,  2.06s/it]predicting train subjects:  81%|████████  | 215/266 [08:28<01:44,  2.05s/it]predicting train subjects:  81%|████████  | 216/266 [08:30<01:41,  2.02s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:32<01:39,  2.03s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:34<01:37,  2.02s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:36<01:35,  2.03s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:38<01:33,  2.03s/it]predicting train subjects:  83%|████████▎ | 221/266 [08:40<01:30,  2.00s/it]predicting train subjects:  83%|████████▎ | 222/266 [08:42<01:28,  2.01s/it]predicting train subjects:  84%|████████▍ | 223/266 [08:44<01:27,  2.03s/it]predicting train subjects:  84%|████████▍ | 224/266 [08:46<01:24,  2.02s/it]predicting train subjects:  85%|████████▍ | 225/266 [08:48<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [08:50<01:19,  2.00s/it]predicting train subjects:  85%|████████▌ | 227/266 [08:52<01:18,  2.00s/it]predicting train subjects:  86%|████████▌ | 228/266 [08:54<01:16,  2.01s/it]predicting train subjects:  86%|████████▌ | 229/266 [08:56<01:14,  2.02s/it]predicting train subjects:  86%|████████▋ | 230/266 [08:58<01:13,  2.04s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:00<01:11,  2.03s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:02<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:04<01:04,  1.96s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:06<01:02,  1.96s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:08<01:00,  1.95s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:10<00:59,  1.97s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:12<00:57,  1.99s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:14<00:55,  1.97s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:16<00:53,  1.98s/it]predicting train subjects:  90%|█████████ | 240/266 [09:18<00:51,  1.97s/it]predicting train subjects:  91%|█████████ | 241/266 [09:20<00:48,  1.95s/it]predicting train subjects:  91%|█████████ | 242/266 [09:22<00:47,  1.97s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:24<00:45,  1.98s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:26<00:43,  1.96s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:28<00:41,  1.97s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:30<00:39,  1.99s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:32<00:37,  1.98s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:34<00:35,  2.00s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:36<00:36,  2.15s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:39<00:36,  2.25s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:41<00:35,  2.35s/it]predicting train subjects:  95%|█████████▍| 252/266 [09:44<00:33,  2.42s/it]predicting train subjects:  95%|█████████▌| 253/266 [09:46<00:31,  2.45s/it]predicting train subjects:  95%|█████████▌| 254/266 [09:49<00:30,  2.50s/it]predicting train subjects:  96%|█████████▌| 255/266 [09:52<00:28,  2.56s/it]predicting train subjects:  96%|█████████▌| 256/266 [09:54<00:25,  2.58s/it]predicting train subjects:  97%|█████████▋| 257/266 [09:57<00:23,  2.57s/it]predicting train subjects:  97%|█████████▋| 258/266 [09:59<00:20,  2.57s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:02<00:18,  2.61s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:05<00:15,  2.64s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:07<00:13,  2.62s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:10<00:10,  2.62s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:12<00:07,  2.58s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:15<00:05,  2.57s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:18<00:02,  2.59s/it]predicting train subjects: 100%|██████████| 266/266 [10:20<00:00,  2.55s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:12,  2.00it/s]Loading train:   1%|          | 2/266 [00:01<02:15,  1.95it/s]Loading train:   1%|          | 3/266 [00:01<02:05,  2.10it/s]Loading train:   2%|▏         | 4/266 [00:01<01:59,  2.19it/s]Loading train:   2%|▏         | 5/266 [00:02<01:58,  2.21it/s]Loading train:   2%|▏         | 6/266 [00:02<02:00,  2.15it/s]Loading train:   3%|▎         | 7/266 [00:03<02:07,  2.03it/s]Loading train:   3%|▎         | 8/266 [00:03<02:09,  1.99it/s]Loading train:   3%|▎         | 9/266 [00:04<02:04,  2.07it/s]Loading train:   4%|▍         | 10/266 [00:04<02:04,  2.05it/s]Loading train:   4%|▍         | 11/266 [00:05<02:14,  1.89it/s]Loading train:   5%|▍         | 12/266 [00:05<02:16,  1.86it/s]Loading train:   5%|▍         | 13/266 [00:06<02:12,  1.92it/s]Loading train:   5%|▌         | 14/266 [00:07<02:14,  1.87it/s]Loading train:   6%|▌         | 15/266 [00:07<02:10,  1.92it/s]Loading train:   6%|▌         | 16/266 [00:08<02:14,  1.86it/s]Loading train:   6%|▋         | 17/266 [00:08<02:17,  1.82it/s]Loading train:   7%|▋         | 18/266 [00:09<02:12,  1.88it/s]Loading train:   7%|▋         | 19/266 [00:09<02:09,  1.90it/s]Loading train:   8%|▊         | 20/266 [00:10<02:15,  1.81it/s]Loading train:   8%|▊         | 21/266 [00:10<02:19,  1.76it/s]Loading train:   8%|▊         | 22/266 [00:11<02:12,  1.84it/s]Loading train:   9%|▊         | 23/266 [00:11<02:11,  1.85it/s]Loading train:   9%|▉         | 24/266 [00:12<02:11,  1.84it/s]Loading train:   9%|▉         | 25/266 [00:12<02:01,  1.98it/s]Loading train:  10%|▉         | 26/266 [00:13<02:04,  1.93it/s]Loading train:  10%|█         | 27/266 [00:13<01:53,  2.11it/s]Loading train:  11%|█         | 28/266 [00:14<01:51,  2.14it/s]Loading train:  11%|█         | 29/266 [00:14<01:46,  2.22it/s]Loading train:  11%|█▏        | 30/266 [00:15<01:50,  2.13it/s]Loading train:  12%|█▏        | 31/266 [00:15<01:48,  2.17it/s]Loading train:  12%|█▏        | 32/266 [00:16<01:53,  2.05it/s]Loading train:  12%|█▏        | 33/266 [00:16<01:54,  2.03it/s]Loading train:  13%|█▎        | 34/266 [00:17<01:54,  2.02it/s]Loading train:  13%|█▎        | 35/266 [00:17<01:52,  2.05it/s]Loading train:  14%|█▎        | 36/266 [00:18<01:51,  2.07it/s]Loading train:  14%|█▍        | 37/266 [00:18<02:00,  1.90it/s]Loading train:  14%|█▍        | 38/266 [00:19<01:53,  2.01it/s]Loading train:  15%|█▍        | 39/266 [00:19<01:52,  2.02it/s]Loading train:  15%|█▌        | 40/266 [00:20<01:48,  2.08it/s]Loading train:  15%|█▌        | 41/266 [00:20<01:42,  2.20it/s]Loading train:  16%|█▌        | 42/266 [00:20<01:37,  2.30it/s]Loading train:  16%|█▌        | 43/266 [00:21<01:38,  2.27it/s]Loading train:  17%|█▋        | 44/266 [00:21<01:35,  2.32it/s]Loading train:  17%|█▋        | 45/266 [00:22<01:28,  2.51it/s]Loading train:  17%|█▋        | 46/266 [00:22<01:25,  2.58it/s]Loading train:  18%|█▊        | 47/266 [00:22<01:26,  2.54it/s]Loading train:  18%|█▊        | 48/266 [00:23<01:24,  2.59it/s]Loading train:  18%|█▊        | 49/266 [00:23<01:22,  2.62it/s]Loading train:  19%|█▉        | 50/266 [00:23<01:23,  2.59it/s]Loading train:  19%|█▉        | 51/266 [00:24<01:19,  2.70it/s]Loading train:  20%|█▉        | 52/266 [00:24<01:13,  2.90it/s]Loading train:  20%|█▉        | 53/266 [00:24<01:11,  2.97it/s]Loading train:  20%|██        | 54/266 [00:25<01:13,  2.87it/s]Loading train:  21%|██        | 55/266 [00:25<01:22,  2.57it/s]Loading train:  21%|██        | 56/266 [00:26<01:23,  2.50it/s]Loading train:  21%|██▏       | 57/266 [00:26<01:27,  2.40it/s]Loading train:  22%|██▏       | 58/266 [00:27<01:23,  2.50it/s]Loading train:  22%|██▏       | 59/266 [00:27<01:18,  2.63it/s]Loading train:  23%|██▎       | 60/266 [00:27<01:17,  2.65it/s]Loading train:  23%|██▎       | 61/266 [00:28<01:17,  2.64it/s]Loading train:  23%|██▎       | 62/266 [00:28<01:17,  2.65it/s]Loading train:  24%|██▎       | 63/266 [00:28<01:19,  2.56it/s]Loading train:  24%|██▍       | 64/266 [00:29<01:25,  2.36it/s]Loading train:  24%|██▍       | 65/266 [00:29<01:25,  2.36it/s]Loading train:  25%|██▍       | 66/266 [00:30<01:23,  2.40it/s]Loading train:  25%|██▌       | 67/266 [00:30<01:15,  2.64it/s]Loading train:  26%|██▌       | 68/266 [00:30<01:12,  2.74it/s]Loading train:  26%|██▌       | 69/266 [00:31<01:10,  2.78it/s]Loading train:  26%|██▋       | 70/266 [00:31<01:12,  2.71it/s]Loading train:  27%|██▋       | 71/266 [00:32<01:19,  2.45it/s]Loading train:  27%|██▋       | 72/266 [00:32<01:22,  2.35it/s]Loading train:  27%|██▋       | 73/266 [00:32<01:17,  2.49it/s]Loading train:  28%|██▊       | 74/266 [00:33<01:10,  2.71it/s]Loading train:  28%|██▊       | 75/266 [00:33<01:06,  2.88it/s]Loading train:  29%|██▊       | 76/266 [00:33<01:02,  3.03it/s]Loading train:  29%|██▉       | 77/266 [00:34<01:03,  2.95it/s]Loading train:  29%|██▉       | 78/266 [00:34<01:14,  2.52it/s]Loading train:  30%|██▉       | 79/266 [00:35<01:13,  2.53it/s]Loading train:  30%|███       | 80/266 [00:35<01:15,  2.46it/s]Loading train:  30%|███       | 81/266 [00:35<01:14,  2.47it/s]Loading train:  31%|███       | 82/266 [00:36<01:12,  2.52it/s]Loading train:  31%|███       | 83/266 [00:36<01:11,  2.57it/s]Loading train:  32%|███▏      | 84/266 [00:37<01:19,  2.30it/s]Loading train:  32%|███▏      | 85/266 [00:37<01:23,  2.17it/s]Loading train:  32%|███▏      | 86/266 [00:38<01:25,  2.11it/s]Loading train:  33%|███▎      | 87/266 [00:38<01:21,  2.19it/s]Loading train:  33%|███▎      | 88/266 [00:39<01:18,  2.27it/s]Loading train:  33%|███▎      | 89/266 [00:39<01:16,  2.31it/s]Loading train:  34%|███▍      | 90/266 [00:39<01:17,  2.27it/s]Loading train:  34%|███▍      | 91/266 [00:40<01:18,  2.23it/s]Loading train:  35%|███▍      | 92/266 [00:40<01:19,  2.20it/s]Loading train:  35%|███▍      | 93/266 [00:41<01:19,  2.18it/s]Loading train:  35%|███▌      | 94/266 [00:41<01:16,  2.24it/s]Loading train:  36%|███▌      | 95/266 [00:42<01:18,  2.17it/s]Loading train:  36%|███▌      | 96/266 [00:42<01:21,  2.08it/s]Loading train:  36%|███▋      | 97/266 [00:43<01:20,  2.10it/s]Loading train:  37%|███▋      | 98/266 [00:43<01:20,  2.08it/s]Loading train:  37%|███▋      | 99/266 [00:44<01:15,  2.20it/s]Loading train:  38%|███▊      | 100/266 [00:44<01:12,  2.28it/s]Loading train:  38%|███▊      | 101/266 [00:45<01:15,  2.19it/s]Loading train:  38%|███▊      | 102/266 [00:45<01:17,  2.11it/s]Loading train:  39%|███▊      | 103/266 [00:45<01:16,  2.13it/s]Loading train:  39%|███▉      | 104/266 [00:46<01:17,  2.09it/s]Loading train:  39%|███▉      | 105/266 [00:46<01:12,  2.24it/s]Loading train:  40%|███▉      | 106/266 [00:47<01:11,  2.25it/s]Loading train:  40%|████      | 107/266 [00:47<01:14,  2.15it/s]Loading train:  41%|████      | 108/266 [00:48<01:09,  2.29it/s]Loading train:  41%|████      | 109/266 [00:48<01:08,  2.28it/s]Loading train:  41%|████▏     | 110/266 [00:49<01:08,  2.29it/s]Loading train:  42%|████▏     | 111/266 [00:49<01:08,  2.27it/s]Loading train:  42%|████▏     | 112/266 [00:49<01:07,  2.27it/s]Loading train:  42%|████▏     | 113/266 [00:50<01:09,  2.21it/s]Loading train:  43%|████▎     | 114/266 [00:50<01:06,  2.30it/s]Loading train:  43%|████▎     | 115/266 [00:51<01:03,  2.36it/s]Loading train:  44%|████▎     | 116/266 [00:51<00:58,  2.55it/s]Loading train:  44%|████▍     | 117/266 [00:51<00:57,  2.61it/s]Loading train:  44%|████▍     | 118/266 [00:52<00:59,  2.48it/s]Loading train:  45%|████▍     | 119/266 [00:52<01:01,  2.40it/s]Loading train:  45%|████▌     | 120/266 [00:53<01:01,  2.36it/s]Loading train:  45%|████▌     | 121/266 [00:53<01:00,  2.39it/s]Loading train:  46%|████▌     | 122/266 [00:54<01:02,  2.29it/s]Loading train:  46%|████▌     | 123/266 [00:54<01:05,  2.19it/s]Loading train:  47%|████▋     | 124/266 [00:55<01:04,  2.19it/s]Loading train:  47%|████▋     | 125/266 [00:55<01:07,  2.10it/s]Loading train:  47%|████▋     | 126/266 [00:56<01:04,  2.16it/s]Loading train:  48%|████▊     | 127/266 [00:56<01:02,  2.21it/s]Loading train:  48%|████▊     | 128/266 [00:56<01:04,  2.14it/s]Loading train:  48%|████▊     | 129/266 [00:57<01:06,  2.07it/s]Loading train:  49%|████▉     | 130/266 [00:58<01:12,  1.88it/s]Loading train:  49%|████▉     | 131/266 [00:58<01:06,  2.03it/s]Loading train:  50%|████▉     | 132/266 [00:58<01:00,  2.20it/s]Loading train:  50%|█████     | 133/266 [00:59<00:57,  2.33it/s]Loading train:  50%|█████     | 134/266 [00:59<00:53,  2.45it/s]Loading train:  51%|█████     | 135/266 [01:00<00:56,  2.32it/s]Loading train:  51%|█████     | 136/266 [01:00<00:58,  2.21it/s]Loading train:  52%|█████▏    | 137/266 [01:01<00:56,  2.29it/s]Loading train:  52%|█████▏    | 138/266 [01:01<00:54,  2.35it/s]Loading train:  52%|█████▏    | 139/266 [01:01<00:50,  2.52it/s]Loading train:  53%|█████▎    | 140/266 [01:02<00:47,  2.63it/s]Loading train:  53%|█████▎    | 141/266 [01:02<00:46,  2.67it/s]Loading train:  53%|█████▎    | 142/266 [01:02<00:48,  2.53it/s]Loading train:  54%|█████▍    | 143/266 [01:03<00:51,  2.39it/s]Loading train:  54%|█████▍    | 144/266 [01:03<00:52,  2.34it/s]Loading train:  55%|█████▍    | 145/266 [01:04<00:53,  2.25it/s]Loading train:  55%|█████▍    | 146/266 [01:04<00:51,  2.34it/s]Loading train:  55%|█████▌    | 147/266 [01:05<00:52,  2.28it/s]Loading train:  56%|█████▌    | 148/266 [01:05<00:54,  2.18it/s]Loading train:  56%|█████▌    | 149/266 [01:06<00:51,  2.29it/s]Loading train:  56%|█████▋    | 150/266 [01:06<00:47,  2.43it/s]Loading train:  57%|█████▋    | 151/266 [01:06<00:48,  2.37it/s]Loading train:  57%|█████▋    | 152/266 [01:07<00:49,  2.29it/s]Loading train:  58%|█████▊    | 153/266 [01:07<00:49,  2.27it/s]Loading train:  58%|█████▊    | 154/266 [01:08<00:53,  2.08it/s]Loading train:  58%|█████▊    | 155/266 [01:08<00:50,  2.20it/s]Loading train:  59%|█████▊    | 156/266 [01:09<00:45,  2.41it/s]Loading train:  59%|█████▉    | 157/266 [01:09<00:41,  2.61it/s]Loading train:  59%|█████▉    | 158/266 [01:09<00:39,  2.77it/s]Loading train:  60%|█████▉    | 159/266 [01:09<00:36,  2.92it/s]Loading train:  60%|██████    | 160/266 [01:10<00:35,  3.03it/s]Loading train:  61%|██████    | 161/266 [01:10<00:36,  2.87it/s]Loading train:  61%|██████    | 162/266 [01:10<00:33,  3.10it/s]Loading train:  61%|██████▏   | 163/266 [01:11<00:31,  3.27it/s]Loading train:  62%|██████▏   | 164/266 [01:11<00:31,  3.27it/s]Loading train:  62%|██████▏   | 165/266 [01:11<00:31,  3.19it/s]Loading train:  62%|██████▏   | 166/266 [01:12<00:31,  3.20it/s]Loading train:  63%|██████▎   | 167/266 [01:12<00:29,  3.32it/s]Loading train:  63%|██████▎   | 168/266 [01:12<00:30,  3.24it/s]Loading train:  64%|██████▎   | 169/266 [01:13<00:30,  3.21it/s]Loading train:  64%|██████▍   | 170/266 [01:13<00:31,  3.08it/s]Loading train:  64%|██████▍   | 171/266 [01:13<00:29,  3.18it/s]Loading train:  65%|██████▍   | 172/266 [01:13<00:28,  3.28it/s]Loading train:  65%|██████▌   | 173/266 [01:14<00:30,  3.06it/s]Loading train:  65%|██████▌   | 174/266 [01:14<00:33,  2.77it/s]Loading train:  66%|██████▌   | 175/266 [01:15<00:33,  2.74it/s]Loading train:  66%|██████▌   | 176/266 [01:15<00:32,  2.79it/s]Loading train:  67%|██████▋   | 177/266 [01:15<00:34,  2.60it/s]Loading train:  67%|██████▋   | 178/266 [01:16<00:32,  2.67it/s]Loading train:  67%|██████▋   | 179/266 [01:16<00:34,  2.53it/s]Loading train:  68%|██████▊   | 180/266 [01:17<00:33,  2.61it/s]Loading train:  68%|██████▊   | 181/266 [01:17<00:34,  2.50it/s]Loading train:  68%|██████▊   | 182/266 [01:18<00:38,  2.17it/s]Loading train:  69%|██████▉   | 183/266 [01:18<00:40,  2.06it/s]Loading train:  69%|██████▉   | 184/266 [01:19<00:44,  1.85it/s]Loading train:  70%|██████▉   | 185/266 [01:20<00:46,  1.74it/s]Loading train:  70%|██████▉   | 186/266 [01:20<00:42,  1.88it/s]Loading train:  70%|███████   | 187/266 [01:20<00:42,  1.86it/s]Loading train:  71%|███████   | 188/266 [01:21<00:41,  1.89it/s]Loading train:  71%|███████   | 189/266 [01:22<00:41,  1.85it/s]Loading train:  71%|███████▏  | 190/266 [01:22<00:44,  1.72it/s]Loading train:  72%|███████▏  | 191/266 [01:23<00:41,  1.79it/s]Loading train:  72%|███████▏  | 192/266 [01:23<00:39,  1.85it/s]Loading train:  73%|███████▎  | 193/266 [01:24<00:39,  1.87it/s]Loading train:  73%|███████▎  | 194/266 [01:24<00:37,  1.90it/s]Loading train:  73%|███████▎  | 195/266 [01:25<00:34,  2.06it/s]Loading train:  74%|███████▎  | 196/266 [01:25<00:35,  1.96it/s]Loading train:  74%|███████▍  | 197/266 [01:26<00:37,  1.86it/s]Loading train:  74%|███████▍  | 198/266 [01:26<00:35,  1.92it/s]Loading train:  75%|███████▍  | 199/266 [01:27<00:34,  1.95it/s]Loading train:  75%|███████▌  | 200/266 [01:27<00:33,  1.96it/s]Loading train:  76%|███████▌  | 201/266 [01:28<00:34,  1.90it/s]Loading train:  76%|███████▌  | 202/266 [01:28<00:31,  2.03it/s]Loading train:  76%|███████▋  | 203/266 [01:29<00:34,  1.84it/s]Loading train:  77%|███████▋  | 204/266 [01:29<00:33,  1.85it/s]Loading train:  77%|███████▋  | 205/266 [01:30<00:32,  1.90it/s]Loading train:  77%|███████▋  | 206/266 [01:30<00:31,  1.93it/s]Loading train:  78%|███████▊  | 207/266 [01:31<00:30,  1.93it/s]Loading train:  78%|███████▊  | 208/266 [01:31<00:29,  1.98it/s]Loading train:  79%|███████▊  | 209/266 [01:32<00:33,  1.68it/s]Loading train:  79%|███████▉  | 210/266 [01:33<00:32,  1.71it/s]Loading train:  79%|███████▉  | 211/266 [01:33<00:31,  1.74it/s]Loading train:  80%|███████▉  | 212/266 [01:34<00:31,  1.72it/s]Loading train:  80%|████████  | 213/266 [01:34<00:28,  1.87it/s]Loading train:  80%|████████  | 214/266 [01:35<00:27,  1.90it/s]Loading train:  81%|████████  | 215/266 [01:35<00:26,  1.90it/s]Loading train:  81%|████████  | 216/266 [01:36<00:24,  2.01it/s]Loading train:  82%|████████▏ | 217/266 [01:36<00:24,  2.02it/s]Loading train:  82%|████████▏ | 218/266 [01:37<00:23,  2.02it/s]Loading train:  82%|████████▏ | 219/266 [01:37<00:23,  1.98it/s]Loading train:  83%|████████▎ | 220/266 [01:38<00:23,  1.96it/s]Loading train:  83%|████████▎ | 221/266 [01:38<00:23,  1.92it/s]Loading train:  83%|████████▎ | 222/266 [01:39<00:25,  1.75it/s]Loading train:  84%|████████▍ | 223/266 [01:40<00:23,  1.84it/s]Loading train:  84%|████████▍ | 224/266 [01:40<00:21,  1.92it/s]Loading train:  85%|████████▍ | 225/266 [01:41<00:20,  2.01it/s]Loading train:  85%|████████▍ | 226/266 [01:41<00:21,  1.82it/s]Loading train:  85%|████████▌ | 227/266 [01:42<00:19,  1.95it/s]Loading train:  86%|████████▌ | 228/266 [01:42<00:19,  1.97it/s]Loading train:  86%|████████▌ | 229/266 [01:43<00:19,  1.93it/s]Loading train:  86%|████████▋ | 230/266 [01:43<00:18,  1.91it/s]Loading train:  87%|████████▋ | 231/266 [01:44<00:19,  1.81it/s]Loading train:  87%|████████▋ | 232/266 [01:44<00:19,  1.76it/s]Loading train:  88%|████████▊ | 233/266 [01:45<00:17,  1.93it/s]Loading train:  88%|████████▊ | 234/266 [01:45<00:16,  1.98it/s]Loading train:  88%|████████▊ | 235/266 [01:46<00:18,  1.69it/s]Loading train:  89%|████████▊ | 236/266 [01:47<00:17,  1.75it/s]Loading train:  89%|████████▉ | 237/266 [01:47<00:15,  1.86it/s]Loading train:  89%|████████▉ | 238/266 [01:48<00:15,  1.86it/s]Loading train:  90%|████████▉ | 239/266 [01:48<00:13,  1.94it/s]Loading train:  90%|█████████ | 240/266 [01:49<00:14,  1.83it/s]Loading train:  91%|█████████ | 241/266 [01:49<00:13,  1.90it/s]Loading train:  91%|█████████ | 242/266 [01:50<00:12,  1.86it/s]Loading train:  91%|█████████▏| 243/266 [01:50<00:12,  1.84it/s]Loading train:  92%|█████████▏| 244/266 [01:51<00:11,  1.84it/s]Loading train:  92%|█████████▏| 245/266 [01:51<00:11,  1.81it/s]Loading train:  92%|█████████▏| 246/266 [01:52<00:11,  1.79it/s]Loading train:  93%|█████████▎| 247/266 [01:52<00:10,  1.88it/s]Loading train:  93%|█████████▎| 248/266 [01:53<00:09,  1.88it/s]Loading train:  94%|█████████▎| 249/266 [01:54<00:09,  1.79it/s]Loading train:  94%|█████████▍| 250/266 [01:54<00:09,  1.73it/s]Loading train:  94%|█████████▍| 251/266 [01:55<00:08,  1.85it/s]Loading train:  95%|█████████▍| 252/266 [01:55<00:07,  1.90it/s]Loading train:  95%|█████████▌| 253/266 [01:56<00:07,  1.84it/s]Loading train:  95%|█████████▌| 254/266 [01:56<00:07,  1.70it/s]Loading train:  96%|█████████▌| 255/266 [01:57<00:06,  1.71it/s]Loading train:  96%|█████████▌| 256/266 [01:58<00:05,  1.67it/s]Loading train:  97%|█████████▋| 257/266 [01:58<00:05,  1.63it/s]Loading train:  97%|█████████▋| 258/266 [01:59<00:05,  1.52it/s]Loading train:  97%|█████████▋| 259/266 [02:00<00:04,  1.67it/s]Loading train:  98%|█████████▊| 260/266 [02:00<00:03,  1.74it/s]Loading train:  98%|█████████▊| 261/266 [02:01<00:02,  1.73it/s]Loading train:  98%|█████████▊| 262/266 [02:01<00:02,  1.67it/s]Loading train:  99%|█████████▉| 263/266 [02:02<00:01,  1.69it/s]Loading train:  99%|█████████▉| 264/266 [02:02<00:01,  1.73it/s]Loading train: 100%|█████████▉| 265/266 [02:03<00:00,  1.82it/s]Loading train: 100%|██████████| 266/266 [02:03<00:00,  1.84it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 4/266 [00:00<00:08, 32.12it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:08, 31.06it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:08, 28.96it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:09, 25.66it/s]concatenating: train:   6%|▌         | 16/266 [00:00<00:09, 25.20it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:09, 27.19it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:09, 25.16it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:08, 27.65it/s]concatenating: train:  22%|██▏       | 59/266 [00:01<00:05, 38.06it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:03, 51.60it/s]concatenating: train:  41%|████      | 108/266 [00:01<00:02, 61.21it/s]concatenating: train:  47%|████▋     | 124/266 [00:01<00:02, 62.96it/s]concatenating: train:  64%|██████▍   | 170/266 [00:01<00:01, 84.89it/s]concatenating: train:  82%|████████▏ | 219/266 [00:01<00:00, 112.58it/s]concatenating: train:  98%|█████████▊| 262/266 [00:01<00:00, 144.52it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 138.49it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:02,  1.44it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.54it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  1.64it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.68it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation:  75%|███████▌  | 3/4 [00:00<00:00, 27.82it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 25.01it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<02:35,  1.70it/s]Loading trainS:   1%|          | 2/266 [00:01<02:38,  1.67it/s]Loading trainS:   1%|          | 3/266 [00:01<02:31,  1.73it/s]Loading trainS:   2%|▏         | 4/266 [00:02<02:31,  1.73it/s]Loading trainS:   2%|▏         | 5/266 [00:02<02:27,  1.76it/s]Loading trainS:   2%|▏         | 6/266 [00:03<02:27,  1.76it/s]Loading trainS:   3%|▎         | 7/266 [00:04<02:31,  1.70it/s]Loading trainS:   3%|▎         | 8/266 [00:04<02:42,  1.59it/s]Loading trainS:   3%|▎         | 9/266 [00:05<02:42,  1.59it/s]Loading trainS:   4%|▍         | 10/266 [00:06<02:45,  1.54it/s]Loading trainS:   4%|▍         | 11/266 [00:06<02:33,  1.66it/s]Loading trainS:   5%|▍         | 12/266 [00:07<02:40,  1.58it/s]Loading trainS:   5%|▍         | 13/266 [00:07<02:35,  1.62it/s]Loading trainS:   5%|▌         | 14/266 [00:08<02:40,  1.57it/s]Loading trainS:   6%|▌         | 15/266 [00:09<02:29,  1.68it/s]Loading trainS:   6%|▌         | 16/266 [00:09<02:31,  1.65it/s]Loading trainS:   6%|▋         | 17/266 [00:10<02:29,  1.66it/s]Loading trainS:   7%|▋         | 18/266 [00:10<02:23,  1.72it/s]Loading trainS:   7%|▋         | 19/266 [00:11<02:25,  1.69it/s]Loading trainS:   8%|▊         | 20/266 [00:12<02:26,  1.68it/s]Loading trainS:   8%|▊         | 21/266 [00:12<02:25,  1.69it/s]Loading trainS:   8%|▊         | 22/266 [00:13<02:29,  1.63it/s]Loading trainS:   9%|▊         | 23/266 [00:13<02:25,  1.67it/s]Loading trainS:   9%|▉         | 24/266 [00:14<02:20,  1.72it/s]Loading trainS:   9%|▉         | 25/266 [00:14<02:20,  1.71it/s]Loading trainS:  10%|▉         | 26/266 [00:15<02:12,  1.81it/s]Loading trainS:  10%|█         | 27/266 [00:16<02:10,  1.83it/s]Loading trainS:  11%|█         | 28/266 [00:16<02:10,  1.83it/s]Loading trainS:  11%|█         | 29/266 [00:17<02:17,  1.72it/s]Loading trainS:  11%|█▏        | 30/266 [00:17<02:18,  1.70it/s]Loading trainS:  12%|█▏        | 31/266 [00:18<02:18,  1.69it/s]Loading trainS:  12%|█▏        | 32/266 [00:18<02:12,  1.76it/s]Loading trainS:  12%|█▏        | 33/266 [00:19<02:06,  1.84it/s]Loading trainS:  13%|█▎        | 34/266 [00:20<02:14,  1.72it/s]Loading trainS:  13%|█▎        | 35/266 [00:20<02:23,  1.61it/s]Loading trainS:  14%|█▎        | 36/266 [00:21<02:12,  1.74it/s]Loading trainS:  14%|█▍        | 37/266 [00:21<02:11,  1.74it/s]Loading trainS:  14%|█▍        | 38/266 [00:22<02:14,  1.70it/s]Loading trainS:  15%|█▍        | 39/266 [00:22<02:07,  1.79it/s]Loading trainS:  15%|█▌        | 40/266 [00:23<02:08,  1.76it/s]Loading trainS:  15%|█▌        | 41/266 [00:24<02:13,  1.68it/s]Loading trainS:  16%|█▌        | 42/266 [00:24<02:08,  1.74it/s]Loading trainS:  16%|█▌        | 43/266 [00:25<02:08,  1.73it/s]Loading trainS:  17%|█▋        | 44/266 [00:25<02:06,  1.75it/s]Loading trainS:  17%|█▋        | 45/266 [00:26<02:06,  1.75it/s]Loading trainS:  17%|█▋        | 46/266 [00:26<02:04,  1.76it/s]Loading trainS:  18%|█▊        | 47/266 [00:27<02:05,  1.74it/s]Loading trainS:  18%|█▊        | 48/266 [00:28<02:05,  1.74it/s]Loading trainS:  18%|█▊        | 49/266 [00:28<01:57,  1.84it/s]Loading trainS:  19%|█▉        | 50/266 [00:29<01:56,  1.85it/s]Loading trainS:  19%|█▉        | 51/266 [00:29<01:58,  1.82it/s]Loading trainS:  20%|█▉        | 52/266 [00:30<01:53,  1.89it/s]Loading trainS:  20%|█▉        | 53/266 [00:30<01:55,  1.84it/s]Loading trainS:  20%|██        | 54/266 [00:31<01:55,  1.83it/s]Loading trainS:  21%|██        | 55/266 [00:31<02:01,  1.74it/s]Loading trainS:  21%|██        | 56/266 [00:32<02:02,  1.72it/s]Loading trainS:  21%|██▏       | 57/266 [00:33<01:58,  1.76it/s]Loading trainS:  22%|██▏       | 58/266 [00:33<01:58,  1.75it/s]Loading trainS:  22%|██▏       | 59/266 [00:34<01:54,  1.81it/s]Loading trainS:  23%|██▎       | 60/266 [00:34<01:49,  1.89it/s]Loading trainS:  23%|██▎       | 61/266 [00:35<01:46,  1.93it/s]Loading trainS:  23%|██▎       | 62/266 [00:35<01:44,  1.96it/s]Loading trainS:  24%|██▎       | 63/266 [00:36<01:47,  1.88it/s]Loading trainS:  24%|██▍       | 64/266 [00:36<01:51,  1.82it/s]Loading trainS:  24%|██▍       | 65/266 [00:37<01:51,  1.80it/s]Loading trainS:  25%|██▍       | 66/266 [00:37<01:48,  1.85it/s]Loading trainS:  25%|██▌       | 67/266 [00:38<01:44,  1.90it/s]Loading trainS:  26%|██▌       | 68/266 [00:38<01:42,  1.94it/s]Loading trainS:  26%|██▌       | 69/266 [00:39<01:44,  1.89it/s]Loading trainS:  26%|██▋       | 70/266 [00:40<01:46,  1.84it/s]Loading trainS:  27%|██▋       | 71/266 [00:40<01:44,  1.87it/s]Loading trainS:  27%|██▋       | 72/266 [00:40<01:37,  1.98it/s]Loading trainS:  27%|██▋       | 73/266 [00:41<01:35,  2.01it/s]Loading trainS:  28%|██▊       | 74/266 [00:41<01:36,  1.99it/s]Loading trainS:  28%|██▊       | 75/266 [00:42<01:36,  1.97it/s]Loading trainS:  29%|██▊       | 76/266 [00:43<01:40,  1.90it/s]Loading trainS:  29%|██▉       | 77/266 [00:43<01:38,  1.92it/s]Loading trainS:  29%|██▉       | 78/266 [00:44<01:39,  1.90it/s]Loading trainS:  30%|██▉       | 79/266 [00:44<01:38,  1.89it/s]Loading trainS:  30%|███       | 80/266 [00:45<01:39,  1.87it/s]Loading trainS:  30%|███       | 81/266 [00:45<01:38,  1.87it/s]Loading trainS:  31%|███       | 82/266 [00:46<01:41,  1.81it/s]Loading trainS:  31%|███       | 83/266 [00:46<01:41,  1.80it/s]Loading trainS:  32%|███▏      | 84/266 [00:47<01:43,  1.76it/s]Loading trainS:  32%|███▏      | 85/266 [00:48<01:45,  1.72it/s]Loading trainS:  32%|███▏      | 86/266 [00:48<01:41,  1.77it/s]Loading trainS:  33%|███▎      | 87/266 [00:49<01:40,  1.79it/s]Loading trainS:  33%|███▎      | 88/266 [00:49<01:41,  1.76it/s]Loading trainS:  33%|███▎      | 89/266 [00:50<01:42,  1.72it/s]Loading trainS:  34%|███▍      | 90/266 [00:50<01:38,  1.78it/s]Loading trainS:  34%|███▍      | 91/266 [00:51<01:39,  1.75it/s]Loading trainS:  35%|███▍      | 92/266 [00:52<01:44,  1.67it/s]Loading trainS:  35%|███▍      | 93/266 [00:52<01:39,  1.74it/s]Loading trainS:  35%|███▌      | 94/266 [00:53<01:41,  1.70it/s]Loading trainS:  36%|███▌      | 95/266 [00:53<01:42,  1.68it/s]Loading trainS:  36%|███▌      | 96/266 [00:54<01:39,  1.70it/s]Loading trainS:  36%|███▋      | 97/266 [00:55<01:39,  1.70it/s]Loading trainS:  37%|███▋      | 98/266 [00:55<01:37,  1.72it/s]Loading trainS:  37%|███▋      | 99/266 [00:56<01:33,  1.79it/s]Loading trainS:  38%|███▊      | 100/266 [00:56<01:29,  1.85it/s]Loading trainS:  38%|███▊      | 101/266 [00:57<01:27,  1.88it/s]Loading trainS:  38%|███▊      | 102/266 [00:57<01:25,  1.92it/s]Loading trainS:  39%|███▊      | 103/266 [00:58<01:25,  1.91it/s]Loading trainS:  39%|███▉      | 104/266 [00:58<01:26,  1.88it/s]Loading trainS:  39%|███▉      | 105/266 [00:59<01:34,  1.71it/s]Loading trainS:  40%|███▉      | 106/266 [00:59<01:32,  1.73it/s]Loading trainS:  40%|████      | 107/266 [01:00<01:29,  1.78it/s]Loading trainS:  41%|████      | 108/266 [01:01<01:25,  1.85it/s]Loading trainS:  41%|████      | 109/266 [01:01<01:25,  1.84it/s]Loading trainS:  41%|████▏     | 110/266 [01:02<01:22,  1.90it/s]Loading trainS:  42%|████▏     | 111/266 [01:02<01:21,  1.91it/s]Loading trainS:  42%|████▏     | 112/266 [01:03<01:21,  1.89it/s]Loading trainS:  42%|████▏     | 113/266 [01:03<01:22,  1.86it/s]Loading trainS:  43%|████▎     | 114/266 [01:04<01:18,  1.94it/s]Loading trainS:  43%|████▎     | 115/266 [01:04<01:25,  1.77it/s]Loading trainS:  44%|████▎     | 116/266 [01:05<01:24,  1.78it/s]Loading trainS:  44%|████▍     | 117/266 [01:05<01:24,  1.76it/s]Loading trainS:  44%|████▍     | 118/266 [01:06<01:20,  1.84it/s]Loading trainS:  45%|████▍     | 119/266 [01:07<01:24,  1.73it/s]Loading trainS:  45%|████▌     | 120/266 [01:07<01:24,  1.72it/s]Loading trainS:  45%|████▌     | 121/266 [01:08<01:22,  1.76it/s]Loading trainS:  46%|████▌     | 122/266 [01:08<01:25,  1.69it/s]Loading trainS:  46%|████▌     | 123/266 [01:09<01:23,  1.72it/s]Loading trainS:  47%|████▋     | 124/266 [01:10<01:24,  1.69it/s]Loading trainS:  47%|████▋     | 125/266 [01:10<01:22,  1.71it/s]Loading trainS:  47%|████▋     | 126/266 [01:11<01:17,  1.82it/s]Loading trainS:  48%|████▊     | 127/266 [01:11<01:12,  1.92it/s]Loading trainS:  48%|████▊     | 128/266 [01:12<01:11,  1.92it/s]Loading trainS:  48%|████▊     | 129/266 [01:12<01:10,  1.94it/s]Loading trainS:  49%|████▉     | 130/266 [01:13<01:10,  1.92it/s]Loading trainS:  49%|████▉     | 131/266 [01:13<01:11,  1.89it/s]Loading trainS:  50%|████▉     | 132/266 [01:14<01:10,  1.89it/s]Loading trainS:  50%|█████     | 133/266 [01:14<01:09,  1.91it/s]Loading trainS:  50%|█████     | 134/266 [01:15<01:07,  1.95it/s]Loading trainS:  51%|█████     | 135/266 [01:15<01:07,  1.94it/s]Loading trainS:  51%|█████     | 136/266 [01:16<01:10,  1.83it/s]Loading trainS:  52%|█████▏    | 137/266 [01:16<01:11,  1.80it/s]Loading trainS:  52%|█████▏    | 138/266 [01:17<01:10,  1.83it/s]Loading trainS:  52%|█████▏    | 139/266 [01:17<01:08,  1.86it/s]Loading trainS:  53%|█████▎    | 140/266 [01:18<01:09,  1.82it/s]Loading trainS:  53%|█████▎    | 141/266 [01:18<01:06,  1.88it/s]Loading trainS:  53%|█████▎    | 142/266 [01:19<01:06,  1.88it/s]Loading trainS:  54%|█████▍    | 143/266 [01:20<01:07,  1.83it/s]Loading trainS:  54%|█████▍    | 144/266 [01:20<01:06,  1.83it/s]Loading trainS:  55%|█████▍    | 145/266 [01:21<01:05,  1.84it/s]Loading trainS:  55%|█████▍    | 146/266 [01:21<01:04,  1.85it/s]Loading trainS:  55%|█████▌    | 147/266 [01:22<01:06,  1.79it/s]Loading trainS:  56%|█████▌    | 148/266 [01:22<01:07,  1.76it/s]Loading trainS:  56%|█████▌    | 149/266 [01:23<01:05,  1.78it/s]Loading trainS:  56%|█████▋    | 150/266 [01:23<01:04,  1.80it/s]Loading trainS:  57%|█████▋    | 151/266 [01:24<01:02,  1.83it/s]Loading trainS:  57%|█████▋    | 152/266 [01:25<01:03,  1.80it/s]Loading trainS:  58%|█████▊    | 153/266 [01:25<01:03,  1.78it/s]Loading trainS:  58%|█████▊    | 154/266 [01:26<01:02,  1.78it/s]Loading trainS:  58%|█████▊    | 155/266 [01:26<01:01,  1.82it/s]Loading trainS:  59%|█████▊    | 156/266 [01:27<00:58,  1.87it/s]Loading trainS:  59%|█████▉    | 157/266 [01:27<00:55,  1.96it/s]Loading trainS:  59%|█████▉    | 158/266 [01:28<00:51,  2.10it/s]Loading trainS:  60%|█████▉    | 159/266 [01:28<00:47,  2.23it/s]Loading trainS:  60%|██████    | 160/266 [01:28<00:47,  2.23it/s]Loading trainS:  61%|██████    | 161/266 [01:29<00:48,  2.17it/s]Loading trainS:  61%|██████    | 162/266 [01:29<00:48,  2.15it/s]Loading trainS:  61%|██████▏   | 163/266 [01:30<00:47,  2.17it/s]Loading trainS:  62%|██████▏   | 164/266 [01:30<00:48,  2.12it/s]Loading trainS:  62%|██████▏   | 165/266 [01:31<00:45,  2.24it/s]Loading trainS:  62%|██████▏   | 166/266 [01:31<00:45,  2.19it/s]Loading trainS:  63%|██████▎   | 167/266 [01:32<00:46,  2.14it/s]Loading trainS:  63%|██████▎   | 168/266 [01:32<00:45,  2.14it/s]Loading trainS:  64%|██████▎   | 169/266 [01:33<00:41,  2.31it/s]Loading trainS:  64%|██████▍   | 170/266 [01:33<00:41,  2.29it/s]Loading trainS:  64%|██████▍   | 171/266 [01:33<00:43,  2.20it/s]Loading trainS:  65%|██████▍   | 172/266 [01:34<00:43,  2.18it/s]Loading trainS:  65%|██████▌   | 173/266 [01:34<00:44,  2.08it/s]Loading trainS:  65%|██████▌   | 174/266 [01:35<00:50,  1.81it/s]Loading trainS:  66%|██████▌   | 175/266 [01:36<00:50,  1.80it/s]Loading trainS:  66%|██████▌   | 176/266 [01:36<00:49,  1.83it/s]Loading trainS:  67%|██████▋   | 177/266 [01:37<00:46,  1.89it/s]Loading trainS:  67%|██████▋   | 178/266 [01:37<00:47,  1.87it/s]Loading trainS:  67%|██████▋   | 179/266 [01:38<00:50,  1.73it/s]Loading trainS:  68%|██████▊   | 180/266 [01:39<00:50,  1.69it/s]Loading trainS:  68%|██████▊   | 181/266 [01:39<00:45,  1.88it/s]Loading trainS:  68%|██████▊   | 182/266 [01:39<00:43,  1.94it/s]Loading trainS:  69%|██████▉   | 183/266 [01:40<00:43,  1.91it/s]Loading trainS:  69%|██████▉   | 184/266 [01:41<00:42,  1.92it/s]Loading trainS:  70%|██████▉   | 185/266 [01:41<00:44,  1.84it/s]Loading trainS:  70%|██████▉   | 186/266 [01:42<00:43,  1.85it/s]Loading trainS:  70%|███████   | 187/266 [01:42<00:42,  1.85it/s]Loading trainS:  71%|███████   | 188/266 [01:43<00:40,  1.91it/s]Loading trainS:  71%|███████   | 189/266 [01:43<00:39,  1.93it/s]Loading trainS:  71%|███████▏  | 190/266 [01:44<00:39,  1.94it/s]Loading trainS:  72%|███████▏  | 191/266 [01:44<00:43,  1.71it/s]Loading trainS:  72%|███████▏  | 192/266 [01:45<00:41,  1.76it/s]Loading trainS:  73%|███████▎  | 193/266 [01:45<00:39,  1.83it/s]Loading trainS:  73%|███████▎  | 194/266 [01:46<00:41,  1.74it/s]Loading trainS:  73%|███████▎  | 195/266 [01:46<00:36,  1.95it/s]Loading trainS:  74%|███████▎  | 196/266 [01:47<00:37,  1.86it/s]Loading trainS:  74%|███████▍  | 197/266 [01:48<00:38,  1.80it/s]Loading trainS:  74%|███████▍  | 198/266 [01:48<00:36,  1.85it/s]Loading trainS:  75%|███████▍  | 199/266 [01:49<00:36,  1.83it/s]Loading trainS:  75%|███████▌  | 200/266 [01:49<00:36,  1.81it/s]Loading trainS:  76%|███████▌  | 201/266 [01:50<00:32,  2.03it/s]Loading trainS:  76%|███████▌  | 202/266 [01:50<00:33,  1.91it/s]Loading trainS:  76%|███████▋  | 203/266 [01:51<00:32,  1.91it/s]Loading trainS:  77%|███████▋  | 204/266 [01:51<00:31,  1.97it/s]Loading trainS:  77%|███████▋  | 205/266 [01:52<00:31,  1.92it/s]Loading trainS:  77%|███████▋  | 206/266 [01:52<00:30,  1.95it/s]Loading trainS:  78%|███████▊  | 207/266 [01:53<00:31,  1.88it/s]Loading trainS:  78%|███████▊  | 208/266 [01:53<00:32,  1.79it/s]Loading trainS:  79%|███████▊  | 209/266 [01:54<00:31,  1.79it/s]Loading trainS:  79%|███████▉  | 210/266 [01:55<00:30,  1.84it/s]Loading trainS:  79%|███████▉  | 211/266 [01:55<00:28,  1.92it/s]Loading trainS:  80%|███████▉  | 212/266 [01:56<00:28,  1.92it/s]Loading trainS:  80%|████████  | 213/266 [01:56<00:27,  1.95it/s]Loading trainS:  80%|████████  | 214/266 [01:57<00:28,  1.86it/s]Loading trainS:  81%|████████  | 215/266 [01:57<00:28,  1.80it/s]Loading trainS:  81%|████████  | 216/266 [01:58<00:27,  1.82it/s]Loading trainS:  82%|████████▏ | 217/266 [01:58<00:26,  1.88it/s]Loading trainS:  82%|████████▏ | 218/266 [01:59<00:24,  1.94it/s]Loading trainS:  82%|████████▏ | 219/266 [01:59<00:24,  1.94it/s]Loading trainS:  83%|████████▎ | 220/266 [02:00<00:23,  1.94it/s]Loading trainS:  83%|████████▎ | 221/266 [02:00<00:22,  1.97it/s]Loading trainS:  83%|████████▎ | 222/266 [02:01<00:22,  1.96it/s]Loading trainS:  84%|████████▍ | 223/266 [02:01<00:22,  1.90it/s]Loading trainS:  84%|████████▍ | 224/266 [02:02<00:21,  1.92it/s]Loading trainS:  85%|████████▍ | 225/266 [02:02<00:20,  1.97it/s]Loading trainS:  85%|████████▍ | 226/266 [02:03<00:20,  1.95it/s]Loading trainS:  85%|████████▌ | 227/266 [02:03<00:19,  1.97it/s]Loading trainS:  86%|████████▌ | 228/266 [02:04<00:19,  1.93it/s]Loading trainS:  86%|████████▌ | 229/266 [02:04<00:19,  1.88it/s]Loading trainS:  86%|████████▋ | 230/266 [02:05<00:17,  2.01it/s]Loading trainS:  87%|████████▋ | 231/266 [02:05<00:17,  1.97it/s]Loading trainS:  87%|████████▋ | 232/266 [02:06<00:16,  2.04it/s]Loading trainS:  88%|████████▊ | 233/266 [02:06<00:16,  1.96it/s]Loading trainS:  88%|████████▊ | 234/266 [02:07<00:16,  1.98it/s]Loading trainS:  88%|████████▊ | 235/266 [02:07<00:15,  2.01it/s]Loading trainS:  89%|████████▊ | 236/266 [02:08<00:16,  1.86it/s]Loading trainS:  89%|████████▉ | 237/266 [02:09<00:15,  1.89it/s]Loading trainS:  89%|████████▉ | 238/266 [02:09<00:14,  1.89it/s]Loading trainS:  90%|████████▉ | 239/266 [02:10<00:14,  1.91it/s]Loading trainS:  90%|█████████ | 240/266 [02:10<00:13,  1.92it/s]Loading trainS:  91%|█████████ | 241/266 [02:11<00:13,  1.85it/s]Loading trainS:  91%|█████████ | 242/266 [02:11<00:13,  1.82it/s]Loading trainS:  91%|█████████▏| 243/266 [02:12<00:12,  1.82it/s]Loading trainS:  92%|█████████▏| 244/266 [02:12<00:11,  1.84it/s]Loading trainS:  92%|█████████▏| 245/266 [02:13<00:10,  1.98it/s]Loading trainS:  92%|█████████▏| 246/266 [02:13<00:10,  1.94it/s]Loading trainS:  93%|█████████▎| 247/266 [02:14<00:10,  1.83it/s]Loading trainS:  93%|█████████▎| 248/266 [02:14<00:09,  1.81it/s]Loading trainS:  94%|█████████▎| 249/266 [02:15<00:10,  1.64it/s]Loading trainS:  94%|█████████▍| 250/266 [02:16<00:09,  1.65it/s]Loading trainS:  94%|█████████▍| 251/266 [02:16<00:09,  1.65it/s]Loading trainS:  95%|█████████▍| 252/266 [02:17<00:08,  1.72it/s]Loading trainS:  95%|█████████▌| 253/266 [02:18<00:07,  1.71it/s]Loading trainS:  95%|█████████▌| 254/266 [02:18<00:06,  1.77it/s]Loading trainS:  96%|█████████▌| 255/266 [02:19<00:06,  1.70it/s]Loading trainS:  96%|█████████▌| 256/266 [02:19<00:05,  1.73it/s]Loading trainS:  97%|█████████▋| 257/266 [02:20<00:05,  1.63it/s]Loading trainS:  97%|█████████▋| 258/266 [02:21<00:04,  1.64it/s]Loading trainS:  97%|█████████▋| 259/266 [02:21<00:04,  1.67it/s]Loading trainS:  98%|█████████▊| 260/266 [02:22<00:03,  1.70it/s]Loading trainS:  98%|█████████▊| 261/266 [02:22<00:03,  1.56it/s]Loading trainS:  98%|█████████▊| 262/266 [02:23<00:02,  1.57it/s]Loading trainS:  99%|█████████▉| 263/266 [02:24<00:01,  1.60it/s]Loading trainS:  99%|█████████▉| 264/266 [02:24<00:01,  1.69it/s]Loading trainS: 100%|█████████▉| 265/266 [02:25<00:00,  1.77it/s]Loading trainS: 100%|██████████| 266/266 [02:25<00:00,  1.74it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  1.87it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.89it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  1.87it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.80it/s]2019-07-29 03:28:16.827281: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 03:28:16.827369: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 03:28:16.827384: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 03:28:16.827392: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 03:28:16.827755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.19it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.15it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.84it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.46it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.01it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.99it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.37it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.22it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.13it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.89it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.31it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.26it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.00it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.29it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.12it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:03<00:00,  6.60it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  7.32it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.34it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.06it/s]
Epoch 00047: val_mDice did not improve from 0.64837
Restoring model weights from the end of the best epoch
Epoch 00047: early stopping
{'val_loss': [0.7396891022360088, 0.5803846298464087, 0.5153383640264044, 0.48434733949749675, 0.48604974525653766, 0.5373020681324384, 0.4700661739766203, 0.4787463056330649, 0.5610366207084908, 0.4898117389900005, 0.48980368802089563, 0.47908524645874834, 0.48207031417366686, 0.47357363614025494, 0.474646426194551, 0.48868948892252334, 0.4681386470005212, 4.832244355157511, 0.5073717497042473, 0.49430702972096324, 0.48056439887608915, 0.46593913100413137, 0.5039509803254083, 0.4762640405964378, 0.4675986123400808, 0.46677968320467617, 0.4802812333928039, 0.4763023955932516, 0.4794497596507041, 0.4789020857274138, 0.4578241994049375, 0.45994970182709344, 0.46837335351287135, 0.4678125113051459, 0.48085531730525544, 0.52148411921318, 0.4654122448914888, 0.47928745265038597, 0.4899411023847315, 0.5072210119260068, 0.4686736717129385, 0.45516211426021247, 0.4557789879918888, 0.4717719187799668, 0.47923732238100064, 0.47770721036077335, 0.46456201700185307], 'val_acc': [0.9412695303657986, 0.9340721313527088, 0.9450160201811633, 0.9487001378804643, 0.9450110927322842, 0.9437365334555013, 0.9521362335476654, 0.9512328505516052, 0.9484126911258066, 0.9497217630708454, 0.9513330534593949, 0.9489678476030463, 0.9500946078868892, 0.9510078220967425, 0.9511392329702314, 0.95026052511291, 0.9503689033306197, 0.9150537457687176, 0.9412103753216219, 0.9458717897238321, 0.949928719081626, 0.9514233789696599, 0.9481252641077863, 0.9500091896941331, 0.9500880288761973, 0.9494129877216768, 0.9474255608407077, 0.9496445509771637, 0.9475996644291657, 0.9508780908110915, 0.9497907469604189, 0.9512919704645675, 0.9481301895830015, 0.9484981089238299, 0.9492782981979926, 0.9445397005175913, 0.9502687067385541, 0.9481778073784531, 0.9481154068416318, 0.9443327622697842, 0.9485424417533622, 0.9495903585130805, 0.9487953864975481, 0.9492996378450205, 0.948475129162239, 0.9504017383847015, 0.9474518346470713], 'val_mDice': [0.533408864049722, 0.5851377319815932, 0.6244605345441806, 0.6412046634598284, 0.6344415691514679, 0.6153446554348169, 0.6483729114595628, 0.6411075986773762, 0.6008475624172893, 0.6335118353761584, 0.6346390144714457, 0.638569901321108, 0.6387322943731649, 0.6403258304722261, 0.6395951406845194, 0.6357688185394994, 0.6464911415087466, 0.26671156681926045, 0.621644708494477, 0.6264991515519603, 0.634906781430276, 0.642723674016283, 0.605906102041535, 0.6401222470580348, 0.6405555846675343, 0.6400927999951193, 0.6386884790382638, 0.6365387644988811, 0.6334545991278642, 0.6351417855711172, 0.6442820394275993, 0.6415321534832582, 0.6374599917834958, 0.6356843457316721, 0.6278527888241193, 0.6137375800025384, 0.63571756249232, 0.6280085701026664, 0.6177917616256815, 0.6176782562243228, 0.630352453680228, 0.6361209201496958, 0.635946270645849, 0.6278634268716471, 0.6234756171308606, 0.6286071428400002, 0.6260043343171379], 'loss': [1.483455938215439, 0.4809979580056209, 0.39616782920291793, 0.36281715677334714, 0.35912457896539796, 0.34005448480065054, 0.31967276979524356, 0.3134486344284736, 0.3019418160502727, 0.309986287727952, 0.28902164517113793, 0.27959565008775544, 0.27511792508168864, 0.2682322815347176, 0.26301270006940913, 0.260281694193299, 0.2552557327569677, 0.3220782499187268, 0.35559128138881463, 0.297860228528197, 0.27798921206536203, 0.2664646650306307, 0.29271314500902706, 0.2683771070666038, 0.2527933410153939, 0.2470284175271025, 0.2645077355062732, 0.24682650313927576, 0.2406178587474502, 0.23715418942559224, 0.2510425467044115, 0.23299329369687116, 0.2308195264150317, 0.22786129244531578, 0.22644850626014745, 0.22591550519260076, 0.2226947624809467, 0.2219053375749634, 0.22356074883674198, 0.24824558914853975, 0.23360913712531328, 0.2221118648035022, 0.21860120638918418, 0.21600561603330648, 0.2135927346893228, 0.2129125468289623, 0.21109202769226754], 'acc': [0.8225473845019363, 0.9293553023957289, 0.938948294864251, 0.9419330696646984, 0.942736069456889, 0.9439483631688815, 0.9455339258106855, 0.9465718974287693, 0.9471777451152985, 0.946086737112357, 0.9481476568258725, 0.9488877198443963, 0.9493355077619736, 0.9498437989789706, 0.950323567367517, 0.9506746295552987, 0.9511399893806531, 0.9451212653746972, 0.9418243923439429, 0.947166919708252, 0.9490729690744326, 0.9501385072676035, 0.9486421366723684, 0.9500450268387794, 0.9513905337796762, 0.9518710185702031, 0.9512887279001566, 0.9519120827317238, 0.9525600714752307, 0.9528900063954867, 0.9522001161598243, 0.9532067027802651, 0.9535328920644063, 0.953673283641155, 0.9538376425894407, 0.9538997875956389, 0.9542022954959136, 0.9542849757350408, 0.9544273700851661, 0.9521608619162669, 0.9531159850840385, 0.9540836298121855, 0.9545423861306447, 0.9547619785253818, 0.9549023193808702, 0.9549983544991567, 0.9551565867777054], 'mDice': [0.33645927417987526, 0.6074162053947265, 0.6597606502473354, 0.6824566186047517, 0.6890220215114263, 0.6987592758467565, 0.7130703370158489, 0.7218185474093144, 0.7285236297891691, 0.7204633229053937, 0.7360213682628595, 0.7431842638896062, 0.746558514638589, 0.7519571781158447, 0.7560720108449459, 0.7581294316511887, 0.762167460929889, 0.7219084091484547, 0.6879728906429731, 0.7294450032596405, 0.744763127886332, 0.7533305241511419, 0.7384953576211746, 0.7516751833833181, 0.7640344875936325, 0.7686831879501159, 0.7620950805453154, 0.7689535411504599, 0.7740207795913403, 0.7767202160679377, 0.7702532479396234, 0.7800782062113285, 0.7819675765931606, 0.78438725695014, 0.7855059487315325, 0.7861397025676874, 0.7886443699781711, 0.7892527918402965, 0.7905570750053112, 0.7714721844173394, 0.7795746512711048, 0.7890335788520483, 0.7920448075120265, 0.7941695669522653, 0.7961456853036697, 0.7967705637789689, 0.7982491678916491]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 108, 116, 40) 0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 108, 116, 40) 0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 108, 116, 41) 0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 108, 116, 20) 7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 108, 116, 20) 80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 108, 116, 20) 0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 108, 116, 20) 3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 108, 116, 20) 80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 108, 116, 20) 0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 54, 58, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 54, 58, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 54, 58, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 54, 58, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 54, 58, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 54, 58, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 54, 58, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 27, 29, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 27, 29, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 27, 29, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 27, 29, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 27, 29, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 27, 29, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 27, 29, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 27, 29, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 54, 58, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 54, 58, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 54, 58, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 54, 58, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 54, 58, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 54, 58, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 54, 58, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 20) 7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 108, 116, 20) 80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 108, 116, 20) 0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 108, 116, 20) 3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 108, 116, 20) 80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 108, 116, 20) 0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 108, 116, 60) 0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 108, 116, 60) 0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 108, 116, 40) 21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 108, 116, 40) 160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 108, 116, 40) 0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 108, 116, 40) 0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 108, 116, 40) 14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 108, 116, 40) 160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 108, 116, 40) 0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 108, 116, 40) 0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 108, 116, 100 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 108, 116, 2)  202         concatenate_8[0][0]              
==================================================================================================
Total params: 282,002
Trainable params: 107,002
Non-trainable params: 175,000
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 256 samples
Epoch 1/300
 - 73s - loss: 0.2681 - acc: 0.9624 - mDice: 0.6680 - val_loss: 0.4155 - val_acc: 0.9852 - val_mDice: 0.7096

Epoch 00001: val_mDice improved from -inf to 0.70965, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 68s - loss: 0.1008 - acc: 0.9897 - mDice: 0.8236 - val_loss: 0.3330 - val_acc: 0.9910 - val_mDice: 0.7918

Epoch 00002: val_mDice improved from 0.70965 to 0.79181, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 69s - loss: 0.0844 - acc: 0.9911 - mDice: 0.8495 - val_loss: 0.2985 - val_acc: 0.9912 - val_mDice: 0.7862

Epoch 00003: val_mDice did not improve from 0.79181
Epoch 4/300
 - 69s - loss: 0.0753 - acc: 0.9919 - mDice: 0.8644 - val_loss: 0.2446 - val_acc: 0.9928 - val_mDice: 0.8242

Epoch 00004: val_mDice improved from 0.79181 to 0.82420, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 68s - loss: 0.0697 - acc: 0.9924 - mDice: 0.8738 - val_loss: 0.2483 - val_acc: 0.9918 - val_mDice: 0.8137

Epoch 00005: val_mDice did not improve from 0.82420
Epoch 6/300
 - 69s - loss: 0.0651 - acc: 0.9928 - mDice: 0.8816 - val_loss: 0.2384 - val_acc: 0.9931 - val_mDice: 0.8241

Epoch 00006: val_mDice did not improve from 0.82420
Epoch 7/300
 - 67s - loss: 0.0630 - acc: 0.9930 - mDice: 0.8852 - val_loss: 0.3631 - val_acc: 0.9895 - val_mDice: 0.6831

Epoch 00007: val_mDice did not improve from 0.82420
Epoch 8/300
 - 67s - loss: 0.0597 - acc: 0.9933 - mDice: 0.8909 - val_loss: 0.2208 - val_acc: 0.9934 - val_mDice: 0.8371

Epoch 00008: val_mDice improved from 0.82420 to 0.83715, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 67s - loss: 0.0583 - acc: 0.9934 - mDice: 0.8933 - val_loss: 0.2225 - val_acc: 0.9928 - val_mDice: 0.8285

Epoch 00009: val_mDice did not improve from 0.83715
Epoch 10/300
 - 67s - loss: 0.0569 - acc: 0.9935 - mDice: 0.8956 - val_loss: 0.2091 - val_acc: 0.9937 - val_mDice: 0.8424

Epoch 00010: val_mDice improved from 0.83715 to 0.84237, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 68s - loss: 0.0549 - acc: 0.9937 - mDice: 0.8991 - val_loss: 0.2132 - val_acc: 0.9929 - val_mDice: 0.8329

Epoch 00011: val_mDice did not improve from 0.84237
Epoch 12/300
 - 70s - loss: 0.0538 - acc: 0.9938 - mDice: 0.9011 - val_loss: 0.2198 - val_acc: 0.9932 - val_mDice: 0.8357

Epoch 00012: val_mDice did not improve from 0.84237
Epoch 13/300
 - 70s - loss: 0.0523 - acc: 0.9939 - mDice: 0.9036 - val_loss: 0.3942 - val_acc: 0.9890 - val_mDice: 0.6309

Epoch 00013: val_mDice did not improve from 0.84237
Epoch 14/300
 - 70s - loss: 0.0519 - acc: 0.9940 - mDice: 0.9044 - val_loss: 0.3590 - val_acc: 0.9898 - val_mDice: 0.7874

Epoch 00014: val_mDice did not improve from 0.84237
Epoch 15/300
 - 69s - loss: 0.0506 - acc: 0.9941 - mDice: 0.9067 - val_loss: 0.1838 - val_acc: 0.9935 - val_mDice: 0.8405

Epoch 00015: val_mDice did not improve from 0.84237
Epoch 16/300
 - 69s - loss: 0.0495 - acc: 0.9942 - mDice: 0.9085 - val_loss: 0.2018 - val_acc: 0.9934 - val_mDice: 0.8324

Epoch 00016: val_mDice did not improve from 0.84237
Epoch 17/300
 - 70s - loss: 0.0490 - acc: 0.9943 - mDice: 0.9094 - val_loss: 0.2091 - val_acc: 0.9931 - val_mDice: 0.8290

Epoch 00017: val_mDice did not improve from 0.84237
Epoch 18/300
 - 69s - loss: 0.0481 - acc: 0.9944 - mDice: 0.9109 - val_loss: 0.1925 - val_acc: 0.9930 - val_mDice: 0.8320

Epoch 00018: val_mDice did not improve from 0.84237
Epoch 19/300
 - 70s - loss: 0.0482 - acc: 0.9944 - mDice: 0.9109 - val_loss: 0.2349 - val_acc: 0.9921 - val_mDice: 0.7743

Epoch 00019: val_mDice did not improve from 0.84237
Epoch 20/300
 - 69s - loss: 0.0477 - acc: 0.9944 - mDice: 0.9118 - val_loss: 0.2083 - val_acc: 0.9925 - val_mDice: 0.7985

Epoch 00020: val_mDice did not improve from 0.84237
Epoch 21/300
 - 70s - loss: 0.0463 - acc: 0.9945 - mDice: 0.9141 - val_loss: 0.1861 - val_acc: 0.9933 - val_mDice: 0.8312

Epoch 00021: val_mDice did not improve from 0.84237
Epoch 22/300
 - 69s - loss: 0.0458 - acc: 0.9946 - mDice: 0.9150 - val_loss: 0.1803 - val_acc: 0.9933 - val_mDice: 0.8395

Epoch 00022: val_mDice did not improve from 0.84237
Epoch 23/300
 - 70s - loss: 0.0456 - acc: 0.9946 - mDice: 0.9154 - val_loss: 0.4592 - val_acc: 0.9796 - val_mDice: 0.6692

Epoch 00023: val_mDice did not improve from 0.84237
Epoch 24/300
 - 69s - loss: 0.0450 - acc: 0.9947 - mDice: 0.9164 - val_loss: 0.1826 - val_acc: 0.9934 - val_mDice: 0.8368

Epoch 00024: val_mDice did not improve from 0.84237
Epoch 25/300
 - 70s - loss: 0.0442 - acc: 0.9948 - mDice: 0.9178 - val_loss: 0.1794 - val_acc: 0.9938 - val_mDice: 0.8393

Epoch 00025: val_mDice did not improve from 0.84237
Epoch 26/300
 - 70s - loss: 0.0436 - acc: 0.9948 - mDice: 0.9189 - val_loss: 0.1797 - val_acc: 0.9922 - val_mDice: 0.8253

Epoch 00026: val_mDice did not improve from 0.84237
Epoch 27/300
 - 70s - loss: 0.0435 - acc: 0.9948 - mDice: 0.9191 - val_loss: 0.1856 - val_acc: 0.9933 - val_mDice: 0.8220

Epoch 00027: val_mDice did not improve from 0.84237
Epoch 28/300
 - 70s - loss: 0.0432 - acc: 0.9948 - mDice: 0.9198 - val_loss: 0.1841 - val_acc: 0.9932 - val_mDice: 0.8241

Epoch 00028: val_mDice did not improve from 0.84237
Epoch 29/300
 - 70s - loss: 0.0429 - acc: 0.9949 - mDice: 0.9202 - val_loss: 0.1728 - val_acc: 0.9930 - val_mDice: 0.8382

Epoch 00029: val_mDice did not improve from 0.84237
Epoch 30/300
 - 69s - loss: 0.0427 - acc: 0.9949 - mDice: 0.9205 - val_loss: 0.1600 - val_acc: 0.9936 - val_mDice: 0.8415

Epoch 00030: val_mDice did not improve from 0.84237
Epoch 31/300
 - 69s - loss: 0.0423 - acc: 0.9950 - mDice: 0.9213 - val_loss: 0.1553 - val_acc: 0.9930 - val_mDice: 0.8381

Epoch 00031: val_mDice did not improve from 0.84237
Epoch 32/300
 - 68s - loss: 0.0413 - acc: 0.9951 - mDice: 0.9231 - val_loss: 0.1714 - val_acc: 0.9933 - val_mDice: 0.8392

Epoch 00032: val_mDice did not improve from 0.84237
Epoch 33/300
 - 69s - loss: 0.0412 - acc: 0.9950 - mDice: 0.9232 - val_loss: 0.1627 - val_acc: 0.9937 - val_mDice: 0.8358

Epoch 00033: val_mDice did not improve from 0.84237
Epoch 34/300
 - 68s - loss: 0.0406 - acc: 0.9951 - mDice: 0.9243 - val_loss: 0.1492 - val_acc: 0.9938 - val_mDice: 0.8465

Epoch 00034: val_mDice improved from 0.84237 to 0.84652, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 35/300
 - 67s - loss: 0.0408 - acc: 0.9951 - mDice: 0.9239 - val_loss: 0.1557 - val_acc: 0.9933 - val_mDice: 0.8405

Epoch 00035: val_mDice did not improve from 0.84652
Epoch 36/300
 - 67s - loss: 0.0403 - acc: 0.9952 - mDice: 0.9248 - val_loss: 0.1703 - val_acc: 0.9930 - val_mDice: 0.8130

Epoch 00036: val_mDice did not improve from 0.84652
Epoch 37/300
 - 67s - loss: 0.0398 - acc: 0.9952 - mDice: 0.9257 - val_loss: 0.1398 - val_acc: 0.9936 - val_mDice: 0.8426

Epoch 00037: val_mDice did not improve from 0.84652
Epoch 38/300
 - 67s - loss: 0.0392 - acc: 0.9952 - mDice: 0.9269 - val_loss: 0.1414 - val_acc: 0.9935 - val_mDice: 0.8322

Epoch 00038: val_mDice did not improve from 0.84652
Epoch 39/300
 - 67s - loss: 0.0395 - acc: 0.9952 - mDice: 0.9263 - val_loss: 0.1434 - val_acc: 0.9936 - val_mDice: 0.8459

Epoch 00039: val_mDice did not improve from 0.84652
Epoch 40/300
 - 67s - loss: 0.0396 - acc: 0.9952 - mDice: 0.9261 - val_loss: 0.1702 - val_acc: 0.9927 - val_mDice: 0.8092

Epoch 00040: val_mDice did not improve from 0.84652
Epoch 41/300
 - 67s - loss: 0.0390 - acc: 0.9953 - mDice: 0.9271 - val_loss: 0.1338 - val_acc: 0.9937 - val_mDice: 0.8433

Epoch 00041: val_mDice did not improve from 0.84652
Epoch 42/300
 - 67s - loss: 0.0385 - acc: 0.9953 - mDice: 0.9280 - val_loss: 0.1553 - val_acc: 0.9940 - val_mDice: 0.8431

Epoch 00042: val_mDice did not improve from 0.84652
Epoch 43/300
 - 69s - loss: 0.0383 - acc: 0.9953 - mDice: 0.9285 - val_loss: 0.1265 - val_acc: 0.9939 - val_mDice: 0.8478

Epoch 00043: val_mDice improved from 0.84652 to 0.84780, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 69s - loss: 0.0380 - acc: 0.9953 - mDice: 0.9290 - val_loss: 0.3331 - val_acc: 0.9901 - val_mDice: 0.7936

Epoch 00044: val_mDice did not improve from 0.84780
Epoch 45/300
 - 70s - loss: 0.0375 - acc: 0.9954 - mDice: 0.9299 - val_loss: 0.1270 - val_acc: 0.9938 - val_mDice: 0.8385

Epoch 00045: val_mDice did not improve from 0.84780
Epoch 46/300
 - 69s - loss: 0.0376 - acc: 0.9954 - mDice: 0.9297 - val_loss: 0.1517 - val_acc: 0.9923 - val_mDice: 0.8266

Epoch 00046: val_mDice did not improve from 0.84780
Epoch 47/300
 - 70s - loss: 0.0374 - acc: 0.9954 - mDice: 0.9301 - val_loss: 0.1148 - val_acc: 0.9938 - val_mDice: 0.8442

Epoch 00047: val_mDice did not improve from 0.84780
Epoch 48/300
 - 69s - loss: 0.0370 - acc: 0.9954 - mDice: 0.9308 - val_loss: 0.1422 - val_acc: 0.9931 - val_mDice: 0.8344

Epoch 00048: val_mDice did not improve from 0.84780
Epoch 49/300
 - 69s - loss: 0.0373 - acc: 0.9954 - mDice: 0.9302 - val_loss: 0.1416 - val_acc: 0.9929 - val_mDice: 0.8372

Epoch 00049: val_mDice did not improve from 0.84780
Epoch 50/300
 - 69s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.1404 - val_acc: 0.9927 - val_mDice: 0.8296

Epoch 00050: val_mDice did not improve from 0.84780
Epoch 51/300
 - 69s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9312 - val_loss: 0.1134 - val_acc: 0.9934 - val_mDice: 0.8411

Epoch 00051: val_mDice did not improve from 0.84780
Epoch 52/300
 - 69s - loss: 0.0368 - acc: 0.9955 - mDice: 0.9311 - val_loss: 0.1341 - val_acc: 0.9932 - val_mDice: 0.8374

Epoch 00052: val_mDice did not improve from 0.84780
Epoch 53/300
 - 70s - loss: 0.0366 - acc: 0.9955 - mDice: 0.9315 - val_loss: 0.1275 - val_acc: 0.9932 - val_mDice: 0.8395

Epoch 00053: val_mDice did not improve from 0.84780
Epoch 54/300
 - 69s - loss: 0.0365 - acc: 0.9955 - mDice: 0.9317 - val_loss: 0.1381 - val_acc: 0.9935 - val_mDice: 0.8422

Epoch 00054: val_mDice did not improve from 0.84780
Epoch 55/300
 - 70s - loss: 0.0367 - acc: 0.9955 - mDice: 0.9313 - val_loss: 0.1294 - val_acc: 0.9931 - val_mDice: 0.8324

Epoch 00055: val_mDice did not improve from 0.84780
Epoch 56/300
 - 69s - loss: 0.0360 - acc: 0.9955 - mDice: 0.9326 - val_loss: 0.1224 - val_acc: 0.9935 - val_mDice: 0.8360

Epoch 00056: val_mDice did not improve from 0.84780
Epoch 57/300
 - 70s - loss: 0.0359 - acc: 0.9956 - mDice: 0.9327 - val_loss: 0.1260 - val_acc: 0.9936 - val_mDice: 0.8418

Epoch 00057: val_mDice did not improve from 0.84780
Epoch 58/300
 - 69s - loss: 0.0362 - acc: 0.9955 - mDice: 0.9322 - val_loss: 0.1106 - val_acc: 0.9937 - val_mDice: 0.8415

Epoch 00058: val_mDice did not improve from 0.84780
Epoch 59/300
 - 70s - loss: 0.0355 - acc: 0.9956 - mDice: 0.9334 - val_loss: 0.1274 - val_acc: 0.9928 - val_mDice: 0.8153

Epoch 00059: val_mDice did not improve from 0.84780
Epoch 60/300
 - 70s - loss: 0.0355 - acc: 0.9956 - mDice: 0.9335 - val_loss: 0.0940 - val_acc: 0.9934 - val_mDice: 0.8385

Epoch 00060: val_mDice did not improve from 0.84780
Epoch 61/300
 - 69s - loss: 0.0353 - acc: 0.9956 - mDice: 0.9339 - val_loss: 0.1098 - val_acc: 0.9937 - val_mDice: 0.8388

Epoch 00061: val_mDice did not improve from 0.84780
Epoch 62/300
 - 69s - loss: 0.0353 - acc: 0.9956 - mDice: 0.9339 - val_loss: 0.1213 - val_acc: 0.9935 - val_mDice: 0.8383

Epoch 00062: val_mDice did not improve from 0.84780
Epoch 63/300
 - 69s - loss: 0.0353 - acc: 0.9956 - mDice: 0.9339 - val_loss: 0.1094 - val_acc: 0.9937 - val_mDice: 0.8371

Epoch 00063: val_mDice did not improve from 0.84780
Epoch 64/300
 - 69s - loss: 0.0351 - acc: 0.9956 - mDice: 0.9342 - val_loss: 0.1044 - val_acc: 0.9934 - val_mDice: 0.8355

Epoch 00064: val_mDice did not improve from 0.84780
Epoch 65/300
 - 70s - loss: 0.0351 - acc: 0.9956 - mDice: 0.9342 - val_loss: 0.1694 - val_acc: 0.9913 - val_mDice: 0.7501

Epoch 00065: val_mDice did not improve from 0.84780
Epoch 66/300
 - 70s - loss: 0.0348 - acc: 0.9957 - mDice: 0.9349 - val_loss: 0.1080 - val_acc: 0.9936 - val_mDice: 0.8427

Epoch 00066: val_mDice did not improve from 0.84780
Epoch 67/300
 - 70s - loss: 0.0348 - acc: 0.9957 - mDice: 0.9347 - val_loss: 0.1088 - val_acc: 0.9936 - val_mDice: 0.8395

Epoch 00067: val_mDice did not improve from 0.84780
Epoch 68/300
 - 70s - loss: 0.0346 - acc: 0.9957 - mDice: 0.9352 - val_loss: 0.1091 - val_acc: 0.9933 - val_mDice: 0.8395

Epoch 00068: val_mDice did not improve from 0.84780
Epoch 69/300
 - 70s - loss: 0.0347 - acc: 0.9957 - mDice: 0.9349 - val_loss: 0.0966 - val_acc: 0.9935 - val_mDice: 0.8384

Epoch 00069: val_mDice did not improve from 0.84780
Epoch 70/300
 - 69s - loss: 0.0341 - acc: 0.9957 - mDice: 0.9362 - val_loss: 0.1232 - val_acc: 0.9933 - val_mDice: 0.8350

Epoch 00070: val_mDice did not improve from 0.84780
Epoch 71/300
 - 70s - loss: 0.0346 - acc: 0.9957 - mDice: 0.9352 - val_loss: 0.1125 - val_acc: 0.9930 - val_mDice: 0.8180

Epoch 00071: val_mDice did not improve from 0.84780
Epoch 72/300
 - 69s - loss: 0.0340 - acc: 0.9958 - mDice: 0.9363 - val_loss: 0.1212 - val_acc: 0.9936 - val_mDice: 0.8398

Epoch 00072: val_mDice did not improve from 0.84780
Epoch 73/300
 - 70s - loss: 0.0344 - acc: 0.9957 - mDice: 0.9355 - val_loss: 0.0909 - val_acc: 0.9938 - val_mDice: 0.8435

Epoch 00073: val_mDice did not improve from 0.84780
Epoch 74/300
 - 69s - loss: 0.0340 - acc: 0.9957 - mDice: 0.9363 - val_loss: 0.2672 - val_acc: 0.9927 - val_mDice: 0.8260

Epoch 00074: val_mDice did not improve from 0.84780
Epoch 75/300
 - 71s - loss: 0.0342 - acc: 0.9957 - mDice: 0.9359 - val_loss: 0.1175 - val_acc: 0.9926 - val_mDice: 0.8290

Epoch 00075: val_mDice did not improve from 0.84780
Epoch 76/300
 - 70s - loss: 0.0343 - acc: 0.9957 - mDice: 0.9358 - val_loss: 0.1198 - val_acc: 0.9925 - val_mDice: 0.7991

Epoch 00076: val_mDice did not improve from 0.84780
Epoch 77/300
 - 71s - loss: 0.0337 - acc: 0.9958 - mDice: 0.9368 - val_loss: 0.0883 - val_acc: 0.9938 - val_mDice: 0.8454

Epoch 00077: val_mDice did not improve from 0.84780
Epoch 78/300
 - 71s - loss: 0.0338 - acc: 0.9958 - mDice: 0.9367 - val_loss: 0.1265 - val_acc: 0.9923 - val_mDice: 0.7898

Epoch 00078: val_mDice did not improve from 0.84780
Epoch 79/300
 - 71s - loss: 0.0338 - acc: 0.9958 - mDice: 0.9366 - val_loss: 0.0927 - val_acc: 0.9934 - val_mDice: 0.8298

Epoch 00079: val_mDice did not improve from 0.84780
Epoch 80/300
 - 71s - loss: 0.0337 - acc: 0.9958 - mDice: 0.9368 - val_loss: 0.2636 - val_acc: 0.9929 - val_mDice: 0.8338

Epoch 00080: val_mDice did not improve from 0.84780
Epoch 81/300
 - 71s - loss: 0.0338 - acc: 0.9958 - mDice: 0.9366 - val_loss: 0.0991 - val_acc: 0.9928 - val_mDice: 0.8296

Epoch 00081: val_mDice did not improve from 0.84780
Epoch 82/300
 - 71s - loss: 0.0334 - acc: 0.9958 - mDice: 0.9373 - val_loss: 0.0839 - val_acc: 0.9925 - val_mDice: 0.8277

Epoch 00082: val_mDice did not improve from 0.84780
Epoch 83/300
 - 70s - loss: 0.0333 - acc: 0.9958 - mDice: 0.9376 - val_loss: 0.0751 - val_acc: 0.9938 - val_mDice: 0.8414

Epoch 00083: val_mDice did not improve from 0.84780
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [0.4154813709901646, 0.3330196639872156, 0.2985261506983079, 0.24456281881430186, 0.24825575659633614, 0.23835278768092394, 0.36307987678446807, 0.2208326720574405, 0.22245999169535935, 0.20906319070491008, 0.2132171163102612, 0.21982546473736875, 0.39418171034776606, 0.35901701549300924, 0.18384299869649112, 0.20180696577881463, 0.20914601723779924, 0.1925382245099172, 0.2349028700555209, 0.208324933599215, 0.18613121574162506, 0.180266807845328, 0.45919189642881975, 0.18260041443863884, 0.17941458532004617, 0.1796740132267587, 0.1856210926489439, 0.184147390013095, 0.17279450056958012, 0.15998952637892216, 0.15533373053767718, 0.17144023542641662, 0.16268047684570774, 0.1491543141019065, 0.1556872020009905, 0.17034501960733905, 0.1398293168458622, 0.14141057920642197, 0.14344636275200173, 0.17017497119377367, 0.13378953214851208, 0.1553138159797527, 0.12650270597077906, 0.3330845691380091, 0.12704207241768017, 0.15170574671356007, 0.1147693763487041, 0.1422335798270069, 0.14157210153643973, 0.14039789940579794, 0.11340824331273325, 0.13409652819973417, 0.1274658688926138, 0.13814743084367365, 0.1293925428763032, 0.12239218849572353, 0.1260313572420273, 0.1106473874533549, 0.12739853499806486, 0.09396025855676271, 0.10975531316944398, 0.12134045222774148, 0.10937417348031886, 0.1044314261234831, 0.16941429895814508, 0.10801180667476729, 0.10878367823897861, 0.10911526507698, 0.09660801480640657, 0.12320400186581537, 0.11249071758356877, 0.12115587893640622, 0.09090351869235747, 0.2671913994126953, 0.11750154834589921, 0.11976830620551482, 0.08834684058092535, 0.12651193141937256, 0.09272947613499127, 0.2636171803751495, 0.09906662107096054, 0.08393856209295336, 0.07510832491243491], 'val_acc': [0.9852492827922106, 0.9909811359830201, 0.99117850093171, 0.992757779546082, 0.9917687498964369, 0.9931076308712363, 0.9894901062361896, 0.9934406252577901, 0.9928354169242084, 0.9937019078060985, 0.9928934150375426, 0.99317527981475, 0.9889681464992464, 0.9897576244547963, 0.9934799154289067, 0.993441253900528, 0.9931066995486617, 0.993029038887471, 0.9920786824077368, 0.9925473239272833, 0.9933349317871034, 0.993303744122386, 0.9795819725841284, 0.9934138264507055, 0.993764900136739, 0.9921594397164881, 0.9932519975118339, 0.9932211241684854, 0.9929707380943, 0.9936370644718409, 0.9930128338746727, 0.9932641396299005, 0.9937031767331064, 0.9938288237899542, 0.9933411600068212, 0.9930499587208033, 0.9936267966404557, 0.9935011146590114, 0.9935775063931942, 0.9927306664176285, 0.9937315355055034, 0.9939819215796888, 0.9939289060421288, 0.9900750457309186, 0.9938176013529301, 0.9922779272310436, 0.9937929678708315, 0.9930829857476056, 0.9928650329820812, 0.99270603293553, 0.9934456194750965, 0.9931871308945119, 0.9932292266748846, 0.9935213942080736, 0.9930739519186318, 0.9934970634058118, 0.9936411157250404, 0.9937075423076749, 0.9928385484963655, 0.9934175633825362, 0.9936523381620646, 0.9935213942080736, 0.9936785432510078, 0.9933633022010326, 0.9912979314103723, 0.9935856205411255, 0.9936142936348915, 0.9933078070171177, 0.9934690073132515, 0.9933396116830409, 0.9929819605313241, 0.9936373787932098, 0.9937624204903841, 0.9926913701929152, 0.9926311895251274, 0.992457521148026, 0.9937558663077652, 0.9923437251709402, 0.9934004154056311, 0.9928952963091433, 0.9927521799691021, 0.9925479525700212, 0.9938222812488675], 'val_mDice': [0.70964558981359, 0.791810848750174, 0.7861721096560359, 0.8242024458013475, 0.8137020748108625, 0.8241113158874214, 0.6830862374044955, 0.8371477597393095, 0.8284585317596793, 0.8423726423643529, 0.8328795549459755, 0.8356754435226321, 0.630934617947787, 0.7874034577980638, 0.8405001717619598, 0.8324035326950252, 0.8290094789117575, 0.8319903165102005, 0.7742598769254982, 0.7984605501405895, 0.8312071673572063, 0.8394950535148382, 0.6692276569083333, 0.8367643342353404, 0.8393344236537814, 0.8253499399870634, 0.8220064337365329, 0.8240885916166008, 0.8382208063267171, 0.8415166405029595, 0.8381323190405965, 0.8392435032874346, 0.8358343271538615, 0.8465205202810466, 0.8404833730310202, 0.8129557594656944, 0.8425605832599103, 0.8321873843669891, 0.8458719705231488, 0.8092299103736877, 0.8432782720774412, 0.8430602727457881, 0.8478006348013878, 0.793641374912113, 0.8385416585952044, 0.8265816373750567, 0.8441656711511314, 0.8344203699380159, 0.8371622767299414, 0.8295656531117857, 0.8411156595684588, 0.837401207536459, 0.8394510950893164, 0.8421763661317527, 0.8324307622388005, 0.8360293693840504, 0.8417697390541434, 0.8414667681790888, 0.8153358940035105, 0.8385425666347146, 0.8388269576244056, 0.8382640313357115, 0.8370936149731278, 0.8355473284609616, 0.7500567357055843, 0.8426738902926445, 0.8394649135880172, 0.8395134820602834, 0.8384039159864187, 0.8350131218321621, 0.8180445642210543, 0.8397605270147324, 0.8435360505245626, 0.8260133094154298, 0.8290242869406939, 0.7991294609382749, 0.8453803020529449, 0.7897713920101523, 0.8297737571410835, 0.8338059182278812, 0.8295804029330611, 0.8276925422251225, 0.8414134266786277], 'loss': [0.26809936190445804, 0.10079065901613048, 0.08443257531627928, 0.07533046431372885, 0.06973070198388913, 0.06508488425071943, 0.06298886966538081, 0.05966486385068551, 0.058266126039680656, 0.056911144839290044, 0.05491718178998237, 0.05375435386353826, 0.05232203519940238, 0.051876746070891204, 0.05056141341691359, 0.04952643956135094, 0.049026411833927384, 0.048143665347712736, 0.04815077106930957, 0.047665156786749555, 0.04634529744626906, 0.04581390217680666, 0.045578252309458285, 0.04502083515579365, 0.04423544629373845, 0.04361962374380702, 0.0435488396255507, 0.04315761357448035, 0.04291496218848799, 0.04274162314758631, 0.042282889239715966, 0.041282657249953475, 0.04123369698769036, 0.040640715598814214, 0.04082477347111818, 0.04033590805820365, 0.039822374003626294, 0.039167468258930346, 0.03951320056994507, 0.03958667526126559, 0.039037754888173126, 0.03854277913482559, 0.03826891659086273, 0.038007491746160145, 0.037495801590172705, 0.037626145406042616, 0.03738316667601735, 0.03701690818014648, 0.03732423401526753, 0.03684495539650402, 0.03677715508472224, 0.03683945717684128, 0.036633087847993406, 0.0365015173704644, 0.036742516730659806, 0.03603996191573286, 0.035940805254663144, 0.03621218091588278, 0.035544011490407604, 0.03549197864770349, 0.0352733859966995, 0.03531164910453419, 0.035296553142296946, 0.03511312376697837, 0.03512699809412314, 0.03476896545993329, 0.03484658560015203, 0.03458373994067999, 0.03472942695133297, 0.03405964322192537, 0.034552576426778905, 0.033961803406828424, 0.03439254983346353, 0.03396544179164866, 0.03417286554147374, 0.03425598808024193, 0.033713902651820435, 0.033766708041262, 0.03379123743618734, 0.03372323629871033, 0.03381293615930287, 0.033433694794749814, 0.03328414046683523], 'acc': [0.9624209207560219, 0.9897108554106023, 0.9910981874301401, 0.9918723382904954, 0.9923760550728766, 0.9927956896181706, 0.9929810441563849, 0.9932646744824929, 0.993414629277167, 0.9935487366116004, 0.993723843209043, 0.99384003226677, 0.9939426480996646, 0.9940206291535126, 0.994116453782626, 0.9942309539520575, 0.9942851287639694, 0.9943697612446554, 0.9943677317366252, 0.9944294041023307, 0.994527237685671, 0.9945911261502688, 0.9946240648251593, 0.9946646059004012, 0.9947502145690205, 0.9947824140964546, 0.9948159752787371, 0.9948433438036601, 0.9948823184547101, 0.9949093280429138, 0.9949592630442419, 0.9950542682635738, 0.9950460962984944, 0.9950933557527882, 0.9951164953257406, 0.9951586811346114, 0.9951768817975849, 0.9952412716073968, 0.9952221391050605, 0.9951973079222343, 0.9952644239780004, 0.9953087775206142, 0.9953113361228783, 0.9953463870611731, 0.9953972833406167, 0.9954009504147602, 0.9954284260507603, 0.9954453374127056, 0.9954205397960131, 0.9954793168731969, 0.9954653783751459, 0.9954673865052817, 0.9954932651287645, 0.995503369878501, 0.9955054962622575, 0.995529525645923, 0.9955500438471795, 0.9955306436190888, 0.9955904523199189, 0.9956146560785066, 0.9956103204517425, 0.995613255836801, 0.9956184129508874, 0.9956284519395333, 0.9956337419123521, 0.9956531583521858, 0.9956590245170877, 0.9956860201788431, 0.9956884063798487, 0.9957261660158032, 0.9957109717967079, 0.995751968102684, 0.9956990007920951, 0.9957430364640454, 0.9957100498602893, 0.9957065989265628, 0.9957670969069454, 0.9957666078953983, 0.9957593215790251, 0.9957693087330288, 0.9957679408455582, 0.9958077100659269, 0.9957879915862905], 'mDice': [0.6679604390526366, 0.82361300059197, 0.8494575401763543, 0.8643589065412036, 0.873755015852671, 0.881613219789862, 0.8851795950126493, 0.8908700901857857, 0.8933222374254588, 0.8956366168423592, 0.8991058814936957, 0.9011059235692703, 0.9035906540720087, 0.9043802997231332, 0.9066769279807069, 0.9084910320545914, 0.9093588065973651, 0.9109193013148453, 0.9108926892086675, 0.9117636800754135, 0.9141093873598164, 0.9150348302932155, 0.91544973608563, 0.9164378410212819, 0.9178326105883109, 0.9189412461640708, 0.9190541586837688, 0.9197556930883596, 0.9201873742191997, 0.9205033476931356, 0.9213233246916301, 0.9230992603526377, 0.9232054504074535, 0.9242584796626074, 0.9239299482233893, 0.9248116194156178, 0.925712832538068, 0.9268984993091094, 0.9262867682595363, 0.9261469407836167, 0.9271257136623466, 0.9280349760156926, 0.9285292463448317, 0.9289917373914841, 0.9299147230165822, 0.9296698729668094, 0.9301208482603586, 0.9307841379717001, 0.9302148979979137, 0.9310877663036305, 0.931210492516528, 0.9310942249762357, 0.9314714519490317, 0.9317094251726429, 0.9312748642101845, 0.9325522016021894, 0.9327283864848439, 0.9322431434512457, 0.9334434385885272, 0.9335386149487429, 0.9339456176929556, 0.9338700605821039, 0.93389619490238, 0.9342323337488229, 0.9342055403702875, 0.9348661768681582, 0.9347172185866913, 0.9351921904733874, 0.9349277368666085, 0.9361524492713429, 0.935248000129834, 0.9363271799377826, 0.9355433407984393, 0.9363189162700534, 0.9359463186190354, 0.935800066722233, 0.9367752790354098, 0.9366779177394134, 0.9366406422535606, 0.9367569700633107, 0.9365944129755595, 0.9372876717596363, 0.9375640846606232]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:03,  1.13s/it]predicting test subjects:  50%|█████     | 2/4 [00:01<00:01,  1.13it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  1.42it/s]predicting test subjects: 100%|██████████| 4/4 [00:02<00:00,  1.73it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:44,  2.53it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:42,  2.58it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:39,  2.64it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:37,  2.68it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:37,  2.69it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:39,  2.61it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:44,  2.48it/s]predicting train subjects:   3%|▎         | 8/266 [00:03<01:43,  2.49it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:40,  2.56it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:38,  2.60it/s]predicting train subjects:   4%|▍         | 11/266 [00:04<01:37,  2.61it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:36,  2.64it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:34,  2.69it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:37,  2.59it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:37,  2.58it/s]predicting train subjects:   6%|▌         | 16/266 [00:06<01:35,  2.62it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:33,  2.67it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:30,  2.74it/s]predicting train subjects:   7%|▋         | 19/266 [00:07<01:29,  2.75it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:28,  2.78it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:27,  2.80it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:26,  2.82it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:26,  2.82it/s]predicting train subjects:   9%|▉         | 24/266 [00:08<01:24,  2.85it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:24,  2.85it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:26,  2.79it/s]predicting train subjects:  10%|█         | 27/266 [00:10<01:25,  2.79it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:24,  2.83it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:25,  2.76it/s]predicting train subjects:  11%|█▏        | 30/266 [00:11<01:28,  2.67it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:25,  2.75it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:23,  2.80it/s]predicting train subjects:  12%|█▏        | 33/266 [00:12<01:21,  2.87it/s]predicting train subjects:  13%|█▎        | 34/266 [00:12<01:20,  2.87it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:21,  2.82it/s]predicting train subjects:  14%|█▎        | 36/266 [00:13<01:21,  2.82it/s]predicting train subjects:  14%|█▍        | 37/266 [00:13<01:23,  2.73it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:22,  2.76it/s]predicting train subjects:  15%|█▍        | 39/266 [00:14<01:24,  2.69it/s]predicting train subjects:  15%|█▌        | 40/266 [00:14<01:22,  2.72it/s]predicting train subjects:  15%|█▌        | 41/266 [00:15<01:21,  2.76it/s]predicting train subjects:  16%|█▌        | 42/266 [00:15<01:14,  2.99it/s]predicting train subjects:  16%|█▌        | 43/266 [00:15<01:12,  3.06it/s]predicting train subjects:  17%|█▋        | 44/266 [00:15<01:09,  3.18it/s]predicting train subjects:  17%|█▋        | 45/266 [00:16<01:08,  3.24it/s]predicting train subjects:  17%|█▋        | 46/266 [00:16<01:09,  3.16it/s]predicting train subjects:  18%|█▊        | 47/266 [00:16<01:08,  3.20it/s]predicting train subjects:  18%|█▊        | 48/266 [00:17<01:07,  3.24it/s]predicting train subjects:  18%|█▊        | 49/266 [00:17<01:04,  3.34it/s]predicting train subjects:  19%|█▉        | 50/266 [00:17<01:05,  3.28it/s]predicting train subjects:  19%|█▉        | 51/266 [00:18<01:03,  3.37it/s]predicting train subjects:  20%|█▉        | 52/266 [00:18<01:04,  3.31it/s]predicting train subjects:  20%|█▉        | 53/266 [00:18<01:05,  3.26it/s]predicting train subjects:  20%|██        | 54/266 [00:18<01:02,  3.40it/s]predicting train subjects:  21%|██        | 55/266 [00:19<01:00,  3.46it/s]predicting train subjects:  21%|██        | 56/266 [00:19<01:00,  3.49it/s]predicting train subjects:  21%|██▏       | 57/266 [00:19<00:59,  3.53it/s]predicting train subjects:  22%|██▏       | 58/266 [00:20<00:58,  3.53it/s]predicting train subjects:  22%|██▏       | 59/266 [00:20<00:57,  3.59it/s]predicting train subjects:  23%|██▎       | 60/266 [00:20<00:58,  3.53it/s]predicting train subjects:  23%|██▎       | 61/266 [00:20<00:57,  3.57it/s]predicting train subjects:  23%|██▎       | 62/266 [00:21<00:56,  3.62it/s]predicting train subjects:  24%|██▎       | 63/266 [00:21<00:56,  3.62it/s]predicting train subjects:  24%|██▍       | 64/266 [00:21<00:54,  3.69it/s]predicting train subjects:  24%|██▍       | 65/266 [00:21<00:53,  3.72it/s]predicting train subjects:  25%|██▍       | 66/266 [00:22<00:54,  3.64it/s]predicting train subjects:  25%|██▌       | 67/266 [00:22<00:54,  3.68it/s]predicting train subjects:  26%|██▌       | 68/266 [00:22<00:53,  3.71it/s]predicting train subjects:  26%|██▌       | 69/266 [00:23<00:52,  3.73it/s]predicting train subjects:  26%|██▋       | 70/266 [00:23<00:54,  3.63it/s]predicting train subjects:  27%|██▋       | 71/266 [00:23<00:53,  3.68it/s]predicting train subjects:  27%|██▋       | 72/266 [00:23<00:52,  3.73it/s]predicting train subjects:  27%|██▋       | 73/266 [00:24<00:51,  3.76it/s]predicting train subjects:  28%|██▊       | 74/266 [00:24<00:50,  3.77it/s]predicting train subjects:  28%|██▊       | 75/266 [00:24<00:50,  3.77it/s]predicting train subjects:  29%|██▊       | 76/266 [00:24<00:51,  3.72it/s]predicting train subjects:  29%|██▉       | 77/266 [00:25<00:50,  3.72it/s]predicting train subjects:  29%|██▉       | 78/266 [00:25<00:54,  3.45it/s]predicting train subjects:  30%|██▉       | 79/266 [00:25<01:00,  3.09it/s]predicting train subjects:  30%|███       | 80/266 [00:26<01:01,  3.03it/s]predicting train subjects:  30%|███       | 81/266 [00:26<01:04,  2.87it/s]predicting train subjects:  31%|███       | 82/266 [00:27<01:04,  2.83it/s]predicting train subjects:  31%|███       | 83/266 [00:27<01:03,  2.87it/s]predicting train subjects:  32%|███▏      | 84/266 [00:27<01:03,  2.86it/s]predicting train subjects:  32%|███▏      | 85/266 [00:28<01:02,  2.91it/s]predicting train subjects:  32%|███▏      | 86/266 [00:28<01:01,  2.91it/s]predicting train subjects:  33%|███▎      | 87/266 [00:28<01:01,  2.92it/s]predicting train subjects:  33%|███▎      | 88/266 [00:29<01:00,  2.93it/s]predicting train subjects:  33%|███▎      | 89/266 [00:29<01:02,  2.85it/s]predicting train subjects:  34%|███▍      | 90/266 [00:29<01:02,  2.82it/s]predicting train subjects:  34%|███▍      | 91/266 [00:30<01:04,  2.70it/s]predicting train subjects:  35%|███▍      | 92/266 [00:30<01:04,  2.70it/s]predicting train subjects:  35%|███▍      | 93/266 [00:31<01:06,  2.62it/s]predicting train subjects:  35%|███▌      | 94/266 [00:31<01:07,  2.53it/s]predicting train subjects:  36%|███▌      | 95/266 [00:31<01:06,  2.57it/s]predicting train subjects:  36%|███▌      | 96/266 [00:32<01:05,  2.59it/s]predicting train subjects:  36%|███▋      | 97/266 [00:32<01:05,  2.58it/s]predicting train subjects:  37%|███▋      | 98/266 [00:32<01:04,  2.62it/s]predicting train subjects:  37%|███▋      | 99/266 [00:33<01:01,  2.69it/s]predicting train subjects:  38%|███▊      | 100/266 [00:33<00:58,  2.86it/s]predicting train subjects:  38%|███▊      | 101/266 [00:33<00:55,  2.98it/s]predicting train subjects:  38%|███▊      | 102/266 [00:34<00:53,  3.06it/s]predicting train subjects:  39%|███▊      | 103/266 [00:34<00:53,  3.04it/s]predicting train subjects:  39%|███▉      | 104/266 [00:34<00:52,  3.07it/s]predicting train subjects:  39%|███▉      | 105/266 [00:35<00:50,  3.19it/s]predicting train subjects:  40%|███▉      | 106/266 [00:35<00:50,  3.15it/s]predicting train subjects:  40%|████      | 107/266 [00:35<00:49,  3.18it/s]predicting train subjects:  41%|████      | 108/266 [00:36<00:48,  3.27it/s]predicting train subjects:  41%|████      | 109/266 [00:36<00:47,  3.30it/s]predicting train subjects:  41%|████▏     | 110/266 [00:36<00:48,  3.22it/s]predicting train subjects:  42%|████▏     | 111/266 [00:37<00:51,  3.04it/s]predicting train subjects:  42%|████▏     | 112/266 [00:37<00:50,  3.04it/s]predicting train subjects:  42%|████▏     | 113/266 [00:37<00:48,  3.12it/s]predicting train subjects:  43%|████▎     | 114/266 [00:38<00:49,  3.09it/s]predicting train subjects:  43%|████▎     | 115/266 [00:38<00:49,  3.07it/s]predicting train subjects:  44%|████▎     | 116/266 [00:38<00:47,  3.19it/s]predicting train subjects:  44%|████▍     | 117/266 [00:38<00:47,  3.11it/s]predicting train subjects:  44%|████▍     | 118/266 [00:39<00:45,  3.23it/s]predicting train subjects:  45%|████▍     | 119/266 [00:39<00:51,  2.87it/s]predicting train subjects:  45%|████▌     | 120/266 [00:40<00:52,  2.79it/s]predicting train subjects:  45%|████▌     | 121/266 [00:40<00:52,  2.78it/s]predicting train subjects:  46%|████▌     | 122/266 [00:40<00:52,  2.73it/s]predicting train subjects:  46%|████▌     | 123/266 [00:41<00:51,  2.78it/s]predicting train subjects:  47%|████▋     | 124/266 [00:41<00:52,  2.68it/s]predicting train subjects:  47%|████▋     | 125/266 [00:41<00:52,  2.71it/s]predicting train subjects:  47%|████▋     | 126/266 [00:42<00:51,  2.73it/s]predicting train subjects:  48%|████▊     | 127/266 [00:42<00:50,  2.77it/s]predicting train subjects:  48%|████▊     | 128/266 [00:42<00:49,  2.81it/s]predicting train subjects:  48%|████▊     | 129/266 [00:43<00:49,  2.77it/s]predicting train subjects:  49%|████▉     | 130/266 [00:43<00:48,  2.79it/s]predicting train subjects:  49%|████▉     | 131/266 [00:44<00:48,  2.80it/s]predicting train subjects:  50%|████▉     | 132/266 [00:44<00:48,  2.77it/s]predicting train subjects:  50%|█████     | 133/266 [00:44<00:48,  2.74it/s]predicting train subjects:  50%|█████     | 134/266 [00:45<00:48,  2.73it/s]predicting train subjects:  51%|█████     | 135/266 [00:45<00:47,  2.76it/s]predicting train subjects:  51%|█████     | 136/266 [00:45<00:46,  2.77it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:46<00:44,  2.88it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:46<00:43,  2.95it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:46<00:43,  2.90it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:47<00:43,  2.89it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:47<00:43,  2.85it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:47<00:41,  2.96it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:48<00:40,  3.02it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:48<00:39,  3.08it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:48<00:38,  3.12it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:49<00:40,  2.96it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:49<00:39,  3.02it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:49<00:38,  3.03it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:50<00:38,  3.03it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:50<00:37,  3.06it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:50<00:37,  3.05it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:51<00:38,  2.95it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:51<00:37,  3.00it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:51<00:36,  3.04it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:52<00:33,  3.31it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:52<00:30,  3.56it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:52<00:29,  3.75it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:52<00:27,  3.88it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:53<00:26,  3.97it/s]predicting train subjects:  60%|██████    | 160/266 [00:53<00:26,  4.05it/s]predicting train subjects:  61%|██████    | 161/266 [00:53<00:25,  4.09it/s]predicting train subjects:  61%|██████    | 162/266 [00:53<00:26,  3.87it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:54<00:26,  3.93it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:54<00:25,  4.02it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:54<00:25,  4.03it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:54<00:24,  4.08it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:54<00:24,  4.11it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:55<00:23,  4.10it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:55<00:23,  4.10it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:55<00:23,  4.10it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:55<00:23,  4.12it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:56<00:22,  4.11it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:56<00:23,  3.94it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:56<00:25,  3.56it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:57<00:25,  3.55it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:57<00:25,  3.54it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:57<00:25,  3.53it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:57<00:24,  3.55it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:58<00:26,  3.31it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:58<00:25,  3.35it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:58<00:26,  3.27it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:59<00:24,  3.38it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:59<00:24,  3.36it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:59<00:25,  3.22it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:00<00:25,  3.21it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:00<00:25,  3.18it/s]predicting train subjects:  70%|███████   | 187/266 [01:00<00:23,  3.30it/s]predicting train subjects:  71%|███████   | 188/266 [01:01<00:23,  3.34it/s]predicting train subjects:  71%|███████   | 189/266 [01:01<00:24,  3.15it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:01<00:24,  3.15it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:02<00:24,  3.07it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:02<00:26,  2.81it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:02<00:24,  3.03it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:03<00:24,  2.96it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:03<00:23,  2.99it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:03<00:23,  3.00it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:04<00:22,  3.12it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:04<00:20,  3.26it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:04<00:21,  3.14it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:05<00:21,  3.11it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:05<00:20,  3.22it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:05<00:19,  3.22it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:05<00:20,  3.11it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:06<00:19,  3.23it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:06<00:19,  3.16it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:06<00:19,  3.04it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:07<00:20,  2.94it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:07<00:19,  3.04it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:07<00:17,  3.17it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:08<00:17,  3.28it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:08<00:16,  3.32it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:08<00:15,  3.39it/s]predicting train subjects:  80%|████████  | 213/266 [01:08<00:15,  3.52it/s]predicting train subjects:  80%|████████  | 214/266 [01:09<00:14,  3.62it/s]predicting train subjects:  81%|████████  | 215/266 [01:09<00:13,  3.71it/s]predicting train subjects:  81%|████████  | 216/266 [01:09<00:13,  3.76it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:10<00:13,  3.77it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:10<00:12,  3.83it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:10<00:12,  3.88it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:10<00:11,  3.91it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:11<00:11,  3.94it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:11<00:11,  3.91it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:11<00:11,  3.90it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:11<00:10,  3.90it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:12<00:10,  3.91it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:12<00:10,  3.92it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:12<00:09,  3.96it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:12<00:09,  3.92it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:13<00:09,  3.93it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:13<00:09,  3.93it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:13<00:09,  3.84it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:13<00:08,  3.83it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:14<00:08,  3.67it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:14<00:08,  3.69it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:14<00:08,  3.74it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:14<00:08,  3.68it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:15<00:07,  3.69it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:15<00:07,  3.73it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:15<00:07,  3.76it/s]predicting train subjects:  90%|█████████ | 240/266 [01:16<00:06,  3.79it/s]predicting train subjects:  91%|█████████ | 241/266 [01:16<00:06,  3.73it/s]predicting train subjects:  91%|█████████ | 242/266 [01:16<00:06,  3.77it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:16<00:06,  3.72it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:17<00:06,  3.52it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:17<00:05,  3.60it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:17<00:05,  3.66it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:17<00:05,  3.72it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:18<00:04,  3.74it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:18<00:04,  3.43it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:18<00:04,  3.33it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:19<00:04,  3.15it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:19<00:04,  3.14it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:19<00:04,  3.02it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:20<00:03,  3.03it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:20<00:03,  3.07it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:20<00:03,  3.05it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:21<00:02,  3.07it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:21<00:02,  2.96it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:21<00:02,  2.93it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:22<00:02,  2.94it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:22<00:01,  2.90it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:22<00:01,  2.90it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:23<00:01,  2.93it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:23<00:00,  2.98it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:23<00:00,  3.03it/s]predicting train subjects: 100%|██████████| 266/266 [01:24<00:00,  2.91it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  3.60it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  3.66it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  3.56it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:31,  2.91it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:32,  2.85it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:01<01:30,  2.92it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:24,  3.11it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:25,  3.06it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:01<01:26,  3.00it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:02<01:27,  2.96it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:31,  2.83it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:03<01:34,  2.72it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:03<01:35,  2.69it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:03<01:32,  2.76it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:04<01:34,  2.68it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:04<01:37,  2.58it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:05<01:34,  2.68it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:05<01:34,  2.66it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:05<01:34,  2.64it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:06<01:34,  2.64it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:06<01:31,  2.70it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:06<01:31,  2.71it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:07<01:34,  2.60it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:07<01:32,  2.65it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:08<01:33,  2.61it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:08<01:35,  2.55it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:08<01:32,  2.62it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:09<01:29,  2.71it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:09<01:25,  2.80it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:09<01:24,  2.83it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:10<01:23,  2.87it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:10<01:24,  2.80it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:10<01:22,  2.88it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:11<01:22,  2.84it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:11<01:22,  2.84it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:11<01:23,  2.77it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:12<01:22,  2.81it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:12<01:21,  2.84it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:13<01:22,  2.79it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:13<01:23,  2.76it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:13<01:23,  2.73it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:14<01:23,  2.72it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:14<01:20,  2.81it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:14<01:20,  2.79it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:15<01:14,  3.01it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:15<01:10,  3.16it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:15<01:10,  3.14it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:16<01:08,  3.24it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:16<01:06,  3.31it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:16<01:04,  3.38it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:16<01:06,  3.28it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:17<01:06,  3.24it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:17<01:04,  3.35it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:17<01:03,  3.41it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:18<01:01,  3.49it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:18<00:59,  3.55it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:18<00:58,  3.60it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:18<00:59,  3.53it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:19<00:59,  3.50it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:19<00:58,  3.56it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:19<00:57,  3.59it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:19<00:57,  3.58it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:20<00:58,  3.54it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:20<00:56,  3.60it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:20<00:55,  3.65it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:21<00:54,  3.69it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:21<00:55,  3.63it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:21<00:54,  3.69it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:21<00:55,  3.59it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:22<00:58,  3.41it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:22<00:56,  3.49it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:22<00:54,  3.59it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:23<00:55,  3.56it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:23<00:56,  3.47it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:23<00:57,  3.40it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:24<01:00,  3.22it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:24<01:00,  3.16it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:24<01:02,  3.07it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:25<01:00,  3.13it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:25<00:57,  3.27it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:25<01:01,  3.04it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:26<01:05,  2.84it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:26<01:06,  2.81it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:26<01:08,  2.69it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:27<01:05,  2.79it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:27<01:07,  2.73it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:27<01:07,  2.68it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:28<01:06,  2.73it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:28<01:04,  2.81it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:28<01:02,  2.87it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:29<01:01,  2.89it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:29<01:03,  2.79it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:30<01:03,  2.77it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:30<01:04,  2.71it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:30<01:02,  2.79it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:31<01:02,  2.79it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:31<01:00,  2.85it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:31<00:59,  2.89it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:32<00:56,  3.02it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:32<00:56,  2.98it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:32<00:55,  3.03it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:33<00:51,  3.26it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:33<00:49,  3.36it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:33<00:48,  3.43it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:33<00:49,  3.29it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:34<00:48,  3.36it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:34<00:47,  3.41it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:34<00:48,  3.30it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:35<00:49,  3.27it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:35<00:48,  3.27it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:35<00:49,  3.19it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:36<00:47,  3.30it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:36<00:46,  3.33it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:36<00:45,  3.38it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:36<00:44,  3.44it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:37<00:44,  3.47it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:37<00:43,  3.50it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:37<00:44,  3.41it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:38<00:43,  3.43it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:38<00:42,  3.47it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:38<00:42,  3.47it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:38<00:45,  3.25it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:39<00:46,  3.17it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:39<00:49,  2.95it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:40<00:48,  2.94it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:40<00:49,  2.89it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:40<00:50,  2.81it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:41<00:52,  2.68it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:41<00:51,  2.72it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:41<00:52,  2.66it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:42<00:51,  2.66it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:42<00:49,  2.76it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:42<00:48,  2.81it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:43<00:49,  2.72it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:43<00:48,  2.76it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:44<00:47,  2.78it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:44<00:47,  2.80it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:44<00:46,  2.85it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:45<00:46,  2.81it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:45<00:45,  2.85it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:45<00:45,  2.84it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:46<00:44,  2.88it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:46<00:43,  2.90it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:46<00:42,  2.95it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:47<00:42,  2.94it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:47<00:41,  2.96it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:47<00:40,  3.02it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:48<00:40,  3.01it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:48<00:38,  3.09it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:48<00:37,  3.14it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:49<00:37,  3.17it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:49<00:36,  3.19it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:49<00:36,  3.19it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:50<00:35,  3.21it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:50<00:35,  3.22it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:50<00:34,  3.24it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:50<00:34,  3.20it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:51<00:32,  3.38it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:51<00:30,  3.59it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:51<00:28,  3.78it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:51<00:27,  3.89it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:52<00:27,  3.93it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:52<00:26,  3.96it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:52<00:26,  3.98it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:52<00:25,  4.00it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:53<00:25,  4.07it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:53<00:24,  4.12it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:53<00:24,  4.15it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:53<00:23,  4.18it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:54<00:23,  4.21it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:54<00:23,  4.21it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:54<00:23,  4.07it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:54<00:24,  3.94it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:55<00:24,  3.91it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:55<00:23,  3.99it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:55<00:24,  3.76it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:55<00:24,  3.73it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:56<00:25,  3.54it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:56<00:25,  3.60it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:56<00:24,  3.64it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:57<00:24,  3.65it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:57<00:23,  3.64it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:57<00:24,  3.47it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:57<00:25,  3.35it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:58<00:25,  3.28it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:58<00:25,  3.19it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:58<00:27,  3.04it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:59<00:25,  3.12it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:59<00:25,  3.13it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:59<00:25,  3.14it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [01:00<00:24,  3.14it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [01:00<00:25,  3.03it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [01:00<00:24,  3.08it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [01:01<00:24,  3.06it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [01:01<00:22,  3.26it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [01:01<00:22,  3.20it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [01:02<00:22,  3.13it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [01:02<00:22,  3.20it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [01:02<00:21,  3.22it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [01:03<00:20,  3.32it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [01:03<00:21,  3.21it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [01:03<00:21,  3.16it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [01:04<00:20,  3.23it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [01:04<00:20,  3.17it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [01:04<00:20,  3.11it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [01:04<00:19,  3.24it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [01:05<00:18,  3.32it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [01:05<00:18,  3.38it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [01:05<00:17,  3.42it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [01:06<00:17,  3.41it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [01:06<00:16,  3.47it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [01:06<00:16,  3.47it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [01:06<00:15,  3.50it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [01:07<00:16,  3.27it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [01:07<00:16,  3.34it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [01:07<00:15,  3.51it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [01:08<00:14,  3.64it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [01:08<00:13,  3.74it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [01:08<00:13,  3.82it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [01:08<00:12,  3.88it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [01:09<00:12,  3.93it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [01:09<00:11,  3.95it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [01:09<00:11,  3.95it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [01:09<00:11,  3.95it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [01:10<00:11,  3.93it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [01:10<00:10,  3.94it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [01:10<00:10,  3.94it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [01:10<00:10,  3.95it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [01:11<00:10,  3.94it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [01:11<00:09,  3.93it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [01:11<00:09,  3.93it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [01:11<00:09,  3.90it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [01:12<00:09,  3.90it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [01:12<00:09,  3.86it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [01:12<00:08,  3.83it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [01:12<00:08,  3.80it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [01:13<00:08,  3.81it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [01:13<00:08,  3.80it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [01:13<00:07,  3.79it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [01:13<00:07,  3.78it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [01:14<00:07,  3.79it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [01:14<00:07,  3.77it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [01:14<00:06,  3.76it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [01:15<00:06,  3.76it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [01:15<00:06,  3.74it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [01:15<00:06,  3.69it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [01:15<00:06,  3.63it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [01:16<00:05,  3.59it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [01:16<00:05,  3.38it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [01:16<00:05,  3.44it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [01:17<00:05,  3.55it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [01:17<00:05,  3.37it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [01:17<00:05,  3.20it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [01:18<00:04,  3.13it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [01:18<00:04,  3.08it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [01:18<00:04,  2.94it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [01:19<00:04,  2.77it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [01:19<00:03,  2.83it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [01:19<00:03,  2.79it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [01:20<00:03,  2.72it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [01:20<00:03,  2.66it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:21<00:02,  2.72it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:21<00:02,  2.82it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:21<00:01,  2.88it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:22<00:01,  2.78it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:22<00:01,  2.88it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:22<00:00,  2.89it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:23<00:00,  2.90it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:23<00:00,  2.90it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 70.63it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:03, 65.61it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 64.33it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 63.68it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 64.14it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 65.40it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:03, 66.15it/s]saving BB  train1-THALAMUS:  19%|█▉        | 50/266 [00:00<00:03, 69.03it/s]saving BB  train1-THALAMUS:  22%|██▏       | 58/266 [00:00<00:02, 70.97it/s]saving BB  train1-THALAMUS:  25%|██▍       | 66/266 [00:00<00:02, 73.40it/s]saving BB  train1-THALAMUS:  28%|██▊       | 75/266 [00:01<00:02, 76.02it/s]saving BB  train1-THALAMUS:  31%|███       | 83/266 [00:01<00:02, 74.89it/s]saving BB  train1-THALAMUS:  34%|███▍      | 91/266 [00:01<00:02, 73.68it/s]saving BB  train1-THALAMUS:  37%|███▋      | 99/266 [00:01<00:02, 72.82it/s]saving BB  train1-THALAMUS:  40%|████      | 107/266 [00:01<00:02, 72.75it/s]saving BB  train1-THALAMUS:  43%|████▎     | 115/266 [00:01<00:02, 72.76it/s]saving BB  train1-THALAMUS:  46%|████▌     | 123/266 [00:01<00:01, 72.34it/s]saving BB  train1-THALAMUS:  49%|████▉     | 131/266 [00:01<00:01, 71.35it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 139/266 [00:01<00:01, 69.88it/s]saving BB  train1-THALAMUS:  55%|█████▍    | 146/266 [00:02<00:01, 68.39it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 153/266 [00:02<00:01, 66.70it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:02<00:01, 69.09it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 170/266 [00:02<00:01, 73.19it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 179/266 [00:02<00:01, 75.89it/s]saving BB  train1-THALAMUS:  70%|███████   | 187/266 [00:02<00:01, 74.12it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 195/266 [00:02<00:00, 74.19it/s]saving BB  train1-THALAMUS:  76%|███████▋  | 203/266 [00:02<00:00, 73.47it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 211/266 [00:02<00:00, 73.42it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 219/266 [00:03<00:00, 74.43it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 228/266 [00:03<00:00, 75.82it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 237/266 [00:03<00:00, 77.30it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 245/266 [00:03<00:00, 77.18it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 253/266 [00:03<00:00, 75.77it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 261/266 [00:03<00:00, 74.09it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 72.30it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 70.77it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:03, 69.15it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:03, 67.53it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:03, 66.58it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 29/266 [00:00<00:03, 67.51it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 37/266 [00:00<00:03, 69.52it/s]saving BB  train1-THALAMUS Sagittal:  17%|█▋        | 45/266 [00:00<00:03, 71.69it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 53/266 [00:00<00:02, 73.88it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 61/266 [00:00<00:02, 75.55it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:00<00:02, 77.59it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 79/266 [00:01<00:02, 78.86it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 87/266 [00:01<00:02, 77.04it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 95/266 [00:01<00:02, 76.11it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▊      | 103/266 [00:01<00:02, 75.92it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 111/266 [00:01<00:02, 76.47it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 119/266 [00:01<00:01, 76.63it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 127/266 [00:01<00:01, 74.88it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 135/266 [00:01<00:01, 74.32it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 143/266 [00:01<00:01, 72.91it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 151/266 [00:02<00:01, 73.41it/s]saving BB  train1-THALAMUS Sagittal:  60%|██████    | 160/266 [00:02<00:01, 76.00it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▎   | 169/266 [00:02<00:01, 78.92it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 178/266 [00:02<00:01, 81.21it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 187/266 [00:02<00:00, 79.06it/s]saving BB  train1-THALAMUS Sagittal:  73%|███████▎  | 195/266 [00:02<00:00, 76.16it/s]saving BB  train1-THALAMUS Sagittal:  76%|███████▋  | 203/266 [00:02<00:00, 76.38it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 211/266 [00:02<00:00, 77.12it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 219/266 [00:02<00:00, 77.52it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 228/266 [00:03<00:00, 78.73it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 237/266 [00:03<00:00, 79.29it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 246/266 [00:03<00:00, 79.71it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 254/266 [00:03<00:00, 77.90it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 262/266 [00:03<00:00, 76.45it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 75.94it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:33,  1.71s/it]Loading train:   1%|          | 2/266 [00:03<07:24,  1.68s/it]Loading train:   1%|          | 3/266 [00:04<06:44,  1.54s/it]Loading train:   2%|▏         | 4/266 [00:05<06:13,  1.43s/it]Loading train:   2%|▏         | 5/266 [00:07<06:16,  1.44s/it]Loading train:   2%|▏         | 6/266 [00:08<05:44,  1.33s/it]Loading train:   3%|▎         | 7/266 [00:09<05:15,  1.22s/it]Loading train:   3%|▎         | 8/266 [00:10<04:51,  1.13s/it]Loading train:   3%|▎         | 9/266 [00:11<04:33,  1.06s/it]Loading train:   4%|▍         | 10/266 [00:11<04:24,  1.03s/it]Loading train:   4%|▍         | 11/266 [00:12<04:19,  1.02s/it]Loading train:   5%|▍         | 12/266 [00:13<04:05,  1.03it/s]Loading train:   5%|▍         | 13/266 [00:14<04:10,  1.01it/s]Loading train:   5%|▌         | 14/266 [00:15<04:09,  1.01it/s]Loading train:   6%|▌         | 15/266 [00:16<04:05,  1.02it/s]Loading train:   6%|▌         | 16/266 [00:17<04:00,  1.04it/s]Loading train:   6%|▋         | 17/266 [00:18<04:03,  1.02it/s]Loading train:   7%|▋         | 18/266 [00:19<04:07,  1.00it/s]Loading train:   7%|▋         | 19/266 [00:20<04:03,  1.02it/s]Loading train:   8%|▊         | 20/266 [00:21<03:59,  1.03it/s]Loading train:   8%|▊         | 21/266 [00:22<04:02,  1.01it/s]Loading train:   8%|▊         | 22/266 [00:23<04:09,  1.02s/it]Loading train:   9%|▊         | 23/266 [00:24<04:03,  1.00s/it]Loading train:   9%|▉         | 24/266 [00:25<04:04,  1.01s/it]Loading train:   9%|▉         | 25/266 [00:26<03:54,  1.03it/s]Loading train:  10%|▉         | 26/266 [00:27<03:47,  1.06it/s]Loading train:  10%|█         | 27/266 [00:28<03:57,  1.01it/s]Loading train:  11%|█         | 28/266 [00:29<03:49,  1.04it/s]Loading train:  11%|█         | 29/266 [00:30<03:48,  1.04it/s]Loading train:  11%|█▏        | 30/266 [00:31<03:46,  1.04it/s]Loading train:  12%|█▏        | 31/266 [00:32<03:43,  1.05it/s]Loading train:  12%|█▏        | 32/266 [00:33<03:44,  1.04it/s]Loading train:  12%|█▏        | 33/266 [00:34<03:44,  1.04it/s]Loading train:  13%|█▎        | 34/266 [00:35<03:35,  1.08it/s]Loading train:  13%|█▎        | 35/266 [00:36<03:28,  1.11it/s]Loading train:  14%|█▎        | 36/266 [00:36<03:22,  1.14it/s]Loading train:  14%|█▍        | 37/266 [00:37<03:20,  1.14it/s]Loading train:  14%|█▍        | 38/266 [00:38<03:28,  1.10it/s]Loading train:  15%|█▍        | 39/266 [00:39<03:24,  1.11it/s]Loading train:  15%|█▌        | 40/266 [00:40<03:20,  1.12it/s]Loading train:  15%|█▌        | 41/266 [00:41<03:23,  1.11it/s]Loading train:  16%|█▌        | 42/266 [00:42<03:25,  1.09it/s]Loading train:  16%|█▌        | 43/266 [00:43<03:12,  1.16it/s]Loading train:  17%|█▋        | 44/266 [00:43<03:02,  1.22it/s]Loading train:  17%|█▋        | 45/266 [00:44<03:00,  1.23it/s]Loading train:  17%|█▋        | 46/266 [00:45<02:50,  1.29it/s]Loading train:  18%|█▊        | 47/266 [00:46<02:45,  1.32it/s]Loading train:  18%|█▊        | 48/266 [00:46<02:42,  1.34it/s]Loading train:  18%|█▊        | 49/266 [00:47<02:45,  1.31it/s]Loading train:  19%|█▉        | 50/266 [00:48<02:39,  1.35it/s]Loading train:  19%|█▉        | 51/266 [00:48<02:37,  1.37it/s]Loading train:  20%|█▉        | 52/266 [00:49<02:38,  1.35it/s]Loading train:  20%|█▉        | 53/266 [00:50<02:37,  1.36it/s]Loading train:  20%|██        | 54/266 [00:51<02:40,  1.32it/s]Loading train:  21%|██        | 55/266 [00:52<02:44,  1.28it/s]Loading train:  21%|██        | 56/266 [00:52<02:40,  1.31it/s]Loading train:  21%|██▏       | 57/266 [00:53<02:36,  1.34it/s]Loading train:  22%|██▏       | 58/266 [00:54<02:35,  1.33it/s]Loading train:  22%|██▏       | 59/266 [00:54<02:31,  1.36it/s]Loading train:  23%|██▎       | 60/266 [00:55<02:33,  1.34it/s]Loading train:  23%|██▎       | 61/266 [00:56<02:30,  1.37it/s]Loading train:  23%|██▎       | 62/266 [00:57<02:28,  1.37it/s]Loading train:  24%|██▎       | 63/266 [00:57<02:30,  1.35it/s]Loading train:  24%|██▍       | 64/266 [00:58<02:28,  1.36it/s]Loading train:  24%|██▍       | 65/266 [00:59<02:25,  1.38it/s]Loading train:  25%|██▍       | 66/266 [01:00<02:27,  1.35it/s]Loading train:  25%|██▌       | 67/266 [01:00<02:25,  1.37it/s]Loading train:  26%|██▌       | 68/266 [01:01<02:22,  1.39it/s]Loading train:  26%|██▌       | 69/266 [01:02<02:20,  1.40it/s]Loading train:  26%|██▋       | 70/266 [01:03<02:23,  1.37it/s]Loading train:  27%|██▋       | 71/266 [01:03<02:23,  1.36it/s]Loading train:  27%|██▋       | 72/266 [01:04<02:19,  1.39it/s]Loading train:  27%|██▋       | 73/266 [01:05<02:17,  1.40it/s]Loading train:  28%|██▊       | 74/266 [01:05<02:15,  1.42it/s]Loading train:  28%|██▊       | 75/266 [01:06<02:14,  1.42it/s]Loading train:  29%|██▊       | 76/266 [01:07<02:13,  1.42it/s]Loading train:  29%|██▉       | 77/266 [01:07<02:12,  1.43it/s]Loading train:  29%|██▉       | 78/266 [01:08<02:24,  1.30it/s]Loading train:  30%|██▉       | 79/266 [01:09<02:31,  1.24it/s]Loading train:  30%|███       | 80/266 [01:10<02:37,  1.18it/s]Loading train:  30%|███       | 81/266 [01:11<02:36,  1.18it/s]Loading train:  31%|███       | 82/266 [01:12<02:38,  1.16it/s]Loading train:  31%|███       | 83/266 [01:13<02:42,  1.12it/s]Loading train:  32%|███▏      | 84/266 [01:14<02:39,  1.14it/s]Loading train:  32%|███▏      | 85/266 [01:15<02:36,  1.15it/s]Loading train:  32%|███▏      | 86/266 [01:16<02:43,  1.10it/s]Loading train:  33%|███▎      | 87/266 [01:16<02:43,  1.09it/s]Loading train:  33%|███▎      | 88/266 [01:17<02:47,  1.06it/s]Loading train:  33%|███▎      | 89/266 [01:18<02:45,  1.07it/s]Loading train:  34%|███▍      | 90/266 [01:19<02:47,  1.05it/s]Loading train:  34%|███▍      | 91/266 [01:20<02:43,  1.07it/s]Loading train:  35%|███▍      | 92/266 [01:21<02:45,  1.05it/s]Loading train:  35%|███▍      | 93/266 [01:22<02:39,  1.08it/s]Loading train:  35%|███▌      | 94/266 [01:23<02:38,  1.09it/s]Loading train:  36%|███▌      | 95/266 [01:24<02:33,  1.11it/s]Loading train:  36%|███▌      | 96/266 [01:25<02:46,  1.02it/s]Loading train:  36%|███▋      | 97/266 [01:27<03:09,  1.12s/it]Loading train:  37%|███▋      | 98/266 [01:28<03:09,  1.13s/it]Loading train:  37%|███▋      | 99/266 [01:29<03:00,  1.08s/it]Loading train:  38%|███▊      | 100/266 [01:30<03:03,  1.10s/it]Loading train:  38%|███▊      | 101/266 [01:31<02:47,  1.02s/it]Loading train:  38%|███▊      | 102/266 [01:31<02:36,  1.05it/s]Loading train:  39%|███▊      | 103/266 [01:32<02:29,  1.09it/s]Loading train:  39%|███▉      | 104/266 [01:33<02:21,  1.14it/s]Loading train:  39%|███▉      | 105/266 [01:34<02:17,  1.17it/s]Loading train:  40%|███▉      | 106/266 [01:35<02:09,  1.24it/s]Loading train:  40%|████      | 107/266 [01:35<02:06,  1.26it/s]Loading train:  41%|████      | 108/266 [01:36<02:08,  1.23it/s]Loading train:  41%|████      | 109/266 [01:37<02:10,  1.20it/s]Loading train:  41%|████▏     | 110/266 [01:38<02:08,  1.22it/s]Loading train:  42%|████▏     | 111/266 [01:39<02:09,  1.19it/s]Loading train:  42%|████▏     | 112/266 [01:40<02:09,  1.19it/s]Loading train:  42%|████▏     | 113/266 [01:40<02:05,  1.22it/s]Loading train:  43%|████▎     | 114/266 [01:41<02:04,  1.22it/s]Loading train:  43%|████▎     | 115/266 [01:42<02:02,  1.23it/s]Loading train:  44%|████▎     | 116/266 [01:43<02:01,  1.24it/s]Loading train:  44%|████▍     | 117/266 [01:44<02:05,  1.18it/s]Loading train:  44%|████▍     | 118/266 [01:44<02:00,  1.23it/s]Loading train:  45%|████▍     | 119/266 [01:45<02:10,  1.13it/s]Loading train:  45%|████▌     | 120/266 [01:46<02:10,  1.11it/s]Loading train:  45%|████▌     | 121/266 [01:47<02:11,  1.10it/s]Loading train:  46%|████▌     | 122/266 [01:48<02:14,  1.07it/s]Loading train:  46%|████▌     | 123/266 [01:49<02:13,  1.07it/s]Loading train:  47%|████▋     | 124/266 [01:50<02:11,  1.08it/s]Loading train:  47%|████▋     | 125/266 [01:51<02:11,  1.07it/s]Loading train:  47%|████▋     | 126/266 [01:52<02:11,  1.06it/s]Loading train:  48%|████▊     | 127/266 [01:53<02:08,  1.08it/s]Loading train:  48%|████▊     | 128/266 [01:54<02:08,  1.08it/s]Loading train:  48%|████▊     | 129/266 [01:55<02:13,  1.03it/s]Loading train:  49%|████▉     | 130/266 [01:56<02:09,  1.05it/s]Loading train:  49%|████▉     | 131/266 [01:57<02:07,  1.06it/s]Loading train:  50%|████▉     | 132/266 [01:58<02:03,  1.09it/s]Loading train:  50%|█████     | 133/266 [01:59<01:59,  1.11it/s]Loading train:  50%|█████     | 134/266 [01:59<01:59,  1.10it/s]Loading train:  51%|█████     | 135/266 [02:00<02:03,  1.06it/s]Loading train:  51%|█████     | 136/266 [02:02<02:05,  1.03it/s]Loading train:  52%|█████▏    | 137/266 [02:03<02:06,  1.02it/s]Loading train:  52%|█████▏    | 138/266 [02:03<02:01,  1.05it/s]Loading train:  52%|█████▏    | 139/266 [02:04<01:58,  1.07it/s]Loading train:  53%|█████▎    | 140/266 [02:05<01:56,  1.09it/s]Loading train:  53%|█████▎    | 141/266 [02:06<01:50,  1.13it/s]Loading train:  53%|█████▎    | 142/266 [02:07<01:49,  1.13it/s]Loading train:  54%|█████▍    | 143/266 [02:08<01:45,  1.16it/s]Loading train:  54%|█████▍    | 144/266 [02:09<01:45,  1.16it/s]Loading train:  55%|█████▍    | 145/266 [02:09<01:43,  1.17it/s]Loading train:  55%|█████▍    | 146/266 [02:10<01:42,  1.18it/s]Loading train:  55%|█████▌    | 147/266 [02:11<01:39,  1.19it/s]Loading train:  56%|█████▌    | 148/266 [02:12<01:42,  1.15it/s]Loading train:  56%|█████▌    | 149/266 [02:13<01:42,  1.14it/s]Loading train:  56%|█████▋    | 150/266 [02:14<01:44,  1.11it/s]Loading train:  57%|█████▋    | 151/266 [02:15<01:45,  1.09it/s]Loading train:  57%|█████▋    | 152/266 [02:16<01:45,  1.08it/s]Loading train:  58%|█████▊    | 153/266 [02:17<01:40,  1.12it/s]Loading train:  58%|█████▊    | 154/266 [02:18<01:43,  1.08it/s]Loading train:  58%|█████▊    | 155/266 [02:18<01:40,  1.11it/s]Loading train:  59%|█████▊    | 156/266 [02:19<01:34,  1.16it/s]Loading train:  59%|█████▉    | 157/266 [02:20<01:30,  1.20it/s]Loading train:  59%|█████▉    | 158/266 [02:21<01:25,  1.27it/s]Loading train:  60%|█████▉    | 159/266 [02:21<01:21,  1.31it/s]Loading train:  60%|██████    | 160/266 [02:22<01:17,  1.36it/s]Loading train:  61%|██████    | 161/266 [02:23<01:13,  1.44it/s]Loading train:  61%|██████    | 162/266 [02:23<01:11,  1.46it/s]Loading train:  61%|██████▏   | 163/266 [02:24<01:09,  1.47it/s]Loading train:  62%|██████▏   | 164/266 [02:25<01:08,  1.49it/s]Loading train:  62%|██████▏   | 165/266 [02:25<01:08,  1.47it/s]Loading train:  62%|██████▏   | 166/266 [02:26<01:07,  1.49it/s]Loading train:  63%|██████▎   | 167/266 [02:27<01:05,  1.51it/s]Loading train:  63%|██████▎   | 168/266 [02:27<01:08,  1.44it/s]Loading train:  64%|██████▎   | 169/266 [02:28<01:10,  1.38it/s]Loading train:  64%|██████▍   | 170/266 [02:29<01:07,  1.41it/s]Loading train:  64%|██████▍   | 171/266 [02:30<01:08,  1.40it/s]Loading train:  65%|██████▍   | 172/266 [02:30<01:08,  1.36it/s]Loading train:  65%|██████▌   | 173/266 [02:31<01:10,  1.33it/s]Loading train:  65%|██████▌   | 174/266 [02:32<01:09,  1.32it/s]Loading train:  66%|██████▌   | 175/266 [02:33<01:08,  1.33it/s]Loading train:  66%|██████▌   | 176/266 [02:33<01:08,  1.32it/s]Loading train:  67%|██████▋   | 177/266 [02:34<01:07,  1.32it/s]Loading train:  67%|██████▋   | 178/266 [02:35<01:05,  1.35it/s]Loading train:  67%|██████▋   | 179/266 [02:36<01:03,  1.38it/s]Loading train:  68%|██████▊   | 180/266 [02:36<01:05,  1.32it/s]Loading train:  68%|██████▊   | 181/266 [02:37<01:05,  1.29it/s]Loading train:  68%|██████▊   | 182/266 [02:38<01:03,  1.33it/s]Loading train:  69%|██████▉   | 183/266 [02:39<01:01,  1.35it/s]Loading train:  69%|██████▉   | 184/266 [02:39<00:59,  1.38it/s]Loading train:  70%|██████▉   | 185/266 [02:40<01:00,  1.34it/s]Loading train:  70%|██████▉   | 186/266 [02:41<00:57,  1.39it/s]Loading train:  70%|███████   | 187/266 [02:42<00:58,  1.35it/s]Loading train:  71%|███████   | 188/266 [02:42<00:57,  1.36it/s]Loading train:  71%|███████   | 189/266 [02:43<00:58,  1.31it/s]Loading train:  71%|███████▏  | 190/266 [02:44<00:57,  1.32it/s]Loading train:  72%|███████▏  | 191/266 [02:45<01:07,  1.11it/s]Loading train:  72%|███████▏  | 192/266 [02:46<01:11,  1.04it/s]Loading train:  73%|███████▎  | 193/266 [02:47<01:12,  1.00it/s]Loading train:  73%|███████▎  | 194/266 [02:49<01:22,  1.14s/it]Loading train:  73%|███████▎  | 195/266 [02:49<01:12,  1.03s/it]Loading train:  74%|███████▎  | 196/266 [02:50<01:08,  1.02it/s]Loading train:  74%|███████▍  | 197/266 [02:51<01:02,  1.10it/s]Loading train:  74%|███████▍  | 198/266 [02:52<01:00,  1.12it/s]Loading train:  75%|███████▍  | 199/266 [02:53<00:57,  1.16it/s]Loading train:  75%|███████▌  | 200/266 [02:54<00:55,  1.19it/s]Loading train:  76%|███████▌  | 201/266 [02:54<00:56,  1.16it/s]Loading train:  76%|███████▌  | 202/266 [02:55<00:53,  1.20it/s]Loading train:  76%|███████▋  | 203/266 [02:56<00:53,  1.19it/s]Loading train:  77%|███████▋  | 204/266 [02:57<00:52,  1.19it/s]Loading train:  77%|███████▋  | 205/266 [02:58<00:52,  1.16it/s]Loading train:  77%|███████▋  | 206/266 [02:59<00:50,  1.19it/s]Loading train:  78%|███████▊  | 207/266 [02:59<00:49,  1.19it/s]Loading train:  78%|███████▊  | 208/266 [03:00<00:48,  1.20it/s]Loading train:  79%|███████▊  | 209/266 [03:01<00:47,  1.21it/s]Loading train:  79%|███████▉  | 210/266 [03:02<00:46,  1.21it/s]Loading train:  79%|███████▉  | 211/266 [03:03<00:45,  1.20it/s]Loading train:  80%|███████▉  | 212/266 [03:04<00:44,  1.22it/s]Loading train:  80%|████████  | 213/266 [03:04<00:42,  1.26it/s]Loading train:  80%|████████  | 214/266 [03:05<00:40,  1.30it/s]Loading train:  81%|████████  | 215/266 [03:06<00:37,  1.35it/s]Loading train:  81%|████████  | 216/266 [03:06<00:36,  1.37it/s]Loading train:  82%|████████▏ | 217/266 [03:07<00:35,  1.37it/s]Loading train:  82%|████████▏ | 218/266 [03:08<00:34,  1.40it/s]Loading train:  82%|████████▏ | 219/266 [03:08<00:33,  1.40it/s]Loading train:  83%|████████▎ | 220/266 [03:09<00:31,  1.44it/s]Loading train:  83%|████████▎ | 221/266 [03:10<00:31,  1.43it/s]Loading train:  83%|████████▎ | 222/266 [03:10<00:30,  1.46it/s]Loading train:  84%|████████▍ | 223/266 [03:11<00:29,  1.45it/s]Loading train:  84%|████████▍ | 224/266 [03:12<00:28,  1.48it/s]Loading train:  85%|████████▍ | 225/266 [03:13<00:28,  1.43it/s]Loading train:  85%|████████▍ | 226/266 [03:13<00:27,  1.43it/s]Loading train:  85%|████████▌ | 227/266 [03:14<00:27,  1.42it/s]Loading train:  86%|████████▌ | 228/266 [03:15<00:25,  1.47it/s]Loading train:  86%|████████▌ | 229/266 [03:15<00:25,  1.46it/s]Loading train:  86%|████████▋ | 230/266 [03:16<00:24,  1.47it/s]Loading train:  87%|████████▋ | 231/266 [03:17<00:24,  1.41it/s]Loading train:  87%|████████▋ | 232/266 [03:18<00:24,  1.39it/s]Loading train:  88%|████████▊ | 233/266 [03:18<00:24,  1.37it/s]Loading train:  88%|████████▊ | 234/266 [03:19<00:23,  1.39it/s]Loading train:  88%|████████▊ | 235/266 [03:20<00:21,  1.43it/s]Loading train:  89%|████████▊ | 236/266 [03:20<00:21,  1.41it/s]Loading train:  89%|████████▉ | 237/266 [03:21<00:21,  1.37it/s]Loading train:  89%|████████▉ | 238/266 [03:22<00:19,  1.40it/s]Loading train:  90%|████████▉ | 239/266 [03:22<00:18,  1.43it/s]Loading train:  90%|█████████ | 240/266 [03:23<00:18,  1.39it/s]Loading train:  91%|█████████ | 241/266 [03:24<00:18,  1.39it/s]Loading train:  91%|█████████ | 242/266 [03:25<00:17,  1.36it/s]Loading train:  91%|█████████▏| 243/266 [03:25<00:16,  1.38it/s]Loading train:  92%|█████████▏| 244/266 [03:26<00:16,  1.35it/s]Loading train:  92%|█████████▏| 245/266 [03:27<00:15,  1.35it/s]Loading train:  92%|█████████▏| 246/266 [03:28<00:14,  1.38it/s]Loading train:  93%|█████████▎| 247/266 [03:28<00:13,  1.42it/s]Loading train:  93%|█████████▎| 248/266 [03:29<00:12,  1.44it/s]Loading train:  94%|█████████▎| 249/266 [03:30<00:12,  1.31it/s]Loading train:  94%|█████████▍| 250/266 [03:31<00:12,  1.27it/s]Loading train:  94%|█████████▍| 251/266 [03:32<00:12,  1.22it/s]Loading train:  95%|█████████▍| 252/266 [03:32<00:11,  1.22it/s]Loading train:  95%|█████████▌| 253/266 [03:33<00:10,  1.19it/s]Loading train:  95%|█████████▌| 254/266 [03:34<00:10,  1.18it/s]Loading train:  96%|█████████▌| 255/266 [03:35<00:09,  1.17it/s]Loading train:  96%|█████████▌| 256/266 [03:36<00:08,  1.17it/s]Loading train:  97%|█████████▋| 257/266 [03:37<00:07,  1.16it/s]Loading train:  97%|█████████▋| 258/266 [03:38<00:06,  1.18it/s]Loading train:  97%|█████████▋| 259/266 [03:39<00:06,  1.13it/s]Loading train:  98%|█████████▊| 260/266 [03:39<00:05,  1.15it/s]Loading train:  98%|█████████▊| 261/266 [03:40<00:04,  1.16it/s]Loading train:  98%|█████████▊| 262/266 [03:41<00:03,  1.15it/s]Loading train:  99%|█████████▉| 263/266 [03:42<00:02,  1.17it/s]Loading train:  99%|█████████▉| 264/266 [03:43<00:01,  1.19it/s]Loading train: 100%|█████████▉| 265/266 [03:44<00:00,  1.21it/s]Loading train: 100%|██████████| 266/266 [03:44<00:00,  1.18it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:01, 147.35it/s]concatenating: train:  16%|█▌        | 43/266 [00:00<00:01, 170.79it/s]concatenating: train:  25%|██▍       | 66/266 [00:00<00:01, 183.71it/s]concatenating: train:  35%|███▍      | 93/266 [00:00<00:00, 201.29it/s]concatenating: train:  46%|████▌     | 123/266 [00:00<00:00, 220.86it/s]concatenating: train:  56%|█████▌    | 148/266 [00:00<00:00, 225.53it/s]concatenating: train:  66%|██████▌   | 176/266 [00:00<00:00, 233.63it/s]concatenating: train:  77%|███████▋  | 205/266 [00:00<00:00, 247.39it/s]concatenating: train:  87%|████████▋ | 232/266 [00:00<00:00, 253.62it/s]concatenating: train:  98%|█████████▊| 261/266 [00:02<00:00, 58.47it/s] concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 113.86it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:03,  1.19s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.15s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]Loading test: 100%|██████████| 4/4 [00:04<00:00,  1.21s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 126.12it/s]2019-07-29 05:11:28.225429: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 05:11:28.225508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 05:11:28.225523: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 05:11:28.225531: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 05:11:28.225877: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.84it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.78it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.59it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.17it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.25it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.12it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.22it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.02it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.44it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.85it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.54it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.88it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.15it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.30it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.00it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.31it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.42it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.39it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 84, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 84, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 84, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 84, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 84, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 84, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 84, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 84, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 84, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 42, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 42, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 42, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 42, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 42, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 42, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 42, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 21, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 21, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 21, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 21, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 21, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 21, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 21, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 21, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 42, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 42, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 42, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 42, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 42, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 42, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 42, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 84, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 84, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 84, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 84, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 84, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 84, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 84, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 84, 40)   21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 84, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 84, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 84, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 84, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 84, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 84, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 84, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 84, 100)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 84, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 283,113
Trainable params: 108,113
Non-trainable params: 175,000
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33457607e-02 3.28312283e-02 7.67713118e-02 9.53922153e-03
 2.76086793e-02 7.22303270e-03 8.44378772e-02 1.14107916e-01
 8.95972367e-02 1.36129381e-02 2.90491864e-01 1.90176105e-01
 2.56828632e-04]
Train on 9796 samples, validate on 141 samples
Epoch 1/300
 - 23s - loss: 1.9015 - acc: 0.7397 - mDice: 0.2335 - val_loss: 2.1331 - val_acc: 0.9127 - val_mDice: 0.3010

Epoch 00001: val_mDice improved from -inf to 0.30102, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 17s - loss: 0.6646 - acc: 0.9020 - mDice: 0.5057 - val_loss: 0.6181 - val_acc: 0.9334 - val_mDice: 0.5412

Epoch 00002: val_mDice improved from 0.30102 to 0.54119, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.5228 - acc: 0.9160 - mDice: 0.5806 - val_loss: 0.5268 - val_acc: 0.9433 - val_mDice: 0.5895

Epoch 00003: val_mDice improved from 0.54119 to 0.58949, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 16s - loss: 0.4652 - acc: 0.9261 - mDice: 0.6158 - val_loss: 0.4795 - val_acc: 0.9441 - val_mDice: 0.6081

Epoch 00004: val_mDice improved from 0.58949 to 0.60805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 16s - loss: 0.4350 - acc: 0.9342 - mDice: 0.6344 - val_loss: 0.4851 - val_acc: 0.9458 - val_mDice: 0.6127

Epoch 00005: val_mDice improved from 0.60805 to 0.61269, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 17s - loss: 0.4109 - acc: 0.9374 - mDice: 0.6498 - val_loss: 0.5087 - val_acc: 0.9474 - val_mDice: 0.6079

Epoch 00006: val_mDice did not improve from 0.61269
Epoch 7/300
 - 16s - loss: 0.3981 - acc: 0.9387 - mDice: 0.6582 - val_loss: 0.4597 - val_acc: 0.9469 - val_mDice: 0.6277

Epoch 00007: val_mDice improved from 0.61269 to 0.62773, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 17s - loss: 0.3973 - acc: 0.9389 - mDice: 0.6598 - val_loss: 0.4577 - val_acc: 0.9469 - val_mDice: 0.6267

Epoch 00008: val_mDice did not improve from 0.62773
Epoch 9/300
 - 18s - loss: 0.3778 - acc: 0.9407 - mDice: 0.6718 - val_loss: 0.4731 - val_acc: 0.9473 - val_mDice: 0.6249

Epoch 00009: val_mDice did not improve from 0.62773
Epoch 10/300
 - 18s - loss: 0.3762 - acc: 0.9408 - mDice: 0.6733 - val_loss: 0.4601 - val_acc: 0.9473 - val_mDice: 0.6280

Epoch 00010: val_mDice improved from 0.62773 to 0.62800, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 18s - loss: 0.3614 - acc: 0.9421 - mDice: 0.6830 - val_loss: 0.4529 - val_acc: 0.9494 - val_mDice: 0.6330

Epoch 00011: val_mDice improved from 0.62800 to 0.63298, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 18s - loss: 0.3547 - acc: 0.9428 - mDice: 0.6878 - val_loss: 0.4701 - val_acc: 0.9476 - val_mDice: 0.6279

Epoch 00012: val_mDice did not improve from 0.63298
Epoch 13/300
 - 18s - loss: 0.3506 - acc: 0.9432 - mDice: 0.6909 - val_loss: 0.4821 - val_acc: 0.9471 - val_mDice: 0.6199

Epoch 00013: val_mDice did not improve from 0.63298
Epoch 14/300
 - 18s - loss: 0.3482 - acc: 0.9432 - mDice: 0.6924 - val_loss: 0.4423 - val_acc: 0.9488 - val_mDice: 0.6368

Epoch 00014: val_mDice improved from 0.63298 to 0.63681, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 18s - loss: 0.3734 - acc: 0.9408 - mDice: 0.6766 - val_loss: 0.4838 - val_acc: 0.9476 - val_mDice: 0.6179

Epoch 00015: val_mDice did not improve from 0.63681
Epoch 16/300
 - 18s - loss: 0.3446 - acc: 0.9437 - mDice: 0.6951 - val_loss: 0.4405 - val_acc: 0.9477 - val_mDice: 0.6387

Epoch 00016: val_mDice improved from 0.63681 to 0.63867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 18s - loss: 0.3375 - acc: 0.9443 - mDice: 0.7000 - val_loss: 0.4390 - val_acc: 0.9465 - val_mDice: 0.6374

Epoch 00017: val_mDice did not improve from 0.63867
Epoch 18/300
 - 18s - loss: 0.3325 - acc: 0.9447 - mDice: 0.7037 - val_loss: 0.4300 - val_acc: 0.9485 - val_mDice: 0.6441

Epoch 00018: val_mDice improved from 0.63867 to 0.64407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 18s - loss: 0.3272 - acc: 0.9452 - mDice: 0.7076 - val_loss: 0.4327 - val_acc: 0.9492 - val_mDice: 0.6427

Epoch 00019: val_mDice did not improve from 0.64407
Epoch 20/300
 - 18s - loss: 0.3255 - acc: 0.9454 - mDice: 0.7087 - val_loss: 0.4513 - val_acc: 0.9477 - val_mDice: 0.6316

Epoch 00020: val_mDice did not improve from 0.64407
Epoch 21/300
 - 18s - loss: 0.3215 - acc: 0.9456 - mDice: 0.7116 - val_loss: 0.4197 - val_acc: 0.9490 - val_mDice: 0.6480

Epoch 00021: val_mDice improved from 0.64407 to 0.64801, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 18s - loss: 0.3218 - acc: 0.9458 - mDice: 0.7117 - val_loss: 0.4649 - val_acc: 0.9489 - val_mDice: 0.6293

Epoch 00022: val_mDice did not improve from 0.64801
Epoch 23/300
 - 18s - loss: 0.3189 - acc: 0.9460 - mDice: 0.7136 - val_loss: 0.4258 - val_acc: 0.9494 - val_mDice: 0.6461

Epoch 00023: val_mDice did not improve from 0.64801
Epoch 24/300
 - 18s - loss: 0.3145 - acc: 0.9462 - mDice: 0.7168 - val_loss: 0.4284 - val_acc: 0.9471 - val_mDice: 0.6424

Epoch 00024: val_mDice did not improve from 0.64801
Epoch 25/300
 - 21s - loss: 0.3113 - acc: 0.9466 - mDice: 0.7192 - val_loss: 0.4257 - val_acc: 0.9479 - val_mDice: 0.6441

Epoch 00025: val_mDice did not improve from 0.64801
Epoch 26/300
 - 22s - loss: 0.3086 - acc: 0.9470 - mDice: 0.7213 - val_loss: 0.4304 - val_acc: 0.9481 - val_mDice: 0.6422

Epoch 00026: val_mDice did not improve from 0.64801
Epoch 27/300
 - 22s - loss: 0.3082 - acc: 0.9468 - mDice: 0.7214 - val_loss: 0.4418 - val_acc: 0.9505 - val_mDice: 0.6406

Epoch 00027: val_mDice did not improve from 0.64801
Epoch 28/300
 - 21s - loss: 0.3062 - acc: 0.9471 - mDice: 0.7230 - val_loss: 0.4228 - val_acc: 0.9501 - val_mDice: 0.6487

Epoch 00028: val_mDice improved from 0.64801 to 0.64868, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 22s - loss: 0.3025 - acc: 0.9473 - mDice: 0.7258 - val_loss: 0.4374 - val_acc: 0.9434 - val_mDice: 0.6358

Epoch 00029: val_mDice did not improve from 0.64868
Epoch 30/300
 - 21s - loss: 0.3004 - acc: 0.9477 - mDice: 0.7274 - val_loss: 0.4497 - val_acc: 0.9412 - val_mDice: 0.6300

Epoch 00030: val_mDice did not improve from 0.64868
Epoch 31/300
 - 21s - loss: 0.2979 - acc: 0.9477 - mDice: 0.7293 - val_loss: 0.4214 - val_acc: 0.9510 - val_mDice: 0.6507

Epoch 00031: val_mDice improved from 0.64868 to 0.65065, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 18s - loss: 0.2965 - acc: 0.9479 - mDice: 0.7303 - val_loss: 0.4422 - val_acc: 0.9433 - val_mDice: 0.6323

Epoch 00032: val_mDice did not improve from 0.65065
Epoch 33/300
 - 18s - loss: 0.2962 - acc: 0.9481 - mDice: 0.7306 - val_loss: 0.4322 - val_acc: 0.9489 - val_mDice: 0.6425

Epoch 00033: val_mDice did not improve from 0.65065
Epoch 34/300
 - 19s - loss: 0.3005 - acc: 0.9478 - mDice: 0.7277 - val_loss: 0.4499 - val_acc: 0.9416 - val_mDice: 0.6282

Epoch 00034: val_mDice did not improve from 0.65065
Epoch 35/300
 - 19s - loss: 0.2938 - acc: 0.9482 - mDice: 0.7324 - val_loss: 0.4461 - val_acc: 0.9435 - val_mDice: 0.6317

Epoch 00035: val_mDice did not improve from 0.65065
Epoch 36/300
 - 18s - loss: 0.2888 - acc: 0.9485 - mDice: 0.7361 - val_loss: 0.4592 - val_acc: 0.9500 - val_mDice: 0.6357

Epoch 00036: val_mDice did not improve from 0.65065
Epoch 37/300
 - 18s - loss: 0.2917 - acc: 0.9484 - mDice: 0.7343 - val_loss: 0.4469 - val_acc: 0.9504 - val_mDice: 0.6377

Epoch 00037: val_mDice did not improve from 0.65065
Epoch 38/300
 - 18s - loss: 0.2873 - acc: 0.9488 - mDice: 0.7373 - val_loss: 0.4270 - val_acc: 0.9521 - val_mDice: 0.6478

Epoch 00038: val_mDice did not improve from 0.65065
Epoch 39/300
 - 18s - loss: 0.2848 - acc: 0.9489 - mDice: 0.7391 - val_loss: 0.5509 - val_acc: 0.9460 - val_mDice: 0.5964

Epoch 00039: val_mDice did not improve from 0.65065
Epoch 40/300
 - 18s - loss: 0.2839 - acc: 0.9489 - mDice: 0.7397 - val_loss: 0.4336 - val_acc: 0.9498 - val_mDice: 0.6419

Epoch 00040: val_mDice did not improve from 0.65065
Epoch 41/300
 - 18s - loss: 0.2846 - acc: 0.9490 - mDice: 0.7395 - val_loss: 0.4313 - val_acc: 0.9495 - val_mDice: 0.6443

Epoch 00041: val_mDice did not improve from 0.65065
Epoch 42/300
 - 18s - loss: 0.2808 - acc: 0.9493 - mDice: 0.7422 - val_loss: 0.4676 - val_acc: 0.9398 - val_mDice: 0.6170

Epoch 00042: val_mDice did not improve from 0.65065
Epoch 43/300
 - 18s - loss: 0.2795 - acc: 0.9495 - mDice: 0.7431 - val_loss: 0.6282 - val_acc: 0.9421 - val_mDice: 0.5757

Epoch 00043: val_mDice did not improve from 0.65065
Epoch 44/300
 - 18s - loss: 0.2791 - acc: 0.9494 - mDice: 0.7435 - val_loss: 0.5444 - val_acc: 0.9463 - val_mDice: 0.6010

Epoch 00044: val_mDice did not improve from 0.65065
Epoch 45/300
 - 18s - loss: 0.2775 - acc: 0.9495 - mDice: 0.7447 - val_loss: 0.4683 - val_acc: 0.9493 - val_mDice: 0.6292

Epoch 00045: val_mDice did not improve from 0.65065
Epoch 46/300
 - 18s - loss: 0.2777 - acc: 0.9495 - mDice: 0.7445 - val_loss: 0.4432 - val_acc: 0.9466 - val_mDice: 0.6336

Epoch 00046: val_mDice did not improve from 0.65065
Epoch 47/300
 - 18s - loss: 0.2761 - acc: 0.9497 - mDice: 0.7458 - val_loss: 0.4609 - val_acc: 0.9485 - val_mDice: 0.6290

Epoch 00047: val_mDice did not improve from 0.65065
Epoch 48/300
 - 18s - loss: 0.2733 - acc: 0.9499 - mDice: 0.7481 - val_loss: 0.4313 - val_acc: 0.9468 - val_mDice: 0.6405

Epoch 00048: val_mDice did not improve from 0.65065
Epoch 49/300
 - 18s - loss: 0.2731 - acc: 0.9499 - mDice: 0.7482 - val_loss: 0.5080 - val_acc: 0.9480 - val_mDice: 0.6138

Epoch 00049: val_mDice did not improve from 0.65065
Epoch 50/300
 - 18s - loss: 0.2725 - acc: 0.9500 - mDice: 0.7486 - val_loss: 0.4352 - val_acc: 0.9506 - val_mDice: 0.6401

Epoch 00050: val_mDice did not improve from 0.65065
Epoch 51/300
 - 19s - loss: 0.2717 - acc: 0.9501 - mDice: 0.7495 - val_loss: 0.4556 - val_acc: 0.9500 - val_mDice: 0.6339

Epoch 00051: val_mDice did not improve from 0.65065
Epoch 52/300
 - 19s - loss: 0.2700 - acc: 0.9502 - mDice: 0.7506 - val_loss: 0.4331 - val_acc: 0.9473 - val_mDice: 0.6403

Epoch 00052: val_mDice did not improve from 0.65065
Epoch 53/300
 - 18s - loss: 0.2694 - acc: 0.9503 - mDice: 0.7511 - val_loss: 0.4341 - val_acc: 0.9498 - val_mDice: 0.6395

Epoch 00053: val_mDice did not improve from 0.65065
Epoch 54/300
 - 18s - loss: 0.2701 - acc: 0.9502 - mDice: 0.7505 - val_loss: 0.4815 - val_acc: 0.9477 - val_mDice: 0.6184

Epoch 00054: val_mDice did not improve from 0.65065
Epoch 55/300
 - 18s - loss: 0.2689 - acc: 0.9503 - mDice: 0.7514 - val_loss: 0.4705 - val_acc: 0.9482 - val_mDice: 0.6238

Epoch 00055: val_mDice did not improve from 0.65065
Epoch 56/300
 - 18s - loss: 0.2649 - acc: 0.9506 - mDice: 0.7545 - val_loss: 0.4772 - val_acc: 0.9498 - val_mDice: 0.6247

Epoch 00056: val_mDice did not improve from 0.65065
Epoch 57/300
 - 18s - loss: 0.2654 - acc: 0.9508 - mDice: 0.7541 - val_loss: 0.4833 - val_acc: 0.9467 - val_mDice: 0.6171

Epoch 00057: val_mDice did not improve from 0.65065
Epoch 58/300
 - 18s - loss: 0.2648 - acc: 0.9507 - mDice: 0.7547 - val_loss: 0.4307 - val_acc: 0.9498 - val_mDice: 0.6426

Epoch 00058: val_mDice did not improve from 0.65065
Epoch 59/300
 - 18s - loss: 0.2644 - acc: 0.9507 - mDice: 0.7550 - val_loss: 0.5182 - val_acc: 0.9470 - val_mDice: 0.6057

Epoch 00059: val_mDice did not improve from 0.65065
Epoch 60/300
 - 18s - loss: 0.2636 - acc: 0.9506 - mDice: 0.7556 - val_loss: 0.4641 - val_acc: 0.9488 - val_mDice: 0.6269

Epoch 00060: val_mDice did not improve from 0.65065
Epoch 61/300
 - 19s - loss: 0.2634 - acc: 0.9509 - mDice: 0.7564 - val_loss: 0.4441 - val_acc: 0.9502 - val_mDice: 0.6364

Epoch 00061: val_mDice did not improve from 0.65065
Epoch 62/300
 - 18s - loss: 0.2620 - acc: 0.9509 - mDice: 0.7569 - val_loss: 0.4469 - val_acc: 0.9505 - val_mDice: 0.6336

Epoch 00062: val_mDice did not improve from 0.65065
Epoch 63/300
 - 18s - loss: 0.2601 - acc: 0.9510 - mDice: 0.7582 - val_loss: 0.4417 - val_acc: 0.9520 - val_mDice: 0.6380

Epoch 00063: val_mDice did not improve from 0.65065
Epoch 64/300
 - 18s - loss: 0.2629 - acc: 0.9508 - mDice: 0.7562 - val_loss: 0.4428 - val_acc: 0.9489 - val_mDice: 0.6386

Epoch 00064: val_mDice did not improve from 0.65065
Epoch 65/300
 - 18s - loss: 0.2589 - acc: 0.9512 - mDice: 0.7593 - val_loss: 0.4280 - val_acc: 0.9483 - val_mDice: 0.6421

Epoch 00065: val_mDice did not improve from 0.65065
Epoch 66/300
 - 18s - loss: 0.2569 - acc: 0.9512 - mDice: 0.7608 - val_loss: 0.4232 - val_acc: 0.9493 - val_mDice: 0.6450

Epoch 00066: val_mDice did not improve from 0.65065
Epoch 67/300
 - 18s - loss: 0.2563 - acc: 0.9515 - mDice: 0.7613 - val_loss: 0.4142 - val_acc: 0.9497 - val_mDice: 0.6511

Epoch 00067: val_mDice improved from 0.65065 to 0.65110, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 68/300
 - 18s - loss: 0.2572 - acc: 0.9514 - mDice: 0.7608 - val_loss: 0.4443 - val_acc: 0.9501 - val_mDice: 0.6358

Epoch 00068: val_mDice did not improve from 0.65110
Epoch 69/300
 - 17s - loss: 0.2577 - acc: 0.9512 - mDice: 0.7602 - val_loss: 0.4165 - val_acc: 0.9511 - val_mDice: 0.6513

Epoch 00069: val_mDice improved from 0.65110 to 0.65132, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 70/300
 - 17s - loss: 0.2556 - acc: 0.9514 - mDice: 0.7619 - val_loss: 0.4678 - val_acc: 0.9497 - val_mDice: 0.6257

Epoch 00070: val_mDice did not improve from 0.65132
Epoch 71/300
 - 17s - loss: 0.2538 - acc: 0.9516 - mDice: 0.7633 - val_loss: 0.4255 - val_acc: 0.9487 - val_mDice: 0.6450

Epoch 00071: val_mDice did not improve from 0.65132
Epoch 72/300
 - 17s - loss: 0.2542 - acc: 0.9516 - mDice: 0.7630 - val_loss: 0.4306 - val_acc: 0.9479 - val_mDice: 0.6420

Epoch 00072: val_mDice did not improve from 0.65132
Epoch 73/300
 - 17s - loss: 0.2519 - acc: 0.9518 - mDice: 0.7647 - val_loss: 0.4399 - val_acc: 0.9499 - val_mDice: 0.6383

Epoch 00073: val_mDice did not improve from 0.65132
Epoch 74/300
 - 17s - loss: 0.2534 - acc: 0.9516 - mDice: 0.7636 - val_loss: 0.4318 - val_acc: 0.9493 - val_mDice: 0.6414

Epoch 00074: val_mDice did not improve from 0.65132
Epoch 75/300
 - 17s - loss: 0.2583 - acc: 0.9518 - mDice: 0.7647 - val_loss: 0.4229 - val_acc: 0.9505 - val_mDice: 0.6464

Epoch 00075: val_mDice did not improve from 0.65132
Epoch 76/300
 - 17s - loss: 0.2524 - acc: 0.9518 - mDice: 0.7643 - val_loss: 0.4357 - val_acc: 0.9499 - val_mDice: 0.6416

Epoch 00076: val_mDice did not improve from 0.65132
Epoch 77/300
 - 17s - loss: 0.2519 - acc: 0.9518 - mDice: 0.7648 - val_loss: 0.4329 - val_acc: 0.9494 - val_mDice: 0.6418

Epoch 00077: val_mDice did not improve from 0.65132
Epoch 78/300
 - 17s - loss: 0.2493 - acc: 0.9519 - mDice: 0.7668 - val_loss: 0.4629 - val_acc: 0.9492 - val_mDice: 0.6279

Epoch 00078: val_mDice did not improve from 0.65132
Epoch 79/300
 - 17s - loss: 0.2497 - acc: 0.9519 - mDice: 0.7665 - val_loss: 0.4259 - val_acc: 0.9490 - val_mDice: 0.6433

Epoch 00079: val_mDice did not improve from 0.65132
Epoch 80/300
 - 17s - loss: 0.2496 - acc: 0.9520 - mDice: 0.7666 - val_loss: 0.4201 - val_acc: 0.9494 - val_mDice: 0.6475

Epoch 00080: val_mDice did not improve from 0.65132
Epoch 81/300
 - 17s - loss: 0.2487 - acc: 0.9521 - mDice: 0.7673 - val_loss: 0.4315 - val_acc: 0.9458 - val_mDice: 0.6399

Epoch 00081: val_mDice did not improve from 0.65132
Epoch 82/300
 - 17s - loss: 0.2461 - acc: 0.9521 - mDice: 0.7694 - val_loss: 0.4426 - val_acc: 0.9436 - val_mDice: 0.6321

Epoch 00082: val_mDice did not improve from 0.65132
Epoch 83/300
 - 17s - loss: 0.2469 - acc: 0.9522 - mDice: 0.7688 - val_loss: 0.4296 - val_acc: 0.9482 - val_mDice: 0.6420

Epoch 00083: val_mDice did not improve from 0.65132
Epoch 84/300
 - 17s - loss: 0.2468 - acc: 0.9523 - mDice: 0.7689 - val_loss: 0.4553 - val_acc: 0.9499 - val_mDice: 0.6316

Epoch 00084: val_mDice did not improve from 0.65132
Epoch 85/300
 - 17s - loss: 0.2466 - acc: 0.9522 - mDice: 0.7689 - val_loss: 0.4288 - val_acc: 0.9502 - val_mDice: 0.6433

Epoch 00085: val_mDice did not improve from 0.65132
Epoch 86/300
 - 17s - loss: 0.2460 - acc: 0.9523 - mDice: 0.7695 - val_loss: 0.4372 - val_acc: 0.9493 - val_mDice: 0.6382

Epoch 00086: val_mDice did not improve from 0.65132
Epoch 87/300
 - 17s - loss: 0.2456 - acc: 0.9523 - mDice: 0.7700 - val_loss: 0.4346 - val_acc: 0.9484 - val_mDice: 0.6391

Epoch 00087: val_mDice did not improve from 0.65132
Epoch 88/300
 - 17s - loss: 0.2454 - acc: 0.9523 - mDice: 0.7699 - val_loss: 0.4421 - val_acc: 0.9496 - val_mDice: 0.6375

Epoch 00088: val_mDice did not improve from 0.65132
Epoch 89/300
 - 17s - loss: 0.2461 - acc: 0.9522 - mDice: 0.7694 - val_loss: 0.4384 - val_acc: 0.9440 - val_mDice: 0.6357

Epoch 00089: val_mDice did not improve from 0.65132
Epoch 90/300
 - 17s - loss: 0.2454 - acc: 0.9524 - mDice: 0.7700 - val_loss: 0.4555 - val_acc: 0.9502 - val_mDice: 0.6315

Epoch 00090: val_mDice did not improve from 0.65132
Epoch 91/300
 - 17s - loss: 0.2429 - acc: 0.9525 - mDice: 0.7720 - val_loss: 0.4391 - val_acc: 0.9508 - val_mDice: 0.6413

Epoch 00091: val_mDice did not improve from 0.65132
Epoch 92/300
 - 17s - loss: 0.2413 - acc: 0.9527 - mDice: 0.7733 - val_loss: 0.4478 - val_acc: 0.9457 - val_mDice: 0.6307

Epoch 00092: val_mDice did not improve from 0.65132
Epoch 93/300
 - 17s - loss: 0.2422 - acc: 0.9527 - mDice: 0.7726 - val_loss: 0.4294 - val_acc: 0.9451 - val_mDice: 0.6401

Epoch 00093: val_mDice did not improve from 0.65132
Epoch 94/300
 - 17s - loss: 0.2411 - acc: 0.9527 - mDice: 0.7735 - val_loss: 0.4352 - val_acc: 0.9512 - val_mDice: 0.6413

Epoch 00094: val_mDice did not improve from 0.65132
Epoch 95/300
 - 17s - loss: 0.2412 - acc: 0.9527 - mDice: 0.7733 - val_loss: 0.4198 - val_acc: 0.9479 - val_mDice: 0.6466

Epoch 00095: val_mDice did not improve from 0.65132
Epoch 96/300
 - 17s - loss: 0.2397 - acc: 0.9528 - mDice: 0.7746 - val_loss: 0.4393 - val_acc: 0.9506 - val_mDice: 0.6365

Epoch 00096: val_mDice did not improve from 0.65132
Epoch 97/300
 - 17s - loss: 0.2405 - acc: 0.9528 - mDice: 0.7740 - val_loss: 0.4389 - val_acc: 0.9507 - val_mDice: 0.6398

Epoch 00097: val_mDice did not improve from 0.65132
Epoch 98/300
 - 17s - loss: 0.2382 - acc: 0.9529 - mDice: 0.7758 - val_loss: 0.4340 - val_acc: 0.9486 - val_mDice: 0.6380

Epoch 00098: val_mDice did not improve from 0.65132
Epoch 99/300
 - 17s - loss: 0.2409 - acc: 0.9528 - mDice: 0.7737 - val_loss: 0.4424 - val_acc: 0.9504 - val_mDice: 0.6379

Epoch 00099: val_mDice did not improve from 0.65132
Epoch 100/300
 - 17s - loss: 0.2391 - acc: 0.9527 - mDice: 0.7751 - val_loss: 0.4283 - val_acc: 0.9479 - val_mDice: 0.6411

Epoch 00100: val_mDice did not improve from 0.65132
Epoch 101/300
 - 17s - loss: 0.2383 - acc: 0.9529 - mDice: 0.7757 - val_loss: 0.4655 - val_acc: 0.9385 - val_mDice: 0.6175

Epoch 00101: val_mDice did not improve from 0.65132
Epoch 102/300
 - 17s - loss: 0.2376 - acc: 0.9529 - mDice: 0.7764 - val_loss: 0.4287 - val_acc: 0.9508 - val_mDice: 0.6436

Epoch 00102: val_mDice did not improve from 0.65132
Epoch 103/300
 - 18s - loss: 0.2394 - acc: 0.9529 - mDice: 0.7749 - val_loss: 0.4458 - val_acc: 0.9497 - val_mDice: 0.6349

Epoch 00103: val_mDice did not improve from 0.65132
Epoch 104/300
 - 17s - loss: 0.2387 - acc: 0.9529 - mDice: 0.7754 - val_loss: 0.4340 - val_acc: 0.9501 - val_mDice: 0.6407

Epoch 00104: val_mDice did not improve from 0.65132
Epoch 105/300
 - 19s - loss: 0.2378 - acc: 0.9530 - mDice: 0.7762 - val_loss: 0.4906 - val_acc: 0.9491 - val_mDice: 0.6161

Epoch 00105: val_mDice did not improve from 0.65132
Epoch 106/300
 - 20s - loss: 0.2366 - acc: 0.9531 - mDice: 0.7771 - val_loss: 0.4381 - val_acc: 0.9504 - val_mDice: 0.6398

Epoch 00106: val_mDice did not improve from 0.65132
Epoch 107/300
 - 20s - loss: 0.2355 - acc: 0.9532 - mDice: 0.7780 - val_loss: 0.4180 - val_acc: 0.9496 - val_mDice: 0.6487

Epoch 00107: val_mDice did not improve from 0.65132
Epoch 108/300
 - 19s - loss: 0.2372 - acc: 0.9531 - mDice: 0.7767 - val_loss: 0.4511 - val_acc: 0.9440 - val_mDice: 0.6277

Epoch 00108: val_mDice did not improve from 0.65132
Epoch 109/300
 - 19s - loss: 0.2357 - acc: 0.9531 - mDice: 0.7779 - val_loss: 0.4592 - val_acc: 0.9493 - val_mDice: 0.6299

Epoch 00109: val_mDice did not improve from 0.65132
Restoring model weights from the end of the best epoch
Epoch 00109: early stopping
{'val_loss': [2.1331033546028406, 0.6180992760556809, 0.5267626543839773, 0.4794848975560344, 0.4851473992597972, 0.508737230765904, 0.4597154604205003, 0.457653634725733, 0.47312688679559856, 0.4601316481617326, 0.452923539471119, 0.47014279864358566, 0.4821145274537675, 0.4423078254182288, 0.48384831475873363, 0.44050862899063326, 0.43904256355677934, 0.4300430414947212, 0.4326784456452579, 0.4513315114569157, 0.41971555204256206, 0.46488634238006377, 0.4257870136846042, 0.428400938181167, 0.42572496588348496, 0.4304420303368399, 0.4418162352649878, 0.42282244182647544, 0.43739878983362346, 0.4497194622002595, 0.4214156574391304, 0.442181555726004, 0.4322452855871079, 0.4498732734656503, 0.4461014581487534, 0.45923128639552613, 0.44693642389689775, 0.4270424081924114, 0.5508839433074842, 0.43359844988964974, 0.431309590525661, 0.46762412342619386, 0.6282345333420638, 0.5443949957265921, 0.4682659183410888, 0.4431816003424056, 0.4609143871364864, 0.43129704501611965, 0.5080038118869701, 0.4352090574325399, 0.45561023680030877, 0.4331243463019107, 0.4341162476979249, 0.4815053157772578, 0.470546396700203, 0.4772160161048808, 0.4832502584508125, 0.43073959194176586, 0.5182437364091265, 0.4641357715248216, 0.4441323394471027, 0.4469006638577644, 0.4417031986493591, 0.44276615681377707, 0.42803987966361623, 0.4231832904595855, 0.41415270275258004, 0.4443232789107248, 0.41651566337186396, 0.4677513649700381, 0.42551580177131276, 0.430618905006571, 0.4399465356312745, 0.43180225778978765, 0.42292393479786866, 0.4356675706011184, 0.4329291977358203, 0.46287250983799605, 0.42590177946902336, 0.420053816433494, 0.4315463342565171, 0.4426050894226588, 0.42959198693857126, 0.4553435933082662, 0.4287931614733757, 0.4371644104203434, 0.43455700037327216, 0.44209446594224755, 0.43836391056683044, 0.455476924037257, 0.43907038053722247, 0.447839211064873, 0.4294245365663623, 0.43519493303400403, 0.4198021628755204, 0.43927497052131814, 0.43885093462382646, 0.4339569240597123, 0.44241703909339636, 0.4283021920961691, 0.4655231463570967, 0.4286608611438291, 0.44578189968217347, 0.4339606706977736, 0.49061544313498423, 0.4380983750448159, 0.4180383329273116, 0.4510883018902853, 0.45920932905893797], 'val_acc': [0.9126659306228584, 0.9334018763075483, 0.9432607859584456, 0.9440563959432832, 0.9457515013133381, 0.9473508097601275, 0.9468929353335225, 0.9468555746349037, 0.9473053588934824, 0.9472972458981453, 0.9494356208659233, 0.9475505368929382, 0.9470731713247638, 0.9487910190372603, 0.9475602634409641, 0.9477015260263537, 0.946488655628042, 0.9484873697267356, 0.9491514736878957, 0.9476901745119839, 0.9490215731850753, 0.9489468703878686, 0.9493528088779314, 0.9470634397040022, 0.9479353334886808, 0.9481074438027456, 0.9504974809944207, 0.9501159258768068, 0.9433517130554145, 0.9411759959890488, 0.9510446715016737, 0.9433419683300857, 0.9488543352336748, 0.9416387326328467, 0.943455640305864, 0.9499568144480387, 0.950404924703828, 0.952121155059084, 0.9459771856348566, 0.9498252961652499, 0.9494632068255269, 0.939792626292993, 0.9421031166475715, 0.9463051777359441, 0.9493203344920003, 0.9466185333035516, 0.9485426008278597, 0.9467792785759513, 0.9480489932053479, 0.9505884135868532, 0.9500477373177278, 0.9473199818996673, 0.9498009440746713, 0.9476641784323022, 0.9482438386754787, 0.949820413657114, 0.9466883721926533, 0.9498171671062496, 0.9469887411340754, 0.948846218011058, 0.9502019780747434, 0.9504504026250636, 0.9519815487219087, 0.9489014245939593, 0.9482892992648673, 0.9493268284391849, 0.9497311440765435, 0.9501451549800575, 0.951069028664988, 0.9496547981356898, 0.948716309899134, 0.947893130863812, 0.94989350121072, 0.9492927189414383, 0.9504699034893767, 0.9499016053287695, 0.9493771504003106, 0.9491953110018521, 0.9490248226950354, 0.9494420979039889, 0.9458424199557474, 0.9435985088348389, 0.9482032470669307, 0.9499454468700057, 0.9501532700890345, 0.9493170951275115, 0.9483575072694332, 0.949589859086571, 0.9440011973922134, 0.9502101147428472, 0.9508076297475937, 0.9457206569664868, 0.945085790563137, 0.9511615672010056, 0.9478866360711713, 0.9505575895309448, 0.9506663616667402, 0.94864325954559, 0.9503610941535192, 0.9479401990876976, 0.9384985599957459, 0.9508108606575228, 0.9496710469536748, 0.9501191512912723, 0.949133610894494, 0.9504244340227005, 0.9496077358299959, 0.9439849439242207, 0.9492830012707], 'val_mDice': [0.3010229846687182, 0.5411928951317537, 0.5894858879400483, 0.6080547182272512, 0.612691157253076, 0.6078858409367555, 0.6277277118770789, 0.6267171683886372, 0.624866487286615, 0.6279960202832594, 0.6329839407129491, 0.6279454489126273, 0.6198969132511328, 0.6368111921540389, 0.617931528717068, 0.6386682310848372, 0.6374295801981121, 0.6440720909030725, 0.6427018135151965, 0.6315903862317404, 0.6480072694467315, 0.6292535726060259, 0.6461393418886983, 0.6424415090405349, 0.6440921751319939, 0.6421508586153071, 0.640639583692483, 0.6486793346438847, 0.6357647358103001, 0.6299974250455275, 0.6506516375440232, 0.6323065415341803, 0.6425252429982449, 0.628194141895213, 0.6317217540233693, 0.6357477590547386, 0.6377258343054047, 0.6477551215083887, 0.596356860712065, 0.6418682243807096, 0.644313504509892, 0.6169704342564792, 0.5757023205993869, 0.600972906917545, 0.6292227920910991, 0.6336216330528259, 0.6290479412315585, 0.64047893733843, 0.6138488248730383, 0.6400653825584033, 0.6338955557092707, 0.6403087643866844, 0.6394916100704924, 0.6184060002895112, 0.6237721117675727, 0.6246943186360894, 0.6170658621382206, 0.6425594336597632, 0.6057109929991107, 0.6268747689876151, 0.6363730523603183, 0.6335850235418226, 0.6379960995193914, 0.6386111518169971, 0.6421340653236877, 0.6450288338018647, 0.651095707365807, 0.6357724675050018, 0.6513184769779232, 0.6257122721232421, 0.645043469912617, 0.6419581597578441, 0.6383035280180316, 0.6414442231469121, 0.6463919615914636, 0.6415977046844807, 0.6418015276286619, 0.6279278190423411, 0.6432793119274978, 0.6474920003972156, 0.639903540729631, 0.6321436674036878, 0.6419599648063065, 0.6315630103679414, 0.6432848141548482, 0.6382015106525827, 0.6390663909573927, 0.6375001757702929, 0.6356854282372387, 0.6315241751941383, 0.6413350156013001, 0.6307456459559447, 0.640131449868493, 0.6412512207707615, 0.6465517967305285, 0.636538065071647, 0.6397865947256697, 0.6380442807860408, 0.637860044519952, 0.6411118228384789, 0.6174708118675448, 0.6435981126541787, 0.6348889127690741, 0.6407166609527372, 0.6160779388238352, 0.6397575013180996, 0.6487009313935084, 0.6277148909602605, 0.6299091797348455], 'loss': [1.9014825323690148, 0.6646377397172546, 0.5227531927758307, 0.4651779148312382, 0.4349839440008824, 0.41087601584845923, 0.3980892096041854, 0.3973469387857025, 0.37781934124954186, 0.37624339303005566, 0.3613970307621872, 0.35474341652645486, 0.3506017359191907, 0.34824197229169834, 0.3734414467839817, 0.3446463738085543, 0.33749004504226965, 0.3325011947535651, 0.3271797042067755, 0.32554694530111083, 0.3215102569005011, 0.32178695202969004, 0.31890684884633275, 0.3144898422217554, 0.31131746078107053, 0.30863332130827187, 0.30823631666177825, 0.30622570313400715, 0.30253915360943545, 0.30038320163942545, 0.29786860670250936, 0.29653942019124574, 0.2961757134094001, 0.3004907455832289, 0.2937986772064775, 0.2888376693115423, 0.29172217166268033, 0.28733903061022026, 0.2848223190847442, 0.2839299364630764, 0.2845775760914073, 0.28076096873908396, 0.27954910044197456, 0.2790794593490061, 0.27749278608720224, 0.277744715641644, 0.27611061965338596, 0.2733293723401706, 0.2731020927167562, 0.27254512178053314, 0.2716726513298836, 0.2699893264593568, 0.2694254636296013, 0.27007271583686804, 0.26891453753093547, 0.26491445709109646, 0.26543905955643105, 0.2648032049790311, 0.2644341427356723, 0.2635949922276059, 0.26344225781396635, 0.2620125348444324, 0.26013128254098666, 0.26293548782804443, 0.25886449011224494, 0.2569427568451781, 0.25628699985644243, 0.25715210466128846, 0.2576506175541936, 0.2556216950962231, 0.2538481064752298, 0.2541893963675783, 0.2518641180155374, 0.2534164507025697, 0.25834933262837084, 0.25243453791600046, 0.2519060793264684, 0.24932188549519754, 0.2497224158117994, 0.2495679425348696, 0.2487343147993331, 0.24612557763905368, 0.24693156159705365, 0.2467645779312898, 0.24664266543480365, 0.2459966259532775, 0.2455584772019398, 0.24544436003588424, 0.2461229362333001, 0.24544997536415664, 0.2429452778101454, 0.24129968721278106, 0.24216468574721844, 0.24110602104953474, 0.24118566221913887, 0.2397111704205678, 0.2404842282093608, 0.2381712487731821, 0.24093960065253173, 0.23913146839878324, 0.23831536626331462, 0.2375716662324171, 0.2393672767434864, 0.23870962079068309, 0.2377594801912555, 0.23659542298173358, 0.2355494622875837, 0.23716974330525245, 0.23567527555394727], 'acc': [0.7396600112484798, 0.9019587504566811, 0.9159891317089317, 0.9260982177290638, 0.9341806135478434, 0.9373998591465675, 0.9386871995707832, 0.938891389312526, 0.9406725281766601, 0.9408338064074565, 0.9420885927168969, 0.9427593970673578, 0.9431765355860374, 0.9432341442540404, 0.9408334542922265, 0.943673278505143, 0.9443162744533972, 0.9447189461776021, 0.9452424240798647, 0.9454117652565764, 0.9456285287186096, 0.9457589826592624, 0.9459578199939565, 0.9461802348354584, 0.946564235337757, 0.946951533249808, 0.9467814671428606, 0.947101292755225, 0.9473021137636504, 0.9476880573919716, 0.9476551534862798, 0.9479454595149902, 0.9480739501774579, 0.9477688940070804, 0.9482288486790102, 0.9485028232662666, 0.9484147612125643, 0.9487873836165304, 0.9489470493822694, 0.948866117665017, 0.948999565564744, 0.9492584166355452, 0.9494520863035154, 0.9493912093952852, 0.9495127575282615, 0.9494926348882288, 0.9496635209302018, 0.9498583390402181, 0.9498938819543349, 0.9499519109093155, 0.9500604442257257, 0.9502073062858372, 0.9503003212932472, 0.9501823474797194, 0.950288916349703, 0.9505726805556887, 0.9507821742346356, 0.9506947900772874, 0.9507121332400476, 0.9506118940353004, 0.9508825983135688, 0.9509425212189148, 0.9509678759006346, 0.9508496469115666, 0.951218456102907, 0.9512226621123322, 0.951488246341879, 0.9513659228739226, 0.9512188312422261, 0.9513902975958968, 0.9515742960147539, 0.9515819153818805, 0.9518228633981084, 0.9516198432727851, 0.9518090071192368, 0.951835134653424, 0.951766610084723, 0.9519269085018038, 0.9518749795066137, 0.9519965552757983, 0.9521195999988978, 0.9521116090336835, 0.9521883801812296, 0.9522705985337386, 0.9521732117726687, 0.9522997870548446, 0.9523419949194517, 0.9523209154167775, 0.9522146019413793, 0.9523530019308022, 0.9525218775876935, 0.9527204090378731, 0.9526624044577605, 0.9526954026502606, 0.9526948437563202, 0.9527771979533881, 0.9527522853779861, 0.9529301578436836, 0.9527748880726116, 0.9527485039512592, 0.9528743021339239, 0.9529282191229042, 0.9528990320134231, 0.952864511127908, 0.9529516597507729, 0.9530967910979027, 0.9532012565129141, 0.9530586743778284, 0.9530990808630243], 'mDice': [0.23346459634127473, 0.5056867118987223, 0.5806243739696657, 0.6157605313266623, 0.6343715286293824, 0.649836113497694, 0.6582135196216937, 0.6598064021924993, 0.6717803695095759, 0.6733412157277177, 0.6830210866198924, 0.6877836093409979, 0.6908518646799238, 0.6924298568835985, 0.676566121236506, 0.695069158001791, 0.70003683521291, 0.7037186240142295, 0.707568686061511, 0.7086588222793581, 0.7115682942398035, 0.7117094839772871, 0.7136456592441238, 0.7167660226112192, 0.7191851097936774, 0.7212904565380076, 0.7214467403790376, 0.7229712349801902, 0.7257750669198408, 0.7273555524181765, 0.7292963258827789, 0.730264459850351, 0.7305682787923435, 0.7277219313633787, 0.7324290364043671, 0.7361047162407026, 0.7343035679585888, 0.7372770389886524, 0.7391081836307326, 0.739722183233575, 0.7394537557845896, 0.7421812075602857, 0.7431418791431561, 0.7434802768594541, 0.744684054102884, 0.7445202719902398, 0.7457842966667143, 0.7481032361201532, 0.748196626120852, 0.748624279225004, 0.7494531527447574, 0.7505931010315398, 0.7510957703779259, 0.7505345546186774, 0.7513832000505198, 0.7545032920935729, 0.7541340483042989, 0.7547331629674646, 0.7550064326062792, 0.7556297389669484, 0.7564444826081511, 0.7568992731667578, 0.7581825140131985, 0.7562142424726545, 0.759298911334155, 0.7607930916311694, 0.7612979398814451, 0.7607835074768791, 0.7602028391248307, 0.7618768639518758, 0.7632726353131882, 0.7630114489888697, 0.764746141000493, 0.7636257921520083, 0.7646668630139883, 0.7643463425657709, 0.764842038217395, 0.7668436613190948, 0.7665071763302074, 0.766614189606484, 0.7673368751029181, 0.769402736228259, 0.7687615099830402, 0.7689278162757247, 0.7689101558624359, 0.7694824275409703, 0.7699891948709686, 0.7699470882052644, 0.7693598961625697, 0.770003331004478, 0.7719564603123679, 0.7732927557058167, 0.7726231883646956, 0.7734836704904277, 0.7733364723053889, 0.7745924743524422, 0.7739623093201025, 0.7757868709346137, 0.7737081734780732, 0.7751067281621191, 0.7757461385952789, 0.7764089652327627, 0.7748984065942737, 0.7753666743252802, 0.776150569885592, 0.7771421424487797, 0.7779943520388052, 0.7767123673316555, 0.7778889127729766]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:04<00:14,  5.00s/it]predicting test subjects:  50%|█████     | 2/4 [00:08<00:08,  4.45s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:11<00:04,  4.06s/it]predicting test subjects: 100%|██████████| 4/4 [00:15<00:00,  4.03s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<16:53,  3.82s/it]predicting train subjects:   1%|          | 2/266 [00:08<17:26,  3.97s/it]predicting train subjects:   1%|          | 3/266 [00:11<16:46,  3.83s/it]predicting train subjects:   2%|▏         | 4/266 [00:15<16:08,  3.70s/it]predicting train subjects:   2%|▏         | 5/266 [00:19<16:40,  3.83s/it]predicting train subjects:   2%|▏         | 6/266 [00:23<17:23,  4.01s/it]predicting train subjects:   3%|▎         | 7/266 [00:28<17:54,  4.15s/it]predicting train subjects:   3%|▎         | 8/266 [00:32<17:53,  4.16s/it]predicting train subjects:   3%|▎         | 9/266 [00:36<17:39,  4.12s/it]predicting train subjects:   4%|▍         | 10/266 [00:40<17:36,  4.13s/it]predicting train subjects:   4%|▍         | 11/266 [00:44<17:58,  4.23s/it]predicting train subjects:   5%|▍         | 12/266 [00:49<18:05,  4.27s/it]predicting train subjects:   5%|▍         | 13/266 [00:53<17:55,  4.25s/it]predicting train subjects:   5%|▌         | 14/266 [00:57<18:10,  4.33s/it]predicting train subjects:   6%|▌         | 15/266 [01:02<17:56,  4.29s/it]predicting train subjects:   6%|▌         | 16/266 [01:06<18:19,  4.40s/it]predicting train subjects:   6%|▋         | 17/266 [01:11<18:31,  4.46s/it]predicting train subjects:   7%|▋         | 18/266 [01:16<19:09,  4.64s/it]predicting train subjects:   7%|▋         | 19/266 [01:20<18:49,  4.57s/it]predicting train subjects:   8%|▊         | 20/266 [01:25<18:59,  4.63s/it]predicting train subjects:   8%|▊         | 21/266 [01:29<18:10,  4.45s/it]predicting train subjects:   8%|▊         | 22/266 [01:34<18:46,  4.62s/it]predicting train subjects:   9%|▊         | 23/266 [01:39<19:19,  4.77s/it]predicting train subjects:   9%|▉         | 24/266 [01:44<18:53,  4.69s/it]predicting train subjects:   9%|▉         | 25/266 [01:49<18:56,  4.72s/it]predicting train subjects:  10%|▉         | 26/266 [01:53<18:45,  4.69s/it]predicting train subjects:  10%|█         | 27/266 [01:58<18:43,  4.70s/it]predicting train subjects:  11%|█         | 28/266 [02:02<18:23,  4.63s/it]predicting train subjects:  11%|█         | 29/266 [02:07<18:01,  4.56s/it]predicting train subjects:  11%|█▏        | 30/266 [02:12<18:08,  4.61s/it]predicting train subjects:  12%|█▏        | 31/266 [02:16<18:15,  4.66s/it]predicting train subjects:  12%|█▏        | 32/266 [02:21<18:35,  4.77s/it]predicting train subjects:  12%|█▏        | 33/266 [02:26<18:24,  4.74s/it]predicting train subjects:  13%|█▎        | 34/266 [02:30<17:44,  4.59s/it]predicting train subjects:  13%|█▎        | 35/266 [02:35<17:21,  4.51s/it]predicting train subjects:  14%|█▎        | 36/266 [02:39<16:58,  4.43s/it]predicting train subjects:  14%|█▍        | 37/266 [02:43<16:45,  4.39s/it]predicting train subjects:  14%|█▍        | 38/266 [02:48<17:10,  4.52s/it]predicting train subjects:  15%|█▍        | 39/266 [02:52<17:00,  4.50s/it]predicting train subjects:  15%|█▌        | 40/266 [02:57<16:49,  4.47s/it]predicting train subjects:  15%|█▌        | 41/266 [03:01<16:52,  4.50s/it]predicting train subjects:  16%|█▌        | 42/266 [03:05<16:00,  4.29s/it]predicting train subjects:  16%|█▌        | 43/266 [03:09<15:33,  4.19s/it]predicting train subjects:  17%|█▋        | 44/266 [03:13<14:48,  4.00s/it]predicting train subjects:  17%|█▋        | 45/266 [03:16<14:20,  3.89s/it]predicting train subjects:  17%|█▋        | 46/266 [03:20<13:56,  3.80s/it]predicting train subjects:  18%|█▊        | 47/266 [03:24<13:47,  3.78s/it]predicting train subjects:  18%|█▊        | 48/266 [03:27<13:40,  3.76s/it]predicting train subjects:  18%|█▊        | 49/266 [03:31<13:38,  3.77s/it]predicting train subjects:  19%|█▉        | 50/266 [03:35<13:47,  3.83s/it]predicting train subjects:  19%|█▉        | 51/266 [03:39<13:15,  3.70s/it]predicting train subjects:  20%|█▉        | 52/266 [03:42<13:03,  3.66s/it]predicting train subjects:  20%|█▉        | 53/266 [03:46<13:02,  3.67s/it]predicting train subjects:  20%|██        | 54/266 [03:50<13:07,  3.72s/it]predicting train subjects:  21%|██        | 55/266 [03:54<13:17,  3.78s/it]predicting train subjects:  21%|██        | 56/266 [03:57<13:21,  3.82s/it]predicting train subjects:  21%|██▏       | 57/266 [04:01<13:19,  3.82s/it]predicting train subjects:  22%|██▏       | 58/266 [04:05<13:26,  3.88s/it]predicting train subjects:  22%|██▏       | 59/266 [04:09<13:09,  3.81s/it]predicting train subjects:  23%|██▎       | 60/266 [04:12<12:47,  3.72s/it]predicting train subjects:  23%|██▎       | 61/266 [04:16<12:43,  3.73s/it]predicting train subjects:  23%|██▎       | 62/266 [04:20<12:56,  3.80s/it]predicting train subjects:  24%|██▎       | 63/266 [04:24<12:50,  3.79s/it]predicting train subjects:  24%|██▍       | 64/266 [04:28<13:00,  3.87s/it]predicting train subjects:  24%|██▍       | 65/266 [04:32<12:37,  3.77s/it]predicting train subjects:  25%|██▍       | 66/266 [04:35<12:33,  3.77s/it]predicting train subjects:  25%|██▌       | 67/266 [04:39<12:17,  3.71s/it]predicting train subjects:  26%|██▌       | 68/266 [04:42<12:05,  3.66s/it]predicting train subjects:  26%|██▌       | 69/266 [04:46<12:17,  3.74s/it]predicting train subjects:  26%|██▋       | 70/266 [04:50<11:58,  3.67s/it]predicting train subjects:  27%|██▋       | 71/266 [04:53<11:41,  3.60s/it]predicting train subjects:  27%|██▋       | 72/266 [04:57<11:32,  3.57s/it]predicting train subjects:  27%|██▋       | 73/266 [05:00<11:18,  3.51s/it]predicting train subjects:  28%|██▊       | 74/266 [05:04<11:05,  3.47s/it]predicting train subjects:  28%|██▊       | 75/266 [05:07<11:07,  3.49s/it]predicting train subjects:  29%|██▊       | 76/266 [05:11<11:24,  3.60s/it]predicting train subjects:  29%|██▉       | 77/266 [05:15<11:48,  3.75s/it]predicting train subjects:  29%|██▉       | 78/266 [05:20<13:01,  4.15s/it]predicting train subjects:  30%|██▉       | 79/266 [05:25<13:19,  4.28s/it]predicting train subjects:  30%|███       | 80/266 [05:29<13:26,  4.34s/it]predicting train subjects:  30%|███       | 81/266 [05:34<13:59,  4.54s/it]predicting train subjects:  31%|███       | 82/266 [05:39<13:46,  4.49s/it]predicting train subjects:  31%|███       | 83/266 [05:43<13:28,  4.42s/it]predicting train subjects:  32%|███▏      | 84/266 [05:47<13:15,  4.37s/it]predicting train subjects:  32%|███▏      | 85/266 [05:52<13:21,  4.43s/it]predicting train subjects:  32%|███▏      | 86/266 [05:56<12:48,  4.27s/it]predicting train subjects:  33%|███▎      | 87/266 [06:00<12:49,  4.30s/it]predicting train subjects:  33%|███▎      | 88/266 [06:04<12:49,  4.32s/it]predicting train subjects:  33%|███▎      | 89/266 [06:09<12:52,  4.37s/it]predicting train subjects:  34%|███▍      | 90/266 [06:13<12:54,  4.40s/it]predicting train subjects:  34%|███▍      | 91/266 [06:17<12:25,  4.26s/it]predicting train subjects:  35%|███▍      | 92/266 [06:21<12:24,  4.28s/it]predicting train subjects:  35%|███▍      | 93/266 [06:26<12:28,  4.33s/it]predicting train subjects:  35%|███▌      | 94/266 [06:30<12:14,  4.27s/it]predicting train subjects:  36%|███▌      | 95/266 [06:34<11:57,  4.20s/it]predicting train subjects:  36%|███▌      | 96/266 [06:38<11:30,  4.06s/it]predicting train subjects:  36%|███▋      | 97/266 [06:42<11:36,  4.12s/it]predicting train subjects:  37%|███▋      | 98/266 [06:46<11:37,  4.15s/it]predicting train subjects:  37%|███▋      | 99/266 [06:50<10:54,  3.92s/it]predicting train subjects:  38%|███▊      | 100/266 [06:53<10:30,  3.80s/it]predicting train subjects:  38%|███▊      | 101/266 [06:57<10:40,  3.88s/it]predicting train subjects:  38%|███▊      | 102/266 [07:01<10:40,  3.90s/it]predicting train subjects:  39%|███▊      | 103/266 [07:05<10:40,  3.93s/it]predicting train subjects:  39%|███▉      | 104/266 [07:09<10:43,  3.97s/it]predicting train subjects:  39%|███▉      | 105/266 [07:13<10:32,  3.93s/it]predicting train subjects:  40%|███▉      | 106/266 [07:17<10:49,  4.06s/it]predicting train subjects:  40%|████      | 107/266 [07:22<10:50,  4.09s/it]predicting train subjects:  41%|████      | 108/266 [07:25<10:26,  3.96s/it]predicting train subjects:  41%|████      | 109/266 [07:29<09:59,  3.82s/it]predicting train subjects:  41%|████▏     | 110/266 [07:33<10:26,  4.01s/it]predicting train subjects:  42%|████▏     | 111/266 [07:37<10:18,  3.99s/it]predicting train subjects:  42%|████▏     | 112/266 [07:41<10:14,  3.99s/it]predicting train subjects:  42%|████▏     | 113/266 [07:45<10:09,  3.98s/it]predicting train subjects:  43%|████▎     | 114/266 [07:49<10:07,  4.00s/it]predicting train subjects:  43%|████▎     | 115/266 [07:54<10:29,  4.17s/it]predicting train subjects:  44%|████▎     | 116/266 [07:58<10:10,  4.07s/it]predicting train subjects:  44%|████▍     | 117/266 [08:02<10:13,  4.12s/it]predicting train subjects:  44%|████▍     | 118/266 [08:06<09:53,  4.01s/it]predicting train subjects:  45%|████▍     | 119/266 [08:10<10:03,  4.11s/it]predicting train subjects:  45%|████▌     | 120/266 [08:14<10:11,  4.19s/it]predicting train subjects:  45%|████▌     | 121/266 [08:19<10:10,  4.21s/it]predicting train subjects:  46%|████▌     | 122/266 [08:23<10:07,  4.22s/it]predicting train subjects:  46%|████▌     | 123/266 [08:28<10:26,  4.38s/it]predicting train subjects:  47%|████▋     | 124/266 [08:33<11:03,  4.68s/it]predicting train subjects:  47%|████▋     | 125/266 [08:38<10:58,  4.67s/it]predicting train subjects:  47%|████▋     | 126/266 [08:42<10:36,  4.54s/it]predicting train subjects:  48%|████▊     | 127/266 [08:46<10:32,  4.55s/it]predicting train subjects:  48%|████▊     | 128/266 [08:51<10:28,  4.55s/it]predicting train subjects:  48%|████▊     | 129/266 [08:55<10:19,  4.52s/it]predicting train subjects:  49%|████▉     | 130/266 [09:00<10:25,  4.60s/it]predicting train subjects:  49%|████▉     | 131/266 [09:05<10:14,  4.55s/it]predicting train subjects:  50%|████▉     | 132/266 [09:09<09:43,  4.35s/it]predicting train subjects:  50%|█████     | 133/266 [09:13<09:54,  4.47s/it]predicting train subjects:  50%|█████     | 134/266 [09:18<09:44,  4.43s/it]predicting train subjects:  51%|█████     | 135/266 [09:22<09:49,  4.50s/it]predicting train subjects:  51%|█████     | 136/266 [09:27<09:57,  4.60s/it]predicting train subjects:  52%|█████▏    | 137/266 [09:31<09:43,  4.53s/it]predicting train subjects:  52%|█████▏    | 138/266 [09:36<09:21,  4.39s/it]predicting train subjects:  52%|█████▏    | 139/266 [09:39<09:00,  4.25s/it]predicting train subjects:  53%|█████▎    | 140/266 [09:44<08:51,  4.22s/it]predicting train subjects:  53%|█████▎    | 141/266 [09:48<08:57,  4.30s/it]predicting train subjects:  53%|█████▎    | 142/266 [09:52<08:51,  4.29s/it]predicting train subjects:  54%|█████▍    | 143/266 [09:56<08:37,  4.21s/it]predicting train subjects:  54%|█████▍    | 144/266 [10:01<08:33,  4.21s/it]predicting train subjects:  55%|█████▍    | 145/266 [10:05<08:31,  4.23s/it]predicting train subjects:  55%|█████▍    | 146/266 [10:09<08:26,  4.22s/it]predicting train subjects:  55%|█████▌    | 147/266 [10:14<08:32,  4.31s/it]predicting train subjects:  56%|█████▌    | 148/266 [10:17<08:08,  4.14s/it]predicting train subjects:  56%|█████▌    | 149/266 [10:22<08:09,  4.18s/it]predicting train subjects:  56%|█████▋    | 150/266 [10:26<08:14,  4.26s/it]predicting train subjects:  57%|█████▋    | 151/266 [10:30<08:04,  4.22s/it]predicting train subjects:  57%|█████▋    | 152/266 [10:35<08:06,  4.27s/it]predicting train subjects:  58%|█████▊    | 153/266 [10:39<08:01,  4.26s/it]predicting train subjects:  58%|█████▊    | 154/266 [10:43<07:56,  4.25s/it]predicting train subjects:  58%|█████▊    | 155/266 [10:47<07:29,  4.05s/it]predicting train subjects:  59%|█████▊    | 156/266 [10:50<06:59,  3.82s/it]predicting train subjects:  59%|█████▉    | 157/266 [10:53<06:44,  3.71s/it]predicting train subjects:  59%|█████▉    | 158/266 [10:57<06:29,  3.61s/it]predicting train subjects:  60%|█████▉    | 159/266 [11:00<06:09,  3.46s/it]predicting train subjects:  60%|██████    | 160/266 [11:03<06:10,  3.50s/it]predicting train subjects:  61%|██████    | 161/266 [11:06<05:52,  3.35s/it]predicting train subjects:  61%|██████    | 162/266 [11:10<05:45,  3.32s/it]predicting train subjects:  61%|██████▏   | 163/266 [11:13<05:47,  3.37s/it]predicting train subjects:  62%|██████▏   | 164/266 [11:16<05:40,  3.34s/it]predicting train subjects:  62%|██████▏   | 165/266 [11:20<05:32,  3.29s/it]predicting train subjects:  62%|██████▏   | 166/266 [11:23<05:19,  3.20s/it]predicting train subjects:  63%|██████▎   | 167/266 [11:26<05:14,  3.18s/it]predicting train subjects:  63%|██████▎   | 168/266 [11:29<05:14,  3.21s/it]predicting train subjects:  64%|██████▎   | 169/266 [11:33<05:24,  3.34s/it]predicting train subjects:  64%|██████▍   | 170/266 [11:36<05:33,  3.47s/it]predicting train subjects:  64%|██████▍   | 171/266 [11:40<05:25,  3.43s/it]predicting train subjects:  65%|██████▍   | 172/266 [11:43<05:16,  3.37s/it]predicting train subjects:  65%|██████▌   | 173/266 [11:47<05:30,  3.56s/it]predicting train subjects:  65%|██████▌   | 174/266 [11:51<05:29,  3.58s/it]predicting train subjects:  66%|██████▌   | 175/266 [11:54<05:14,  3.46s/it]predicting train subjects:  66%|██████▌   | 176/266 [11:57<05:13,  3.49s/it]predicting train subjects:  67%|██████▋   | 177/266 [12:01<05:18,  3.58s/it]predicting train subjects:  67%|██████▋   | 178/266 [12:05<05:19,  3.63s/it]predicting train subjects:  67%|██████▋   | 179/266 [12:09<05:26,  3.75s/it]predicting train subjects:  68%|██████▊   | 180/266 [12:13<05:29,  3.83s/it]predicting train subjects:  68%|██████▊   | 181/266 [12:17<05:27,  3.86s/it]predicting train subjects:  68%|██████▊   | 182/266 [12:21<05:19,  3.80s/it]predicting train subjects:  69%|██████▉   | 183/266 [12:24<05:18,  3.84s/it]predicting train subjects:  69%|██████▉   | 184/266 [12:28<05:09,  3.77s/it]predicting train subjects:  70%|██████▉   | 185/266 [12:32<04:58,  3.69s/it]predicting train subjects:  70%|██████▉   | 186/266 [12:35<04:57,  3.71s/it]predicting train subjects:  70%|███████   | 187/266 [12:39<04:55,  3.74s/it]predicting train subjects:  71%|███████   | 188/266 [12:43<04:58,  3.82s/it]predicting train subjects:  71%|███████   | 189/266 [12:47<04:45,  3.70s/it]predicting train subjects:  71%|███████▏  | 190/266 [12:50<04:36,  3.64s/it]predicting train subjects:  72%|███████▏  | 191/266 [12:54<04:31,  3.62s/it]predicting train subjects:  72%|███████▏  | 192/266 [12:57<04:12,  3.41s/it]predicting train subjects:  73%|███████▎  | 193/266 [13:00<04:16,  3.52s/it]predicting train subjects:  73%|███████▎  | 194/266 [13:05<04:36,  3.84s/it]predicting train subjects:  73%|███████▎  | 195/266 [13:08<04:24,  3.73s/it]predicting train subjects:  74%|███████▎  | 196/266 [13:12<04:10,  3.58s/it]predicting train subjects:  74%|███████▍  | 197/266 [13:15<03:54,  3.40s/it]predicting train subjects:  74%|███████▍  | 198/266 [13:18<03:56,  3.47s/it]predicting train subjects:  75%|███████▍  | 199/266 [13:21<03:46,  3.38s/it]predicting train subjects:  75%|███████▌  | 200/266 [13:25<03:43,  3.39s/it]predicting train subjects:  76%|███████▌  | 201/266 [13:28<03:39,  3.38s/it]predicting train subjects:  76%|███████▌  | 202/266 [13:31<03:29,  3.28s/it]predicting train subjects:  76%|███████▋  | 203/266 [13:34<03:23,  3.23s/it]predicting train subjects:  77%|███████▋  | 204/266 [13:38<03:20,  3.24s/it]predicting train subjects:  77%|███████▋  | 205/266 [13:41<03:17,  3.24s/it]predicting train subjects:  77%|███████▋  | 206/266 [13:44<03:12,  3.20s/it]predicting train subjects:  78%|███████▊  | 207/266 [13:47<03:07,  3.18s/it]predicting train subjects:  78%|███████▊  | 208/266 [13:50<03:06,  3.21s/it]predicting train subjects:  79%|███████▊  | 209/266 [13:53<03:00,  3.17s/it]predicting train subjects:  79%|███████▉  | 210/266 [13:57<02:57,  3.17s/it]predicting train subjects:  79%|███████▉  | 211/266 [14:00<02:50,  3.10s/it]predicting train subjects:  80%|███████▉  | 212/266 [14:02<02:42,  3.02s/it]predicting train subjects:  80%|████████  | 213/266 [14:05<02:37,  2.98s/it]predicting train subjects:  80%|████████  | 214/266 [14:08<02:29,  2.88s/it]predicting train subjects:  81%|████████  | 215/266 [14:11<02:24,  2.84s/it]predicting train subjects:  81%|████████  | 216/266 [14:13<02:14,  2.70s/it]predicting train subjects:  82%|████████▏ | 217/266 [14:16<02:11,  2.68s/it]predicting train subjects:  82%|████████▏ | 218/266 [14:18<02:05,  2.61s/it]predicting train subjects:  82%|████████▏ | 219/266 [14:21<02:03,  2.63s/it]predicting train subjects:  83%|████████▎ | 220/266 [14:23<02:01,  2.64s/it]predicting train subjects:  83%|████████▎ | 221/266 [14:26<02:01,  2.70s/it]predicting train subjects:  83%|████████▎ | 222/266 [14:29<02:01,  2.75s/it]predicting train subjects:  84%|████████▍ | 223/266 [14:32<02:02,  2.86s/it]predicting train subjects:  84%|████████▍ | 224/266 [14:35<01:58,  2.81s/it]predicting train subjects:  85%|████████▍ | 225/266 [14:38<01:53,  2.77s/it]predicting train subjects:  85%|████████▍ | 226/266 [14:40<01:51,  2.79s/it]predicting train subjects:  85%|████████▌ | 227/266 [14:43<01:46,  2.74s/it]predicting train subjects:  86%|████████▌ | 228/266 [14:46<01:44,  2.75s/it]predicting train subjects:  86%|████████▌ | 229/266 [14:49<01:41,  2.73s/it]predicting train subjects:  86%|████████▋ | 230/266 [14:51<01:36,  2.68s/it]predicting train subjects:  87%|████████▋ | 231/266 [14:54<01:33,  2.67s/it]predicting train subjects:  87%|████████▋ | 232/266 [14:56<01:26,  2.54s/it]predicting train subjects:  88%|████████▊ | 233/266 [14:59<01:29,  2.70s/it]predicting train subjects:  88%|████████▊ | 234/266 [15:02<01:25,  2.69s/it]predicting train subjects:  88%|████████▊ | 235/266 [15:04<01:19,  2.57s/it]predicting train subjects:  89%|████████▊ | 236/266 [15:06<01:15,  2.53s/it]predicting train subjects:  89%|████████▉ | 237/266 [15:09<01:12,  2.50s/it]predicting train subjects:  89%|████████▉ | 238/266 [15:12<01:11,  2.55s/it]predicting train subjects:  90%|████████▉ | 239/266 [15:14<01:07,  2.50s/it]predicting train subjects:  90%|█████████ | 240/266 [15:16<01:04,  2.49s/it]predicting train subjects:  91%|█████████ | 241/266 [15:19<01:02,  2.48s/it]predicting train subjects:  91%|█████████ | 242/266 [15:22<01:00,  2.52s/it]predicting train subjects:  91%|█████████▏| 243/266 [15:24<00:57,  2.49s/it]predicting train subjects:  92%|█████████▏| 244/266 [15:26<00:54,  2.49s/it]predicting train subjects:  92%|█████████▏| 245/266 [15:29<00:55,  2.66s/it]predicting train subjects:  92%|█████████▏| 246/266 [15:32<00:52,  2.64s/it]predicting train subjects:  93%|█████████▎| 247/266 [15:35<00:51,  2.73s/it]predicting train subjects:  93%|█████████▎| 248/266 [15:38<00:48,  2.71s/it]predicting train subjects:  94%|█████████▎| 249/266 [15:41<00:49,  2.88s/it]predicting train subjects:  94%|█████████▍| 250/266 [15:44<00:48,  3.03s/it]predicting train subjects:  94%|█████████▍| 251/266 [15:48<00:47,  3.14s/it]predicting train subjects:  95%|█████████▍| 252/266 [15:51<00:46,  3.31s/it]predicting train subjects:  95%|█████████▌| 253/266 [15:55<00:42,  3.28s/it]predicting train subjects:  95%|█████████▌| 254/266 [15:58<00:40,  3.37s/it]predicting train subjects:  96%|█████████▌| 255/266 [16:01<00:36,  3.33s/it]predicting train subjects:  96%|█████████▌| 256/266 [16:05<00:33,  3.38s/it]predicting train subjects:  97%|█████████▋| 257/266 [16:08<00:30,  3.41s/it]predicting train subjects:  97%|█████████▋| 258/266 [16:12<00:27,  3.47s/it]predicting train subjects:  97%|█████████▋| 259/266 [16:15<00:23,  3.32s/it]predicting train subjects:  98%|█████████▊| 260/266 [16:18<00:20,  3.37s/it]predicting train subjects:  98%|█████████▊| 261/266 [16:22<00:16,  3.30s/it]predicting train subjects:  98%|█████████▊| 262/266 [16:25<00:13,  3.32s/it]predicting train subjects:  99%|█████████▉| 263/266 [16:28<00:10,  3.34s/it]predicting train subjects:  99%|█████████▉| 264/266 [16:32<00:06,  3.32s/it]predicting train subjects: 100%|█████████▉| 265/266 [16:35<00:03,  3.28s/it]predicting train subjects: 100%|██████████| 266/266 [16:38<00:00,  3.37s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:13,  1.98it/s]Loading train:   1%|          | 2/266 [00:01<02:22,  1.85it/s]Loading train:   1%|          | 3/266 [00:01<02:24,  1.82it/s]Loading train:   2%|▏         | 4/266 [00:02<02:24,  1.81it/s]Loading train:   2%|▏         | 5/266 [00:02<02:36,  1.66it/s]Loading train:   2%|▏         | 6/266 [00:03<02:30,  1.73it/s]Loading train:   3%|▎         | 7/266 [00:04<02:40,  1.61it/s]Loading train:   3%|▎         | 8/266 [00:04<02:26,  1.76it/s]Loading train:   3%|▎         | 9/266 [00:05<02:25,  1.76it/s]Loading train:   4%|▍         | 10/266 [00:05<02:28,  1.73it/s]Loading train:   4%|▍         | 11/266 [00:06<02:28,  1.72it/s]Loading train:   5%|▍         | 12/266 [00:07<02:30,  1.69it/s]Loading train:   5%|▍         | 13/266 [00:07<02:30,  1.69it/s]Loading train:   5%|▌         | 14/266 [00:08<02:24,  1.74it/s]Loading train:   6%|▌         | 15/266 [00:08<02:24,  1.74it/s]Loading train:   6%|▌         | 16/266 [00:09<02:25,  1.71it/s]Loading train:   6%|▋         | 17/266 [00:09<02:24,  1.72it/s]Loading train:   7%|▋         | 18/266 [00:10<02:28,  1.67it/s]Loading train:   7%|▋         | 19/266 [00:11<02:21,  1.74it/s]Loading train:   8%|▊         | 20/266 [00:11<02:16,  1.80it/s]Loading train:   8%|▊         | 21/266 [00:12<02:18,  1.77it/s]Loading train:   8%|▊         | 22/266 [00:12<02:11,  1.86it/s]Loading train:   9%|▊         | 23/266 [00:13<02:18,  1.76it/s]Loading train:   9%|▉         | 24/266 [00:13<02:24,  1.68it/s]Loading train:   9%|▉         | 25/266 [00:14<02:20,  1.71it/s]Loading train:  10%|▉         | 26/266 [00:15<02:16,  1.76it/s]Loading train:  10%|█         | 27/266 [00:15<02:19,  1.71it/s]Loading train:  11%|█         | 28/266 [00:16<02:11,  1.81it/s]Loading train:  11%|█         | 29/266 [00:16<02:13,  1.77it/s]Loading train:  11%|█▏        | 30/266 [00:17<02:08,  1.83it/s]Loading train:  12%|█▏        | 31/266 [00:17<02:14,  1.74it/s]Loading train:  12%|█▏        | 32/266 [00:18<02:17,  1.70it/s]Loading train:  12%|█▏        | 33/266 [00:19<02:31,  1.54it/s]Loading train:  13%|█▎        | 34/266 [00:19<02:20,  1.65it/s]Loading train:  13%|█▎        | 35/266 [00:20<02:11,  1.75it/s]Loading train:  14%|█▎        | 36/266 [00:20<02:17,  1.67it/s]Loading train:  14%|█▍        | 37/266 [00:21<02:05,  1.83it/s]Loading train:  14%|█▍        | 38/266 [00:21<02:04,  1.83it/s]Loading train:  15%|█▍        | 39/266 [00:22<02:07,  1.78it/s]Loading train:  15%|█▌        | 40/266 [00:23<02:06,  1.79it/s]Loading train:  15%|█▌        | 41/266 [00:23<02:05,  1.79it/s]Loading train:  16%|█▌        | 42/266 [00:24<02:00,  1.86it/s]Loading train:  16%|█▌        | 43/266 [00:24<02:11,  1.70it/s]Loading train:  17%|█▋        | 44/266 [00:25<02:10,  1.70it/s]Loading train:  17%|█▋        | 45/266 [00:25<02:04,  1.77it/s]Loading train:  17%|█▋        | 46/266 [00:26<02:08,  1.71it/s]Loading train:  18%|█▊        | 47/266 [00:27<02:08,  1.70it/s]Loading train:  18%|█▊        | 48/266 [00:27<01:59,  1.83it/s]Loading train:  18%|█▊        | 49/266 [00:28<01:57,  1.84it/s]Loading train:  19%|█▉        | 50/266 [00:28<02:01,  1.78it/s]Loading train:  19%|█▉        | 51/266 [00:29<01:59,  1.79it/s]Loading train:  20%|█▉        | 52/266 [00:29<02:02,  1.75it/s]Loading train:  20%|█▉        | 53/266 [00:30<01:57,  1.81it/s]Loading train:  20%|██        | 54/266 [00:30<01:57,  1.80it/s]Loading train:  21%|██        | 55/266 [00:31<02:01,  1.74it/s]Loading train:  21%|██        | 56/266 [00:32<01:56,  1.81it/s]Loading train:  21%|██▏       | 57/266 [00:32<01:55,  1.81it/s]Loading train:  22%|██▏       | 58/266 [00:33<01:50,  1.88it/s]Loading train:  22%|██▏       | 59/266 [00:33<01:47,  1.93it/s]Loading train:  23%|██▎       | 60/266 [00:34<01:44,  1.97it/s]Loading train:  23%|██▎       | 61/266 [00:34<01:46,  1.92it/s]Loading train:  23%|██▎       | 62/266 [00:35<01:43,  1.97it/s]Loading train:  24%|██▎       | 63/266 [00:35<01:48,  1.88it/s]Loading train:  24%|██▍       | 64/266 [00:36<01:47,  1.88it/s]Loading train:  24%|██▍       | 65/266 [00:36<01:47,  1.88it/s]Loading train:  25%|██▍       | 66/266 [00:37<01:46,  1.88it/s]Loading train:  25%|██▌       | 67/266 [00:37<01:51,  1.78it/s]Loading train:  26%|██▌       | 68/266 [00:38<01:46,  1.86it/s]Loading train:  26%|██▌       | 69/266 [00:38<01:45,  1.86it/s]Loading train:  26%|██▋       | 70/266 [00:39<01:45,  1.86it/s]Loading train:  27%|██▋       | 71/266 [00:39<01:41,  1.92it/s]Loading train:  27%|██▋       | 72/266 [00:40<01:44,  1.86it/s]Loading train:  27%|██▋       | 73/266 [00:41<01:44,  1.84it/s]Loading train:  28%|██▊       | 74/266 [00:41<01:50,  1.74it/s]Loading train:  28%|██▊       | 75/266 [00:42<01:46,  1.79it/s]Loading train:  29%|██▊       | 76/266 [00:42<01:48,  1.75it/s]Loading train:  29%|██▉       | 77/266 [00:43<01:47,  1.76it/s]Loading train:  29%|██▉       | 78/266 [00:44<01:51,  1.68it/s]Loading train:  30%|██▉       | 79/266 [00:44<02:00,  1.55it/s]Loading train:  30%|███       | 80/266 [00:45<02:06,  1.47it/s]Loading train:  30%|███       | 81/266 [00:46<01:55,  1.59it/s]Loading train:  31%|███       | 82/266 [00:46<01:52,  1.64it/s]Loading train:  31%|███       | 83/266 [00:47<01:52,  1.63it/s]Loading train:  32%|███▏      | 84/266 [00:47<01:53,  1.61it/s]Loading train:  32%|███▏      | 85/266 [00:48<01:46,  1.70it/s]Loading train:  32%|███▏      | 86/266 [00:48<01:41,  1.78it/s]Loading train:  33%|███▎      | 87/266 [00:49<01:44,  1.71it/s]Loading train:  33%|███▎      | 88/266 [00:50<01:41,  1.75it/s]Loading train:  33%|███▎      | 89/266 [00:50<01:43,  1.72it/s]Loading train:  34%|███▍      | 90/266 [00:51<01:38,  1.78it/s]Loading train:  34%|███▍      | 91/266 [00:51<01:39,  1.76it/s]Loading train:  35%|███▍      | 92/266 [00:52<01:40,  1.73it/s]Loading train:  35%|███▍      | 93/266 [00:53<01:43,  1.67it/s]Loading train:  35%|███▌      | 94/266 [00:53<01:44,  1.65it/s]Loading train:  36%|███▌      | 95/266 [00:54<01:37,  1.75it/s]Loading train:  36%|███▌      | 96/266 [00:54<01:39,  1.71it/s]Loading train:  36%|███▋      | 97/266 [00:55<01:40,  1.67it/s]Loading train:  37%|███▋      | 98/266 [00:55<01:37,  1.72it/s]Loading train:  37%|███▋      | 99/266 [00:56<01:34,  1.77it/s]Loading train:  38%|███▊      | 100/266 [00:57<01:33,  1.77it/s]Loading train:  38%|███▊      | 101/266 [00:57<01:31,  1.81it/s]Loading train:  38%|███▊      | 102/266 [00:58<01:34,  1.74it/s]Loading train:  39%|███▊      | 103/266 [00:58<01:31,  1.78it/s]Loading train:  39%|███▉      | 104/266 [00:59<01:32,  1.75it/s]Loading train:  39%|███▉      | 105/266 [00:59<01:32,  1.73it/s]Loading train:  40%|███▉      | 106/266 [01:00<01:32,  1.73it/s]Loading train:  40%|████      | 107/266 [01:01<01:33,  1.71it/s]Loading train:  41%|████      | 108/266 [01:01<01:27,  1.80it/s]Loading train:  41%|████      | 109/266 [01:02<01:26,  1.82it/s]Loading train:  41%|████▏     | 110/266 [01:02<01:24,  1.85it/s]Loading train:  42%|████▏     | 111/266 [01:03<01:23,  1.86it/s]Loading train:  42%|████▏     | 112/266 [01:03<01:25,  1.81it/s]Loading train:  42%|████▏     | 113/266 [01:04<01:23,  1.83it/s]Loading train:  43%|████▎     | 114/266 [01:04<01:24,  1.80it/s]Loading train:  43%|████▎     | 115/266 [01:05<01:25,  1.77it/s]Loading train:  44%|████▎     | 116/266 [01:06<01:23,  1.80it/s]Loading train:  44%|████▍     | 117/266 [01:06<01:24,  1.77it/s]Loading train:  44%|████▍     | 118/266 [01:07<01:22,  1.79it/s]Loading train:  45%|████▍     | 119/266 [01:07<01:27,  1.68it/s]Loading train:  45%|████▌     | 120/266 [01:08<01:28,  1.65it/s]Loading train:  45%|████▌     | 121/266 [01:09<01:30,  1.59it/s]Loading train:  46%|████▌     | 122/266 [01:09<01:32,  1.55it/s]Loading train:  46%|████▌     | 123/266 [01:10<01:38,  1.45it/s]Loading train:  47%|████▋     | 124/266 [01:11<01:44,  1.35it/s]Loading train:  47%|████▋     | 125/266 [01:12<01:37,  1.45it/s]Loading train:  47%|████▋     | 126/266 [01:12<01:25,  1.64it/s]Loading train:  48%|████▊     | 127/266 [01:12<01:15,  1.84it/s]Loading train:  48%|████▊     | 128/266 [01:13<01:10,  1.96it/s]Loading train:  48%|████▊     | 129/266 [01:13<01:14,  1.85it/s]Loading train:  49%|████▉     | 130/266 [01:14<01:16,  1.79it/s]Loading train:  49%|████▉     | 131/266 [01:15<01:19,  1.71it/s]Loading train:  50%|████▉     | 132/266 [01:15<01:22,  1.62it/s]Loading train:  50%|█████     | 133/266 [01:16<01:12,  1.82it/s]Loading train:  50%|█████     | 134/266 [01:16<01:09,  1.89it/s]Loading train:  51%|█████     | 135/266 [01:17<01:07,  1.94it/s]Loading train:  51%|█████     | 136/266 [01:17<01:09,  1.87it/s]Loading train:  52%|█████▏    | 137/266 [01:18<01:10,  1.82it/s]Loading train:  52%|█████▏    | 138/266 [01:18<01:09,  1.85it/s]Loading train:  52%|█████▏    | 139/266 [01:19<01:03,  1.99it/s]Loading train:  53%|█████▎    | 140/266 [01:19<00:59,  2.12it/s]Loading train:  53%|█████▎    | 141/266 [01:20<01:00,  2.05it/s]Loading train:  53%|█████▎    | 142/266 [01:20<01:02,  1.98it/s]Loading train:  54%|█████▍    | 143/266 [01:21<00:59,  2.08it/s]Loading train:  54%|█████▍    | 144/266 [01:21<00:57,  2.11it/s]Loading train:  55%|█████▍    | 145/266 [01:22<00:55,  2.18it/s]Loading train:  55%|█████▍    | 146/266 [01:22<00:52,  2.28it/s]Loading train:  55%|█████▌    | 147/266 [01:22<00:50,  2.35it/s]Loading train:  56%|█████▌    | 148/266 [01:23<00:49,  2.37it/s]Loading train:  56%|█████▌    | 149/266 [01:23<00:49,  2.34it/s]Loading train:  56%|█████▋    | 150/266 [01:24<00:49,  2.32it/s]Loading train:  57%|█████▋    | 151/266 [01:24<00:51,  2.25it/s]Loading train:  57%|█████▋    | 152/266 [01:25<00:49,  2.31it/s]Loading train:  58%|█████▊    | 153/266 [01:25<00:47,  2.39it/s]Loading train:  58%|█████▊    | 154/266 [01:25<00:47,  2.35it/s]Loading train:  58%|█████▊    | 155/266 [01:26<00:45,  2.43it/s]Loading train:  59%|█████▊    | 156/266 [01:26<00:45,  2.43it/s]Loading train:  59%|█████▉    | 157/266 [01:27<00:45,  2.41it/s]Loading train:  59%|█████▉    | 158/266 [01:27<00:44,  2.41it/s]Loading train:  60%|█████▉    | 159/266 [01:27<00:43,  2.45it/s]Loading train:  60%|██████    | 160/266 [01:28<00:42,  2.51it/s]Loading train:  61%|██████    | 161/266 [01:28<00:42,  2.50it/s]Loading train:  61%|██████    | 162/266 [01:29<00:40,  2.55it/s]Loading train:  61%|██████▏   | 163/266 [01:29<00:38,  2.71it/s]Loading train:  62%|██████▏   | 164/266 [01:29<00:35,  2.84it/s]Loading train:  62%|██████▏   | 165/266 [01:29<00:34,  2.91it/s]Loading train:  62%|██████▏   | 166/266 [01:30<00:33,  2.98it/s]Loading train:  63%|██████▎   | 167/266 [01:30<00:32,  3.02it/s]Loading train:  63%|██████▎   | 168/266 [01:30<00:32,  3.06it/s]Loading train:  64%|██████▎   | 169/266 [01:31<00:31,  3.10it/s]Loading train:  64%|██████▍   | 170/266 [01:31<00:30,  3.12it/s]Loading train:  64%|██████▍   | 171/266 [01:31<00:30,  3.13it/s]Loading train:  65%|██████▍   | 172/266 [01:32<00:30,  3.08it/s]Loading train:  65%|██████▌   | 173/266 [01:32<00:30,  3.02it/s]Loading train:  65%|██████▌   | 174/266 [01:32<00:31,  2.91it/s]Loading train:  66%|██████▌   | 175/266 [01:33<00:33,  2.68it/s]Loading train:  66%|██████▌   | 176/266 [01:33<00:36,  2.44it/s]Loading train:  67%|██████▋   | 177/266 [01:34<00:37,  2.40it/s]Loading train:  67%|██████▋   | 178/266 [01:34<00:37,  2.32it/s]Loading train:  67%|██████▋   | 179/266 [01:35<00:36,  2.36it/s]Loading train:  68%|██████▊   | 180/266 [01:35<00:37,  2.30it/s]Loading train:  68%|██████▊   | 181/266 [01:36<00:35,  2.40it/s]Loading train:  68%|██████▊   | 182/266 [01:36<00:32,  2.55it/s]Loading train:  69%|██████▉   | 183/266 [01:36<00:32,  2.59it/s]Loading train:  69%|██████▉   | 184/266 [01:37<00:30,  2.71it/s]Loading train:  70%|██████▉   | 185/266 [01:37<00:29,  2.72it/s]Loading train:  70%|██████▉   | 186/266 [01:37<00:32,  2.49it/s]Loading train:  70%|███████   | 187/266 [01:38<00:33,  2.39it/s]Loading train:  71%|███████   | 188/266 [01:38<00:34,  2.25it/s]Loading train:  71%|███████   | 189/266 [01:39<00:35,  2.16it/s]Loading train:  71%|███████▏  | 190/266 [01:39<00:34,  2.23it/s]Loading train:  72%|███████▏  | 191/266 [01:40<00:33,  2.24it/s]Loading train:  72%|███████▏  | 192/266 [01:40<00:33,  2.19it/s]Loading train:  73%|███████▎  | 193/266 [01:41<00:33,  2.17it/s]Loading train:  73%|███████▎  | 194/266 [01:41<00:33,  2.12it/s]Loading train:  73%|███████▎  | 195/266 [01:42<00:32,  2.16it/s]Loading train:  74%|███████▎  | 196/266 [01:42<00:31,  2.19it/s]Loading train:  74%|███████▍  | 197/266 [01:43<00:31,  2.20it/s]Loading train:  74%|███████▍  | 198/266 [01:43<00:30,  2.26it/s]Loading train:  75%|███████▍  | 199/266 [01:43<00:29,  2.30it/s]Loading train:  75%|███████▌  | 200/266 [01:44<00:28,  2.30it/s]Loading train:  76%|███████▌  | 201/266 [01:44<00:28,  2.32it/s]Loading train:  76%|███████▌  | 202/266 [01:45<00:28,  2.23it/s]Loading train:  76%|███████▋  | 203/266 [01:45<00:27,  2.26it/s]Loading train:  77%|███████▋  | 204/266 [01:46<00:26,  2.30it/s]Loading train:  77%|███████▋  | 205/266 [01:46<00:27,  2.25it/s]Loading train:  77%|███████▋  | 206/266 [01:46<00:27,  2.21it/s]Loading train:  78%|███████▊  | 207/266 [01:47<00:26,  2.24it/s]Loading train:  78%|███████▊  | 208/266 [01:47<00:24,  2.34it/s]Loading train:  79%|███████▊  | 209/266 [01:48<00:22,  2.51it/s]Loading train:  79%|███████▉  | 210/266 [01:48<00:21,  2.55it/s]Loading train:  79%|███████▉  | 211/266 [01:48<00:22,  2.49it/s]Loading train:  80%|███████▉  | 212/266 [01:49<00:22,  2.44it/s]Loading train:  80%|████████  | 213/266 [01:49<00:21,  2.43it/s]Loading train:  80%|████████  | 214/266 [01:50<00:20,  2.54it/s]Loading train:  81%|████████  | 215/266 [01:50<00:19,  2.55it/s]Loading train:  81%|████████  | 216/266 [01:50<00:20,  2.47it/s]Loading train:  82%|████████▏ | 217/266 [01:51<00:19,  2.48it/s]Loading train:  82%|████████▏ | 218/266 [01:51<00:18,  2.64it/s]Loading train:  82%|████████▏ | 219/266 [01:51<00:16,  2.77it/s]Loading train:  83%|████████▎ | 220/266 [01:52<00:16,  2.87it/s]Loading train:  83%|████████▎ | 221/266 [01:52<00:15,  2.95it/s]Loading train:  83%|████████▎ | 222/266 [01:52<00:14,  3.00it/s]Loading train:  84%|████████▍ | 223/266 [01:53<00:15,  2.84it/s]Loading train:  84%|████████▍ | 224/266 [01:53<00:15,  2.74it/s]Loading train:  85%|████████▍ | 225/266 [01:54<00:14,  2.82it/s]Loading train:  85%|████████▍ | 226/266 [01:54<00:14,  2.72it/s]Loading train:  85%|████████▌ | 227/266 [01:54<00:13,  2.84it/s]Loading train:  86%|████████▌ | 228/266 [01:55<00:12,  2.93it/s]Loading train:  86%|████████▌ | 229/266 [01:55<00:12,  3.00it/s]Loading train:  86%|████████▋ | 230/266 [01:55<00:12,  2.83it/s]Loading train:  87%|████████▋ | 231/266 [01:56<00:12,  2.81it/s]Loading train:  87%|████████▋ | 232/266 [01:56<00:12,  2.66it/s]Loading train:  88%|████████▊ | 233/266 [01:56<00:12,  2.69it/s]Loading train:  88%|████████▊ | 234/266 [01:57<00:11,  2.72it/s]Loading train:  88%|████████▊ | 235/266 [01:57<00:10,  2.83it/s]Loading train:  89%|████████▊ | 236/266 [01:57<00:10,  2.93it/s]Loading train:  89%|████████▉ | 237/266 [01:58<00:09,  2.99it/s]Loading train:  89%|████████▉ | 238/266 [01:58<00:09,  3.03it/s]Loading train:  90%|████████▉ | 239/266 [01:58<00:08,  3.06it/s]Loading train:  90%|█████████ | 240/266 [01:59<00:08,  3.06it/s]Loading train:  91%|█████████ | 241/266 [01:59<00:08,  3.09it/s]Loading train:  91%|█████████ | 242/266 [01:59<00:07,  3.01it/s]Loading train:  91%|█████████▏| 243/266 [02:00<00:07,  2.98it/s]Loading train:  92%|█████████▏| 244/266 [02:00<00:07,  2.88it/s]Loading train:  92%|█████████▏| 245/266 [02:00<00:07,  2.90it/s]Loading train:  92%|█████████▏| 246/266 [02:01<00:06,  2.92it/s]Loading train:  93%|█████████▎| 247/266 [02:01<00:06,  2.90it/s]Loading train:  93%|█████████▎| 248/266 [02:01<00:06,  2.91it/s]Loading train:  94%|█████████▎| 249/266 [02:02<00:06,  2.75it/s]Loading train:  94%|█████████▍| 250/266 [02:02<00:06,  2.66it/s]Loading train:  94%|█████████▍| 251/266 [02:03<00:05,  2.63it/s]Loading train:  95%|█████████▍| 252/266 [02:03<00:05,  2.59it/s]Loading train:  95%|█████████▌| 253/266 [02:03<00:05,  2.58it/s]Loading train:  95%|█████████▌| 254/266 [02:04<00:04,  2.48it/s]Loading train:  96%|█████████▌| 255/266 [02:04<00:04,  2.50it/s]Loading train:  96%|█████████▌| 256/266 [02:05<00:03,  2.52it/s]Loading train:  97%|█████████▋| 257/266 [02:05<00:03,  2.43it/s]Loading train:  97%|█████████▋| 258/266 [02:06<00:03,  2.46it/s]Loading train:  97%|█████████▋| 259/266 [02:06<00:02,  2.49it/s]Loading train:  98%|█████████▊| 260/266 [02:06<00:02,  2.50it/s]Loading train:  98%|█████████▊| 261/266 [02:07<00:01,  2.51it/s]Loading train:  98%|█████████▊| 262/266 [02:07<00:01,  2.50it/s]Loading train:  99%|█████████▉| 263/266 [02:08<00:01,  2.52it/s]Loading train:  99%|█████████▉| 264/266 [02:08<00:00,  2.53it/s]Loading train: 100%|█████████▉| 265/266 [02:08<00:00,  2.51it/s]Loading train: 100%|██████████| 266/266 [02:09<00:00,  2.44it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:02, 106.87it/s]concatenating: train:  11%|█         | 29/266 [00:00<00:01, 120.92it/s]concatenating: train:  17%|█▋        | 46/266 [00:00<00:01, 132.30it/s]concatenating: train:  26%|██▌       | 68/266 [00:00<00:01, 149.57it/s]concatenating: train:  33%|███▎      | 89/266 [00:00<00:01, 163.52it/s]concatenating: train:  43%|████▎     | 114/266 [00:00<00:00, 182.04it/s]concatenating: train:  51%|█████     | 135/266 [00:00<00:00, 189.42it/s]concatenating: train:  62%|██████▏   | 166/266 [00:00<00:00, 213.54it/s]concatenating: train:  75%|███████▌  | 200/266 [00:00<00:00, 239.36it/s]concatenating: train:  89%|████████▊ | 236/266 [00:01<00:00, 265.94it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 247.09it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  1.88it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  2.01it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  2.08it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  1.98it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 39.60it/s]2019-07-29 06:03:47.482863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 06:03:47.482950: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 06:03:47.482966: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 06:03:47.482975: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 06:03:47.483352: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.73it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.63it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.41it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.94it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.22it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.01it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.27it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.10it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.61it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.00it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.64it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.98it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.10it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.27it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.92it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.26it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.28it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.45it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.35it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 40)  400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 40)  160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 40)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 76, 108, 40)  0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 40)  14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 40)  160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 40)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 76, 108, 40)  0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 76, 108, 41)  0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 76, 108, 30)  11100       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 76, 108, 30)  120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 76, 108, 30)  0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 76, 108, 30)  8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 76, 108, 30)  120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 76, 108, 30)  0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 38, 54, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 38, 54, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 38, 54, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 38, 54, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 38, 54, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 38, 54, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 38, 54, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 19, 27, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 19, 27, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 19, 27, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 19, 27, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 19, 27, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 19, 27, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 19, 27, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 19, 27, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 38, 54, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 38, 54, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 38, 54, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 38, 54, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 38, 54, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 38, 54, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 38, 54, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 30)  16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 76, 108, 30)  120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 76, 108, 30)  0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 76, 108, 30)  8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 76, 108, 30)  120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 76, 108, 30)  0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 76, 108, 90)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 76, 108, 90)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 76, 108, 40)  32440       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 76, 108, 40)  160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 76, 108, 40)  0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 76, 108, 40)  0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 76, 108, 40)  14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 76, 108, 40)  160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 76, 108, 40)  0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 76, 108, 40)  0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 76, 108, 130) 0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 76, 108, 2)   262         concatenate_8[0][0]              
==================================================================================================
Total params: 573,582
Trainable params: 181,042
Non-trainable params: 392,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 396 samples
Epoch 1/300
 - 98s - loss: 0.1014 - acc: 0.9900 - mDice: 0.8456 - val_loss: 0.0713 - val_acc: 0.9934 - val_mDice: 0.8708

Epoch 00001: val_mDice improved from -inf to 0.87080, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 94s - loss: 0.0520 - acc: 0.9944 - mDice: 0.9038 - val_loss: 0.0769 - val_acc: 0.9945 - val_mDice: 0.8621

Epoch 00002: val_mDice did not improve from 0.87080
Epoch 3/300
 - 95s - loss: 0.0471 - acc: 0.9949 - mDice: 0.9126 - val_loss: 0.0607 - val_acc: 0.9947 - val_mDice: 0.8890

Epoch 00003: val_mDice improved from 0.87080 to 0.88895, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 95s - loss: 0.0438 - acc: 0.9952 - mDice: 0.9184 - val_loss: 0.0589 - val_acc: 0.9949 - val_mDice: 0.8920

Epoch 00004: val_mDice improved from 0.88895 to 0.89198, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 95s - loss: 0.0409 - acc: 0.9954 - mDice: 0.9237 - val_loss: 0.0590 - val_acc: 0.9948 - val_mDice: 0.8918

Epoch 00005: val_mDice did not improve from 0.89198
Epoch 6/300
 - 95s - loss: 0.0395 - acc: 0.9956 - mDice: 0.9262 - val_loss: 0.0638 - val_acc: 0.9948 - val_mDice: 0.8839

Epoch 00006: val_mDice did not improve from 0.89198
Epoch 7/300
 - 96s - loss: 0.0377 - acc: 0.9957 - mDice: 0.9294 - val_loss: 0.0658 - val_acc: 0.9945 - val_mDice: 0.8807

Epoch 00007: val_mDice did not improve from 0.89198
Epoch 8/300
 - 95s - loss: 0.0366 - acc: 0.9958 - mDice: 0.9313 - val_loss: 0.0608 - val_acc: 0.9948 - val_mDice: 0.8890

Epoch 00008: val_mDice did not improve from 0.89198
Epoch 9/300
 - 95s - loss: 0.0354 - acc: 0.9959 - mDice: 0.9336 - val_loss: 0.0637 - val_acc: 0.9943 - val_mDice: 0.8842

Epoch 00009: val_mDice did not improve from 0.89198
Epoch 10/300
 - 95s - loss: 0.0346 - acc: 0.9960 - mDice: 0.9351 - val_loss: 0.0645 - val_acc: 0.9945 - val_mDice: 0.8830

Epoch 00010: val_mDice did not improve from 0.89198
Epoch 11/300
 - 95s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9363 - val_loss: 0.0617 - val_acc: 0.9948 - val_mDice: 0.8873

Epoch 00011: val_mDice did not improve from 0.89198
Epoch 12/300
 - 95s - loss: 0.0331 - acc: 0.9961 - mDice: 0.9377 - val_loss: 0.0627 - val_acc: 0.9948 - val_mDice: 0.8861

Epoch 00012: val_mDice did not improve from 0.89198
Epoch 13/300
 - 97s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9389 - val_loss: 0.0641 - val_acc: 0.9945 - val_mDice: 0.8837

Epoch 00013: val_mDice did not improve from 0.89198
Epoch 14/300
 - 97s - loss: 0.0322 - acc: 0.9962 - mDice: 0.9394 - val_loss: 0.0661 - val_acc: 0.9946 - val_mDice: 0.8802

Epoch 00014: val_mDice did not improve from 0.89198
Epoch 15/300
 - 96s - loss: 0.0315 - acc: 0.9962 - mDice: 0.9406 - val_loss: 0.0632 - val_acc: 0.9947 - val_mDice: 0.8853

Epoch 00015: val_mDice did not improve from 0.89198
Epoch 16/300
 - 96s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9412 - val_loss: 0.0631 - val_acc: 0.9948 - val_mDice: 0.8854

Epoch 00016: val_mDice did not improve from 0.89198
Epoch 17/300
 - 95s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9424 - val_loss: 0.0623 - val_acc: 0.9947 - val_mDice: 0.8868

Epoch 00017: val_mDice did not improve from 0.89198
Epoch 18/300
 - 93s - loss: 0.0304 - acc: 0.9963 - mDice: 0.9426 - val_loss: 0.0611 - val_acc: 0.9945 - val_mDice: 0.8886

Epoch 00018: val_mDice did not improve from 0.89198
Epoch 19/300
 - 90s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9436 - val_loss: 0.0621 - val_acc: 0.9946 - val_mDice: 0.8870

Epoch 00019: val_mDice did not improve from 0.89198
Epoch 20/300
 - 90s - loss: 0.0297 - acc: 0.9964 - mDice: 0.9440 - val_loss: 0.0673 - val_acc: 0.9947 - val_mDice: 0.8780

Epoch 00020: val_mDice did not improve from 0.89198
Epoch 21/300
 - 93s - loss: 0.0293 - acc: 0.9964 - mDice: 0.9446 - val_loss: 0.0646 - val_acc: 0.9949 - val_mDice: 0.8830

Epoch 00021: val_mDice did not improve from 0.89198
Epoch 22/300
 - 94s - loss: 0.0291 - acc: 0.9965 - mDice: 0.9452 - val_loss: 0.0632 - val_acc: 0.9947 - val_mDice: 0.8851

Epoch 00022: val_mDice did not improve from 0.89198
Epoch 23/300
 - 94s - loss: 0.0289 - acc: 0.9965 - mDice: 0.9454 - val_loss: 0.0621 - val_acc: 0.9947 - val_mDice: 0.8869

Epoch 00023: val_mDice did not improve from 0.89198
Epoch 24/300
 - 94s - loss: 0.0286 - acc: 0.9965 - mDice: 0.9460 - val_loss: 0.0628 - val_acc: 0.9943 - val_mDice: 0.8858

Epoch 00024: val_mDice did not improve from 0.89198
Epoch 25/300
 - 94s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9465 - val_loss: 0.0600 - val_acc: 0.9948 - val_mDice: 0.8905

Epoch 00025: val_mDice did not improve from 0.89198
Epoch 26/300
 - 94s - loss: 0.0282 - acc: 0.9966 - mDice: 0.9468 - val_loss: 0.0626 - val_acc: 0.9946 - val_mDice: 0.8861

Epoch 00026: val_mDice did not improve from 0.89198
Epoch 27/300
 - 94s - loss: 0.0281 - acc: 0.9966 - mDice: 0.9470 - val_loss: 0.0626 - val_acc: 0.9944 - val_mDice: 0.8863

Epoch 00027: val_mDice did not improve from 0.89198
Epoch 28/300
 - 94s - loss: 0.0277 - acc: 0.9966 - mDice: 0.9476 - val_loss: 0.0646 - val_acc: 0.9946 - val_mDice: 0.8828

Epoch 00028: val_mDice did not improve from 0.89198
Epoch 29/300
 - 95s - loss: 0.0277 - acc: 0.9966 - mDice: 0.9477 - val_loss: 0.0629 - val_acc: 0.9947 - val_mDice: 0.8856

Epoch 00029: val_mDice did not improve from 0.89198
Epoch 30/300
 - 95s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9480 - val_loss: 0.0623 - val_acc: 0.9948 - val_mDice: 0.8869

Epoch 00030: val_mDice did not improve from 0.89198
Epoch 31/300
 - 95s - loss: 0.0273 - acc: 0.9966 - mDice: 0.9484 - val_loss: 0.0622 - val_acc: 0.9946 - val_mDice: 0.8870

Epoch 00031: val_mDice did not improve from 0.89198
Epoch 32/300
 - 94s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9482 - val_loss: 0.0652 - val_acc: 0.9945 - val_mDice: 0.8821

Epoch 00032: val_mDice did not improve from 0.89198
Epoch 33/300
 - 94s - loss: 0.0271 - acc: 0.9967 - mDice: 0.9488 - val_loss: 0.0660 - val_acc: 0.9946 - val_mDice: 0.8806

Epoch 00033: val_mDice did not improve from 0.89198
Epoch 34/300
 - 94s - loss: 0.0270 - acc: 0.9967 - mDice: 0.9489 - val_loss: 0.0629 - val_acc: 0.9945 - val_mDice: 0.8856

Epoch 00034: val_mDice did not improve from 0.89198
Epoch 35/300
 - 94s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9494 - val_loss: 0.0626 - val_acc: 0.9947 - val_mDice: 0.8861

Epoch 00035: val_mDice did not improve from 0.89198
Epoch 36/300
 - 91s - loss: 0.0268 - acc: 0.9967 - mDice: 0.9493 - val_loss: 0.0631 - val_acc: 0.9948 - val_mDice: 0.8854

Epoch 00036: val_mDice did not improve from 0.89198
Epoch 37/300
 - 89s - loss: 0.0267 - acc: 0.9967 - mDice: 0.9496 - val_loss: 0.0613 - val_acc: 0.9948 - val_mDice: 0.8885

Epoch 00037: val_mDice did not improve from 0.89198
Epoch 38/300
 - 90s - loss: 0.0265 - acc: 0.9967 - mDice: 0.9499 - val_loss: 0.0633 - val_acc: 0.9947 - val_mDice: 0.8852

Epoch 00038: val_mDice did not improve from 0.89198
Epoch 39/300
 - 90s - loss: 0.0263 - acc: 0.9967 - mDice: 0.9503 - val_loss: 0.0622 - val_acc: 0.9945 - val_mDice: 0.8871

Epoch 00039: val_mDice did not improve from 0.89198
Epoch 40/300
 - 89s - loss: 0.0264 - acc: 0.9967 - mDice: 0.9501 - val_loss: 0.0620 - val_acc: 0.9947 - val_mDice: 0.8873

Epoch 00040: val_mDice did not improve from 0.89198
Epoch 41/300
 - 92s - loss: 0.0261 - acc: 0.9968 - mDice: 0.9507 - val_loss: 0.0647 - val_acc: 0.9947 - val_mDice: 0.8828

Epoch 00041: val_mDice did not improve from 0.89198
Epoch 42/300
 - 94s - loss: 0.0261 - acc: 0.9968 - mDice: 0.9506 - val_loss: 0.0630 - val_acc: 0.9944 - val_mDice: 0.8855

Epoch 00042: val_mDice did not improve from 0.89198
Epoch 43/300
 - 94s - loss: 0.0259 - acc: 0.9968 - mDice: 0.9510 - val_loss: 0.0651 - val_acc: 0.9946 - val_mDice: 0.8820

Epoch 00043: val_mDice did not improve from 0.89198
Epoch 44/300
 - 94s - loss: 0.0258 - acc: 0.9968 - mDice: 0.9511 - val_loss: 0.0642 - val_acc: 0.9944 - val_mDice: 0.8834

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:03,  1.30s/it]predicting test subjects:  50%|█████     | 2/4 [00:01<00:02,  1.04s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:02<00:00,  1.19it/s]predicting test subjects: 100%|██████████| 4/4 [00:02<00:00,  1.35it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<03:09,  1.40it/s]predicting train subjects:   1%|          | 2/266 [00:01<02:54,  1.51it/s]predicting train subjects:   1%|          | 3/266 [00:01<02:36,  1.68it/s]predicting train subjects:   2%|▏         | 4/266 [00:02<02:21,  1.86it/s]predicting train subjects:   2%|▏         | 5/266 [00:02<02:29,  1.74it/s]predicting train subjects:   2%|▏         | 6/266 [00:03<02:19,  1.87it/s]predicting train subjects:   3%|▎         | 7/266 [00:03<02:32,  1.70it/s]predicting train subjects:   3%|▎         | 8/266 [00:04<02:21,  1.82it/s]predicting train subjects:   3%|▎         | 9/266 [00:04<02:21,  1.82it/s]predicting train subjects:   4%|▍         | 10/266 [00:05<02:18,  1.85it/s]predicting train subjects:   4%|▍         | 11/266 [00:06<02:21,  1.81it/s]predicting train subjects:   5%|▍         | 12/266 [00:06<02:18,  1.83it/s]predicting train subjects:   5%|▍         | 13/266 [00:07<02:28,  1.70it/s]predicting train subjects:   5%|▌         | 14/266 [00:07<02:21,  1.77it/s]predicting train subjects:   6%|▌         | 15/266 [00:08<02:31,  1.66it/s]predicting train subjects:   6%|▌         | 16/266 [00:08<02:25,  1.72it/s]predicting train subjects:   6%|▋         | 17/266 [00:09<02:23,  1.73it/s]predicting train subjects:   7%|▋         | 18/266 [00:10<02:16,  1.82it/s]predicting train subjects:   7%|▋         | 19/266 [00:10<02:18,  1.79it/s]predicting train subjects:   8%|▊         | 20/266 [00:11<02:09,  1.90it/s]predicting train subjects:   8%|▊         | 21/266 [00:11<02:13,  1.83it/s]predicting train subjects:   8%|▊         | 22/266 [00:12<02:07,  1.91it/s]predicting train subjects:   9%|▊         | 23/266 [00:12<02:05,  1.93it/s]predicting train subjects:   9%|▉         | 24/266 [00:13<02:00,  2.02it/s]predicting train subjects:   9%|▉         | 25/266 [00:13<02:06,  1.91it/s]predicting train subjects:  10%|▉         | 26/266 [00:14<02:03,  1.94it/s]predicting train subjects:  10%|█         | 27/266 [00:14<02:02,  1.94it/s]predicting train subjects:  11%|█         | 28/266 [00:15<02:02,  1.94it/s]predicting train subjects:  11%|█         | 29/266 [00:15<02:03,  1.92it/s]predicting train subjects:  11%|█▏        | 30/266 [00:16<02:04,  1.90it/s]predicting train subjects:  12%|█▏        | 31/266 [00:16<01:58,  1.99it/s]predicting train subjects:  12%|█▏        | 32/266 [00:17<02:05,  1.86it/s]predicting train subjects:  12%|█▏        | 33/266 [00:17<02:07,  1.83it/s]predicting train subjects:  13%|█▎        | 34/266 [00:18<02:11,  1.76it/s]predicting train subjects:  13%|█▎        | 35/266 [00:18<02:05,  1.85it/s]predicting train subjects:  14%|█▎        | 36/266 [00:19<02:09,  1.78it/s]predicting train subjects:  14%|█▍        | 37/266 [00:20<02:01,  1.88it/s]predicting train subjects:  14%|█▍        | 38/266 [00:20<02:03,  1.85it/s]predicting train subjects:  15%|█▍        | 39/266 [00:21<02:00,  1.88it/s]predicting train subjects:  15%|█▌        | 40/266 [00:21<02:05,  1.81it/s]predicting train subjects:  15%|█▌        | 41/266 [00:22<01:55,  1.95it/s]predicting train subjects:  16%|█▌        | 42/266 [00:22<01:43,  2.17it/s]predicting train subjects:  16%|█▌        | 43/266 [00:22<01:41,  2.20it/s]predicting train subjects:  17%|█▋        | 44/266 [00:23<01:47,  2.06it/s]predicting train subjects:  17%|█▋        | 45/266 [00:23<01:41,  2.18it/s]predicting train subjects:  17%|█▋        | 46/266 [00:24<01:34,  2.32it/s]predicting train subjects:  18%|█▊        | 47/266 [00:24<01:37,  2.24it/s]predicting train subjects:  18%|█▊        | 48/266 [00:25<01:41,  2.15it/s]predicting train subjects:  18%|█▊        | 49/266 [00:25<01:34,  2.29it/s]predicting train subjects:  19%|█▉        | 50/266 [00:26<01:35,  2.27it/s]predicting train subjects:  19%|█▉        | 51/266 [00:26<01:38,  2.18it/s]predicting train subjects:  20%|█▉        | 52/266 [00:26<01:35,  2.25it/s]predicting train subjects:  20%|█▉        | 53/266 [00:27<01:31,  2.34it/s]predicting train subjects:  20%|██        | 54/266 [00:27<01:38,  2.14it/s]predicting train subjects:  21%|██        | 55/266 [00:28<01:33,  2.25it/s]predicting train subjects:  21%|██        | 56/266 [00:28<01:38,  2.13it/s]predicting train subjects:  21%|██▏       | 57/266 [00:29<01:49,  1.90it/s]predicting train subjects:  22%|██▏       | 58/266 [00:29<01:38,  2.11it/s]predicting train subjects:  22%|██▏       | 59/266 [00:30<01:40,  2.05it/s]predicting train subjects:  23%|██▎       | 60/266 [00:31<01:49,  1.88it/s]predicting train subjects:  23%|██▎       | 61/266 [00:31<01:40,  2.04it/s]predicting train subjects:  23%|██▎       | 62/266 [00:31<01:37,  2.09it/s]predicting train subjects:  24%|██▎       | 63/266 [00:32<01:39,  2.04it/s]predicting train subjects:  24%|██▍       | 64/266 [00:32<01:31,  2.20it/s]predicting train subjects:  24%|██▍       | 65/266 [00:33<01:26,  2.32it/s]predicting train subjects:  25%|██▍       | 66/266 [00:33<01:30,  2.21it/s]predicting train subjects:  25%|██▌       | 67/266 [00:34<01:33,  2.14it/s]predicting train subjects:  26%|██▌       | 68/266 [00:34<01:26,  2.28it/s]predicting train subjects:  26%|██▌       | 69/266 [00:34<01:25,  2.30it/s]predicting train subjects:  26%|██▋       | 70/266 [00:35<01:26,  2.27it/s]predicting train subjects:  27%|██▋       | 71/266 [00:35<01:25,  2.27it/s]predicting train subjects:  27%|██▋       | 72/266 [00:36<01:21,  2.39it/s]predicting train subjects:  27%|██▋       | 73/266 [00:36<01:30,  2.14it/s]predicting train subjects:  28%|██▊       | 74/266 [00:37<01:33,  2.05it/s]predicting train subjects:  28%|██▊       | 75/266 [00:37<01:26,  2.20it/s]predicting train subjects:  29%|██▊       | 76/266 [00:38<01:28,  2.15it/s]predicting train subjects:  29%|██▉       | 77/266 [00:38<01:35,  1.98it/s]predicting train subjects:  29%|██▉       | 78/266 [00:39<01:32,  2.04it/s]predicting train subjects:  30%|██▉       | 79/266 [00:39<01:32,  2.02it/s]predicting train subjects:  30%|███       | 80/266 [00:40<01:30,  2.05it/s]predicting train subjects:  30%|███       | 81/266 [00:40<01:26,  2.15it/s]predicting train subjects:  31%|███       | 82/266 [00:41<01:35,  1.93it/s]predicting train subjects:  31%|███       | 83/266 [00:41<01:35,  1.92it/s]predicting train subjects:  32%|███▏      | 84/266 [00:42<01:33,  1.96it/s]predicting train subjects:  32%|███▏      | 85/266 [00:42<01:39,  1.82it/s]predicting train subjects:  32%|███▏      | 86/266 [00:43<01:31,  1.96it/s]predicting train subjects:  33%|███▎      | 87/266 [00:43<01:36,  1.85it/s]predicting train subjects:  33%|███▎      | 88/266 [00:44<01:34,  1.88it/s]predicting train subjects:  33%|███▎      | 89/266 [00:45<01:41,  1.74it/s]predicting train subjects:  34%|███▍      | 90/266 [00:45<01:37,  1.81it/s]predicting train subjects:  34%|███▍      | 91/266 [00:46<01:35,  1.84it/s]predicting train subjects:  35%|███▍      | 92/266 [00:46<01:33,  1.85it/s]predicting train subjects:  35%|███▍      | 93/266 [00:47<01:36,  1.79it/s]predicting train subjects:  35%|███▌      | 94/266 [00:47<01:35,  1.81it/s]predicting train subjects:  36%|███▌      | 95/266 [00:48<01:35,  1.80it/s]predicting train subjects:  36%|███▌      | 96/266 [00:48<01:26,  1.95it/s]predicting train subjects:  36%|███▋      | 97/266 [00:49<01:25,  1.98it/s]predicting train subjects:  37%|███▋      | 98/266 [00:49<01:24,  1.99it/s]predicting train subjects:  37%|███▋      | 99/266 [00:50<01:17,  2.17it/s]predicting train subjects:  38%|███▊      | 100/266 [00:50<01:12,  2.28it/s]predicting train subjects:  38%|███▊      | 101/266 [00:50<01:07,  2.44it/s]predicting train subjects:  38%|███▊      | 102/266 [00:51<01:03,  2.57it/s]predicting train subjects:  39%|███▊      | 103/266 [00:51<01:01,  2.67it/s]predicting train subjects:  39%|███▉      | 104/266 [00:51<00:59,  2.72it/s]predicting train subjects:  39%|███▉      | 105/266 [00:52<00:58,  2.75it/s]predicting train subjects:  40%|███▉      | 106/266 [00:52<01:04,  2.48it/s]predicting train subjects:  40%|████      | 107/266 [00:53<01:15,  2.10it/s]predicting train subjects:  41%|████      | 108/266 [00:53<01:09,  2.27it/s]predicting train subjects:  41%|████      | 109/266 [00:54<01:06,  2.36it/s]predicting train subjects:  41%|████▏     | 110/266 [00:54<01:11,  2.17it/s]predicting train subjects:  42%|████▏     | 111/266 [00:55<01:13,  2.11it/s]predicting train subjects:  42%|████▏     | 112/266 [00:55<01:11,  2.15it/s]predicting train subjects:  42%|████▏     | 113/266 [00:56<01:18,  1.95it/s]predicting train subjects:  43%|████▎     | 114/266 [00:56<01:13,  2.05it/s]predicting train subjects:  43%|████▎     | 115/266 [00:57<01:10,  2.15it/s]predicting train subjects:  44%|████▎     | 116/266 [00:57<01:18,  1.91it/s]predicting train subjects:  44%|████▍     | 117/266 [00:58<01:19,  1.87it/s]predicting train subjects:  44%|████▍     | 118/266 [00:58<01:19,  1.86it/s]predicting train subjects:  45%|████▍     | 119/266 [00:59<01:14,  1.97it/s]predicting train subjects:  45%|████▌     | 120/266 [00:59<01:08,  2.12it/s]predicting train subjects:  45%|████▌     | 121/266 [01:00<01:06,  2.19it/s]predicting train subjects:  46%|████▌     | 122/266 [01:00<01:03,  2.28it/s]predicting train subjects:  46%|████▌     | 123/266 [01:00<01:00,  2.37it/s]predicting train subjects:  47%|████▋     | 124/266 [01:01<00:57,  2.45it/s]predicting train subjects:  47%|████▋     | 125/266 [01:01<00:56,  2.51it/s]predicting train subjects:  47%|████▋     | 126/266 [01:02<00:55,  2.54it/s]predicting train subjects:  48%|████▊     | 127/266 [01:02<00:54,  2.57it/s]predicting train subjects:  48%|████▊     | 128/266 [01:02<00:54,  2.54it/s]predicting train subjects:  48%|████▊     | 129/266 [01:03<00:54,  2.52it/s]predicting train subjects:  49%|████▉     | 130/266 [01:03<00:52,  2.57it/s]predicting train subjects:  49%|████▉     | 131/266 [01:03<00:52,  2.59it/s]predicting train subjects:  50%|████▉     | 132/266 [01:04<00:51,  2.59it/s]predicting train subjects:  50%|█████     | 133/266 [01:04<00:50,  2.63it/s]predicting train subjects:  50%|█████     | 134/266 [01:05<00:50,  2.63it/s]predicting train subjects:  51%|█████     | 135/266 [01:05<00:50,  2.57it/s]predicting train subjects:  51%|█████     | 136/266 [01:05<00:51,  2.52it/s]predicting train subjects:  52%|█████▏    | 137/266 [01:06<00:51,  2.52it/s]predicting train subjects:  52%|█████▏    | 138/266 [01:06<00:50,  2.52it/s]predicting train subjects:  52%|█████▏    | 139/266 [01:07<00:50,  2.51it/s]predicting train subjects:  53%|█████▎    | 140/266 [01:07<00:48,  2.58it/s]predicting train subjects:  53%|█████▎    | 141/266 [01:07<00:48,  2.60it/s]predicting train subjects:  53%|█████▎    | 142/266 [01:08<00:48,  2.58it/s]predicting train subjects:  54%|█████▍    | 143/266 [01:08<00:46,  2.62it/s]predicting train subjects:  54%|█████▍    | 144/266 [01:08<00:46,  2.65it/s]predicting train subjects:  55%|█████▍    | 145/266 [01:09<00:44,  2.70it/s]predicting train subjects:  55%|█████▍    | 146/266 [01:09<00:45,  2.67it/s]predicting train subjects:  55%|█████▌    | 147/266 [01:10<00:44,  2.69it/s]predicting train subjects:  56%|█████▌    | 148/266 [01:10<00:43,  2.72it/s]predicting train subjects:  56%|█████▌    | 149/266 [01:10<00:44,  2.65it/s]predicting train subjects:  56%|█████▋    | 150/266 [01:11<00:43,  2.67it/s]predicting train subjects:  57%|█████▋    | 151/266 [01:11<00:42,  2.69it/s]predicting train subjects:  57%|█████▋    | 152/266 [01:11<00:42,  2.70it/s]predicting train subjects:  58%|█████▊    | 153/266 [01:12<00:41,  2.74it/s]predicting train subjects:  58%|█████▊    | 154/266 [01:12<00:41,  2.73it/s]predicting train subjects:  58%|█████▊    | 155/266 [01:12<00:38,  2.87it/s]predicting train subjects:  59%|█████▊    | 156/266 [01:13<00:37,  2.92it/s]predicting train subjects:  59%|█████▉    | 157/266 [01:13<00:37,  2.94it/s]predicting train subjects:  59%|█████▉    | 158/266 [01:13<00:36,  2.99it/s]predicting train subjects:  60%|█████▉    | 159/266 [01:14<00:35,  3.01it/s]predicting train subjects:  60%|██████    | 160/266 [01:14<00:34,  3.07it/s]predicting train subjects:  61%|██████    | 161/266 [01:14<00:33,  3.17it/s]predicting train subjects:  61%|██████    | 162/266 [01:15<00:31,  3.30it/s]predicting train subjects:  61%|██████▏   | 163/266 [01:15<00:30,  3.37it/s]predicting train subjects:  62%|██████▏   | 164/266 [01:15<00:29,  3.41it/s]predicting train subjects:  62%|██████▏   | 165/266 [01:16<00:29,  3.39it/s]predicting train subjects:  62%|██████▏   | 166/266 [01:16<00:29,  3.44it/s]predicting train subjects:  63%|██████▎   | 167/266 [01:16<00:28,  3.49it/s]predicting train subjects:  63%|██████▎   | 168/266 [01:16<00:28,  3.49it/s]predicting train subjects:  64%|██████▎   | 169/266 [01:17<00:29,  3.34it/s]predicting train subjects:  64%|██████▍   | 170/266 [01:17<00:28,  3.33it/s]predicting train subjects:  64%|██████▍   | 171/266 [01:17<00:29,  3.28it/s]predicting train subjects:  65%|██████▍   | 172/266 [01:18<00:27,  3.37it/s]predicting train subjects:  65%|██████▌   | 173/266 [01:18<00:28,  3.22it/s]predicting train subjects:  65%|██████▌   | 174/266 [01:18<00:30,  3.00it/s]predicting train subjects:  66%|██████▌   | 175/266 [01:19<00:31,  2.93it/s]predicting train subjects:  66%|██████▌   | 176/266 [01:19<00:31,  2.88it/s]predicting train subjects:  67%|██████▋   | 177/266 [01:19<00:30,  2.88it/s]predicting train subjects:  67%|██████▋   | 178/266 [01:20<00:29,  2.97it/s]predicting train subjects:  67%|██████▋   | 179/266 [01:20<00:28,  3.05it/s]predicting train subjects:  68%|██████▊   | 180/266 [01:20<00:27,  3.10it/s]predicting train subjects:  68%|██████▊   | 181/266 [01:21<00:27,  3.14it/s]predicting train subjects:  68%|██████▊   | 182/266 [01:21<00:27,  3.08it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:21<00:26,  3.08it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:22<00:26,  3.12it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:22<00:25,  3.16it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:22<00:25,  3.17it/s]predicting train subjects:  70%|███████   | 187/266 [01:23<00:25,  3.10it/s]predicting train subjects:  71%|███████   | 188/266 [01:23<00:25,  3.07it/s]predicting train subjects:  71%|███████   | 189/266 [01:23<00:24,  3.10it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:24<00:24,  3.07it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:24<00:24,  3.00it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:24<00:25,  2.88it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:25<00:24,  3.00it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:25<00:26,  2.71it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:25<00:26,  2.66it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:26<00:25,  2.73it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:26<00:24,  2.85it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:26<00:23,  2.94it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:27<00:23,  2.90it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:27<00:21,  3.00it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:27<00:22,  2.95it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:28<00:21,  2.96it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:28<00:21,  3.00it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:28<00:20,  3.05it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:29<00:19,  3.09it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:29<00:19,  3.13it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:29<00:18,  3.13it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:30<00:18,  3.10it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:30<00:18,  3.11it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:30<00:18,  2.98it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:31<00:18,  3.03it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:31<00:18,  2.97it/s]predicting train subjects:  80%|████████  | 213/266 [01:31<00:17,  3.11it/s]predicting train subjects:  80%|████████  | 214/266 [01:32<00:16,  3.15it/s]predicting train subjects:  81%|████████  | 215/266 [01:32<00:15,  3.30it/s]predicting train subjects:  81%|████████  | 216/266 [01:32<00:14,  3.36it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:32<00:14,  3.42it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:33<00:14,  3.42it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:33<00:14,  3.33it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:33<00:13,  3.39it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:34<00:13,  3.43it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:34<00:12,  3.43it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:34<00:12,  3.33it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:35<00:12,  3.29it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:35<00:12,  3.21it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:35<00:13,  3.07it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:36<00:12,  3.13it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:36<00:11,  3.25it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:36<00:11,  3.30it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:36<00:11,  3.24it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:37<00:10,  3.26it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:37<00:10,  3.31it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:37<00:09,  3.33it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:38<00:09,  3.26it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:38<00:09,  3.30it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:38<00:09,  3.29it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:39<00:08,  3.25it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:39<00:08,  3.15it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:39<00:08,  3.08it/s]predicting train subjects:  90%|█████████ | 240/266 [01:40<00:08,  3.03it/s]predicting train subjects:  91%|█████████ | 241/266 [01:40<00:08,  2.99it/s]predicting train subjects:  91%|█████████ | 242/266 [01:40<00:08,  2.98it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:41<00:07,  3.07it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:41<00:07,  3.14it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:41<00:06,  3.20it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:41<00:06,  3.21it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:42<00:05,  3.24it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:42<00:05,  3.25it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:42<00:05,  3.04it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:43<00:05,  2.88it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:43<00:05,  2.82it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:44<00:05,  2.76it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:44<00:04,  2.74it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:44<00:04,  2.74it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:45<00:04,  2.72it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:45<00:03,  2.67it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:45<00:03,  2.62it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:46<00:03,  2.58it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:46<00:02,  2.53it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:47<00:02,  2.58it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:47<00:01,  2.54it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:47<00:01,  2.53it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:48<00:01,  2.58it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:48<00:00,  2.61it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:49<00:00,  2.60it/s]predicting train subjects: 100%|██████████| 266/266 [01:49<00:00,  2.63it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 58.01it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:04, 62.61it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 63.74it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 63.76it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 65.20it/s]saving BB  train1-THALAMUS:  13%|█▎        | 35/266 [00:00<00:03, 66.57it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 69.15it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 71.47it/s]saving BB  train1-THALAMUS:  22%|██▏       | 59/266 [00:00<00:02, 73.64it/s]saving BB  train1-THALAMUS:  26%|██▌       | 68/266 [00:00<00:02, 76.50it/s]saving BB  train1-THALAMUS:  29%|██▉       | 77/266 [00:01<00:02, 78.17it/s]saving BB  train1-THALAMUS:  32%|███▏      | 85/266 [00:01<00:02, 75.80it/s]saving BB  train1-THALAMUS:  35%|███▍      | 93/266 [00:01<00:02, 67.21it/s]saving BB  train1-THALAMUS:  38%|███▊      | 101/266 [00:01<00:02, 68.19it/s]saving BB  train1-THALAMUS:  41%|████      | 109/266 [00:01<00:02, 70.75it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 72.36it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:01, 71.74it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 70.87it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 141/266 [00:01<00:01, 70.47it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 149/266 [00:02<00:01, 69.48it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:02<00:01, 71.04it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 74.85it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 78.10it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 79.76it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 193/266 [00:02<00:00, 80.14it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 77.87it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 76.61it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:02<00:00, 77.04it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:03<00:00, 77.74it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:03<00:00, 78.84it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 244/266 [00:03<00:00, 79.87it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 253/266 [00:03<00:00, 75.44it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 261/266 [00:03<00:00, 74.71it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 73.85it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:45,  1.98s/it]Loading train:   1%|          | 2/266 [00:03<08:15,  1.88s/it]Loading train:   1%|          | 3/266 [00:04<07:31,  1.72s/it]Loading train:   2%|▏         | 4/266 [00:06<06:47,  1.56s/it]Loading train:   2%|▏         | 5/266 [00:08<07:18,  1.68s/it]Loading train:   2%|▏         | 6/266 [00:09<06:45,  1.56s/it]Loading train:   3%|▎         | 7/266 [00:10<06:17,  1.46s/it]Loading train:   3%|▎         | 8/266 [00:11<05:51,  1.36s/it]Loading train:   3%|▎         | 9/266 [00:12<05:31,  1.29s/it]Loading train:   4%|▍         | 10/266 [00:14<05:18,  1.24s/it]Loading train:   4%|▍         | 11/266 [00:15<05:13,  1.23s/it]Loading train:   5%|▍         | 12/266 [00:16<05:06,  1.21s/it]Loading train:   5%|▍         | 13/266 [00:17<04:59,  1.18s/it]Loading train:   5%|▌         | 14/266 [00:18<04:49,  1.15s/it]Loading train:   6%|▌         | 15/266 [00:19<04:39,  1.12s/it]Loading train:   6%|▌         | 16/266 [00:20<04:41,  1.13s/it]Loading train:   6%|▋         | 17/266 [00:21<04:39,  1.12s/it]Loading train:   7%|▋         | 18/266 [00:22<04:38,  1.12s/it]Loading train:   7%|▋         | 19/266 [00:24<04:42,  1.15s/it]Loading train:   8%|▊         | 20/266 [00:25<04:40,  1.14s/it]Loading train:   8%|▊         | 21/266 [00:26<04:28,  1.10s/it]Loading train:   8%|▊         | 22/266 [00:27<04:27,  1.10s/it]Loading train:   9%|▊         | 23/266 [00:28<04:21,  1.08s/it]Loading train:   9%|▉         | 24/266 [00:29<04:15,  1.06s/it]Loading train:   9%|▉         | 25/266 [00:30<04:06,  1.02s/it]Loading train:  10%|▉         | 26/266 [00:31<03:55,  1.02it/s]Loading train:  10%|█         | 27/266 [00:32<03:45,  1.06it/s]Loading train:  11%|█         | 28/266 [00:33<03:44,  1.06it/s]Loading train:  11%|█         | 29/266 [00:34<03:47,  1.04it/s]Loading train:  11%|█▏        | 30/266 [00:35<03:45,  1.04it/s]Loading train:  12%|█▏        | 31/266 [00:35<03:38,  1.08it/s]Loading train:  12%|█▏        | 32/266 [00:36<03:36,  1.08it/s]Loading train:  12%|█▏        | 33/266 [00:37<03:39,  1.06it/s]Loading train:  13%|█▎        | 34/266 [00:38<03:45,  1.03it/s]Loading train:  13%|█▎        | 35/266 [00:39<03:41,  1.04it/s]Loading train:  14%|█▎        | 36/266 [00:40<03:37,  1.06it/s]Loading train:  14%|█▍        | 37/266 [00:41<03:40,  1.04it/s]Loading train:  14%|█▍        | 38/266 [00:42<03:41,  1.03it/s]Loading train:  15%|█▍        | 39/266 [00:43<03:41,  1.03it/s]Loading train:  15%|█▌        | 40/266 [00:44<03:41,  1.02it/s]Loading train:  15%|█▌        | 41/266 [00:45<03:40,  1.02it/s]Loading train:  16%|█▌        | 42/266 [00:46<03:52,  1.04s/it]Loading train:  16%|█▌        | 43/266 [00:47<03:48,  1.02s/it]Loading train:  17%|█▋        | 44/266 [00:48<03:41,  1.00it/s]Loading train:  17%|█▋        | 45/266 [00:49<03:38,  1.01it/s]Loading train:  17%|█▋        | 46/266 [00:50<03:32,  1.03it/s]Loading train:  18%|█▊        | 47/266 [00:51<03:30,  1.04it/s]Loading train:  18%|█▊        | 48/266 [00:52<03:24,  1.07it/s]Loading train:  18%|█▊        | 49/266 [00:53<03:23,  1.07it/s]Loading train:  19%|█▉        | 50/266 [00:54<03:23,  1.06it/s]Loading train:  19%|█▉        | 51/266 [00:55<03:20,  1.07it/s]Loading train:  20%|█▉        | 52/266 [00:56<03:17,  1.08it/s]Loading train:  20%|█▉        | 53/266 [00:57<03:14,  1.10it/s]Loading train:  20%|██        | 54/266 [00:57<03:10,  1.11it/s]Loading train:  21%|██        | 55/266 [00:58<03:13,  1.09it/s]Loading train:  21%|██        | 56/266 [00:59<03:08,  1.11it/s]Loading train:  21%|██▏       | 57/266 [01:00<03:12,  1.08it/s]Loading train:  22%|██▏       | 58/266 [01:01<03:09,  1.10it/s]Loading train:  22%|██▏       | 59/266 [01:02<03:05,  1.12it/s]Loading train:  23%|██▎       | 60/266 [01:03<03:05,  1.11it/s]Loading train:  23%|██▎       | 61/266 [01:04<03:00,  1.14it/s]Loading train:  23%|██▎       | 62/266 [01:04<02:51,  1.19it/s]Loading train:  24%|██▎       | 63/266 [01:05<02:49,  1.20it/s]Loading train:  24%|██▍       | 64/266 [01:06<02:41,  1.25it/s]Loading train:  24%|██▍       | 65/266 [01:07<02:36,  1.29it/s]Loading train:  25%|██▍       | 66/266 [01:07<02:37,  1.27it/s]Loading train:  25%|██▌       | 67/266 [01:08<02:34,  1.28it/s]Loading train:  26%|██▌       | 68/266 [01:09<02:35,  1.28it/s]Loading train:  26%|██▌       | 69/266 [01:10<02:36,  1.26it/s]Loading train:  26%|██▋       | 70/266 [01:11<02:41,  1.22it/s]Loading train:  27%|██▋       | 71/266 [01:12<02:42,  1.20it/s]Loading train:  27%|██▋       | 72/266 [01:12<02:42,  1.20it/s]Loading train:  27%|██▋       | 73/266 [01:13<02:42,  1.19it/s]Loading train:  28%|██▊       | 74/266 [01:14<02:42,  1.18it/s]Loading train:  28%|██▊       | 75/266 [01:15<02:40,  1.19it/s]Loading train:  29%|██▊       | 76/266 [01:16<02:40,  1.19it/s]Loading train:  29%|██▉       | 77/266 [01:17<02:42,  1.16it/s]Loading train:  29%|██▉       | 78/266 [01:18<02:56,  1.07it/s]Loading train:  30%|██▉       | 79/266 [01:19<03:02,  1.03it/s]Loading train:  30%|███       | 80/266 [01:20<03:02,  1.02it/s]Loading train:  30%|███       | 81/266 [01:21<03:06,  1.01s/it]Loading train:  31%|███       | 82/266 [01:22<02:57,  1.04it/s]Loading train:  31%|███       | 83/266 [01:23<02:57,  1.03it/s]Loading train:  32%|███▏      | 84/266 [01:24<02:55,  1.04it/s]Loading train:  32%|███▏      | 85/266 [01:25<02:56,  1.03it/s]Loading train:  32%|███▏      | 86/266 [01:26<02:54,  1.03it/s]Loading train:  33%|███▎      | 87/266 [01:27<02:55,  1.02it/s]Loading train:  33%|███▎      | 88/266 [01:28<02:53,  1.02it/s]Loading train:  33%|███▎      | 89/266 [01:29<02:55,  1.01it/s]Loading train:  34%|███▍      | 90/266 [01:30<02:55,  1.00it/s]Loading train:  34%|███▍      | 91/266 [01:31<02:54,  1.00it/s]Loading train:  35%|███▍      | 92/266 [01:32<02:52,  1.01it/s]Loading train:  35%|███▍      | 93/266 [01:33<02:56,  1.02s/it]Loading train:  35%|███▌      | 94/266 [01:34<02:49,  1.01it/s]Loading train:  36%|███▌      | 95/266 [01:35<02:48,  1.02it/s]Loading train:  36%|███▌      | 96/266 [01:36<03:17,  1.16s/it]Loading train:  36%|███▋      | 97/266 [01:38<03:32,  1.26s/it]Loading train:  37%|███▋      | 98/266 [01:39<03:37,  1.29s/it]Loading train:  37%|███▋      | 99/266 [01:40<03:24,  1.23s/it]Loading train:  38%|███▊      | 100/266 [01:41<03:26,  1.25s/it]Loading train:  38%|███▊      | 101/266 [01:42<03:12,  1.17s/it]Loading train:  38%|███▊      | 102/266 [01:43<02:56,  1.07s/it]Loading train:  39%|███▊      | 103/266 [01:44<02:42,  1.00it/s]Loading train:  39%|███▉      | 104/266 [01:45<02:31,  1.07it/s]Loading train:  39%|███▉      | 105/266 [01:46<02:28,  1.09it/s]Loading train:  40%|███▉      | 106/266 [01:47<02:26,  1.09it/s]Loading train:  40%|████      | 107/266 [01:48<02:23,  1.11it/s]Loading train:  41%|████      | 108/266 [01:49<02:24,  1.10it/s]Loading train:  41%|████      | 109/266 [01:49<02:23,  1.10it/s]Loading train:  41%|████▏     | 110/266 [01:51<02:29,  1.04it/s]Loading train:  42%|████▏     | 111/266 [01:52<02:32,  1.02it/s]Loading train:  42%|████▏     | 112/266 [01:53<02:30,  1.02it/s]Loading train:  42%|████▏     | 113/266 [01:54<02:35,  1.01s/it]Loading train:  43%|████▎     | 114/266 [01:55<02:32,  1.00s/it]Loading train:  43%|████▎     | 115/266 [01:56<02:29,  1.01it/s]Loading train:  44%|████▎     | 116/266 [01:56<02:23,  1.04it/s]Loading train:  44%|████▍     | 117/266 [01:57<02:22,  1.05it/s]Loading train:  44%|████▍     | 118/266 [01:58<02:19,  1.06it/s]Loading train:  45%|████▍     | 119/266 [01:59<02:26,  1.00it/s]Loading train:  45%|████▌     | 120/266 [02:01<02:30,  1.03s/it]Loading train:  45%|████▌     | 121/266 [02:02<02:29,  1.03s/it]Loading train:  46%|████▌     | 122/266 [02:03<02:25,  1.01s/it]Loading train:  46%|████▌     | 123/266 [02:04<02:25,  1.02s/it]Loading train:  47%|████▋     | 124/266 [02:05<02:24,  1.01s/it]Loading train:  47%|████▋     | 125/266 [02:06<02:21,  1.00s/it]Loading train:  47%|████▋     | 126/266 [02:07<02:19,  1.00it/s]Loading train:  48%|████▊     | 127/266 [02:08<02:19,  1.00s/it]Loading train:  48%|████▊     | 128/266 [02:09<02:19,  1.01s/it]Loading train:  48%|████▊     | 129/266 [02:10<02:21,  1.03s/it]Loading train:  49%|████▉     | 130/266 [02:11<02:20,  1.03s/it]Loading train:  49%|████▉     | 131/266 [02:12<02:17,  1.02s/it]Loading train:  50%|████▉     | 132/266 [02:13<02:15,  1.01s/it]Loading train:  50%|█████     | 133/266 [02:14<02:14,  1.01s/it]Loading train:  50%|█████     | 134/266 [02:15<02:10,  1.01it/s]Loading train:  51%|█████     | 135/266 [02:16<02:09,  1.01it/s]Loading train:  51%|█████     | 136/266 [02:17<02:07,  1.02it/s]Loading train:  52%|█████▏    | 137/266 [02:18<02:10,  1.01s/it]Loading train:  52%|█████▏    | 138/266 [02:19<02:10,  1.02s/it]Loading train:  52%|█████▏    | 139/266 [02:20<02:07,  1.00s/it]Loading train:  53%|█████▎    | 140/266 [02:21<02:05,  1.01it/s]Loading train:  53%|█████▎    | 141/266 [02:22<02:02,  1.02it/s]Loading train:  53%|█████▎    | 142/266 [02:23<02:02,  1.01it/s]Loading train:  54%|█████▍    | 143/266 [02:24<01:59,  1.03it/s]Loading train:  54%|█████▍    | 144/266 [02:24<01:58,  1.03it/s]Loading train:  55%|█████▍    | 145/266 [02:25<01:58,  1.02it/s]Loading train:  55%|█████▍    | 146/266 [02:26<01:57,  1.02it/s]Loading train:  55%|█████▌    | 147/266 [02:27<01:57,  1.01it/s]Loading train:  56%|█████▌    | 148/266 [02:28<01:56,  1.02it/s]Loading train:  56%|█████▌    | 149/266 [02:29<01:56,  1.01it/s]Loading train:  56%|█████▋    | 150/266 [02:30<01:52,  1.03it/s]Loading train:  57%|█████▋    | 151/266 [02:31<01:52,  1.02it/s]Loading train:  57%|█████▋    | 152/266 [02:32<01:50,  1.03it/s]Loading train:  58%|█████▊    | 153/266 [02:33<01:51,  1.01it/s]Loading train:  58%|█████▊    | 154/266 [02:34<01:48,  1.03it/s]Loading train:  58%|█████▊    | 155/266 [02:35<01:45,  1.05it/s]Loading train:  59%|█████▊    | 156/266 [02:36<01:41,  1.09it/s]Loading train:  59%|█████▉    | 157/266 [02:37<01:37,  1.12it/s]Loading train:  59%|█████▉    | 158/266 [02:38<01:37,  1.11it/s]Loading train:  60%|█████▉    | 159/266 [02:39<01:39,  1.08it/s]Loading train:  60%|██████    | 160/266 [02:40<01:36,  1.10it/s]Loading train:  61%|██████    | 161/266 [02:41<01:34,  1.11it/s]Loading train:  61%|██████    | 162/266 [02:41<01:31,  1.14it/s]Loading train:  61%|██████▏   | 163/266 [02:42<01:33,  1.10it/s]Loading train:  62%|██████▏   | 164/266 [02:43<01:29,  1.14it/s]Loading train:  62%|██████▏   | 165/266 [02:44<01:25,  1.18it/s]Loading train:  62%|██████▏   | 166/266 [02:45<01:23,  1.20it/s]Loading train:  63%|██████▎   | 167/266 [02:46<01:24,  1.17it/s]Loading train:  63%|██████▎   | 168/266 [02:46<01:22,  1.19it/s]Loading train:  64%|██████▎   | 169/266 [02:47<01:21,  1.19it/s]Loading train:  64%|██████▍   | 170/266 [02:48<01:19,  1.21it/s]Loading train:  64%|██████▍   | 171/266 [02:49<01:20,  1.18it/s]Loading train:  65%|██████▍   | 172/266 [02:50<01:19,  1.18it/s]Loading train:  65%|██████▌   | 173/266 [02:51<01:20,  1.15it/s]Loading train:  65%|██████▌   | 174/266 [02:52<01:18,  1.17it/s]Loading train:  66%|██████▌   | 175/266 [02:52<01:17,  1.17it/s]Loading train:  66%|██████▌   | 176/266 [02:53<01:15,  1.19it/s]Loading train:  67%|██████▋   | 177/266 [02:54<01:16,  1.16it/s]Loading train:  67%|██████▋   | 178/266 [02:55<01:17,  1.14it/s]Loading train:  67%|██████▋   | 179/266 [02:56<01:17,  1.13it/s]Loading train:  68%|██████▊   | 180/266 [02:57<01:18,  1.09it/s]Loading train:  68%|██████▊   | 181/266 [02:58<01:17,  1.09it/s]Loading train:  68%|██████▊   | 182/266 [02:59<01:16,  1.10it/s]Loading train:  69%|██████▉   | 183/266 [03:00<01:13,  1.12it/s]Loading train:  69%|██████▉   | 184/266 [03:00<01:12,  1.13it/s]Loading train:  70%|██████▉   | 185/266 [03:01<01:10,  1.15it/s]Loading train:  70%|██████▉   | 186/266 [03:02<01:08,  1.16it/s]Loading train:  70%|███████   | 187/266 [03:03<01:07,  1.17it/s]Loading train:  71%|███████   | 188/266 [03:04<01:03,  1.22it/s]Loading train:  71%|███████   | 189/266 [03:05<01:03,  1.22it/s]Loading train:  71%|███████▏  | 190/266 [03:05<01:02,  1.22it/s]Loading train:  72%|███████▏  | 191/266 [03:07<01:12,  1.03it/s]Loading train:  72%|███████▏  | 192/266 [03:08<01:17,  1.05s/it]Loading train:  73%|███████▎  | 193/266 [03:09<01:18,  1.07s/it]Loading train:  73%|███████▎  | 194/266 [03:11<01:27,  1.21s/it]Loading train:  73%|███████▎  | 195/266 [03:11<01:17,  1.09s/it]Loading train:  74%|███████▎  | 196/266 [03:12<01:10,  1.01s/it]Loading train:  74%|███████▍  | 197/266 [03:13<01:05,  1.05it/s]Loading train:  74%|███████▍  | 198/266 [03:14<01:02,  1.09it/s]Loading train:  75%|███████▍  | 199/266 [03:15<01:00,  1.11it/s]Loading train:  75%|███████▌  | 200/266 [03:16<00:57,  1.14it/s]Loading train:  76%|███████▌  | 201/266 [03:16<00:56,  1.16it/s]Loading train:  76%|███████▌  | 202/266 [03:17<00:56,  1.14it/s]Loading train:  76%|███████▋  | 203/266 [03:18<00:55,  1.13it/s]Loading train:  77%|███████▋  | 204/266 [03:19<00:53,  1.15it/s]Loading train:  77%|███████▋  | 205/266 [03:20<00:53,  1.14it/s]Loading train:  77%|███████▋  | 206/266 [03:21<00:53,  1.12it/s]Loading train:  78%|███████▊  | 207/266 [03:22<00:52,  1.12it/s]Loading train:  78%|███████▊  | 208/266 [03:23<00:53,  1.07it/s]Loading train:  79%|███████▊  | 209/266 [03:24<00:52,  1.08it/s]Loading train:  79%|███████▉  | 210/266 [03:25<00:51,  1.09it/s]Loading train:  79%|███████▉  | 211/266 [03:25<00:50,  1.09it/s]Loading train:  80%|███████▉  | 212/266 [03:26<00:49,  1.10it/s]Loading train:  80%|████████  | 213/266 [03:27<00:47,  1.11it/s]Loading train:  80%|████████  | 214/266 [03:28<00:46,  1.11it/s]Loading train:  81%|████████  | 215/266 [03:29<00:45,  1.12it/s]Loading train:  81%|████████  | 216/266 [03:30<00:44,  1.14it/s]Loading train:  82%|████████▏ | 217/266 [03:31<00:42,  1.15it/s]Loading train:  82%|████████▏ | 218/266 [03:32<00:41,  1.15it/s]Loading train:  82%|████████▏ | 219/266 [03:32<00:39,  1.19it/s]Loading train:  83%|████████▎ | 220/266 [03:33<00:38,  1.20it/s]Loading train:  83%|████████▎ | 221/266 [03:34<00:38,  1.17it/s]Loading train:  83%|████████▎ | 222/266 [03:35<00:37,  1.16it/s]Loading train:  84%|████████▍ | 223/266 [03:36<00:36,  1.17it/s]Loading train:  84%|████████▍ | 224/266 [03:37<00:35,  1.17it/s]Loading train:  85%|████████▍ | 225/266 [03:38<00:35,  1.16it/s]Loading train:  85%|████████▍ | 226/266 [03:38<00:35,  1.14it/s]Loading train:  85%|████████▌ | 227/266 [03:39<00:34,  1.13it/s]Loading train:  86%|████████▌ | 228/266 [03:40<00:33,  1.13it/s]Loading train:  86%|████████▌ | 229/266 [03:41<00:33,  1.12it/s]Loading train:  86%|████████▋ | 230/266 [03:42<00:32,  1.12it/s]Loading train:  87%|████████▋ | 231/266 [03:43<00:32,  1.08it/s]Loading train:  87%|████████▋ | 232/266 [03:44<00:31,  1.09it/s]Loading train:  88%|████████▊ | 233/266 [03:45<00:30,  1.10it/s]Loading train:  88%|████████▊ | 234/266 [03:46<00:28,  1.11it/s]Loading train:  88%|████████▊ | 235/266 [03:47<00:26,  1.16it/s]Loading train:  89%|████████▊ | 236/266 [03:47<00:25,  1.18it/s]Loading train:  89%|████████▉ | 237/266 [03:48<00:24,  1.19it/s]Loading train:  89%|████████▉ | 238/266 [03:49<00:22,  1.22it/s]Loading train:  90%|████████▉ | 239/266 [03:50<00:21,  1.24it/s]Loading train:  90%|█████████ | 240/266 [03:51<00:21,  1.22it/s]Loading train:  91%|█████████ | 241/266 [03:51<00:20,  1.19it/s]Loading train:  91%|█████████ | 242/266 [03:52<00:19,  1.20it/s]Loading train:  91%|█████████▏| 243/266 [03:53<00:19,  1.19it/s]Loading train:  92%|█████████▏| 244/266 [03:54<00:18,  1.18it/s]Loading train:  92%|█████████▏| 245/266 [03:55<00:17,  1.17it/s]Loading train:  92%|█████████▏| 246/266 [03:56<00:17,  1.16it/s]Loading train:  93%|█████████▎| 247/266 [03:56<00:15,  1.19it/s]Loading train:  93%|█████████▎| 248/266 [03:57<00:14,  1.22it/s]Loading train:  94%|█████████▎| 249/266 [03:58<00:15,  1.11it/s]Loading train:  94%|█████████▍| 250/266 [03:59<00:15,  1.05it/s]Loading train:  94%|█████████▍| 251/266 [04:01<00:15,  1.00s/it]Loading train:  95%|█████████▍| 252/266 [04:02<00:14,  1.02s/it]Loading train:  95%|█████████▌| 253/266 [04:03<00:13,  1.01s/it]Loading train:  95%|█████████▌| 254/266 [04:04<00:12,  1.01s/it]Loading train:  96%|█████████▌| 255/266 [04:05<00:11,  1.03s/it]Loading train:  96%|█████████▌| 256/266 [04:06<00:10,  1.03s/it]Loading train:  97%|█████████▋| 257/266 [04:07<00:09,  1.03s/it]Loading train:  97%|█████████▋| 258/266 [04:08<00:08,  1.03s/it]Loading train:  97%|█████████▋| 259/266 [04:09<00:07,  1.04s/it]Loading train:  98%|█████████▊| 260/266 [04:10<00:06,  1.03s/it]Loading train:  98%|█████████▊| 261/266 [04:11<00:05,  1.04s/it]Loading train:  98%|█████████▊| 262/266 [04:12<00:04,  1.05s/it]Loading train:  99%|█████████▉| 263/266 [04:13<00:03,  1.06s/it]Loading train:  99%|█████████▉| 264/266 [04:14<00:02,  1.06s/it]Loading train: 100%|█████████▉| 265/266 [04:15<00:01,  1.04s/it]Loading train: 100%|██████████| 266/266 [04:16<00:00,  1.03s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:02, 107.06it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:02, 118.78it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:01, 130.77it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:01, 138.93it/s]concatenating: train:  31%|███       | 83/266 [00:00<00:01, 152.97it/s]concatenating: train:  40%|████      | 107/266 [00:00<00:00, 170.73it/s]concatenating: train:  52%|█████▏    | 139/266 [00:00<00:00, 198.05it/s]concatenating: train:  64%|██████▍   | 171/266 [00:00<00:00, 222.48it/s]concatenating: train:  77%|███████▋  | 205/266 [00:00<00:00, 247.47it/s]concatenating: train:  89%|████████▉ | 238/266 [00:01<00:00, 266.86it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 240.32it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.38s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.32s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.29s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 52.55it/s]2019-07-29 07:19:26.370665: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 07:19:26.370747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 07:19:26.370769: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 07:19:26.370778: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 07:19:26.371158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.45it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.26it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.95it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.31it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.49it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.15it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.40it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.99it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.59it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.26it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.81it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.17it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.34it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.46it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.94it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.12it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.44it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.70it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.25it/s]
Epoch 00044: val_mDice did not improve from 0.89198
Restoring model weights from the end of the best epoch
Epoch 00044: early stopping
{'val_loss': [0.07125375280627097, 0.07692009443887557, 0.06073312384236341, 0.058894911573992834, 0.058995767092012395, 0.06376985855626338, 0.06583373865695914, 0.06081561217404375, 0.063682067048068, 0.06447697293502513, 0.061739064113359256, 0.06265979623327954, 0.06411160363091363, 0.06614033702873823, 0.0632078917414853, 0.0631429527067777, 0.06227636442642019, 0.061057265678589996, 0.062087497175341906, 0.06731096687115203, 0.06460010903802785, 0.0632293645969846, 0.06207882503818984, 0.06276476375683389, 0.06001055361044527, 0.06263502595024277, 0.06257115018488181, 0.06464355386266804, 0.06290125954105999, 0.06226639840940033, 0.062184292616115674, 0.06518003611703112, 0.0660163669310736, 0.0629468574706051, 0.0626223161252159, 0.06309565147290928, 0.061266285245015165, 0.06327066995730304, 0.06220159553593457, 0.061967201474489586, 0.06466906465063191, 0.06299165818802636, 0.0651459340758697, 0.0642261863168743], 'val_acc': [0.9933552209174994, 0.9945236917095955, 0.9947402778297963, 0.9949334974240776, 0.994768908228537, 0.9947812138783811, 0.9945101584448959, 0.9947645920093613, 0.9942917206672707, 0.9945104658001601, 0.9947664424626514, 0.9947682868952703, 0.994454168310069, 0.9946215447753367, 0.9946793853634536, 0.9947516617148814, 0.9947165837793639, 0.9944621643634758, 0.9946384568407078, 0.9947021266426703, 0.994945802170821, 0.9947172186591409, 0.9947485911725747, 0.9943043399940837, 0.9947990546322832, 0.9946221495517577, 0.9944135513570573, 0.9945895382852266, 0.9946516800408411, 0.9948024328308877, 0.9945661546003939, 0.994546770748466, 0.9945566100303573, 0.9945197024128654, 0.9947488997319732, 0.9947661357094543, 0.9948316631895123, 0.9946747687127855, 0.9944655452713822, 0.9947279884357645, 0.9946926100687548, 0.9943535625934601, 0.9945944677097629, 0.9944384817523185], 'val_mDice': [0.8708028630776838, 0.8620964911851016, 0.8889509565902479, 0.8919821706685153, 0.8917866984401086, 0.8838789992862277, 0.8806881215235199, 0.8890261343031218, 0.8842373538498927, 0.883019003904227, 0.8873463044262896, 0.8861384448981044, 0.8837376357329012, 0.880220416519377, 0.8853311174445682, 0.8854493161644599, 0.8867864307731089, 0.8886092217883679, 0.8870149381232985, 0.8779990934964382, 0.8830017552833365, 0.8850903845194614, 0.88686097902481, 0.8858274483319485, 0.8904690218694282, 0.8861126598685679, 0.8862832272895659, 0.8828407857153151, 0.8856429352302744, 0.8868952408583477, 0.8870155212253031, 0.8821229880506342, 0.8805784607174421, 0.8856494360499911, 0.8860764536592696, 0.8853708379196398, 0.8884649707211388, 0.8852002376859839, 0.8870852487255828, 0.8872557125910364, 0.8827550929002087, 0.8855093413531178, 0.8820225012422812, 0.8833599424723423], 'loss': [0.10136341603718613, 0.05204890923520059, 0.04707548836903752, 0.04378502227944457, 0.04085608025812518, 0.0394501177278001, 0.03771416325826658, 0.03664972169069388, 0.035390395167315895, 0.0345724364878074, 0.0338837459351181, 0.033137431290563325, 0.03249125089772573, 0.03219044688300662, 0.031526743021036314, 0.03119857463079616, 0.030576787702586164, 0.030447855945241967, 0.029921218820479826, 0.029708325893765552, 0.029349811481893664, 0.02905622554537186, 0.028943930796667384, 0.02858881409193715, 0.0283413160020353, 0.028181556200949833, 0.028052753886029506, 0.02773241377013506, 0.027676542930902125, 0.027545702134654675, 0.027318189817897336, 0.02740126940065264, 0.027088501315648973, 0.027014228563478754, 0.026790226414849207, 0.026813435022591987, 0.026658920148590476, 0.026504322152443565, 0.026303468134389853, 0.026370252750971827, 0.026055055352878068, 0.026102915150992747, 0.025899109645014656, 0.025842602108652624], 'acc': [0.9900164286964307, 0.9943794918907082, 0.9948563908642117, 0.9951604119590758, 0.9954249938124607, 0.9955542088023471, 0.9956988224553182, 0.9958077505303847, 0.9958979372115756, 0.9959812836022257, 0.9960417986175965, 0.9961093515301456, 0.9961645894292195, 0.9961887595226481, 0.9962495689470975, 0.9962713264228915, 0.9963391706031733, 0.9963471624664407, 0.9963950612675608, 0.9964182154262599, 0.9964432192435707, 0.9964717139780157, 0.9964944044548748, 0.9965147420060627, 0.9965370610948927, 0.9965660961344639, 0.9965722167202696, 0.9966055150519666, 0.9966136117722991, 0.9966074572663456, 0.9966435519965825, 0.9966268836014369, 0.9966594475119913, 0.996668321495037, 0.9966905707203316, 0.9966864617055655, 0.9967035346038515, 0.9967030949943058, 0.9967239502819123, 0.9967223932987821, 0.996761210679403, 0.9967502150482936, 0.9967659077669223, 0.9967732202944131], 'mDice': [0.8455548090199699, 0.903802891327398, 0.9125699825654371, 0.9184332400561444, 0.9236795828542377, 0.9262136241100513, 0.9293520823528381, 0.9312755378657276, 0.9335736188426995, 0.9350617051222541, 0.9363164342850672, 0.9376804511080338, 0.9388609222776787, 0.9394127839835003, 0.9406308969675453, 0.9412335556441191, 0.9423721939156019, 0.9426114325862088, 0.943580331294471, 0.943973280706943, 0.9446333094515014, 0.9451746742612156, 0.945381022400082, 0.9460379190032973, 0.9464943844111704, 0.9467855933292948, 0.9470278542963609, 0.9476156365059152, 0.9477181239335463, 0.9479671289573491, 0.9483838994096584, 0.9482344480752988, 0.9488112112927778, 0.9489495076456608, 0.949363819356857, 0.9493219420517757, 0.9496085301137973, 0.9498946091968342, 0.9502656000703291, 0.9501445556234717, 0.9507260338160396, 0.9506393980484971, 0.9510216666459739, 0.9511263169915013]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 48, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 48, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 48, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 48, 52, 30)   11100       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 48, 52, 30)   120         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 48, 52, 30)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 48, 52, 30)   8130        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 48, 52, 30)   120         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 48, 52, 30)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 24, 26, 60)   16260       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 24, 26, 60)   240         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 24, 26, 60)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 24, 26, 60)   32460       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 24, 26, 60)   240         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 24, 26, 60)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 24, 26, 90)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 12, 13, 120)  97320       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 12, 13, 120)  480         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 12, 13, 120)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 12, 13, 120)  129720      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 12, 13, 120)  480         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 12, 13, 120)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 12, 13, 210)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 12, 13, 210)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 24, 26, 60)   240         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 24, 26, 60)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 24, 26, 60)   32460       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 24, 26, 60)   240         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 24, 26, 60)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 24, 26, 210)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 24, 26, 210)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 30)   16230       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 48, 52, 30)   120         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 48, 52, 30)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 48, 52, 30)   8130        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 48, 52, 30)   120         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 48, 52, 30)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 48, 52, 90)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 48, 52, 90)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 48, 52, 40)   32440       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 48, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 48, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 48, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 48, 52, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 48, 52, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 48, 52, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 48, 52, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 48, 52, 130)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 48, 52, 13)   1703        concatenate_8[0][0]              
==================================================================================================
Total params: 575,023
Trainable params: 182,483
Non-trainable params: 392,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34754289e-02 3.28984335e-02 7.69284619e-02 9.55874822e-03
 2.76651940e-02 7.23787788e-03 8.42775321e-02 1.14341494e-01
 8.97806414e-02 1.36408037e-02 2.91086498e-01 1.88842878e-01
 2.66008460e-04]
Train on 16655 samples, validate on 238 samples
Epoch 1/300
 - 26s - loss: 1.1198 - acc: 0.8536 - mDice: 0.4489 - val_loss: 0.9439 - val_acc: 0.9438 - val_mDice: 0.5834

Epoch 00001: val_mDice improved from -inf to 0.58335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 21s - loss: 0.4314 - acc: 0.9360 - mDice: 0.6428 - val_loss: 0.8510 - val_acc: 0.9483 - val_mDice: 0.6129

Epoch 00002: val_mDice improved from 0.58335 to 0.61287, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 20s - loss: 0.3823 - acc: 0.9422 - mDice: 0.6770 - val_loss: 1.0614 - val_acc: 0.9465 - val_mDice: 0.5255

Epoch 00003: val_mDice did not improve from 0.61287
Epoch 4/300
 - 20s - loss: 0.3539 - acc: 0.9439 - mDice: 0.6933 - val_loss: 0.9269 - val_acc: 0.9496 - val_mDice: 0.5598

Epoch 00004: val_mDice did not improve from 0.61287
Epoch 5/300
 - 21s - loss: 0.3396 - acc: 0.9452 - mDice: 0.7039 - val_loss: 1.9440 - val_acc: 0.9173 - val_mDice: 0.4430

Epoch 00005: val_mDice did not improve from 0.61287
Epoch 6/300
 - 20s - loss: 0.3754 - acc: 0.9425 - mDice: 0.6834 - val_loss: 0.9719 - val_acc: 0.9355 - val_mDice: 0.5583

Epoch 00006: val_mDice did not improve from 0.61287
Epoch 7/300
 - 20s - loss: 0.3555 - acc: 0.9428 - mDice: 0.6929 - val_loss: 0.7943 - val_acc: 0.9506 - val_mDice: 0.6134

Epoch 00007: val_mDice improved from 0.61287 to 0.61344, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 20s - loss: 0.3283 - acc: 0.9457 - mDice: 0.7112 - val_loss: 0.8426 - val_acc: 0.9484 - val_mDice: 0.6129

Epoch 00008: val_mDice did not improve from 0.61344
Epoch 9/300
 - 21s - loss: 0.3309 - acc: 0.9465 - mDice: 0.7146 - val_loss: 0.7937 - val_acc: 0.9500 - val_mDice: 0.6133

Epoch 00009: val_mDice did not improve from 0.61344
Epoch 10/300
 - 20s - loss: 0.3234 - acc: 0.9467 - mDice: 0.7166 - val_loss: 0.8256 - val_acc: 0.9494 - val_mDice: 0.6172

Epoch 00010: val_mDice improved from 0.61344 to 0.61716, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 20s - loss: 0.3279 - acc: 0.9466 - mDice: 0.7148 - val_loss: 0.8182 - val_acc: 0.9413 - val_mDice: 0.5761

Epoch 00011: val_mDice did not improve from 0.61716
Epoch 12/300
 - 20s - loss: 0.3112 - acc: 0.9479 - mDice: 0.7267 - val_loss: 0.7716 - val_acc: 0.9486 - val_mDice: 0.6071

Epoch 00012: val_mDice did not improve from 0.61716
Epoch 13/300
 - 20s - loss: 0.3206 - acc: 0.9474 - mDice: 0.7244 - val_loss: 0.8120 - val_acc: 0.9483 - val_mDice: 0.6001

Epoch 00013: val_mDice did not improve from 0.61716
Epoch 14/300
 - 21s - loss: 0.3125 - acc: 0.9476 - mDice: 0.7243 - val_loss: 0.6390 - val_acc: 0.9490 - val_mDice: 0.6105

Epoch 00014: val_mDice did not improve from 0.61716
Epoch 15/300
 - 20s - loss: 0.3267 - acc: 0.9468 - mDice: 0.7174 - val_loss: 0.6759 - val_acc: 0.9441 - val_mDice: 0.6086

Epoch 00015: val_mDice did not improve from 0.61716
Epoch 16/300
 - 20s - loss: 0.3528 - acc: 0.9424 - mDice: 0.6999 - val_loss: 0.8317 - val_acc: 0.9479 - val_mDice: 0.6035

Epoch 00016: val_mDice did not improve from 0.61716
Epoch 17/300
 - 20s - loss: 0.3363 - acc: 0.9450 - mDice: 0.7083 - val_loss: 0.8482 - val_acc: 0.9456 - val_mDice: 0.5836

Epoch 00017: val_mDice did not improve from 0.61716
Epoch 18/300
 - 21s - loss: 0.3483 - acc: 0.9448 - mDice: 0.7029 - val_loss: 0.6944 - val_acc: 0.9467 - val_mDice: 0.6007

Epoch 00018: val_mDice did not improve from 0.61716
Epoch 19/300
 - 21s - loss: 0.3116 - acc: 0.9479 - mDice: 0.7297 - val_loss: 0.8563 - val_acc: 0.9491 - val_mDice: 0.6013

Epoch 00019: val_mDice did not improve from 0.61716
Epoch 20/300
 - 20s - loss: 0.3213 - acc: 0.9474 - mDice: 0.7239 - val_loss: 0.9551 - val_acc: 0.9476 - val_mDice: 0.6068

Epoch 00020: val_mDice did not improve from 0.61716
Epoch 21/300
 - 20s - loss: 0.3527 - acc: 0.9448 - mDice: 0.7015 - val_loss: 0.8744 - val_acc: 0.9462 - val_mDice: 0.6134

Epoch 00021: val_mDice did not improve from 0.61716
Epoch 22/300
 - 20s - loss: 0.3241 - acc: 0.9457 - mDice: 0.7175 - val_loss: 0.7658 - val_acc: 0.9483 - val_mDice: 0.6099

Epoch 00022: val_mDice did not improve from 0.61716
Epoch 23/300
 - 20s - loss: 0.2970 - acc: 0.9487 - mDice: 0.7352 - val_loss: 0.7028 - val_acc: 0.9508 - val_mDice: 0.6127

Epoch 00023: val_mDice did not improve from 0.61716
Epoch 24/300
 - 21s - loss: 0.3012 - acc: 0.9485 - mDice: 0.7336 - val_loss: 0.8406 - val_acc: 0.9478 - val_mDice: 0.6127

Epoch 00024: val_mDice did not improve from 0.61716
Epoch 25/300
 - 20s - loss: 0.2910 - acc: 0.9488 - mDice: 0.7373 - val_loss: 0.7264 - val_acc: 0.9489 - val_mDice: 0.6069

Epoch 00025: val_mDice did not improve from 0.61716
Epoch 26/300
 - 20s - loss: 0.2938 - acc: 0.9489 - mDice: 0.7385 - val_loss: 0.7832 - val_acc: 0.9496 - val_mDice: 0.6120

Epoch 00026: val_mDice did not improve from 0.61716
Epoch 27/300
 - 20s - loss: 0.3224 - acc: 0.9477 - mDice: 0.7262 - val_loss: 0.8149 - val_acc: 0.9468 - val_mDice: 0.5852

Epoch 00027: val_mDice did not improve from 0.61716
Epoch 28/300
 - 21s - loss: 0.2939 - acc: 0.9492 - mDice: 0.7383 - val_loss: 0.7518 - val_acc: 0.9505 - val_mDice: 0.6137

Epoch 00028: val_mDice did not improve from 0.61716
Epoch 29/300
 - 21s - loss: 0.3196 - acc: 0.9468 - mDice: 0.7222 - val_loss: 0.5812 - val_acc: 0.9488 - val_mDice: 0.6184

Epoch 00029: val_mDice improved from 0.61716 to 0.61842, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 20s - loss: 0.2854 - acc: 0.9498 - mDice: 0.7444 - val_loss: 0.6705 - val_acc: 0.9481 - val_mDice: 0.6201

Epoch 00030: val_mDice improved from 0.61842 to 0.62005, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 20s - loss: 0.2818 - acc: 0.9497 - mDice: 0.7449 - val_loss: 0.5448 - val_acc: 0.9473 - val_mDice: 0.6145

Epoch 00031: val_mDice did not improve from 0.62005
Epoch 32/300
 - 20s - loss: 0.2708 - acc: 0.9497 - mDice: 0.7514 - val_loss: 0.6994 - val_acc: 0.9475 - val_mDice: 0.6169

Epoch 00032: val_mDice did not improve from 0.62005
Epoch 33/300
 - 20s - loss: 0.2797 - acc: 0.9502 - mDice: 0.7486 - val_loss: 0.9916 - val_acc: 0.9468 - val_mDice: 0.5523

Epoch 00033: val_mDice did not improve from 0.62005
Epoch 34/300
 - 21s - loss: 0.3050 - acc: 0.9488 - mDice: 0.7362 - val_loss: 0.6130 - val_acc: 0.9495 - val_mDice: 0.6171

Epoch 00034: val_mDice did not improve from 0.62005
Epoch 35/300
 - 20s - loss: 0.3078 - acc: 0.9489 - mDice: 0.7355 - val_loss: 0.6592 - val_acc: 0.9490 - val_mDice: 0.6267

Epoch 00035: val_mDice improved from 0.62005 to 0.62672, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 20s - loss: 0.2855 - acc: 0.9502 - mDice: 0.7492 - val_loss: 0.7957 - val_acc: 0.9480 - val_mDice: 0.5866

Epoch 00036: val_mDice did not improve from 0.62672
Epoch 37/300
 - 20s - loss: 0.3285 - acc: 0.9457 - mDice: 0.7144 - val_loss: 0.8081 - val_acc: 0.9478 - val_mDice: 0.6101

Epoch 00037: val_mDice did not improve from 0.62672
Epoch 38/300
 - 21s - loss: 0.2766 - acc: 0.9500 - mDice: 0.7477 - val_loss: 0.9502 - val_acc: 0.9505 - val_mDice: 0.6104

Epoch 00038: val_mDice did not improve from 0.62672
Epoch 39/300
 - 21s - loss: 0.2824 - acc: 0.9499 - mDice: 0.7478 - val_loss: 0.9760 - val_acc: 0.9478 - val_mDice: 0.5726

Epoch 00039: val_mDice did not improve from 0.62672
Epoch 40/300
 - 20s - loss: 0.3530 - acc: 0.9440 - mDice: 0.7002 - val_loss: 0.7728 - val_acc: 0.9485 - val_mDice: 0.6083

Epoch 00040: val_mDice did not improve from 0.62672
Epoch 41/300
 - 20s - loss: 0.2767 - acc: 0.9499 - mDice: 0.7468 - val_loss: 0.6502 - val_acc: 0.9484 - val_mDice: 0.6022

Epoch 00041: val_mDice did not improve from 0.62672
Epoch 42/300
 - 21s - loss: 0.2735 - acc: 0.9507 - mDice: 0.7539 - val_loss: 0.7064 - val_acc: 0.9500 - val_mDice: 0.6012

Epoch 00042: val_mDice did not improve from 0.62672
Epoch 43/300
 - 21s - loss: 0.3138 - acc: 0.9473 - mDice: 0.7274 - val_loss: 0.6174 - val_acc: 0.9444 - val_mDice: 0.6070

Epoch 00043: val_mDice did not improve from 0.62672
Epoch 44/300
 - 21s - loss: 0.3079 - acc: 0.9467 - mDice: 0.7264 - val_loss: 0.5498 - val_acc: 0.9496 - val_mDice: 0.6229

Epoch 00044: val_mDice did not improve from 0.62672
Epoch 45/300
 - 21s - loss: 0.2655 - acc: 0.9508 - mDice: 0.7551 - val_loss: 0.8279 - val_acc: 0.9487 - val_mDice: 0.6170

Epoch 00045: val_mDice did not improve from 0.62672
Epoch 46/300
 - 21s - loss: 0.2711 - acc: 0.9511 - mDice: 0.7570 - val_loss: 0.7632 - val_acc: 0.9509 - val_mDice: 0.6112

Epoch 00046: val_mDice did not improve from 0.62672
Epoch 47/300
 - 21s - loss: 0.2692 - acc: 0.9512 - mDice: 0.7590 - val_loss: 0.7323 - val_acc: 0.9481 - val_mDice: 0.6049

Epoch 00047: val_mDice did not improve from 0.62672
Epoch 48/300
 - 21s - loss: 0.2766 - acc: 0.9505 - mDice: 0.7521 - val_loss: 0.7193 - val_acc: 0.9487 - val_mDice: 0.6120

Epoch 00048: val_mDice did not improve from 0.62672
Epoch 49/300
 - 21s - loss: 0.2567 - acc: 0.9519 - mDice: 0.7665 - val_loss: 1.4488 - val_acc: 0.9481 - val_mDice: 0.5152

Epoch 00049: val_mDice did not improve from 0.62672
Epoch 50/300
 - 21s - loss: 0.2614 - acc: 0.9513 - mDice: 0.7614 - val_loss: 0.7706 - val_acc: 0.9515 - val_mDice: 0.6089

Epoch 00050: val_mDice did not improve from 0.62672
Epoch 51/300
 - 21s - loss: 0.3064 - acc: 0.9484 - mDice: 0.7344 - val_loss: 0.7407 - val_acc: 0.9494 - val_mDice: 0.6066

Epoch 00051: val_mDice did not improve from 0.62672
Epoch 52/300
 - 22s - loss: 0.3066 - acc: 0.9473 - mDice: 0.7264 - val_loss: 1.1873 - val_acc: 0.9506 - val_mDice: 0.5880

Epoch 00052: val_mDice did not improve from 0.62672
Epoch 53/300
 - 22s - loss: 0.3212 - acc: 0.9451 - mDice: 0.7160 - val_loss: 0.5380 - val_acc: 0.9473 - val_mDice: 0.6192

Epoch 00053: val_mDice did not improve from 0.62672
Epoch 54/300
 - 21s - loss: 0.2665 - acc: 0.9507 - mDice: 0.7551 - val_loss: 0.5758 - val_acc: 0.9502 - val_mDice: 0.6163

Epoch 00054: val_mDice did not improve from 0.62672
Epoch 55/300
 - 22s - loss: 0.3363 - acc: 0.9459 - mDice: 0.7128 - val_loss: 0.6425 - val_acc: 0.9471 - val_mDice: 0.6154

Epoch 00055: val_mDice did not improve from 0.62672
Epoch 56/300
 - 21s - loss: 0.2734 - acc: 0.9503 - mDice: 0.7520 - val_loss: 0.7528 - val_acc: 0.9479 - val_mDice: 0.6173

Epoch 00056: val_mDice did not improve from 0.62672
Epoch 57/300
 - 21s - loss: 0.2849 - acc: 0.9492 - mDice: 0.7431 - val_loss: 0.7382 - val_acc: 0.9480 - val_mDice: 0.6199

Epoch 00057: val_mDice did not improve from 0.62672
Epoch 58/300
 - 21s - loss: 0.2810 - acc: 0.9504 - mDice: 0.7527 - val_loss: 0.7322 - val_acc: 0.9478 - val_mDice: 0.6045

Epoch 00058: val_mDice did not improve from 0.62672
Epoch 59/300
 - 21s - loss: 0.2910 - acc: 0.9488 - mDice: 0.7391 - val_loss: 0.5608 - val_acc: 0.9483 - val_mDice: 0.5977

Epoch 00059: val_mDice did not improve from 0.62672
Epoch 60/300
 - 21s - loss: 0.3265 - acc: 0.9461 - mDice: 0.7196 - val_loss: 0.8325 - val_acc: 0.9478 - val_mDice: 0.5794

Epoch 00060: val_mDice did not improve from 0.62672
Epoch 61/300
 - 21s - loss: 0.2849 - acc: 0.9495 - mDice: 0.7451 - val_loss: 0.9074 - val_acc: 0.9509 - val_mDice: 0.5976

Epoch 00061: val_mDice did not improve from 0.62672
Epoch 62/300
 - 21s - loss: 0.2951 - acc: 0.9489 - mDice: 0.7389 - val_loss: 0.7696 - val_acc: 0.9472 - val_mDice: 0.6183

Epoch 00062: val_mDice did not improve from 0.62672
Epoch 63/300
 - 21s - loss: 0.2614 - acc: 0.9515 - mDice: 0.7614 - val_loss: 0.7826 - val_acc: 0.9489 - val_mDice: 0.6164

Epoch 00063: val_mDice did not improve from 0.62672
Epoch 64/300
 - 22s - loss: 0.2867 - acc: 0.9501 - mDice: 0.7475 - val_loss: 0.8127 - val_acc: 0.9424 - val_mDice: 0.5883

Epoch 00064: val_mDice did not improve from 0.62672
Epoch 65/300
 - 21s - loss: 0.2730 - acc: 0.9508 - mDice: 0.7534 - val_loss: 0.4773 - val_acc: 0.9505 - val_mDice: 0.6263

Epoch 00065: val_mDice did not improve from 0.62672
Epoch 66/300
 - 21s - loss: 0.2700 - acc: 0.9507 - mDice: 0.7545 - val_loss: 0.5234 - val_acc: 0.9499 - val_mDice: 0.6131

Epoch 00066: val_mDice did not improve from 0.62672
Epoch 67/300
 - 21s - loss: 0.2753 - acc: 0.9511 - mDice: 0.7572 - val_loss: 0.4666 - val_acc: 0.9504 - val_mDice: 0.6251

Epoch 00067: val_mDice did not improve from 0.62672
Epoch 68/300
 - 21s - loss: 0.2468 - acc: 0.9524 - mDice: 0.7700 - val_loss: 0.5835 - val_acc: 0.9489 - val_mDice: 0.6223

Epoch 00068: val_mDice did not improve from 0.62672
Epoch 69/300
 - 21s - loss: 0.3019 - acc: 0.9479 - mDice: 0.7334 - val_loss: 0.6725 - val_acc: 0.9499 - val_mDice: 0.6209

Epoch 00069: val_mDice did not improve from 0.62672
Epoch 70/300
 - 22s - loss: 0.2721 - acc: 0.9510 - mDice: 0.7563 - val_loss: 0.7403 - val_acc: 0.9511 - val_mDice: 0.6106

Epoch 00070: val_mDice did not improve from 0.62672
Epoch 71/300
 - 21s - loss: 0.2542 - acc: 0.9520 - mDice: 0.7671 - val_loss: 0.6151 - val_acc: 0.9494 - val_mDice: 0.6159

Epoch 00071: val_mDice did not improve from 0.62672
Epoch 72/300
 - 22s - loss: 0.2602 - acc: 0.9514 - mDice: 0.7609 - val_loss: 0.8967 - val_acc: 0.9508 - val_mDice: 0.5972

Epoch 00072: val_mDice did not improve from 0.62672
Epoch 73/300
 - 22s - loss: 0.3122 - acc: 0.9486 - mDice: 0.7334 - val_loss: 0.4719 - val_acc: 0.9476 - val_mDice: 0.6131

Epoch 00073: val_mDice did not improve from 0.62672
Epoch 74/300
 - 22s - loss: 0.2648 - acc: 0.9517 - mDice: 0.7618 - val_loss: 0.4681 - val_acc: 0.9501 - val_mDice: 0.6194

Epoch 00074: val_mDice did not improve from 0.62672
Epoch 75/300
 - 21s - loss: 0.2716 - acc: 0.9509 - mDice: 0.7538 - val_loss: 0.9452 - val_acc: 0.9457 - val_mDice: 0.6062

Epoch 00075: val_mDice did not improve from 0.62672
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [0.9438928836534003, 0.8509697137760515, 1.0613664366117044, 0.9268900048332054, 1.943963242679083, 0.9719233565470752, 0.7943225690797597, 0.8426011815792372, 0.7937175796813324, 0.8256283199586788, 0.8182072138585964, 0.771628945815463, 0.8120347286472801, 0.6390147459607164, 0.6759382546448908, 0.8316691314973751, 0.8482467532157898, 0.6944353993700332, 0.8563143641007047, 0.9551130838754798, 0.8744223541071435, 0.7658384216933691, 0.7027684477697901, 0.8405506433058185, 0.7264466999458665, 0.783241877535812, 0.8148706835858962, 0.7518373477358778, 0.5812264417900759, 0.6705266199692959, 0.5448105645780804, 0.6993980392688462, 0.991588487845509, 0.6129658389993075, 0.6592478396511879, 0.7957142518848932, 0.8080621684799675, 0.9501914725083263, 0.9760339498019018, 0.7728151386024571, 0.6502376138663092, 0.7063662745371586, 0.6173542447450782, 0.5497506238332316, 0.8278741420817977, 0.7632392098923692, 0.7322828399033106, 0.7192897583757129, 1.4488406541968595, 0.7706039540407037, 0.7407223051335631, 1.187252459405851, 0.53796891454889, 0.5758079085029474, 0.64245125300744, 0.752821074563916, 0.7382255179040572, 0.7321628322120474, 0.5608211014451099, 0.8324839294958515, 0.9074486326269743, 0.7695528664508787, 0.7826448223170113, 0.8127216213390607, 0.4772836525901025, 0.5234324984690722, 0.4665501681195588, 0.5834845424700184, 0.6725493687040666, 0.7402671340132961, 0.615069895481863, 0.8967269654033565, 0.4719224296698049, 0.46808804859634207, 0.94517879000231], 'val_acc': [0.9438395460112756, 0.9483240432098132, 0.9464959071463898, 0.9495731066255009, 0.9172979127459165, 0.9354563976536278, 0.9505645933271456, 0.9483779067752742, 0.9500461195697304, 0.9494232670599673, 0.9413481720355379, 0.9486303990628538, 0.948275210476723, 0.9490495850058163, 0.9440735313070923, 0.9478762675734127, 0.9455953090130782, 0.9467332658647489, 0.9491269994182747, 0.9475884152059796, 0.9461558571382731, 0.9483139494887921, 0.9507868184762842, 0.9478291218020335, 0.948914912568421, 0.9495966699944824, 0.9468393090392361, 0.9505258853695974, 0.9488189475876945, 0.9480833285996894, 0.9473173893800303, 0.9475395844764068, 0.9467568157099876, 0.9495091167818598, 0.9490327369265196, 0.9480092530490971, 0.9477954712234625, 0.9504888323174805, 0.9478291373292939, 0.9485108952562348, 0.9484300848816624, 0.9500494879834792, 0.9444102214164093, 0.9496286416254124, 0.9487246795862663, 0.9509282102103994, 0.9480715363967318, 0.9487297174309482, 0.9480715303861794, 0.9514652054850795, 0.9494249550234369, 0.9505696441946911, 0.947250074198266, 0.9502346540699486, 0.9470783552201856, 0.9479099291713298, 0.9480025227330312, 0.947780313111153, 0.9483189953475439, 0.9478240849591103, 0.9509080102463731, 0.94717766557421, 0.9488644038929659, 0.9423531419088861, 0.9505494417262679, 0.9498845203583982, 0.9504232081044622, 0.9489115336362053, 0.9498845283724681, 0.9511218000860775, 0.9493677285539002, 0.9508087069046598, 0.9475833648393134, 0.950111767324079, 0.9457097739732566], 'val_mDice': [0.5833522401937917, 0.6128692356478266, 0.5255181268483651, 0.559849357905508, 0.44301141084743145, 0.5583200184237055, 0.6134401479689013, 0.612947080315662, 0.6132613555723879, 0.6171641134414352, 0.5760976306530607, 0.6070548691669432, 0.60011273472249, 0.6105039700740525, 0.608644793514444, 0.6034525933385897, 0.5836318721290396, 0.600691838925626, 0.6013160513228729, 0.6067500640364254, 0.613395670882794, 0.6098599679329816, 0.6126920465661698, 0.6126873132561436, 0.60693662056402, 0.6120399732549652, 0.5852050405590474, 0.6137239637495089, 0.6184247171177584, 0.6200546181502462, 0.6144627287608235, 0.6168618377517251, 0.5522879059074306, 0.6171464334015085, 0.6267205216303593, 0.5865916950362069, 0.6100623687776197, 0.6103569719971729, 0.5726111225721215, 0.608293026435275, 0.6021905846956397, 0.6012069067033399, 0.6070036196909031, 0.6228907053210154, 0.6169902481952635, 0.6112243543152048, 0.6049217005737689, 0.6119530356230856, 0.515209484751485, 0.6088527526174273, 0.6066489409999687, 0.5879794935218426, 0.6191988231755104, 0.6163334460819468, 0.6153725400692275, 0.6173123717308044, 0.6199088737744243, 0.6045099276454509, 0.5977246410706464, 0.5794058692555467, 0.5976445955388686, 0.6183294448531976, 0.616402698665106, 0.5882518481807548, 0.6262615313049124, 0.6130583331364543, 0.6250507886670217, 0.6223145813501182, 0.6209119538299176, 0.6105932152571798, 0.6158785915174404, 0.597238582723281, 0.6131102938611969, 0.6193573760385273, 0.6061513098348089], 'loss': [1.1197736251107282, 0.4314240145275307, 0.3822946872162912, 0.3539298865323452, 0.3396310745614028, 0.37536215984366816, 0.3554895476191225, 0.32828072102640315, 0.3308755183713782, 0.3234363948930244, 0.3279158321095458, 0.3112073583454028, 0.32061619176695705, 0.3125410531956453, 0.32666014401055926, 0.35284159019593897, 0.336346729511758, 0.34832522907403096, 0.3115990357834167, 0.3212662099700402, 0.3526940036557237, 0.32411124913122014, 0.296970649851367, 0.3011546646178001, 0.29102251737978824, 0.2938389012187997, 0.3224094721316146, 0.29386674183977507, 0.31962608197758197, 0.28543640329149955, 0.28178966271737715, 0.27076448854008656, 0.27973402401807607, 0.30497354184031594, 0.30784130340687543, 0.2855226562854156, 0.3284798879070133, 0.27656728171507755, 0.2824059426873985, 0.353043834481716, 0.2766696910838829, 0.2734503809914006, 0.31376210274692057, 0.30785188421548865, 0.2655482761980141, 0.27105550318106414, 0.2692082435456313, 0.2765553583436025, 0.2567201143036158, 0.26136800268325533, 0.3063897239628657, 0.30663904524429253, 0.321207582082737, 0.26648713964594267, 0.3362830362406553, 0.2733552026716448, 0.28494342891384766, 0.2810321817864029, 0.2909663431424702, 0.3265204054569919, 0.28492145847358064, 0.29512391427514506, 0.26142762345939885, 0.28673373820795306, 0.2730019662704814, 0.26999920645085085, 0.2752803076462358, 0.24681382912374122, 0.3018788796525501, 0.272116219915094, 0.2542026394732683, 0.2601578617392986, 0.31216118003612736, 0.2647544332486092, 0.2716010771009594], 'acc': [0.853554676550532, 0.9359959909701913, 0.9421751487366039, 0.9439192039764024, 0.9452498716407622, 0.9424513981207038, 0.9428200223216134, 0.9457440170680607, 0.9465248981634442, 0.9466769284258659, 0.9466156126213875, 0.9479235936234713, 0.9474052509292401, 0.9475881189277887, 0.946802016315214, 0.9424342228928975, 0.9450038818402606, 0.9448095634691496, 0.9479209246738506, 0.9474426338852293, 0.9448362647395562, 0.9457178923576238, 0.9486600962246334, 0.9485027976882097, 0.94881570933281, 0.9489497690542937, 0.9476603824288521, 0.9491542391646771, 0.9468159174926286, 0.9497912469228014, 0.9496784761337789, 0.9496903839285973, 0.9502149821222454, 0.9488333180765961, 0.9488724555671484, 0.950231604928979, 0.9457176513265325, 0.9499607175293359, 0.9498647611193455, 0.943973256442254, 0.9498713762149622, 0.9506737648349236, 0.9473449673533834, 0.9467292731139654, 0.9507619517052077, 0.9511324033047193, 0.951240772941169, 0.9505061713899803, 0.9519053485722057, 0.9512564799013312, 0.9483843262007343, 0.9472555550717262, 0.9451140792152968, 0.9506788408924459, 0.9458933016696301, 0.9503286188338047, 0.9491910928006432, 0.9504484638764099, 0.9488028380757014, 0.9460534628752437, 0.949497701025911, 0.9489257135072008, 0.9514831550591559, 0.9500889341167701, 0.9507583668732278, 0.9506575757946849, 0.9510883829393962, 0.9524197218046644, 0.9478669670278767, 0.9509561028934319, 0.9520174689709479, 0.9513687927133863, 0.948632215315499, 0.9517095127967484, 0.9508918987598837], 'mDice': [0.44893302134353097, 0.6428123646242703, 0.6769930965207569, 0.6932810287205745, 0.7038709437371159, 0.6834070134971708, 0.6928974623008735, 0.7111716286372365, 0.7145520421038587, 0.7165557495719569, 0.7147903876668231, 0.726736973316882, 0.7244475388161881, 0.7242561013302764, 0.7173639863183713, 0.6999497202576477, 0.7083169831344939, 0.702938989847138, 0.7296524744551306, 0.7239353827476788, 0.701466044177883, 0.7175416084908394, 0.7352471116139558, 0.7335685941772896, 0.7373457017763712, 0.7385139969224795, 0.7261666339354914, 0.7382789710125598, 0.7221869660261263, 0.7444045744082549, 0.744947819515092, 0.7513608686990546, 0.748595273045583, 0.7362386852690709, 0.7354647081129474, 0.7491885779391392, 0.7144273016160044, 0.7476717694068378, 0.7478233873575738, 0.7002072122962365, 0.7467526141425505, 0.7539035473561294, 0.7273939135678714, 0.7264177707876396, 0.755101296465807, 0.7570280008704696, 0.7589635421334355, 0.7521377247899403, 0.7665323299962241, 0.7614160906584977, 0.7343825065617231, 0.7264281858627734, 0.7159608035644445, 0.7551375163170497, 0.7128123139447544, 0.7519708690933907, 0.7430589745546454, 0.7527451571921477, 0.7391239168120733, 0.7196333244447414, 0.74511124040228, 0.7388861999609062, 0.7614304757411685, 0.7474523122712894, 0.7534320318494893, 0.7544858888332925, 0.7572289065568879, 0.7700133464315638, 0.7333667752657592, 0.7562792181646598, 0.7671061760668495, 0.7608600069330606, 0.73340382269287, 0.7618317398821688, 0.75378733477017]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:10,  3.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:05<00:06,  3.12s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:08<00:02,  2.97s/it]predicting test subjects: 100%|██████████| 4/4 [00:11<00:00,  2.89s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<14:58,  3.39s/it]predicting train subjects:   1%|          | 2/266 [00:06<14:29,  3.29s/it]predicting train subjects:   1%|          | 3/266 [00:09<13:46,  3.14s/it]predicting train subjects:   2%|▏         | 4/266 [00:11<13:08,  3.01s/it]predicting train subjects:   2%|▏         | 5/266 [00:14<13:08,  3.02s/it]predicting train subjects:   2%|▏         | 6/266 [00:18<13:28,  3.11s/it]predicting train subjects:   3%|▎         | 7/266 [00:21<13:33,  3.14s/it]predicting train subjects:   3%|▎         | 8/266 [00:24<13:28,  3.13s/it]predicting train subjects:   3%|▎         | 9/266 [00:28<13:50,  3.23s/it]predicting train subjects:   4%|▍         | 10/266 [00:31<13:55,  3.26s/it]predicting train subjects:   4%|▍         | 11/266 [00:34<13:49,  3.25s/it]predicting train subjects:   5%|▍         | 12/266 [00:37<13:50,  3.27s/it]predicting train subjects:   5%|▍         | 13/266 [00:41<13:52,  3.29s/it]predicting train subjects:   5%|▌         | 14/266 [00:44<13:52,  3.30s/it]predicting train subjects:   6%|▌         | 15/266 [00:47<13:42,  3.28s/it]predicting train subjects:   6%|▌         | 16/266 [00:51<13:43,  3.29s/it]predicting train subjects:   6%|▋         | 17/266 [00:54<13:32,  3.26s/it]predicting train subjects:   7%|▋         | 18/266 [00:57<13:23,  3.24s/it]predicting train subjects:   7%|▋         | 19/266 [01:01<13:48,  3.35s/it]predicting train subjects:   8%|▊         | 20/266 [01:04<14:00,  3.42s/it]predicting train subjects:   8%|▊         | 21/266 [01:08<14:10,  3.47s/it]predicting train subjects:   8%|▊         | 22/266 [01:11<13:59,  3.44s/it]predicting train subjects:   9%|▊         | 23/266 [01:15<13:48,  3.41s/it]predicting train subjects:   9%|▉         | 24/266 [01:18<13:28,  3.34s/it]predicting train subjects:   9%|▉         | 25/266 [01:21<12:58,  3.23s/it]predicting train subjects:  10%|▉         | 26/266 [01:24<12:45,  3.19s/it]predicting train subjects:  10%|█         | 27/266 [01:27<12:39,  3.18s/it]predicting train subjects:  11%|█         | 28/266 [01:30<12:37,  3.18s/it]predicting train subjects:  11%|█         | 29/266 [01:33<12:16,  3.11s/it]predicting train subjects:  11%|█▏        | 30/266 [01:36<12:30,  3.18s/it]predicting train subjects:  12%|█▏        | 31/266 [01:40<12:22,  3.16s/it]predicting train subjects:  12%|█▏        | 32/266 [01:42<12:04,  3.10s/it]predicting train subjects:  12%|█▏        | 33/266 [01:46<12:18,  3.17s/it]predicting train subjects:  13%|█▎        | 34/266 [01:49<11:59,  3.10s/it]predicting train subjects:  13%|█▎        | 35/266 [01:52<11:59,  3.11s/it]predicting train subjects:  14%|█▎        | 36/266 [01:55<11:30,  3.00s/it]predicting train subjects:  14%|█▍        | 37/266 [01:58<11:31,  3.02s/it]predicting train subjects:  14%|█▍        | 38/266 [02:01<11:49,  3.11s/it]predicting train subjects:  15%|█▍        | 39/266 [02:04<11:47,  3.12s/it]predicting train subjects:  15%|█▌        | 40/266 [02:07<11:37,  3.08s/it]predicting train subjects:  15%|█▌        | 41/266 [02:10<11:41,  3.12s/it]predicting train subjects:  16%|█▌        | 42/266 [02:13<11:30,  3.08s/it]predicting train subjects:  16%|█▌        | 43/266 [02:16<10:49,  2.91s/it]predicting train subjects:  17%|█▋        | 44/266 [02:18<10:22,  2.81s/it]predicting train subjects:  17%|█▋        | 45/266 [02:21<10:16,  2.79s/it]predicting train subjects:  17%|█▋        | 46/266 [02:24<10:25,  2.84s/it]predicting train subjects:  18%|█▊        | 47/266 [02:27<10:08,  2.78s/it]predicting train subjects:  18%|█▊        | 48/266 [02:29<09:31,  2.62s/it]predicting train subjects:  18%|█▊        | 49/266 [02:32<09:50,  2.72s/it]predicting train subjects:  19%|█▉        | 50/266 [02:35<09:37,  2.67s/it]predicting train subjects:  19%|█▉        | 51/266 [02:37<09:27,  2.64s/it]predicting train subjects:  20%|█▉        | 52/266 [02:39<09:06,  2.55s/it]predicting train subjects:  20%|█▉        | 53/266 [02:42<09:03,  2.55s/it]predicting train subjects:  20%|██        | 54/266 [02:44<08:37,  2.44s/it]predicting train subjects:  21%|██        | 55/266 [02:46<08:19,  2.37s/it]predicting train subjects:  21%|██        | 56/266 [02:49<08:08,  2.33s/it]predicting train subjects:  21%|██▏       | 57/266 [02:51<08:03,  2.31s/it]predicting train subjects:  22%|██▏       | 58/266 [02:53<07:56,  2.29s/it]predicting train subjects:  22%|██▏       | 59/266 [02:55<07:53,  2.29s/it]predicting train subjects:  23%|██▎       | 60/266 [02:58<07:37,  2.22s/it]predicting train subjects:  23%|██▎       | 61/266 [03:00<07:22,  2.16s/it]predicting train subjects:  23%|██▎       | 62/266 [03:01<07:08,  2.10s/it]predicting train subjects:  24%|██▎       | 63/266 [03:03<06:59,  2.07s/it]predicting train subjects:  24%|██▍       | 64/266 [03:05<06:50,  2.03s/it]predicting train subjects:  24%|██▍       | 65/266 [03:07<06:49,  2.04s/it]predicting train subjects:  25%|██▍       | 66/266 [03:10<06:48,  2.04s/it]predicting train subjects:  25%|██▌       | 67/266 [03:12<06:52,  2.07s/it]predicting train subjects:  26%|██▌       | 68/266 [03:14<06:48,  2.07s/it]predicting train subjects:  26%|██▌       | 69/266 [03:16<06:59,  2.13s/it]predicting train subjects:  26%|██▋       | 70/266 [03:18<06:53,  2.11s/it]predicting train subjects:  27%|██▋       | 71/266 [03:20<06:47,  2.09s/it]predicting train subjects:  27%|██▋       | 72/266 [03:22<06:46,  2.10s/it]predicting train subjects:  27%|██▋       | 73/266 [03:24<06:41,  2.08s/it]predicting train subjects:  28%|██▊       | 74/266 [03:26<06:36,  2.06s/it]predicting train subjects:  28%|██▊       | 75/266 [03:28<06:34,  2.07s/it]predicting train subjects:  29%|██▊       | 76/266 [03:30<06:29,  2.05s/it]predicting train subjects:  29%|██▉       | 77/266 [03:32<06:27,  2.05s/it]predicting train subjects:  29%|██▉       | 78/266 [03:35<06:58,  2.22s/it]predicting train subjects:  30%|██▉       | 79/266 [03:38<07:13,  2.32s/it]predicting train subjects:  30%|███       | 80/266 [03:40<07:34,  2.44s/it]predicting train subjects:  30%|███       | 81/266 [03:43<07:36,  2.47s/it]predicting train subjects:  31%|███       | 82/266 [03:45<07:40,  2.51s/it]predicting train subjects:  31%|███       | 83/266 [03:48<07:41,  2.52s/it]predicting train subjects:  32%|███▏      | 84/266 [03:50<07:38,  2.52s/it]predicting train subjects:  32%|███▏      | 85/266 [03:53<07:36,  2.52s/it]predicting train subjects:  32%|███▏      | 86/266 [03:56<07:35,  2.53s/it]predicting train subjects:  33%|███▎      | 87/266 [03:58<07:47,  2.61s/it]predicting train subjects:  33%|███▎      | 88/266 [04:01<07:43,  2.60s/it]predicting train subjects:  33%|███▎      | 89/266 [04:04<07:40,  2.60s/it]predicting train subjects:  34%|███▍      | 90/266 [04:06<07:51,  2.68s/it]predicting train subjects:  34%|███▍      | 91/266 [04:09<07:45,  2.66s/it]predicting train subjects:  35%|███▍      | 92/266 [04:12<07:37,  2.63s/it]predicting train subjects:  35%|███▍      | 93/266 [04:14<07:35,  2.63s/it]predicting train subjects:  35%|███▌      | 94/266 [04:17<07:32,  2.63s/it]predicting train subjects:  36%|███▌      | 95/266 [04:20<07:38,  2.68s/it]predicting train subjects:  36%|███▌      | 96/266 [04:22<07:20,  2.59s/it]predicting train subjects:  36%|███▋      | 97/266 [04:25<07:20,  2.61s/it]predicting train subjects:  37%|███▋      | 98/266 [04:27<07:15,  2.59s/it]predicting train subjects:  37%|███▋      | 99/266 [04:29<06:44,  2.42s/it]predicting train subjects:  38%|███▊      | 100/266 [04:31<06:27,  2.33s/it]predicting train subjects:  38%|███▊      | 101/266 [04:34<06:24,  2.33s/it]predicting train subjects:  38%|███▊      | 102/266 [04:36<06:20,  2.32s/it]predicting train subjects:  39%|███▊      | 103/266 [04:38<06:25,  2.37s/it]predicting train subjects:  39%|███▉      | 104/266 [04:41<06:18,  2.34s/it]predicting train subjects:  39%|███▉      | 105/266 [04:43<06:19,  2.36s/it]predicting train subjects:  40%|███▉      | 106/266 [04:45<06:12,  2.33s/it]predicting train subjects:  40%|████      | 107/266 [04:48<06:09,  2.32s/it]predicting train subjects:  41%|████      | 108/266 [04:50<06:06,  2.32s/it]predicting train subjects:  41%|████      | 109/266 [04:52<06:03,  2.32s/it]predicting train subjects:  41%|████▏     | 110/266 [04:55<06:12,  2.39s/it]predicting train subjects:  42%|████▏     | 111/266 [04:57<06:12,  2.40s/it]predicting train subjects:  42%|████▏     | 112/266 [05:00<06:03,  2.36s/it]predicting train subjects:  42%|████▏     | 113/266 [05:02<05:59,  2.35s/it]predicting train subjects:  43%|████▎     | 114/266 [05:04<05:53,  2.33s/it]predicting train subjects:  43%|████▎     | 115/266 [05:06<05:49,  2.31s/it]predicting train subjects:  44%|████▎     | 116/266 [05:09<05:52,  2.35s/it]predicting train subjects:  44%|████▍     | 117/266 [05:11<05:49,  2.35s/it]predicting train subjects:  44%|████▍     | 118/266 [05:14<05:46,  2.34s/it]predicting train subjects:  45%|████▍     | 119/266 [05:16<06:07,  2.50s/it]predicting train subjects:  45%|████▌     | 120/266 [05:19<06:17,  2.59s/it]predicting train subjects:  45%|████▌     | 121/266 [05:22<06:15,  2.59s/it]predicting train subjects:  46%|████▌     | 122/266 [05:24<06:13,  2.59s/it]predicting train subjects:  46%|████▌     | 123/266 [05:27<06:13,  2.61s/it]predicting train subjects:  47%|████▋     | 124/266 [05:30<06:13,  2.63s/it]predicting train subjects:  47%|████▋     | 125/266 [05:32<06:09,  2.62s/it]predicting train subjects:  47%|████▋     | 126/266 [05:35<06:05,  2.61s/it]predicting train subjects:  48%|████▊     | 127/266 [05:38<06:07,  2.64s/it]predicting train subjects:  48%|████▊     | 128/266 [05:40<06:01,  2.62s/it]predicting train subjects:  48%|████▊     | 129/266 [05:43<05:58,  2.61s/it]predicting train subjects:  49%|████▉     | 130/266 [05:46<05:57,  2.63s/it]predicting train subjects:  49%|████▉     | 131/266 [05:48<05:53,  2.62s/it]predicting train subjects:  50%|████▉     | 132/266 [05:51<05:49,  2.61s/it]predicting train subjects:  50%|█████     | 133/266 [05:53<05:46,  2.60s/it]predicting train subjects:  50%|█████     | 134/266 [05:56<05:43,  2.60s/it]predicting train subjects:  51%|█████     | 135/266 [05:58<05:39,  2.59s/it]predicting train subjects:  51%|█████     | 136/266 [06:01<05:41,  2.62s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:04<05:39,  2.63s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:06<05:32,  2.60s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:09<05:26,  2.57s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:11<05:20,  2.55s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:14<05:19,  2.55s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:16<05:15,  2.54s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:19<05:10,  2.52s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:21<05:10,  2.54s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:24<05:05,  2.52s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:26<05:01,  2.52s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:29<04:57,  2.50s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:31<04:55,  2.51s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:34<04:57,  2.54s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:36<04:51,  2.51s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:39<04:51,  2.53s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:42<04:46,  2.51s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:44<04:42,  2.50s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:47<04:40,  2.50s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:48<04:17,  2.32s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:50<04:01,  2.20s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:52<03:51,  2.12s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:54<03:45,  2.09s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:56<03:36,  2.03s/it]predicting train subjects:  60%|██████    | 160/266 [06:58<03:33,  2.01s/it]predicting train subjects:  61%|██████    | 161/266 [07:00<03:29,  1.99s/it]predicting train subjects:  61%|██████    | 162/266 [07:02<03:26,  1.99s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:04<03:23,  1.98s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:06<03:20,  1.97s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:08<03:17,  1.95s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:10<03:14,  1.94s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:12<03:13,  1.95s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:14<03:12,  1.97s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:16<03:11,  1.98s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:18<03:08,  1.96s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:20<03:05,  1.95s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:22<03:03,  1.95s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:24<03:05,  2.00s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:26<03:06,  2.03s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:28<03:09,  2.09s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:30<03:08,  2.10s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:32<03:06,  2.09s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:34<03:05,  2.10s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:36<03:01,  2.09s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:39<03:01,  2.11s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:41<03:00,  2.12s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:43<02:56,  2.11s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:45<02:54,  2.11s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:47<02:51,  2.09s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:49<02:47,  2.07s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:51<02:45,  2.07s/it]predicting train subjects:  70%|███████   | 187/266 [07:53<02:46,  2.10s/it]predicting train subjects:  71%|███████   | 188/266 [07:55<02:45,  2.12s/it]predicting train subjects:  71%|███████   | 189/266 [07:58<02:43,  2.13s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:00<02:40,  2.12s/it]predicting train subjects:  72%|███████▏  | 191/266 [08:02<02:40,  2.15s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:04<02:37,  2.12s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:06<02:34,  2.11s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:09<02:45,  2.30s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:11<02:43,  2.30s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:13<02:39,  2.28s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:16<02:36,  2.28s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:18<02:34,  2.27s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:20<02:31,  2.27s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:22<02:29,  2.27s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:25<02:27,  2.27s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:27<02:25,  2.27s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:29<02:23,  2.28s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:31<02:20,  2.27s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:34<02:16,  2.24s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:36<02:14,  2.24s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:38<02:14,  2.28s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:40<02:11,  2.26s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:43<02:08,  2.25s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:45<02:05,  2.25s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:47<02:02,  2.24s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:49<02:00,  2.23s/it]predicting train subjects:  80%|████████  | 213/266 [08:51<01:53,  2.14s/it]predicting train subjects:  80%|████████  | 214/266 [08:53<01:48,  2.09s/it]predicting train subjects:  81%|████████  | 215/266 [08:55<01:44,  2.05s/it]predicting train subjects:  81%|████████  | 216/266 [08:57<01:41,  2.03s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:59<01:38,  2.00s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:01<01:35,  2.00s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:03<01:34,  2.01s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:05<01:32,  2.00s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:07<01:29,  1.99s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:09<01:28,  2.00s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:11<01:25,  1.98s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:13<01:24,  2.00s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:15<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:17<01:20,  2.01s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:19<01:18,  2.00s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:21<01:16,  2.02s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:23<01:13,  1.99s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:25<01:11,  1.98s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:27<01:09,  1.99s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:29<01:07,  1.99s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:31<01:05,  2.00s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:33<01:04,  2.02s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:35<01:02,  2.02s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:37<01:00,  2.02s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:39<00:58,  2.03s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:41<00:57,  2.04s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:43<00:55,  2.04s/it]predicting train subjects:  90%|█████████ | 240/266 [09:45<00:53,  2.05s/it]predicting train subjects:  91%|█████████ | 241/266 [09:47<00:50,  2.04s/it]predicting train subjects:  91%|█████████ | 242/266 [09:49<00:48,  2.02s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:51<00:46,  2.01s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:53<00:44,  2.01s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:55<00:41,  2.00s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:57<00:40,  2.02s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:59<00:38,  2.01s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:01<00:36,  2.00s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:04<00:37,  2.20s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:07<00:36,  2.30s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:09<00:35,  2.38s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:12<00:34,  2.44s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:14<00:32,  2.47s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:17<00:29,  2.49s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:19<00:27,  2.51s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:22<00:25,  2.52s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:25<00:23,  2.56s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:27<00:20,  2.58s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:30<00:18,  2.58s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:32<00:15,  2.59s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:35<00:13,  2.63s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:38<00:10,  2.63s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:40<00:07,  2.64s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:43<00:05,  2.64s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:46<00:02,  2.65s/it]predicting train subjects: 100%|██████████| 266/266 [10:48<00:00,  2.64s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:48,  1.77s/it]Loading train:   1%|          | 2/266 [00:03<07:36,  1.73s/it]Loading train:   1%|          | 3/266 [00:04<06:55,  1.58s/it]Loading train:   2%|▏         | 4/266 [00:05<06:27,  1.48s/it]Loading train:   2%|▏         | 5/266 [00:07<06:28,  1.49s/it]Loading train:   2%|▏         | 6/266 [00:08<05:41,  1.31s/it]Loading train:   3%|▎         | 7/266 [00:09<05:12,  1.20s/it]Loading train:   3%|▎         | 8/266 [00:10<04:57,  1.15s/it]Loading train:   3%|▎         | 9/266 [00:11<04:51,  1.13s/it]Loading train:   4%|▍         | 10/266 [00:12<04:33,  1.07s/it]Loading train:   4%|▍         | 11/266 [00:13<04:23,  1.03s/it]Loading train:   5%|▍         | 12/266 [00:14<04:27,  1.05s/it]Loading train:   5%|▍         | 13/266 [00:15<04:24,  1.04s/it]Loading train:   5%|▌         | 14/266 [00:16<04:21,  1.04s/it]Loading train:   6%|▌         | 15/266 [00:17<04:20,  1.04s/it]Loading train:   6%|▌         | 16/266 [00:18<04:22,  1.05s/it]Loading train:   6%|▋         | 17/266 [00:19<04:22,  1.06s/it]Loading train:   7%|▋         | 18/266 [00:20<04:20,  1.05s/it]Loading train:   7%|▋         | 19/266 [00:21<04:15,  1.03s/it]Loading train:   8%|▊         | 20/266 [00:22<04:10,  1.02s/it]Loading train:   8%|▊         | 21/266 [00:23<04:08,  1.01s/it]Loading train:   8%|▊         | 22/266 [00:24<04:07,  1.01s/it]Loading train:   9%|▊         | 23/266 [00:25<04:00,  1.01it/s]Loading train:   9%|▉         | 24/266 [00:26<03:50,  1.05it/s]Loading train:   9%|▉         | 25/266 [00:27<03:38,  1.10it/s]Loading train:  10%|▉         | 26/266 [00:28<03:39,  1.09it/s]Loading train:  10%|█         | 27/266 [00:29<03:44,  1.07it/s]Loading train:  11%|█         | 28/266 [00:29<03:38,  1.09it/s]Loading train:  11%|█         | 29/266 [00:30<03:37,  1.09it/s]Loading train:  11%|█▏        | 30/266 [00:31<03:33,  1.11it/s]Loading train:  12%|█▏        | 31/266 [00:32<03:32,  1.11it/s]Loading train:  12%|█▏        | 32/266 [00:33<03:30,  1.11it/s]Loading train:  12%|█▏        | 33/266 [00:34<03:32,  1.09it/s]Loading train:  13%|█▎        | 34/266 [00:35<03:34,  1.08it/s]Loading train:  13%|█▎        | 35/266 [00:36<03:35,  1.07it/s]Loading train:  14%|█▎        | 36/266 [00:37<03:34,  1.07it/s]Loading train:  14%|█▍        | 37/266 [00:38<03:31,  1.08it/s]Loading train:  14%|█▍        | 38/266 [00:39<03:22,  1.12it/s]Loading train:  15%|█▍        | 39/266 [00:39<03:19,  1.14it/s]Loading train:  15%|█▌        | 40/266 [00:40<03:21,  1.12it/s]Loading train:  15%|█▌        | 41/266 [00:41<03:20,  1.12it/s]Loading train:  16%|█▌        | 42/266 [00:42<03:16,  1.14it/s]Loading train:  16%|█▌        | 43/266 [00:43<03:04,  1.21it/s]Loading train:  17%|█▋        | 44/266 [00:44<03:01,  1.22it/s]Loading train:  17%|█▋        | 45/266 [00:44<03:01,  1.22it/s]Loading train:  17%|█▋        | 46/266 [00:45<02:55,  1.26it/s]Loading train:  18%|█▊        | 47/266 [00:46<02:50,  1.29it/s]Loading train:  18%|█▊        | 48/266 [00:47<02:52,  1.26it/s]Loading train:  18%|█▊        | 49/266 [00:47<02:50,  1.27it/s]Loading train:  19%|█▉        | 50/266 [00:48<02:55,  1.23it/s]Loading train:  19%|█▉        | 51/266 [00:49<02:55,  1.22it/s]Loading train:  20%|█▉        | 52/266 [00:50<02:51,  1.25it/s]Loading train:  20%|█▉        | 53/266 [00:51<02:51,  1.24it/s]Loading train:  20%|██        | 54/266 [00:52<02:52,  1.23it/s]Loading train:  21%|██        | 55/266 [00:52<02:50,  1.23it/s]Loading train:  21%|██        | 56/266 [00:53<02:45,  1.27it/s]Loading train:  21%|██▏       | 57/266 [00:54<02:42,  1.29it/s]Loading train:  22%|██▏       | 58/266 [00:55<02:38,  1.31it/s]Loading train:  22%|██▏       | 59/266 [00:55<02:39,  1.30it/s]Loading train:  23%|██▎       | 60/266 [00:56<02:40,  1.28it/s]Loading train:  23%|██▎       | 61/266 [00:57<02:38,  1.29it/s]Loading train:  23%|██▎       | 62/266 [00:58<02:36,  1.30it/s]Loading train:  24%|██▎       | 63/266 [00:58<02:31,  1.34it/s]Loading train:  24%|██▍       | 64/266 [00:59<02:30,  1.35it/s]Loading train:  24%|██▍       | 65/266 [01:00<02:32,  1.31it/s]Loading train:  25%|██▍       | 66/266 [01:01<02:35,  1.28it/s]Loading train:  25%|██▌       | 67/266 [01:02<02:32,  1.30it/s]Loading train:  26%|██▌       | 68/266 [01:02<02:35,  1.28it/s]Loading train:  26%|██▌       | 69/266 [01:03<02:30,  1.31it/s]Loading train:  26%|██▋       | 70/266 [01:04<02:28,  1.32it/s]Loading train:  27%|██▋       | 71/266 [01:05<02:27,  1.32it/s]Loading train:  27%|██▋       | 72/266 [01:05<02:22,  1.36it/s]Loading train:  27%|██▋       | 73/266 [01:06<02:19,  1.38it/s]Loading train:  28%|██▊       | 74/266 [01:07<02:22,  1.34it/s]Loading train:  28%|██▊       | 75/266 [01:07<02:17,  1.38it/s]Loading train:  29%|██▊       | 76/266 [01:08<02:13,  1.42it/s]Loading train:  29%|██▉       | 77/266 [01:09<02:13,  1.41it/s]Loading train:  29%|██▉       | 78/266 [01:10<02:39,  1.18it/s]Loading train:  30%|██▉       | 79/266 [01:11<02:48,  1.11it/s]Loading train:  30%|███       | 80/266 [01:12<02:51,  1.09it/s]Loading train:  30%|███       | 81/266 [01:13<02:48,  1.09it/s]Loading train:  31%|███       | 82/266 [01:14<02:46,  1.10it/s]Loading train:  31%|███       | 83/266 [01:15<02:48,  1.09it/s]Loading train:  32%|███▏      | 84/266 [01:16<02:53,  1.05it/s]Loading train:  32%|███▏      | 85/266 [01:17<02:56,  1.02it/s]Loading train:  32%|███▏      | 86/266 [01:18<02:56,  1.02it/s]Loading train:  33%|███▎      | 87/266 [01:19<02:51,  1.04it/s]Loading train:  33%|███▎      | 88/266 [01:19<02:45,  1.08it/s]Loading train:  33%|███▎      | 89/266 [01:20<02:41,  1.10it/s]Loading train:  34%|███▍      | 90/266 [01:21<02:42,  1.09it/s]Loading train:  34%|███▍      | 91/266 [01:22<02:44,  1.07it/s]Loading train:  35%|███▍      | 92/266 [01:23<02:47,  1.04it/s]Loading train:  35%|███▍      | 93/266 [01:24<02:46,  1.04it/s]Loading train:  35%|███▌      | 94/266 [01:25<02:46,  1.03it/s]Loading train:  36%|███▌      | 95/266 [01:26<02:43,  1.05it/s]Loading train:  36%|███▌      | 96/266 [01:28<03:01,  1.07s/it]Loading train:  36%|███▋      | 97/266 [01:29<03:15,  1.15s/it]Loading train:  37%|███▋      | 98/266 [01:30<03:25,  1.22s/it]Loading train:  37%|███▋      | 99/266 [01:31<03:16,  1.18s/it]Loading train:  38%|███▊      | 100/266 [01:32<03:11,  1.16s/it]Loading train:  38%|███▊      | 101/266 [01:33<03:01,  1.10s/it]Loading train:  38%|███▊      | 102/266 [01:34<02:46,  1.01s/it]Loading train:  39%|███▊      | 103/266 [01:35<02:29,  1.09it/s]Loading train:  39%|███▉      | 104/266 [01:36<02:19,  1.16it/s]Loading train:  39%|███▉      | 105/266 [01:36<02:11,  1.22it/s]Loading train:  40%|███▉      | 106/266 [01:37<02:06,  1.27it/s]Loading train:  40%|████      | 107/266 [01:38<02:04,  1.28it/s]Loading train:  41%|████      | 108/266 [01:39<02:03,  1.28it/s]Loading train:  41%|████      | 109/266 [01:39<02:02,  1.28it/s]Loading train:  41%|████▏     | 110/266 [01:40<02:01,  1.28it/s]Loading train:  42%|████▏     | 111/266 [01:41<02:02,  1.27it/s]Loading train:  42%|████▏     | 112/266 [01:42<02:00,  1.27it/s]Loading train:  42%|████▏     | 113/266 [01:43<01:58,  1.29it/s]Loading train:  43%|████▎     | 114/266 [01:43<01:56,  1.31it/s]Loading train:  43%|████▎     | 115/266 [01:44<01:55,  1.31it/s]Loading train:  44%|████▎     | 116/266 [01:45<01:52,  1.33it/s]Loading train:  44%|████▍     | 117/266 [01:46<01:54,  1.30it/s]Loading train:  44%|████▍     | 118/266 [01:46<01:53,  1.30it/s]Loading train:  45%|████▍     | 119/266 [01:47<01:58,  1.24it/s]Loading train:  45%|████▌     | 120/266 [01:48<01:57,  1.25it/s]Loading train:  45%|████▌     | 121/266 [01:49<01:58,  1.23it/s]Loading train:  46%|████▌     | 122/266 [01:50<01:57,  1.23it/s]Loading train:  46%|████▌     | 123/266 [01:50<01:56,  1.22it/s]Loading train:  47%|████▋     | 124/266 [01:51<01:59,  1.19it/s]Loading train:  47%|████▋     | 125/266 [01:52<02:01,  1.16it/s]Loading train:  47%|████▋     | 126/266 [01:53<02:03,  1.14it/s]Loading train:  48%|████▊     | 127/266 [01:54<02:02,  1.13it/s]Loading train:  48%|████▊     | 128/266 [01:55<02:04,  1.11it/s]Loading train:  48%|████▊     | 129/266 [01:56<02:04,  1.10it/s]Loading train:  49%|████▉     | 130/266 [01:57<02:03,  1.10it/s]Loading train:  49%|████▉     | 131/266 [01:58<02:05,  1.08it/s]Loading train:  50%|████▉     | 132/266 [01:59<02:04,  1.08it/s]Loading train:  50%|█████     | 133/266 [02:00<02:02,  1.09it/s]Loading train:  50%|█████     | 134/266 [02:01<02:00,  1.09it/s]Loading train:  51%|█████     | 135/266 [02:02<02:02,  1.07it/s]Loading train:  51%|█████     | 136/266 [02:02<02:00,  1.08it/s]Loading train:  52%|█████▏    | 137/266 [02:03<02:02,  1.06it/s]Loading train:  52%|█████▏    | 138/266 [02:04<01:58,  1.08it/s]Loading train:  52%|█████▏    | 139/266 [02:05<01:56,  1.09it/s]Loading train:  53%|█████▎    | 140/266 [02:06<01:54,  1.10it/s]Loading train:  53%|█████▎    | 141/266 [02:07<01:55,  1.09it/s]Loading train:  53%|█████▎    | 142/266 [02:08<01:57,  1.06it/s]Loading train:  54%|█████▍    | 143/266 [02:09<01:54,  1.08it/s]Loading train:  54%|█████▍    | 144/266 [02:10<01:53,  1.07it/s]Loading train:  55%|█████▍    | 145/266 [02:11<01:53,  1.07it/s]Loading train:  55%|█████▍    | 146/266 [02:12<01:54,  1.05it/s]Loading train:  55%|█████▌    | 147/266 [02:13<01:59,  1.00s/it]Loading train:  56%|█████▌    | 148/266 [02:14<02:12,  1.13s/it]Loading train:  56%|█████▌    | 149/266 [02:16<02:20,  1.20s/it]Loading train:  56%|█████▋    | 150/266 [02:17<02:13,  1.15s/it]Loading train:  57%|█████▋    | 151/266 [02:18<02:12,  1.15s/it]Loading train:  57%|█████▋    | 152/266 [02:19<02:09,  1.13s/it]Loading train:  58%|█████▊    | 153/266 [02:20<02:06,  1.12s/it]Loading train:  58%|█████▊    | 154/266 [02:21<02:02,  1.10s/it]Loading train:  58%|█████▊    | 155/266 [02:22<01:57,  1.06s/it]Loading train:  59%|█████▊    | 156/266 [02:23<01:52,  1.02s/it]Loading train:  59%|█████▉    | 157/266 [02:24<01:51,  1.02s/it]Loading train:  59%|█████▉    | 158/266 [02:25<01:45,  1.02it/s]Loading train:  60%|█████▉    | 159/266 [02:26<01:39,  1.08it/s]Loading train:  60%|██████    | 160/266 [02:27<01:37,  1.09it/s]Loading train:  61%|██████    | 161/266 [02:28<01:35,  1.10it/s]Loading train:  61%|██████    | 162/266 [02:28<01:35,  1.09it/s]Loading train:  61%|██████▏   | 163/266 [02:29<01:31,  1.12it/s]Loading train:  62%|██████▏   | 164/266 [02:30<01:32,  1.11it/s]Loading train:  62%|██████▏   | 165/266 [02:31<01:39,  1.02it/s]Loading train:  62%|██████▏   | 166/266 [02:32<01:38,  1.02it/s]Loading train:  63%|██████▎   | 167/266 [02:33<01:34,  1.05it/s]Loading train:  63%|██████▎   | 168/266 [02:34<01:35,  1.02it/s]Loading train:  64%|██████▎   | 169/266 [02:35<01:32,  1.05it/s]Loading train:  64%|██████▍   | 170/266 [02:36<01:27,  1.10it/s]Loading train:  64%|██████▍   | 171/266 [02:37<01:26,  1.10it/s]Loading train:  65%|██████▍   | 172/266 [02:38<01:26,  1.09it/s]Loading train:  65%|██████▌   | 173/266 [02:39<01:27,  1.06it/s]Loading train:  65%|██████▌   | 174/266 [02:40<01:25,  1.08it/s]Loading train:  66%|██████▌   | 175/266 [02:41<01:27,  1.05it/s]Loading train:  66%|██████▌   | 176/266 [02:42<01:24,  1.07it/s]Loading train:  67%|██████▋   | 177/266 [02:43<01:26,  1.03it/s]Loading train:  67%|██████▋   | 178/266 [02:44<01:25,  1.03it/s]Loading train:  67%|██████▋   | 179/266 [02:45<01:23,  1.04it/s]Loading train:  68%|██████▊   | 180/266 [02:46<01:23,  1.03it/s]Loading train:  68%|██████▊   | 181/266 [02:47<01:25,  1.01s/it]Loading train:  68%|██████▊   | 182/266 [02:48<01:26,  1.03s/it]Loading train:  69%|██████▉   | 183/266 [02:49<01:22,  1.00it/s]Loading train:  69%|██████▉   | 184/266 [02:50<01:20,  1.02it/s]Loading train:  70%|██████▉   | 185/266 [02:51<01:16,  1.06it/s]Loading train:  70%|██████▉   | 186/266 [02:51<01:15,  1.05it/s]Loading train:  70%|███████   | 187/266 [02:52<01:12,  1.09it/s]Loading train:  71%|███████   | 188/266 [02:53<01:15,  1.04it/s]Loading train:  71%|███████   | 189/266 [02:54<01:12,  1.06it/s]Loading train:  71%|███████▏  | 190/266 [02:56<01:20,  1.06s/it]Loading train:  72%|███████▏  | 191/266 [02:57<01:31,  1.23s/it]Loading train:  72%|███████▏  | 192/266 [02:58<01:31,  1.24s/it]Loading train:  73%|███████▎  | 193/266 [03:00<01:31,  1.25s/it]Loading train:  73%|███████▎  | 194/266 [03:01<01:39,  1.38s/it]Loading train:  73%|███████▎  | 195/266 [03:02<01:29,  1.27s/it]Loading train:  74%|███████▎  | 196/266 [03:03<01:21,  1.17s/it]Loading train:  74%|███████▍  | 197/266 [03:05<01:19,  1.15s/it]Loading train:  74%|███████▍  | 198/266 [03:06<01:16,  1.13s/it]Loading train:  75%|███████▍  | 199/266 [03:07<01:13,  1.10s/it]Loading train:  75%|███████▌  | 200/266 [03:08<01:14,  1.13s/it]Loading train:  76%|███████▌  | 201/266 [03:09<01:13,  1.14s/it]Loading train:  76%|███████▌  | 202/266 [03:10<01:11,  1.12s/it]Loading train:  76%|███████▋  | 203/266 [03:11<01:08,  1.09s/it]Loading train:  77%|███████▋  | 204/266 [03:12<01:07,  1.10s/it]Loading train:  77%|███████▋  | 205/266 [03:13<01:08,  1.12s/it]Loading train:  77%|███████▋  | 206/266 [03:14<01:06,  1.11s/it]Loading train:  78%|███████▊  | 207/266 [03:15<01:03,  1.08s/it]Loading train:  78%|███████▊  | 208/266 [03:17<01:06,  1.14s/it]Loading train:  79%|███████▊  | 209/266 [03:18<01:04,  1.14s/it]Loading train:  79%|███████▉  | 210/266 [03:19<01:04,  1.15s/it]Loading train:  79%|███████▉  | 211/266 [03:20<01:01,  1.12s/it]Loading train:  80%|███████▉  | 212/266 [03:21<01:00,  1.13s/it]Loading train:  80%|████████  | 213/266 [03:22<00:58,  1.11s/it]Loading train:  80%|████████  | 214/266 [03:23<00:55,  1.06s/it]Loading train:  81%|████████  | 215/266 [03:24<00:56,  1.10s/it]Loading train:  81%|████████  | 216/266 [03:26<00:58,  1.18s/it]Loading train:  82%|████████▏ | 217/266 [03:27<00:57,  1.18s/it]Loading train:  82%|████████▏ | 218/266 [03:28<00:53,  1.12s/it]Loading train:  82%|████████▏ | 219/266 [03:29<00:50,  1.08s/it]Loading train:  83%|████████▎ | 220/266 [03:30<00:51,  1.12s/it]Loading train:  83%|████████▎ | 221/266 [03:31<00:50,  1.11s/it]Loading train:  83%|████████▎ | 222/266 [03:32<00:45,  1.04s/it]Loading train:  84%|████████▍ | 223/266 [03:33<00:46,  1.09s/it]Loading train:  84%|████████▍ | 224/266 [03:34<00:42,  1.02s/it]Loading train:  85%|████████▍ | 225/266 [03:35<00:43,  1.06s/it]Loading train:  85%|████████▍ | 226/266 [03:36<00:42,  1.06s/it]Loading train:  85%|████████▌ | 227/266 [03:38<00:41,  1.08s/it]Loading train:  86%|████████▌ | 228/266 [03:39<00:40,  1.06s/it]Loading train:  86%|████████▌ | 229/266 [03:40<00:39,  1.08s/it]Loading train:  86%|████████▋ | 230/266 [03:41<00:37,  1.04s/it]Loading train:  87%|████████▋ | 231/266 [03:42<00:35,  1.01s/it]Loading train:  87%|████████▋ | 232/266 [03:43<00:35,  1.05s/it]Loading train:  88%|████████▊ | 233/266 [03:44<00:35,  1.07s/it]Loading train:  88%|████████▊ | 234/266 [03:45<00:34,  1.08s/it]Loading train:  88%|████████▊ | 235/266 [03:46<00:32,  1.06s/it]Loading train:  89%|████████▊ | 236/266 [03:47<00:33,  1.11s/it]Loading train:  89%|████████▉ | 237/266 [03:48<00:31,  1.09s/it]Loading train:  89%|████████▉ | 238/266 [03:49<00:29,  1.06s/it]Loading train:  90%|████████▉ | 239/266 [03:50<00:28,  1.07s/it]Loading train:  90%|█████████ | 240/266 [03:51<00:26,  1.04s/it]Loading train:  91%|█████████ | 241/266 [03:52<00:24,  1.00it/s]Loading train:  91%|█████████ | 242/266 [03:53<00:23,  1.02it/s]Loading train:  91%|█████████▏| 243/266 [03:54<00:22,  1.01it/s]Loading train:  92%|█████████▏| 244/266 [03:55<00:21,  1.02it/s]Loading train:  92%|█████████▏| 245/266 [03:56<00:19,  1.06it/s]Loading train:  92%|█████████▏| 246/266 [03:57<00:20,  1.01s/it]Loading train:  93%|█████████▎| 247/266 [03:58<00:18,  1.01it/s]Loading train:  93%|█████████▎| 248/266 [03:59<00:17,  1.01it/s]Loading train:  94%|█████████▎| 249/266 [04:00<00:18,  1.11s/it]Loading train:  94%|█████████▍| 250/266 [04:02<00:18,  1.13s/it]Loading train:  94%|█████████▍| 251/266 [04:03<00:16,  1.07s/it]Loading train:  95%|█████████▍| 252/266 [04:04<00:14,  1.05s/it]Loading train:  95%|█████████▌| 253/266 [04:05<00:13,  1.03s/it]Loading train:  95%|█████████▌| 254/266 [04:06<00:12,  1.06s/it]Loading train:  96%|█████████▌| 255/266 [04:07<00:11,  1.03s/it]Loading train:  96%|█████████▌| 256/266 [04:08<00:10,  1.09s/it]Loading train:  97%|█████████▋| 257/266 [04:09<00:10,  1.12s/it]Loading train:  97%|█████████▋| 258/266 [04:10<00:09,  1.14s/it]Loading train:  97%|█████████▋| 259/266 [04:11<00:07,  1.10s/it]Loading train:  98%|█████████▊| 260/266 [04:12<00:06,  1.13s/it]Loading train:  98%|█████████▊| 261/266 [04:14<00:05,  1.17s/it]Loading train:  98%|█████████▊| 262/266 [04:15<00:04,  1.17s/it]Loading train:  99%|█████████▉| 263/266 [04:16<00:03,  1.17s/it]Loading train:  99%|█████████▉| 264/266 [04:17<00:02,  1.15s/it]Loading train: 100%|█████████▉| 265/266 [04:18<00:01,  1.13s/it]Loading train: 100%|██████████| 266/266 [04:20<00:00,  1.23s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:06, 41.50it/s]concatenating: train:   4%|▍         | 11/266 [00:00<00:05, 45.32it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:05, 49.39it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:04, 52.71it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:04, 56.38it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:03, 64.80it/s]concatenating: train:  21%|██        | 55/266 [00:00<00:02, 75.29it/s]concatenating: train:  25%|██▍       | 66/266 [00:00<00:02, 83.08it/s]concatenating: train:  30%|██▉       | 79/266 [00:00<00:02, 92.37it/s]concatenating: train:  35%|███▍      | 92/266 [00:01<00:01, 100.22it/s]concatenating: train:  39%|███▉      | 104/266 [00:01<00:01, 104.35it/s]concatenating: train:  45%|████▌     | 121/266 [00:01<00:01, 118.00it/s]concatenating: train:  53%|█████▎    | 140/266 [00:01<00:00, 130.92it/s]concatenating: train:  58%|█████▊    | 155/266 [00:01<00:00, 126.51it/s]concatenating: train:  66%|██████▌   | 176/266 [00:01<00:00, 143.49it/s]concatenating: train:  78%|███████▊  | 208/266 [00:01<00:00, 169.89it/s]concatenating: train:  86%|████████▌ | 228/266 [00:01<00:00, 154.77it/s]concatenating: train:  92%|█████████▏| 246/266 [00:01<00:00, 153.65it/s]concatenating: train: 100%|██████████| 266/266 [00:02<00:00, 127.60it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:01<00:04,  1.46s/it]Loading test:  50%|█████     | 2/4 [00:02<00:02,  1.40s/it]Loading test:  75%|███████▌  | 3/4 [00:03<00:01,  1.33s/it]Loading test: 100%|██████████| 4/4 [00:05<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 152.47it/s]2019-07-29 08:01:36.728622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-29 08:01:36.728699: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-29 08:01:36.728712: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-29 08:01:36.728721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-29 08:01:36.729074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:09:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.87it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.83it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.57it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.17it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.73it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.59it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.83it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.55it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.10it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.77it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.48it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.88it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.13it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.63it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.26it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.71it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.78it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.95it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.96it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 3  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 84, 48, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 84, 48, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 84, 48, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 84, 48, 40)   14800       concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 84, 48, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 84, 48, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 84, 48, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 84, 48, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 84, 48, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 42, 24, 80)   28880       dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 42, 24, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 42, 24, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 42, 24, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 42, 24, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 42, 24, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 42, 24, 120)  0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 21, 12, 160)  172960      dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 21, 12, 160)  640         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 21, 12, 160)  0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 21, 12, 160)  230560      activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 21, 12, 160)  640         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 21, 12, 160)  0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 21, 12, 280)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 21, 12, 280)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 42, 24, 80)   320         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 42, 24, 80)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 42, 24, 80)   57680       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 42, 24, 80)   320         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 42, 24, 80)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 42, 24, 280)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 42, 24, 280)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 40)   28840       concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 84, 48, 40)   160         conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 84, 48, 40)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 84, 48, 40)   14440       activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 84, 48, 40)   160         conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 84, 48, 40)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 84, 48, 120)  0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 84, 48, 120)  0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 84, 48, 40)   43240       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 84, 48, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 84, 48, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 84, 48, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 84, 48, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 84, 48, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 84, 48, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 84, 48, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 84, 48, 160)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 84, 48, 13)   2093        concatenate_8[0][0]              
==================================================================================================
Total params: 977,333
Trainable params: 280,453
Non-trainable params: 696,880
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33785835e-02 3.28482398e-02 7.68110910e-02 9.54416430e-03
 2.76229848e-02 7.22682411e-03 8.45401742e-02 1.14167041e-01
 8.96436617e-02 1.36199917e-02 2.90642383e-01 1.89686673e-01
 2.68187751e-04]
Train on 10223 samples, validate on 146 samples
Epoch 1/300
 - 29s - loss: 1.6458 - acc: 0.7523 - mDice: 0.2813 - val_loss: 0.8409 - val_acc: 0.9175 - val_mDice: 0.4633

Epoch 00001: val_mDice improved from -inf to 0.46335, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 23s - loss: 0.6160 - acc: 0.9088 - mDice: 0.5288 - val_loss: 0.4940 - val_acc: 0.9387 - val_mDice: 0.5978

Epoch 00002: val_mDice improved from 0.46335 to 0.59783, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 22s - loss: 0.4908 - acc: 0.9260 - mDice: 0.5981 - val_loss: 0.5134 - val_acc: 0.9398 - val_mDice: 0.5915

Epoch 00003: val_mDice did not improve from 0.59783
Epoch 4/300
 - 22s - loss: 0.4288 - acc: 0.9324 - mDice: 0.6372 - val_loss: 0.4957 - val_acc: 0.9412 - val_mDice: 0.6003

Epoch 00004: val_mDice improved from 0.59783 to 0.60027, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 22s - loss: 0.4024 - acc: 0.9351 - mDice: 0.6543 - val_loss: 0.4764 - val_acc: 0.9399 - val_mDice: 0.6127

Epoch 00005: val_mDice improved from 0.60027 to 0.61265, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 23s - loss: 0.3796 - acc: 0.9376 - mDice: 0.6700 - val_loss: 0.4940 - val_acc: 0.9390 - val_mDice: 0.6041

Epoch 00006: val_mDice did not improve from 0.61265
Epoch 7/300
 - 22s - loss: 0.3634 - acc: 0.9392 - mDice: 0.6819 - val_loss: 0.7458 - val_acc: 0.9107 - val_mDice: 0.5090

Epoch 00007: val_mDice did not improve from 0.61265
Epoch 8/300
 - 22s - loss: 0.3542 - acc: 0.9400 - mDice: 0.6882 - val_loss: 0.4946 - val_acc: 0.9420 - val_mDice: 0.6018

Epoch 00008: val_mDice did not improve from 0.61265
Epoch 9/300
 - 22s - loss: 0.3319 - acc: 0.9418 - mDice: 0.7037 - val_loss: 0.4799 - val_acc: 0.9408 - val_mDice: 0.6104

Epoch 00009: val_mDice did not improve from 0.61265
Epoch 10/300
 - 23s - loss: 0.3236 - acc: 0.9428 - mDice: 0.7098 - val_loss: 0.5097 - val_acc: 0.9408 - val_mDice: 0.5948

Epoch 00010: val_mDice did not improve from 0.61265
Epoch 11/300
 - 23s - loss: 0.3129 - acc: 0.9437 - mDice: 0.7176 - val_loss: 0.4724 - val_acc: 0.9440 - val_mDice: 0.6154

Epoch 00011: val_mDice improved from 0.61265 to 0.61545, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 22s - loss: 0.3036 - acc: 0.9447 - mDice: 0.7246 - val_loss: 0.4543 - val_acc: 0.9442 - val_mDice: 0.6243

Epoch 00012: val_mDice improved from 0.61545 to 0.62425, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 22s - loss: 0.3026 - acc: 0.9452 - mDice: 0.7275 - val_loss: 0.4993 - val_acc: 0.9411 - val_mDice: 0.6010

Epoch 00013: val_mDice did not improve from 0.62425
Epoch 14/300
 - 23s - loss: 0.2963 - acc: 0.9455 - mDice: 0.7302 - val_loss: 0.4972 - val_acc: 0.9449 - val_mDice: 0.6029

Epoch 00014: val_mDice did not improve from 0.62425
Epoch 15/300
 - 23s - loss: 0.2848 - acc: 0.9464 - mDice: 0.7387 - val_loss: 0.4790 - val_acc: 0.9441 - val_mDice: 0.6129

Epoch 00015: val_mDice did not improve from 0.62425
Epoch 16/300
 - 23s - loss: 0.2807 - acc: 0.9469 - mDice: 0.7421 - val_loss: 0.4694 - val_acc: 0.9419 - val_mDice: 0.6165

Epoch 00016: val_mDice did not improve from 0.62425
Epoch 17/300
 - 23s - loss: 0.2766 - acc: 0.9473 - mDice: 0.7452 - val_loss: 0.4993 - val_acc: 0.9422 - val_mDice: 0.6025

Epoch 00017: val_mDice did not improve from 0.62425
Epoch 18/300
 - 23s - loss: 0.2692 - acc: 0.9480 - mDice: 0.7510 - val_loss: 0.4933 - val_acc: 0.9433 - val_mDice: 0.6028

Epoch 00018: val_mDice did not improve from 0.62425
Epoch 19/300
 - 23s - loss: 0.2682 - acc: 0.9482 - mDice: 0.7519 - val_loss: 0.4799 - val_acc: 0.9439 - val_mDice: 0.6123

Epoch 00019: val_mDice did not improve from 0.62425
Epoch 20/300
 - 23s - loss: 0.2609 - acc: 0.9489 - mDice: 0.7576 - val_loss: 0.4816 - val_acc: 0.9446 - val_mDice: 0.6132

Epoch 00020: val_mDice did not improve from 0.62425
Epoch 21/300
 - 24s - loss: 0.3407 - acc: 0.9419 - mDice: 0.7025 - val_loss: 0.5693 - val_acc: 0.9365 - val_mDice: 0.5673

Epoch 00021: val_mDice did not improve from 0.62425
Epoch 22/300
 - 24s - loss: 0.2794 - acc: 0.9471 - mDice: 0.7428 - val_loss: 0.4578 - val_acc: 0.9447 - val_mDice: 0.6214

Epoch 00022: val_mDice did not improve from 0.62425
Epoch 23/300
 - 23s - loss: 0.2636 - acc: 0.9486 - mDice: 0.7552 - val_loss: 0.4741 - val_acc: 0.9446 - val_mDice: 0.6181

Epoch 00023: val_mDice did not improve from 0.62425
Epoch 24/300
 - 24s - loss: 0.2577 - acc: 0.9494 - mDice: 0.7614 - val_loss: 0.5496 - val_acc: 0.9332 - val_mDice: 0.5758

Epoch 00024: val_mDice did not improve from 0.62425
Epoch 25/300
 - 23s - loss: 0.2562 - acc: 0.9493 - mDice: 0.7613 - val_loss: 0.4941 - val_acc: 0.9418 - val_mDice: 0.6040

Epoch 00025: val_mDice did not improve from 0.62425
Epoch 26/300
 - 23s - loss: 0.2487 - acc: 0.9501 - mDice: 0.7673 - val_loss: 0.4790 - val_acc: 0.9422 - val_mDice: 0.6124

Epoch 00026: val_mDice did not improve from 0.62425
Epoch 27/300
 - 24s - loss: 0.2452 - acc: 0.9505 - mDice: 0.7701 - val_loss: 0.5193 - val_acc: 0.9432 - val_mDice: 0.5948

Epoch 00027: val_mDice did not improve from 0.62425
Epoch 28/300
 - 24s - loss: 0.2517 - acc: 0.9502 - mDice: 0.7679 - val_loss: 0.4929 - val_acc: 0.9382 - val_mDice: 0.6006

Epoch 00028: val_mDice did not improve from 0.62425
Epoch 29/300
 - 24s - loss: 0.2454 - acc: 0.9502 - mDice: 0.7699 - val_loss: 0.4906 - val_acc: 0.9424 - val_mDice: 0.6092

Epoch 00029: val_mDice did not improve from 0.62425
Epoch 30/300
 - 24s - loss: 0.2385 - acc: 0.9511 - mDice: 0.7754 - val_loss: 0.4833 - val_acc: 0.9437 - val_mDice: 0.6124

Epoch 00030: val_mDice did not improve from 0.62425
Epoch 31/300
 - 24s - loss: 0.2442 - acc: 0.9511 - mDice: 0.7757 - val_loss: 0.4770 - val_acc: 0.9403 - val_mDice: 0.6121

Epoch 00031: val_mDice did not improve from 0.62425
Epoch 32/300
 - 24s - loss: 0.2352 - acc: 0.9514 - mDice: 0.7782 - val_loss: 0.4709 - val_acc: 0.9442 - val_mDice: 0.6144

Epoch 00032: val_mDice did not improve from 0.62425
Epoch 33/300
 - 26s - loss: 0.2374 - acc: 0.9516 - mDice: 0.7788 - val_loss: 0.5316 - val_acc: 0.9440 - val_mDice: 0.5868

Epoch 00033: val_mDice did not improve from 0.62425
Epoch 34/300
 - 25s - loss: 0.2365 - acc: 0.9514 - mDice: 0.7772 - val_loss: 0.4690 - val_acc: 0.9448 - val_mDice: 0.6187

Epoch 00034: val_mDice did not improve from 0.62425
Epoch 35/300
 - 26s - loss: 0.2382 - acc: 0.9512 - mDice: 0.7759 - val_loss: 0.4765 - val_acc: 0.9412 - val_mDice: 0.6137

Epoch 00035: val_mDice did not improve from 0.62425
Epoch 36/300
 - 27s - loss: 0.2331 - acc: 0.9517 - mDice: 0.7799 - val_loss: 0.4780 - val_acc: 0.9443 - val_mDice: 0.6170

Epoch 00036: val_mDice did not improve from 0.62425
Epoch 37/300
 - 26s - loss: 0.2276 - acc: 0.9523 - mDice: 0.7844 - val_loss: 0.4569 - val_acc: 0.9439 - val_mDice: 0.6235

Epoch 00037: val_mDice did not improve from 0.62425
Epoch 38/300
 - 25s - loss: 0.2241 - acc: 0.9526 - mDice: 0.7874 - val_loss: 0.4812 - val_acc: 0.9420 - val_mDice: 0.6163

Epoch 00038: val_mDice did not improve from 0.62425
Epoch 39/300
 - 26s - loss: 0.2216 - acc: 0.9528 - mDice: 0.7894 - val_loss: 0.4832 - val_acc: 0.9429 - val_mDice: 0.6115

Epoch 00039: val_mDice did not improve from 0.62425
Epoch 40/300
 - 25s - loss: 0.2187 - acc: 0.9530 - mDice: 0.7918 - val_loss: 0.5063 - val_acc: 0.9425 - val_mDice: 0.6006

Epoch 00040: val_mDice did not improve from 0.62425
Epoch 41/300
 - 25s - loss: 0.2197 - acc: 0.9530 - mDice: 0.7910 - val_loss: 0.4988 - val_acc: 0.9427 - val_mDice: 0.6022

Epoch 00041: val_mDice did not improve from 0.62425
Epoch 42/300
 - 24s - loss: 0.2191 - acc: 0.9530 - mDice: 0.7915 - val_loss: 0.4769 - val_acc: 0.9442 - val_mDice: 0.6131

Epoch 00042: val_mDice did not improve from 0.62425
Epoch 43/300
 - 26s - loss: 0.2165 - acc: 0.9532 - mDice: 0.7936 - val_loss: 0.4939 - val_acc: 0.9410 - val_mDice: 0.6053

Epoch 00043: val_mDice did not improve from 0.62425
Epoch 44/300
 - 25s - loss: 0.2218 - acc: 0.9530 - mDice: 0.7894 - val_loss: 0.5071 - val_acc: 0.9420 - val_mDice: 0.5948

Epoch 00044: val_mDice did not improve from 0.62425
Epoch 45/300
 - 26s - loss: 0.2156 - acc: 0.9535 - mDice: 0.7944 - val_loss: 0.4950 - val_acc: 0.9420 - val_mDice: 0.6031

Epoch 00045: val_mDice did not improve from 0.62425
Epoch 46/300
 - 23s - loss: 0.2135 - acc: 0.9536 - mDice: 0.7961 - val_loss: 0.4967 - val_acc: 0.9421 - val_mDice: 0.6040

Epoch 00046: val_mDice did not improve from 0.62425
Epoch 47/300
 - 26s - loss: 0.2118 - acc: 0.9538 - mDice: 0.7976 - val_loss: 0.5457 - val_acc: 0.9423 - val_mDice: 0.5858

Epoch 00047: val_mDice did not improve from 0.62425
Epoch 48/300
 - 25s - loss: 0.2135 - acc: 0.9537 - mDice: 0.7962 - val_loss: 0.4681 - val_acc: 0.9416 - val_mDice: 0.6181

Epoch 00048: val_mDice did not improve from 0.62425
Epoch 49/300
 - 25s - loss: 0.2094 - acc: 0.9540 - mDice: 0.7996 - val_loss: 0.4953 - val_acc: 0.9450 - val_mDice: 0.6050

Epoch 00049: val_mDice did not improve from 0.62425
Epoch 50/300
 - 26s - loss: 0.2099 - acc: 0.9539 - mDice: 0.7992 - val_loss: 0.4754 - val_acc: 0.9453 - val_mDice: 0.6202

Epoch 00050: val_mDice did not improve from 0.62425
Epoch 51/300
 - 26s - loss: 0.2078 - acc: 0.9542 - mDice: 0.8010 - val_loss: 0.4653 - val_acc: 0.9452 - val_mDice: 0.6218

Epoch 00051: val_mDice did not improve from 0.62425
Epoch 52/300
 - 25s - loss: 0.2065 - acc: 0.9544 - mDice: 0.8021 - val_loss: 0.4786 - val_acc: 0.9434 - val_mDice: 0.6141

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:03<00:10,  3.61s/it]predicting test subjects:  50%|█████     | 2/4 [00:06<00:06,  3.29s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:08<00:03,  3.03s/it]predicting test subjects: 100%|██████████| 4/4 [00:11<00:00,  2.98s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<16:20,  3.70s/it]predicting train subjects:   1%|          | 2/266 [00:06<15:41,  3.56s/it]predicting train subjects:   1%|          | 3/266 [00:09<14:27,  3.30s/it]predicting train subjects:   2%|▏         | 4/266 [00:12<13:18,  3.05s/it]predicting train subjects:   2%|▏         | 5/266 [00:15<13:15,  3.05s/it]predicting train subjects:   2%|▏         | 6/266 [00:18<13:39,  3.15s/it]predicting train subjects:   3%|▎         | 7/266 [00:21<13:34,  3.14s/it]predicting train subjects:   3%|▎         | 8/266 [00:25<14:03,  3.27s/it]predicting train subjects:   3%|▎         | 9/266 [00:28<14:10,  3.31s/it]predicting train subjects:   4%|▍         | 10/266 [00:32<14:18,  3.36s/it]predicting train subjects:   4%|▍         | 11/266 [00:35<14:22,  3.38s/it]predicting train subjects:   5%|▍         | 12/266 [00:39<14:36,  3.45s/it]predicting train subjects:   5%|▍         | 13/266 [00:42<14:20,  3.40s/it]predicting train subjects:   5%|▌         | 14/266 [00:45<14:12,  3.38s/it]predicting train subjects:   6%|▌         | 15/266 [00:49<14:09,  3.38s/it]predicting train subjects:   6%|▌         | 16/266 [00:52<14:24,  3.46s/it]predicting train subjects:   6%|▋         | 17/266 [00:55<13:53,  3.35s/it]predicting train subjects:   7%|▋         | 18/266 [00:59<13:40,  3.31s/it]predicting train subjects:   7%|▋         | 19/266 [01:02<13:54,  3.38s/it]predicting train subjects:   8%|▊         | 20/266 [01:06<14:10,  3.46s/it]predicting train subjects:   8%|▊         | 21/266 [01:09<14:03,  3.44s/it]predicting train subjects:   8%|▊         | 22/266 [01:13<14:01,  3.45s/it]predicting train subjects:   9%|▊         | 23/266 [01:16<13:43,  3.39s/it]predicting train subjects:   9%|▉         | 24/266 [01:19<13:08,  3.26s/it]predicting train subjects:   9%|▉         | 25/266 [01:22<12:51,  3.20s/it]predicting train subjects:  10%|▉         | 26/266 [01:25<12:52,  3.22s/it]predicting train subjects:  10%|█         | 27/266 [01:28<12:30,  3.14s/it]predicting train subjects:  11%|█         | 28/266 [01:31<12:31,  3.16s/it]predicting train subjects:  11%|█         | 29/266 [01:34<12:25,  3.14s/it]predicting train subjects:  11%|█▏        | 30/266 [01:38<12:34,  3.20s/it]predicting train subjects:  12%|█▏        | 31/266 [01:41<12:05,  3.09s/it]predicting train subjects:  12%|█▏        | 32/266 [01:44<12:02,  3.09s/it]predicting train subjects:  12%|█▏        | 33/266 [01:47<12:02,  3.10s/it]predicting train subjects:  13%|█▎        | 34/266 [01:50<12:03,  3.12s/it]predicting train subjects:  13%|█▎        | 35/266 [01:53<12:00,  3.12s/it]predicting train subjects:  14%|█▎        | 36/266 [01:56<12:03,  3.14s/it]predicting train subjects:  14%|█▍        | 37/266 [01:59<11:49,  3.10s/it]predicting train subjects:  14%|█▍        | 38/266 [02:02<11:51,  3.12s/it]predicting train subjects:  15%|█▍        | 39/266 [02:06<11:55,  3.15s/it]predicting train subjects:  15%|█▌        | 40/266 [02:09<12:11,  3.24s/it]predicting train subjects:  15%|█▌        | 41/266 [02:12<11:53,  3.17s/it]predicting train subjects:  16%|█▌        | 42/266 [02:15<11:22,  3.05s/it]predicting train subjects:  16%|█▌        | 43/266 [02:17<10:38,  2.86s/it]predicting train subjects:  17%|█▋        | 44/266 [02:20<10:16,  2.78s/it]predicting train subjects:  17%|█▋        | 45/266 [02:22<09:55,  2.69s/it]predicting train subjects:  17%|█▋        | 46/266 [02:25<09:36,  2.62s/it]predicting train subjects:  18%|█▊        | 47/266 [02:27<09:21,  2.56s/it]predicting train subjects:  18%|█▊        | 48/266 [02:30<09:17,  2.56s/it]predicting train subjects:  18%|█▊        | 49/266 [02:32<09:21,  2.59s/it]predicting train subjects:  19%|█▉        | 50/266 [02:35<09:09,  2.54s/it]predicting train subjects:  19%|█▉        | 51/266 [02:37<08:58,  2.51s/it]predicting train subjects:  20%|█▉        | 52/266 [02:40<09:10,  2.57s/it]predicting train subjects:  20%|█▉        | 53/266 [02:43<09:11,  2.59s/it]predicting train subjects:  20%|██        | 54/266 [02:45<08:59,  2.55s/it]predicting train subjects:  21%|██        | 55/266 [02:48<08:56,  2.54s/it]predicting train subjects:  21%|██        | 56/266 [02:50<09:01,  2.58s/it]predicting train subjects:  21%|██▏       | 57/266 [02:53<09:05,  2.61s/it]predicting train subjects:  22%|██▏       | 58/266 [02:56<09:03,  2.61s/it]predicting train subjects:  22%|██▏       | 59/266 [02:58<09:06,  2.64s/it]predicting train subjects:  23%|██▎       | 60/266 [03:01<08:51,  2.58s/it]predicting train subjects:  23%|██▎       | 61/266 [03:03<08:33,  2.50s/it]predicting train subjects:  23%|██▎       | 62/266 [03:05<08:12,  2.41s/it]predicting train subjects:  24%|██▎       | 63/266 [03:08<08:09,  2.41s/it]predicting train subjects:  24%|██▍       | 64/266 [03:10<08:15,  2.45s/it]predicting train subjects:  24%|██▍       | 65/266 [03:13<08:10,  2.44s/it]predicting train subjects:  25%|██▍       | 66/266 [03:15<07:50,  2.35s/it]predicting train subjects:  25%|██▌       | 67/266 [03:17<07:39,  2.31s/it]predicting train subjects:  26%|██▌       | 68/266 [03:19<07:33,  2.29s/it]predicting train subjects:  26%|██▌       | 69/266 [03:22<08:01,  2.44s/it]predicting train subjects:  26%|██▋       | 70/266 [03:25<08:15,  2.53s/it]predicting train subjects:  27%|██▋       | 71/266 [03:28<08:22,  2.58s/it]predicting train subjects:  27%|██▋       | 72/266 [03:30<08:21,  2.58s/it]predicting train subjects:  27%|██▋       | 73/266 [03:33<08:16,  2.57s/it]predicting train subjects:  28%|██▊       | 74/266 [03:36<08:47,  2.75s/it]predicting train subjects:  28%|██▊       | 75/266 [03:39<08:44,  2.75s/it]predicting train subjects:  29%|██▊       | 76/266 [03:41<08:27,  2.67s/it]predicting train subjects:  29%|██▉       | 77/266 [03:44<08:21,  2.65s/it]predicting train subjects:  29%|██▉       | 78/266 [03:47<08:59,  2.87s/it]predicting train subjects:  30%|██▉       | 79/266 [03:50<09:28,  3.04s/it]predicting train subjects:  30%|███       | 80/266 [03:54<09:54,  3.20s/it]predicting train subjects:  30%|███       | 81/266 [03:57<10:04,  3.27s/it]predicting train subjects:  31%|███       | 82/266 [04:01<10:02,  3.27s/it]predicting train subjects:  31%|███       | 83/266 [04:04<10:16,  3.37s/it]predicting train subjects:  32%|███▏      | 84/266 [04:08<10:43,  3.54s/it]predicting train subjects:  32%|███▏      | 85/266 [04:12<10:35,  3.51s/it]predicting train subjects:  32%|███▏      | 86/266 [04:15<10:32,  3.51s/it]predicting train subjects:  33%|███▎      | 87/266 [04:19<10:40,  3.58s/it]predicting train subjects:  33%|███▎      | 88/266 [04:22<10:30,  3.54s/it]predicting train subjects:  33%|███▎      | 89/266 [04:26<10:20,  3.50s/it]predicting train subjects:  34%|███▍      | 90/266 [04:30<10:26,  3.56s/it]predicting train subjects:  34%|███▍      | 91/266 [04:33<10:18,  3.54s/it]predicting train subjects:  35%|███▍      | 92/266 [04:37<10:22,  3.58s/it]predicting train subjects:  35%|███▍      | 93/266 [04:40<10:05,  3.50s/it]predicting train subjects:  35%|███▌      | 94/266 [04:43<09:52,  3.45s/it]predicting train subjects:  36%|███▌      | 95/266 [04:47<09:43,  3.41s/it]predicting train subjects:  36%|███▌      | 96/266 [04:50<09:12,  3.25s/it]predicting train subjects:  36%|███▋      | 97/266 [04:53<09:09,  3.25s/it]predicting train subjects:  37%|███▋      | 98/266 [04:56<09:02,  3.23s/it]predicting train subjects:  37%|███▋      | 99/266 [04:58<08:15,  2.97s/it]predicting train subjects:  38%|███▊      | 100/266 [05:01<08:06,  2.93s/it]predicting train subjects:  38%|███▊      | 101/266 [05:04<08:21,  3.04s/it]predicting train subjects:  38%|███▊      | 102/266 [05:07<08:06,  2.97s/it]predicting train subjects:  39%|███▊      | 103/266 [05:10<07:54,  2.91s/it]predicting train subjects:  39%|███▉      | 104/266 [05:13<07:52,  2.92s/it]predicting train subjects:  39%|███▉      | 105/266 [05:16<08:04,  3.01s/it]predicting train subjects:  40%|███▉      | 106/266 [05:19<08:01,  3.01s/it]predicting train subjects:  40%|████      | 107/266 [05:22<07:59,  3.02s/it]predicting train subjects:  41%|████      | 108/266 [05:25<07:41,  2.92s/it]predicting train subjects:  41%|████      | 109/266 [05:28<07:36,  2.91s/it]predicting train subjects:  41%|████▏     | 110/266 [05:31<07:36,  2.93s/it]predicting train subjects:  42%|████▏     | 111/266 [05:34<07:35,  2.94s/it]predicting train subjects:  42%|████▏     | 112/266 [05:37<07:33,  2.95s/it]predicting train subjects:  42%|████▏     | 113/266 [05:40<07:40,  3.01s/it]predicting train subjects:  43%|████▎     | 114/266 [05:43<07:31,  2.97s/it]predicting train subjects:  43%|████▎     | 115/266 [05:46<07:31,  2.99s/it]predicting train subjects:  44%|████▎     | 116/266 [05:49<07:25,  2.97s/it]predicting train subjects:  44%|████▍     | 117/266 [05:52<07:14,  2.92s/it]predicting train subjects:  44%|████▍     | 118/266 [05:55<07:34,  3.07s/it]predicting train subjects:  45%|████▍     | 119/266 [05:59<07:53,  3.22s/it]predicting train subjects:  45%|████▌     | 120/266 [06:02<07:58,  3.28s/it]predicting train subjects:  45%|████▌     | 121/266 [06:05<07:56,  3.28s/it]predicting train subjects:  46%|████▌     | 122/266 [06:09<08:05,  3.37s/it]predicting train subjects:  46%|████▌     | 123/266 [06:12<08:03,  3.38s/it]predicting train subjects:  47%|████▋     | 124/266 [06:16<08:08,  3.44s/it]predicting train subjects:  47%|████▋     | 125/266 [06:19<08:03,  3.43s/it]predicting train subjects:  47%|████▋     | 126/266 [06:22<07:42,  3.31s/it]predicting train subjects:  48%|████▊     | 127/266 [06:26<07:49,  3.38s/it]predicting train subjects:  48%|████▊     | 128/266 [06:29<07:39,  3.33s/it]predicting train subjects:  48%|████▊     | 129/266 [06:32<07:31,  3.29s/it]predicting train subjects:  49%|████▉     | 130/266 [06:35<07:23,  3.26s/it]predicting train subjects:  49%|████▉     | 131/266 [06:39<07:28,  3.32s/it]predicting train subjects:  50%|████▉     | 132/266 [06:42<07:30,  3.36s/it]predicting train subjects:  50%|█████     | 133/266 [06:46<07:42,  3.47s/it]predicting train subjects:  50%|█████     | 134/266 [06:49<07:26,  3.38s/it]predicting train subjects:  51%|█████     | 135/266 [06:53<07:26,  3.41s/it]predicting train subjects:  51%|█████     | 136/266 [06:56<07:25,  3.42s/it]predicting train subjects:  52%|█████▏    | 137/266 [07:00<07:22,  3.43s/it]predicting train subjects:  52%|█████▏    | 138/266 [07:03<07:33,  3.54s/it]predicting train subjects:  52%|█████▏    | 139/266 [07:07<07:31,  3.56s/it]predicting train subjects:  53%|█████▎    | 140/266 [07:10<06:55,  3.30s/it]predicting train subjects:  53%|█████▎    | 141/266 [07:13<06:53,  3.31s/it]predicting train subjects:  53%|█████▎    | 142/266 [07:17<07:09,  3.47s/it]predicting train subjects:  54%|█████▍    | 143/266 [07:20<07:11,  3.51s/it]predicting train subjects:  54%|█████▍    | 144/266 [07:24<06:57,  3.42s/it]predicting train subjects:  55%|█████▍    | 145/266 [07:26<06:25,  3.19s/it]predicting train subjects:  55%|█████▍    | 146/266 [07:29<06:01,  3.01s/it]predicting train subjects:  55%|█████▌    | 147/266 [07:31<05:40,  2.86s/it]predicting train subjects:  56%|█████▌    | 148/266 [07:34<05:24,  2.75s/it]predicting train subjects:  56%|█████▌    | 149/266 [07:36<05:11,  2.66s/it]predicting train subjects:  56%|█████▋    | 150/266 [07:39<05:01,  2.60s/it]predicting train subjects:  57%|█████▋    | 151/266 [07:41<04:55,  2.57s/it]predicting train subjects:  57%|█████▋    | 152/266 [07:44<04:48,  2.53s/it]predicting train subjects:  58%|█████▊    | 153/266 [07:46<04:44,  2.52s/it]predicting train subjects:  58%|█████▊    | 154/266 [07:49<04:40,  2.50s/it]predicting train subjects:  58%|█████▊    | 155/266 [07:51<04:15,  2.30s/it]predicting train subjects:  59%|█████▊    | 156/266 [07:52<03:57,  2.15s/it]predicting train subjects:  59%|█████▉    | 157/266 [07:54<03:42,  2.04s/it]predicting train subjects:  59%|█████▉    | 158/266 [07:56<03:34,  1.98s/it]predicting train subjects:  60%|█████▉    | 159/266 [07:58<03:26,  1.93s/it]predicting train subjects:  60%|██████    | 160/266 [08:00<03:23,  1.92s/it]predicting train subjects:  61%|██████    | 161/266 [08:01<03:19,  1.90s/it]predicting train subjects:  61%|██████    | 162/266 [08:03<03:14,  1.87s/it]predicting train subjects:  61%|██████▏   | 163/266 [08:05<03:12,  1.87s/it]predicting train subjects:  62%|██████▏   | 164/266 [08:07<03:10,  1.87s/it]predicting train subjects:  62%|██████▏   | 165/266 [08:09<03:06,  1.85s/it]predicting train subjects:  62%|██████▏   | 166/266 [08:11<03:04,  1.85s/it]predicting train subjects:  63%|██████▎   | 167/266 [08:13<03:02,  1.84s/it]predicting train subjects:  63%|██████▎   | 168/266 [08:14<02:59,  1.83s/it]predicting train subjects:  64%|██████▎   | 169/266 [08:16<02:57,  1.83s/it]predicting train subjects:  64%|██████▍   | 170/266 [08:18<02:54,  1.82s/it]predicting train subjects:  64%|██████▍   | 171/266 [08:20<02:51,  1.81s/it]predicting train subjects:  65%|██████▍   | 172/266 [08:22<02:49,  1.81s/it]predicting train subjects:  65%|██████▌   | 173/266 [08:24<02:52,  1.86s/it]predicting train subjects:  65%|██████▌   | 174/266 [08:26<02:55,  1.91s/it]predicting train subjects:  66%|██████▌   | 175/266 [08:28<02:55,  1.93s/it]predicting train subjects:  66%|██████▌   | 176/266 [08:30<02:57,  1.97s/it]predicting train subjects:  67%|██████▋   | 177/266 [08:32<02:56,  1.99s/it]predicting train subjects:  67%|██████▋   | 178/266 [08:34<02:55,  2.00s/it]predicting train subjects:  67%|██████▋   | 179/266 [08:36<02:53,  2.00s/it]predicting train subjects:  68%|██████▊   | 180/266 [08:38<02:54,  2.03s/it]predicting train subjects:  68%|██████▊   | 181/266 [08:40<02:52,  2.03s/it]predicting train subjects:  68%|██████▊   | 182/266 [08:42<02:48,  2.00s/it]predicting train subjects:  69%|██████▉   | 183/266 [08:44<02:45,  2.00s/it]predicting train subjects:  69%|██████▉   | 184/266 [08:46<02:46,  2.02s/it]predicting train subjects:  70%|██████▉   | 185/266 [08:48<02:42,  2.01s/it]predicting train subjects:  70%|██████▉   | 186/266 [08:50<02:41,  2.02s/it]predicting train subjects:  70%|███████   | 187/266 [08:52<02:38,  2.01s/it]predicting train subjects:  71%|███████   | 188/266 [08:54<02:35,  2.00s/it]predicting train subjects:  71%|███████   | 189/266 [08:56<02:35,  2.02s/it]predicting train subjects:  71%|███████▏  | 190/266 [08:58<02:33,  2.02s/it]predicting train subjects:  72%|███████▏  | 191/266 [09:00<02:36,  2.08s/it]predicting train subjects:  72%|███████▏  | 192/266 [09:02<02:34,  2.09s/it]predicting train subjects:  73%|███████▎  | 193/266 [09:04<02:30,  2.06s/it]predicting train subjects:  73%|███████▎  | 194/266 [09:07<02:38,  2.20s/it]predicting train subjects:  73%|███████▎  | 195/266 [09:09<02:36,  2.20s/it]predicting train subjects:  74%|███████▎  | 196/266 [09:11<02:34,  2.20s/it]predicting train subjects:  74%|███████▍  | 197/266 [09:13<02:32,  2.20s/it]predicting train subjects:  74%|███████▍  | 198/266 [09:16<02:30,  2.22s/it]predicting train subjects:  75%|███████▍  | 199/266 [09:18<02:28,  2.21s/it]predicting train subjects:  75%|███████▌  | 200/266 [09:20<02:25,  2.20s/it]predicting train subjects:  76%|███████▌  | 201/266 [09:22<02:22,  2.19s/it]predicting train subjects:  76%|███████▌  | 202/266 [09:24<02:19,  2.18s/it]predicting train subjects:  76%|███████▋  | 203/266 [09:26<02:17,  2.18s/it]predicting train subjects:  77%|███████▋  | 204/266 [09:29<02:15,  2.18s/it]predicting train subjects:  77%|███████▋  | 205/266 [09:31<02:13,  2.19s/it]predicting train subjects:  77%|███████▋  | 206/266 [09:33<02:11,  2.20s/it]predicting train subjects:  78%|███████▊  | 207/266 [09:35<02:09,  2.20s/it]predicting train subjects:  78%|███████▊  | 208/266 [09:37<02:08,  2.21s/it]predicting train subjects:  79%|███████▊  | 209/266 [09:40<02:05,  2.20s/it]predicting train subjects:  79%|███████▉  | 210/266 [09:42<02:03,  2.20s/it]predicting train subjects:  79%|███████▉  | 211/266 [09:44<02:01,  2.20s/it]predicting train subjects:  80%|███████▉  | 212/266 [09:46<01:58,  2.20s/it]predicting train subjects:  80%|████████  | 213/266 [09:48<01:52,  2.12s/it]predicting train subjects:  80%|████████  | 214/266 [09:50<01:48,  2.08s/it]predicting train subjects:  81%|████████  | 215/266 [09:52<01:44,  2.04s/it]predicting train subjects:  81%|████████  | 216/266 [09:54<01:40,  2.01s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:56<01:37,  1.98s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:58<01:33,  1.96s/it]predicting train subjects:  82%|████████▏ | 219/266 [10:00<01:31,  1.94s/it]predicting train subjects:  83%|████████▎ | 220/266 [10:02<01:29,  1.94s/it]predicting train subjects:  83%|████████▎ | 221/266 [10:04<01:28,  1.96s/it]predicting train subjects:  83%|████████▎ | 222/266 [10:06<01:26,  1.96s/it]predicting train subjects:  84%|████████▍ | 223/266 [10:08<01:24,  1.96s/it]predicting train subjects:  84%|████████▍ | 224/266 [10:10<01:21,  1.95s/it]predicting train subjects:  85%|████████▍ | 225/266 [10:12<01:19,  1.95s/it]predicting train subjects:  85%|████████▍ | 226/266 [10:13<01:17,  1.95s/it]predicting train subjects:  85%|████████▌ | 227/266 [10:15<01:15,  1.94s/it]predicting train subjects:  86%|████████▌ | 228/266 [10:17<01:13,  1.94s/it]predicting train subjects:  86%|████████▌ | 229/266 [10:19<01:12,  1.95s/it]predicting train subjects:  86%|████████▋ | 230/266 [10:21<01:10,  1.95s/it]predicting train subjects:  87%|████████▋ | 231/266 [10:23<01:07,  1.94s/it]predicting train subjects:  87%|████████▋ | 232/266 [10:25<01:05,  1.93s/it]predicting train subjects:  88%|████████▊ | 233/266 [10:27<01:03,  1.93s/it]predicting train subjects:  88%|████████▊ | 234/266 [10:29<01:01,  1.94s/it]predicting train subjects:  88%|████████▊ | 235/266 [10:31<01:00,  1.96s/it]predicting train subjects:  89%|████████▊ | 236/266 [10:33<00:59,  1.97s/it]predicting train subjects:  89%|████████▉ | 237/266 [10:35<00:56,  1.96s/it]predicting train subjects:  89%|████████▉ | 238/266 [10:37<00:55,  1.97s/it]predicting train subjects:  90%|████████▉ | 239/266 [10:39<00:53,  1.97s/it]predicting train subjects:  90%|█████████ | 240/266 [10:41<00:50,  1.93s/it]predicting train subjects:  91%|█████████ | 241/266 [10:43<00:48,  1.92s/it]predicting train subjects:  91%|█████████ | 242/266 [10:45<00:46,  1.93s/it]predicting train subjects:  91%|█████████▏| 243/266 [10:46<00:44,  1.93s/it]predicting train subjects:  92%|█████████▏| 244/266 [10:48<00:42,  1.94s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:50<00:40,  1.94s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:52<00:39,  1.95s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:54<00:37,  1.95s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:56<00:35,  1.95s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:59<00:36,  2.13s/it]predicting train subjects:  94%|█████████▍| 250/266 [11:01<00:35,  2.23s/it]predicting train subjects:  94%|█████████▍| 251/266 [11:04<00:34,  2.32s/it]predicting train subjects:  95%|█████████▍| 252/266 [11:06<00:33,  2.40s/it]predicting train subjects:  95%|█████████▌| 253/266 [11:09<00:31,  2.44s/it]predicting train subjects:  95%|█████████▌| 254/266 [11:11<00:29,  2.46s/it]predicting train subjects:  96%|█████████▌| 255/266 [11:14<00:27,  2.45s/it]predicting train subjects:  96%|█████████▌| 256/266 [11:16<00:24,  2.47s/it]predicting train subjects:  97%|█████████▋| 257/266 [11:19<00:22,  2.50s/it]predicting train subjects:  97%|█████████▋| 258/266 [11:22<00:20,  2.52s/it]predicting train subjects:  97%|█████████▋| 259/266 [11:24<00:17,  2.53s/it]predicting train subjects:  98%|█████████▊| 260/266 [11:27<00:15,  2.53s/it]predicting train subjects:  98%|█████████▊| 261/266 [11:29<00:12,  2.52s/it]predicting train subjects:  98%|█████████▊| 262/266 [11:32<00:10,  2.50s/it]predicting train subjects:  99%|█████████▉| 263/266 [11:34<00:07,  2.51s/it]predicting train subjects:  99%|█████████▉| 264/266 [11:37<00:05,  2.52s/it]predicting train subjects: 100%|█████████▉| 265/266 [11:39<00:02,  2.52s/it]predicting train subjects: 100%|██████████| 266/266 [11:42<00:00,  2.51s/it]

Epoch 00052: val_mDice did not improve from 0.62425
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [0.8409496913217518, 0.4939621650192836, 0.5133563590376344, 0.4956827486214572, 0.4764079210692889, 0.49399986128284507, 0.7457608613249374, 0.4946316382656359, 0.479874412082646, 0.5096690193431018, 0.4724495623209705, 0.4542737362319476, 0.4992505556916537, 0.49716146269889727, 0.4789642418084079, 0.4693601617257889, 0.49934139153728746, 0.4932764527732379, 0.479859613800702, 0.4815952822770158, 0.5693006887011332, 0.45783546117887103, 0.47406347238854185, 0.5495971102420598, 0.49411172205454684, 0.4790477483239892, 0.5192819813342944, 0.4928738972912096, 0.49059296144198067, 0.48330587638567574, 0.4770119206546104, 0.4708507236552565, 0.5315919726678769, 0.46904407053777614, 0.47653808332469366, 0.4779930984320706, 0.4569273652279214, 0.481214361239786, 0.48324402554394447, 0.5062841099419005, 0.49879187508805156, 0.476867381432285, 0.49389203484744243, 0.5071064899229023, 0.49496838123831033, 0.49668828102007306, 0.5457224225344723, 0.4680643608308818, 0.4952747744240173, 0.4753741515825873, 0.46531453565375447, 0.47858256632334567], 'val_acc': [0.9175347293892951, 0.938702693540756, 0.9397882067993896, 0.9411794641246535, 0.9398799367146949, 0.9389524165898153, 0.9107074966169384, 0.9419812568246502, 0.9408227401236965, 0.9407598988650596, 0.9439925755539985, 0.9442355134715773, 0.941123415346015, 0.9449455754397666, 0.9440503504178296, 0.9418912619760592, 0.9422326781978346, 0.9432790867269856, 0.9439280376042405, 0.944609233777817, 0.9365351126618582, 0.9446907492533122, 0.9446414913216682, 0.9332225853449678, 0.9417689344654344, 0.942156242997679, 0.9432434211038563, 0.9381913779533073, 0.9423787789802028, 0.9436698041550101, 0.9403029100535667, 0.9441947406285429, 0.9440452333999007, 0.944819887206979, 0.9412406274717148, 0.9442864672778404, 0.9438617662207721, 0.9420441372753823, 0.9429291739855727, 0.9425452612850764, 0.9427168205992816, 0.9442083108915041, 0.9409960067435487, 0.9420475167770909, 0.9420305531318873, 0.9420984901794015, 0.9422717600652616, 0.9416347276674558, 0.944998221038139, 0.9452581283164351, 0.9452360517358127, 0.9434252242519431], 'val_mDice': [0.4633460600082188, 0.5978268099157777, 0.5914591673302324, 0.6002725795523761, 0.6126503544311, 0.6041411765634197, 0.5090192862569469, 0.601759721155036, 0.6104201527491008, 0.5948058905666822, 0.6154495126580539, 0.6242543099677726, 0.6010452459936273, 0.602927612115259, 0.6128507158527635, 0.6165050039552662, 0.6025111160866202, 0.6027835860644302, 0.6122759596942222, 0.6132442469466223, 0.5673053044162385, 0.6214048005130193, 0.6180687767185576, 0.575830246487709, 0.6040311463891643, 0.6124190132911891, 0.5948322423516887, 0.6006225633294615, 0.6092279226812598, 0.612427241181674, 0.612061471971747, 0.6144161167210096, 0.5868341783954673, 0.6186964356735961, 0.6136935835015284, 0.6170386533214621, 0.6234931398744452, 0.6162965134398578, 0.6115310755494523, 0.6006012395636676, 0.6022496141799508, 0.613143262797839, 0.6052588616331963, 0.5947714652100654, 0.6031481027603149, 0.6039839280794744, 0.5857621006769677, 0.6180763628384839, 0.6049720179544736, 0.6202418199957234, 0.6217941919418231, 0.6141407702067126], 'loss': [1.6457944851407658, 0.615971591471926, 0.49080575596653037, 0.4287688177322019, 0.4024393832154159, 0.37961950061501537, 0.36341433740578716, 0.3542332101285685, 0.33186732491296667, 0.32361286818532226, 0.31292631908497626, 0.303649439184817, 0.3025604766968189, 0.2962745805169393, 0.284784843374649, 0.28069320744081894, 0.2766134391573326, 0.2691935753998406, 0.2682047035903319, 0.2608906502279647, 0.3406535061671171, 0.2794321550060529, 0.26360973618559486, 0.25765703962376985, 0.256181916597129, 0.24867764426242064, 0.24518033286357455, 0.2516578488750816, 0.2454232650791772, 0.23854467712374078, 0.24418217431166092, 0.23518926658812747, 0.23742851343253324, 0.23653078998393373, 0.23822364590935985, 0.23312440221001582, 0.22756703957225857, 0.2240725490493713, 0.22159136727832715, 0.21866975383470288, 0.2196537787685956, 0.2190916060404361, 0.21647855100578772, 0.22179241625661897, 0.2156495046740372, 0.21354628596055839, 0.21177776639888074, 0.21352815308834863, 0.2094187515085485, 0.2099095171609527, 0.20783244921866548, 0.20645348189115686], 'acc': [0.7522651842353201, 0.9087816879822296, 0.9259738008488324, 0.9323573385527558, 0.9351343045982843, 0.9375882354499099, 0.9391737862492942, 0.9400426304224919, 0.9418370147618041, 0.9428289329995151, 0.9437382921516738, 0.9446987434339817, 0.9451847547224493, 0.9455382309873709, 0.9464012068229611, 0.9469491547886597, 0.947318108606791, 0.9480042738899563, 0.9481881182743916, 0.9489038548951838, 0.9418875034933137, 0.9470649509178989, 0.9485614395626695, 0.9493791417729, 0.9493459777322217, 0.9501409233228622, 0.9505150955063623, 0.9501657932515738, 0.9502370936185148, 0.9510525648845545, 0.9511247146016497, 0.9514489100367242, 0.9516218384044762, 0.9513868251437371, 0.9512491734319618, 0.9517433358115669, 0.9522582174548545, 0.9525934040085812, 0.9527571380843881, 0.9530201201498141, 0.9529809157558935, 0.9530043748625452, 0.9532438499417007, 0.9529684720691911, 0.9534701572802743, 0.9535794240218208, 0.9538340144785699, 0.953695488118337, 0.9540399394657565, 0.9539375343715026, 0.9542346792970632, 0.95436112807593], 'mDice': [0.28133418098723223, 0.5287527635607551, 0.5980896421413091, 0.6371508930208258, 0.6542731686824573, 0.6700262943732579, 0.6818706800790025, 0.6881999345449835, 0.7036691971467943, 0.7097917277670928, 0.717579707735079, 0.724615707680121, 0.7274856744511748, 0.7302458764673457, 0.7387049344494818, 0.7421129633684652, 0.7451942735987961, 0.7509623808682601, 0.7519352571740141, 0.7576070017139704, 0.7024985674215158, 0.7428425401551236, 0.7552218437253129, 0.7613985884169783, 0.7612870096647261, 0.7672906637914748, 0.7701456696217767, 0.7679131705502317, 0.769863345350618, 0.7754328189082287, 0.775707814332663, 0.7781870725464357, 0.7787616721550382, 0.777217120669726, 0.7758657897240516, 0.7798858517759947, 0.7844095974825348, 0.7873678486442585, 0.7893940691470773, 0.7918483545131136, 0.7910149772549916, 0.7914924045650621, 0.7936393521973196, 0.7894437490325379, 0.794350060309541, 0.796094879063447, 0.7975987794638776, 0.7962412595352432, 0.799555075958052, 0.7991566621987866, 0.8009905011572507, 0.8021406712369258]}
