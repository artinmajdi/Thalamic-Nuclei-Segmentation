2020-01-21 17:27:06.845769: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 17:27:08.937589: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 17:27:08.937653: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 17:27:09.358318: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 17:27:09.358393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 17:27:09.358405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 17:27:09.358893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<05:26,  1.33s/it]Loading train:   1%|          | 2/247 [00:02<04:58,  1.22s/it]Loading train:   1%|          | 3/247 [00:03<04:23,  1.08s/it]Loading train:   2%|▏         | 4/247 [00:03<03:55,  1.03it/s]Loading train:   2%|▏         | 5/247 [00:04<03:37,  1.11it/s]Loading train:   2%|▏         | 6/247 [00:05<03:25,  1.17it/s]Loading train:   3%|▎         | 7/247 [00:05<03:09,  1.27it/s]Loading train:   3%|▎         | 8/247 [00:06<02:57,  1.35it/s]Loading train:   4%|▎         | 9/247 [00:07<02:56,  1.35it/s]Loading train:   4%|▍         | 10/247 [00:07<02:44,  1.44it/s]Loading train:   4%|▍         | 11/247 [00:08<02:40,  1.47it/s]Loading train:   5%|▍         | 12/247 [00:09<02:35,  1.51it/s]Loading train:   5%|▌         | 13/247 [00:09<02:29,  1.56it/s]Loading train:   6%|▌         | 14/247 [00:10<02:28,  1.57it/s]Loading train:   6%|▌         | 15/247 [00:10<02:25,  1.59it/s]Loading train:   6%|▋         | 16/247 [00:11<02:22,  1.63it/s]Loading train:   7%|▋         | 17/247 [00:12<02:22,  1.62it/s]Loading train:   7%|▋         | 18/247 [00:12<02:27,  1.56it/s]Loading train:   8%|▊         | 19/247 [00:13<02:22,  1.60it/s]Loading train:   8%|▊         | 20/247 [00:14<02:22,  1.59it/s]Loading train:   9%|▊         | 21/247 [00:14<02:23,  1.58it/s]Loading train:   9%|▉         | 22/247 [00:15<02:23,  1.57it/s]Loading train:   9%|▉         | 23/247 [00:15<02:22,  1.58it/s]Loading train:  10%|▉         | 24/247 [00:16<02:21,  1.58it/s]Loading train:  10%|█         | 25/247 [00:17<02:18,  1.60it/s]Loading train:  11%|█         | 26/247 [00:17<02:24,  1.53it/s]Loading train:  11%|█         | 27/247 [00:18<02:20,  1.56it/s]Loading train:  11%|█▏        | 28/247 [00:19<02:20,  1.56it/s]Loading train:  12%|█▏        | 29/247 [00:19<02:17,  1.59it/s]Loading train:  12%|█▏        | 30/247 [00:20<02:16,  1.59it/s]Loading train:  13%|█▎        | 31/247 [00:21<02:16,  1.59it/s]Loading train:  13%|█▎        | 32/247 [00:21<02:15,  1.58it/s]Loading train:  13%|█▎        | 33/247 [00:22<02:14,  1.60it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:09,  1.65it/s]Loading train:  14%|█▍        | 35/247 [00:23<02:09,  1.64it/s]Loading train:  15%|█▍        | 36/247 [00:24<02:05,  1.68it/s]Loading train:  15%|█▍        | 37/247 [00:24<02:04,  1.68it/s]Loading train:  15%|█▌        | 38/247 [00:25<02:06,  1.65it/s]Loading train:  16%|█▌        | 39/247 [00:25<02:02,  1.70it/s]Loading train:  16%|█▌        | 40/247 [00:26<02:03,  1.68it/s]Loading train:  17%|█▋        | 41/247 [00:26<01:57,  1.75it/s]Loading train:  17%|█▋        | 42/247 [00:27<01:55,  1.78it/s]Loading train:  17%|█▋        | 43/247 [00:28<01:58,  1.72it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:01,  1.66it/s]Loading train:  18%|█▊        | 45/247 [00:29<02:01,  1.66it/s]Loading train:  19%|█▊        | 46/247 [00:30<02:03,  1.62it/s]Loading train:  19%|█▉        | 47/247 [00:30<02:01,  1.65it/s]Loading train:  19%|█▉        | 48/247 [00:31<02:02,  1.62it/s]Loading train:  20%|█▉        | 49/247 [00:31<02:02,  1.62it/s]Loading train:  20%|██        | 50/247 [00:32<02:00,  1.64it/s]Loading train:  21%|██        | 51/247 [00:33<02:01,  1.62it/s]Loading train:  21%|██        | 52/247 [00:33<01:55,  1.68it/s]Loading train:  21%|██▏       | 53/247 [00:34<01:51,  1.74it/s]Loading train:  22%|██▏       | 54/247 [00:34<01:51,  1.74it/s]Loading train:  22%|██▏       | 55/247 [00:35<01:59,  1.60it/s]Loading train:  23%|██▎       | 56/247 [00:36<01:58,  1.61it/s]Loading train:  23%|██▎       | 57/247 [00:36<02:02,  1.55it/s]Loading train:  23%|██▎       | 58/247 [00:37<02:01,  1.56it/s]Loading train:  24%|██▍       | 59/247 [00:38<01:57,  1.61it/s]Loading train:  24%|██▍       | 60/247 [00:38<01:59,  1.57it/s]Loading train:  25%|██▍       | 61/247 [00:39<02:00,  1.55it/s]Loading train:  25%|██▌       | 62/247 [00:39<01:59,  1.54it/s]Loading train:  26%|██▌       | 63/247 [00:40<01:56,  1.58it/s]Loading train:  26%|██▌       | 64/247 [00:41<01:54,  1.60it/s]Loading train:  26%|██▋       | 65/247 [00:41<01:54,  1.58it/s]Loading train:  27%|██▋       | 66/247 [00:42<01:57,  1.54it/s]Loading train:  27%|██▋       | 67/247 [00:43<01:55,  1.56it/s]Loading train:  28%|██▊       | 68/247 [00:43<01:54,  1.56it/s]Loading train:  28%|██▊       | 69/247 [00:44<01:53,  1.56it/s]Loading train:  28%|██▊       | 70/247 [00:45<01:53,  1.56it/s]Loading train:  29%|██▊       | 71/247 [00:45<01:53,  1.56it/s]Loading train:  29%|██▉       | 72/247 [00:46<01:54,  1.53it/s]Loading train:  30%|██▉       | 73/247 [00:47<01:52,  1.55it/s]Loading train:  30%|██▉       | 74/247 [00:47<01:48,  1.60it/s]Loading train:  30%|███       | 75/247 [00:48<01:48,  1.59it/s]Loading train:  31%|███       | 76/247 [00:48<01:48,  1.57it/s]Loading train:  31%|███       | 77/247 [00:49<01:48,  1.57it/s]Loading train:  32%|███▏      | 78/247 [00:50<02:11,  1.28it/s]Loading train:  32%|███▏      | 79/247 [00:51<02:03,  1.36it/s]Loading train:  32%|███▏      | 80/247 [00:51<01:45,  1.58it/s]Loading train:  33%|███▎      | 81/247 [00:52<01:43,  1.60it/s]Loading train:  33%|███▎      | 82/247 [00:52<01:40,  1.64it/s]Loading train:  34%|███▎      | 83/247 [00:53<01:40,  1.63it/s]Loading train:  34%|███▍      | 84/247 [00:54<01:41,  1.61it/s]Loading train:  34%|███▍      | 85/247 [00:54<01:38,  1.64it/s]Loading train:  35%|███▍      | 86/247 [00:55<01:39,  1.62it/s]Loading train:  35%|███▌      | 87/247 [00:55<01:40,  1.60it/s]Loading train:  36%|███▌      | 88/247 [00:56<01:38,  1.62it/s]Loading train:  36%|███▌      | 89/247 [00:57<01:37,  1.62it/s]Loading train:  36%|███▋      | 90/247 [00:57<01:36,  1.63it/s]Loading train:  37%|███▋      | 91/247 [00:58<01:37,  1.60it/s]Loading train:  37%|███▋      | 92/247 [00:59<01:36,  1.61it/s]Loading train:  38%|███▊      | 93/247 [00:59<01:34,  1.63it/s]Loading train:  38%|███▊      | 94/247 [01:00<01:35,  1.60it/s]Loading train:  38%|███▊      | 95/247 [01:00<01:37,  1.56it/s]Loading train:  39%|███▉      | 96/247 [01:01<01:34,  1.60it/s]Loading train:  39%|███▉      | 97/247 [01:02<01:34,  1.59it/s]Loading train:  40%|███▉      | 98/247 [01:02<01:31,  1.63it/s]Loading train:  40%|████      | 99/247 [01:03<01:32,  1.61it/s]Loading train:  40%|████      | 100/247 [01:04<01:34,  1.55it/s]Loading train:  41%|████      | 101/247 [01:04<01:38,  1.48it/s]Loading train:  41%|████▏     | 102/247 [01:05<01:38,  1.47it/s]Loading train:  42%|████▏     | 103/247 [01:06<01:39,  1.44it/s]Loading train:  42%|████▏     | 104/247 [01:07<01:42,  1.40it/s]Loading train:  43%|████▎     | 105/247 [01:07<01:38,  1.44it/s]Loading train:  43%|████▎     | 106/247 [01:08<01:39,  1.41it/s]Loading train:  43%|████▎     | 107/247 [01:09<01:36,  1.46it/s]Loading train:  44%|████▎     | 108/247 [01:09<01:36,  1.45it/s]Loading train:  44%|████▍     | 109/247 [01:10<01:38,  1.40it/s]Loading train:  45%|████▍     | 110/247 [01:11<01:39,  1.38it/s]Loading train:  45%|████▍     | 111/247 [01:11<01:32,  1.46it/s]Loading train:  45%|████▌     | 112/247 [01:12<01:32,  1.45it/s]Loading train:  46%|████▌     | 113/247 [01:13<01:32,  1.45it/s]Loading train:  46%|████▌     | 114/247 [01:13<01:31,  1.45it/s]Loading train:  47%|████▋     | 115/247 [01:14<01:31,  1.45it/s]Loading train:  47%|████▋     | 116/247 [01:15<01:30,  1.44it/s]Loading train:  47%|████▋     | 117/247 [01:16<01:30,  1.43it/s]Loading train:  48%|████▊     | 118/247 [01:16<01:27,  1.48it/s]Loading train:  48%|████▊     | 119/247 [01:17<01:24,  1.51it/s]Loading train:  49%|████▊     | 120/247 [01:17<01:23,  1.52it/s]Loading train:  49%|████▉     | 121/247 [01:18<01:15,  1.67it/s]Loading train:  49%|████▉     | 122/247 [01:18<01:13,  1.71it/s]Loading train:  50%|████▉     | 123/247 [01:19<01:14,  1.66it/s]Loading train:  50%|█████     | 124/247 [01:20<01:15,  1.63it/s]Loading train:  51%|█████     | 125/247 [01:20<01:13,  1.65it/s]Loading train:  51%|█████     | 126/247 [01:21<01:14,  1.63it/s]Loading train:  51%|█████▏    | 127/247 [01:22<01:14,  1.61it/s]Loading train:  52%|█████▏    | 128/247 [01:22<01:12,  1.64it/s]Loading train:  52%|█████▏    | 129/247 [01:23<01:11,  1.65it/s]Loading train:  53%|█████▎    | 130/247 [01:23<01:11,  1.63it/s]Loading train:  53%|█████▎    | 131/247 [01:24<01:12,  1.60it/s]Loading train:  53%|█████▎    | 132/247 [01:25<01:12,  1.58it/s]Loading train:  54%|█████▍    | 133/247 [01:25<01:08,  1.66it/s]Loading train:  54%|█████▍    | 134/247 [01:26<01:09,  1.62it/s]Loading train:  55%|█████▍    | 135/247 [01:27<01:09,  1.61it/s]Loading train:  55%|█████▌    | 136/247 [01:27<01:05,  1.69it/s]Loading train:  55%|█████▌    | 137/247 [01:28<01:03,  1.73it/s]Loading train:  56%|█████▌    | 138/247 [01:28<00:59,  1.83it/s]Loading train:  56%|█████▋    | 139/247 [01:29<00:56,  1.90it/s]Loading train:  57%|█████▋    | 140/247 [01:29<00:56,  1.89it/s]Loading train:  57%|█████▋    | 141/247 [01:30<00:56,  1.87it/s]Loading train:  57%|█████▋    | 142/247 [01:30<00:56,  1.87it/s]Loading train:  58%|█████▊    | 143/247 [01:31<00:56,  1.84it/s]Loading train:  58%|█████▊    | 144/247 [01:31<00:54,  1.90it/s]Loading train:  59%|█████▊    | 145/247 [01:32<00:52,  1.94it/s]Loading train:  59%|█████▉    | 146/247 [01:32<00:52,  1.92it/s]Loading train:  60%|█████▉    | 147/247 [01:33<00:49,  2.02it/s]Loading train:  60%|█████▉    | 148/247 [01:33<00:50,  1.97it/s]Loading train:  60%|██████    | 149/247 [01:34<00:52,  1.88it/s]Loading train:  61%|██████    | 150/247 [01:34<00:50,  1.93it/s]Loading train:  61%|██████    | 151/247 [01:35<00:50,  1.88it/s]Loading train:  62%|██████▏   | 152/247 [01:35<00:51,  1.84it/s]Loading train:  62%|██████▏   | 153/247 [01:36<00:52,  1.78it/s]Loading train:  62%|██████▏   | 154/247 [01:37<00:55,  1.69it/s]Loading train:  63%|██████▎   | 155/247 [01:37<00:54,  1.69it/s]Loading train:  63%|██████▎   | 156/247 [01:38<00:52,  1.74it/s]Loading train:  64%|██████▎   | 157/247 [01:38<00:53,  1.68it/s]Loading train:  64%|██████▍   | 158/247 [01:39<00:53,  1.68it/s]Loading train:  64%|██████▍   | 159/247 [01:40<00:52,  1.69it/s]Loading train:  65%|██████▍   | 160/247 [01:40<00:51,  1.70it/s]Loading train:  65%|██████▌   | 161/247 [01:41<00:50,  1.69it/s]Loading train:  66%|██████▌   | 162/247 [01:41<00:51,  1.64it/s]Loading train:  66%|██████▌   | 163/247 [01:42<00:51,  1.63it/s]Loading train:  66%|██████▋   | 164/247 [01:43<00:49,  1.68it/s]Loading train:  67%|██████▋   | 165/247 [01:43<00:50,  1.63it/s]Loading train:  67%|██████▋   | 166/247 [01:44<00:50,  1.61it/s]Loading train:  68%|██████▊   | 167/247 [01:45<00:49,  1.63it/s]Loading train:  68%|██████▊   | 168/247 [01:45<00:48,  1.64it/s]Loading train:  68%|██████▊   | 169/247 [01:46<00:48,  1.62it/s]Loading train:  69%|██████▉   | 170/247 [01:46<00:45,  1.68it/s]Loading train:  69%|██████▉   | 171/247 [01:47<00:45,  1.67it/s]Loading train:  70%|██████▉   | 172/247 [01:48<00:44,  1.68it/s]Loading train:  70%|███████   | 173/247 [01:48<00:44,  1.68it/s]Loading train:  70%|███████   | 174/247 [01:49<00:44,  1.63it/s]Loading train:  71%|███████   | 175/247 [01:50<00:46,  1.55it/s]Loading train:  71%|███████▏  | 176/247 [01:50<00:45,  1.57it/s]Loading train:  72%|███████▏  | 177/247 [01:51<00:43,  1.59it/s]Loading train:  72%|███████▏  | 178/247 [01:51<00:42,  1.61it/s]Loading train:  72%|███████▏  | 179/247 [01:52<00:42,  1.59it/s]Loading train:  73%|███████▎  | 180/247 [01:53<00:41,  1.63it/s]Loading train:  73%|███████▎  | 181/247 [01:53<00:39,  1.65it/s]Loading train:  74%|███████▎  | 182/247 [01:54<00:40,  1.62it/s]Loading train:  74%|███████▍  | 183/247 [01:54<00:37,  1.70it/s]Loading train:  74%|███████▍  | 184/247 [01:55<00:37,  1.66it/s]Loading train:  75%|███████▍  | 185/247 [01:56<00:36,  1.68it/s]Loading train:  75%|███████▌  | 186/247 [01:56<00:36,  1.67it/s]Loading train:  76%|███████▌  | 187/247 [01:57<00:35,  1.68it/s]Loading train:  76%|███████▌  | 188/247 [01:57<00:35,  1.68it/s]Loading train:  77%|███████▋  | 189/247 [01:58<00:35,  1.63it/s]Loading train:  77%|███████▋  | 190/247 [01:59<00:34,  1.65it/s]Loading train:  77%|███████▋  | 191/247 [01:59<00:33,  1.66it/s]Loading train:  78%|███████▊  | 192/247 [02:00<00:33,  1.64it/s]Loading train:  78%|███████▊  | 193/247 [02:00<00:32,  1.66it/s]Loading train:  79%|███████▊  | 194/247 [02:01<00:31,  1.67it/s]Loading train:  79%|███████▉  | 195/247 [02:02<00:31,  1.67it/s]Loading train:  79%|███████▉  | 196/247 [02:02<00:30,  1.67it/s]Loading train:  80%|███████▉  | 197/247 [02:03<00:30,  1.64it/s]Loading train:  80%|████████  | 198/247 [02:03<00:28,  1.69it/s]Loading train:  81%|████████  | 199/247 [02:04<00:27,  1.71it/s]Loading train:  81%|████████  | 200/247 [02:05<00:27,  1.71it/s]Loading train:  81%|████████▏ | 201/247 [02:05<00:27,  1.70it/s]Loading train:  82%|████████▏ | 202/247 [02:06<00:27,  1.66it/s]Loading train:  82%|████████▏ | 203/247 [02:06<00:26,  1.67it/s]Loading train:  83%|████████▎ | 204/247 [02:07<00:25,  1.71it/s]Loading train:  83%|████████▎ | 205/247 [02:07<00:23,  1.76it/s]Loading train:  83%|████████▎ | 206/247 [02:08<00:24,  1.70it/s]Loading train:  84%|████████▍ | 207/247 [02:09<00:23,  1.69it/s]Loading train:  84%|████████▍ | 208/247 [02:09<00:21,  1.79it/s]Loading train:  85%|████████▍ | 209/247 [02:10<00:21,  1.79it/s]Loading train:  85%|████████▌ | 210/247 [02:10<00:20,  1.77it/s]Loading train:  85%|████████▌ | 211/247 [02:11<00:20,  1.73it/s]Loading train:  86%|████████▌ | 212/247 [02:11<00:20,  1.72it/s]Loading train:  86%|████████▌ | 213/247 [02:12<00:20,  1.66it/s]Loading train:  87%|████████▋ | 214/247 [02:13<00:20,  1.64it/s]Loading train:  87%|████████▋ | 215/247 [02:13<00:19,  1.61it/s]Loading train:  87%|████████▋ | 216/247 [02:14<00:19,  1.62it/s]Loading train:  88%|████████▊ | 217/247 [02:15<00:18,  1.59it/s]Loading train:  88%|████████▊ | 218/247 [02:15<00:17,  1.65it/s]Loading train:  89%|████████▊ | 219/247 [02:16<00:16,  1.66it/s]Loading train:  89%|████████▉ | 220/247 [02:16<00:16,  1.64it/s]Loading train:  89%|████████▉ | 221/247 [02:17<00:15,  1.67it/s]Loading train:  90%|████████▉ | 222/247 [02:18<00:15,  1.64it/s]Loading train:  90%|█████████ | 223/247 [02:18<00:14,  1.65it/s]Loading train:  91%|█████████ | 224/247 [02:19<00:13,  1.68it/s]Loading train:  91%|█████████ | 225/247 [02:19<00:13,  1.64it/s]Loading train:  91%|█████████▏| 226/247 [02:20<00:12,  1.64it/s]Loading train:  92%|█████████▏| 227/247 [02:21<00:12,  1.62it/s]Loading train:  92%|█████████▏| 228/247 [02:21<00:11,  1.65it/s]Loading train:  93%|█████████▎| 229/247 [02:22<00:10,  1.65it/s]Loading train:  93%|█████████▎| 230/247 [02:22<00:10,  1.65it/s]Loading train:  94%|█████████▎| 231/247 [02:23<00:09,  1.60it/s]Loading train:  94%|█████████▍| 232/247 [02:24<00:09,  1.57it/s]Loading train:  94%|█████████▍| 233/247 [02:24<00:08,  1.57it/s]Loading train:  95%|█████████▍| 234/247 [02:25<00:08,  1.51it/s]Loading train:  95%|█████████▌| 235/247 [02:26<00:07,  1.52it/s]Loading train:  96%|█████████▌| 236/247 [02:26<00:07,  1.56it/s]Loading train:  96%|█████████▌| 237/247 [02:27<00:06,  1.56it/s]Loading train:  96%|█████████▋| 238/247 [02:28<00:05,  1.55it/s]Loading train:  97%|█████████▋| 239/247 [02:28<00:05,  1.51it/s]Loading train:  97%|█████████▋| 240/247 [02:29<00:04,  1.52it/s]Loading train:  98%|█████████▊| 241/247 [02:30<00:03,  1.52it/s]Loading train:  98%|█████████▊| 242/247 [02:30<00:03,  1.55it/s]Loading train:  98%|█████████▊| 243/247 [02:31<00:02,  1.59it/s]Loading train:  99%|█████████▉| 244/247 [02:32<00:01,  1.50it/s]Loading train:  99%|█████████▉| 245/247 [02:32<00:01,  1.47it/s]Loading train: 100%|█████████▉| 246/247 [02:33<00:00,  1.49it/s]Loading train: 100%|██████████| 247/247 [02:34<00:00,  1.47it/s]Loading train: 100%|██████████| 247/247 [02:34<00:00,  1.60it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.39it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 47.42it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 47.42it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 47.34it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 46.86it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 47.09it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 47.32it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 47.57it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 47.55it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 47.51it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:04, 47.73it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 47.93it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 47.82it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 48.03it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 48.40it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:03, 48.60it/s]concatenating: train:  35%|███▍      | 86/247 [00:01<00:03, 49.24it/s]concatenating: train:  37%|███▋      | 92/247 [00:01<00:03, 49.58it/s]concatenating: train:  40%|███▉      | 98/247 [00:02<00:02, 49.87it/s]concatenating: train:  42%|████▏     | 103/247 [00:02<00:02, 48.01it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:03, 46.27it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:02, 44.91it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 44.32it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 43.48it/s]concatenating: train:  52%|█████▏    | 128/247 [00:02<00:02, 44.51it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:02, 45.18it/s]concatenating: train:  56%|█████▋    | 139/247 [00:02<00:02, 46.70it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 48.23it/s]concatenating: train:  61%|██████    | 151/247 [00:03<00:01, 49.71it/s]concatenating: train:  64%|██████▎   | 157/247 [00:03<00:01, 49.61it/s]concatenating: train:  66%|██████▌   | 162/247 [00:03<00:01, 49.56it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:01, 49.55it/s]concatenating: train:  70%|██████▉   | 172/247 [00:03<00:01, 49.54it/s]concatenating: train:  72%|███████▏  | 177/247 [00:03<00:01, 49.25it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:01, 49.47it/s]concatenating: train:  76%|███████▌  | 188/247 [00:03<00:01, 49.61it/s]concatenating: train:  78%|███████▊  | 193/247 [00:04<00:01, 49.63it/s]concatenating: train:  81%|████████  | 199/247 [00:04<00:00, 49.99it/s]concatenating: train:  83%|████████▎ | 205/247 [00:04<00:00, 50.25it/s]concatenating: train:  85%|████████▌ | 211/247 [00:04<00:00, 50.45it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 49.97it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 49.58it/s]concatenating: train:  92%|█████████▏| 227/247 [00:04<00:00, 48.97it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 48.05it/s]concatenating: train:  97%|█████████▋| 239/247 [00:04<00:00, 52.34it/s]concatenating: train: 100%|█████████▉| 246/247 [00:05<00:00, 55.93it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 49.00it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.32it/s]Loading test:  40%|████      | 2/5 [00:01<00:02,  1.32it/s]Loading test:  60%|██████    | 3/5 [00:02<00:01,  1.43it/s]Loading test:  80%|████████  | 4/5 [00:02<00:00,  1.48it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]Loading test: 100%|██████████| 5/5 [00:03<00:00,  1.47it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 63.06it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<02:44,  1.50it/s]Loading trainS:   1%|          | 2/247 [00:01<02:43,  1.50it/s]Loading trainS:   1%|          | 3/247 [00:01<02:37,  1.55it/s]Loading trainS:   2%|▏         | 4/247 [00:02<02:30,  1.61it/s]Loading trainS:   2%|▏         | 5/247 [00:03<02:32,  1.59it/s]Loading trainS:   2%|▏         | 6/247 [00:03<02:27,  1.64it/s]Loading trainS:   3%|▎         | 7/247 [00:04<02:26,  1.63it/s]Loading trainS:   3%|▎         | 8/247 [00:04<02:24,  1.66it/s]Loading trainS:   4%|▎         | 9/247 [00:05<02:26,  1.63it/s]Loading trainS:   4%|▍         | 10/247 [00:06<02:28,  1.60it/s]Loading trainS:   4%|▍         | 11/247 [00:06<02:28,  1.59it/s]Loading trainS:   5%|▍         | 12/247 [00:07<02:25,  1.61it/s]Loading trainS:   5%|▌         | 13/247 [00:07<02:19,  1.68it/s]Loading trainS:   6%|▌         | 14/247 [00:08<02:24,  1.62it/s]Loading trainS:   6%|▌         | 15/247 [00:09<02:25,  1.59it/s]Loading trainS:   6%|▋         | 16/247 [00:09<02:25,  1.59it/s]Loading trainS:   7%|▋         | 17/247 [00:10<02:19,  1.64it/s]Loading trainS:   7%|▋         | 18/247 [00:11<02:18,  1.65it/s]Loading trainS:   8%|▊         | 19/247 [00:11<02:16,  1.67it/s]Loading trainS:   8%|▊         | 20/247 [00:12<02:15,  1.68it/s]Loading trainS:   9%|▊         | 21/247 [00:12<02:18,  1.64it/s]Loading trainS:   9%|▉         | 22/247 [00:13<02:27,  1.52it/s]Loading trainS:   9%|▉         | 23/247 [00:14<02:18,  1.62it/s]Loading trainS:  10%|▉         | 24/247 [00:14<02:16,  1.64it/s]Loading trainS:  10%|█         | 25/247 [00:15<02:14,  1.65it/s]Loading trainS:  11%|█         | 26/247 [00:15<02:12,  1.67it/s]Loading trainS:  11%|█         | 27/247 [00:16<02:10,  1.69it/s]Loading trainS:  11%|█▏        | 28/247 [00:17<02:11,  1.67it/s]Loading trainS:  12%|█▏        | 29/247 [00:17<02:08,  1.69it/s]Loading trainS:  12%|█▏        | 30/247 [00:18<02:09,  1.67it/s]Loading trainS:  13%|█▎        | 31/247 [00:18<02:08,  1.67it/s]Loading trainS:  13%|█▎        | 32/247 [00:19<02:12,  1.62it/s]Loading trainS:  13%|█▎        | 33/247 [00:20<02:10,  1.64it/s]Loading trainS:  14%|█▍        | 34/247 [00:20<02:05,  1.70it/s]Loading trainS:  14%|█▍        | 35/247 [00:21<02:09,  1.64it/s]Loading trainS:  15%|█▍        | 36/247 [00:22<02:08,  1.64it/s]Loading trainS:  15%|█▍        | 37/247 [00:22<02:10,  1.61it/s]Loading trainS:  15%|█▌        | 38/247 [00:23<02:12,  1.58it/s]Loading trainS:  16%|█▌        | 39/247 [00:23<02:04,  1.67it/s]Loading trainS:  16%|█▌        | 40/247 [00:24<01:59,  1.73it/s]Loading trainS:  17%|█▋        | 41/247 [00:25<02:02,  1.68it/s]Loading trainS:  17%|█▋        | 42/247 [00:25<02:00,  1.70it/s]Loading trainS:  17%|█▋        | 43/247 [00:26<02:00,  1.69it/s]Loading trainS:  18%|█▊        | 44/247 [00:26<01:59,  1.69it/s]Loading trainS:  18%|█▊        | 45/247 [00:27<02:03,  1.64it/s]Loading trainS:  19%|█▊        | 46/247 [00:28<02:04,  1.61it/s]Loading trainS:  19%|█▉        | 47/247 [00:28<02:05,  1.60it/s]Loading trainS:  19%|█▉        | 48/247 [00:29<02:02,  1.62it/s]Loading trainS:  20%|█▉        | 49/247 [00:29<02:01,  1.63it/s]Loading trainS:  20%|██        | 50/247 [00:30<02:01,  1.62it/s]Loading trainS:  21%|██        | 51/247 [00:31<02:02,  1.60it/s]Loading trainS:  21%|██        | 52/247 [00:31<02:03,  1.58it/s]Loading trainS:  21%|██▏       | 53/247 [00:32<02:02,  1.58it/s]Loading trainS:  22%|██▏       | 54/247 [00:33<01:59,  1.62it/s]Loading trainS:  22%|██▏       | 55/247 [00:33<01:57,  1.64it/s]Loading trainS:  23%|██▎       | 56/247 [00:34<01:58,  1.61it/s]Loading trainS:  23%|██▎       | 57/247 [00:34<01:55,  1.64it/s]Loading trainS:  23%|██▎       | 58/247 [00:35<01:53,  1.66it/s]Loading trainS:  24%|██▍       | 59/247 [00:36<01:55,  1.62it/s]Loading trainS:  24%|██▍       | 60/247 [00:36<01:54,  1.63it/s]Loading trainS:  25%|██▍       | 61/247 [00:37<01:53,  1.64it/s]Loading trainS:  25%|██▌       | 62/247 [00:37<01:49,  1.69it/s]Loading trainS:  26%|██▌       | 63/247 [00:38<01:50,  1.67it/s]Loading trainS:  26%|██▌       | 64/247 [00:39<01:54,  1.60it/s]Loading trainS:  26%|██▋       | 65/247 [00:39<01:53,  1.60it/s]Loading trainS:  27%|██▋       | 66/247 [00:40<01:51,  1.63it/s]Loading trainS:  27%|██▋       | 67/247 [00:40<01:49,  1.65it/s]Loading trainS:  28%|██▊       | 68/247 [00:41<01:50,  1.62it/s]Loading trainS:  28%|██▊       | 69/247 [00:42<01:46,  1.66it/s]Loading trainS:  28%|██▊       | 70/247 [00:42<01:46,  1.66it/s]Loading trainS:  29%|██▊       | 71/247 [00:43<01:48,  1.62it/s]Loading trainS:  29%|██▉       | 72/247 [00:44<01:47,  1.62it/s]Loading trainS:  30%|██▉       | 73/247 [00:44<01:44,  1.66it/s]Loading trainS:  30%|██▉       | 74/247 [00:45<01:45,  1.64it/s]Loading trainS:  30%|███       | 75/247 [00:45<01:47,  1.61it/s]Loading trainS:  31%|███       | 76/247 [00:46<01:47,  1.59it/s]Loading trainS:  31%|███       | 77/247 [00:47<01:47,  1.58it/s]Loading trainS:  32%|███▏      | 78/247 [00:47<01:53,  1.49it/s]Loading trainS:  32%|███▏      | 79/247 [00:48<01:54,  1.46it/s]Loading trainS:  32%|███▏      | 80/247 [00:49<01:40,  1.66it/s]Loading trainS:  33%|███▎      | 81/247 [00:49<01:32,  1.79it/s]Loading trainS:  33%|███▎      | 82/247 [00:50<01:34,  1.75it/s]Loading trainS:  34%|███▎      | 83/247 [00:50<01:32,  1.78it/s]Loading trainS:  34%|███▍      | 84/247 [00:51<01:35,  1.70it/s]Loading trainS:  34%|███▍      | 85/247 [00:51<01:35,  1.70it/s]Loading trainS:  35%|███▍      | 86/247 [00:52<01:36,  1.67it/s]Loading trainS:  35%|███▌      | 87/247 [00:53<01:34,  1.70it/s]Loading trainS:  36%|███▌      | 88/247 [00:53<01:32,  1.73it/s]Loading trainS:  36%|███▌      | 89/247 [00:54<01:34,  1.68it/s]Loading trainS:  36%|███▋      | 90/247 [00:54<01:33,  1.68it/s]Loading trainS:  37%|███▋      | 91/247 [00:55<01:30,  1.72it/s]Loading trainS:  37%|███▋      | 92/247 [00:55<01:30,  1.72it/s]Loading trainS:  38%|███▊      | 93/247 [00:56<01:31,  1.69it/s]Loading trainS:  38%|███▊      | 94/247 [00:57<01:29,  1.71it/s]Loading trainS:  38%|███▊      | 95/247 [00:57<01:29,  1.71it/s]Loading trainS:  39%|███▉      | 96/247 [00:58<01:28,  1.72it/s]Loading trainS:  39%|███▉      | 97/247 [00:58<01:28,  1.69it/s]Loading trainS:  40%|███▉      | 98/247 [00:59<01:28,  1.68it/s]Loading trainS:  40%|████      | 99/247 [01:00<01:25,  1.73it/s]Loading trainS:  40%|████      | 100/247 [01:00<01:30,  1.62it/s]Loading trainS:  41%|████      | 101/247 [01:01<01:34,  1.54it/s]Loading trainS:  41%|████▏     | 102/247 [01:02<01:36,  1.51it/s]Loading trainS:  42%|████▏     | 103/247 [01:02<01:34,  1.52it/s]Loading trainS:  42%|████▏     | 104/247 [01:03<01:38,  1.46it/s]Loading trainS:  43%|████▎     | 105/247 [01:04<01:40,  1.41it/s]Loading trainS:  43%|████▎     | 106/247 [01:05<01:39,  1.42it/s]Loading trainS:  43%|████▎     | 107/247 [01:05<01:37,  1.43it/s]Loading trainS:  44%|████▎     | 108/247 [01:06<01:35,  1.45it/s]Loading trainS:  44%|████▍     | 109/247 [01:07<01:35,  1.45it/s]Loading trainS:  45%|████▍     | 110/247 [01:07<01:34,  1.44it/s]Loading trainS:  45%|████▍     | 111/247 [01:08<01:32,  1.47it/s]Loading trainS:  45%|████▌     | 112/247 [01:09<01:30,  1.49it/s]Loading trainS:  46%|████▌     | 113/247 [01:09<01:29,  1.50it/s]Loading trainS:  46%|████▌     | 114/247 [01:10<01:31,  1.45it/s]Loading trainS:  47%|████▋     | 115/247 [01:11<01:31,  1.44it/s]Loading trainS:  47%|████▋     | 116/247 [01:11<01:29,  1.46it/s]Loading trainS:  47%|████▋     | 117/247 [01:12<01:29,  1.45it/s]Loading trainS:  48%|████▊     | 118/247 [01:13<01:27,  1.47it/s]Loading trainS:  48%|████▊     | 119/247 [01:13<01:22,  1.55it/s]Loading trainS:  49%|████▊     | 120/247 [01:14<01:21,  1.55it/s]Loading trainS:  49%|████▉     | 121/247 [01:15<01:19,  1.59it/s]Loading trainS:  49%|████▉     | 122/247 [01:15<01:18,  1.60it/s]Loading trainS:  50%|████▉     | 123/247 [01:16<01:18,  1.58it/s]Loading trainS:  50%|█████     | 124/247 [01:16<01:13,  1.67it/s]Loading trainS:  51%|█████     | 125/247 [01:17<01:11,  1.70it/s]Loading trainS:  51%|█████     | 126/247 [01:18<01:11,  1.68it/s]Loading trainS:  51%|█████▏    | 127/247 [01:18<01:13,  1.63it/s]Loading trainS:  52%|█████▏    | 128/247 [01:19<01:14,  1.60it/s]Loading trainS:  52%|█████▏    | 129/247 [01:19<01:14,  1.58it/s]Loading trainS:  53%|█████▎    | 130/247 [01:20<01:13,  1.59it/s]Loading trainS:  53%|█████▎    | 131/247 [01:21<01:13,  1.57it/s]Loading trainS:  53%|█████▎    | 132/247 [01:21<01:13,  1.57it/s]Loading trainS:  54%|█████▍    | 133/247 [01:22<01:11,  1.60it/s]Loading trainS:  54%|█████▍    | 134/247 [01:23<01:11,  1.58it/s]Loading trainS:  55%|█████▍    | 135/247 [01:23<01:10,  1.59it/s]Loading trainS:  55%|█████▌    | 136/247 [01:24<01:08,  1.63it/s]Loading trainS:  55%|█████▌    | 137/247 [01:24<01:03,  1.73it/s]Loading trainS:  56%|█████▌    | 138/247 [01:25<01:00,  1.81it/s]Loading trainS:  56%|█████▋    | 139/247 [01:25<00:57,  1.88it/s]Loading trainS:  57%|█████▋    | 140/247 [01:26<00:57,  1.85it/s]Loading trainS:  57%|█████▋    | 141/247 [01:26<00:54,  1.96it/s]Loading trainS:  57%|█████▋    | 142/247 [01:27<00:54,  1.93it/s]Loading trainS:  58%|█████▊    | 143/247 [01:27<00:53,  1.95it/s]Loading trainS:  58%|█████▊    | 144/247 [01:28<00:52,  1.96it/s]Loading trainS:  59%|█████▊    | 145/247 [01:28<00:51,  1.99it/s]Loading trainS:  59%|█████▉    | 146/247 [01:29<00:51,  1.96it/s]Loading trainS:  60%|█████▉    | 147/247 [01:29<00:50,  1.98it/s]Loading trainS:  60%|█████▉    | 148/247 [01:30<00:51,  1.91it/s]Loading trainS:  60%|██████    | 149/247 [01:30<00:50,  1.94it/s]Loading trainS:  61%|██████    | 150/247 [01:31<00:51,  1.88it/s]Loading trainS:  61%|██████    | 151/247 [01:32<00:51,  1.87it/s]Loading trainS:  62%|██████▏   | 152/247 [01:32<00:49,  1.92it/s]Loading trainS:  62%|██████▏   | 153/247 [01:33<00:50,  1.85it/s]Loading trainS:  62%|██████▏   | 154/247 [01:33<00:52,  1.78it/s]Loading trainS:  63%|██████▎   | 155/247 [01:34<00:51,  1.79it/s]Loading trainS:  63%|██████▎   | 156/247 [01:34<00:52,  1.74it/s]Loading trainS:  64%|██████▎   | 157/247 [01:35<00:53,  1.69it/s]Loading trainS:  64%|██████▍   | 158/247 [01:36<00:52,  1.69it/s]Loading trainS:  64%|██████▍   | 159/247 [01:36<00:52,  1.68it/s]Loading trainS:  65%|██████▍   | 160/247 [01:37<00:53,  1.62it/s]Loading trainS:  65%|██████▌   | 161/247 [01:37<00:52,  1.63it/s]Loading trainS:  66%|██████▌   | 162/247 [01:38<00:53,  1.59it/s]Loading trainS:  66%|██████▌   | 163/247 [01:39<00:52,  1.60it/s]Loading trainS:  66%|██████▋   | 164/247 [01:39<00:51,  1.62it/s]Loading trainS:  67%|██████▋   | 165/247 [01:40<00:51,  1.59it/s]Loading trainS:  67%|██████▋   | 166/247 [01:41<00:50,  1.61it/s]Loading trainS:  68%|██████▊   | 167/247 [01:41<00:49,  1.62it/s]Loading trainS:  68%|██████▊   | 168/247 [01:42<00:49,  1.60it/s]Loading trainS:  68%|██████▊   | 169/247 [01:42<00:46,  1.66it/s]Loading trainS:  69%|██████▉   | 170/247 [01:43<00:47,  1.62it/s]Loading trainS:  69%|██████▉   | 171/247 [01:44<00:46,  1.63it/s]Loading trainS:  70%|██████▉   | 172/247 [01:44<00:45,  1.65it/s]Loading trainS:  70%|███████   | 173/247 [01:45<00:44,  1.66it/s]Loading trainS:  70%|███████   | 174/247 [01:45<00:44,  1.65it/s]Loading trainS:  71%|███████   | 175/247 [01:46<00:45,  1.58it/s]Loading trainS:  71%|███████▏  | 176/247 [01:47<00:44,  1.60it/s]Loading trainS:  72%|███████▏  | 177/247 [01:47<00:41,  1.69it/s]Loading trainS:  72%|███████▏  | 178/247 [01:48<00:40,  1.68it/s]Loading trainS:  72%|███████▏  | 179/247 [01:48<00:39,  1.71it/s]Loading trainS:  73%|███████▎  | 180/247 [01:49<00:40,  1.67it/s]Loading trainS:  73%|███████▎  | 181/247 [01:50<00:38,  1.72it/s]Loading trainS:  74%|███████▎  | 182/247 [01:50<00:38,  1.70it/s]Loading trainS:  74%|███████▍  | 183/247 [01:51<00:38,  1.65it/s]Loading trainS:  74%|███████▍  | 184/247 [01:51<00:38,  1.65it/s]Loading trainS:  75%|███████▍  | 185/247 [01:52<00:37,  1.66it/s]Loading trainS:  75%|███████▌  | 186/247 [01:53<00:37,  1.62it/s]Loading trainS:  76%|███████▌  | 187/247 [01:53<00:35,  1.68it/s]Loading trainS:  76%|███████▌  | 188/247 [01:54<00:34,  1.69it/s]Loading trainS:  77%|███████▋  | 189/247 [01:54<00:35,  1.64it/s]Loading trainS:  77%|███████▋  | 190/247 [01:55<00:34,  1.64it/s]Loading trainS:  77%|███████▋  | 191/247 [01:56<00:33,  1.65it/s]Loading trainS:  78%|███████▊  | 192/247 [01:56<00:33,  1.63it/s]Loading trainS:  78%|███████▊  | 193/247 [01:57<00:33,  1.63it/s]Loading trainS:  79%|███████▊  | 194/247 [01:57<00:31,  1.68it/s]Loading trainS:  79%|███████▉  | 195/247 [01:58<00:31,  1.66it/s]Loading trainS:  79%|███████▉  | 196/247 [01:59<00:30,  1.67it/s]Loading trainS:  80%|███████▉  | 197/247 [01:59<00:29,  1.68it/s]Loading trainS:  80%|████████  | 198/247 [02:00<00:28,  1.71it/s]Loading trainS:  81%|████████  | 199/247 [02:00<00:28,  1.71it/s]Loading trainS:  81%|████████  | 200/247 [02:01<00:27,  1.70it/s]Loading trainS:  81%|████████▏ | 201/247 [02:02<00:27,  1.68it/s]Loading trainS:  82%|████████▏ | 202/247 [02:02<00:26,  1.70it/s]Loading trainS:  82%|████████▏ | 203/247 [02:03<00:25,  1.71it/s]Loading trainS:  83%|████████▎ | 204/247 [02:03<00:25,  1.71it/s]Loading trainS:  83%|████████▎ | 205/247 [02:04<00:25,  1.66it/s]Loading trainS:  83%|████████▎ | 206/247 [02:05<00:25,  1.64it/s]Loading trainS:  84%|████████▍ | 207/247 [02:05<00:23,  1.74it/s]Loading trainS:  84%|████████▍ | 208/247 [02:06<00:22,  1.72it/s]Loading trainS:  85%|████████▍ | 209/247 [02:06<00:22,  1.70it/s]Loading trainS:  85%|████████▌ | 210/247 [02:07<00:21,  1.68it/s]Loading trainS:  85%|████████▌ | 211/247 [02:08<00:22,  1.63it/s]Loading trainS:  86%|████████▌ | 212/247 [02:08<00:21,  1.62it/s]Loading trainS:  86%|████████▌ | 213/247 [02:09<00:21,  1.60it/s]Loading trainS:  87%|████████▋ | 214/247 [02:09<00:20,  1.62it/s]Loading trainS:  87%|████████▋ | 215/247 [02:10<00:20,  1.59it/s]Loading trainS:  87%|████████▋ | 216/247 [02:11<00:19,  1.58it/s]Loading trainS:  88%|████████▊ | 217/247 [02:11<00:18,  1.66it/s]Loading trainS:  88%|████████▊ | 218/247 [02:12<00:17,  1.64it/s]Loading trainS:  89%|████████▊ | 219/247 [02:12<00:16,  1.69it/s]Loading trainS:  89%|████████▉ | 220/247 [02:13<00:16,  1.64it/s]Loading trainS:  89%|████████▉ | 221/247 [02:14<00:15,  1.63it/s]Loading trainS:  90%|████████▉ | 222/247 [02:14<00:15,  1.62it/s]Loading trainS:  90%|█████████ | 223/247 [02:15<00:14,  1.61it/s]Loading trainS:  91%|█████████ | 224/247 [02:16<00:14,  1.59it/s]Loading trainS:  91%|█████████ | 225/247 [02:16<00:13,  1.64it/s]Loading trainS:  91%|█████████▏| 226/247 [02:17<00:13,  1.60it/s]Loading trainS:  92%|█████████▏| 227/247 [02:18<00:12,  1.58it/s]Loading trainS:  92%|█████████▏| 228/247 [02:18<00:11,  1.62it/s]Loading trainS:  93%|█████████▎| 229/247 [02:19<00:11,  1.60it/s]Loading trainS:  93%|█████████▎| 230/247 [02:19<00:11,  1.52it/s]Loading trainS:  94%|█████████▎| 231/247 [02:20<00:10,  1.58it/s]Loading trainS:  94%|█████████▍| 232/247 [02:21<00:09,  1.57it/s]Loading trainS:  94%|█████████▍| 233/247 [02:21<00:08,  1.57it/s]Loading trainS:  95%|█████████▍| 234/247 [02:22<00:08,  1.58it/s]Loading trainS:  95%|█████████▌| 235/247 [02:23<00:08,  1.49it/s]Loading trainS:  96%|█████████▌| 236/247 [02:23<00:07,  1.53it/s]Loading trainS:  96%|█████████▌| 237/247 [02:24<00:06,  1.54it/s]Loading trainS:  96%|█████████▋| 238/247 [02:25<00:06,  1.49it/s]Loading trainS:  97%|█████████▋| 239/247 [02:25<00:05,  1.55it/s]Loading trainS:  97%|█████████▋| 240/247 [02:26<00:04,  1.53it/s]Loading trainS:  98%|█████████▊| 241/247 [02:27<00:04,  1.48it/s]Loading trainS:  98%|█████████▊| 242/247 [02:27<00:03,  1.56it/s]Loading trainS:  98%|█████████▊| 243/247 [02:28<00:02,  1.50it/s]Loading trainS:  99%|█████████▉| 244/247 [02:29<00:02,  1.47it/s]Loading trainS:  99%|█████████▉| 245/247 [02:29<00:01,  1.50it/s]Loading trainS: 100%|█████████▉| 246/247 [02:30<00:00,  1.45it/s]Loading trainS: 100%|██████████| 247/247 [02:31<00:00,  1.47it/s]Loading trainS: 100%|██████████| 247/247 [02:31<00:00,  1.63it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.43it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.42it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.51it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.58it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.59it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.58it/s]----------+++ 
CrossVal ['b']
CrossVal ['b']
(0/5) test vimp2_ANON911_CSFn2
(1/5) test vimp2_D_CSFn2
(2/5) test vimp2_F_CSFn2
(3/5) test vimp2_G_CSFn2
(4/5) test vimp2_J_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 77s - loss: 0.1114 - acc: 0.9875 - mDice: 0.7844 - val_loss: 0.3126 - val_acc: 0.9877 - val_mDice: 0.3814

Epoch 00001: val_mDice improved from -inf to 0.38136, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 72s - loss: 0.0760 - acc: 0.9920 - mDice: 0.8522 - val_loss: 0.3331 - val_acc: 0.9877 - val_mDice: 0.3404

Epoch 00002: val_mDice did not improve from 0.38136
Epoch 3/300
 - 71s - loss: 0.0667 - acc: 0.9931 - mDice: 0.8703 - val_loss: 0.2874 - val_acc: 0.9875 - val_mDice: 0.4320

Epoch 00003: val_mDice improved from 0.38136 to 0.43202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 73s - loss: 0.0622 - acc: 0.9935 - mDice: 0.8791 - val_loss: 0.2849 - val_acc: 0.9897 - val_mDice: 0.4359

Epoch 00004: val_mDice improved from 0.43202 to 0.43592, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 74s - loss: 0.0567 - acc: 0.9939 - mDice: 0.8897 - val_loss: 0.2816 - val_acc: 0.9917 - val_mDice: 0.4392

Epoch 00005: val_mDice improved from 0.43592 to 0.43923, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 74s - loss: 0.0524 - acc: 0.9943 - mDice: 0.8981 - val_loss: 0.2653 - val_acc: 0.9917 - val_mDice: 0.4589

Epoch 00006: val_mDice improved from 0.43923 to 0.45887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 74s - loss: 0.0507 - acc: 0.9944 - mDice: 0.9015 - val_loss: 0.3015 - val_acc: 0.9892 - val_mDice: 0.3999

Epoch 00007: val_mDice did not improve from 0.45887
Epoch 8/300
 - 74s - loss: 0.0493 - acc: 0.9946 - mDice: 0.9041 - val_loss: 0.2728 - val_acc: 0.9917 - val_mDice: 0.4579

Epoch 00008: val_mDice did not improve from 0.45887
Epoch 9/300
 - 74s - loss: 0.0449 - acc: 0.9949 - mDice: 0.9128 - val_loss: 0.3116 - val_acc: 0.9890 - val_mDice: 0.3606

Epoch 00009: val_mDice did not improve from 0.45887
Epoch 10/300
 - 74s - loss: 0.0431 - acc: 0.9951 - mDice: 0.9162 - val_loss: 0.2634 - val_acc: 0.9910 - val_mDice: 0.4581

Epoch 00010: val_mDice did not improve from 0.45887
Epoch 11/300
 - 74s - loss: 0.0419 - acc: 0.9952 - mDice: 0.9185 - val_loss: 0.2451 - val_acc: 0.9885 - val_mDice: 0.3465

Epoch 00011: val_mDice did not improve from 0.45887
Epoch 12/300
 - 74s - loss: 0.0496 - acc: 0.9945 - mDice: 0.9035 - val_loss: 0.2423 - val_acc: 0.9921 - val_mDice: 0.4617

Epoch 00012: val_mDice improved from 0.45887 to 0.46174, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 13/300
 - 74s - loss: 0.0419 - acc: 0.9953 - mDice: 0.9185 - val_loss: 0.2595 - val_acc: 0.9891 - val_mDice: 0.4661

Epoch 00013: val_mDice improved from 0.46174 to 0.46615, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 14/300
 - 74s - loss: 0.0399 - acc: 0.9954 - mDice: 0.9225 - val_loss: 0.2266 - val_acc: 0.9917 - val_mDice: 0.4721

Epoch 00014: val_mDice improved from 0.46615 to 0.47213, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 15/300
 - 74s - loss: 0.0400 - acc: 0.9955 - mDice: 0.9222 - val_loss: 0.2187 - val_acc: 0.9857 - val_mDice: 0.4435

Epoch 00015: val_mDice did not improve from 0.47213
Epoch 16/300
 - 74s - loss: 0.0380 - acc: 0.9955 - mDice: 0.9262 - val_loss: 0.2483 - val_acc: 0.9929 - val_mDice: 0.4825

Epoch 00016: val_mDice improved from 0.47213 to 0.48248, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 17/300
 - 73s - loss: 0.0371 - acc: 0.9956 - mDice: 0.9279 - val_loss: 0.2627 - val_acc: 0.9921 - val_mDice: 0.4754

Epoch 00017: val_mDice did not improve from 0.48248
Epoch 18/300
 - 73s - loss: 0.0392 - acc: 0.9955 - mDice: 0.9239 - val_loss: 0.2193 - val_acc: 0.9918 - val_mDice: 0.4572

Epoch 00018: val_mDice did not improve from 0.48248
Epoch 19/300
 - 73s - loss: 0.0387 - acc: 0.9956 - mDice: 0.9248 - val_loss: 0.1892 - val_acc: 0.9917 - val_mDice: 0.4691

Epoch 00019: val_mDice did not improve from 0.48248
Epoch 20/300
 - 73s - loss: 0.0362 - acc: 0.9957 - mDice: 0.9296 - val_loss: 0.1331 - val_acc: 0.9910 - val_mDice: 0.4630

Epoch 00020: val_mDice did not improve from 0.48248
Epoch 21/300
 - 74s - loss: 0.0351 - acc: 0.9958 - mDice: 0.9319 - val_loss: 0.1952 - val_acc: 0.9925 - val_mDice: 0.4742

Epoch 00021: val_mDice did not improve from 0.48248
Epoch 22/300
 - 75s - loss: 0.0361 - acc: 0.9958 - mDice: 0.9298 - val_loss: 0.2809 - val_acc: 0.9894 - val_mDice: 0.4080

Epoch 00022: val_mDice did not improve from 0.48248
Epoch 23/300
 - 75s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9314 - val_loss: 0.2252 - val_acc: 0.9926 - val_mDice: 0.4620

Epoch 00023: val_mDice did not improve from 0.48248
Epoch 24/300
 - 75s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9321 - val_loss: 0.2255 - val_acc: 0.9917 - val_mDice: 0.4521

Epoch 00024: val_mDice did not improve from 0.48248
Epoch 25/300
 - 75s - loss: 0.0336 - acc: 0.9960 - mDice: 0.9348 - val_loss: 0.2309 - val_acc: 0.9905 - val_mDice: 0.4579

Epoch 00025: val_mDice did not improve from 0.48248
Epoch 26/300
 - 75s - loss: 0.0337 - acc: 0.9959 - mDice: 0.9346 - val_loss: 0.1246 - val_acc: 0.9932 - val_mDice: 0.4755

Epoch 00026: val_mDice did not improve from 0.48248
Epoch 27/300
 - 75s - loss: 0.0328 - acc: 0.9960 - mDice: 0.9363 - val_loss: 0.1633 - val_acc: 0.9915 - val_mDice: 0.4650

Epoch 00027: val_mDice did not improve from 0.48248
Epoch 28/300
 - 75s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9355 - val_loss: 0.1389 - val_acc: 0.9902 - val_mDice: 0.4219

Epoch 00028: val_mDice did not improve from 0.48248
Epoch 29/300
 - 75s - loss: 0.0326 - acc: 0.9960 - mDice: 0.9367 - val_loss: 0.1283 - val_acc: 0.9863 - val_mDice: 0.3120

Epoch 00029: val_mDice did not improve from 0.48248
Epoch 30/300
 - 75s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9354 - val_loss: 0.2186 - val_acc: 0.9929 - val_mDice: 0.4582

Epoch 00030: val_mDice did not improve from 0.48248
Epoch 31/300
 - 75s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9374 - val_loss: 0.1981 - val_acc: 0.9889 - val_mDice: 0.4417

Epoch 00031: val_mDice did not improve from 0.48248

Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 32/300
 - 75s - loss: 0.0303 - acc: 0.9962 - mDice: 0.9413 - val_loss: 0.1116 - val_acc: 0.9900 - val_mDice: 0.3833

Epoch 00032: val_mDice did not improve from 0.48248
Epoch 33/300
 - 75s - loss: 0.0297 - acc: 0.9962 - mDice: 0.9423 - val_loss: 0.1849 - val_acc: 0.9922 - val_mDice: 0.4611

Epoch 00033: val_mDice did not improve from 0.48248
Epoch 34/300
 - 75s - loss: 0.0290 - acc: 0.9963 - mDice: 0.9438 - val_loss: 0.1439 - val_acc: 0.9919 - val_mDice: 0.4430

Epoch 00034: val_mDice did not improve from 0.48248
Epoch 35/300
 - 75s - loss: 0.0291 - acc: 0.9963 - mDice: 0.9436 - val_loss: 0.1370 - val_acc: 0.9926 - val_mDice: 0.4684

Epoch 00035: val_mDice did not improve from 0.48248
Epoch 36/300
 - 75s - loss: 0.0293 - acc: 0.9963 - mDice: 0.9433 - val_loss: 0.1207 - val_acc: 0.9919 - val_mDice: 0.4511

Epoch 00036: val_mDice did not improve from 0.48248
Epoch 37/300
 - 75s - loss: 0.0291 - acc: 0.9963 - mDice: 0.9436 - val_loss: 0.1127 - val_acc: 0.9919 - val_mDice: 0.4654

Epoch 00037: val_mDice did not improve from 0.48248
Epoch 38/300
 - 75s - loss: 0.0287 - acc: 0.9964 - mDice: 0.9444 - val_loss: 0.1419 - val_acc: 0.9919 - val_mDice: 0.4739

Epoch 00038: val_mDice did not improve from 0.48248
Epoch 39/300
 - 75s - loss: 0.0281 - acc: 0.9964 - mDice: 0.9455 - val_loss: 0.0238 - val_acc: 0.9915 - val_mDice: 0.4423

Epoch 00039: val_mDice did not improve from 0.48248
Epoch 40/300
 - 75s - loss: 0.0275 - acc: 0.9964 - mDice: 0.9467 - val_loss: 0.0546 - val_acc: 0.9923 - val_mDice: 0.4643

Epoch 00040: val_mDice did not improve from 0.48248
Epoch 41/300
 - 75s - loss: 0.0277 - acc: 0.9964 - mDice: 0.9463 - val_loss: 0.0350 - val_acc: 0.9915 - val_mDice: 0.4533

Epoch 00041: val_mDice did not improve from 0.48248
Epoch 42/300
 - 75s - loss: 0.0281 - acc: 0.9964 - mDice: 0.9454 - val_loss: 0.1022 - val_acc: 0.9916 - val_mDice: 0.4530

Epoch 00042: val_mDice did not improve from 0.48248
Epoch 43/300
 - 75s - loss: 0.0276 - acc: 0.9964 - mDice: 0.9465 - val_loss: 0.0924 - val_acc: 0.9930 - val_mDice: 0.4807

Epoch 00043: val_mDice did not improve from 0.48248
Epoch 44/300
 - 75s - loss: 0.0294 - acc: 0.9964 - mDice: 0.9429 - val_loss: 0.0746 - val_acc: 0.9913 - val_mDice: 0.4418

Epoch 00044: val_mDice did not improve from 0.48248
Epoch 45/300
 - 75s - loss: 0.0277 - acc: 0.9964 - mDice: 0.9463 - val_loss: 0.0780 - val_acc: 0.9921 - val_mDice: 0.4597

Epoch 00045: val_mDice did not improve from 0.48248
Epoch 46/300
 - 75s - loss: 0.0274 - acc: 0.9964 - mDice: 0.9469 - val_loss: 0.0680 - val_acc: 0.9920 - val_mDice: 0.4607

Epoch 00046: val_mDice did not improve from 0.48248

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 47/300
 - 75s - loss: 0.0263 - acc: 0.9965 - mDice: 0.9491 - val_loss: 0.0604 - val_acc: 0.9921 - val_mDice: 0.4633

Epoch 00047: val_mDice did not improve from 0.48248
Epoch 48/300
 - 75s - loss: 0.0269 - acc: 0.9965 - mDice: 0.9478 - val_loss: 0.0672 - val_acc: 0.9927 - val_mDice: 0.4728

Epoch 00048: val_mDice did not improve from 0.48248
Epoch 49/300
 - 75s - loss: 0.0267 - acc: 0.9965 - mDice: 0.9482 - val_loss: 0.0861 - val_acc: 0.9924 - val_mDice: 0.4644

Epoch 00049: val_mDice did not improve from 0.48248
Epoch 50/300
 - 75s - loss: 0.0259 - acc: 0.9965 - mDice: 0.9498 - val_loss: 0.1214 - val_acc: 0.9927 - val_mDice: 0.4704

Epoch 00050: val_mDice did not improve from 0.48248
Epoch 51/300
 - 75s - loss: 0.0255 - acc: 0.9966 - mDice: 0.9505 - val_loss: 0.1805 - val_acc: 0.9926 - val_mDice: 0.4673

Epoch 00051: val_mDice did not improve from 0.48248
Epoch 52/300
 - 75s - loss: 0.0257 - acc: 0.9966 - mDice: 0.9502 - val_loss: 0.1136 - val_acc: 0.9927 - val_mDice: 0.4659

Epoch 00052: val_mDice did not improve from 0.48248
Epoch 53/300
 - 75s - loss: 0.0264 - acc: 0.9966 - mDice: 0.9488 - val_loss: 0.1157 - val_acc: 0.9926 - val_mDice: 0.4437

Epoch 00053: val_mDice did not improve from 0.48248
Epoch 54/300
 - 75s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9503 - val_loss: 0.0977 - val_acc: 0.9923 - val_mDice: 0.4544

Epoch 00054: val_mDice did not improve from 0.48248
Epoch 55/300
 - 75s - loss: 0.0254 - acc: 0.9966 - mDice: 0.9508 - val_loss: 0.0615 - val_acc: 0.9927 - val_mDice: 0.4713

Epoch 00055: val_mDice did not improve from 0.48248
Epoch 56/300
 - 75s - loss: 0.0252 - acc: 0.9966 - mDice: 0.9511 - val_loss: 0.1608 - val_acc: 0.9921 - val_mDice: 0.4552

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.17it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.49it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.78it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.03it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.41it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.54it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:38,  6.35it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:37,  6.46it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:36,  6.61it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:37,  6.55it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:36,  6.55it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:36,  6.54it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:36,  6.56it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:36,  6.54it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:37,  6.26it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:37,  6.31it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:37,  6.35it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.40it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.39it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:36,  6.45it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:35,  6.51it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:35,  6.57it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:34,  6.60it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:34,  6.62it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:34,  6.60it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:34,  6.61it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.60it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:33,  6.63it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.74it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:34,  6.49it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:33,  6.58it/s]predicting train subjects:  11%|█         | 26/247 [00:04<00:36,  6.02it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:35,  6.25it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:34,  6.43it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:33,  6.45it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:32,  6.58it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:32,  6.63it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:32,  6.70it/s]predicting train subjects:  13%|█▎        | 33/247 [00:05<00:31,  6.71it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:31,  6.74it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:31,  6.80it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:30,  6.81it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:30,  6.86it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:30,  6.85it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:30,  6.77it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:30,  6.68it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:30,  6.72it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:30,  6.78it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:30,  6.80it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:30,  6.76it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.77it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:29,  6.77it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:29,  6.74it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:29,  6.77it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:29,  6.73it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:29,  6.71it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:29,  6.71it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:29,  6.65it/s]predicting train subjects:  21%|██▏       | 53/247 [00:08<00:29,  6.69it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:28,  6.71it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:28,  6.68it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:28,  6.71it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:29,  6.52it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:28,  6.54it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:29,  6.48it/s]predicting train subjects:  24%|██▍       | 60/247 [00:09<00:30,  6.07it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:32,  5.75it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:31,  5.89it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:30,  6.07it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:29,  6.18it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.29it/s]predicting train subjects:  27%|██▋       | 66/247 [00:10<00:28,  6.36it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:28,  6.40it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:27,  6.43it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:27,  6.44it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.46it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.50it/s]predicting train subjects:  29%|██▉       | 72/247 [00:11<00:26,  6.51it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:26,  6.50it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:26,  6.51it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:26,  6.53it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:26,  6.50it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:34,  4.93it/s]predicting train subjects:  32%|███▏      | 78/247 [00:12<00:36,  4.58it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:33,  4.95it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:37,  4.50it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:33,  4.94it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:31,  5.20it/s]predicting train subjects:  34%|███▎      | 83/247 [00:13<00:29,  5.52it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:28,  5.80it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:26,  6.02it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:26,  6.17it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:25,  6.28it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:24,  6.38it/s]predicting train subjects:  36%|███▌      | 89/247 [00:14<00:24,  6.44it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:24,  6.50it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:23,  6.57it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:23,  6.61it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:23,  6.62it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:23,  6.62it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:22,  6.61it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:22,  6.59it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:22,  6.59it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:22,  6.58it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:22,  6.56it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:23,  6.21it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:26,  5.54it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:27,  5.22it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:27,  5.32it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:26,  5.43it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:25,  5.50it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:25,  5.58it/s]predicting train subjects:  43%|████▎     | 107/247 [00:17<00:24,  5.62it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:24,  5.62it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:24,  5.61it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:24,  5.61it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:24,  5.60it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:24,  5.58it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:23,  5.60it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:23,  5.63it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:23,  5.65it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:23,  5.65it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:22,  5.67it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:22,  5.79it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:21,  5.94it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:21,  6.02it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:20,  6.08it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:20,  6.06it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:20,  6.14it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:19,  6.19it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:19,  6.16it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:19,  6.19it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:19,  6.16it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:20,  5.72it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:20,  5.81it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:20<00:19,  5.95it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:19,  5.97it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:18,  6.06it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:18,  6.10it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:18,  6.12it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:18,  6.08it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:17,  6.45it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:16,  6.73it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:15,  6.91it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:15,  7.05it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:14,  7.16it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:14,  7.26it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:14,  7.31it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:14,  7.31it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:22<00:14,  7.32it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:13,  7.37it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:13,  7.38it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:13,  7.43it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:13,  7.46it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:13,  7.03it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:13,  7.15it/s]predicting train subjects:  61%|██████    | 151/247 [00:23<00:13,  7.21it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:12,  7.32it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:12,  7.42it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:12,  7.20it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:12,  7.09it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:13,  6.94it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:24<00:13,  6.86it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:24<00:13,  6.82it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:12,  6.80it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:12,  6.78it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:12,  6.74it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:12,  6.75it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:25<00:12,  6.77it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:25<00:12,  6.65it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:12,  6.70it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:11,  6.75it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:11,  6.77it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:11,  6.80it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:11,  6.84it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:26<00:11,  6.84it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:26<00:11,  6.76it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:11,  6.69it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:14,  5.05it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:13,  5.45it/s]predicting train subjects:  71%|███████   | 175/247 [00:27<00:14,  4.97it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:27<00:13,  5.38it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:12,  5.65it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  5.93it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:11,  6.16it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.32it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:28<00:10,  6.47it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:28<00:09,  6.60it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:28<00:09,  6.70it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.78it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.83it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:08,  6.83it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:08,  6.82it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:29<00:08,  6.79it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:29<00:08,  6.76it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:29<00:08,  6.75it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.78it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:08,  6.80it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:07,  6.82it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:30<00:07,  6.95it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:30<00:07,  7.04it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:30<00:07,  7.04it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:30<00:07,  6.76it/s]predicting train subjects:  80%|████████  | 198/247 [00:31<00:07,  6.81it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:07,  6.83it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  6.86it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:31<00:06,  6.92it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:31<00:06,  6.98it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:31<00:06,  6.95it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:31<00:06,  6.97it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:32<00:05,  7.03it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  7.01it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  7.04it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:32<00:05,  7.08it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:32<00:05,  7.10it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:32<00:05,  7.09it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:32<00:05,  7.10it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:33<00:05,  6.86it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:05,  6.77it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  6.72it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:33<00:04,  6.66it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  6.60it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:33<00:04,  6.54it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  6.57it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:34<00:04,  6.51it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:04,  6.51it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:34<00:03,  6.56it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:34<00:03,  6.59it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  6.64it/s]predicting train subjects:  91%|█████████ | 224/247 [00:34<00:03,  6.61it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  6.64it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:03,  6.62it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:03,  6.64it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:35<00:02,  6.60it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:35<00:02,  6.59it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:02,  6.31it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:03,  5.31it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  5.34it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  5.51it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:36<00:02,  5.66it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:36<00:02,  5.77it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:01,  5.83it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  5.88it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  5.94it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:37<00:01,  5.94it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:37<00:01,  5.93it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:37<00:01,  5.94it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:37<00:00,  5.90it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  5.88it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  5.88it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:38<00:00,  5.86it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:38<00:00,  5.90it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  5.92it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  6.36it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  5.47it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  5.56it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  5.92it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  6.16it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.05it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.11it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:37,  6.62it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:36,  6.69it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:37,  6.55it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:37,  6.51it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:36,  6.56it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:36,  6.63it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:36,  6.67it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:35,  6.69it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:35,  6.66it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:35,  6.63it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:35,  6.63it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:35,  6.57it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:35,  6.57it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:35,  6.60it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:35,  6.62it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:35,  6.50it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:35,  6.46it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:35,  6.49it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:34,  6.52it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:34,  6.51it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:34,  6.56it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:34,  6.60it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:03<00:33,  6.70it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:33,  6.74it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:32,  6.81it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:32,  6.87it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:32,  6.86it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:31,  6.85it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:04<00:31,  6.88it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:04<00:31,  6.85it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:04<00:31,  6.87it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:04<00:31,  6.83it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:04<00:31,  6.85it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:05<00:30,  6.89it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:05<00:31,  6.75it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:05<00:31,  6.65it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:05<00:31,  6.68it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:05<00:31,  6.63it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:05<00:31,  6.69it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:05<00:31,  6.67it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:06<00:30,  6.70it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:06<00:32,  6.31it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:06<00:31,  6.46it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:06<00:30,  6.58it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:06<00:33,  6.06it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:06<00:33,  6.07it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:07<00:31,  6.27it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:07<00:31,  6.41it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:07<00:30,  6.51it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:07<00:29,  6.62it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:07<00:29,  6.60it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:07<00:29,  6.69it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:08<00:28,  6.73it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:08<00:28,  6.76it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:08<00:28,  6.78it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:08<00:27,  6.83it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:08<00:27,  6.88it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:08<00:27,  6.86it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:08<00:27,  6.76it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:09<00:27,  6.70it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:09<00:28,  6.61it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:09<00:28,  6.59it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:09<00:27,  6.58it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:09<00:27,  6.54it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:09<00:28,  6.48it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:09<00:27,  6.50it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:10<00:27,  6.47it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:10<00:27,  6.48it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:10<00:27,  6.51it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:10<00:27,  6.50it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:10<00:27,  6.48it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:10<00:26,  6.51it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:11<00:26,  6.53it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:11<00:26,  6.45it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:11<00:26,  6.42it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:11<00:26,  6.44it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:11<00:26,  6.48it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:11<00:27,  6.16it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:12<00:27,  6.10it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:12<00:28,  5.87it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:12<00:27,  6.08it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:12<00:26,  6.21it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:12<00:26,  6.29it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:12<00:25,  6.39it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:12<00:25,  6.48it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:13<00:26,  6.10it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:13<00:25,  6.22it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:13<00:25,  6.28it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:13<00:24,  6.39it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:13<00:24,  6.33it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:13<00:24,  6.42it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:14<00:23,  6.48it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:14<00:23,  6.55it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:14<00:23,  6.61it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:14<00:23,  6.56it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:14<00:22,  6.57it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:14<00:22,  6.56it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:14<00:22,  6.60it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:15<00:22,  6.49it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:15<00:24,  6.10it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:15<00:24,  5.97it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:15<00:24,  5.85it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:15<00:24,  5.80it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:16<00:24,  5.75it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:16<00:25,  5.63it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:16<00:24,  5.66it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:16<00:24,  5.63it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:16<00:24,  5.65it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:16<00:24,  5.65it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:17<00:24,  5.63it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:17<00:24,  5.64it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:17<00:24,  5.56it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:17<00:24,  5.47it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:17<00:24,  5.52it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:18<00:24,  5.50it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:18<00:23,  5.53it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:18<00:23,  5.53it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:18<00:22,  5.68it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:18<00:22,  5.79it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:18<00:21,  5.89it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:19<00:21,  5.97it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:19<00:20,  6.02it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:19<00:20,  6.07it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:19<00:20,  6.10it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:19<00:19,  6.11it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:19<00:19,  6.11it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:19<00:19,  6.13it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:20<00:19,  6.17it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:20<00:19,  6.21it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:20<00:18,  6.22it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:20<00:19,  6.09it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:20<00:18,  6.06it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:20<00:18,  6.09it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:21<00:18,  6.13it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:21<00:18,  6.14it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:21<00:17,  6.50it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:21<00:16,  6.78it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:21<00:15,  6.98it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:21<00:15,  7.13it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:21<00:14,  7.23it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:22<00:14,  7.25it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:22<00:14,  7.36it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:22<00:14,  7.42it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:22<00:13,  7.45it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:22<00:14,  7.28it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:22<00:13,  7.26it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:22<00:13,  7.23it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:23<00:13,  7.22it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:23<00:13,  7.28it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:23<00:13,  7.34it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:23<00:13,  7.29it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:23<00:12,  7.37it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:23<00:12,  7.39it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:23<00:13,  7.12it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:24<00:13,  7.01it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:24<00:13,  6.94it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:24<00:13,  6.86it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:24<00:13,  6.82it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:24<00:12,  6.78it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:24<00:12,  6.78it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:24<00:12,  6.64it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:25<00:12,  6.61it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:25<00:12,  6.65it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:25<00:12,  6.63it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:25<00:12,  6.60it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:25<00:12,  6.59it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:25<00:12,  6.60it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:25<00:11,  6.63it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:26<00:11,  6.68it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:26<00:11,  6.73it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:26<00:11,  6.76it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:26<00:11,  6.75it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:26<00:10,  6.80it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:26<00:10,  6.73it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:27<00:11,  6.46it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:27<00:10,  6.55it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:27<00:10,  6.61it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:27<00:10,  6.65it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:27<00:11,  6.14it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:27<00:10,  6.27it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:27<00:10,  6.37it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:28<00:10,  6.44it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:28<00:09,  6.50it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:28<00:09,  6.39it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:28<00:09,  6.37it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:28<00:09,  6.31it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:28<00:09,  6.41it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:29<00:09,  6.48it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:29<00:08,  6.53it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:29<00:08,  6.59it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:29<00:08,  6.65it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:29<00:08,  6.66it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:29<00:08,  6.67it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:29<00:07,  6.74it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:30<00:08,  6.41it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:30<00:08,  6.01it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:30<00:08,  6.16it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:30<00:07,  6.40it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:30<00:07,  6.56it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:30<00:07,  6.55it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:31<00:06,  6.62it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:31<00:06,  6.71it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:31<00:06,  6.78it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:31<00:06,  6.83it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:31<00:06,  6.89it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:31<00:05,  6.91it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:31<00:05,  6.95it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:32<00:05,  6.98it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:32<00:05,  7.04it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:32<00:05,  7.07it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:32<00:05,  7.11it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:32<00:05,  6.99it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:32<00:04,  6.95it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:32<00:04,  6.92it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:33<00:04,  6.91it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:33<00:04,  6.86it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:33<00:04,  6.86it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:33<00:04,  6.86it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:33<00:04,  6.87it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:33<00:03,  6.86it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:34<00:04,  6.16it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:34<00:03,  6.27it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:34<00:03,  6.42it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:34<00:03,  6.56it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:34<00:03,  6.66it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:34<00:03,  6.69it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:34<00:03,  6.65it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:35<00:02,  6.55it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:35<00:02,  6.54it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:35<00:02,  6.30it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:35<00:02,  6.18it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:35<00:02,  6.12it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:35<00:02,  6.08it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:36<00:02,  6.06it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:36<00:01,  6.03it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:36<00:01,  5.98it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:36<00:01,  5.96it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:36<00:01,  5.97it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:36<00:01,  5.94it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:37<00:01,  5.92it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:37<00:01,  5.88it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:37<00:00,  5.89it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:37<00:00,  5.87it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:37<00:00,  5.74it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:37<00:00,  5.80it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:38<00:00,  5.79it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:38<00:00,  5.84it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:38<00:00,  6.45it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 74.50it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 80.65it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 81.05it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 81.92it/s]saving BB  train1-THALAMUS:  15%|█▍        | 37/247 [00:00<00:02, 84.38it/s]saving BB  train1-THALAMUS:  18%|█▊        | 44/247 [00:00<00:02, 76.49it/s]saving BB  train1-THALAMUS:  21%|██        | 52/247 [00:00<00:02, 76.30it/s]saving BB  train1-THALAMUS:  25%|██▍       | 61/247 [00:00<00:02, 78.27it/s]saving BB  train1-THALAMUS:  28%|██▊       | 69/247 [00:00<00:02, 77.71it/s]saving BB  train1-THALAMUS:  32%|███▏      | 78/247 [00:00<00:02, 78.56it/s]saving BB  train1-THALAMUS:  35%|███▌      | 87/247 [00:01<00:01, 80.00it/s]saving BB  train1-THALAMUS:  39%|███▉      | 96/247 [00:01<00:01, 80.34it/s]saving BB  train1-THALAMUS:  42%|████▏     | 104/247 [00:01<00:01, 80.20it/s]saving BB  train1-THALAMUS:  45%|████▌     | 112/247 [00:01<00:01, 79.12it/s]saving BB  train1-THALAMUS:  49%|████▊     | 120/247 [00:01<00:01, 78.57it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 128/247 [00:01<00:01, 75.51it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 136/247 [00:01<00:01, 74.09it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 146/247 [00:01<00:01, 78.59it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 155/247 [00:01<00:01, 81.53it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 165/247 [00:02<00:00, 85.18it/s]saving BB  train1-THALAMUS:  70%|███████   | 174/247 [00:02<00:00, 86.51it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 183/247 [00:02<00:00, 85.21it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 192/247 [00:02<00:00, 84.35it/s]saving BB  train1-THALAMUS:  81%|████████▏ | 201/247 [00:02<00:00, 85.24it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 210/247 [00:02<00:00, 86.52it/s]saving BB  train1-THALAMUS:  89%|████████▊ | 219/247 [00:02<00:00, 87.15it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 228/247 [00:02<00:00, 87.59it/s]saving BB  train1-THALAMUS:  96%|█████████▌| 237/247 [00:02<00:00, 85.44it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 246/247 [00:03<00:00, 82.83it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 81.89it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 78.92it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 84.08it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 84.70it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 83.78it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 36/247 [00:00<00:02, 85.22it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▊        | 46/247 [00:00<00:02, 87.67it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 56/247 [00:00<00:02, 89.75it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 65/247 [00:00<00:02, 87.75it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 74/247 [00:00<00:02, 84.98it/s]saving BB  train1-THALAMUS Sagittal:  34%|███▎      | 83/247 [00:00<00:01, 85.31it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 92/247 [00:01<00:01, 85.12it/s]saving BB  train1-THALAMUS Sagittal:  41%|████      | 101/247 [00:01<00:01, 82.07it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 110/247 [00:01<00:01, 80.60it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 118/247 [00:01<00:01, 79.68it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 126/247 [00:01<00:01, 79.70it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 134/247 [00:01<00:01, 78.31it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 143/247 [00:01<00:01, 80.14it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 153/247 [00:01<00:01, 83.24it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 163/247 [00:01<00:00, 85.45it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 173/247 [00:02<00:00, 86.83it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 182/247 [00:02<00:00, 83.08it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 191/247 [00:02<00:00, 78.28it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 200/247 [00:02<00:00, 80.49it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 209/247 [00:02<00:00, 82.42it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 218/247 [00:02<00:00, 75.88it/s]saving BB  train1-THALAMUS Sagittal:  91%|█████████▏| 226/247 [00:02<00:00, 72.35it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▌| 235/247 [00:02<00:00, 75.17it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 243/247 [00:02<00:00, 75.60it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 81.42it/s]
Epoch 00056: val_mDice did not improve from 0.48248
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [0.31259851596197924, 0.3330802407350626, 0.2874390013941057, 0.2849198547569481, 0.28162254120136526, 0.2652814423178767, 0.30145768919685584, 0.2728482214538185, 0.3116315072094714, 0.26335000633835437, 0.24509218142734276, 0.24227954782881178, 0.25953251866248994, 0.22656301952697136, 0.21866450438628326, 0.2482919698362952, 0.26272018137457853, 0.2193433998135833, 0.18921395295017115, 0.13309459755191574, 0.19520552492177523, 0.28090058656426165, 0.22520804843745074, 0.22548117911493457, 0.23087838005733202, 0.12456356029252748, 0.1633289057213265, 0.1389388922188017, 0.1283279247022606, 0.2186471128517443, 0.19809877706898582, 0.111551225901366, 0.1848669770333144, 0.14389963018464613, 0.13701205340412645, 0.12073425393741768, 0.11271573706074162, 0.1419208691463814, 0.023795439540086925, 0.05456228706392798, 0.03498620179680375, 0.10219068646251976, 0.09240783482521504, 0.07455444031649523, 0.07797393328076727, 0.0679511806896857, 0.060355196307013345, 0.06716664632161458, 0.08608260862641148, 0.12143708586513817, 0.18050205689650756, 0.1136110339973782, 0.11572848224604095, 0.09771589626063097, 0.06152958519107945, 0.1608446198361772], 'val_acc': [0.9876653467928683, 0.9876593576895224, 0.9874563260121388, 0.9896594361141995, 0.9916810978640307, 0.9917484546924854, 0.9891994504241256, 0.9917151297892894, 0.9889741305474404, 0.9909703778075026, 0.9885016733461672, 0.9921382100016505, 0.9891256194214921, 0.9917407776858356, 0.985660948194899, 0.9929342613563882, 0.9921338944821745, 0.9917839275108086, 0.9916741439888069, 0.9909881142166642, 0.9924742763822859, 0.9894357944752002, 0.992573272000562, 0.9917136978458714, 0.990498403887133, 0.9932058526946975, 0.9915411146553429, 0.9902491079078423, 0.9862872891955905, 0.9928621128872708, 0.988911563569719, 0.9900206753441522, 0.9922257053243505, 0.9918946704349002, 0.992592692733169, 0.9918882034204386, 0.9919258331035351, 0.9918982681927381, 0.9915015661680663, 0.9923112782630118, 0.9915248119795287, 0.991584731651856, 0.993008573849996, 0.9913347268605733, 0.9921384552219609, 0.9919646691989612, 0.9920622239241729, 0.9927427478738733, 0.9923556255506681, 0.9926502210599882, 0.9926427874837194, 0.9926653209033313, 0.9926051488509765, 0.9923201473625572, 0.9927460968315422, 0.9920828367496753], 'val_mDice': [0.3813645404893283, 0.34036863365758857, 0.432019244281443, 0.4359217836626902, 0.43923219224423926, 0.4588688507273952, 0.3998769389925742, 0.45785246707598704, 0.36055786387839023, 0.45810485566346515, 0.34651836811292536, 0.4617417435925286, 0.46614569166987047, 0.4721255515430783, 0.4434942744473728, 0.4824799209743649, 0.47543397178879016, 0.4572011906693421, 0.46909239467557845, 0.46295938641127327, 0.4742280396076294, 0.4080137668608187, 0.4620169751994994, 0.4521496819790911, 0.45788926986960676, 0.47553836851864606, 0.4649690972143286, 0.4219345233819864, 0.3120313559353978, 0.45820568874067563, 0.44165998697280884, 0.3832551823542999, 0.4610983172694484, 0.44295031722780465, 0.4683608259703662, 0.45108478326160273, 0.4654246680550389, 0.4739037021860346, 0.44232645997771985, 0.46434281600846183, 0.4533456171955074, 0.45303748512232267, 0.4806795009263643, 0.4417859002187087, 0.45971763138477506, 0.46071710529270116, 0.4632781839764512, 0.4728279819896629, 0.46442424033855173, 0.4704180324041808, 0.467318809694714, 0.465909287825719, 0.44368983762585745, 0.45441953112950195, 0.47126370149418995, 0.4551758055573974], 'loss': [0.11143311424226157, 0.07601123961859087, 0.06667794578965146, 0.062151637109724135, 0.05672699322863826, 0.0523957187654813, 0.05067549139766434, 0.04929715685882717, 0.04486798503994374, 0.043125320475000506, 0.04191796786425175, 0.04964422184481302, 0.04191612094143112, 0.03988552460382268, 0.04002775849198457, 0.03800320290499706, 0.03714724363379914, 0.03917731995957517, 0.03870837134612143, 0.03624512866053322, 0.035103151880894815, 0.036132502373071196, 0.03530708903770932, 0.0349813215138912, 0.03359037268563654, 0.03366726222897127, 0.03284258211947919, 0.033231510223944855, 0.03261822944565066, 0.03327596222311419, 0.03226211546534667, 0.03028001963645721, 0.02972971688705084, 0.028962360804863987, 0.029087619594063623, 0.02925120531267669, 0.029087873058548867, 0.028673777834141975, 0.028109879652573323, 0.027500581848425347, 0.02771353197604102, 0.02814967764758979, 0.027606962863494233, 0.029374841299104535, 0.02771029328608935, 0.02740168209042173, 0.02625952714205197, 0.026891127056556614, 0.02670433689137049, 0.025928314471311414, 0.025540729387095146, 0.02571646121333693, 0.026412215263349626, 0.0256443735542967, 0.02540787691941648, 0.02522085698345231], 'acc': [0.9875394550628279, 0.9919835870042392, 0.9930615153329939, 0.9934862740236149, 0.9939092484763838, 0.9942692523267215, 0.9944388218194248, 0.9946203985847554, 0.9949434236014626, 0.995086240614038, 0.9952361075721176, 0.9945474031781191, 0.9952715911696308, 0.9953665436846773, 0.9954584006218447, 0.9955264498192835, 0.9956125253329586, 0.9955060984413099, 0.9955801322879311, 0.9956925794303428, 0.9957550685183676, 0.9957859612678273, 0.9958204268334472, 0.9958519583376284, 0.9959527035076182, 0.9959416873045902, 0.9959717885432686, 0.9959599869825387, 0.9960159081957407, 0.9960026054274551, 0.9960513063388645, 0.9962181997113012, 0.9962438633234401, 0.9962762967721749, 0.9963168934575112, 0.9963083041069221, 0.9963302214889933, 0.9963565270005086, 0.9963861440417956, 0.9964006929600112, 0.9964018937300352, 0.9964055074645515, 0.9964162051340911, 0.996421327969966, 0.9964239228022271, 0.9964428156695664, 0.9965176660252726, 0.9965193934436375, 0.9965463996001648, 0.9965492930308455, 0.9965606036394197, 0.9965713525202893, 0.9965617944646143, 0.9965827551374556, 0.9965984188604412, 0.9965989208813282], 'mDice': [0.7844016585377185, 0.8522079213862158, 0.8702553735819173, 0.8790600957128993, 0.8896756384791428, 0.8981391329341755, 0.9014844254314858, 0.9041421790562632, 0.9128186359692207, 0.9162217058512412, 0.91854968993416, 0.903487715902071, 0.9185398164215364, 0.9225422212581212, 0.9222103079480448, 0.9262116715178612, 0.927878569746069, 0.923871807062244, 0.9247820996139233, 0.9296306295664634, 0.9318795377705167, 0.9298067479336135, 0.9314360557893036, 0.9320668283019563, 0.9347921069118986, 0.9346473856726402, 0.9362718567765862, 0.9355012381404523, 0.9367064734987437, 0.9353900878901839, 0.9373953795631336, 0.941257612806344, 0.9423380163418105, 0.9438486111314703, 0.9435807112383241, 0.9432612828705532, 0.9435747550499737, 0.9443885473575027, 0.9455041294362491, 0.946704606644033, 0.9462782600199818, 0.9454053565022544, 0.9464828964339598, 0.9429471822823655, 0.9462730040149714, 0.9468821648317446, 0.9491219698690276, 0.947845941297244, 0.9482185721480652, 0.9497557966060225, 0.9505343133325039, 0.9501679015911902, 0.9487849755723411, 0.9503134989517468, 0.9507778196870377, 0.9511451196514624], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:21,  1.22it/s]Loading train:   1%|          | 2/247 [00:01<03:15,  1.25it/s]Loading train:   1%|          | 3/247 [00:02<03:07,  1.30it/s]Loading train:   2%|▏         | 4/247 [00:03<03:15,  1.24it/s]Loading train:   2%|▏         | 5/247 [00:03<02:53,  1.40it/s]Loading train:   2%|▏         | 6/247 [00:04<02:36,  1.54it/s]Loading train:   3%|▎         | 7/247 [00:04<02:24,  1.66it/s]Loading train:   3%|▎         | 8/247 [00:05<02:15,  1.76it/s]Loading train:   4%|▎         | 9/247 [00:05<02:09,  1.84it/s]Loading train:   4%|▍         | 10/247 [00:06<02:06,  1.87it/s]Loading train:   4%|▍         | 11/247 [00:06<02:03,  1.91it/s]Loading train:   5%|▍         | 12/247 [00:07<02:01,  1.94it/s]Loading train:   5%|▌         | 13/247 [00:07<02:00,  1.95it/s]Loading train:   6%|▌         | 14/247 [00:08<01:57,  1.99it/s]Loading train:   6%|▌         | 15/247 [00:08<02:00,  1.93it/s]Loading train:   6%|▋         | 16/247 [00:09<01:58,  1.95it/s]Loading train:   7%|▋         | 17/247 [00:09<01:58,  1.94it/s]Loading train:   7%|▋         | 18/247 [00:10<01:56,  1.96it/s]Loading train:   8%|▊         | 19/247 [00:10<01:53,  2.01it/s]Loading train:   8%|▊         | 20/247 [00:11<01:52,  2.02it/s]Loading train:   9%|▊         | 21/247 [00:11<01:52,  2.00it/s]Loading train:   9%|▉         | 22/247 [00:12<01:52,  2.00it/s]Loading train:   9%|▉         | 23/247 [00:12<01:50,  2.03it/s]Loading train:  10%|▉         | 24/247 [00:13<01:47,  2.07it/s]Loading train:  10%|█         | 25/247 [00:13<01:45,  2.11it/s]Loading train:  11%|█         | 26/247 [00:14<01:43,  2.13it/s]Loading train:  11%|█         | 27/247 [00:14<01:42,  2.15it/s]Loading train:  11%|█▏        | 28/247 [00:14<01:42,  2.15it/s]Loading train:  12%|█▏        | 29/247 [00:15<01:41,  2.15it/s]Loading train:  12%|█▏        | 30/247 [00:15<01:41,  2.14it/s]Loading train:  13%|█▎        | 31/247 [00:16<01:42,  2.10it/s]Loading train:  13%|█▎        | 32/247 [00:16<01:41,  2.12it/s]Loading train:  13%|█▎        | 33/247 [00:17<01:40,  2.12it/s]Loading train:  14%|█▍        | 34/247 [00:17<01:40,  2.11it/s]Loading train:  14%|█▍        | 35/247 [00:18<01:39,  2.13it/s]Loading train:  15%|█▍        | 36/247 [00:18<01:37,  2.16it/s]Loading train:  15%|█▍        | 37/247 [00:19<01:38,  2.13it/s]Loading train:  15%|█▌        | 38/247 [00:19<01:40,  2.07it/s]Loading train:  16%|█▌        | 39/247 [00:20<01:40,  2.08it/s]Loading train:  16%|█▌        | 40/247 [00:20<01:38,  2.09it/s]Loading train:  17%|█▋        | 41/247 [00:21<01:37,  2.11it/s]Loading train:  17%|█▋        | 42/247 [00:21<01:38,  2.09it/s]Loading train:  17%|█▋        | 43/247 [00:22<01:37,  2.10it/s]Loading train:  18%|█▊        | 44/247 [00:22<01:39,  2.05it/s]Loading train:  18%|█▊        | 45/247 [00:23<01:37,  2.08it/s]Loading train:  19%|█▊        | 46/247 [00:23<01:35,  2.10it/s]Loading train:  19%|█▉        | 47/247 [00:23<01:35,  2.10it/s]Loading train:  19%|█▉        | 48/247 [00:24<01:33,  2.13it/s]Loading train:  20%|█▉        | 49/247 [00:24<01:30,  2.18it/s]Loading train:  20%|██        | 50/247 [00:25<01:30,  2.17it/s]Loading train:  21%|██        | 51/247 [00:25<01:33,  2.11it/s]Loading train:  21%|██        | 52/247 [00:26<01:34,  2.05it/s]Loading train:  21%|██▏       | 53/247 [00:26<01:33,  2.07it/s]Loading train:  22%|██▏       | 54/247 [00:27<01:34,  2.05it/s]Loading train:  22%|██▏       | 55/247 [00:27<01:32,  2.09it/s]Loading train:  23%|██▎       | 56/247 [00:28<01:29,  2.14it/s]Loading train:  23%|██▎       | 57/247 [00:28<01:28,  2.16it/s]Loading train:  23%|██▎       | 58/247 [00:29<01:27,  2.15it/s]Loading train:  24%|██▍       | 59/247 [00:29<01:33,  2.00it/s]Loading train:  24%|██▍       | 60/247 [00:30<01:40,  1.87it/s]Loading train:  25%|██▍       | 61/247 [00:30<01:41,  1.84it/s]Loading train:  25%|██▌       | 62/247 [00:31<01:41,  1.82it/s]Loading train:  26%|██▌       | 63/247 [00:32<01:41,  1.81it/s]Loading train:  26%|██▌       | 64/247 [00:32<01:41,  1.81it/s]Loading train:  26%|██▋       | 65/247 [00:33<01:39,  1.84it/s]Loading train:  27%|██▋       | 66/247 [00:33<01:39,  1.82it/s]Loading train:  27%|██▋       | 67/247 [00:34<01:42,  1.75it/s]Loading train:  28%|██▊       | 68/247 [00:34<01:41,  1.77it/s]Loading train:  28%|██▊       | 69/247 [00:35<01:40,  1.78it/s]Loading train:  28%|██▊       | 70/247 [00:35<01:39,  1.78it/s]Loading train:  29%|██▊       | 71/247 [00:36<01:36,  1.83it/s]Loading train:  29%|██▉       | 72/247 [00:37<01:37,  1.80it/s]Loading train:  30%|██▉       | 73/247 [00:37<01:37,  1.78it/s]Loading train:  30%|██▉       | 74/247 [00:38<01:38,  1.76it/s]Loading train:  30%|███       | 75/247 [00:38<01:39,  1.73it/s]Loading train:  31%|███       | 76/247 [00:39<01:38,  1.73it/s]Loading train:  31%|███       | 77/247 [00:40<01:49,  1.55it/s]Loading train:  32%|███▏      | 78/247 [00:41<02:01,  1.39it/s]Loading train:  32%|███▏      | 79/247 [00:41<02:07,  1.32it/s]Loading train:  32%|███▏      | 80/247 [00:42<02:02,  1.37it/s]Loading train:  33%|███▎      | 81/247 [00:43<02:03,  1.35it/s]Loading train:  33%|███▎      | 82/247 [00:43<01:52,  1.46it/s]Loading train:  34%|███▎      | 83/247 [00:44<01:44,  1.57it/s]Loading train:  34%|███▍      | 84/247 [00:44<01:37,  1.67it/s]Loading train:  34%|███▍      | 85/247 [00:45<01:33,  1.73it/s]Loading train:  35%|███▍      | 86/247 [00:45<01:29,  1.80it/s]Loading train:  35%|███▌      | 87/247 [00:46<01:27,  1.84it/s]Loading train:  36%|███▌      | 88/247 [00:47<01:25,  1.86it/s]Loading train:  36%|███▌      | 89/247 [00:47<01:24,  1.86it/s]Loading train:  36%|███▋      | 90/247 [00:48<01:22,  1.91it/s]Loading train:  37%|███▋      | 91/247 [00:48<01:20,  1.94it/s]Loading train:  37%|███▋      | 92/247 [00:49<01:19,  1.95it/s]Loading train:  38%|███▊      | 93/247 [00:49<01:17,  1.98it/s]Loading train:  38%|███▊      | 94/247 [00:50<01:18,  1.95it/s]Loading train:  38%|███▊      | 95/247 [00:50<01:20,  1.89it/s]Loading train:  39%|███▉      | 96/247 [00:51<01:20,  1.89it/s]Loading train:  39%|███▉      | 97/247 [00:51<01:19,  1.89it/s]Loading train:  40%|███▉      | 98/247 [00:52<01:18,  1.89it/s]Loading train:  40%|████      | 99/247 [00:52<01:18,  1.88it/s]Loading train:  40%|████      | 100/247 [00:53<01:19,  1.84it/s]Loading train:  41%|████      | 101/247 [00:53<01:20,  1.81it/s]Loading train:  41%|████▏     | 102/247 [00:54<01:20,  1.80it/s]Loading train:  42%|████▏     | 103/247 [00:55<01:19,  1.81it/s]Loading train:  42%|████▏     | 104/247 [00:55<01:20,  1.77it/s]Loading train:  43%|████▎     | 105/247 [00:56<01:20,  1.76it/s]Loading train:  43%|████▎     | 106/247 [00:56<01:21,  1.73it/s]Loading train:  43%|████▎     | 107/247 [00:57<01:20,  1.75it/s]Loading train:  44%|████▎     | 108/247 [00:57<01:18,  1.78it/s]Loading train:  44%|████▍     | 109/247 [00:58<01:18,  1.77it/s]Loading train:  45%|████▍     | 110/247 [00:58<01:16,  1.80it/s]Loading train:  45%|████▍     | 111/247 [00:59<01:15,  1.80it/s]Loading train:  45%|████▌     | 112/247 [01:00<01:16,  1.77it/s]Loading train:  46%|████▌     | 113/247 [01:00<01:14,  1.79it/s]Loading train:  46%|████▌     | 114/247 [01:01<01:15,  1.77it/s]Loading train:  47%|████▋     | 115/247 [01:01<01:13,  1.79it/s]Loading train:  47%|████▋     | 116/247 [01:02<01:12,  1.82it/s]Loading train:  47%|████▋     | 117/247 [01:02<01:11,  1.81it/s]Loading train:  48%|████▊     | 118/247 [01:03<01:13,  1.76it/s]Loading train:  48%|████▊     | 119/247 [01:04<01:13,  1.74it/s]Loading train:  49%|████▊     | 120/247 [01:04<01:13,  1.72it/s]Loading train:  49%|████▉     | 121/247 [01:05<01:13,  1.71it/s]Loading train:  49%|████▉     | 122/247 [01:05<01:14,  1.68it/s]Loading train:  50%|████▉     | 123/247 [01:06<01:14,  1.67it/s]Loading train:  50%|█████     | 124/247 [01:07<01:13,  1.67it/s]Loading train:  51%|█████     | 125/247 [01:07<01:12,  1.67it/s]Loading train:  51%|█████     | 126/247 [01:08<01:11,  1.68it/s]Loading train:  51%|█████▏    | 127/247 [01:08<01:10,  1.70it/s]Loading train:  52%|█████▏    | 128/247 [01:09<01:11,  1.67it/s]Loading train:  52%|█████▏    | 129/247 [01:10<01:10,  1.67it/s]Loading train:  53%|█████▎    | 130/247 [01:10<01:10,  1.66it/s]Loading train:  53%|█████▎    | 131/247 [01:11<01:09,  1.66it/s]Loading train:  53%|█████▎    | 132/247 [01:11<01:09,  1.66it/s]Loading train:  54%|█████▍    | 133/247 [01:12<01:08,  1.66it/s]Loading train:  54%|█████▍    | 134/247 [01:13<01:06,  1.69it/s]Loading train:  55%|█████▍    | 135/247 [01:13<01:05,  1.70it/s]Loading train:  55%|█████▌    | 136/247 [01:14<01:02,  1.78it/s]Loading train:  55%|█████▌    | 137/247 [01:14<00:58,  1.87it/s]Loading train:  56%|█████▌    | 138/247 [01:15<00:56,  1.93it/s]Loading train:  56%|█████▋    | 139/247 [01:15<00:55,  1.95it/s]Loading train:  57%|█████▋    | 140/247 [01:16<00:54,  1.96it/s]Loading train:  57%|█████▋    | 141/247 [01:16<00:52,  2.01it/s]Loading train:  57%|█████▋    | 142/247 [01:17<00:51,  2.03it/s]Loading train:  58%|█████▊    | 143/247 [01:17<00:49,  2.08it/s]Loading train:  58%|█████▊    | 144/247 [01:17<00:49,  2.09it/s]Loading train:  59%|█████▊    | 145/247 [01:18<00:47,  2.14it/s]Loading train:  59%|█████▉    | 146/247 [01:18<00:47,  2.14it/s]Loading train:  60%|█████▉    | 147/247 [01:19<00:45,  2.18it/s]Loading train:  60%|█████▉    | 148/247 [01:19<00:45,  2.20it/s]Loading train:  60%|██████    | 149/247 [01:20<00:44,  2.19it/s]Loading train:  61%|██████    | 150/247 [01:20<00:44,  2.19it/s]Loading train:  61%|██████    | 151/247 [01:21<00:43,  2.19it/s]Loading train:  62%|██████▏   | 152/247 [01:21<00:44,  2.14it/s]Loading train:  62%|██████▏   | 153/247 [01:22<00:44,  2.10it/s]Loading train:  62%|██████▏   | 154/247 [01:22<00:44,  2.08it/s]Loading train:  63%|██████▎   | 155/247 [01:23<00:44,  2.09it/s]Loading train:  63%|██████▎   | 156/247 [01:23<00:43,  2.12it/s]Loading train:  64%|██████▎   | 157/247 [01:24<00:42,  2.11it/s]Loading train:  64%|██████▍   | 158/247 [01:24<00:42,  2.08it/s]Loading train:  64%|██████▍   | 159/247 [01:25<00:42,  2.08it/s]Loading train:  65%|██████▍   | 160/247 [01:25<00:42,  2.07it/s]Loading train:  65%|██████▌   | 161/247 [01:25<00:41,  2.06it/s]Loading train:  66%|██████▌   | 162/247 [01:26<00:41,  2.04it/s]Loading train:  66%|██████▌   | 163/247 [01:26<00:40,  2.05it/s]Loading train:  66%|██████▋   | 164/247 [01:27<00:39,  2.08it/s]Loading train:  67%|██████▋   | 165/247 [01:27<00:39,  2.06it/s]Loading train:  67%|██████▋   | 166/247 [01:28<00:38,  2.08it/s]Loading train:  68%|██████▊   | 167/247 [01:28<00:38,  2.08it/s]Loading train:  68%|██████▊   | 168/247 [01:29<00:38,  2.03it/s]Loading train:  68%|██████▊   | 169/247 [01:29<00:38,  2.04it/s]Loading train:  69%|██████▉   | 170/247 [01:30<00:37,  2.05it/s]Loading train:  69%|██████▉   | 171/247 [01:30<00:36,  2.09it/s]Loading train:  70%|██████▉   | 172/247 [01:31<00:43,  1.73it/s]Loading train:  70%|███████   | 173/247 [01:32<00:47,  1.57it/s]Loading train:  70%|███████   | 174/247 [01:33<00:49,  1.48it/s]Loading train:  71%|███████   | 175/247 [01:34<00:53,  1.35it/s]Loading train:  71%|███████▏  | 176/247 [01:34<00:48,  1.47it/s]Loading train:  72%|███████▏  | 177/247 [01:35<00:44,  1.56it/s]Loading train:  72%|███████▏  | 178/247 [01:35<00:42,  1.64it/s]Loading train:  72%|███████▏  | 179/247 [01:36<00:40,  1.68it/s]Loading train:  73%|███████▎  | 180/247 [01:36<00:39,  1.72it/s]Loading train:  73%|███████▎  | 181/247 [01:37<00:37,  1.76it/s]Loading train:  74%|███████▎  | 182/247 [01:37<00:36,  1.77it/s]Loading train:  74%|███████▍  | 183/247 [01:38<00:36,  1.76it/s]Loading train:  74%|███████▍  | 184/247 [01:39<00:34,  1.80it/s]Loading train:  75%|███████▍  | 185/247 [01:39<00:33,  1.82it/s]Loading train:  75%|███████▌  | 186/247 [01:40<00:33,  1.84it/s]Loading train:  76%|███████▌  | 187/247 [01:40<00:32,  1.84it/s]Loading train:  76%|███████▌  | 188/247 [01:41<00:32,  1.82it/s]Loading train:  77%|███████▋  | 189/247 [01:41<00:31,  1.82it/s]Loading train:  77%|███████▋  | 190/247 [01:42<00:31,  1.80it/s]Loading train:  77%|███████▋  | 191/247 [01:42<00:30,  1.82it/s]Loading train:  78%|███████▊  | 192/247 [01:43<00:29,  1.84it/s]Loading train:  78%|███████▊  | 193/247 [01:43<00:29,  1.86it/s]Loading train:  79%|███████▊  | 194/247 [01:44<00:28,  1.85it/s]Loading train:  79%|███████▉  | 195/247 [01:44<00:28,  1.85it/s]Loading train:  79%|███████▉  | 196/247 [01:45<00:27,  1.84it/s]Loading train:  80%|███████▉  | 197/247 [01:46<00:27,  1.85it/s]Loading train:  80%|████████  | 198/247 [01:46<00:26,  1.85it/s]Loading train:  81%|████████  | 199/247 [01:47<00:25,  1.86it/s]Loading train:  81%|████████  | 200/247 [01:47<00:25,  1.87it/s]Loading train:  81%|████████▏ | 201/247 [01:48<00:23,  1.93it/s]Loading train:  82%|████████▏ | 202/247 [01:48<00:22,  1.96it/s]Loading train:  82%|████████▏ | 203/247 [01:49<00:23,  1.90it/s]Loading train:  83%|████████▎ | 204/247 [01:49<00:23,  1.86it/s]Loading train:  83%|████████▎ | 205/247 [01:50<00:22,  1.85it/s]Loading train:  83%|████████▎ | 206/247 [01:50<00:22,  1.85it/s]Loading train:  84%|████████▍ | 207/247 [01:51<00:21,  1.84it/s]Loading train:  84%|████████▍ | 208/247 [01:51<00:20,  1.89it/s]Loading train:  85%|████████▍ | 209/247 [01:52<00:20,  1.88it/s]Loading train:  85%|████████▌ | 210/247 [01:52<00:19,  1.91it/s]Loading train:  85%|████████▌ | 211/247 [01:53<00:18,  1.94it/s]Loading train:  86%|████████▌ | 212/247 [01:53<00:17,  1.97it/s]Loading train:  86%|████████▌ | 213/247 [01:54<00:17,  2.00it/s]Loading train:  87%|████████▋ | 214/247 [01:54<00:16,  2.01it/s]Loading train:  87%|████████▋ | 215/247 [01:55<00:15,  2.04it/s]Loading train:  87%|████████▋ | 216/247 [01:55<00:15,  2.02it/s]Loading train:  88%|████████▊ | 217/247 [01:56<00:14,  2.01it/s]Loading train:  88%|████████▊ | 218/247 [01:56<00:14,  2.01it/s]Loading train:  89%|████████▊ | 219/247 [01:57<00:13,  2.02it/s]Loading train:  89%|████████▉ | 220/247 [01:57<00:13,  2.01it/s]Loading train:  89%|████████▉ | 221/247 [01:58<00:12,  2.00it/s]Loading train:  90%|████████▉ | 222/247 [01:58<00:12,  1.95it/s]Loading train:  90%|█████████ | 223/247 [01:59<00:12,  1.91it/s]Loading train:  91%|█████████ | 224/247 [01:59<00:11,  1.93it/s]Loading train:  91%|█████████ | 225/247 [02:00<00:11,  1.94it/s]Loading train:  91%|█████████▏| 226/247 [02:01<00:16,  1.28it/s]Loading train:  92%|█████████▏| 227/247 [02:06<00:39,  1.97s/it]Loading train:  92%|█████████▏| 228/247 [02:10<00:47,  2.49s/it]Loading train:  93%|█████████▎| 229/247 [02:14<00:51,  2.88s/it]Loading train:  93%|█████████▎| 230/247 [02:20<01:05,  3.88s/it]Loading train:  94%|█████████▎| 231/247 [02:26<01:12,  4.52s/it]Loading train:  94%|█████████▍| 232/247 [02:32<01:14,  4.96s/it]Loading train:  94%|█████████▍| 233/247 [02:38<01:14,  5.31s/it]Loading train:  95%|█████████▍| 234/247 [02:44<01:10,  5.44s/it]Loading train:  95%|█████████▌| 235/247 [02:49<01:05,  5.50s/it]Loading train:  96%|█████████▌| 236/247 [02:55<01:00,  5.50s/it]Loading train:  96%|█████████▌| 237/247 [03:01<00:56,  5.63s/it]Loading train:  96%|█████████▋| 238/247 [03:06<00:50,  5.66s/it]Loading train:  97%|█████████▋| 239/247 [03:12<00:45,  5.70s/it]Loading train:  97%|█████████▋| 240/247 [03:18<00:39,  5.63s/it]Loading train:  98%|█████████▊| 241/247 [03:24<00:34,  5.76s/it]Loading train:  98%|█████████▊| 242/247 [03:29<00:28,  5.71s/it]Loading train:  98%|█████████▊| 243/247 [03:35<00:23,  5.76s/it]Loading train:  99%|█████████▉| 244/247 [03:41<00:17,  5.68s/it]Loading train:  99%|█████████▉| 245/247 [03:47<00:11,  5.77s/it]Loading train: 100%|█████████▉| 246/247 [03:53<00:05,  5.77s/it]Loading train: 100%|██████████| 247/247 [03:58<00:00,  5.82s/it]Loading train: 100%|██████████| 247/247 [03:58<00:00,  1.03it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 59.37it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:03, 59.25it/s]concatenating: train:   8%|▊         | 19/247 [00:00<00:03, 59.97it/s]concatenating: train:  11%|█         | 26/247 [00:00<00:03, 60.35it/s]concatenating: train:  13%|█▎        | 33/247 [00:00<00:03, 60.46it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:03, 61.06it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 61.23it/s]concatenating: train:  22%|██▏       | 54/247 [00:00<00:03, 61.14it/s]concatenating: train:  24%|██▍       | 60/247 [00:00<00:03, 60.74it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 59.26it/s]concatenating: train:  29%|██▉       | 72/247 [00:01<00:03, 58.18it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:02, 58.25it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:02, 58.56it/s]concatenating: train:  37%|███▋      | 91/247 [00:01<00:02, 59.36it/s]concatenating: train:  39%|███▉      | 97/247 [00:01<00:02, 59.10it/s]concatenating: train:  42%|████▏     | 104/247 [00:01<00:02, 60.23it/s]concatenating: train:  45%|████▍     | 111/247 [00:01<00:02, 60.74it/s]concatenating: train:  48%|████▊     | 118/247 [00:01<00:02, 60.95it/s]concatenating: train:  51%|█████     | 125/247 [00:02<00:02, 58.17it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 56.59it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:01, 56.05it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:01, 57.09it/s]concatenating: train:  60%|██████    | 149/247 [00:02<00:01, 57.63it/s]concatenating: train:  63%|██████▎   | 156/247 [00:02<00:01, 59.41it/s]concatenating: train:  66%|██████▌   | 163/247 [00:02<00:01, 61.04it/s]concatenating: train:  69%|██████▉   | 170/247 [00:02<00:01, 59.82it/s]concatenating: train:  72%|███████▏  | 177/247 [00:02<00:01, 56.65it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:01, 53.54it/s]concatenating: train:  77%|███████▋  | 189/247 [00:03<00:01, 52.37it/s]concatenating: train:  79%|███████▉  | 195/247 [00:03<00:01, 50.34it/s]concatenating: train:  81%|████████▏ | 201/247 [00:03<00:00, 47.88it/s]concatenating: train:  83%|████████▎ | 206/247 [00:03<00:00, 45.56it/s]concatenating: train:  85%|████████▌ | 211/247 [00:03<00:00, 43.99it/s]concatenating: train:  88%|████████▊ | 217/247 [00:03<00:00, 46.02it/s]concatenating: train:  90%|█████████ | 223/247 [00:03<00:00, 47.15it/s]concatenating: train:  93%|█████████▎| 229/247 [00:04<00:00, 47.84it/s]concatenating: train:  95%|█████████▌| 235/247 [00:04<00:00, 48.74it/s]concatenating: train:  97%|█████████▋| 240/247 [00:04<00:00, 49.10it/s]concatenating: train: 100%|█████████▉| 246/247 [00:04<00:00, 49.76it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 55.29it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:14<00:56, 14.14s/it]Loading test:  40%|████      | 2/5 [00:28<00:42, 14.16s/it]Loading test:  60%|██████    | 3/5 [00:34<00:23, 11.75s/it]Loading test:  80%|████████  | 4/5 [00:39<00:09,  9.87s/it]Loading test: 100%|██████████| 5/5 [00:52<00:00, 10.72s/it]Loading test: 100%|██████████| 5/5 [00:52<00:00, 10.53s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 52.44it/s]
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 40, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 40, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 40, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 40, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 40, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 40, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 40, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 40, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 20, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 20, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 20, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 20, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 20, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 20, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 20, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 20, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 20, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 40, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 40, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 40, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 40, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 40, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 40, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 40, 24, 80)   0           batch_normalization_8[0][0]      2020-01-21 18:53:03.547075: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 18:53:03.547174: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 18:53:03.547189: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 18:53:03.547197: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 18:53:03.547497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 40, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 80, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 80, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 80, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 80, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 80, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 80, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 80, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 80, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.22607173e-02 3.14043656e-02 7.85951242e-02 9.57280094e-03
 2.85240388e-02 7.21930367e-03 8.59059512e-02 1.14988713e-01
 8.99457685e-02 1.30456602e-02 2.93654711e-01 1.84603341e-01
 2.79503891e-04]
Train on 9236 samples, validate on 193 samples
Epoch 1/300
 - 26s - loss: 0.5561 - acc: 0.9025 - mDice: 0.4012 - val_loss: 0.6700 - val_acc: 0.9362 - val_mDice: 0.2765

Epoch 00001: val_mDice improved from -inf to 0.27652, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.3873 - acc: 0.9318 - mDice: 0.5829 - val_loss: 0.6456 - val_acc: 0.9386 - val_mDice: 0.3028

Epoch 00002: val_mDice improved from 0.27652 to 0.30276, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 0.3530 - acc: 0.9366 - mDice: 0.6199 - val_loss: 0.6532 - val_acc: 0.9383 - val_mDice: 0.2929

Epoch 00003: val_mDice did not improve from 0.30276
Epoch 4/300
 - 21s - loss: 0.3330 - acc: 0.9394 - mDice: 0.6415 - val_loss: 0.6489 - val_acc: 0.9414 - val_mDice: 0.2948

Epoch 00004: val_mDice did not improve from 0.30276
Epoch 5/300
 - 21s - loss: 0.3214 - acc: 0.9414 - mDice: 0.6540 - val_loss: 0.6474 - val_acc: 0.9349 - val_mDice: 0.2885

Epoch 00005: val_mDice did not improve from 0.30276
Epoch 6/300
 - 21s - loss: 0.3103 - acc: 0.9428 - mDice: 0.6659 - val_loss: 0.6480 - val_acc: 0.9379 - val_mDice: 0.2883

Epoch 00006: val_mDice did not improve from 0.30276
Epoch 7/300
 - 22s - loss: 0.3032 - acc: 0.9439 - mDice: 0.6736 - val_loss: 0.6234 - val_acc: 0.9312 - val_mDice: 0.2656

Epoch 00007: val_mDice did not improve from 0.30276
Epoch 8/300
 - 21s - loss: 0.2977 - acc: 0.9442 - mDice: 0.6796 - val_loss: 0.6438 - val_acc: 0.9341 - val_mDice: 0.2915

Epoch 00008: val_mDice did not improve from 0.30276
Epoch 9/300
 - 21s - loss: 0.2810 - acc: 0.9463 - mDice: 0.6976 - val_loss: 0.5620 - val_acc: 0.9404 - val_mDice: 0.2944

Epoch 00009: val_mDice did not improve from 0.30276
Epoch 10/300
 - 21s - loss: 0.2859 - acc: 0.9465 - mDice: 0.6923 - val_loss: 0.6208 - val_acc: 0.9364 - val_mDice: 0.2903

Epoch 00010: val_mDice did not improve from 0.30276
Epoch 11/300
 - 21s - loss: 0.2812 - acc: 0.9471 - mDice: 0.6973 - val_loss: 0.5486 - val_acc: 0.9391 - val_mDice: 0.2962

Epoch 00011: val_mDice did not improve from 0.30276
Epoch 12/300
 - 21s - loss: 0.2758 - acc: 0.9476 - mDice: 0.7031 - val_loss: 0.4218 - val_acc: 0.9414 - val_mDice: 0.2930

Epoch 00012: val_mDice did not improve from 0.30276
Epoch 13/300
 - 21s - loss: 0.2681 - acc: 0.9482 - mDice: 0.7114 - val_loss: 0.5332 - val_acc: 0.9390 - val_mDice: 0.2905

Epoch 00013: val_mDice did not improve from 0.30276
Epoch 14/300
 - 21s - loss: 0.2713 - acc: 0.9478 - mDice: 0.7080 - val_loss: 0.5636 - val_acc: 0.9355 - val_mDice: 0.2917

Epoch 00014: val_mDice did not improve from 0.30276
Epoch 15/300
 - 21s - loss: 0.2636 - acc: 0.9493 - mDice: 0.7163 - val_loss: 0.4579 - val_acc: 0.9291 - val_mDice: 0.2656

Epoch 00015: val_mDice did not improve from 0.30276
Epoch 16/300
 - 21s - loss: 0.2624 - acc: 0.9494 - mDice: 0.7176 - val_loss: 0.4643 - val_acc: 0.9383 - val_mDice: 0.2807

Epoch 00016: val_mDice did not improve from 0.30276
Epoch 17/300
 - 21s - loss: 0.2583 - acc: 0.9499 - mDice: 0.7220 - val_loss: 0.2937 - val_acc: 0.9393 - val_mDice: 0.2965

Epoch 00017: val_mDice did not improve from 0.30276

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 18/300
 - 21s - loss: 0.2431 - acc: 0.9515 - mDice: 0.7385 - val_loss: 0.3556 - val_acc: 0.9376 - val_mDice: 0.2869

Epoch 00018: val_mDice did not improve from 0.30276
Epoch 19/300
 - 21s - loss: 0.2416 - acc: 0.9518 - mDice: 0.7401 - val_loss: 0.2373 - val_acc: 0.9390 - val_mDice: 0.2802

Epoch 00019: val_mDice did not improve from 0.30276
Epoch 20/300
 - 21s - loss: 0.2359 - acc: 0.9523 - mDice: 0.7461 - val_loss: 0.2141 - val_acc: 0.9399 - val_mDice: 0.2816

Epoch 00020: val_mDice did not improve from 0.30276
Epoch 21/300
 - 22s - loss: 0.2328 - acc: 0.9527 - mDice: 0.7495 - val_loss: 0.2253 - val_acc: 0.9317 - val_mDice: 0.2747

Epoch 00021: val_mDice did not improve from 0.30276
Epoch 22/300
 - 22s - loss: 0.2377 - acc: 0.9527 - mDice: 0.7442 - val_loss: 0.2527 - val_acc: 0.9393 - val_mDice: 0.2886

Epoch 00022: val_mDice did not improve from 0.30276
Epoch 23/300
 - 21s - loss: 0.2346 - acc: 0.9530 - mDice: 0.7475 - val_loss: 0.2592 - val_acc: 0.9366 - val_mDice: 0.2825

Epoch 00023: val_mDice did not improve from 0.30276
Epoch 24/300
 - 21s - loss: 0.2307 - acc: 0.9532 - mDice: 0.7518 - val_loss: 0.3447 - val_acc: 0.9381 - val_mDice: 0.2744

Epoch 00024: val_mDice did not improve from 0.30276
Epoch 25/300
 - 21s - loss: 0.2332 - acc: 0.9533 - mDice: 0.7490 - val_loss: 0.2299 - val_acc: 0.9371 - val_mDice: 0.2863

Epoch 00025: val_mDice did not improve from 0.30276
Epoch 26/300
 - 21s - loss: 0.2291 - acc: 0.9534 - mDice: 0.7535 - val_loss: 0.2234 - val_acc: 0.9370 - val_mDice: 0.2684

Epoch 00026: val_mDice did not improve from 0.30276
Epoch 27/300
 - 21s - loss: 0.2276 - acc: 0.9535 - mDice: 0.7552 - val_loss: 0.1422 - val_acc: 0.9404 - val_mDice: 0.2942

Epoch 00027: val_mDice did not improve from 0.30276
Epoch 28/300
 - 21s - loss: 0.2254 - acc: 0.9540 - mDice: 0.7575 - val_loss: 0.3238 - val_acc: 0.9402 - val_mDice: 0.2888

Epoch 00028: val_mDice did not improve from 0.30276
Epoch 29/300
 - 21s - loss: 0.2263 - acc: 0.9537 - mDice: 0.7566 - val_loss: 0.2733 - val_acc: 0.9366 - val_mDice: 0.2820

Epoch 00029: val_mDice did not improve from 0.30276
Epoch 30/300
 - 21s - loss: 0.2244 - acc: 0.9538 - mDice: 0.7586 - val_loss: 0.1978 - val_acc: 0.9366 - val_mDice: 0.2838

Epoch 00030: val_mDice did not improve from 0.30276
Epoch 31/300
 - 21s - loss: 0.2246 - acc: 0.9540 - mDice: 0.7583 - val_loss: 0.1126 - val_acc: 0.9399 - val_mDice: 0.2919

Epoch 00031: val_mDice did not improve from 0.30276
Epoch 32/300
 - 21s - loss: 0.2205 - acc: 0.9541 - mDice: 0.7627 - val_loss: 0.1664 - val_acc: 0.9373 - val_mDice: 0.2695

Epoch 00032: val_mDice did not improve from 0.30276

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 33/300
 - 21s - loss: 0.2181 - acc: 0.9547 - mDice: 0.7653 - val_loss: 0.0708 - val_acc: 0.9392 - val_mDice: 0.2879

Epoch 00033: val_mDice did not improve from 0.30276
Epoch 34/300
 - 21s - loss: 0.2151 - acc: 0.9551 - mDice: 0.7686 - val_loss: 0.0895 - val_acc: 0.9385 - val_mDice: 0.2890

Epoch 00034: val_mDice did not improve from 0.30276
Epoch 35/300
 - 21s - loss: 0.2145 - acc: 0.9551 - mDice: 0.7693 - val_loss: 0.1200 - val_acc: 0.9370 - val_mDice: 0.2772

Epoch 00035: val_mDice did not improve from 0.30276
Epoch 36/300
 - 21s - loss: 0.2128 - acc: 0.9553 - mDice: 0.7711 - val_loss: 0.1341 - val_acc: 0.9361 - val_mDice: 0.2783

Epoch 00036: val_mDice did not improve from 0.30276
Epoch 37/300
 - 22s - loss: 0.2152 - acc: 0.9552 - mDice: 0.7685 - val_loss: 0.0414 - val_acc: 0.9398 - val_mDice: 0.2856

Epoch 00037: val_mDice did not improve from 0.30276
Epoch 38/300
 - 21s - loss: 0.2135 - acc: 0.9554 - mDice: 0.7703 - val_loss: 0.1046 - val_acc: 0.9367 - val_mDice: 0.2778

Epoch 00038: val_mDice did not improve from 0.30276
Epoch 39/300
 - 22s - loss: 0.2122 - acc: 0.9554 - mDice: 0.7717 - val_loss: 0.1648 - val_acc: 0.9372 - val_mDice: 0.2823

Epoch 00039: val_mDice did not improve from 0.30276
Epoch 40/300
 - 22s - loss: 0.2129 - acc: 0.9556 - mDice: 0.7710 - val_loss: 0.1087 - val_acc: 0.9358 - val_mDice: 0.2773

Epoch 00040: val_mDice did not improve from 0.30276
Epoch 41/300
 - 21s - loss: 0.2096 - acc: 0.9556 - mDice: 0.7745 - val_loss: 0.0904 - val_acc: 0.9381 - val_mDice: 0.2797

Epoch 00041: val_mDice did not improve from 0.30276
Epoch 42/300
 - 22s - loss: 0.2092 - acc: 0.9557 - mDice: 0.7749 - val_loss: 0.0738 - val_acc: 0.9383 - val_mDice: 0.2802

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.66s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.48s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.31s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.18s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.15s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.12s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:18,  3.15it/s]Loading train:   1%|          | 2/247 [00:00<01:16,  3.20it/s]Loading train:   1%|          | 3/247 [00:00<01:13,  3.31it/s]Loading train:   2%|▏         | 4/247 [00:01<01:14,  3.27it/s]Loading train:   2%|▏         | 5/247 [00:01<01:13,  3.30it/s]Loading train:   2%|▏         | 6/247 [00:01<01:12,  3.34it/s]Loading train:   3%|▎         | 7/247 [00:02<01:11,  3.38it/s]Loading train:   3%|▎         | 8/247 [00:02<01:10,  3.39it/s]Loading train:   4%|▎         | 9/247 [00:02<01:10,  3.39it/s]Loading train:   4%|▍         | 10/247 [00:02<01:10,  3.38it/s]Loading train:   4%|▍         | 11/247 [00:03<01:10,  3.36it/s]Loading train:   5%|▍         | 12/247 [00:03<01:09,  3.37it/s]Loading train:   5%|▌         | 13/247 [00:03<01:09,  3.39it/s]Loading train:   6%|▌         | 14/247 [00:04<01:08,  3.40it/s]Loading train:   6%|▌         | 15/247 [00:04<01:07,  3.42it/s]Loading train:   6%|▋         | 16/247 [00:04<01:07,  3.44it/s]Loading train:   7%|▋         | 17/247 [00:05<01:07,  3.42it/s]Loading train:   7%|▋         | 18/247 [00:05<01:07,  3.41it/s]Loading train:   8%|▊         | 19/247 [00:05<01:06,  3.40it/s]Loading train:   8%|▊         | 20/247 [00:05<01:06,  3.43it/s]Loading train:   9%|▊         | 21/247 [00:06<01:05,  3.45it/s]Loading train:   9%|▉         | 22/247 [00:06<01:05,  3.43it/s]Loading train:   9%|▉         | 23/247 [00:06<01:04,  3.50it/s]Loading train:  10%|▉         | 24/247 [00:07<01:01,  3.63it/s]Loading train:  10%|█         | 25/247 [00:07<00:59,  3.74it/s]Loading train:  11%|█         | 26/247 [00:07<00:57,  3.82it/s]Loading train:  11%|█         | 27/247 [00:07<00:56,  3.88it/s]Loading train:  11%|█▏        | 28/247 [00:07<00:55,  3.93it/s]Loading train:  12%|█▏        | 29/247 [00:08<00:55,  3.96it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:54,  3.95it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:55,  3.91it/s]Loading train:  13%|█▎        | 32/247 [00:09<00:54,  3.94it/s]Loading train:  13%|█▎        | 33/247 [00:09<00:54,  3.94it/s]Loading train:  14%|█▍        | 34/247 [00:09<00:53,  3.96it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:53,  3.98it/s]Loading train:  15%|█▍        | 36/247 [00:10<00:53,  3.97it/s]Loading train:  15%|█▍        | 37/247 [00:10<00:55,  3.81it/s]Loading train:  15%|█▌        | 38/247 [00:10<00:54,  3.83it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:53,  3.86it/s]Loading train:  16%|█▌        | 40/247 [00:11<00:53,  3.89it/s]Loading train:  17%|█▋        | 41/247 [00:11<00:54,  3.81it/s]Loading train:  17%|█▋        | 42/247 [00:11<00:54,  3.78it/s]Loading train:  17%|█▋        | 43/247 [00:11<00:54,  3.76it/s]Loading train:  18%|█▊        | 44/247 [00:12<00:54,  3.75it/s]Loading train:  18%|█▊        | 45/247 [00:12<00:53,  3.76it/s]Loading train:  19%|█▊        | 46/247 [00:12<00:53,  3.76it/s]Loading train:  19%|█▉        | 47/247 [00:12<00:53,  3.77it/s]Loading train:  19%|█▉        | 48/247 [00:13<00:53,  3.74it/s]Loading train:  20%|█▉        | 49/247 [00:13<00:53,  3.72it/s]Loading train:  20%|██        | 50/247 [00:13<00:53,  3.72it/s]Loading train:  21%|██        | 51/247 [00:14<00:52,  3.72it/s]Loading train:  21%|██        | 52/247 [00:14<00:52,  3.73it/s]Loading train:  21%|██▏       | 53/247 [00:14<00:52,  3.71it/s]Loading train:  22%|██▏       | 54/247 [00:14<00:52,  3.71it/s]Loading train:  22%|██▏       | 55/247 [00:15<00:51,  3.72it/s]Loading train:  23%|██▎       | 56/247 [00:15<00:51,  3.73it/s]Loading train:  23%|██▎       | 57/247 [00:15<00:50,  3.77it/s]Loading train:  23%|██▎       | 58/247 [00:15<00:50,  3.78it/s]Loading train:  24%|██▍       | 59/247 [00:16<00:50,  3.72it/s]Loading train:  24%|██▍       | 60/247 [00:16<00:51,  3.66it/s]Loading train:  25%|██▍       | 61/247 [00:16<00:51,  3.63it/s]Loading train:  25%|██▌       | 62/247 [00:17<00:51,  3.59it/s]Loading train:  26%|██▌       | 63/247 [00:17<00:51,  3.57it/s]Loading train:  26%|██▌       | 64/247 [00:17<00:51,  3.54it/s]Loading train:  26%|██▋       | 65/247 [00:17<00:51,  3.50it/s]Loading train:  27%|██▋       | 66/247 [00:18<00:51,  3.50it/s]Loading train:  27%|██▋       | 67/247 [00:18<00:51,  3.47it/s]Loading train:  28%|██▊       | 68/247 [00:18<00:51,  3.46it/s]Loading train:  28%|██▊       | 69/247 [00:19<00:51,  3.47it/s]Loading train:  28%|██▊       | 70/247 [00:19<00:51,  3.45it/s]Loading train:  29%|██▊       | 71/247 [00:19<00:51,  3.43it/s]Loading train:  29%|██▉       | 72/247 [00:19<00:51,  3.42it/s]Loading train:  30%|██▉       | 73/247 [00:20<00:50,  3.42it/s]Loading train:  30%|██▉       | 74/247 [00:20<00:50,  3.41it/s]Loading train:  30%|███       | 75/247 [00:20<00:50,  3.43it/s]Loading train:  31%|███       | 76/247 [00:21<00:49,  3.44it/s]Loading train:  31%|███       | 77/247 [00:21<00:50,  3.35it/s]Loading train:  32%|███▏      | 78/247 [00:21<00:52,  3.23it/s]Loading train:  32%|███▏      | 79/247 [00:22<00:52,  3.21it/s]Loading train:  32%|███▏      | 80/247 [00:22<00:50,  3.30it/s]Loading train:  33%|███▎      | 81/247 [00:22<00:50,  3.30it/s]Loading train:  33%|███▎      | 82/247 [00:22<00:50,  3.29it/s]Loading train:  34%|███▎      | 83/247 [00:23<00:50,  3.27it/s]Loading train:  34%|███▍      | 84/247 [00:23<00:49,  3.27it/s]Loading train:  34%|███▍      | 85/247 [00:23<00:49,  3.26it/s]Loading train:  35%|███▍      | 86/247 [00:24<00:49,  3.25it/s]Loading train:  35%|███▌      | 87/247 [00:24<00:49,  3.26it/s]Loading train:  36%|███▌      | 88/247 [00:24<00:48,  3.25it/s]Loading train:  36%|███▌      | 89/247 [00:25<00:48,  3.25it/s]Loading train:  36%|███▋      | 90/247 [00:25<00:48,  3.22it/s]Loading train:  37%|███▋      | 91/247 [00:25<00:48,  3.20it/s]Loading train:  37%|███▋      | 92/247 [00:26<00:48,  3.22it/s]Loading train:  38%|███▊      | 93/247 [00:26<00:47,  3.22it/s]Loading train:  38%|███▊      | 94/247 [00:26<00:47,  3.22it/s]Loading train:  38%|███▊      | 95/247 [00:26<00:47,  3.23it/s]Loading train:  39%|███▉      | 96/247 [00:27<00:46,  3.24it/s]Loading train:  39%|███▉      | 97/247 [00:27<00:46,  3.25it/s]Loading train:  40%|███▉      | 98/247 [00:27<00:45,  3.27it/s]Loading train:  40%|████      | 99/247 [00:28<00:44,  3.29it/s]Loading train:  40%|████      | 100/247 [00:28<00:45,  3.25it/s]Loading train:  41%|████      | 101/247 [00:28<00:45,  3.22it/s]Loading train:  41%|████▏     | 102/247 [00:29<00:45,  3.21it/s]Loading train:  42%|████▏     | 103/247 [00:29<00:44,  3.21it/s]Loading train:  42%|████▏     | 104/247 [00:29<00:44,  3.23it/s]Loading train:  43%|████▎     | 105/247 [00:30<00:43,  3.23it/s]Loading train:  43%|████▎     | 106/247 [00:30<00:45,  3.13it/s]Loading train:  43%|████▎     | 107/247 [00:30<00:45,  3.10it/s]Loading train:  44%|████▎     | 108/247 [00:31<00:45,  3.07it/s]Loading train:  44%|████▍     | 109/247 [00:31<00:44,  3.09it/s]Loading train:  45%|████▍     | 110/247 [00:31<00:44,  3.05it/s]Loading train:  45%|████▍     | 111/247 [00:32<00:44,  3.05it/s]Loading train:  45%|████▌     | 112/247 [00:32<00:44,  3.02it/s]Loading train:  46%|████▌     | 113/247 [00:32<00:44,  3.03it/s]Loading train:  46%|████▌     | 114/247 [00:33<00:43,  3.05it/s]Loading train:  47%|████▋     | 115/247 [00:33<00:43,  3.03it/s]Loading train:  47%|████▋     | 116/247 [00:33<00:43,  3.03it/s]Loading train:  47%|████▋     | 117/247 [00:34<00:42,  3.07it/s]Loading train:  48%|████▊     | 118/247 [00:34<00:40,  3.17it/s]Loading train:  48%|████▊     | 119/247 [00:34<00:39,  3.24it/s]Loading train:  49%|████▊     | 120/247 [00:34<00:38,  3.28it/s]Loading train:  49%|████▉     | 121/247 [00:35<00:38,  3.26it/s]Loading train:  49%|████▉     | 122/247 [00:35<00:39,  3.19it/s]Loading train:  50%|████▉     | 123/247 [00:35<00:39,  3.15it/s]Loading train:  50%|█████     | 124/247 [00:36<00:39,  3.15it/s]Loading train:  51%|█████     | 125/247 [00:36<00:38,  3.16it/s]Loading train:  51%|█████     | 126/247 [00:36<00:37,  3.20it/s]Loading train:  51%|█████▏    | 127/247 [00:37<00:37,  3.23it/s]Loading train:  52%|█████▏    | 128/247 [00:37<00:36,  3.28it/s]Loading train:  52%|█████▏    | 129/247 [00:37<00:35,  3.29it/s]Loading train:  53%|█████▎    | 130/247 [00:37<00:35,  3.32it/s]Loading train:  53%|█████▎    | 131/247 [00:38<00:34,  3.33it/s]Loading train:  53%|█████▎    | 132/247 [00:38<00:34,  3.35it/s]Loading train:  54%|█████▍    | 133/247 [00:38<00:34,  3.34it/s]Loading train:  54%|█████▍    | 134/247 [00:39<00:33,  3.34it/s]Loading train:  55%|█████▍    | 135/247 [00:39<00:33,  3.32it/s]Loading train:  55%|█████▌    | 136/247 [00:39<00:32,  3.40it/s]Loading train:  55%|█████▌    | 137/247 [00:40<00:31,  3.46it/s]Loading train:  56%|█████▌    | 138/247 [00:40<00:30,  3.57it/s]Loading train:  56%|█████▋    | 139/247 [00:40<00:30,  3.60it/s]Loading train:  57%|█████▋    | 140/247 [00:40<00:29,  3.61it/s]Loading train:  57%|█████▋    | 141/247 [00:41<00:29,  3.65it/s]Loading train:  57%|█████▋    | 142/247 [00:41<00:28,  3.71it/s]Loading train:  58%|█████▊    | 143/247 [00:41<00:27,  3.73it/s]Loading train:  58%|█████▊    | 144/247 [00:41<00:27,  3.77it/s]Loading train:  59%|█████▊    | 145/247 [00:42<00:26,  3.80it/s]Loading train:  59%|█████▉    | 146/247 [00:42<00:26,  3.78it/s]Loading train:  60%|█████▉    | 147/247 [00:42<00:26,  3.82it/s]Loading train:  60%|█████▉    | 148/247 [00:42<00:25,  3.83it/s]Loading train:  60%|██████    | 149/247 [00:43<00:25,  3.81it/s]Loading train:  61%|██████    | 150/247 [00:43<00:25,  3.83it/s]Loading train:  61%|██████    | 151/247 [00:43<00:25,  3.74it/s]Loading train:  62%|██████▏   | 152/247 [00:44<00:25,  3.72it/s]Loading train:  62%|██████▏   | 153/247 [00:44<00:25,  3.67it/s]Loading train:  62%|██████▏   | 154/247 [00:44<00:26,  3.56it/s]Loading train:  63%|██████▎   | 155/247 [00:44<00:26,  3.54it/s]Loading train:  63%|██████▎   | 156/247 [00:45<00:25,  3.51it/s]Loading train:  64%|██████▎   | 157/247 [00:45<00:25,  3.50it/s]Loading train:  64%|██████▍   | 158/247 [00:45<00:25,  3.47it/s]Loading train:  64%|██████▍   | 159/247 [00:46<00:25,  3.41it/s]Loading train:  65%|██████▍   | 160/247 [00:46<00:25,  3.39it/s]Loading train:  65%|██████▌   | 161/247 [00:46<00:25,  3.41it/s]Loading train:  66%|██████▌   | 162/247 [00:46<00:25,  3.39it/s]Loading train:  66%|██████▌   | 163/247 [00:47<00:24,  3.40it/s]Loading train:  66%|██████▋   | 164/247 [00:47<00:24,  3.38it/s]Loading train:  67%|██████▋   | 165/247 [00:47<00:24,  3.38it/s]Loading train:  67%|██████▋   | 166/247 [00:48<00:23,  3.40it/s]Loading train:  68%|██████▊   | 167/247 [00:48<00:23,  3.45it/s]Loading train:  68%|██████▊   | 168/247 [00:48<00:22,  3.50it/s]Loading train:  68%|██████▊   | 169/247 [00:48<00:21,  3.55it/s]Loading train:  69%|██████▉   | 170/247 [00:49<00:21,  3.52it/s]Loading train:  69%|██████▉   | 171/247 [00:49<00:21,  3.49it/s]Loading train:  70%|██████▉   | 172/247 [00:49<00:21,  3.44it/s]Loading train:  70%|███████   | 173/247 [00:50<00:20,  3.54it/s]Loading train:  70%|███████   | 174/247 [00:50<00:20,  3.54it/s]Loading train:  71%|███████   | 175/247 [00:50<00:21,  3.36it/s]Loading train:  71%|███████▏  | 176/247 [00:50<00:20,  3.45it/s]Loading train:  72%|███████▏  | 177/247 [00:51<00:19,  3.50it/s]Loading train:  72%|███████▏  | 178/247 [00:51<00:19,  3.53it/s]Loading train:  72%|███████▏  | 179/247 [00:51<00:19,  3.57it/s]Loading train:  73%|███████▎  | 180/247 [00:52<00:18,  3.57it/s]Loading train:  73%|███████▎  | 181/247 [00:52<00:19,  3.44it/s]Loading train:  74%|███████▎  | 182/247 [00:52<00:18,  3.46it/s]Loading train:  74%|███████▍  | 183/247 [00:52<00:18,  3.49it/s]Loading train:  74%|███████▍  | 184/247 [00:53<00:17,  3.54it/s]Loading train:  75%|███████▍  | 185/247 [00:53<00:17,  3.59it/s]Loading train:  75%|███████▌  | 186/247 [00:53<00:17,  3.59it/s]Loading train:  76%|███████▌  | 187/247 [00:54<00:16,  3.58it/s]Loading train:  76%|███████▌  | 188/247 [00:54<00:16,  3.62it/s]Loading train:  77%|███████▋  | 189/247 [00:54<00:16,  3.60it/s]Loading train:  77%|███████▋  | 190/247 [00:54<00:15,  3.61it/s]Loading train:  77%|███████▋  | 191/247 [00:55<00:15,  3.61it/s]Loading train:  78%|███████▊  | 192/247 [00:55<00:15,  3.59it/s]Loading train:  78%|███████▊  | 193/247 [00:55<00:14,  3.62it/s]Loading train:  79%|███████▊  | 194/247 [00:56<00:14,  3.67it/s]Loading train:  79%|███████▉  | 195/247 [00:56<00:14,  3.69it/s]Loading train:  79%|███████▉  | 196/247 [00:56<00:13,  3.74it/s]Loading train:  80%|███████▉  | 197/247 [00:56<00:13,  3.81it/s]Loading train:  80%|████████  | 198/247 [00:57<00:12,  3.88it/s]Loading train:  81%|████████  | 199/247 [00:57<00:12,  3.91it/s]Loading train:  81%|████████  | 200/247 [00:57<00:11,  3.92it/s]Loading train:  81%|████████▏ | 201/247 [00:57<00:11,  3.90it/s]Loading train:  82%|████████▏ | 202/247 [00:58<00:11,  3.90it/s]Loading train:  82%|████████▏ | 203/247 [00:58<00:11,  3.85it/s]Loading train:  83%|████████▎ | 204/247 [00:58<00:11,  3.87it/s]Loading train:  83%|████████▎ | 205/247 [00:58<00:10,  3.91it/s]Loading train:  83%|████████▎ | 206/247 [00:59<00:10,  3.94it/s]Loading train:  84%|████████▍ | 207/247 [00:59<00:10,  3.94it/s]Loading train:  84%|████████▍ | 208/247 [00:59<00:09,  3.95it/s]Loading train:  85%|████████▍ | 209/247 [00:59<00:09,  3.93it/s]Loading train:  85%|████████▌ | 210/247 [01:00<00:09,  3.93it/s]Loading train:  85%|████████▌ | 211/247 [01:00<00:09,  3.95it/s]Loading train:  86%|████████▌ | 212/247 [01:00<00:09,  3.88it/s]Loading train:  86%|████████▌ | 213/247 [01:00<00:08,  3.81it/s]Loading train:  87%|████████▋ | 214/247 [01:01<00:08,  3.76it/s]Loading train:  87%|████████▋ | 215/247 [01:01<00:08,  3.68it/s]Loading train:  87%|████████▋ | 216/247 [01:01<00:08,  3.55it/s]Loading train:  88%|████████▊ | 217/247 [01:02<00:08,  3.58it/s]Loading train:  88%|████████▊ | 218/247 [01:02<00:08,  3.60it/s]Loading train:  89%|████████▊ | 219/247 [01:02<00:07,  3.64it/s]Loading train:  89%|████████▉ | 220/247 [01:02<00:07,  3.68it/s]Loading train:  89%|████████▉ | 221/247 [01:03<00:07,  3.71it/s]Loading train:  90%|████████▉ | 222/247 [01:03<00:06,  3.72it/s]Loading train:  90%|█████████ | 223/247 [01:03<00:06,  3.72it/s]Loading train:  91%|█████████ | 224/247 [01:03<00:06,  3.73it/s]Loading train:  91%|█████████ | 225/247 [01:04<00:05,  3.73it/s]Loading train:  91%|█████████▏| 226/247 [01:04<00:05,  3.75it/s]Loading train:  92%|█████████▏| 227/247 [01:04<00:05,  3.70it/s]Loading train:  92%|█████████▏| 228/247 [01:04<00:05,  3.70it/s]Loading train:  93%|█████████▎| 229/247 [01:05<00:04,  3.66it/s]Loading train:  93%|█████████▎| 230/247 [01:05<00:04,  3.52it/s]Loading train:  94%|█████████▎| 231/247 [01:05<00:04,  3.44it/s]Loading train:  94%|█████████▍| 232/247 [01:06<00:04,  3.41it/s]Loading train:  94%|█████████▍| 233/247 [01:06<00:04,  3.35it/s]Loading train:  95%|█████████▍| 234/247 [01:06<00:03,  3.34it/s]Loading train:  95%|█████████▌| 235/247 [01:07<00:03,  3.32it/s]Loading train:  96%|█████████▌| 236/247 [01:07<00:03,  3.31it/s]Loading train:  96%|█████████▌| 237/247 [01:07<00:03,  3.29it/s]Loading train:  96%|█████████▋| 238/247 [01:08<00:02,  3.25it/s]Loading train:  97%|█████████▋| 239/247 [01:08<00:02,  3.20it/s]Loading train:  97%|█████████▋| 240/247 [01:08<00:02,  3.22it/s]Loading train:  98%|█████████▊| 241/247 [01:08<00:01,  3.24it/s]Loading train:  98%|█████████▊| 242/247 [01:09<00:01,  3.23it/s]Loading train:  98%|█████████▊| 243/247 [01:09<00:01,  3.22it/s]Loading train:  99%|█████████▉| 244/247 [01:09<00:00,  3.22it/s]Loading train:  99%|█████████▉| 245/247 [01:10<00:00,  3.21it/s]Loading train: 100%|█████████▉| 246/247 [01:10<00:00,  3.21it/s]Loading train: 100%|██████████| 247/247 [01:10<00:00,  3.21it/s]Loading train: 100%|██████████| 247/247 [01:10<00:00,  3.49it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/247 [00:00<00:08, 29.48it/s]concatenating: train:   3%|▎         | 8/247 [00:00<00:07, 32.75it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:07, 32.04it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:07, 32.06it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:06, 33.47it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:06, 34.94it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:05, 38.30it/s]concatenating: train:  13%|█▎        | 33/247 [00:00<00:05, 38.58it/s]concatenating: train:  15%|█▍        | 37/247 [00:00<00:05, 38.35it/s]concatenating: train:  17%|█▋        | 41/247 [00:01<00:05, 38.29it/s]concatenating: train:  19%|█▊        | 46/247 [00:01<00:05, 39.71it/s]concatenating: train:  21%|██        | 51/247 [00:01<00:04, 41.33it/s]concatenating: train:  23%|██▎       | 56/247 [00:01<00:04, 42.81it/s]concatenating: train:  25%|██▍       | 61/247 [00:01<00:04, 43.05it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:04, 43.47it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:04, 43.46it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:03, 43.45it/s]concatenating: train:  33%|███▎      | 81/247 [00:02<00:03, 43.17it/s]concatenating: train:  35%|███▍      | 86/247 [00:02<00:03, 42.76it/s]concatenating: train:  37%|███▋      | 91/247 [00:02<00:03, 42.54it/s]concatenating: train:  39%|███▉      | 96/247 [00:02<00:03, 42.49it/s]concatenating: train:  41%|████      | 101/247 [00:02<00:03, 42.29it/s]concatenating: train:  43%|████▎     | 106/247 [00:02<00:03, 41.63it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:03, 41.30it/s]concatenating: train:  47%|████▋     | 116/247 [00:02<00:03, 39.53it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:03, 37.48it/s]concatenating: train:  51%|█████     | 125/247 [00:03<00:03, 39.01it/s]concatenating: train:  53%|█████▎    | 130/247 [00:03<00:02, 40.17it/s]concatenating: train:  55%|█████▍    | 135/247 [00:03<00:02, 40.81it/s]concatenating: train:  57%|█████▋    | 140/247 [00:03<00:02, 42.49it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 43.69it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:02, 44.68it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:02, 44.73it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:02, 41.25it/s]concatenating: train:  67%|██████▋   | 165/247 [00:04<00:02, 37.92it/s]concatenating: train:  69%|██████▉   | 170/247 [00:04<00:01, 39.75it/s]concatenating: train:  71%|███████   | 175/247 [00:04<00:01, 41.53it/s]concatenating: train:  73%|███████▎  | 180/247 [00:04<00:01, 42.95it/s]concatenating: train:  75%|███████▍  | 185/247 [00:04<00:01, 43.82it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 44.38it/s]concatenating: train:  79%|███████▉  | 195/247 [00:04<00:01, 43.16it/s]concatenating: train:  81%|████████▏ | 201/247 [00:04<00:01, 45.13it/s]concatenating: train:  83%|████████▎ | 206/247 [00:04<00:00, 46.30it/s]concatenating: train:  85%|████████▌ | 211/247 [00:05<00:00, 47.22it/s]concatenating: train:  87%|████████▋ | 216/247 [00:05<00:00, 47.19it/s]concatenating: train:  89%|████████▉ | 221/247 [00:05<00:00, 46.99it/s]concatenating: train:  91%|█████████▏| 226/247 [00:05<00:00, 46.98it/s]concatenating: train:  94%|█████████▎| 231/247 [00:05<00:00, 46.10it/s]concatenating: train:  96%|█████████▌| 236/247 [00:05<00:00, 43.56it/s]concatenating: train:  98%|█████████▊| 241/247 [00:05<00:00, 43.22it/s]concatenating: train: 100%|█████████▉| 246/247 [00:05<00:00, 43.04it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 42.04it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.47it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.65it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.86it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.07it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.00it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.08it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 289.79it/s]
Epoch 00042: val_mDice did not improve from 0.30276
Restoring model weights from the end of the best epoch
Epoch 00042: early stopping
{'val_loss': [0.6700330478539739, 0.6455999035291721, 0.6532006804189534, 0.6489017967115412, 0.647360319609469, 0.6480077304370663, 0.6233776980731154, 0.6437748608811532, 0.5620136650115097, 0.6207795109155883, 0.5486482128578146, 0.421779346280765, 0.5331837919400764, 0.5635680269083211, 0.45787747706156323, 0.4642933971523621, 0.2937424865314843, 0.355585642023871, 0.2372987203184187, 0.2140828405212553, 0.22531973329309973, 0.25265111888088093, 0.2592236583405826, 0.344690059789413, 0.22987064970126425, 0.22341584950839918, 0.14223194680142898, 0.3238030707552894, 0.2732648401873408, 0.1977900927162541, 0.11262186565508805, 0.1663601494978129, 0.0707567877623547, 0.08949421851900576, 0.11997513031982696, 0.13413310417702778, 0.04137121940060601, 0.10455567089097642, 0.16477901554169433, 0.10874737706517926, 0.09041177315415495, 0.07375970984678812], 'val_acc': [0.9362302922831915, 0.9385551550845408, 0.9383028353434153, 0.9414008494485845, 0.9349484542490905, 0.9378872476711174, 0.9311960299397998, 0.9340767946885657, 0.9403524371008799, 0.9364259462282447, 0.9390773356269678, 0.9414035514228702, 0.9390409094682012, 0.9355151659466442, 0.9290803164398115, 0.938324427048777, 0.939320220539607, 0.937607941232197, 0.9389707489334858, 0.9399017725583803, 0.9316574900261478, 0.9393080763248582, 0.9366242891766247, 0.9381206823136522, 0.9370803632266781, 0.9369629760480298, 0.9403699790875528, 0.940204023079551, 0.9366310507522346, 0.9366485881064223, 0.9398815329210746, 0.9373016502573083, 0.9391583003528378, 0.9384607021055074, 0.9370452879006381, 0.9360751296572117, 0.9397776336867575, 0.9367228051541383, 0.9372071997489336, 0.9357512926808293, 0.9381490170646826, 0.9382637084456923], 'val_mDice': [0.27651716282330646, 0.30276496438164785, 0.2929013720448153, 0.29475522215039, 0.28854773054623234, 0.2883235978184586, 0.2655871338717678, 0.29153822439631033, 0.29439547866428456, 0.29032740228534365, 0.29622102347371493, 0.2929553786398833, 0.29051332260660556, 0.29174768222119524, 0.26556829494361434, 0.2806984161465897, 0.2965370418957478, 0.28691034374150587, 0.28020750171471137, 0.2815837464029925, 0.2746575658880367, 0.2886007421606563, 0.28253740427407575, 0.2744243697026851, 0.28626875726052514, 0.2683859582932502, 0.29423583325944414, 0.28879207781868277, 0.2819664801803895, 0.2838130663559227, 0.29185059751562503, 0.26953393112810164, 0.2879049613531389, 0.28899563957063645, 0.2772105441964352, 0.2782573000445885, 0.28562958144771, 0.277763259457183, 0.2823080240599232, 0.27734128042206246, 0.27969823453401654, 0.28022831948618815], 'loss': [0.5560895059598169, 0.38727618160186883, 0.3530218014183009, 0.33297286421421957, 0.3213965199394059, 0.31029669726860376, 0.30323911957755756, 0.29765278053211414, 0.28096013287410637, 0.2858589020654101, 0.2812367629158182, 0.27580303682321694, 0.2681179981680338, 0.27129488310265615, 0.2635732696989802, 0.26240386385688436, 0.25828689701722884, 0.24306724146621575, 0.2415723427581601, 0.23594262331220792, 0.23280013962489488, 0.2377038155994977, 0.2346224678819858, 0.2307051815908933, 0.23324343727013414, 0.22912940547844712, 0.22756509639680927, 0.22540907238780702, 0.2262509368963446, 0.2243759723621408, 0.22461204098488355, 0.22054306451261896, 0.21812300467294962, 0.2151069782574283, 0.21448839293537122, 0.212789654486517, 0.21519454616057815, 0.21347816274918846, 0.21224937331126645, 0.2128922618948159, 0.20962065068505553, 0.20923334101336816], 'acc': [0.9025368063773955, 0.9317978728173769, 0.9366325554185845, 0.9393634334587339, 0.9414494743642481, 0.94281437731037, 0.9438504892517964, 0.9441839326068198, 0.9463097308171472, 0.9464867436534763, 0.9470779538128788, 0.947581445540944, 0.9482334468750894, 0.9478270896150209, 0.9493240620368174, 0.9494103684008199, 0.9498983542348152, 0.9515398863772387, 0.9517846554066, 0.952314708180219, 0.9526509148649139, 0.9527254361851281, 0.9529885048084622, 0.9532283371844401, 0.9532619755135929, 0.9534101728341857, 0.9534504354748699, 0.9539710718891538, 0.9537194532690342, 0.9537907877800629, 0.9539798412580106, 0.9540891840427972, 0.9547117766672112, 0.9551122420507367, 0.9550974677139776, 0.955286182279244, 0.9552401949338141, 0.955388363704066, 0.9554442481955392, 0.9556305099741728, 0.9556217114741589, 0.9557469862268414], 'mDice': [0.401214092680898, 0.5829340313589898, 0.6198602489910894, 0.641485896963431, 0.653954044052175, 0.665933363091228, 0.6735510327512436, 0.6795972006604392, 0.6975929278439905, 0.692269410262019, 0.6972591600902363, 0.7031194227451161, 0.7114269458638377, 0.7079982294980558, 0.7162963777212624, 0.7175769382880435, 0.7220169793945105, 0.7384553309344482, 0.7400599454726012, 0.7461365896058113, 0.749523972092949, 0.744205765332583, 0.7475354283751219, 0.7517588972245114, 0.7490103113258902, 0.7534569060553354, 0.7551510313105511, 0.7574753954187003, 0.7565759619808445, 0.7585979908214291, 0.7583339396314014, 0.7627331935621123, 0.7653420733948609, 0.7685945880211705, 0.7692583179437738, 0.7710918832220212, 0.7684933117015272, 0.7703436358556338, 0.771672329122032, 0.7709670882234846, 0.7745095275216621, 0.774915593734754], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================2020-01-21 19:12:40.517977: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 19:12:40.518081: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 19:12:40.518094: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 19:12:40.518101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 19:12:40.519080: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97426102 0.02573898]
Train on 25213 samples, validate on 542 samples
Epoch 1/300
 - 67s - loss: 0.0780 - acc: 0.9902 - mDice: 0.8517 - val_loss: 0.2629 - val_acc: 0.9920 - val_mDice: 0.4783

Epoch 00001: val_mDice improved from -inf to 0.47829, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 64s - loss: 0.0514 - acc: 0.9942 - mDice: 0.9002 - val_loss: 0.2545 - val_acc: 0.9926 - val_mDice: 0.4939

Epoch 00002: val_mDice improved from 0.47829 to 0.49393, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 63s - loss: 0.0455 - acc: 0.9948 - mDice: 0.9116 - val_loss: 0.2545 - val_acc: 0.9911 - val_mDice: 0.4604

Epoch 00003: val_mDice did not improve from 0.49393
Epoch 4/300
 - 63s - loss: 0.0420 - acc: 0.9951 - mDice: 0.9184 - val_loss: 0.1347 - val_acc: 0.9923 - val_mDice: 0.4861

Epoch 00004: val_mDice did not improve from 0.49393
Epoch 5/300
 - 63s - loss: 0.0392 - acc: 0.9954 - mDice: 0.9239 - val_loss: 0.2142 - val_acc: 0.9913 - val_mDice: 0.4736

Epoch 00005: val_mDice did not improve from 0.49393
Epoch 6/300
 - 63s - loss: 0.0379 - acc: 0.9956 - mDice: 0.9265 - val_loss: 0.1509 - val_acc: 0.9922 - val_mDice: 0.4789

Epoch 00006: val_mDice did not improve from 0.49393
Epoch 7/300
 - 63s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9292 - val_loss: 0.1128 - val_acc: 0.9922 - val_mDice: 0.4940

Epoch 00007: val_mDice improved from 0.49393 to 0.49398, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 8/300
 - 63s - loss: 0.0350 - acc: 0.9958 - mDice: 0.9321 - val_loss: 0.0163 - val_acc: 0.9919 - val_mDice: 0.4890

Epoch 00008: val_mDice did not improve from 0.49398
Epoch 9/300
 - 64s - loss: 0.0341 - acc: 0.9959 - mDice: 0.9338 - val_loss: 0.0134 - val_acc: 0.9911 - val_mDice: 0.4652

Epoch 00009: val_mDice did not improve from 0.49398
Epoch 10/300
 - 66s - loss: 0.0336 - acc: 0.9960 - mDice: 0.9348 - val_loss: 2.9742e-04 - val_acc: 0.9911 - val_mDice: 0.4654

Epoch 00010: val_mDice did not improve from 0.49398
Epoch 11/300
 - 65s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9355 - val_loss: 0.0425 - val_acc: 0.9922 - val_mDice: 0.4900

Epoch 00011: val_mDice did not improve from 0.49398
Epoch 12/300
 - 64s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9357 - val_loss: 0.0388 - val_acc: 0.9920 - val_mDice: 0.4829

Epoch 00012: val_mDice did not improve from 0.49398
Epoch 13/300
 - 64s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9377 - val_loss: 0.0634 - val_acc: 0.9932 - val_mDice: 0.5135

Epoch 00013: val_mDice improved from 0.49398 to 0.51348, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd1/best_model_weights.h5
Epoch 14/300
 - 63s - loss: 0.0320 - acc: 0.9961 - mDice: 0.9378 - val_loss: -3.2688e-02 - val_acc: 0.9922 - val_mDice: 0.4858

Epoch 00014: val_mDice did not improve from 0.51348
Epoch 15/300
 - 63s - loss: 0.0318 - acc: 0.9961 - mDice: 0.9384 - val_loss: -5.3276e-02 - val_acc: 0.9915 - val_mDice: 0.4704

Epoch 00015: val_mDice did not improve from 0.51348
Epoch 16/300
 - 63s - loss: 0.0311 - acc: 0.9962 - mDice: 0.9397 - val_loss: -7.6965e-02 - val_acc: 0.9925 - val_mDice: 0.4899

Epoch 00016: val_mDice did not improve from 0.51348
Epoch 17/300
 - 63s - loss: 0.0306 - acc: 0.9962 - mDice: 0.9407 - val_loss: 0.0516 - val_acc: 0.9923 - val_mDice: 0.4934

Epoch 00017: val_mDice did not improve from 0.51348
Epoch 18/300
 - 63s - loss: 0.0304 - acc: 0.9962 - mDice: 0.9411 - val_loss: -7.7863e-02 - val_acc: 0.9914 - val_mDice: 0.4556

Epoch 00018: val_mDice did not improve from 0.51348
Epoch 19/300
 - 63s - loss: 0.0303 - acc: 0.9963 - mDice: 0.9411 - val_loss: -8.4656e-02 - val_acc: 0.9930 - val_mDice: 0.5015

Epoch 00019: val_mDice did not improve from 0.51348
Epoch 20/300
 - 63s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9422 - val_loss: -4.8945e-02 - val_acc: 0.9929 - val_mDice: 0.4924

Epoch 00020: val_mDice did not improve from 0.51348
Epoch 21/300
 - 63s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9426 - val_loss: -4.3119e-02 - val_acc: 0.9928 - val_mDice: 0.4951

Epoch 00021: val_mDice did not improve from 0.51348
Epoch 22/300
 - 63s - loss: 0.0293 - acc: 0.9963 - mDice: 0.9432 - val_loss: -5.8900e-02 - val_acc: 0.9928 - val_mDice: 0.5007

Epoch 00022: val_mDice did not improve from 0.51348
Epoch 23/300
 - 62s - loss: 0.0298 - acc: 0.9963 - mDice: 0.9421 - val_loss: -7.8997e-02 - val_acc: 0.9933 - val_mDice: 0.5088

Epoch 00023: val_mDice did not improve from 0.51348
Epoch 24/300
 - 63s - loss: 0.0288 - acc: 0.9964 - mDice: 0.9442 - val_loss: -4.4663e-02 - val_acc: 0.9931 - val_mDice: 0.4958

Epoch 00024: val_mDice did not improve from 0.51348
Epoch 25/300
 - 62s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9440 - val_loss: -8.8694e-02 - val_acc: 0.9922 - val_mDice: 0.4735

Epoch 00025: val_mDice did not improve from 0.51348
Epoch 26/300
 - 63s - loss: 0.0290 - acc: 0.9964 - mDice: 0.9437 - val_loss: -1.0105e-01 - val_acc: 0.9932 - val_mDice: 0.5063

Epoch 00026: val_mDice did not improve from 0.51348
Epoch 27/300
 - 63s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9447 - val_loss: -6.8950e-02 - val_acc: 0.9925 - val_mDice: 0.4905

Epoch 00027: val_mDice did not improve from 0.51348
Epoch 28/300
 - 62s - loss: 0.0283 - acc: 0.9964 - mDice: 0.9451 - val_loss: -7.1061e-02 - val_acc: 0.9922 - val_mDice: 0.4823

Epoch 00028: val_mDice did not improve from 0.51348

Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 29/300
 - 63s - loss: 0.0270 - acc: 0.9965 - mDice: 0.9476 - val_loss: -2.3902e-02 - val_acc: 0.9933 - val_mDice: 0.5112

Epoch 00029: val_mDice did not improve from 0.51348
Epoch 30/300
 - 63s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9483 - val_loss: -7.7847e-02 - val_acc: 0.9928 - val_mDice: 0.4953

Epoch 00030: val_mDice did not improve from 0.51348
Epoch 31/300
 - 62s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9483 - val_loss: -9.3542e-02 - val_acc: 0.9933 - val_mDice: 0.5077

Epoch 00031: val_mDice did not improve from 0.51348
Epoch 32/300
 - 63s - loss: 0.0260 - acc: 0.9966 - mDice: 0.9497 - val_loss: -3.7078e-02 - val_acc: 0.9919 - val_mDice: 0.4727

Epoch 00032: val_mDice did not improve from 0.51348
Epoch 33/300
 - 64s - loss: 0.0261 - acc: 0.9966 - mDice: 0.9494 - val_loss: -6.6059e-02 - val_acc: 0.9927 - val_mDice: 0.4919

Epoch 00033: val_mDice did not improve from 0.51348
Epoch 34/300
 - 63s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9492 - val_loss: 0.0246 - val_acc: 0.9936 - val_mDice: 0.5076

Epoch 00034: val_mDice did not improve from 0.51348
Epoch 35/300
 - 63s - loss: 0.0257 - acc: 0.9966 - mDice: 0.9502 - val_loss: -3.2371e-02 - val_acc: 0.9933 - val_mDice: 0.4943

Epoch 00035: val_mDice did not improve from 0.51348
Epoch 36/300
 - 63s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9505 - val_loss: -4.0847e-02 - val_acc: 0.9923 - val_mDice: 0.4857

Epoch 00036: val_mDice did not improve from 0.51348
Epoch 37/300
 - 63s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9503 - val_loss: -3.4833e-02 - val_acc: 0.9926 - val_mDice: 0.4892

Epoch 00037: val_mDice did not improve from 0.51348
Epoch 38/300
 - 63s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: -6.0015e-02 - val_acc: 0.9924 - val_mDice: 0.4901

Epoch 00038: val_mDice did not improve from 0.51348
Epoch 39/300
 - 63s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9505 - val_loss: -8.2105e-02 - val_acc: 0.9930 - val_mDice: 0.4983

Epoch 00039: val_mDice did not improve from 0.51348
Epoch 40/300
 - 63s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9504 - val_loss: -3.4398e-02 - val_acc: 0.9937 - val_mDice: 0.5096

Epoch 00040: val_mDice did not improve from 0.51348
Epoch 41/300
 - 63s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9510 - val_loss: -7.2858e-02 - val_acc: 0.9931 - val_mDice: 0.4984

Epoch 00041: val_mDice did not improve from 0.51348
Epoch 42/300
 - 63s - loss: 0.0251 - acc: 0.9967 - mDice: 0.9514 - val_loss: -3.6876e-02 - val_acc: 0.9932 - val_mDice: 0.5057

Epoch 00042: val_mDice did not improve from 0.51348
Epoch 43/300
 - 64s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: -7.9507e-02 - val_acc: 0.9930 - val_mDice: 0.5008

Epoch 00043: val_mDice did not improve from 0.51348

Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 44/300
 - 63s - loss: 0.0248 - acc: 0.9967 - mDice: 0.9519 - val_loss: -8.1296e-02 - val_acc: 0.9932 - val_mDice: 0.4999

Epoch 00044: val_mDice did not improve from 0.51348
Epoch 45/300
 - 63s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9530 - val_loss: -5.0774e-02 - val_acc: 0.9935 - val_mDice: 0.5042

Epoch 00045: val_mDice did not improve from 0.51348
Epoch 46/300
 - 63s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: -6.2714e-02 - val_acc: 0.9932 - val_mDice: 0.4997

Epoch 00046: val_mDice did not improve from 0.51348
Epoch 47/300
 - 64s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9530 - val_loss: -6.2667e-02 - val_acc: 0.9932 - val_mDice: 0.5021

Epoch 00047: val_mDice did not improve from 0.51348
Epoch 48/300
 - 63s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9528 - val_loss: -2.0319e-02 - val_acc: 0.9936 - val_mDice: 0.5094

Epoch 00048: val_mDice did not improve from 0.51348
Epoch 49/300
 - 63s - loss: 0.0241 - acc: 0.9968 - mDice: 0.9534 - val_loss: -6.0047e-02 - val_acc: 0.9934 - val_mDice: 0.5023

Epoch 00049: val_mDice did not improve from 0.51348
Epoch 50/300
 - 63s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: -5.9609e-02 - val_acc: 0.9930 - val_mDice: 0.5002

Epoch 00050: val_mDice did not improve from 0.51348
Epoch 51/300
 - 63s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9538 - val_loss: -6.1196e-02 - val_acc: 0.9932 - val_mDice: 0.5008

Epoch 00051: val_mDice did not improve from 0.51348
Epoch 52/300
 - 63s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9540 - val_loss: -7.4001e-02 - val_acc: 0.9929 - val_mDice: 0.4939

Epoch 00052: val_mDice did not improve from 0.51348
Epoch 53/300
 - 63s - loss: 0.0241 - acc: 0.9968 - mDice: 0.9533 - val_loss: -6.0854e-02 - val_acc: 0.9936 - val_mDice: 0.5121

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.41it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.78it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.23it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.81it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.14it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.38it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:46,  5.29it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:44,  5.49it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:46,  5.28it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:43,  5.61it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:40,  5.93it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<00:39,  6.17it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:37,  6.36it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:37,  6.42it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:36,  6.53it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:35,  6.61it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:35,  6.65it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:35,  6.68it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:34,  6.70it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:34,  6.75it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:34,  6.76it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:34,  6.71it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:34,  6.67it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:34,  6.71it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:35,  6.50it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:35,  6.42it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.48it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:34,  6.60it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:32,  6.90it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:31,  7.11it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:30,  7.29it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:29,  7.45it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:29,  7.56it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:31,  6.90it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:30,  7.11it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:29,  7.30it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:29,  7.44it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:28,  7.54it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:28,  7.62it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:27,  7.65it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:27,  7.67it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:27,  7.70it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:27,  7.70it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:27,  7.67it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:26,  7.71it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:26,  7.75it/s]predicting train subjects:  17%|█▋        | 41/247 [00:05<00:27,  7.62it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:27,  7.49it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:27,  7.47it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:27,  7.45it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:27,  7.44it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:27,  7.43it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:26,  7.42it/s]predicting train subjects:  19%|█▉        | 48/247 [00:06<00:26,  7.41it/s]predicting train subjects:  20%|█▉        | 49/247 [00:06<00:26,  7.42it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:26,  7.41it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:26,  7.39it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:26,  7.39it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:26,  7.42it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:25,  7.45it/s]predicting train subjects:  22%|██▏       | 55/247 [00:07<00:25,  7.40it/s]predicting train subjects:  23%|██▎       | 56/247 [00:07<00:25,  7.39it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:26,  7.13it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:26,  7.22it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:26,  7.07it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:27,  6.91it/s]predicting train subjects:  25%|██▍       | 61/247 [00:08<00:27,  6.85it/s]predicting train subjects:  25%|██▌       | 62/247 [00:08<00:27,  6.82it/s]predicting train subjects:  26%|██▌       | 63/247 [00:08<00:26,  6.81it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:27,  6.77it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:26,  6.76it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:27,  6.70it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:27,  6.66it/s]predicting train subjects:  28%|██▊       | 68/247 [00:09<00:27,  6.63it/s]predicting train subjects:  28%|██▊       | 69/247 [00:09<00:26,  6.66it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:26,  6.68it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:26,  6.71it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:26,  6.72it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:25,  6.74it/s]predicting train subjects:  30%|██▉       | 74/247 [00:10<00:25,  6.75it/s]predicting train subjects:  30%|███       | 75/247 [00:10<00:25,  6.75it/s]predicting train subjects:  31%|███       | 76/247 [00:10<00:25,  6.73it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:28,  6.02it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:31,  5.42it/s]predicting train subjects:  32%|███▏      | 79/247 [00:11<00:32,  5.24it/s]predicting train subjects:  32%|███▏      | 80/247 [00:11<00:28,  5.77it/s]predicting train subjects:  33%|███▎      | 81/247 [00:11<00:29,  5.70it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:30,  5.48it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:28,  5.75it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:27,  5.95it/s]predicting train subjects:  34%|███▍      | 85/247 [00:12<00:26,  6.11it/s]predicting train subjects:  35%|███▍      | 86/247 [00:12<00:25,  6.22it/s]predicting train subjects:  35%|███▌      | 87/247 [00:12<00:25,  6.27it/s]predicting train subjects:  36%|███▌      | 88/247 [00:12<00:24,  6.36it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:24,  6.32it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:24,  6.34it/s]predicting train subjects:  37%|███▋      | 91/247 [00:13<00:24,  6.39it/s]predicting train subjects:  37%|███▋      | 92/247 [00:13<00:24,  6.31it/s]predicting train subjects:  38%|███▊      | 93/247 [00:13<00:24,  6.39it/s]predicting train subjects:  38%|███▊      | 94/247 [00:13<00:23,  6.38it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:23,  6.35it/s]predicting train subjects:  39%|███▉      | 96/247 [00:14<00:23,  6.38it/s]predicting train subjects:  39%|███▉      | 97/247 [00:14<00:23,  6.42it/s]predicting train subjects:  40%|███▉      | 98/247 [00:14<00:23,  6.43it/s]predicting train subjects:  40%|████      | 99/247 [00:14<00:22,  6.45it/s]predicting train subjects:  40%|████      | 100/247 [00:14<00:23,  6.32it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:23,  6.19it/s]predicting train subjects:  41%|████▏     | 102/247 [00:15<00:23,  6.12it/s]predicting train subjects:  42%|████▏     | 103/247 [00:15<00:23,  6.10it/s]predicting train subjects:  42%|████▏     | 104/247 [00:15<00:23,  6.08it/s]predicting train subjects:  43%|████▎     | 105/247 [00:15<00:23,  6.08it/s]predicting train subjects:  43%|████▎     | 106/247 [00:15<00:23,  6.06it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:23,  6.04it/s]predicting train subjects:  44%|████▎     | 108/247 [00:16<00:23,  5.88it/s]predicting train subjects:  44%|████▍     | 109/247 [00:16<00:23,  5.87it/s]predicting train subjects:  45%|████▍     | 110/247 [00:16<00:23,  5.90it/s]predicting train subjects:  45%|████▍     | 111/247 [00:16<00:23,  5.89it/s]predicting train subjects:  45%|████▌     | 112/247 [00:16<00:23,  5.84it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:23,  5.82it/s]predicting train subjects:  46%|████▌     | 114/247 [00:17<00:22,  5.84it/s]predicting train subjects:  47%|████▋     | 115/247 [00:17<00:22,  5.86it/s]predicting train subjects:  47%|████▋     | 116/247 [00:17<00:22,  5.86it/s]predicting train subjects:  47%|████▋     | 117/247 [00:17<00:22,  5.70it/s]predicting train subjects:  48%|████▊     | 118/247 [00:17<00:22,  5.82it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:21,  5.90it/s]predicting train subjects:  49%|████▊     | 120/247 [00:18<00:21,  5.98it/s]predicting train subjects:  49%|████▉     | 121/247 [00:18<00:20,  6.09it/s]predicting train subjects:  49%|████▉     | 122/247 [00:18<00:20,  6.05it/s]predicting train subjects:  50%|████▉     | 123/247 [00:18<00:20,  6.06it/s]predicting train subjects:  50%|█████     | 124/247 [00:18<00:20,  6.08it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:20,  6.10it/s]predicting train subjects:  51%|█████     | 126/247 [00:19<00:19,  6.12it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:19<00:19,  6.12it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:19<00:19,  6.13it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:19<00:19,  6.14it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:19<00:19,  6.08it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:19,  6.08it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:18,  6.07it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:20<00:18,  6.05it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:20<00:18,  6.09it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:20<00:18,  6.11it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:20<00:17,  6.35it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:20<00:16,  6.60it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:16,  6.79it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:21<00:15,  6.95it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:21<00:15,  7.11it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:21<00:14,  7.23it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:21<00:14,  7.28it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:21<00:14,  7.34it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:21<00:13,  7.42it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:13,  7.45it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:22<00:13,  7.42it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:22<00:13,  7.46it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:22<00:13,  7.50it/s]predicting train subjects:  60%|██████    | 149/247 [00:22<00:13,  7.52it/s]predicting train subjects:  61%|██████    | 150/247 [00:22<00:12,  7.55it/s]predicting train subjects:  61%|██████    | 151/247 [00:22<00:12,  7.56it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:12,  7.49it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:23<00:12,  7.48it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:23<00:12,  7.28it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:23<00:12,  7.12it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:23<00:12,  7.04it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:23<00:12,  7.01it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:23<00:12,  6.94it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:24<00:12,  6.91it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:24<00:12,  6.89it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:24<00:12,  6.89it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:24<00:12,  6.90it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:24<00:12,  6.91it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:24<00:12,  6.88it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:24<00:11,  6.93it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:25<00:11,  6.92it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:25<00:11,  6.83it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:25<00:11,  6.87it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:25<00:11,  6.88it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:25<00:11,  6.86it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:25<00:11,  6.89it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:25<00:10,  6.91it/s]predicting train subjects:  70%|███████   | 173/247 [00:26<00:12,  6.08it/s]predicting train subjects:  70%|███████   | 174/247 [00:26<00:11,  6.38it/s]predicting train subjects:  71%|███████   | 175/247 [00:26<00:12,  5.75it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:26<00:11,  6.07it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:26<00:11,  6.33it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:26<00:10,  6.48it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:27<00:10,  6.61it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:27<00:09,  6.72it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:27<00:09,  6.79it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:27<00:09,  6.68it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:27<00:09,  6.70it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:27<00:09,  6.79it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:27<00:09,  6.88it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:28<00:08,  6.92it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:28<00:08,  6.95it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:28<00:08,  6.97it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:28<00:08,  7.00it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:28<00:08,  7.00it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:28<00:08,  6.97it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:28<00:07,  7.02it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:29<00:07,  7.03it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:29<00:07,  7.16it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:29<00:07,  7.31it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:29<00:06,  7.44it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:29<00:06,  7.54it/s]predicting train subjects:  80%|████████  | 198/247 [00:29<00:06,  7.60it/s]predicting train subjects:  81%|████████  | 199/247 [00:29<00:06,  7.65it/s]predicting train subjects:  81%|████████  | 200/247 [00:29<00:06,  7.69it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:30<00:05,  7.71it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:30<00:05,  7.73it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:30<00:05,  7.70it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:30<00:05,  7.70it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:30<00:05,  7.76it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:30<00:05,  7.72it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:30<00:05,  7.65it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:31<00:05,  7.52it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:31<00:05,  7.52it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:31<00:04,  7.57it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:31<00:04,  7.61it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:31<00:04,  7.37it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:31<00:04,  7.35it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:31<00:04,  7.31it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:31<00:04,  7.29it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:32<00:04,  7.11it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:32<00:04,  7.13it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:32<00:04,  7.14it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:32<00:03,  7.12it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:32<00:03,  7.09it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:32<00:03,  7.13it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:32<00:03,  7.15it/s]predicting train subjects:  90%|█████████ | 223/247 [00:33<00:03,  7.21it/s]predicting train subjects:  91%|█████████ | 224/247 [00:33<00:03,  7.23it/s]predicting train subjects:  91%|█████████ | 225/247 [00:33<00:03,  7.25it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:33<00:02,  7.25it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:33<00:02,  7.26it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:33<00:02,  7.26it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:33<00:02,  7.23it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:34<00:02,  6.82it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:34<00:02,  6.62it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:34<00:02,  6.47it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:34<00:02,  6.31it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:34<00:02,  6.26it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:34<00:01,  6.23it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:35<00:01,  6.20it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:35<00:01,  6.18it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:35<00:01,  6.06it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:35<00:01,  6.09it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:35<00:01,  6.08it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:35<00:00,  6.06it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:36<00:00,  5.97it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:36<00:00,  6.00it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:36<00:00,  5.96it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:36<00:00,  5.98it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:36<00:00,  6.00it/s]predicting train subjects: 100%|██████████| 247/247 [00:36<00:00,  6.00it/s]predicting train subjects: 100%|██████████| 247/247 [00:36<00:00,  6.69it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 72.29it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 82.18it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 82.69it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 82.86it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 83.47it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 84.79it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 86.91it/s]saving BB  train1-THALAMUS:  26%|██▌       | 64/247 [00:00<00:02, 85.69it/s]saving BB  train1-THALAMUS:  29%|██▉       | 72/247 [00:00<00:02, 83.35it/s]saving BB  train1-THALAMUS:  32%|███▏      | 80/247 [00:00<00:02, 80.89it/s]saving BB  train1-THALAMUS:  36%|███▌      | 88/247 [00:01<00:01, 80.07it/s]saving BB  train1-THALAMUS:  39%|███▉      | 97/247 [00:01<00:01, 80.38it/s]saving BB  train1-THALAMUS:  43%|████▎     | 105/247 [00:01<00:01, 79.20it/s]saving BB  train1-THALAMUS:  46%|████▌     | 113/247 [00:01<00:01, 77.36it/s]saving BB  train1-THALAMUS:  49%|████▉     | 121/247 [00:01<00:01, 76.87it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 129/247 [00:01<00:01, 76.91it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 137/247 [00:01<00:01, 77.72it/s]saving BB  train1-THALAMUS:  60%|█████▉    | 147/247 [00:01<00:01, 82.16it/s]saving BB  train1-THALAMUS:  64%|██████▎   | 157/247 [00:01<00:01, 85.05it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 166/247 [00:02<00:00, 85.75it/s]saving BB  train1-THALAMUS:  71%|███████   | 175/247 [00:02<00:00, 85.53it/s]saving BB  train1-THALAMUS:  74%|███████▍  | 184/247 [00:02<00:00, 83.51it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 193/247 [00:02<00:00, 82.20it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 202/247 [00:02<00:00, 84.15it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 211/247 [00:02<00:00, 85.17it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 220/247 [00:02<00:00, 85.48it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 229/247 [00:02<00:00, 86.07it/s]saving BB  train1-THALAMUS:  96%|█████████▋| 238/247 [00:02<00:00, 82.15it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 77.29it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 82.09it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<04:06,  1.00s/it]Loading train:   1%|          | 2/247 [00:01<03:55,  1.04it/s]Loading train:   1%|          | 3/247 [00:02<03:40,  1.11it/s]Loading train:   2%|▏         | 4/247 [00:03<03:46,  1.07it/s]Loading train:   2%|▏         | 5/247 [00:04<03:31,  1.15it/s]Loading train:   2%|▏         | 6/247 [00:04<03:12,  1.25it/s]Loading train:   3%|▎         | 7/247 [00:05<02:59,  1.34it/s]Loading train:   3%|▎         | 8/247 [00:06<02:49,  1.41it/s]Loading train:   4%|▎         | 9/247 [00:06<02:46,  1.43it/s]Loading train:   4%|▍         | 10/247 [00:07<02:41,  1.47it/s]Loading train:   4%|▍         | 11/247 [00:08<02:39,  1.48it/s]Loading train:   5%|▍         | 12/247 [00:08<02:33,  1.53it/s]Loading train:   5%|▌         | 13/247 [00:09<02:31,  1.55it/s]Loading train:   6%|▌         | 14/247 [00:10<02:30,  1.54it/s]Loading train:   6%|▌         | 15/247 [00:10<02:30,  1.54it/s]Loading train:   6%|▋         | 16/247 [00:11<02:26,  1.57it/s]Loading train:   7%|▋         | 17/247 [00:12<02:28,  1.55it/s]Loading train:   7%|▋         | 18/247 [00:12<02:25,  1.58it/s]Loading train:   8%|▊         | 19/247 [00:13<02:28,  1.53it/s]Loading train:   8%|▊         | 20/247 [00:13<02:26,  1.55it/s]Loading train:   9%|▊         | 21/247 [00:14<02:24,  1.56it/s]Loading train:   9%|▉         | 22/247 [00:15<02:20,  1.60it/s]Loading train:   9%|▉         | 23/247 [00:15<02:20,  1.60it/s]Loading train:  10%|▉         | 24/247 [00:16<02:17,  1.63it/s]Loading train:  10%|█         | 25/247 [00:17<02:17,  1.62it/s]Loading train:  11%|█         | 26/247 [00:17<02:14,  1.65it/s]Loading train:  11%|█         | 27/247 [00:18<02:13,  1.64it/s]Loading train:  11%|█▏        | 28/247 [00:18<02:11,  1.67it/s]Loading train:  12%|█▏        | 29/247 [00:19<02:09,  1.69it/s]Loading train:  12%|█▏        | 30/247 [00:19<02:06,  1.72it/s]Loading train:  13%|█▎        | 31/247 [00:20<02:05,  1.72it/s]Loading train:  13%|█▎        | 32/247 [00:21<02:04,  1.72it/s]Loading train:  13%|█▎        | 33/247 [00:21<02:07,  1.68it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:06,  1.69it/s]Loading train:  14%|█▍        | 35/247 [00:22<02:03,  1.71it/s]Loading train:  15%|█▍        | 36/247 [00:23<02:03,  1.70it/s]Loading train:  15%|█▍        | 37/247 [00:24<02:03,  1.71it/s]Loading train:  15%|█▌        | 38/247 [00:24<02:01,  1.72it/s]Loading train:  16%|█▌        | 39/247 [00:25<01:59,  1.74it/s]Loading train:  16%|█▌        | 40/247 [00:25<01:59,  1.74it/s]Loading train:  17%|█▋        | 41/247 [00:26<02:01,  1.70it/s]Loading train:  17%|█▋        | 42/247 [00:26<02:02,  1.67it/s]Loading train:  17%|█▋        | 43/247 [00:27<02:02,  1.66it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:04,  1.63it/s]Loading train:  18%|█▊        | 45/247 [00:28<02:05,  1.62it/s]Loading train:  19%|█▊        | 46/247 [00:29<02:04,  1.62it/s]Loading train:  19%|█▉        | 47/247 [00:30<02:03,  1.62it/s]Loading train:  19%|█▉        | 48/247 [00:30<02:01,  1.64it/s]Loading train:  20%|█▉        | 49/247 [00:31<02:00,  1.65it/s]Loading train:  20%|██        | 50/247 [00:31<02:00,  1.64it/s]Loading train:  21%|██        | 51/247 [00:32<02:00,  1.63it/s]Loading train:  21%|██        | 52/247 [00:33<02:00,  1.62it/s]Loading train:  21%|██▏       | 53/247 [00:33<01:59,  1.62it/s]Loading train:  22%|██▏       | 54/247 [00:34<01:59,  1.62it/s]Loading train:  22%|██▏       | 55/247 [00:35<01:57,  1.63it/s]Loading train:  23%|██▎       | 56/247 [00:35<01:54,  1.66it/s]Loading train:  23%|██▎       | 57/247 [00:36<01:52,  1.69it/s]Loading train:  23%|██▎       | 58/247 [00:36<01:49,  1.73it/s]Loading train:  24%|██▍       | 59/247 [00:37<01:55,  1.62it/s]Loading train:  24%|██▍       | 60/247 [00:38<01:58,  1.58it/s]Loading train:  25%|██▍       | 61/247 [00:38<02:02,  1.52it/s]Loading train:  25%|██▌       | 62/247 [00:39<02:03,  1.50it/s]Loading train:  26%|██▌       | 63/247 [00:40<02:00,  1.52it/s]Loading train:  26%|██▌       | 64/247 [00:40<02:03,  1.48it/s]Loading train:  26%|██▋       | 65/247 [00:41<02:01,  1.50it/s]Loading train:  27%|██▋       | 66/247 [00:42<01:59,  1.51it/s]Loading train:  27%|██▋       | 67/247 [00:42<01:57,  1.53it/s]Loading train:  28%|██▊       | 68/247 [00:43<01:54,  1.56it/s]Loading train:  28%|██▊       | 69/247 [00:43<01:52,  1.58it/s]Loading train:  28%|██▊       | 70/247 [00:44<01:53,  1.56it/s]Loading train:  29%|██▊       | 71/247 [00:45<01:55,  1.52it/s]Loading train:  29%|██▉       | 72/247 [00:46<01:56,  1.50it/s]Loading train:  30%|██▉       | 73/247 [00:46<01:57,  1.48it/s]Loading train:  30%|██▉       | 74/247 [00:47<01:56,  1.48it/s]Loading train:  30%|███       | 75/247 [00:48<01:55,  1.49it/s]Loading train:  31%|███       | 76/247 [00:48<01:54,  1.49it/s]Loading train:  31%|███       | 77/247 [00:49<02:09,  1.31it/s]Loading train:  32%|███▏      | 78/247 [00:50<02:24,  1.17it/s]
Epoch 00053: val_mDice did not improve from 0.51348
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [0.26285874502685236, 0.25446186811281746, 0.25449022628724355, 0.13474787329065843, 0.21415941392473628, 0.15093968214803957, 0.11276285938671154, 0.016275921980833215, 0.013435175992905874, 0.00029741914949733833, 0.04251220717861204, 0.03876716426377807, 0.06336567427179471, -0.032688211965824845, -0.053276248028797414, -0.07696481428463081, 0.05159505860831905, -0.07786296844152507, -0.08465615126589568, -0.04894530869388052, -0.0431194483299097, -0.0589004301936864, -0.07899665114954389, -0.04466268139791665, -0.08869442261233101, -0.10104923062988753, -0.06895036222859942, -0.07106148894202666, -0.023902161122468124, -0.07784715333328036, -0.09354189263718594, -0.037078206609535924, -0.06605942390611691, 0.02457868360065446, -0.03237079122409609, -0.040847179167165085, -0.03483273380356961, -0.060014549546576076, -0.0821053866310753, -0.03439840289499487, -0.07285800015354509, -0.036876315422823505, -0.07950670401328604, -0.08129630086606719, -0.0507740461133503, -0.06271363074489185, -0.0626669325126933, -0.020319485796333678, -0.06004746381976948, -0.059609003117603566, -0.06119606751137554, -0.07400108279997132, -0.060853836336259036], 'val_acc': [0.9920359407843699, 0.9926197022969433, 0.9911496241154266, 0.9922820760755081, 0.9913499023201721, 0.9922112697164951, 0.9922261103932708, 0.9918606063536612, 0.9910669001266086, 0.9911008450817798, 0.9922274586459368, 0.9920112147542384, 0.9932124550932008, 0.9921829520116433, 0.9915241084415535, 0.9924998947615113, 0.9923483867926791, 0.9914222834734899, 0.9930184683676575, 0.9928514499945834, 0.9928148140326637, 0.9927530000570516, 0.9933061883458352, 0.9931456956916189, 0.9922344231517553, 0.9931971690311643, 0.9925216944455221, 0.9922274542470699, 0.9933288919969678, 0.9928019979343203, 0.9933138291774201, 0.9919181534285035, 0.9927226511754673, 0.9935799727140757, 0.9933243974548425, 0.9923050051685629, 0.9926437553004585, 0.9923852558945377, 0.9930119470476664, 0.9936898948961518, 0.993068815597309, 0.9932135790036614, 0.9930263346411645, 0.9932248192079832, 0.9934846701657201, 0.9931780625533354, 0.9932378497510819, 0.9935568236776824, 0.9933504673387732, 0.9929759830126463, 0.9931758125329809, 0.9928728064927668, 0.9936130181009919], 'val_mDice': [0.4782884949058027, 0.4939267319727863, 0.4604219713995323, 0.48612772896090767, 0.47356842601211374, 0.47886270988471497, 0.4939815979382209, 0.4889961840701719, 0.46518097848140005, 0.465444081576328, 0.4899809174102171, 0.48287688531119005, 0.5134756071321199, 0.48575626445652376, 0.4703810336102639, 0.4898762403269096, 0.4933825228706937, 0.45555544694081446, 0.5015124825973792, 0.4924074178252273, 0.4951015895583093, 0.5006661345817947, 0.5087833513412968, 0.4958366352919364, 0.47353696256766187, 0.5063220490168822, 0.4905440023244527, 0.4823428752567495, 0.5111594003284989, 0.4953097224895365, 0.507655197623911, 0.47270846322893656, 0.4918915907615225, 0.507647280763436, 0.4942581579913952, 0.4857209654751739, 0.4891950628854252, 0.4901005866562748, 0.4982915878075955, 0.5095721093930882, 0.498401555078056, 0.5056628425402835, 0.5007621414986924, 0.49986697101065153, 0.5041855716617345, 0.49966211413545364, 0.5021205335525569, 0.5094101046284186, 0.502346630905827, 0.5002030812726249, 0.5008350010287718, 0.49388339928595343, 0.5121100553727238], 'loss': [0.07795806575683403, 0.05143817259484932, 0.04551022659402258, 0.042041677115636146, 0.03922102449362306, 0.037854193246327245, 0.03645938717141172, 0.03496928403772139, 0.03409247833620631, 0.033596480435988056, 0.03323790245740685, 0.03315913048438937, 0.03212497824457179, 0.03202467847361198, 0.0317714948786183, 0.031104644723920657, 0.030577876312949337, 0.030385513778094644, 0.0303489187838647, 0.029820745635409956, 0.029602650126721343, 0.02928814952586174, 0.029830730660443113, 0.028770070497166872, 0.028903091880059396, 0.02902035963453513, 0.028492936295868788, 0.028318002791055414, 0.027030149881872755, 0.02667263476216835, 0.026653423227482965, 0.02596527529397327, 0.026106947473804883, 0.026226095013931847, 0.025718406288994397, 0.025553904886602793, 0.025634146868362264, 0.025380885822554638, 0.025551916237310155, 0.025574341472504997, 0.025310416079397758, 0.025091137233051092, 0.02519953219679627, 0.024833076315955358, 0.024270565078925457, 0.02459974408182816, 0.02426491439406328, 0.024374908273149046, 0.024059731530844373, 0.023883625049978388, 0.023832851553296116, 0.023770609908303847, 0.024108702948597144], 'acc': [0.9901596102082677, 0.9942171117543881, 0.9948157151049976, 0.9951245643413322, 0.995396556113073, 0.9955605730341697, 0.9957007954822568, 0.995834660214254, 0.9958981590756476, 0.995976719465533, 0.9959955802753586, 0.9960074380772431, 0.996100581978804, 0.9961278110958879, 0.9961311691094715, 0.9961696045215168, 0.9962474685869303, 0.9962477635534451, 0.9962612599523331, 0.9962900396790616, 0.9963241833179145, 0.9963377571770726, 0.9963253145390376, 0.9963930752542809, 0.9963773998639047, 0.9963823861743516, 0.9964221987461234, 0.9964204643391392, 0.9965496118598336, 0.9965765705444526, 0.9966157105385758, 0.9966291434794271, 0.9966251809466614, 0.9966302746674536, 0.9966291673279043, 0.9966517099449825, 0.9966660758889483, 0.9966798281341487, 0.996682253629247, 0.9966725896295872, 0.9966920436939244, 0.9966930437838833, 0.9966949472743961, 0.9967433846356665, 0.9967676617424703, 0.9967995868275565, 0.9967835391167774, 0.9967766778711069, 0.9968035839013709, 0.9967979682989238, 0.9967937398371974, 0.9968005734093672, 0.9967958076736945], 'mDice': [0.8516967655632157, 0.9001528062805494, 0.9116356350877471, 0.9183892164194224, 0.9238747286998932, 0.9265154919005706, 0.929225421725361, 0.9321304930338531, 0.9338443466214967, 0.9347950017178484, 0.9355012899832729, 0.9356555878673982, 0.9376568667206756, 0.9378490208153949, 0.9383506711829647, 0.9396584857835445, 0.9406806456287619, 0.9410569622970245, 0.9411272332725326, 0.9421649646958559, 0.942584450398661, 0.9432047206936686, 0.9421280696535982, 0.9442086358226022, 0.943950502886084, 0.9437137993949978, 0.9447478550512013, 0.9450932317150205, 0.9475968104818162, 0.9482937054920995, 0.9483109163764222, 0.9496843781776876, 0.9493984750723965, 0.9491571105538803, 0.9501694869135551, 0.9504891496967429, 0.9503235608305031, 0.9508212952523429, 0.9504817422812278, 0.9504397249333385, 0.9509575978481173, 0.9513900452337597, 0.9511765409957689, 0.9518799298706897, 0.9529899614538965, 0.9523193120309198, 0.952990920487501, 0.9527694515965778, 0.953394875689831, 0.9537429160545635, 0.95384776075711, 0.9539653659197849, 0.9532950161062531], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CMLoading train:  32%|███▏      | 79/247 [00:51<02:30,  1.12it/s]Loading train:  32%|███▏      | 80/247 [00:52<02:25,  1.15it/s]Loading train:  33%|███▎      | 81/247 [00:53<02:23,  1.16it/s]Loading train:  33%|███▎      | 82/247 [00:54<02:14,  1.22it/s]Loading train:  34%|███▎      | 83/247 [00:54<02:08,  1.28it/s]Loading train:  34%|███▍      | 84/247 [00:55<02:03,  1.32it/s]Loading train:  34%|███▍      | 85/247 [00:56<01:59,  1.35it/s]Loading train:  35%|███▍      | 86/247 [00:56<01:57,  1.37it/s]Loading train:  35%|███▌      | 87/247 [00:57<01:56,  1.38it/s]Loading train:  36%|███▌      | 88/247 [00:58<01:53,  1.40it/s]Loading train:  36%|███▌      | 89/247 [00:59<01:51,  1.42it/s]Loading train:  36%|███▋      | 90/247 [00:59<01:48,  1.44it/s]Loading train:  37%|███▋      | 91/247 [01:00<01:48,  1.44it/s]Loading train:  37%|███▋      | 92/247 [01:01<01:47,  1.45it/s]Loading train:  38%|███▊      | 93/247 [01:01<01:45,  1.45it/s]Loading train:  38%|███▊      | 94/247 [01:02<01:47,  1.43it/s]Loading train:  38%|███▊      | 95/247 [01:03<01:46,  1.43it/s]Loading train:  39%|███▉      | 96/247 [01:03<01:45,  1.43it/s]Loading train:  39%|███▉      | 97/247 [01:04<01:44,  1.44it/s]Loading train:  40%|███▉      | 98/247 [01:05<01:43,  1.45it/s]Loading train:  40%|████      | 99/247 [01:05<01:42,  1.45it/s]Loading train:  40%|████      | 100/247 [01:06<01:42,  1.43it/s]Loading train:  41%|████      | 101/247 [01:07<01:40,  1.45it/s]Loading train:  41%|████▏     | 102/247 [01:07<01:38,  1.47it/s]Loading train:  42%|████▏     | 103/247 [01:08<01:40,  1.44it/s]Loading train:  42%|████▏     | 104/247 [01:09<01:38,  1.46it/s]Loading train:  43%|████▎     | 105/247 [01:10<01:36,  1.48it/s]Loading train:  43%|████▎     | 106/247 [01:10<01:35,  1.48it/s]Loading train:  43%|████▎     | 107/247 [01:11<01:35,  1.46it/s]Loading train:  44%|████▎     | 108/247 [01:12<01:37,  1.43it/s]Loading train:  44%|████▍     | 109/247 [01:12<01:37,  1.42it/s]Loading train:  45%|████▍     | 110/247 [01:13<01:36,  1.41it/s]Loading train:  45%|████▍     | 111/247 [01:14<01:35,  1.42it/s]Loading train:  45%|████▌     | 112/247 [01:14<01:34,  1.44it/s]Loading train:  46%|████▌     | 113/247 [01:15<01:32,  1.44it/s]Loading train:  46%|████▌     | 114/247 [01:16<01:33,  1.43it/s]Loading train:  47%|████▋     | 115/247 [01:17<01:32,  1.43it/s]Loading train:  47%|████▋     | 116/247 [01:17<01:29,  1.46it/s]Loading train:  47%|████▋     | 117/247 [01:18<01:28,  1.47it/s]Loading train:  48%|████▊     | 118/247 [01:19<01:30,  1.42it/s]Loading train:  48%|████▊     | 119/247 [01:19<01:29,  1.43it/s]Loading train:  49%|████▊     | 120/247 [01:20<01:28,  1.43it/s]Loading train:  49%|████▉     | 121/247 [01:21<01:28,  1.42it/s]Loading train:  49%|████▉     | 122/247 [01:21<01:29,  1.40it/s]Loading train:  50%|████▉     | 123/247 [01:22<01:28,  1.40it/s]Loading train:  50%|█████     | 124/247 [01:23<01:28,  1.38it/s]Loading train:  51%|█████     | 125/247 [01:24<01:28,  1.38it/s]Loading train:  51%|█████     | 126/247 [01:24<01:27,  1.39it/s]Loading train:  51%|█████▏    | 127/247 [01:25<01:25,  1.40it/s]Loading train:  52%|█████▏    | 128/247 [01:26<01:24,  1.41it/s]Loading train:  52%|█████▏    | 129/247 [01:26<01:23,  1.42it/s]Loading train:  53%|█████▎    | 130/247 [01:27<01:23,  1.41it/s]Loading train:  53%|█████▎    | 131/247 [01:28<01:24,  1.38it/s]Loading train:  53%|█████▎    | 132/247 [01:29<01:23,  1.38it/s]Loading train:  54%|█████▍    | 133/247 [01:29<01:22,  1.38it/s]Loading train:  54%|█████▍    | 134/247 [01:30<01:21,  1.38it/s]Loading train:  55%|█████▍    | 135/247 [01:31<01:20,  1.39it/s]Loading train:  55%|█████▌    | 136/247 [01:31<01:16,  1.45it/s]Loading train:  55%|█████▌    | 137/247 [01:32<01:13,  1.49it/s]Loading train:  56%|█████▌    | 138/247 [01:33<01:10,  1.54it/s]Loading train:  56%|█████▋    | 139/247 [01:33<01:09,  1.56it/s]Loading train:  57%|█████▋    | 140/247 [01:34<01:07,  1.59it/s]Loading train:  57%|█████▋    | 141/247 [01:35<01:05,  1.61it/s]Loading train:  57%|█████▋    | 142/247 [01:35<01:03,  1.65it/s]Loading train:  58%|█████▊    | 143/247 [01:36<01:03,  1.65it/s]Loading train:  58%|█████▊    | 144/247 [01:36<01:02,  1.65it/s]Loading train:  59%|█████▊    | 145/247 [01:37<01:02,  1.62it/s]Loading train:  59%|█████▉    | 146/247 [01:38<01:02,  1.61it/s]Loading train:  60%|█████▉    | 147/247 [01:38<01:01,  1.62it/s]Loading train:  60%|█████▉    | 148/247 [01:39<01:00,  1.64it/s]Loading train:  60%|██████    | 149/247 [01:39<01:00,  1.62it/s]Loading train:  61%|██████    | 150/247 [01:40<00:59,  1.63it/s]Loading train:  61%|██████    | 151/247 [01:41<00:59,  1.62it/s]Loading train:  62%|██████▏   | 152/247 [01:41<00:58,  1.64it/s]Loading train:  62%|██████▏   | 153/247 [01:42<00:57,  1.63it/s]Loading train:  62%|██████▏   | 154/247 [01:42<00:57,  1.63it/s]Loading train:  63%|██████▎   | 155/247 [01:43<00:55,  1.65it/s]Loading train:  63%|██████▎   | 156/247 [01:44<00:55,  1.65it/s]Loading train:  64%|██████▎   | 157/247 [01:44<00:54,  1.67it/s]Loading train:  64%|██████▍   | 158/247 [01:45<00:52,  1.69it/s]Loading train:  64%|██████▍   | 159/247 [01:45<00:51,  1.69it/s]Loading train:  65%|██████▍   | 160/247 [01:46<00:51,  1.70it/s]Loading train:  65%|██████▌   | 161/247 [01:47<00:51,  1.69it/s]Loading train:  66%|██████▌   | 162/247 [01:47<00:49,  1.72it/s]Loading train:  66%|██████▌   | 163/247 [01:48<00:48,  1.72it/s]Loading train:  66%|██████▋   | 164/247 [01:48<00:48,  1.72it/s]Loading train:  67%|██████▋   | 165/247 [01:49<00:47,  1.73it/s]Loading train:  67%|██████▋   | 166/247 [01:49<00:46,  1.72it/s]Loading train:  68%|██████▊   | 167/247 [01:50<00:46,  1.71it/s]Loading train:  68%|██████▊   | 168/247 [01:51<00:45,  1.72it/s]Loading train:  68%|██████▊   | 169/247 [01:51<00:45,  1.73it/s]Loading train:  69%|██████▉   | 170/247 [01:52<00:44,  1.75it/s]Loading train:  69%|██████▉   | 171/247 [01:52<00:42,  1.78it/s]Loading train:  70%|██████▉   | 172/247 [01:53<00:49,  1.52it/s]Loading train:  70%|███████   | 173/247 [01:54<00:51,  1.43it/s]Loading train:  70%|███████   | 174/247 [01:55<00:53,  1.37it/s]Loading train:  71%|███████   | 175/247 [01:56<00:58,  1.24it/s]Loading train:  71%|███████▏  | 176/247 [01:56<00:54,  1.30it/s]Loading train:  72%|███████▏  | 177/247 [01:57<00:51,  1.37it/s]Loading train:  72%|███████▏  | 178/247 [01:58<00:48,  1.43it/s]Loading train:  72%|███████▏  | 179/247 [01:58<00:45,  1.49it/s]Loading train:  73%|███████▎  | 180/247 [01:59<00:43,  1.54it/s]Loading train:  73%|███████▎  | 181/247 [02:00<00:42,  1.56it/s]Loading train:  74%|███████▎  | 182/247 [02:00<00:40,  1.59it/s]Loading train:  74%|███████▍  | 183/247 [02:01<00:40,  1.59it/s]Loading train:  74%|███████▍  | 184/247 [02:01<00:39,  1.59it/s]Loading train:  75%|███████▍  | 185/247 [02:02<00:38,  1.62it/s]Loading train:  75%|███████▌  | 186/247 [02:03<00:37,  1.64it/s]Loading train:  76%|███████▌  | 187/247 [02:03<00:37,  1.59it/s]Loading train:  76%|███████▌  | 188/247 [02:04<00:37,  1.56it/s]Loading train:  77%|███████▋  | 189/247 [02:05<00:37,  1.57it/s]Loading train:  77%|███████▋  | 190/247 [02:05<00:35,  1.59it/s]Loading train:  77%|███████▋  | 191/247 [02:06<00:35,  1.58it/s]Loading train:  78%|███████▊  | 192/247 [02:06<00:34,  1.59it/s]Loading train:  78%|███████▊  | 193/247 [02:07<00:33,  1.61it/s]Loading train:  79%|███████▊  | 194/247 [02:08<00:32,  1.61it/s]Loading train:  79%|███████▉  | 195/247 [02:08<00:32,  1.58it/s]Loading train:  79%|███████▉  | 196/247 [02:09<00:32,  1.57it/s]Loading train:  80%|███████▉  | 197/247 [02:10<00:32,  1.56it/s]Loading train:  80%|████████  | 198/247 [02:10<00:31,  1.57it/s]Loading train:  81%|████████  | 199/247 [02:11<00:30,  1.57it/s]Loading train:  81%|████████  | 200/247 [02:11<00:29,  1.60it/s]Loading train:  81%|████████▏ | 201/247 [02:12<00:29,  1.58it/s]Loading train:  82%|████████▏ | 202/247 [02:13<00:28,  1.60it/s]Loading train:  82%|████████▏ | 203/247 [02:13<00:27,  1.62it/s]Loading train:  83%|████████▎ | 204/247 [02:14<00:25,  1.66it/s]Loading train:  83%|████████▎ | 205/247 [02:15<00:25,  1.65it/s]Loading train:  83%|████████▎ | 206/247 [02:15<00:24,  1.66it/s]Loading train:  84%|████████▍ | 207/247 [02:16<00:24,  1.66it/s]Loading train:  84%|████████▍ | 208/247 [02:16<00:23,  1.67it/s]Loading train:  85%|████████▍ | 209/247 [02:17<00:22,  1.68it/s]Loading train:  85%|████████▌ | 210/247 [02:17<00:21,  1.68it/s]Loading train:  85%|████████▌ | 211/247 [02:18<00:21,  1.70it/s]Loading train:  86%|████████▌ | 212/247 [02:19<00:20,  1.70it/s]Loading train:  86%|████████▌ | 213/247 [02:19<00:20,  1.68it/s]Loading train:  87%|████████▋ | 214/247 [02:20<00:19,  1.66it/s]Loading train:  87%|████████▋ | 215/247 [02:20<00:19,  1.65it/s]Loading train:  87%|████████▋ | 216/247 [02:21<00:19,  1.63it/s]Loading train:  88%|████████▊ | 217/247 [02:22<00:18,  1.62it/s]Loading train:  88%|████████▊ | 218/247 [02:22<00:17,  1.64it/s]Loading train:  89%|████████▊ | 219/247 [02:23<00:17,  1.64it/s]Loading train:  89%|████████▉ | 220/247 [02:24<00:20,  1.29it/s]Loading train:  89%|████████▉ | 221/247 [02:27<00:33,  1.30s/it]Loading train:  90%|████████▉ | 222/247 [02:31<00:51,  2.07s/it]Loading train:  90%|█████████ | 223/247 [02:34<01:01,  2.56s/it]Loading train:  91%|█████████ | 224/247 [02:38<01:05,  2.86s/it]Loading train:  91%|█████████ | 225/247 [02:41<01:06,  3.03s/it]Loading train:  91%|█████████▏| 226/247 [02:45<01:07,  3.23s/it]Loading train:  92%|█████████▏| 227/247 [02:49<01:06,  3.35s/it]Loading train:  92%|█████████▏| 228/247 [02:52<01:04,  3.41s/it]Loading train:  93%|█████████▎| 229/247 [02:56<01:03,  3.54s/it]Loading train:  93%|█████████▎| 230/247 [03:02<01:14,  4.40s/it]Loading train:  94%|█████████▎| 231/247 [03:08<01:18,  4.88s/it]Loading train:  94%|█████████▍| 232/247 [03:14<01:17,  5.17s/it]Loading train:  94%|█████████▍| 233/247 [03:20<01:15,  5.40s/it]Loading train:  95%|█████████▍| 234/247 [03:26<01:12,  5.54s/it]Loading train:  95%|█████████▌| 235/247 [03:32<01:07,  5.62s/it]Loading train:  96%|█████████▌| 236/247 [03:38<01:02,  5.71s/it]Loading train:  96%|█████████▌| 237/247 [03:44<00:57,  5.76s/it]Loading train:  96%|█████████▋| 238/247 [03:49<00:52,  5.81s/it]Loading train:  97%|█████████▋| 239/247 [03:55<00:46,  5.82s/it]Loading train:  97%|█████████▋| 240/247 [04:00<00:38,  5.45s/it]Loading train:  98%|█████████▊| 241/247 [04:06<00:33,  5.64s/it]Loading train:  98%|█████████▊| 242/247 [04:12<00:29,  5.81s/it]Loading train:  98%|█████████▊| 243/247 [04:18<00:23,  5.83s/it]Loading train:  99%|█████████▉| 244/247 [04:24<00:17,  5.88s/it]Loading train:  99%|█████████▉| 245/247 [04:30<00:11,  5.91s/it]Loading train: 100%|█████████▉| 246/247 [04:36<00:05,  5.98s/it]Loading train: 100%|██████████| 247/247 [04:42<00:00,  5.98s/it]Loading train: 100%|██████████| 247/247 [04:42<00:00,  1.14s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 45.85it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 45.83it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:05, 46.00it/s]concatenating: train:   9%|▉         | 22/247 [00:00<00:04, 46.05it/s]concatenating: train:  11%|█▏        | 28/247 [00:00<00:04, 49.32it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:04, 51.58it/s]concatenating: train:  16%|█▌        | 39/247 [00:00<00:04, 50.40it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:03, 51.02it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 48.24it/s]concatenating: train:  23%|██▎       | 56/247 [00:01<00:03, 49.17it/s]concatenating: train:  25%|██▌       | 62/247 [00:01<00:03, 50.17it/s]concatenating: train:  27%|██▋       | 67/247 [00:01<00:03, 48.38it/s]concatenating: train:  30%|██▉       | 73/247 [00:01<00:03, 49.33it/s]concatenating: train:  32%|███▏      | 79/247 [00:01<00:03, 49.64it/s]concatenating: train:  34%|███▍      | 85/247 [00:01<00:03, 50.14it/s]concatenating: train:  37%|███▋      | 91/247 [00:01<00:03, 49.75it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:03, 49.50it/s]concatenating: train:  41%|████▏     | 102/247 [00:02<00:02, 49.95it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:02, 51.06it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:02, 51.78it/s]concatenating: train:  49%|████▊     | 120/247 [00:02<00:02, 51.58it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 50.75it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:02, 49.51it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:02, 49.31it/s]concatenating: train:  57%|█████▋    | 142/247 [00:02<00:02, 49.34it/s]concatenating: train:  60%|█████▉    | 148/247 [00:02<00:01, 50.12it/s]concatenating: train:  62%|██████▏   | 154/247 [00:03<00:01, 50.61it/s]concatenating: train:  65%|██████▌   | 161/247 [00:03<00:01, 53.08it/s]concatenating: train:  68%|██████▊   | 168/247 [00:03<00:01, 55.19it/s]concatenating: train:  70%|███████   | 174/247 [00:03<00:01, 55.45it/s]concatenating: train:  73%|███████▎  | 180/247 [00:03<00:01, 55.11it/s]concatenating: train:  75%|███████▌  | 186/247 [00:03<00:01, 54.34it/s]concatenating: train:  78%|███████▊  | 192/247 [00:03<00:01, 54.24it/s]concatenating: train:  80%|████████  | 198/247 [00:03<00:00, 52.99it/s]concatenating: train:  83%|████████▎ | 204/247 [00:03<00:00, 52.67it/s]concatenating: train:  85%|████████▌ | 210/247 [00:04<00:00, 52.24it/s]concatenating: train:  87%|████████▋ | 216/247 [00:04<00:00, 52.94it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 53.21it/s]concatenating: train:  92%|█████████▏| 228/247 [00:04<00:00, 51.99it/s]concatenating: train:  95%|█████████▍| 234/247 [00:04<00:00, 51.44it/s]concatenating: train:  97%|█████████▋| 240/247 [00:04<00:00, 50.11it/s]concatenating: train: 100%|█████████▉| 246/247 [00:04<00:00, 49.97it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 51.05it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:17<01:09, 17.35s/it]Loading test:  40%|████      | 2/5 [00:31<00:49, 16.38s/it]Loading test:  60%|██████    | 3/5 [00:41<00:28, 14.38s/it]Loading test:  80%|████████  | 4/5 [00:48<00:12, 12.34s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.72s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.47s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 52.98it/s]
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2020-01-21 20:16:55.366379: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 20:16:55.366477: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 20:16:55.366502: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 20:16:55.366511: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 20:16:55.366908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.23732826e-02 3.14611437e-02 7.87372216e-02 9.59010825e-03
 2.85756093e-02 7.23232553e-03 8.58311674e-02 1.15196609e-01
 9.01083875e-02 1.30692463e-02 2.94185629e-01 1.83387874e-01
 2.51395553e-04]
Train on 15611 samples, validate on 317 samples
Epoch 1/300
 - 35s - loss: 0.5474 - acc: 0.9135 - mDice: 0.4098 - val_loss: 0.7441 - val_acc: 0.9297 - val_mDice: 0.1960

Epoch 00001: val_mDice improved from -inf to 0.19599, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 31s - loss: 0.4045 - acc: 0.9406 - mDice: 0.5640 - val_loss: 0.7289 - val_acc: 0.9306 - val_mDice: 0.2089

Epoch 00002: val_mDice improved from 0.19599 to 0.20887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 30s - loss: 0.3767 - acc: 0.9439 - mDice: 0.5940 - val_loss: 0.7180 - val_acc: 0.9388 - val_mDice: 0.2016

Epoch 00003: val_mDice did not improve from 0.20887
Epoch 4/300
 - 30s - loss: 0.3616 - acc: 0.9459 - mDice: 0.6103 - val_loss: 0.6136 - val_acc: 0.9345 - val_mDice: 0.2159

Epoch 00004: val_mDice improved from 0.20887 to 0.21586, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 5/300
 - 30s - loss: 0.3470 - acc: 0.9472 - mDice: 0.6261 - val_loss: 0.6252 - val_acc: 0.9396 - val_mDice: 0.2152

Epoch 00005: val_mDice did not improve from 0.21586
Epoch 6/300
 - 30s - loss: 0.3393 - acc: 0.9482 - mDice: 0.6344 - val_loss: 0.6360 - val_acc: 0.9424 - val_mDice: 0.2007

Epoch 00006: val_mDice did not improve from 0.21586
Epoch 7/300
 - 30s - loss: 0.3349 - acc: 0.9490 - mDice: 0.6392 - val_loss: 0.3890 - val_acc: 0.9398 - val_mDice: 0.2142

Epoch 00007: val_mDice did not improve from 0.21586
Epoch 8/300
 - 30s - loss: 0.3290 - acc: 0.9498 - mDice: 0.6455 - val_loss: 0.5904 - val_acc: 0.9343 - val_mDice: 0.2076

Epoch 00008: val_mDice did not improve from 0.21586
Epoch 9/300
 - 30s - loss: 0.3210 - acc: 0.9505 - mDice: 0.6542 - val_loss: 0.2874 - val_acc: 0.9426 - val_mDice: 0.2184

Epoch 00009: val_mDice improved from 0.21586 to 0.21835, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 10/300
 - 29s - loss: 0.3192 - acc: 0.9508 - mDice: 0.6561 - val_loss: 0.1776 - val_acc: 0.9455 - val_mDice: 0.2228

Epoch 00010: val_mDice improved from 0.21835 to 0.22281, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 11/300
 - 31s - loss: 0.3125 - acc: 0.9513 - mDice: 0.6633 - val_loss: 0.0303 - val_acc: 0.9429 - val_mDice: 0.2099

Epoch 00011: val_mDice did not improve from 0.22281
Epoch 12/300
 - 30s - loss: 0.3113 - acc: 0.9515 - mDice: 0.6646 - val_loss: 0.0704 - val_acc: 0.9437 - val_mDice: 0.2201

Epoch 00012: val_mDice did not improve from 0.22281
Epoch 13/300
 - 31s - loss: 0.3067 - acc: 0.9518 - mDice: 0.6696 - val_loss: -3.0304e-02 - val_acc: 0.9459 - val_mDice: 0.2167

Epoch 00013: val_mDice did not improve from 0.22281
Epoch 14/300
 - 31s - loss: 0.3027 - acc: 0.9525 - mDice: 0.6739 - val_loss: 0.0525 - val_acc: 0.9402 - val_mDice: 0.2191

Epoch 00014: val_mDice did not improve from 0.22281
Epoch 15/300
 - 30s - loss: 0.3056 - acc: 0.9523 - mDice: 0.6707 - val_loss: 0.0484 - val_acc: 0.9375 - val_mDice: 0.2088

Epoch 00015: val_mDice did not improve from 0.22281
Epoch 16/300
 - 31s - loss: 0.2993 - acc: 0.9529 - mDice: 0.6776 - val_loss: -8.4127e-02 - val_acc: 0.9492 - val_mDice: 0.2289

Epoch 00016: val_mDice improved from 0.22281 to 0.22888, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 17/300
 - 30s - loss: 0.2980 - acc: 0.9530 - mDice: 0.6789 - val_loss: -8.1066e-02 - val_acc: 0.9418 - val_mDice: 0.2153

Epoch 00017: val_mDice did not improve from 0.22888
Epoch 18/300
 - 30s - loss: 0.3168 - acc: 0.9499 - mDice: 0.6460 - val_loss: -1.2752e-01 - val_acc: 0.9420 - val_mDice: 0.2092

Epoch 00018: val_mDice did not improve from 0.22888
Epoch 19/300
 - 30s - loss: 0.3030 - acc: 0.9498 - mDice: 0.6380 - val_loss: -1.1311e-01 - val_acc: 0.9369 - val_mDice: 0.2130

Epoch 00019: val_mDice did not improve from 0.22888
Epoch 20/300
 - 29s - loss: 0.2929 - acc: 0.9504 - mDice: 0.6460 - val_loss: -1.6202e-01 - val_acc: 0.9447 - val_mDice: 0.2046

Epoch 00020: val_mDice did not improve from 0.22888
Epoch 21/300
 - 31s - loss: 0.2877 - acc: 0.9510 - mDice: 0.6509 - val_loss: -1.6634e-01 - val_acc: 0.9474 - val_mDice: 0.2263

Epoch 00021: val_mDice did not improve from 0.22888
Epoch 22/300
 - 30s - loss: 0.2904 - acc: 0.9505 - mDice: 0.6458 - val_loss: -1.6452e-01 - val_acc: 0.9432 - val_mDice: 0.2172

Epoch 00022: val_mDice did not improve from 0.22888
Epoch 23/300
 - 30s - loss: 0.2792 - acc: 0.9500 - mDice: 0.6451 - val_loss: -1.6076e-01 - val_acc: 0.9421 - val_mDice: 0.2180

Epoch 00023: val_mDice did not improve from 0.22888
Epoch 24/300
 - 30s - loss: 0.2817 - acc: 0.9488 - mDice: 0.6305 - val_loss: -1.7019e-01 - val_acc: 0.9462 - val_mDice: 0.2176

Epoch 00024: val_mDice did not improve from 0.22888
Epoch 25/300
 - 30s - loss: 0.3178 - acc: 0.9462 - mDice: 0.5751 - val_loss: -1.6526e-01 - val_acc: 0.9422 - val_mDice: 0.1992

Epoch 00025: val_mDice did not improve from 0.22888
Epoch 26/300
 - 30s - loss: 0.2915 - acc: 0.9469 - mDice: 0.5982 - val_loss: -1.5344e-01 - val_acc: 0.9423 - val_mDice: 0.1931

Epoch 00026: val_mDice did not improve from 0.22888
Epoch 27/300
 - 30s - loss: 0.2984 - acc: 0.9457 - mDice: 0.5751 - val_loss: -9.0563e-02 - val_acc: 0.9155 - val_mDice: 0.1781

Epoch 00027: val_mDice did not improve from 0.22888
Epoch 28/300
 - 29s - loss: 0.3024 - acc: 0.9453 - mDice: 0.5655 - val_loss: -1.7547e-01 - val_acc: 0.9401 - val_mDice: 0.1935

Epoch 00028: val_mDice did not improve from 0.22888
Epoch 29/300
 - 30s - loss: 0.3304 - acc: 0.9450 - mDice: 0.5294 - val_loss: -2.2011e-01 - val_acc: 0.9416 - val_mDice: 0.1929

Epoch 00029: val_mDice did not improve from 0.22888
Epoch 30/300
 - 30s - loss: 0.3105 - acc: 0.9448 - mDice: 0.5566 - val_loss: -1.8667e-01 - val_acc: 0.9441 - val_mDice: 0.1867

Epoch 00030: val_mDice did not improve from 0.22888
Epoch 31/300
 - 30s - loss: 0.2835 - acc: 0.9466 - mDice: 0.5953 - val_loss: -1.9676e-01 - val_acc: 0.9431 - val_mDice: 0.2150

Epoch 00031: val_mDice did not improve from 0.22888

Epoch 00031: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 32/300
 - 30s - loss: 0.2531 - acc: 0.9486 - mDice: 0.6234 - val_loss: -2.1991e-01 - val_acc: 0.9446 - val_mDice: 0.2115

Epoch 00032: val_mDice did not improve from 0.22888
Epoch 33/300
 - 30s - loss: 0.2429 - acc: 0.9492 - mDice: 0.6293 - val_loss: -2.1694e-01 - val_acc: 0.9423 - val_mDice: 0.2000

Epoch 00033: val_mDice did not improve from 0.22888
Epoch 34/300
 - 30s - loss: 0.2365 - acc: 0.9496 - mDice: 0.6352 - val_loss: -1.9227e-01 - val_acc: 0.9424 - val_mDice: 0.1995

Epoch 00034: val_mDice did not improve from 0.22888
Epoch 35/300
 - 30s - loss: 0.2367 - acc: 0.9497 - mDice: 0.6304 - val_loss: -2.1676e-01 - val_acc: 0.9445 - val_mDice: 0.2011

Epoch 00035: val_mDice did not improve from 0.22888
Epoch 36/300
 - 30s - loss: 0.2332 - acc: 0.9502 - mDice: 0.6364 - val_loss: -2.1462e-01 - val_acc: 0.9423 - val_mDice: 0.2080

Epoch 00036: val_mDice did not improve from 0.22888
Epoch 37/300
 - 29s - loss: 0.2323 - acc: 0.9500 - mDice: 0.6356 - val_loss: -2.1584e-01 - val_acc: 0.9450 - val_mDice: 0.1987

Epoch 00037: val_mDice did not improve from 0.22888
Epoch 38/300
 - 30s - loss: 0.2376 - acc: 0.9498 - mDice: 0.6311 - val_loss: -2.2160e-01 - val_acc: 0.9447 - val_mDice: 0.2050

Epoch 00038: val_mDice did not improve from 0.22888
Epoch 39/300
 - 30s - loss: 0.2284 - acc: 0.9502 - mDice: 0.6376 - val_loss: -2.0462e-01 - val_acc: 0.9417 - val_mDice: 0.2078

Epoch 00039: val_mDice did not improve from 0.22888
Epoch 40/300
 - 30s - loss: 0.2234 - acc: 0.9510 - mDice: 0.6477 - val_loss: -1.9685e-01 - val_acc: 0.9424 - val_mDice: 0.1992

Epoch 00040: val_mDice did not improve from 0.22888
Epoch 41/300
 - 30s - loss: 0.2357 - acc: 0.9503 - mDice: 0.6385 - val_loss: -1.9987e-01 - val_acc: 0.9405 - val_mDice: 0.1962

Epoch 00041: val_mDice did not improve from 0.22888
Epoch 42/300
 - 30s - loss: 0.2323 - acc: 0.9506 - mDice: 0.6436 - val_loss: -2.0694e-01 - val_acc: 0.9448 - val_mDice: 0.2038

Epoch 00042: val_mDice did not improve from 0.22888
Epoch 43/300
 - 30s - loss: 0.2223 - acc: 0.9513 - mDice: 0.6516 - val_loss: -1.9756e-01 - val_acc: 0.9405 - val_mDice: 0.2082

Epoch 00043: val_mDice did not improve from 0.22888
Epoch 44/300
 - 30s - loss: 0.2432 - acc: 0.9498 - mDice: 0.6257 - val_loss: -1.9348e-01 - val_acc: 0.9425 - val_mDice: 0.2032

Epoch 00044: val_mDice did not improve from 0.22888
Epoch 45/300
 - 30s - loss: 0.2381 - acc: 0.9496 - mDice: 0.6278 - val_loss: -2.0110e-01 - val_acc: 0.9441 - val_mDice: 0.1989

Epoch 00045: val_mDice did not improve from 0.22888
Epoch 46/300
 - 31s - loss: 0.2244 - acc: 0.9502 - mDice: 0.6362 - val_loss: -2.1341e-01 - val_acc: 0.9457 - val_mDice: 0.2020

Epoch 00046: val_mDice did not improve from 0.22888

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 47/300
 - 30s - loss: 0.2158 - acc: 0.9508 - mDice: 0.6492 - val_loss: -2.0476e-01 - val_acc: 0.9449 - val_mDice: 0.2024

Epoch 00047: val_mDice did not improve from 0.22888
Epoch 48/300
 - 30s - loss: 0.2135 - acc: 0.9516 - mDice: 0.6567 - val_loss: -2.0827e-01 - val_acc: 0.9447 - val_mDice: 0.1957

Epoch 00048: val_mDice did not improve from 0.22888
Epoch 49/300
 - 30s - loss: 0.2202 - acc: 0.9510 - mDice: 0.6478 - val_loss: -2.1531e-01 - val_acc: 0.9435 - val_mDice: 0.1969

Epoch 00049: val_mDice did not improve from 0.22888
Epoch 50/300
 - 29s - loss: 0.2107 - acc: 0.9516 - mDice: 0.6543 - val_loss: -2.0774e-01 - val_acc: 0.9426 - val_mDice: 0.2004

Epoch 00050: val_mDice did not improve from 0.22888
Epoch 51/300
 - 30s - loss: 0.2111 - acc: 0.9516 - mDice: 0.6532 - val_loss: -2.0823e-01 - val_acc: 0.9465 - val_mDice: 0.2039

Epoch 00051: val_mDice did not improve from 0.22888
Epoch 52/300
 - 30s - loss: 0.2092 - acc: 0.9518 - mDice: 0.6573 - val_loss: -2.0302e-01 - val_acc: 0.9436 - val_mDice: 0.2060

Epoch 00052: val_mDice did not improve from 0.22888
Epoch 53/300
 - 29s - loss: 0.2049 - acc: 0.9521 - mDice: 0.6628 - val_loss: -1.9968e-01 - val_acc: 0.9438 - val_mDice: 0.2023

Epoch 00053: val_mDice did not improve from 0.22888
Epoch 54/300
 - 30s - loss: 0.2019 - acc: 0.9523 - mDice: 0.6600 - val_loss: -2.0764e-01 - val_acc: 0.9439 - val_mDice: 0.2047

Epoch 00054: val_mDice did not improve from 0.22888
Epoch 55/300
 - 30s - loss: 0.2038 - acc: 0.9524 - mDice: 0.6659 - val_loss: -2.0455e-01 - val_acc: 0.9465 - val_mDice: 0.2074

Epoch 00055: val_mDice did not improve from 0.22888
Epoch 56/300
 - 30s - loss: 0.2057 - acc: 0.9522 - mDice: 0.6626 - val_loss: -2.1008e-01 - val_acc: 0.9475 - val_mDice: 0.2029

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.66s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.49s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.34s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.22s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.19s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:02,  3.96it/s]Loading train:   1%|          | 2/247 [00:00<01:00,  4.04it/s]Loading train:   1%|          | 3/247 [00:00<00:59,  4.10it/s]Loading train:   2%|▏         | 4/247 [00:00<00:59,  4.11it/s]Loading train:   2%|▏         | 5/247 [00:01<00:57,  4.21it/s]Loading train:   2%|▏         | 6/247 [00:01<00:56,  4.28it/s]Loading train:   3%|▎         | 7/247 [00:01<00:56,  4.27it/s]Loading train:   3%|▎         | 8/247 [00:01<00:55,  4.32it/s]Loading train:   4%|▎         | 9/247 [00:02<00:55,  4.29it/s]Loading train:   4%|▍         | 10/247 [00:02<00:55,  4.27it/s]Loading train:   4%|▍         | 11/247 [00:02<00:54,  4.33it/s]Loading train:   5%|▍         | 12/247 [00:02<00:54,  4.32it/s]Loading train:   5%|▌         | 13/247 [00:03<00:54,  4.33it/s]Loading train:   6%|▌         | 14/247 [00:03<00:53,  4.36it/s]Loading train:   6%|▌         | 15/247 [00:03<00:52,  4.42it/s]Loading train:   6%|▋         | 16/247 [00:03<00:52,  4.43it/s]Loading train:   7%|▋         | 17/247 [00:03<00:51,  4.44it/s]Loading train:   7%|▋         | 18/247 [00:04<00:51,  4.47it/s]Loading train:   8%|▊         | 19/247 [00:04<00:50,  4.49it/s]Loading train:   8%|▊         | 20/247 [00:04<00:50,  4.49it/s]Loading train:   9%|▊         | 21/247 [00:04<00:50,  4.48it/s]Loading train:   9%|▉         | 22/247 [00:05<00:50,  4.49it/s]Loading train:   9%|▉         | 23/247 [00:05<00:49,  4.49it/s]Loading train:  10%|▉         | 24/247 [00:05<00:50,  4.46it/s]Loading train:  10%|█         | 25/247 [00:05<00:50,  4.43it/s]Loading train:  11%|█         | 26/247 [00:05<00:49,  4.44it/s]Loading train:  11%|█         | 27/247 [00:06<00:49,  4.49it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:48,  4.50it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:48,  4.51it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:47,  4.53it/s]Loading train:  13%|█▎        | 31/247 [00:07<00:47,  4.52it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:47,  4.51it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:47,  4.51it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:46,  4.55it/s]Loading train:  14%|█▍        | 35/247 [00:07<00:46,  4.55it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:46,  4.55it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:46,  4.52it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:45,  4.55it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:45,  4.55it/s]Loading train:  16%|█▌        | 40/247 [00:09<00:45,  4.53it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:45,  4.54it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:45,  4.54it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:44,  4.55it/s]Loading train:  18%|█▊        | 44/247 [00:09<00:44,  4.56it/s]Loading train:  18%|█▊        | 45/247 [00:10<00:44,  4.58it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:43,  4.59it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:43,  4.58it/s]Loading train:  19%|█▉        | 48/247 [00:10<00:43,  4.57it/s]Loading train:  20%|█▉        | 49/247 [00:10<00:43,  4.55it/s]Loading train:  20%|██        | 50/247 [00:11<00:43,  4.55it/s]Loading train:  21%|██        | 51/247 [00:11<00:43,  4.54it/s]Loading train:  21%|██        | 52/247 [00:11<00:43,  4.52it/s]Loading train:  21%|██▏       | 53/247 [00:11<00:42,  4.53it/s]Loading train:  22%|██▏       | 54/247 [00:12<00:43,  4.47it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:42,  4.52it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:42,  4.52it/s]Loading train:  23%|██▎       | 57/247 [00:12<00:41,  4.53it/s]Loading train:  23%|██▎       | 58/247 [00:12<00:41,  4.54it/s]Loading train:  24%|██▍       | 59/247 [00:13<00:41,  4.51it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:41,  4.50it/s]Loading train:  25%|██▍       | 61/247 [00:13<00:41,  4.49it/s]Loading train:  25%|██▌       | 62/247 [00:13<00:41,  4.51it/s]Loading train:  26%|██▌       | 63/247 [00:14<00:40,  4.51it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:40,  4.49it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:40,  4.52it/s]Loading train:  27%|██▋       | 66/247 [00:14<00:40,  4.49it/s]Loading train:  27%|██▋       | 67/247 [00:14<00:40,  4.48it/s]Loading train:  28%|██▊       | 68/247 [00:15<00:39,  4.49it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:39,  4.51it/s]Loading train:  28%|██▊       | 70/247 [00:15<00:39,  4.48it/s]Loading train:  29%|██▊       | 71/247 [00:15<00:39,  4.49it/s]Loading train:  29%|██▉       | 72/247 [00:16<00:38,  4.49it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:38,  4.46it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:39,  4.41it/s]Loading train:  30%|███       | 75/247 [00:16<00:39,  4.38it/s]Loading train:  31%|███       | 76/247 [00:17<00:39,  4.36it/s]Loading train:  31%|███       | 77/247 [00:17<00:39,  4.26it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:42,  3.98it/s]Loading train:  32%|███▏      | 79/247 [00:17<00:42,  3.94it/s]Loading train:  32%|███▏      | 80/247 [00:18<00:39,  4.18it/s]Loading train:  33%|███▎      | 81/247 [00:18<00:40,  4.15it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:38,  4.24it/s]Loading train:  34%|███▎      | 83/247 [00:18<00:38,  4.29it/s]Loading train:  34%|███▍      | 84/247 [00:18<00:37,  4.33it/s]Loading train:  34%|███▍      | 85/247 [00:19<00:37,  4.37it/s]Loading train:  35%|███▍      | 86/247 [00:19<00:36,  4.40it/s]Loading train:  35%|███▌      | 87/247 [00:19<00:36,  4.43it/s]Loading train:  36%|███▌      | 88/247 [00:19<00:35,  4.44it/s]Loading train:  36%|███▌      | 89/247 [00:20<00:35,  4.42it/s]Loading train:  36%|███▋      | 90/247 [00:20<00:35,  4.45it/s]Loading train:  37%|███▋      | 91/247 [00:20<00:35,  4.44it/s]Loading train:  37%|███▋      | 92/247 [00:20<00:34,  4.45it/s]Loading train:  38%|███▊      | 93/247 [00:20<00:34,  4.47it/s]Loading train:  38%|███▊      | 94/247 [00:21<00:34,  4.50it/s]Loading train:  38%|███▊      | 95/247 [00:21<00:33,  4.51it/s]Loading train:  39%|███▉      | 96/247 [00:21<00:33,  4.50it/s]Loading train:  39%|███▉      | 97/247 [00:21<00:33,  4.49it/s]Loading train:  40%|███▉      | 98/247 [00:22<00:33,  4.46it/s]Loading train:  40%|████      | 99/247 [00:22<00:33,  4.47it/s]Loading train:  40%|████      | 100/247 [00:22<00:34,  4.25it/s]Loading train:  41%|████      | 101/247 [00:22<00:35,  4.10it/s]Loading train:  41%|████▏     | 102/247 [00:23<00:36,  4.01it/s]Loading train:  42%|████▏     | 103/247 [00:23<00:36,  3.92it/s]Loading train:  42%|████▏     | 104/247 [00:23<00:36,  3.90it/s]Loading train:  43%|████▎     | 105/247 [00:23<00:36,  3.87it/s]Loading train:  43%|████▎     | 106/247 [00:24<00:36,  3.83it/s]Loading train:  43%|████▎     | 107/247 [00:24<00:36,  3.85it/s]Loading train:  44%|████▎     | 108/247 [00:24<00:37,  3.74it/s]Loading train:  44%|████▍     | 109/247 [00:24<00:36,  3.76it/s]Loading train:  45%|████▍     | 110/247 [00:25<00:36,  3.74it/s]Loading train:  45%|████▍     | 111/247 [00:25<00:36,  3.72it/s]Loading train:  45%|████▌     | 112/247 [00:25<00:35,  3.75it/s]Loading train:  46%|████▌     | 113/247 [00:26<00:35,  3.79it/s]Loading train:  46%|████▌     | 114/247 [00:26<00:35,  3.80it/s]Loading train:  47%|████▋     | 115/247 [00:26<00:34,  3.80it/s]Loading train:  47%|████▋     | 116/247 [00:26<00:34,  3.78it/s]Loading train:  47%|████▋     | 117/247 [00:27<00:33,  3.83it/s]Loading train:  48%|████▊     | 118/247 [00:27<00:32,  3.92it/s]Loading train:  48%|████▊     | 119/247 [00:27<00:31,  4.04it/s]Loading train:  49%|████▊     | 120/247 [00:27<00:30,  4.12it/s]Loading train:  49%|████▉     | 121/247 [00:27<00:30,  4.17it/s]Loading train:  49%|████▉     | 122/247 [00:28<00:29,  4.20it/s]Loading train:  50%|████▉     | 123/247 [00:28<00:29,  4.20it/s]Loading train:  50%|█████     | 124/247 [00:28<00:29,  4.21it/s]Loading train:  51%|█████     | 125/247 [00:28<00:28,  4.24it/s]Loading train:  51%|█████     | 126/247 [00:29<00:28,  4.26it/s]Loading train:  51%|█████▏    | 127/247 [00:29<00:28,  4.26it/s]Loading train:  52%|█████▏    | 128/247 [00:29<00:27,  4.25it/s]Loading train:  52%|█████▏    | 129/247 [00:29<00:27,  4.26it/s]Loading train:  53%|█████▎    | 130/247 [00:30<00:27,  4.25it/s]Loading train:  53%|█████▎    | 131/247 [00:30<00:27,  4.25it/s]Loading train:  53%|█████▎    | 132/247 [00:30<00:26,  4.26it/s]Loading train:  54%|█████▍    | 133/247 [00:30<00:26,  4.22it/s]Loading train:  54%|█████▍    | 134/247 [00:31<00:26,  4.27it/s]Loading train:  55%|█████▍    | 135/247 [00:31<00:26,  4.24it/s]Loading train:  55%|█████▌    | 136/247 [00:31<00:24,  4.45it/s]Loading train:  55%|█████▌    | 137/247 [00:31<00:23,  4.59it/s]Loading train:  56%|█████▌    | 138/247 [00:31<00:23,  4.71it/s]Loading train:  56%|█████▋    | 139/247 [00:32<00:22,  4.80it/s]Loading train:  57%|█████▋    | 140/247 [00:32<00:21,  4.88it/s]Loading train:  57%|█████▋    | 141/247 [00:32<00:21,  4.94it/s]Loading train:  57%|█████▋    | 142/247 [00:32<00:21,  4.96it/s]Loading train:  58%|█████▊    | 143/247 [00:32<00:20,  4.97it/s]Loading train:  58%|█████▊    | 144/247 [00:33<00:20,  4.99it/s]Loading train:  59%|█████▊    | 145/247 [00:33<00:20,  5.02it/s]Loading train:  59%|█████▉    | 146/247 [00:33<00:20,  5.04it/s]Loading train:  60%|█████▉    | 147/247 [00:33<00:19,  5.05it/s]Loading train:  60%|█████▉    | 148/247 [00:33<00:19,  5.03it/s]Loading train:  60%|██████    | 149/247 [00:34<00:19,  5.03it/s]Loading train:  61%|██████    | 150/247 [00:34<00:19,  5.06it/s]Loading train:  61%|██████    | 151/247 [00:34<00:18,  5.06it/s]Loading train:  62%|██████▏   | 152/247 [00:34<00:18,  5.01it/s]Loading train:  62%|██████▏   | 153/247 [00:34<00:18,  5.06it/s]Loading train:  62%|██████▏   | 154/247 [00:35<00:19,  4.87it/s]Loading train:  63%|██████▎   | 155/247 [00:35<00:19,  4.79it/s]Loading train:  63%|██████▎   | 156/247 [00:35<00:19,  4.71it/s]Loading train:  64%|██████▎   | 157/247 [00:35<00:19,  4.67it/s]Loading train:  64%|██████▍   | 158/247 [00:35<00:19,  4.64it/s]Loading train:  64%|██████▍   | 159/247 [00:36<00:19,  4.62it/s]Loading train:  65%|██████▍   | 160/247 [00:36<00:19,  4.56it/s]Loading train:  65%|██████▌   | 161/247 [00:36<00:18,  4.57it/s]Loading train:  66%|██████▌   | 162/247 [00:36<00:18,  4.57it/s]Loading train:  66%|██████▌   | 163/247 [00:37<00:18,  4.57it/s]Loading train:  66%|██████▋   | 164/247 [00:37<00:18,  4.55it/s]Loading train:  67%|██████▋   | 165/247 [00:37<00:18,  4.54it/s]Loading train:  67%|██████▋   | 166/247 [00:37<00:18,  4.47it/s]Loading train:  68%|██████▊   | 167/247 [00:37<00:18,  4.44it/s]Loading train:  68%|██████▊   | 168/247 [00:38<00:18,  4.29it/s]Loading train:  68%|██████▊   | 169/247 [00:38<00:18,  4.24it/s]Loading train:  69%|██████▉   | 170/247 [00:38<00:17,  4.32it/s]Loading train:  69%|██████▉   | 171/247 [00:38<00:17,  4.38it/s]Loading train:  70%|██████▉   | 172/247 [00:39<00:17,  4.19it/s]Loading train:  70%|███████   | 173/247 [00:39<00:17,  4.20it/s]Loading train:  70%|███████   | 174/247 [00:39<00:17,  4.08it/s]Loading train:  71%|███████   | 175/247 [00:39<00:17,  4.00it/s]Loading train:  71%|███████▏  | 176/247 [00:40<00:17,  4.14it/s]Loading train:  72%|███████▏  | 177/247 [00:40<00:16,  4.24it/s]Loading train:  72%|███████▏  | 178/247 [00:40<00:16,  4.31it/s]Loading train:  72%|███████▏  | 179/247 [00:40<00:15,  4.38it/s]Loading train:  73%|███████▎  | 180/247 [00:41<00:15,  4.38it/s]Loading train:  73%|███████▎  | 181/247 [00:41<00:15,  4.40it/s]Loading train:  74%|███████▎  | 182/247 [00:41<00:14,  4.42it/s]Loading train:  74%|███████▍  | 183/247 [00:41<00:14,  4.44it/s]Loading train:  74%|███████▍  | 184/247 [00:41<00:14,  4.43it/s]Loading train:  75%|███████▍  | 185/247 [00:42<00:14,  4.38it/s]Loading train:  75%|███████▌  | 186/247 [00:42<00:13,  4.41it/s]Loading train:  76%|███████▌  | 187/247 [00:42<00:13,  4.47it/s]Loading train:  76%|███████▌  | 188/247 [00:42<00:13,  4.50it/s]Loading train:  77%|███████▋  | 189/247 [00:43<00:12,  4.53it/s]Loading train:  77%|███████▋  | 190/247 [00:43<00:12,  4.57it/s]Loading train:  77%|███████▋  | 191/247 [00:43<00:12,  4.60it/s]Loading train:  78%|███████▊  | 192/247 [00:43<00:11,  4.61it/s]Loading train:  78%|███████▊  | 193/247 [00:43<00:11,  4.60it/s]Loading train:  79%|███████▊  | 194/247 [00:44<00:11,  4.65it/s]Loading train:  79%|███████▉  | 195/247 [00:44<00:11,  4.69it/s]Loading train:  79%|███████▉  | 196/247 [00:44<00:10,  4.73it/s]Loading train:  80%|███████▉  | 197/247 [00:44<00:10,  4.77it/s]Loading train:  80%|████████  | 198/247 [00:44<00:10,  4.81it/s]Loading train:  81%|████████  | 199/247 [00:45<00:09,  4.84it/s]Loading train:  81%|████████  | 200/247 [00:45<00:09,  4.87it/s]Loading train:  81%|████████▏ | 201/247 [00:45<00:09,  4.86it/s]Loading train:  82%|████████▏ | 202/247 [00:45<00:09,  4.90it/s]Loading train:  82%|████████▏ | 203/247 [00:45<00:08,  4.90it/s]Loading train:  83%|████████▎ | 204/247 [00:46<00:08,  4.89it/s]Loading train:  83%|████████▎ | 205/247 [00:46<00:08,  4.85it/s]Loading train:  83%|████████▎ | 206/247 [00:46<00:08,  4.86it/s]Loading train:  84%|████████▍ | 207/247 [00:46<00:08,  4.88it/s]Loading train:  84%|████████▍ | 208/247 [00:46<00:07,  4.89it/s]Loading train:  85%|████████▍ | 209/247 [00:47<00:07,  4.88it/s]Loading train:  85%|████████▌ | 210/247 [00:47<00:07,  4.87it/s]Loading train:  85%|████████▌ | 211/247 [00:47<00:07,  4.84it/s]Loading train:  86%|████████▌ | 212/247 [00:47<00:07,  4.79it/s]Loading train:  86%|████████▌ | 213/247 [00:48<00:07,  4.76it/s]Loading train:  87%|████████▋ | 214/247 [00:48<00:06,  4.72it/s]Loading train:  87%|████████▋ | 215/247 [00:48<00:06,  4.68it/s]Loading train:  87%|████████▋ | 216/247 [00:48<00:06,  4.65it/s]Loading train:  88%|████████▊ | 217/247 [00:48<00:06,  4.65it/s]Loading train:  88%|████████▊ | 218/247 [00:49<00:06,  4.62it/s]Loading train:  89%|████████▊ | 219/247 [00:49<00:06,  4.56it/s]Loading train:  89%|████████▉ | 220/247 [00:49<00:05,  4.54it/s]Loading train:  89%|████████▉ | 221/247 [00:49<00:05,  4.53it/s]Loading train:  90%|████████▉ | 222/247 [00:50<00:05,  4.52it/s]Loading train:  90%|█████████ | 223/247 [00:50<00:05,  4.56it/s]Loading train:  91%|█████████ | 224/247 [00:50<00:05,  4.56it/s]Loading train:  91%|█████████ | 225/247 [00:50<00:04,  4.55it/s]Loading train:  91%|█████████▏| 226/247 [00:50<00:04,  4.55it/s]Loading train:  92%|█████████▏| 227/247 [00:51<00:04,  4.53it/s]Loading train:  92%|█████████▏| 228/247 [00:51<00:04,  4.52it/s]Loading train:  93%|█████████▎| 229/247 [00:51<00:03,  4.53it/s]Loading train:  93%|█████████▎| 230/247 [00:51<00:03,  4.41it/s]Loading train:  94%|█████████▎| 231/247 [00:52<00:03,  4.35it/s]Loading train:  94%|█████████▍| 232/247 [00:52<00:03,  4.30it/s]Loading train:  94%|█████████▍| 233/247 [00:52<00:03,  4.27it/s]Loading train:  95%|█████████▍| 234/247 [00:52<00:03,  4.25it/s]Loading train:  95%|█████████▌| 235/247 [00:52<00:02,  4.24it/s]Loading train:  96%|█████████▌| 236/247 [00:53<00:02,  4.23it/s]Loading train:  96%|█████████▌| 237/247 [00:53<00:02,  4.23it/s]Loading train:  96%|█████████▋| 238/247 [00:53<00:02,  4.22it/s]Loading train:  97%|█████████▋| 239/247 [00:53<00:01,  4.23it/s]Loading train:  97%|█████████▋| 240/247 [00:54<00:01,  4.25it/s]Loading train:  98%|█████████▊| 241/247 [00:54<00:01,  4.26it/s]Loading train:  98%|█████████▊| 242/247 [00:54<00:01,  4.27it/s]Loading train:  98%|█████████▊| 243/247 [00:54<00:00,  4.28it/s]Loading train:  99%|█████████▉| 244/247 [00:55<00:00,  4.28it/s]Loading train:  99%|█████████▉| 245/247 [00:55<00:00,  4.26it/s]Loading train: 100%|█████████▉| 246/247 [00:55<00:00,  4.22it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.20it/s]Loading train: 100%|██████████| 247/247 [00:55<00:00,  4.43it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:05, 47.28it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:05, 47.17it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 47.07it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 47.30it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 47.46it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 47.21it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 47.21it/s]concatenating: train:  16%|█▌        | 40/247 [00:00<00:04, 47.50it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:04, 47.82it/s]concatenating: train:  20%|██        | 50/247 [00:01<00:04, 47.84it/s]concatenating: train:  22%|██▏       | 55/247 [00:01<00:03, 48.03it/s]concatenating: train:  24%|██▍       | 60/247 [00:01<00:03, 48.18it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 48.34it/s]concatenating: train:  28%|██▊       | 70/247 [00:01<00:03, 48.30it/s]concatenating: train:  30%|███       | 75/247 [00:01<00:03, 48.48it/s]concatenating: train:  32%|███▏      | 80/247 [00:01<00:03, 48.47it/s]concatenating: train:  35%|███▍      | 86/247 [00:01<00:03, 49.17it/s]concatenating: train:  37%|███▋      | 91/247 [00:01<00:03, 48.89it/s]concatenating: train:  39%|███▉      | 96/247 [00:01<00:03, 49.20it/s]concatenating: train:  41%|████      | 101/247 [00:02<00:03, 48.35it/s]concatenating: train:  43%|████▎     | 106/247 [00:02<00:03, 46.09it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:03, 44.94it/s]concatenating: train:  47%|████▋     | 116/247 [00:02<00:02, 44.42it/s]concatenating: train:  49%|████▉     | 121/247 [00:02<00:02, 45.27it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 45.99it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 46.74it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:02, 47.92it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:02, 50.08it/s]concatenating: train:  60%|██████    | 149/247 [00:03<00:01, 51.47it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 52.25it/s]concatenating: train:  65%|██████▌   | 161/247 [00:03<00:01, 51.66it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:01, 50.92it/s]concatenating: train:  70%|███████   | 173/247 [00:03<00:01, 50.85it/s]concatenating: train:  72%|███████▏  | 179/247 [00:03<00:01, 50.69it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 50.80it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:01, 50.09it/s]concatenating: train:  80%|███████▉  | 197/247 [00:04<00:00, 50.60it/s]concatenating: train:  82%|████████▏ | 203/247 [00:04<00:00, 51.00it/s]concatenating: train:  85%|████████▍ | 209/247 [00:04<00:00, 50.55it/s]concatenating: train:  87%|████████▋ | 215/247 [00:04<00:00, 50.42it/s]concatenating: train:  89%|████████▉ | 221/247 [00:04<00:00, 49.98it/s]concatenating: train:  92%|█████████▏| 227/247 [00:04<00:00, 49.74it/s]concatenating: train:  94%|█████████▍| 232/247 [00:04<00:00, 48.40it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 47.64it/s]concatenating: train:  98%|█████████▊| 242/247 [00:04<00:00, 47.18it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 48.70it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.48it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.60it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.87it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.03it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.99it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.04it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 357.47it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<01:01,  4.01it/s]Loading trainS:   1%|          | 2/247 [00:00<01:00,  4.08it/s]Loading trainS:   1%|          | 3/247 [00:00<00:58,  4.16it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:59,  4.10it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:58,  4.17it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:57,  4.22it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:56,  4.24it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:55,  4.28it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:55,  4.30it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:54,  4.32it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:54,  4.31it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:54,  4.28it/s]Loading trainS:   5%|▌         | 13/247 [00:03<00:54,  4.28it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:53,  4.32it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:53,  4.36it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:52,  4.37it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:52,  4.39it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:52,  4.34it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:51,  4.39it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:51,  4.39it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:51,  4.39it/s]Loading trainS:   9%|▉         | 22/247 [00:05<00:51,  4.40it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:50,  4.41it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:50,  4.42it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:50,  4.43it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:49,  4.45it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:49,  4.47it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:48,  4.49it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:48,  4.50it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:48,  4.50it/s]Loading trainS:  13%|█▎        | 31/247 [00:07<00:47,  4.50it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:47,  4.49it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:48,  4.43it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:47,  4.46it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:47,  4.48it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:47,  4.47it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:46,  4.48it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:46,  4.50it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:46,  4.50it/s]Loading trainS:  16%|█▌        | 40/247 [00:09<00:45,  4.51it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:45,  4.51it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:45,  4.51it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:45,  4.52it/s]Loading trainS:  18%|█▊        | 44/247 [00:10<00:45,  4.48it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:45,  4.47it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:44,  4.49it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:44,  4.50it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:44,  4.52it/s]Loading trainS:  20%|█▉        | 49/247 [00:11<00:43,  4.52it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:43,  4.49it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:43,  4.46it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:43,  4.44it/s]Loading trainS:  21%|██▏       | 53/247 [00:12<00:43,  4.43it/s]Loading trainS:  22%|██▏       | 54/247 [00:12<00:43,  4.41it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:43,  4.41it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:43,  4.42it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:42,  4.44it/s]Loading trainS:  23%|██▎       | 58/247 [00:13<00:42,  4.45it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:42,  4.42it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:42,  4.39it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:42,  4.34it/s]Loading trainS:  25%|██▌       | 62/247 [00:14<00:42,  4.39it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:41,  4.43it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:41,  4.43it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:40,  4.46it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:40,  4.46it/s]Loading trainS:  27%|██▋       | 67/247 [00:15<00:40,  4.44it/s]Loading trainS:  28%|██▊       | 68/247 [00:15<00:40,  4.40it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:40,  4.40it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:40,  4.42it/s]Loading trainS:  29%|██▊       | 71/247 [00:16<00:39,  4.42it/s]Loading trainS:  29%|██▉       | 72/247 [00:16<00:39,  4.38it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:39,  4.35it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:39,  4.34it/s]Loading trainS:  30%|███       | 75/247 [00:17<00:39,  4.31it/s]Loading trainS:  31%|███       | 76/247 [00:17<00:39,  4.29it/s]Loading trainS:  31%|███       | 77/247 [00:17<00:40,  4.16it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:42,  4.00it/s]Loading trainS:  32%|███▏      | 79/247 [00:18<00:41,  4.03it/s]Loading trainS:  32%|███▏      | 80/247 [00:18<00:39,  4.28it/s]Loading trainS:  33%|███▎      | 81/247 [00:18<00:38,  4.32it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:37,  4.40it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:36,  4.48it/s]Loading trainS:  34%|███▍      | 84/247 [00:19<00:36,  4.53it/s]Loading trainS:  34%|███▍      | 85/247 [00:19<00:35,  4.58it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:34,  4.61it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:34,  4.63it/s]Loading trainS:  36%|███▌      | 88/247 [00:19<00:34,  4.64it/s]Loading trainS:  36%|███▌      | 89/247 [00:20<00:33,  4.65it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:33,  4.67it/s]Loading trainS:  37%|███▋      | 91/247 [00:20<00:33,  4.68it/s]Loading trainS:  37%|███▋      | 92/247 [00:20<00:32,  4.71it/s]Loading trainS:  38%|███▊      | 93/247 [00:21<00:32,  4.71it/s]Loading trainS:  38%|███▊      | 94/247 [00:21<00:32,  4.72it/s]Loading trainS:  38%|███▊      | 95/247 [00:21<00:32,  4.72it/s]Loading trainS:  39%|███▉      | 96/247 [00:21<00:31,  4.73it/s]Loading trainS:  39%|███▉      | 97/247 [00:21<00:31,  4.70it/s]Loading trainS:  40%|███▉      | 98/247 [00:22<00:31,  4.71it/s]Loading trainS:  40%|████      | 99/247 [00:22<00:31,  4.72it/s]Loading trainS:  40%|████      | 100/247 [00:22<00:32,  4.49it/s]Loading trainS:  41%|████      | 101/247 [00:22<00:33,  4.35it/s]Loading trainS:  41%|████▏     | 102/247 [00:23<00:34,  4.21it/s]Loading trainS:  42%|████▏     | 103/247 [00:23<00:34,  4.15it/s]Loading trainS:  42%|████▏     | 104/247 [00:23<00:34,  4.11it/s]Loading trainS:  43%|████▎     | 105/247 [00:23<00:34,  4.09it/s]Loading trainS:  43%|████▎     | 106/247 [00:24<00:34,  4.06it/s]Loading trainS:  43%|████▎     | 107/247 [00:24<00:34,  4.05it/s]Loading trainS:  44%|████▎     | 108/247 [00:24<00:34,  4.02it/s]Loading trainS:  44%|████▍     | 109/247 [00:24<00:34,  4.02it/s]Loading trainS:  45%|████▍     | 110/247 [00:25<00:34,  4.02it/s]Loading trainS:  45%|████▍     | 111/247 [00:25<00:33,  4.01it/s]Loading trainS:  45%|████▌     | 112/247 [00:25<00:33,  4.02it/s]Loading trainS:  46%|████▌     | 113/247 [00:25<00:33,  4.02it/s]Loading trainS:  46%|████▌     | 114/247 [00:26<00:33,  4.02it/s]Loading trainS:  47%|████▋     | 115/247 [00:26<00:33,  3.98it/s]Loading trainS:  47%|████▋     | 116/247 [00:26<00:33,  3.93it/s]Loading trainS:  47%|████▋     | 117/247 [00:26<00:32,  3.94it/s]Loading trainS:  48%|████▊     | 118/247 [00:27<00:31,  4.09it/s]Loading trainS:  48%|████▊     | 119/247 [00:27<00:30,  4.20it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:29,  4.25it/s]Loading trainS:  49%|████▉     | 121/247 [00:27<00:29,  4.31it/s]Loading trainS:  49%|████▉     | 122/247 [00:27<00:28,  4.33it/s]Loading trainS:  50%|████▉     | 123/247 [00:28<00:28,  4.37it/s]Loading trainS:  50%|█████     | 124/247 [00:28<00:28,  4.38it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:27,  4.42it/s]Loading trainS:  51%|█████     | 126/247 [00:28<00:27,  4.42it/s]Loading trainS:  51%|█████▏    | 127/247 [00:29<00:26,  4.47it/s]Loading trainS:  52%|█████▏    | 128/247 [00:29<00:26,  4.46it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:26,  4.48it/s]Loading trainS:  53%|█████▎    | 130/247 [00:29<00:26,  4.46it/s]Loading trainS:  53%|█████▎    | 131/247 [00:29<00:25,  4.47it/s]Loading trainS:  53%|█████▎    | 132/247 [00:30<00:25,  4.48it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:25,  4.49it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:25,  4.50it/s]Loading trainS:  55%|█████▍    | 135/247 [00:30<00:25,  4.45it/s]Loading trainS:  55%|█████▌    | 136/247 [00:31<00:23,  4.66it/s]Loading trainS:  55%|█████▌    | 137/247 [00:31<00:22,  4.82it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:22,  4.95it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:21,  5.04it/s]Loading trainS:  57%|█████▋    | 140/247 [00:31<00:20,  5.12it/s]Loading trainS:  57%|█████▋    | 141/247 [00:31<00:20,  5.17it/s]Loading trainS:  57%|█████▋    | 142/247 [00:32<00:20,  5.20it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:19,  5.23it/s]Loading trainS:  58%|█████▊    | 144/247 [00:32<00:19,  5.25it/s]Loading trainS:  59%|█████▊    | 145/247 [00:32<00:19,  5.27it/s]Loading trainS:  59%|█████▉    | 146/247 [00:32<00:19,  5.28it/s]Loading trainS:  60%|█████▉    | 147/247 [00:33<00:18,  5.30it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:18,  5.30it/s]Loading trainS:  60%|██████    | 149/247 [00:33<00:18,  5.28it/s]Loading trainS:  61%|██████    | 150/247 [00:33<00:18,  5.32it/s]Loading trainS:  61%|██████    | 151/247 [00:33<00:18,  5.33it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:17,  5.32it/s]Loading trainS:  62%|██████▏   | 153/247 [00:34<00:17,  5.32it/s]Loading trainS:  62%|██████▏   | 154/247 [00:34<00:18,  5.15it/s]Loading trainS:  63%|██████▎   | 155/247 [00:34<00:18,  5.02it/s]Loading trainS:  63%|██████▎   | 156/247 [00:34<00:18,  4.87it/s]Loading trainS:  64%|██████▎   | 157/247 [00:35<00:18,  4.78it/s]Loading trainS:  64%|██████▍   | 158/247 [00:35<00:18,  4.77it/s]Loading trainS:  64%|██████▍   | 159/247 [00:35<00:18,  4.75it/s]Loading trainS:  65%|██████▍   | 160/247 [00:35<00:18,  4.74it/s]Loading trainS:  65%|██████▌   | 161/247 [00:35<00:18,  4.74it/s]Loading trainS:  66%|██████▌   | 162/247 [00:36<00:18,  4.71it/s]Loading trainS:  66%|██████▌   | 163/247 [00:36<00:17,  4.71it/s]Loading trainS:  66%|██████▋   | 164/247 [00:36<00:17,  4.71it/s]Loading trainS:  67%|██████▋   | 165/247 [00:36<00:17,  4.74it/s]Loading trainS:  67%|██████▋   | 166/247 [00:37<00:17,  4.71it/s]Loading trainS:  68%|██████▊   | 167/247 [00:37<00:17,  4.70it/s]Loading trainS:  68%|██████▊   | 168/247 [00:37<00:16,  4.67it/s]Loading trainS:  68%|██████▊   | 169/247 [00:37<00:16,  4.67it/s]Loading trainS:  69%|██████▉   | 170/247 [00:37<00:16,  4.66it/s]Loading trainS:  69%|██████▉   | 171/247 [00:38<00:16,  4.69it/s]Loading trainS:  70%|██████▉   | 172/247 [00:38<00:16,  4.58it/s]Loading trainS:  70%|███████   | 173/247 [00:38<00:16,  4.57it/s]Loading trainS:  70%|███████   | 174/247 [00:38<00:16,  4.51it/s]Loading trainS:  71%|███████   | 175/247 [00:39<00:16,  4.29it/s]Loading trainS:  71%|███████▏  | 176/247 [00:39<00:16,  4.34it/s]Loading trainS:  72%|███████▏  | 177/247 [00:39<00:15,  4.42it/s]Loading trainS:  72%|███████▏  | 178/247 [00:39<00:15,  4.51it/s]Loading trainS:  72%|███████▏  | 179/247 [00:39<00:14,  4.58it/s]Loading trainS:  73%|███████▎  | 180/247 [00:40<00:14,  4.63it/s]Loading trainS:  73%|███████▎  | 181/247 [00:40<00:14,  4.66it/s]Loading trainS:  74%|███████▎  | 182/247 [00:40<00:13,  4.67it/s]Loading trainS:  74%|███████▍  | 183/247 [00:40<00:13,  4.68it/s]Loading trainS:  74%|███████▍  | 184/247 [00:40<00:13,  4.65it/s]Loading trainS:  75%|███████▍  | 185/247 [00:41<00:13,  4.66it/s]Loading trainS:  75%|███████▌  | 186/247 [00:41<00:13,  4.66it/s]Loading trainS:  76%|███████▌  | 187/247 [00:41<00:12,  4.66it/s]Loading trainS:  76%|███████▌  | 188/247 [00:41<00:12,  4.67it/s]Loading trainS:  77%|███████▋  | 189/247 [00:42<00:12,  4.68it/s]Loading trainS:  77%|███████▋  | 190/247 [00:42<00:12,  4.65it/s]Loading trainS:  77%|███████▋  | 191/247 [00:42<00:12,  4.60it/s]Loading trainS:  78%|███████▊  | 192/247 [00:42<00:11,  4.59it/s]Loading trainS:  78%|███████▊  | 193/247 [00:42<00:11,  4.58it/s]Loading trainS:  79%|███████▊  | 194/247 [00:43<00:11,  4.61it/s]Loading trainS:  79%|███████▉  | 195/247 [00:43<00:11,  4.69it/s]Loading trainS:  79%|███████▉  | 196/247 [00:43<00:10,  4.73it/s]Loading trainS:  80%|███████▉  | 197/247 [00:43<00:10,  4.73it/s]Loading trainS:  80%|████████  | 198/247 [00:43<00:10,  4.77it/s]Loading trainS:  81%|████████  | 199/247 [00:44<00:10,  4.79it/s]Loading trainS:  81%|████████  | 200/247 [00:44<00:09,  4.80it/s]Loading trainS:  81%|████████▏ | 201/247 [00:44<00:09,  4.82it/s]Loading trainS:  82%|████████▏ | 202/247 [00:44<00:09,  4.81it/s]Loading trainS:  82%|████████▏ | 203/247 [00:44<00:09,  4.78it/s]Loading trainS:  83%|████████▎ | 204/247 [00:45<00:09,  4.76it/s]Loading trainS:  83%|████████▎ | 205/247 [00:45<00:09,  4.64it/s]Loading trainS:  83%|████████▎ | 206/247 [00:45<00:08,  4.71it/s]Loading trainS:  84%|████████▍ | 207/247 [00:45<00:08,  4.71it/s]Loading trainS:  84%|████████▍ | 208/247 [00:46<00:08,  4.75it/s]Loading trainS:  85%|████████▍ | 209/247 [00:46<00:07,  4.79it/s]Loading trainS:  85%|████████▌ | 210/247 [00:46<00:07,  4.82it/s]Loading trainS:  85%|████████▌ | 211/247 [00:46<00:07,  4.85it/s]Loading trainS:  86%|████████▌ | 212/247 [00:46<00:07,  4.76it/s]Loading trainS:  86%|████████▌ | 213/247 [00:47<00:07,  4.70it/s]Loading trainS:  87%|████████▋ | 214/247 [00:47<00:07,  4.67it/s]Loading trainS:  87%|████████▋ | 215/247 [00:47<00:06,  4.65it/s]Loading trainS:  87%|████████▋ | 216/247 [00:47<00:06,  4.65it/s]Loading trainS:  88%|████████▊ | 217/247 [00:47<00:06,  4.65it/s]Loading trainS:  88%|████████▊ | 218/247 [00:48<00:06,  4.63it/s]Loading trainS:  89%|████████▊ | 219/247 [00:48<00:06,  4.63it/s]Loading trainS:  89%|████████▉ | 220/247 [00:48<00:05,  4.63it/s]Loading trainS:  89%|████████▉ | 221/247 [00:48<00:05,  4.63it/s]Loading trainS:  90%|████████▉ | 222/247 [00:49<00:05,  4.61it/s]Loading trainS:  90%|█████████ | 223/247 [00:49<00:05,  4.61it/s]Loading trainS:  91%|█████████ | 224/247 [00:49<00:04,  4.61it/s]Loading trainS:  91%|█████████ | 225/247 [00:49<00:04,  4.59it/s]Loading trainS:  91%|█████████▏| 226/247 [00:49<00:04,  4.61it/s]Loading trainS:  92%|█████████▏| 227/247 [00:50<00:04,  4.61it/s]Loading trainS:  92%|█████████▏| 228/247 [00:50<00:04,  4.63it/s]Loading trainS:  93%|█████████▎| 229/247 [00:50<00:03,  4.64it/s]Loading trainS:  93%|█████████▎| 230/247 [00:50<00:03,  4.51it/s]Loading trainS:  94%|█████████▎| 231/247 [00:51<00:03,  4.42it/s]Loading trainS:  94%|█████████▍| 232/247 [00:51<00:03,  4.39it/s]Loading trainS:  94%|█████████▍| 233/247 [00:51<00:03,  4.36it/s]Loading trainS:  95%|█████████▍| 234/247 [00:51<00:03,  4.32it/s]Loading trainS:  95%|█████████▌| 235/247 [00:51<00:02,  4.31it/s]Loading trainS:  96%|█████████▌| 236/247 [00:52<00:02,  4.30it/s]Loading trainS:  96%|█████████▌| 237/247 [00:52<00:02,  4.30it/s]Loading trainS:  96%|█████████▋| 238/247 [00:52<00:02,  4.29it/s]Loading trainS:  97%|█████████▋| 239/247 [00:52<00:01,  4.30it/s]Loading trainS:  97%|█████████▋| 240/247 [00:53<00:01,  4.30it/s]Loading trainS:  98%|█████████▊| 241/247 [00:53<00:02,  2.92it/s]Loading trainS:  98%|█████████▊| 242/247 [00:54<00:01,  2.67it/s]Loading trainS:  98%|█████████▊| 243/247 [00:54<00:01,  2.12it/s]Loading trainS:  99%|█████████▉| 244/247 [00:55<00:01,  1.86it/s]Loading trainS:  99%|█████████▉| 245/247 [00:56<00:01,  1.74it/s]Loading trainS: 100%|█████████▉| 246/247 [00:56<00:00,  1.64it/s]Loading trainS: 100%|██████████| 247/247 [00:57<00:00,  1.60it/s]Loading trainS: 100%|██████████| 247/247 [00:57<00:00,  4.29it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.56it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.48it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.72it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.65it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  1.69it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]
Epoch 00056: val_mDice did not improve from 0.22888
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [0.7440990576232646, 0.728881863013427, 0.7180070002748387, 0.6136273737961562, 0.6252341879655134, 0.6360479619600795, 0.38898854700360763, 0.5903778455986961, 0.28738702407065625, 0.17761572532955122, 0.03029519954677201, 0.07043305647556526, -0.030303914123435124, 0.05253483381486654, 0.04837724465982583, -0.08412706475170206, -0.0810657936010263, -0.1275154578055869, -0.11311185352756915, -0.1620220199050323, -0.1663446364665774, -0.1645212465205321, -0.1607644584423595, -0.1701949039262599, -0.1652622579344275, -0.15344263679033573, -0.09056300698112614, -0.17546844179521695, -0.22010706315163747, -0.1866678214905202, -0.1967578700770057, -0.21990912593901157, -0.21693532940952184, -0.19227294641479334, -0.21675995981015195, -0.21461845840377386, -0.2158405367367275, -0.22159612077737834, -0.20461679729471446, -0.19684609865376063, -0.19986924056730554, -0.2069370270433486, -0.1975590047141543, -0.1934834905673841, -0.2010994734219055, -0.21341101927477102, -0.20476320159125028, -0.208269853585573, -0.21530550899357193, -0.20773516740497167, -0.20823037874670436, -0.20302301154571822, -0.19968451421461084, -0.20764204740747574, -0.2045456907162531, -0.21007930110164622], 'val_acc': [0.9297462649149849, 0.9306031600910031, 0.9387726999983803, 0.9344895074044116, 0.9396270639512817, 0.9423531880514103, 0.9397875707984347, 0.9343125731787095, 0.9426400922826412, 0.9454584792961458, 0.9429156052577383, 0.9437408996305255, 0.9459172553068456, 0.9401705259404348, 0.9374924157320137, 0.9491956877031537, 0.941843863165341, 0.9420309104377915, 0.9368781887394396, 0.9446609853193964, 0.9473757390344181, 0.9431961808670959, 0.9421004211112904, 0.9461750752918352, 0.9422457613027434, 0.9422558784860918, 0.9155468989621953, 0.9401136403580194, 0.9415557036640516, 0.944056865356698, 0.9431279348650189, 0.9446079063490739, 0.942259664415185, 0.9424429278268422, 0.9445320704381924, 0.942340553370936, 0.9450401434386942, 0.9446761482145508, 0.9416997803122463, 0.9423696188144504, 0.9404675187748689, 0.9447911614875312, 0.9405496759745601, 0.9425212851834222, 0.944147857957834, 0.9457087168934217, 0.9449188024839769, 0.9447279658979422, 0.943490656768486, 0.9426426154205851, 0.946480930603641, 0.9435525848662439, 0.9438179930677926, 0.9439039335641951, 0.9464594432232132, 0.9474679951788123], 'val_mDice': [0.19598790133601107, 0.2088697650807701, 0.20157735909949343, 0.2158563135644239, 0.2151688506315559, 0.20071419832599277, 0.21418694778101677, 0.20756661464175216, 0.2183519827689658, 0.2228070858760211, 0.20987971585349705, 0.22014245510759414, 0.2167256561927615, 0.21908352025769862, 0.20882396858291294, 0.22887629282305294, 0.215347100061009, 0.20915742253749528, 0.21295865234986464, 0.20462966921859735, 0.22625092318287407, 0.21715432309107827, 0.21804702112727362, 0.21763112069304433, 0.1991768005165956, 0.19308946143001413, 0.17813082702739946, 0.19350455066759129, 0.1928714922150415, 0.18671305149746617, 0.2149929777257826, 0.21153844211379813, 0.19999920118494366, 0.1995148172936981, 0.2010614739889602, 0.20804872321499635, 0.19873151255988925, 0.2050457456933587, 0.20779352541131552, 0.1992314411121588, 0.19617075770388268, 0.20381184126770457, 0.20817943189986496, 0.20320663394330052, 0.19888672614558262, 0.20195056643771825, 0.20241407323804939, 0.19566486069597658, 0.1968560473587987, 0.20044920152811221, 0.20391310582213598, 0.2059523131616108, 0.2022602826192364, 0.2046939938296843, 0.2073808521126347, 0.20290263997220467], 'loss': [0.5474309603597206, 0.40449941853192206, 0.37667817859576047, 0.3615947251179073, 0.34700078154334146, 0.33930322219381476, 0.3348787548841974, 0.3290111076445424, 0.32098038119552275, 0.31923125652093676, 0.31251322063933296, 0.3113441788503449, 0.3067452823888193, 0.30273861111634576, 0.3056260880222923, 0.29930819286472954, 0.2980329056131596, 0.31682634738694926, 0.3029966791086488, 0.29288882707928676, 0.287741310327976, 0.2904022991166629, 0.27922743037376435, 0.28174200977877867, 0.31775139894256044, 0.2914859692085968, 0.29844925228855507, 0.3023795180320888, 0.33039819755238337, 0.31048671723277865, 0.2834813578141738, 0.25313201751494085, 0.2428936469238731, 0.2364906616592169, 0.23670899778757926, 0.23318148823059742, 0.23227988042739572, 0.23755475422671113, 0.2283947188919944, 0.22337344257116218, 0.23566220597631485, 0.23233113068271055, 0.2222643134765632, 0.2432237663191454, 0.23808077482753498, 0.22436203848689365, 0.2157577479282908, 0.2135472530836635, 0.22020085617953228, 0.21070809856090508, 0.21106527050054366, 0.20922019290604024, 0.20492675264328342, 0.20185985587451216, 0.2037676337919112, 0.20571759594861946], 'acc': [0.9135253389804637, 0.9405586383365805, 0.9439041482960114, 0.9459221101564704, 0.9472215310942774, 0.9481868067135015, 0.9489517220352104, 0.9497738434215977, 0.9504762934001219, 0.9507865715275797, 0.9512572244032106, 0.9515040091018598, 0.9517627028016626, 0.9524833993957255, 0.9522671030360512, 0.9528879668480321, 0.9529982458681477, 0.9498753953878063, 0.949764297205682, 0.9503851857323427, 0.9509871611183713, 0.950528417114078, 0.9499739203727358, 0.9488344891831431, 0.9462106767183965, 0.9469148203072912, 0.9456893639151852, 0.9453153872496038, 0.9449659971582707, 0.9448345208960671, 0.9466065699175543, 0.9485631690310314, 0.9492285085491105, 0.9495895767218023, 0.9496871507547338, 0.9502111842306837, 0.9500080277151411, 0.9497959915965931, 0.9501794885034313, 0.9509584177587302, 0.9502672085648397, 0.950570043648666, 0.9512712113236138, 0.9498256592043128, 0.9495957861734104, 0.9502310216766662, 0.9508204726725062, 0.9515552346149403, 0.9510491406861827, 0.9516397974590544, 0.9515778442477135, 0.951753617371536, 0.9520545535371348, 0.9523386548288001, 0.9523706320048249, 0.9522435429514535], 'mDice': [0.40982411244345895, 0.5639599943617658, 0.5940217756564884, 0.610329111475679, 0.626106280919629, 0.6344100162363031, 0.6391885069868092, 0.6455034395422944, 0.6541848213318622, 0.6560727733166318, 0.6633364958225073, 0.6645885050147877, 0.6695631921700428, 0.6738661284247716, 0.6707497561342948, 0.6775522320884186, 0.6789092720547611, 0.6460472612066827, 0.638045547453096, 0.6460257219385118, 0.6508605216610295, 0.6458257529857134, 0.6450989824698787, 0.630486682477851, 0.5750562695405858, 0.5982052849975679, 0.5751192055852125, 0.5654581029739594, 0.5293789077899769, 0.5565728558118007, 0.59532101756941, 0.6233680000655526, 0.6292655722235558, 0.6352290369097285, 0.630435968112017, 0.6364308280280777, 0.6356400531743431, 0.6311307793568927, 0.6375671663662142, 0.64772445150543, 0.6385199693842064, 0.6435896464622377, 0.6515782219657571, 0.625692704612899, 0.6278403920159255, 0.636171878139696, 0.649155279750224, 0.6566903061124824, 0.6477983781868517, 0.654297089499977, 0.6531664651868269, 0.6572922766227739, 0.6627503724179455, 0.6600254746755901, 0.6658949467734405, 0.6625689291536339], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________2020-01-21 20:50:05.048517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 20:50:05.048610: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 20:50:05.048623: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 20:50:05.048630: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 20:50:05.048941: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97300229 0.02699771]
Train on 15751 samples, validate on 333 samples
Epoch 1/300
 - 44s - loss: 0.1351 - acc: 0.9770 - mDice: 0.7418 - val_loss: 0.3074 - val_acc: 0.9897 - val_mDice: 0.3906

Epoch 00001: val_mDice improved from -inf to 0.39063, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 40s - loss: 0.0811 - acc: 0.9916 - mDice: 0.8425 - val_loss: 0.3016 - val_acc: 0.9888 - val_mDice: 0.4024

Epoch 00002: val_mDice improved from 0.39063 to 0.40241, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 40s - loss: 0.0733 - acc: 0.9924 - mDice: 0.8574 - val_loss: 0.2845 - val_acc: 0.9906 - val_mDice: 0.4309

Epoch 00003: val_mDice improved from 0.40241 to 0.43086, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 40s - loss: 0.0695 - acc: 0.9927 - mDice: 0.8647 - val_loss: 0.2743 - val_acc: 0.9913 - val_mDice: 0.4414

Epoch 00004: val_mDice improved from 0.43086 to 0.44142, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 40s - loss: 0.0642 - acc: 0.9932 - mDice: 0.8751 - val_loss: 0.2290 - val_acc: 0.9887 - val_mDice: 0.4355

Epoch 00005: val_mDice did not improve from 0.44142
Epoch 6/300
 - 40s - loss: 0.0607 - acc: 0.9934 - mDice: 0.8820 - val_loss: 0.2427 - val_acc: 0.9913 - val_mDice: 0.4352

Epoch 00006: val_mDice did not improve from 0.44142
Epoch 7/300
 - 40s - loss: 0.0586 - acc: 0.9937 - mDice: 0.8861 - val_loss: 0.2626 - val_acc: 0.9919 - val_mDice: 0.4104

Epoch 00007: val_mDice did not improve from 0.44142
Epoch 8/300
 - 40s - loss: 0.0575 - acc: 0.9938 - mDice: 0.8882 - val_loss: 0.1131 - val_acc: 0.9874 - val_mDice: 0.3388

Epoch 00008: val_mDice did not improve from 0.44142
Epoch 9/300
 - 40s - loss: 0.0550 - acc: 0.9941 - mDice: 0.8931 - val_loss: 0.1993 - val_acc: 0.9908 - val_mDice: 0.4447

Epoch 00009: val_mDice improved from 0.44142 to 0.44474, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 40s - loss: 0.0563 - acc: 0.9940 - mDice: 0.8905 - val_loss: 0.1983 - val_acc: 0.9915 - val_mDice: 0.4353

Epoch 00010: val_mDice did not improve from 0.44474
Epoch 11/300
 - 40s - loss: 0.0552 - acc: 0.9941 - mDice: 0.8926 - val_loss: 0.1961 - val_acc: 0.9913 - val_mDice: 0.4473

Epoch 00011: val_mDice improved from 0.44474 to 0.44727, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 12/300
 - 40s - loss: 0.0507 - acc: 0.9944 - mDice: 0.9014 - val_loss: 0.0522 - val_acc: 0.9922 - val_mDice: 0.4240

Epoch 00012: val_mDice did not improve from 0.44727
Epoch 13/300
 - 40s - loss: 0.0510 - acc: 0.9944 - mDice: 0.9009 - val_loss: 0.1610 - val_acc: 0.9917 - val_mDice: 0.4651

Epoch 00013: val_mDice improved from 0.44727 to 0.46509, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 14/300
 - 41s - loss: 0.0493 - acc: 0.9945 - mDice: 0.9042 - val_loss: 0.0949 - val_acc: 0.9903 - val_mDice: 0.4618

Epoch 00014: val_mDice did not improve from 0.46509
Epoch 15/300
 - 40s - loss: 0.0492 - acc: 0.9946 - mDice: 0.9044 - val_loss: 0.1305 - val_acc: 0.9920 - val_mDice: 0.4431

Epoch 00015: val_mDice did not improve from 0.46509
Epoch 16/300
 - 41s - loss: 0.0472 - acc: 0.9947 - mDice: 0.9082 - val_loss: 0.1487 - val_acc: 0.9907 - val_mDice: 0.4145

Epoch 00016: val_mDice did not improve from 0.46509
Epoch 17/300
 - 40s - loss: 0.0479 - acc: 0.9948 - mDice: 0.9069 - val_loss: 0.1078 - val_acc: 0.9913 - val_mDice: 0.4751

Epoch 00017: val_mDice improved from 0.46509 to 0.47508, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 18/300
 - 40s - loss: 0.0458 - acc: 0.9949 - mDice: 0.9111 - val_loss: 0.1503 - val_acc: 0.9882 - val_mDice: 0.3722

Epoch 00018: val_mDice did not improve from 0.47508
Epoch 19/300
 - 40s - loss: 0.0454 - acc: 0.9949 - mDice: 0.9117 - val_loss: 0.0764 - val_acc: 0.9926 - val_mDice: 0.4770

Epoch 00019: val_mDice improved from 0.47508 to 0.47698, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 40s - loss: 0.0451 - acc: 0.9949 - mDice: 0.9123 - val_loss: 0.1267 - val_acc: 0.9918 - val_mDice: 0.4355

Epoch 00020: val_mDice did not improve from 0.47698
Epoch 21/300
 - 40s - loss: 0.0446 - acc: 0.9950 - mDice: 0.9132 - val_loss: 0.1213 - val_acc: 0.9914 - val_mDice: 0.4472

Epoch 00021: val_mDice did not improve from 0.47698
Epoch 22/300
 - 41s - loss: 0.0449 - acc: 0.9949 - mDice: 0.9129 - val_loss: 0.1588 - val_acc: 0.9904 - val_mDice: 0.4490

Epoch 00022: val_mDice did not improve from 0.47698
Epoch 23/300
 - 40s - loss: 0.0438 - acc: 0.9951 - mDice: 0.9148 - val_loss: 0.0703 - val_acc: 0.9919 - val_mDice: 0.4863

Epoch 00023: val_mDice improved from 0.47698 to 0.48628, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/1-THALAMUS/sd2/best_model_weights.h5
Epoch 24/300
 - 41s - loss: 0.0430 - acc: 0.9951 - mDice: 0.9165 - val_loss: 0.1325 - val_acc: 0.9900 - val_mDice: 0.4222

Epoch 00024: val_mDice did not improve from 0.48628
Epoch 25/300
 - 40s - loss: 0.0435 - acc: 0.9951 - mDice: 0.9155 - val_loss: 0.1100 - val_acc: 0.9923 - val_mDice: 0.4680

Epoch 00025: val_mDice did not improve from 0.48628
Epoch 26/300
 - 41s - loss: 0.0435 - acc: 0.9951 - mDice: 0.9154 - val_loss: 0.1614 - val_acc: 0.9901 - val_mDice: 0.4313

Epoch 00026: val_mDice did not improve from 0.48628
Epoch 27/300
 - 40s - loss: 0.0419 - acc: 0.9952 - mDice: 0.9187 - val_loss: 0.2017 - val_acc: 0.9896 - val_mDice: 0.4572

Epoch 00027: val_mDice did not improve from 0.48628
Epoch 28/300
 - 41s - loss: 0.0437 - acc: 0.9952 - mDice: 0.9151 - val_loss: 0.1103 - val_acc: 0.9911 - val_mDice: 0.4298

Epoch 00028: val_mDice did not improve from 0.48628
Epoch 29/300
 - 40s - loss: 0.0426 - acc: 0.9952 - mDice: 0.9172 - val_loss: 0.1379 - val_acc: 0.9909 - val_mDice: 0.4711

Epoch 00029: val_mDice did not improve from 0.48628
Epoch 30/300
 - 40s - loss: 0.0408 - acc: 0.9953 - mDice: 0.9207 - val_loss: 0.1503 - val_acc: 0.9891 - val_mDice: 0.4477

Epoch 00030: val_mDice did not improve from 0.48628
Epoch 31/300
 - 41s - loss: 0.0432 - acc: 0.9951 - mDice: 0.9160 - val_loss: 0.1163 - val_acc: 0.9916 - val_mDice: 0.4529

Epoch 00031: val_mDice did not improve from 0.48628
Epoch 32/300
 - 40s - loss: 0.0399 - acc: 0.9954 - mDice: 0.9224 - val_loss: 0.1518 - val_acc: 0.9901 - val_mDice: 0.4735

Epoch 00032: val_mDice did not improve from 0.48628
Epoch 33/300
 - 40s - loss: 0.0408 - acc: 0.9954 - mDice: 0.9208 - val_loss: 0.1189 - val_acc: 0.9890 - val_mDice: 0.4538

Epoch 00033: val_mDice did not improve from 0.48628
Epoch 34/300
 - 41s - loss: 0.0403 - acc: 0.9954 - mDice: 0.9217 - val_loss: 0.0841 - val_acc: 0.9917 - val_mDice: 0.4580

Epoch 00034: val_mDice did not improve from 0.48628
Epoch 35/300
 - 40s - loss: 0.0401 - acc: 0.9954 - mDice: 0.9221 - val_loss: 0.0785 - val_acc: 0.9918 - val_mDice: 0.4750

Epoch 00035: val_mDice did not improve from 0.48628
Epoch 36/300
 - 42s - loss: 0.0398 - acc: 0.9954 - mDice: 0.9228 - val_loss: 0.0886 - val_acc: 0.9910 - val_mDice: 0.4522

Epoch 00036: val_mDice did not improve from 0.48628
Epoch 37/300
 - 41s - loss: 0.0396 - acc: 0.9954 - mDice: 0.9230 - val_loss: 0.0732 - val_acc: 0.9917 - val_mDice: 0.4491

Epoch 00037: val_mDice did not improve from 0.48628
Epoch 38/300
 - 41s - loss: 0.0407 - acc: 0.9954 - mDice: 0.9209 - val_loss: 0.1439 - val_acc: 0.9866 - val_mDice: 0.4692

Epoch 00038: val_mDice did not improve from 0.48628

Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 39/300
 - 41s - loss: 0.0383 - acc: 0.9956 - mDice: 0.9257 - val_loss: 0.0660 - val_acc: 0.9918 - val_mDice: 0.4530

Epoch 00039: val_mDice did not improve from 0.48628
Epoch 40/300
 - 41s - loss: 0.0372 - acc: 0.9957 - mDice: 0.9279 - val_loss: 0.0811 - val_acc: 0.9928 - val_mDice: 0.4636

Epoch 00040: val_mDice did not improve from 0.48628
Epoch 41/300
 - 40s - loss: 0.0369 - acc: 0.9957 - mDice: 0.9283 - val_loss: 0.0713 - val_acc: 0.9904 - val_mDice: 0.4802

Epoch 00041: val_mDice did not improve from 0.48628
Epoch 42/300
 - 40s - loss: 0.0365 - acc: 0.9957 - mDice: 0.9291 - val_loss: 0.0889 - val_acc: 0.9916 - val_mDice: 0.4490

Epoch 00042: val_mDice did not improve from 0.48628
Epoch 43/300
 - 41s - loss: 0.0366 - acc: 0.9957 - mDice: 0.9288 - val_loss: 0.0804 - val_acc: 0.9926 - val_mDice: 0.4708

Epoch 00043: val_mDice did not improve from 0.48628
Epoch 44/300
 - 40s - loss: 0.0352 - acc: 0.9958 - mDice: 0.9316 - val_loss: 0.1005 - val_acc: 0.9924 - val_mDice: 0.4568

Epoch 00044: val_mDice did not improve from 0.48628
Epoch 45/300
 - 41s - loss: 0.0360 - acc: 0.9958 - mDice: 0.9301 - val_loss: 0.0907 - val_acc: 0.9919 - val_mDice: 0.4670

Epoch 00045: val_mDice did not improve from 0.48628
Epoch 46/300
 - 40s - loss: 0.0352 - acc: 0.9958 - mDice: 0.9317 - val_loss: 0.0820 - val_acc: 0.9921 - val_mDice: 0.4641

Epoch 00046: val_mDice did not improve from 0.48628
Epoch 47/300
 - 40s - loss: 0.0354 - acc: 0.9958 - mDice: 0.9313 - val_loss: 0.1069 - val_acc: 0.9911 - val_mDice: 0.4354

Epoch 00047: val_mDice did not improve from 0.48628
Epoch 48/300
 - 40s - loss: 0.0353 - acc: 0.9958 - mDice: 0.9314 - val_loss: 0.1136 - val_acc: 0.9910 - val_mDice: 0.4600

Epoch 00048: val_mDice did not improve from 0.48628
Epoch 49/300
 - 40s - loss: 0.0354 - acc: 0.9958 - mDice: 0.9313 - val_loss: 0.1405 - val_acc: 0.9889 - val_mDice: 0.4673

Epoch 00049: val_mDice did not improve from 0.48628
Epoch 50/300
 - 41s - loss: 0.0352 - acc: 0.9958 - mDice: 0.9317 - val_loss: 0.1823 - val_acc: 0.9916 - val_mDice: 0.4414

Epoch 00050: val_mDice did not improve from 0.48628
Epoch 51/300
 - 40s - loss: 0.0348 - acc: 0.9958 - mDice: 0.9325 - val_loss: 0.1092 - val_acc: 0.9920 - val_mDice: 0.4683

Epoch 00051: val_mDice did not improve from 0.48628
Epoch 52/300
 - 41s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9320 - val_loss: 0.0784 - val_acc: 0.9920 - val_mDice: 0.4770

Epoch 00052: val_mDice did not improve from 0.48628
Epoch 53/300
 - 40s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9321 - val_loss: 0.1198 - val_acc: 0.9917 - val_mDice: 0.4496

Epoch 00053: val_mDice did not improve from 0.48628

Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 54/300
 - 41s - loss: 0.0338 - acc: 0.9960 - mDice: 0.9344 - val_loss: 0.0761 - val_acc: 0.9923 - val_mDice: 0.4787

Epoch 00054: val_mDice did not improve from 0.48628
Epoch 55/300
 - 40s - loss: 0.0344 - acc: 0.9960 - mDice: 0.9332 - val_loss: 0.1022 - val_acc: 0.9924 - val_mDice: 0.4811

Epoch 00055: val_mDice did not improve from 0.48628
Epoch 56/300
 - 41s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9342 - val_loss: 0.1046 - val_acc: 0.9919 - val_mDice: 0.4499

Epoch 00056: val_mDice did not improve from 0.48628
Epoch 57/300
 - 41s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9353 - val_loss: 0.0682 - val_acc: 0.9921 - val_mDice: 0.4374

Epoch 00057: val_mDice did not improve from 0.48628
Epoch 58/300
 - 40s - loss: 0.0331 - acc: 0.9960 - mDice: 0.9358 - val_loss: 0.1093 - val_acc: 0.9920 - val_mDice: 0.4722

Epoch 00058: val_mDice did not improve from 0.48628
Epoch 59/300
 - 41s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9350 - val_loss: 0.0725 - val_acc: 0.9924 - val_mDice: 0.4811

Epoch 00059: val_mDice did not improve from 0.48628
Epoch 60/300
 - 40s - loss: 0.0328 - acc: 0.9960 - mDice: 0.9363 - val_loss: 0.1099 - val_acc: 0.9922 - val_mDice: 0.4671

Epoch 00060: val_mDice did not improve from 0.48628
Epoch 61/300
 - 41s - loss: 0.0338 - acc: 0.9960 - mDice: 0.9345 - val_loss: 0.0878 - val_acc: 0.9924 - val_mDice: 0.4590

Epoch 00061: val_mDice did not improve from 0.48628
Epoch 62/300
 - 40s - loss: 0.0333 - acc: 0.9960 - mDice: 0.9353 - val_loss: 0.0752 - val_acc: 0.9919 - val_mDice: 0.4765

Epoch 00062: val_mDice did not improve from 0.48628
Epoch 63/300
 - 40s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9356 - val_loss: 0.1118 - val_acc: 0.9916 - val_mDice: 0.4635

Epoch 00063: val_mDice did not improve from 0.48628
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
{'val_loss': [0.3073991636435191, 0.3016149605269189, 0.2845171452821554, 0.2742633577492144, 0.2289789486396778, 0.24273667079550368, 0.2625922914202865, 0.11311224872643526, 0.19927206818942908, 0.1983234392361598, 0.19614297285810248, 0.05219455551098775, 0.16099798965740492, 0.09490484862893193, 0.13047883648414155, 0.14869621754050613, 0.10778963297337026, 0.1503405695383971, 0.07635835797579081, 0.12669249536754848, 0.1212729988871394, 0.1588472748572404, 0.07033313255947274, 0.13253805717011471, 0.10997867834818614, 0.16140568234004057, 0.20167607605994284, 0.1103016279928677, 0.1379312766385866, 0.1503161679248552, 0.11632028741163535, 0.15184941838632474, 0.11886204054226747, 0.08413638778634973, 0.07845206473682735, 0.08861756101026907, 0.07315844968632534, 0.14389455497443854, 0.06600916882356007, 0.08109746940501102, 0.07127802485639269, 0.08888220446961778, 0.08040794448272602, 0.10050210446208804, 0.09069779036460338, 0.08203196646393957, 0.10685351231434682, 0.11359987128246296, 0.14053786463207668, 0.18225627578235604, 0.10915008786920313, 0.0783768301611548, 0.11983446808190674, 0.07613319579187457, 0.10224909266015073, 0.10464342023517277, 0.06818446033709757, 0.10926661794787054, 0.0725246947090905, 0.1099033972343525, 0.08775279185435435, 0.07519810980146711, 0.11183676696396447], 'val_acc': [0.989735904756609, 0.9887713369306501, 0.9905832572742267, 0.9913038022525318, 0.98869511100265, 0.991306200757757, 0.9919399717548588, 0.987367157105569, 0.9907505691230476, 0.9914878982681412, 0.9912628110822614, 0.9922053269795827, 0.9916635959356038, 0.9902805086370703, 0.9920121273836932, 0.9906630755902769, 0.9913196234373717, 0.9881737600933682, 0.9925991597476306, 0.9917824901976027, 0.9914258092015356, 0.9904389531762751, 0.9918973070007187, 0.989965781793222, 0.9923136731883785, 0.990057821746345, 0.9896474536116775, 0.9910830341659866, 0.9909334640961152, 0.9891186691261269, 0.9915624434525544, 0.9901256618557034, 0.9890136808246464, 0.9916880499493252, 0.9918261143538329, 0.9910142418142553, 0.9917407830556234, 0.986633903629429, 0.9918102967488515, 0.9927834956137626, 0.9903747126146838, 0.9916005582064837, 0.992601316612404, 0.9923546607787903, 0.9919198386304013, 0.9921063313613067, 0.991126901752598, 0.9910379691166921, 0.988883046416549, 0.9915940822423758, 0.9920178766365166, 0.9920018173910834, 0.9917383845503982, 0.9922585415768552, 0.9924435934146961, 0.9919318275766688, 0.9920727701874467, 0.991995824707879, 0.9923975761230286, 0.9921935832536256, 0.9923664080846059, 0.9918606367197123, 0.9915832979185087], 'val_mDice': [0.39062860305011765, 0.40241385719212147, 0.4308582495597925, 0.4414197261688202, 0.4355466110749535, 0.43522919460557297, 0.4104400209552578, 0.3388131636281586, 0.44473629903506956, 0.4352630263157534, 0.4472745524090921, 0.4240300274829348, 0.4650906442074446, 0.46176689528449727, 0.4431197655809534, 0.41453830785937495, 0.47507624457906317, 0.3722125343284807, 0.47697835677378886, 0.43547484296578187, 0.44720012739345477, 0.448994837567076, 0.48628393236223283, 0.42219558434264437, 0.46802184692732207, 0.4312988202851098, 0.45715665204262046, 0.4298119824211877, 0.4710785239129453, 0.4476576772107332, 0.45291748038751817, 0.4734583955269331, 0.4538470712509957, 0.4580131517695235, 0.4749914345977543, 0.45223052459615126, 0.4490521764970041, 0.4691545871106112, 0.45297808609567247, 0.46356295288593563, 0.4802002800298525, 0.4489777478170254, 0.4707531239445861, 0.45676157552198027, 0.4669773659190616, 0.4640550138759175, 0.4353792110720912, 0.4599596152792464, 0.46725206479855397, 0.4414349324531383, 0.46828473887375527, 0.47699138835385757, 0.4496131037431096, 0.47870482544641235, 0.48107511467403835, 0.4498683374158391, 0.43740301043376906, 0.47216360062897744, 0.4811352643522772, 0.4671312196322467, 0.4589644657285722, 0.476495840170004, 0.4634662800365024], 'loss': [0.1350636088296002, 0.081076816643929, 0.07329547905322521, 0.06954348269235322, 0.06421921023750493, 0.06067709418340196, 0.05856360879468733, 0.0575072901845773, 0.05496903254273475, 0.056274658005984274, 0.05519410949378958, 0.05070979955646547, 0.05098319122711217, 0.04929530508752384, 0.049196811340989084, 0.04723198582358485, 0.047879459696961585, 0.04577476667261193, 0.04543467090323754, 0.04511784095607798, 0.04464630373344975, 0.04485211523326493, 0.04384281341385958, 0.043012327180575675, 0.043472054483216796, 0.043519797707185254, 0.04187107996561135, 0.04365009431588931, 0.04262768194570397, 0.04081437931303887, 0.04321947662983688, 0.03993979211357176, 0.04077882262216539, 0.040319691284612116, 0.040111824238151225, 0.03975492897760103, 0.03964715048601707, 0.0407297343269211, 0.038253356701502324, 0.03715560651152454, 0.03692589891323188, 0.036522669065725946, 0.036643473843825554, 0.035245238809417254, 0.0359911623161775, 0.03518186912529961, 0.03541039506652364, 0.03533720429961881, 0.03539000529897349, 0.03517749763395618, 0.03480364832016984, 0.035022419874807836, 0.03498562218995179, 0.03378102482765351, 0.034385589449324384, 0.03389209596499679, 0.03332748677448866, 0.03311323686279075, 0.033485307255500266, 0.03282536952149398, 0.03375608815869697, 0.03334737639621389, 0.03320328476152589], 'acc': [0.977035424045726, 0.9915891679595231, 0.9924211051379164, 0.9926945281841589, 0.9931871675247692, 0.9934171858715425, 0.993710873834777, 0.9937744074704556, 0.994068216296667, 0.9939889131057952, 0.994121905463316, 0.9944130128265963, 0.9944382295950005, 0.9945382153554218, 0.9945922115100209, 0.9947426669121273, 0.9947561658145465, 0.9948540284977089, 0.9949169787942217, 0.994937103772177, 0.9949895283485789, 0.9949417911395672, 0.9950912182092378, 0.9950881304456941, 0.9951293006653816, 0.9951440781557358, 0.9952087059534737, 0.9951615203684016, 0.9952094209745918, 0.995293716106496, 0.9951343435755564, 0.9954111351981086, 0.9953738517454258, 0.9954168008824059, 0.9953930887008318, 0.9954142513316621, 0.9954238395207754, 0.9953857554563544, 0.995607628624641, 0.9956789927424783, 0.9957181253090229, 0.9957274552769346, 0.9957428456987549, 0.9957711887915137, 0.9957795459976969, 0.9957933910846195, 0.995804681758125, 0.995813504418648, 0.9957958528461339, 0.9958144166069813, 0.9958487551073507, 0.9958789179070958, 0.9958719001498406, 0.9959504439727699, 0.995955815732112, 0.9959801247472438, 0.9959778149206218, 0.995974424218202, 0.9960030154889443, 0.9960167545241769, 0.9959952268674028, 0.9960089706593518, 0.9959950194488396], 'mDice': [0.7418441828985349, 0.8424765104918859, 0.8574364086429327, 0.8647369905066544, 0.875093890191644, 0.8820436840496035, 0.8861067850292851, 0.888179816002811, 0.8930941374778841, 0.8905257018819582, 0.8926144769815687, 0.9014282754569363, 0.9008664022373113, 0.9041897867289538, 0.9043592766885659, 0.9082083505014, 0.9069048522063781, 0.9110600954729007, 0.9117060485166067, 0.9123301357134933, 0.9132383780081033, 0.912852056324955, 0.9147942265070292, 0.9164569779117027, 0.9155143882106519, 0.9154190166012748, 0.9186704927350247, 0.9151469225066403, 0.9171569882204924, 0.9207414321638759, 0.9160156303016385, 0.9224280494522287, 0.920771093669297, 0.9216632772783168, 0.9220902385912243, 0.9227943803104444, 0.9230057148280715, 0.920859919915948, 0.9256880618255787, 0.9278508281943897, 0.9282805703040661, 0.9290847747933334, 0.9288349302638017, 0.9316147512030613, 0.9301203892205406, 0.9317269921151428, 0.9312647287788546, 0.9314131050304825, 0.9313098292268728, 0.9317249637150472, 0.9324577681961174, 0.9320044838415692, 0.9320818881982168, 0.9344410206066541, 0.9332279600597577, 0.9342025994921509, 0.9353328492102431, 0.9357611076936715, 0.9349995480250665, 0.936316419878382, 0.9344666383974873, 0.9352782877935136, 0.9355678836108541], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.52it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.95it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.40it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.83it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.36it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.58it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:31,  7.78it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:30,  7.97it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:29,  8.14it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:30,  8.08it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:30,  8.01it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:29,  8.08it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:29,  8.16it/s]predicting train subjects:   3%|▎         | 8/247 [00:00<00:29,  8.22it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:28,  8.26it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:28,  8.29it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:28,  8.30it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:28,  8.32it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:28,  8.34it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:28,  8.25it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:28,  8.14it/s]predicting train subjects:   6%|▋         | 16/247 [00:01<00:28,  8.18it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:27,  8.22it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:27,  8.22it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:27,  8.19it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:27,  8.23it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:27,  8.26it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:28,  7.92it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:27,  8.08it/s]predicting train subjects:  10%|▉         | 24/247 [00:02<00:26,  8.32it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:26,  8.53it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:25,  8.67it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:25,  8.78it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:24,  8.85it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:24,  8.86it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:24,  8.86it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:24,  8.94it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:24,  8.92it/s]predicting train subjects:  13%|█▎        | 33/247 [00:03<00:24,  8.88it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:24,  8.84it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:23,  8.88it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:23,  8.92it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:23,  8.95it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:23,  8.97it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:23,  8.97it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:23,  8.96it/s]predicting train subjects:  17%|█▋        | 41/247 [00:04<00:22,  8.98it/s]predicting train subjects:  17%|█▋        | 42/247 [00:04<00:23,  8.81it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:23,  8.71it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:23,  8.72it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:22,  8.80it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:22,  8.88it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:22,  8.93it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:22,  8.84it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:22,  8.87it/s]predicting train subjects:  20%|██        | 50/247 [00:05<00:22,  8.94it/s]predicting train subjects:  21%|██        | 51/247 [00:05<00:22,  8.88it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:21,  8.92it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:21,  8.94it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:21,  8.91it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:21,  8.95it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:21,  8.99it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:21,  8.99it/s]predicting train subjects:  23%|██▎       | 58/247 [00:06<00:21,  8.95it/s]predicting train subjects:  24%|██▍       | 59/247 [00:06<00:21,  8.72it/s]predicting train subjects:  24%|██▍       | 60/247 [00:06<00:21,  8.56it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:21,  8.50it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:22,  8.40it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:22,  8.25it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:22,  8.22it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:22,  8.26it/s]predicting train subjects:  27%|██▋       | 66/247 [00:07<00:21,  8.24it/s]predicting train subjects:  27%|██▋       | 67/247 [00:07<00:21,  8.28it/s]predicting train subjects:  28%|██▊       | 68/247 [00:07<00:21,  8.31it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:21,  8.30it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:21,  8.29it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:21,  8.28it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:21,  8.23it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:21,  8.27it/s]predicting train subjects:  30%|██▉       | 74/247 [00:08<00:20,  8.30it/s]predicting train subjects:  30%|███       | 75/247 [00:08<00:20,  8.29it/s]predicting train subjects:  31%|███       | 76/247 [00:08<00:20,  8.24it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:24,  6.93it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:26,  6.41it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:25,  6.57it/s]predicting train subjects:  32%|███▏      | 80/247 [00:09<00:26,  6.23it/s]predicting train subjects:  33%|███▎      | 81/247 [00:09<00:24,  6.77it/s]predicting train subjects:  33%|███▎      | 82/247 [00:09<00:23,  6.98it/s]predicting train subjects:  34%|███▎      | 83/247 [00:09<00:22,  7.35it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:21,  7.62it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:20,  7.86it/s]predicting train subjects:  35%|███▍      | 86/247 [00:10<00:19,  8.07it/s]predicting train subjects:  35%|███▌      | 87/247 [00:10<00:19,  8.19it/s]predicting train subjects:  36%|███▌      | 88/247 [00:10<00:19,  8.22it/s]predicting train subjects:  36%|███▌      | 89/247 [00:10<00:19,  8.28it/s]predicting train subjects:  36%|███▋      | 90/247 [00:10<00:18,  8.36it/s]predicting train subjects:  37%|███▋      | 91/247 [00:10<00:18,  8.42it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:18,  8.43it/s]predicting train subjects:  38%|███▊      | 93/247 [00:11<00:18,  8.42it/s]predicting train subjects:  38%|███▊      | 94/247 [00:11<00:18,  8.40it/s]predicting train subjects:  38%|███▊      | 95/247 [00:11<00:18,  8.36it/s]predicting train subjects:  39%|███▉      | 96/247 [00:11<00:18,  8.36it/s]predicting train subjects:  39%|███▉      | 97/247 [00:11<00:18,  8.29it/s]predicting train subjects:  40%|███▉      | 98/247 [00:11<00:18,  8.22it/s]predicting train subjects:  40%|████      | 99/247 [00:11<00:18,  8.18it/s]predicting train subjects:  40%|████      | 100/247 [00:12<00:19,  7.73it/s]predicting train subjects:  41%|████      | 101/247 [00:12<00:19,  7.49it/s]predicting train subjects:  41%|████▏     | 102/247 [00:12<00:19,  7.32it/s]predicting train subjects:  42%|████▏     | 103/247 [00:12<00:19,  7.25it/s]predicting train subjects:  42%|████▏     | 104/247 [00:12<00:19,  7.17it/s]predicting train subjects:  43%|████▎     | 105/247 [00:12<00:19,  7.12it/s]predicting train subjects:  43%|████▎     | 106/247 [00:12<00:19,  7.15it/s]predicting train subjects:  43%|████▎     | 107/247 [00:13<00:19,  7.17it/s]predicting train subjects:  44%|████▎     | 108/247 [00:13<00:19,  7.13it/s]predicting train subjects:  44%|████▍     | 109/247 [00:13<00:19,  7.12it/s]predicting train subjects:  45%|████▍     | 110/247 [00:13<00:19,  7.09it/s]predicting train subjects:  45%|████▍     | 111/247 [00:13<00:19,  7.06it/s]predicting train subjects:  45%|████▌     | 112/247 [00:13<00:19,  7.05it/s]predicting train subjects:  46%|████▌     | 113/247 [00:13<00:19,  7.05it/s]predicting train subjects:  46%|████▌     | 114/247 [00:14<00:18,  7.02it/s]predicting train subjects:  47%|████▋     | 115/247 [00:14<00:18,  7.00it/s]predicting train subjects:  47%|████▋     | 116/247 [00:14<00:18,  6.99it/s]predicting train subjects:  47%|████▋     | 117/247 [00:14<00:18,  6.99it/s]predicting train subjects:  48%|████▊     | 118/247 [00:14<00:18,  7.13it/s]predicting train subjects:  48%|████▊     | 119/247 [00:14<00:17,  7.27it/s]predicting train subjects:  49%|████▊     | 120/247 [00:14<00:17,  7.41it/s]predicting train subjects:  49%|████▉     | 121/247 [00:14<00:16,  7.49it/s]predicting train subjects:  49%|████▉     | 122/247 [00:15<00:16,  7.51it/s]predicting train subjects:  50%|████▉     | 123/247 [00:15<00:16,  7.55it/s]predicting train subjects:  50%|█████     | 124/247 [00:15<00:16,  7.62it/s]predicting train subjects:  51%|█████     | 125/247 [00:15<00:15,  7.65it/s]predicting train subjects:  51%|█████     | 126/247 [00:15<00:15,  7.61it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:15<00:15,  7.62it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:15<00:15,  7.66it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:16<00:15,  7.69it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:16<00:15,  7.71it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:16<00:14,  7.74it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:16<00:14,  7.75it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:16<00:14,  7.74it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:16<00:14,  7.74it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:16<00:14,  7.70it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:16<00:13,  8.08it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:17<00:12,  8.48it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:17<00:12,  8.77it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:17<00:12,  8.90it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:17<00:11,  8.99it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:17<00:11,  9.07it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:17<00:11,  9.18it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:17<00:11,  9.27it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:17<00:11,  9.35it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:17<00:10,  9.39it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:17<00:10,  9.40it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:18<00:10,  9.45it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:18<00:10,  9.49it/s]predicting train subjects:  60%|██████    | 149/247 [00:18<00:10,  9.52it/s]predicting train subjects:  61%|██████    | 150/247 [00:18<00:10,  9.53it/s]predicting train subjects:  61%|██████    | 151/247 [00:18<00:10,  9.49it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:18<00:10,  9.46it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:18<00:09,  9.49it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:18<00:10,  9.13it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:18<00:10,  8.92it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:19<00:10,  8.72it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:19<00:10,  8.62it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:19<00:10,  8.59it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:19<00:10,  8.53it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:19<00:10,  8.52it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:19<00:10,  8.53it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:19<00:09,  8.54it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:19<00:09,  8.55it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:20<00:09,  8.52it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:20<00:09,  8.45it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:20<00:09,  8.40it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:20<00:09,  8.38it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:20<00:09,  8.37it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:20<00:09,  8.32it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:20<00:09,  8.29it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:20<00:09,  8.24it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:20<00:09,  8.18it/s]predicting train subjects:  70%|███████   | 173/247 [00:21<00:10,  6.77it/s]predicting train subjects:  70%|███████   | 174/247 [00:21<00:10,  7.22it/s]predicting train subjects:  71%|███████   | 175/247 [00:21<00:10,  6.83it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:21<00:09,  7.24it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:21<00:09,  7.54it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:21<00:08,  7.75it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:21<00:08,  7.91it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:22<00:08,  8.04it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:22<00:08,  8.14it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:22<00:07,  8.20it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:22<00:07,  8.23it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:22<00:07,  8.25it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:22<00:07,  8.27it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:22<00:07,  8.32it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:22<00:07,  8.35it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:23<00:07,  8.28it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:23<00:06,  8.30it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:23<00:06,  8.34it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:23<00:06,  8.34it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:23<00:06,  8.34it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:23<00:06,  8.33it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:23<00:06,  8.48it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:23<00:06,  8.62it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:23<00:05,  8.69it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:24<00:05,  8.69it/s]predicting train subjects:  80%|████████  | 198/247 [00:24<00:05,  8.72it/s]predicting train subjects:  81%|████████  | 199/247 [00:24<00:05,  8.75it/s]predicting train subjects:  81%|████████  | 200/247 [00:24<00:05,  8.78it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:24<00:05,  8.77it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:24<00:05,  8.72it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:24<00:05,  8.74it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:24<00:04,  8.81it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:24<00:04,  8.87it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:25<00:04,  8.87it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:25<00:04,  8.87it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:25<00:04,  8.89it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:25<00:04,  8.93it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:25<00:04,  8.93it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:25<00:04,  8.83it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:25<00:03,  8.79it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:25<00:03,  8.77it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:26<00:03,  8.75it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:26<00:03,  8.76it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:26<00:03,  8.80it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:26<00:03,  8.76it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:26<00:03,  8.77it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:26<00:03,  8.68it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:26<00:03,  8.62it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:26<00:03,  8.56it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:26<00:02,  8.43it/s]predicting train subjects:  90%|█████████ | 223/247 [00:27<00:02,  8.45it/s]predicting train subjects:  91%|█████████ | 224/247 [00:27<00:02,  8.47it/s]predicting train subjects:  91%|█████████ | 225/247 [00:27<00:02,  8.50it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:27<00:02,  8.42it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:27<00:02,  8.43it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:27<00:02,  8.46it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:27<00:02,  8.47it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:27<00:02,  8.08it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:28<00:02,  7.87it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:28<00:01,  7.72it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:28<00:01,  7.60it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:28<00:01,  7.24it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:28<00:01,  7.27it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:28<00:01,  7.24it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:28<00:01,  7.24it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:29<00:01,  7.28it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:29<00:01,  7.28it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:29<00:00,  7.34it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:29<00:00,  7.44it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:29<00:00,  7.51it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:29<00:00,  7.54it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:29<00:00,  7.56it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:29<00:00,  7.60it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:30<00:00,  7.62it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  7.62it/s]predicting train subjects: 100%|██████████| 247/247 [00:30<00:00,  8.18it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  7.08it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  7.13it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.47it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  7.73it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.60it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.65it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:30,  7.97it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:29,  8.22it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:30,  8.10it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:30,  8.02it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:29,  8.10it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:29,  8.18it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:29,  8.14it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:29,  8.21it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:29,  8.17it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:28,  8.18it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:28,  8.18it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:28,  8.15it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:28,  8.20it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:28,  8.16it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:28,  8.18it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:27,  8.26it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:27,  8.29it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:27,  8.26it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:27,  8.25it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:27,  8.24it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:27,  8.30it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:26,  8.44it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:02<00:26,  8.52it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:25,  8.66it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:25,  8.75it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:25,  8.80it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:25,  8.73it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:24,  8.75it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:24,  8.80it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:24,  8.83it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:24,  8.83it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:03<00:24,  8.77it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:24,  8.82it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:24,  8.82it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:23,  8.81it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:24,  8.69it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:24,  8.67it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:23,  8.67it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:23,  8.69it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:04<00:23,  8.77it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:04<00:23,  8.54it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:24,  8.36it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:23,  8.50it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:23,  8.55it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:23,  8.61it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:23,  8.65it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:22,  8.74it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:05<00:22,  8.82it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:05<00:22,  8.88it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:05<00:21,  8.92it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:21,  8.93it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:21,  8.90it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:21,  8.90it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:21,  8.96it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:21,  9.00it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:06<00:21,  8.99it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:06<00:21,  8.88it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:06<00:21,  8.63it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:21,  8.56it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:21,  8.49it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:21,  8.45it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:21,  8.42it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:21,  8.40it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:07<00:21,  8.34it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:07<00:21,  8.34it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:07<00:21,  8.30it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:07<00:21,  8.25it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:21,  8.25it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:21,  8.28it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:21,  8.18it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:21,  8.15it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:08<00:21,  8.19it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:08<00:20,  8.24it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:08<00:20,  8.28it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:08<00:20,  8.25it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:20,  8.19it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:21,  7.75it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:21,  7.67it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:20,  8.06it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:09<00:20,  8.19it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:09<00:21,  7.59it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:09<00:20,  7.83it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:09<00:20,  8.00it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:19,  8.16it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:19,  8.17it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:19,  8.25it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:10<00:19,  8.32it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:10<00:18,  8.38it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:10<00:18,  8.41it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:10<00:18,  8.43it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:10<00:18,  8.46it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:18,  8.41it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:18,  8.42it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:11<00:18,  8.33it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:11<00:19,  7.70it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:11<00:20,  7.35it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:11<00:20,  7.36it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:11<00:19,  7.61it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:11<00:19,  7.46it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:19,  7.42it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:12<00:19,  7.38it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:12<00:19,  7.36it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:12<00:19,  7.32it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:12<00:19,  7.31it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:12<00:19,  7.32it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:12<00:19,  7.26it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:19,  7.19it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:13<00:19,  7.16it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:13<00:19,  7.16it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:13<00:18,  7.17it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:13<00:18,  7.12it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:13<00:18,  7.13it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:13<00:18,  7.15it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:18,  7.12it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:18,  6.90it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:14<00:18,  6.88it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:14<00:18,  7.14it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:14<00:17,  7.34it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:14<00:17,  7.46it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:14<00:16,  7.54it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:15<00:16,  7.62it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:16,  7.71it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:15,  7.72it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:15<00:15,  7.75it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:15<00:15,  7.78it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:15<00:15,  7.80it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:15<00:15,  7.83it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:15<00:15,  7.85it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:14,  7.88it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:14,  7.89it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:14,  7.89it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:14,  7.88it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:16<00:14,  7.82it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:16<00:15,  7.24it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:16<00:14,  7.51it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:16<00:13,  8.01it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.44it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.77it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:11,  9.01it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:11,  9.26it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:17<00:11,  9.45it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:17<00:10,  9.58it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:17<00:10,  9.66it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:17<00:10,  9.72it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:17<00:10,  9.76it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:17<00:10,  9.79it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:10,  9.78it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:10,  9.73it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:09,  9.79it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:18<00:09,  9.82it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:18<00:09,  9.84it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:18<00:09,  9.72it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:18<00:10,  9.28it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:18<00:10,  9.10it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:18<00:10,  9.04it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:09,  9.02it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:09,  8.95it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:19<00:09,  8.95it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:19<00:09,  8.91it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:19<00:09,  8.91it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:19<00:09,  8.92it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:19<00:09,  8.86it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:19<00:09,  8.76it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:19<00:09,  8.76it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:20<00:09,  8.78it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:20<00:09,  8.83it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:20<00:09,  8.77it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:20<00:08,  8.76it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:20<00:08,  8.79it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:20<00:08,  8.83it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:20<00:08,  8.80it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:20<00:08,  8.95it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:20<00:08,  8.92it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:21<00:08,  8.48it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:21<00:08,  8.53it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:21<00:08,  8.61it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:21<00:07,  8.65it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:21<00:07,  8.63it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:21<00:07,  8.66it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:21<00:07,  8.68it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:21<00:07,  8.68it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:22<00:07,  8.56it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:22<00:07,  8.58it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:22<00:07,  8.60it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:22<00:07,  8.60it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:22<00:07,  8.56it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:22<00:06,  8.51it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:22<00:06,  8.51it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:22<00:06,  8.43it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:22<00:06,  8.45it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:23<00:06,  8.46it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:23<00:06,  8.41it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:23<00:06,  8.59it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:23<00:05,  8.76it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:23<00:05,  8.85it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:23<00:05,  8.66it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:23<00:05,  8.75it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:23<00:05,  8.75it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:23<00:05,  8.63it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:24<00:05,  7.96it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:24<00:05,  8.18it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:24<00:05,  8.34it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:24<00:05,  8.52it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:24<00:04,  8.68it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:24<00:04,  8.76it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:24<00:04,  8.78it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:24<00:04,  8.87it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:25<00:04,  8.94it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:25<00:04,  8.98it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:25<00:04,  8.89it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:25<00:04,  8.66it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:25<00:03,  8.68it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:25<00:03,  8.70it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:25<00:03,  8.73it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:25<00:03,  8.71it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:25<00:03,  8.75it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:26<00:03,  8.73it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:26<00:03,  8.73it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:26<00:03,  8.71it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:26<00:03,  8.66it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:26<00:03,  7.61it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:26<00:03,  7.90it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:26<00:02,  8.13it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:26<00:02,  8.17it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:27<00:02,  8.27it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:27<00:02,  8.28it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:27<00:02,  8.27it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:27<00:02,  8.20it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:27<00:02,  7.97it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:27<00:02,  7.85it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:27<00:01,  7.79it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:27<00:01,  7.73it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:28<00:01,  7.64it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:28<00:01,  7.55it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:28<00:01,  7.58it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:28<00:01,  7.60it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:28<00:01,  7.54it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:28<00:01,  7.52it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:28<00:00,  7.56it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:29<00:00,  7.54it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:29<00:00,  7.48it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:29<00:00,  7.50it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:29<00:00,  6.82it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:29<00:00,  6.45it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:29<00:00,  6.67it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:29<00:00,  6.84it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:29<00:00,  8.26it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 69.02it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/247 [00:00<00:03, 77.60it/s]saving BB  train1-THALAMUS:   6%|▋         | 16/247 [00:00<00:02, 77.55it/s]saving BB  train1-THALAMUS:  10%|▉         | 24/247 [00:00<00:02, 77.90it/s]saving BB  train1-THALAMUS:  13%|█▎        | 33/247 [00:00<00:02, 80.22it/s]saving BB  train1-THALAMUS:  17%|█▋        | 41/247 [00:00<00:02, 79.17it/s]saving BB  train1-THALAMUS:  20%|██        | 50/247 [00:00<00:02, 80.40it/s]saving BB  train1-THALAMUS:  24%|██▍       | 59/247 [00:00<00:02, 82.07it/s]saving BB  train1-THALAMUS:  27%|██▋       | 67/247 [00:00<00:02, 79.43it/s]saving BB  train1-THALAMUS:  30%|███       | 75/247 [00:00<00:02, 76.94it/s]saving BB  train1-THALAMUS:  34%|███▎      | 83/247 [00:01<00:02, 77.65it/s]saving BB  train1-THALAMUS:  37%|███▋      | 91/247 [00:01<00:02, 77.70it/s]saving BB  train1-THALAMUS:  40%|████      | 99/247 [00:01<00:01, 77.95it/s]saving BB  train1-THALAMUS:  43%|████▎     | 107/247 [00:01<00:01, 75.75it/s]saving BB  train1-THALAMUS:  47%|████▋     | 115/247 [00:01<00:01, 74.81it/s]saving BB  train1-THALAMUS:  50%|████▉     | 123/247 [00:01<00:01, 74.97it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 131/247 [00:01<00:01, 74.86it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 140/247 [00:01<00:01, 76.39it/s]saving BB  train1-THALAMUS:  60%|██████    | 149/247 [00:01<00:01, 78.34it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 158/247 [00:02<00:01, 80.05it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 167/247 [00:02<00:00, 82.12it/s]saving BB  train1-THALAMUS:  71%|███████▏  | 176/247 [00:02<00:00, 82.36it/s]saving BB  train1-THALAMUS:  75%|███████▍  | 185/247 [00:02<00:00, 80.67it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 194/247 [00:02<00:00, 79.70it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 203/247 [00:02<00:00, 80.53it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 212/247 [00:02<00:00, 81.50it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 221/247 [00:02<00:00, 82.69it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 230/247 [00:02<00:00, 83.21it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 239/247 [00:03<00:00, 79.75it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 79.02it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 75.51it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/247 [00:00<00:03, 73.26it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 16/247 [00:00<00:03, 74.66it/s]saving BB  train1-THALAMUS Sagittal:  10%|█         | 25/247 [00:00<00:02, 77.69it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 35/247 [00:00<00:02, 80.60it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 44/247 [00:00<00:02, 82.61it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 54/247 [00:00<00:02, 85.66it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 63/247 [00:00<00:02, 85.93it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 72/247 [00:00<00:02, 84.31it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 81/247 [00:00<00:01, 84.26it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▋      | 90/247 [00:01<00:01, 84.07it/s]saving BB  train1-THALAMUS Sagittal:  40%|████      | 99/247 [00:01<00:01, 84.01it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▎     | 108/247 [00:01<00:01, 82.19it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 117/247 [00:01<00:01, 81.10it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 126/247 [00:01<00:01, 80.30it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 134/247 [00:01<00:01, 79.74it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 143/247 [00:01<00:01, 82.35it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 153/247 [00:01<00:01, 84.69it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 163/247 [00:01<00:00, 86.97it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 173/247 [00:02<00:00, 87.90it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 182/247 [00:02<00:00, 84.52it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 191/247 [00:02<00:00, 82.59it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 200/247 [00:02<00:00, 83.92it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▍ | 209/247 [00:02<00:00, 84.98it/s]saving BB  train1-THALAMUS Sagittal:  88%|████████▊ | 218/247 [00:02<00:00, 86.13it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 227/247 [00:02<00:00, 87.14it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 236/247 [00:02<00:00, 84.99it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 245/247 [00:02<00:00, 82.51it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:02<00:00, 83.84it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:40,  1.12it/s]Loading train:   1%|          | 2/247 [00:01<03:29,  1.17it/s]Loading train:   1%|          | 3/247 [00:02<03:22,  1.21it/s]Loading train:   2%|▏         | 4/247 [00:03<03:24,  1.19it/s]Loading train:   2%|▏         | 5/247 [00:03<03:05,  1.30it/s]Loading train:   2%|▏         | 6/247 [00:04<02:48,  1.43it/s]Loading train:   3%|▎         | 7/247 [00:04<02:36,  1.54it/s]Loading train:   3%|▎         | 8/247 [00:05<02:25,  1.64it/s]Loading train:   4%|▎         | 9/247 [00:05<02:17,  1.73it/s]Loading train:   4%|▍         | 10/247 [00:06<02:12,  1.79it/s]Loading train:   4%|▍         | 11/247 [00:07<02:10,  1.81it/s]Loading train:   5%|▍         | 12/247 [00:07<02:08,  1.83it/s]Loading train:   5%|▌         | 13/247 [00:08<02:06,  1.85it/s]Loading train:   6%|▌         | 14/247 [00:08<02:04,  1.87it/s]Loading train:   6%|▌         | 15/247 [00:09<02:04,  1.86it/s]Loading train:   6%|▋         | 16/247 [00:09<02:03,  1.86it/s]Loading train:   7%|▋         | 17/247 [00:10<02:02,  1.88it/s]Loading train:   7%|▋         | 18/247 [00:10<02:03,  1.86it/s]Loading train:   8%|▊         | 19/247 [00:11<02:04,  1.83it/s]Loading train:   8%|▊         | 20/247 [00:11<02:03,  1.83it/s]Loading train:   9%|▊         | 21/247 [00:12<02:04,  1.81it/s]Loading train:   9%|▉         | 22/247 [00:12<02:04,  1.81it/s]Loading train:   9%|▉         | 23/247 [00:13<02:02,  1.82it/s]Loading train:  10%|▉         | 24/247 [00:14<01:59,  1.87it/s]Loading train:  10%|█         | 25/247 [00:14<01:57,  1.89it/s]Loading train:  11%|█         | 26/247 [00:15<01:54,  1.93it/s]Loading train:  11%|█         | 27/247 [00:15<01:52,  1.96it/s]Loading train:  11%|█▏        | 28/247 [00:16<01:51,  1.97it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:50,  1.97it/s]Loading train:  12%|█▏        | 30/247 [00:17<01:50,  1.97it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:50,  1.95it/s]Loading train:  13%|█▎        | 32/247 [00:18<01:52,  1.91it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:52,  1.89it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:50,  1.94it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:48,  1.95it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:50,  1.92it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:49,  1.92it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:47,  1.95it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:45,  1.97it/s]Loading train:  16%|█▌        | 40/247 [00:22<01:44,  1.97it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:41,  2.02it/s]Loading train:  17%|█▋        | 42/247 [00:23<01:40,  2.04it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:38,  2.08it/s]Loading train:  18%|█▊        | 44/247 [00:24<01:36,  2.09it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:37,  2.08it/s]Loading train:  19%|█▊        | 46/247 [00:25<01:37,  2.06it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:35,  2.09it/s]Loading train:  19%|█▉        | 48/247 [00:26<01:34,  2.12it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:34,  2.10it/s]Loading train:  20%|██        | 50/247 [00:26<01:33,  2.11it/s]Loading train:  21%|██        | 51/247 [00:27<01:32,  2.12it/s]Loading train:  21%|██        | 52/247 [00:27<01:31,  2.12it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:32,  2.10it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:35,  2.03it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:35,  2.01it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:34,  2.01it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:34,  2.02it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:32,  2.03it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:37,  1.92it/s]Loading train:  24%|██▍       | 60/247 [00:32<01:37,  1.91it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:37,  1.90it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:38,  1.88it/s]Loading train:  26%|██▌       | 63/247 [00:33<01:38,  1.86it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:39,  1.85it/s]Loading train:  26%|██▋       | 65/247 [00:34<01:40,  1.82it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:40,  1.80it/s]Loading train:  27%|██▋       | 67/247 [00:35<01:37,  1.85it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:37,  1.83it/s]Loading train:  28%|██▊       | 69/247 [00:36<01:36,  1.84it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:37,  1.82it/s]Loading train:  29%|██▊       | 71/247 [00:38<01:37,  1.81it/s]Loading train:  29%|██▉       | 72/247 [00:38<01:35,  1.83it/s]Loading train:  30%|██▉       | 73/247 [00:39<01:35,  1.82it/s]Loading train:  30%|██▉       | 74/247 [00:39<01:36,  1.79it/s]Loading train:  30%|███       | 75/247 [00:40<01:38,  1.75it/s]Loading train:  31%|███       | 76/247 [00:40<01:36,  1.77it/s]Loading train:  31%|███       | 77/247 [00:41<01:51,  1.53it/s]Loading train:  32%|███▏      | 78/247 [00:42<02:04,  1.36it/s]Loading train:  32%|███▏      | 79/247 [00:43<02:07,  1.31it/s]Loading train:  32%|███▏      | 80/247 [00:44<02:03,  1.35it/s]Loading train:  33%|███▎      | 81/247 [00:44<02:05,  1.32it/s]Loading train:  33%|███▎      | 82/247 [00:45<01:57,  1.40it/s]Loading train:  34%|███▎      | 83/247 [00:46<01:49,  1.49it/s]Loading train:  34%|███▍      | 84/247 [00:46<01:44,  1.56it/s]Loading train:  34%|███▍      | 85/247 [00:47<01:41,  1.60it/s]Loading train:  35%|███▍      | 86/247 [00:47<01:36,  1.66it/s]Loading train:  35%|███▌      | 87/247 [00:48<01:35,  1.68it/s]Loading train:  36%|███▌      | 88/247 [00:48<01:31,  1.74it/s]Loading train:  36%|███▌      | 89/247 [00:49<01:28,  1.78it/s]Loading train:  36%|███▋      | 90/247 [00:50<01:27,  1.80it/s]Loading train:  37%|███▋      | 91/247 [00:50<01:27,  1.78it/s]Loading train:  37%|███▋      | 92/247 [00:51<01:28,  1.76it/s]Loading train:  38%|███▊      | 93/247 [00:51<01:27,  1.77it/s]Loading train:  38%|███▊      | 94/247 [00:52<01:26,  1.76it/s]Loading train:  38%|███▊      | 95/247 [00:52<01:26,  1.76it/s]Loading train:  39%|███▉      | 96/247 [00:53<01:25,  1.77it/s]Loading train:  39%|███▉      | 97/247 [00:53<01:23,  1.79it/s]Loading train:  40%|███▉      | 98/247 [00:54<01:22,  1.81it/s]Loading train:  40%|████      | 99/247 [00:55<01:23,  1.78it/s]Loading train:  40%|████      | 100/247 [00:55<01:26,  1.70it/s]Loading train:  41%|████      | 101/247 [00:56<01:28,  1.64it/s]Loading train:  41%|████▏     | 102/247 [00:57<01:28,  1.63it/s]Loading train:  42%|████▏     | 103/247 [00:57<01:28,  1.63it/s]Loading train:  42%|████▏     | 104/247 [00:58<01:27,  1.63it/s]Loading train:  43%|████▎     | 105/247 [00:58<01:28,  1.61it/s]Loading train:  43%|████▎     | 106/247 [00:59<01:27,  1.62it/s]Loading train:  43%|████▎     | 107/247 [01:00<01:26,  1.63it/s]Loading train:  44%|████▎     | 108/247 [01:00<01:25,  1.62it/s]Loading train:  44%|████▍     | 109/247 [01:01<01:25,  1.61it/s]Loading train:  45%|████▍     | 110/247 [01:02<01:25,  1.60it/s]Loading train:  45%|████▍     | 111/247 [01:02<01:24,  1.61it/s]Loading train:  45%|████▌     | 112/247 [01:03<01:23,  1.62it/s]Loading train:  46%|████▌     | 113/247 [01:03<01:23,  1.61it/s]Loading train:  46%|████▌     | 114/247 [01:04<01:23,  1.59it/s]Loading train:  47%|████▋     | 115/247 [01:05<01:22,  1.60it/s]Loading train:  47%|████▋     | 116/247 [01:05<01:20,  1.63it/s]Loading train:  47%|████▋     | 117/247 [01:06<01:20,  1.62it/s]Loading train:  48%|████▊     | 118/247 [01:06<01:17,  1.65it/s]Loading train:  48%|████▊     | 119/247 [01:07<01:16,  1.66it/s]Loading train:  49%|████▊     | 120/247 [01:08<01:15,  1.69it/s]Loading train:  49%|████▉     | 121/247 [01:08<01:14,  1.68it/s]Loading train:  49%|████▉     | 122/247 [01:09<01:14,  1.67it/s]Loading train:  50%|████▉     | 123/247 [01:09<01:14,  1.66it/s]Loading train:  50%|█████     | 124/247 [01:10<01:12,  1.69it/s]Loading train:  51%|█████     | 125/247 [01:11<01:10,  1.74it/s]Loading train:  51%|█████     | 126/247 [01:11<01:08,  1.77it/s]Loading train:  51%|█████▏    | 127/247 [01:12<01:06,  1.79it/s]Loading train:  52%|█████▏    | 128/247 [01:12<01:07,  1.77it/s]Loading train:  52%|█████▏    | 129/247 [01:13<01:06,  1.78it/s]Loading train:  53%|█████▎    | 130/247 [01:13<01:05,  1.78it/s]Loading train:  53%|█████▎    | 131/247 [01:14<01:05,  1.77it/s]Loading train:  53%|█████▎    | 132/247 [01:14<01:04,  1.77it/s]Loading train:  54%|█████▍    | 133/247 [01:15<01:07,  1.69it/s]Loading train:  54%|█████▍    | 134/247 [01:16<01:06,  1.71it/s]Loading train:  55%|█████▍    | 135/247 [01:16<01:05,  1.70it/s]Loading train:  55%|█████▌    | 136/247 [01:17<01:02,  1.78it/s]Loading train:  55%|█████▌    | 137/247 [01:17<00:58,  1.87it/s]Loading train:  56%|█████▌    | 138/247 [01:18<00:57,  1.91it/s]Loading train:  56%|█████▋    | 139/247 [01:18<00:55,  1.94it/s]Loading train:  57%|█████▋    | 140/247 [01:19<00:54,  1.97it/s]Loading train:  57%|█████▋    | 141/247 [01:19<00:53,  1.99it/s]Loading train:  57%|█████▋    | 142/247 [01:20<00:52,  1.99it/s]Loading train:  58%|█████▊    | 143/247 [01:20<00:52,  2.00it/s]Loading train:  58%|█████▊    | 144/247 [01:21<00:50,  2.02it/s]Loading train:  59%|█████▊    | 145/247 [01:21<00:50,  2.02it/s]Loading train:  59%|█████▉    | 146/247 [01:22<00:51,  1.98it/s]Loading train:  60%|█████▉    | 147/247 [01:22<00:50,  1.98it/s]Loading train:  60%|█████▉    | 148/247 [01:23<00:48,  2.03it/s]Loading train:  60%|██████    | 149/247 [01:23<00:48,  2.04it/s]Loading train:  61%|██████    | 150/247 [01:24<00:48,  2.01it/s]Loading train:  61%|██████    | 151/247 [01:24<00:47,  2.01it/s]Loading train:  62%|██████▏   | 152/247 [01:25<00:47,  2.01it/s]Loading train:  62%|██████▏   | 153/247 [01:25<00:46,  2.02it/s]Loading train:  62%|██████▏   | 154/247 [01:26<00:47,  1.96it/s]Loading train:  63%|██████▎   | 155/247 [01:26<00:46,  1.96it/s]Loading train:  63%|██████▎   | 156/247 [01:27<00:46,  1.94it/s]Loading train:  64%|██████▎   | 157/247 [01:27<00:46,  1.95it/s]Loading train:  64%|██████▍   | 158/247 [01:28<00:45,  1.94it/s]Loading train:  64%|██████▍   | 159/247 [01:28<00:44,  1.96it/s]Loading train:  65%|██████▍   | 160/247 [01:29<00:44,  1.96it/s]Loading train:  65%|██████▌   | 161/247 [01:29<00:44,  1.95it/s]Loading train:  66%|██████▌   | 162/247 [01:30<00:43,  1.96it/s]Loading train:  66%|██████▌   | 163/247 [01:30<00:42,  1.97it/s]Loading train:  66%|██████▋   | 164/247 [01:31<00:42,  1.95it/s]Loading train:  67%|██████▋   | 165/247 [01:31<00:42,  1.94it/s]Loading train:  67%|██████▋   | 166/247 [01:32<00:41,  1.95it/s]Loading train:  68%|██████▊   | 167/247 [01:32<00:40,  1.96it/s]Loading train:  68%|██████▊   | 168/247 [01:33<00:40,  1.95it/s]Loading train:  68%|██████▊   | 169/247 [01:33<00:39,  1.96it/s]Loading train:  69%|██████▉   | 170/247 [01:34<00:39,  1.97it/s]Loading train:  69%|██████▉   | 171/247 [01:34<00:38,  1.96it/s]Loading train:  70%|██████▉   | 172/247 [01:35<00:46,  1.60it/s]Loading train:  70%|███████   | 173/247 [01:36<00:48,  1.53it/s]Loading train:  70%|███████   | 174/247 [01:37<00:50,  1.46it/s]Loading train:  71%|███████   | 175/247 [01:38<00:54,  1.32it/s]Loading train:  71%|███████▏  | 176/247 [01:38<00:49,  1.42it/s]Loading train:  72%|███████▏  | 177/247 [01:39<00:46,  1.50it/s]Loading train:  72%|███████▏  | 178/247 [01:39<00:42,  1.61it/s]Loading train:  72%|███████▏  | 179/247 [01:40<00:40,  1.69it/s]Loading train:  73%|███████▎  | 180/247 [01:40<00:38,  1.75it/s]Loading train:  73%|███████▎  | 181/247 [01:41<00:38,  1.72it/s]Loading train:  74%|███████▎  | 182/247 [01:42<00:37,  1.73it/s]Loading train:  74%|███████▍  | 183/247 [01:42<00:36,  1.74it/s]Loading train:  74%|███████▍  | 184/247 [01:43<00:36,  1.72it/s]Loading train:  75%|███████▍  | 185/247 [01:43<00:36,  1.71it/s]Loading train:  75%|███████▌  | 186/247 [01:44<00:35,  1.70it/s]Loading train:  76%|███████▌  | 187/247 [01:45<00:35,  1.70it/s]Loading train:  76%|███████▌  | 188/247 [01:45<00:34,  1.71it/s]Loading train:  77%|███████▋  | 189/247 [01:46<00:33,  1.74it/s]Loading train:  77%|███████▋  | 190/247 [01:46<00:32,  1.76it/s]Loading train:  77%|███████▋  | 191/247 [01:47<00:31,  1.77it/s]Loading train:  78%|███████▊  | 192/247 [01:47<00:31,  1.75it/s]Loading train:  78%|███████▊  | 193/247 [01:48<00:31,  1.74it/s]Loading train:  79%|███████▊  | 194/247 [01:48<00:29,  1.77it/s]Loading train:  79%|███████▉  | 195/247 [01:49<00:28,  1.83it/s]Loading train:  79%|███████▉  | 196/247 [01:49<00:27,  1.89it/s]Loading train:  80%|███████▉  | 197/247 [01:50<00:26,  1.92it/s]Loading train:  80%|████████  | 198/247 [01:50<00:25,  1.94it/s]Loading train:  81%|████████  | 199/247 [01:51<00:24,  1.95it/s]Loading train:  81%|████████  | 200/247 [01:51<00:23,  1.99it/s]Loading train:  81%|████████▏ | 201/247 [01:52<00:23,  1.98it/s]Loading train:  82%|████████▏ | 202/247 [01:52<00:22,  1.97it/s]Loading train:  82%|████████▏ | 203/247 [01:53<00:22,  1.94it/s]Loading train:  83%|████████▎ | 204/247 [01:54<00:22,  1.95it/s]Loading train:  83%|████████▎ | 205/247 [01:54<00:21,  1.93it/s]Loading train:  83%|████████▎ | 206/247 [01:55<00:21,  1.93it/s]Loading train:  84%|████████▍ | 207/247 [01:55<00:20,  1.96it/s]Loading train:  84%|████████▍ | 208/247 [01:56<00:19,  1.97it/s]Loading train:  85%|████████▍ | 209/247 [01:56<00:19,  1.96it/s]Loading train:  85%|████████▌ | 210/247 [01:57<00:18,  1.98it/s]Loading train:  85%|████████▌ | 211/247 [01:57<00:18,  1.96it/s]Loading train:  86%|████████▌ | 212/247 [01:58<00:17,  1.96it/s]Loading train:  86%|████████▌ | 213/247 [01:58<00:17,  1.96it/s]Loading train:  87%|████████▋ | 214/247 [01:59<00:16,  1.97it/s]Loading train:  87%|████████▋ | 215/247 [01:59<00:16,  1.96it/s]Loading train:  87%|████████▋ | 216/247 [02:00<00:15,  1.98it/s]Loading train:  88%|████████▊ | 217/247 [02:02<00:31,  1.04s/it]Loading train:  88%|████████▊ | 218/247 [02:04<00:40,  1.39s/it]Loading train:  89%|████████▊ | 219/247 [02:09<01:09,  2.48s/it]Loading train:  89%|████████▉ | 220/247 [02:17<01:47,  3.99s/it]Loading train:  89%|████████▉ | 221/247 [02:23<01:59,  4.59s/it]Loading train:  90%|████████▉ | 222/247 [02:28<02:02,  4.88s/it]Loading train:  90%|█████████ | 223/247 [02:32<01:49,  4.55s/it]Loading train:  91%|█████████ | 224/247 [02:36<01:39,  4.33s/it]Loading train:  91%|█████████ | 225/247 [02:39<01:30,  4.10s/it]Loading train:  91%|█████████▏| 226/247 [02:43<01:20,  3.86s/it]Loading train:  92%|█████████▏| 227/247 [02:46<01:15,  3.75s/it]Loading train:  92%|█████████▏| 228/247 [02:50<01:08,  3.63s/it]Loading train:  93%|█████████▎| 229/247 [02:53<01:02,  3.50s/it]Loading train:  93%|█████████▎| 230/247 [02:58<01:06,  3.94s/it]Loading train:  94%|█████████▎| 231/247 [03:02<01:06,  4.14s/it]Loading train:  94%|█████████▍| 232/247 [03:07<01:05,  4.39s/it]Loading train:  94%|█████████▍| 233/247 [03:12<01:04,  4.60s/it]Loading train:  95%|█████████▍| 234/247 [03:17<01:01,  4.71s/it]Loading train:  95%|█████████▌| 235/247 [03:22<00:57,  4.78s/it]Loading train:  96%|█████████▌| 236/247 [03:27<00:53,  4.84s/it]Loading train:  96%|█████████▌| 237/247 [03:32<00:49,  4.91s/it]Loading train:  96%|█████████▋| 238/247 [03:37<00:43,  4.89s/it]Loading train:  97%|█████████▋| 239/247 [03:42<00:39,  4.88s/it]Loading train:  97%|█████████▋| 240/247 [03:47<00:34,  4.98s/it]Loading train:  98%|█████████▊| 241/247 [03:52<00:30,  5.05s/it]Loading train:  98%|█████████▊| 242/247 [03:57<00:25,  5.03s/it]Loading train:  98%|█████████▊| 243/247 [04:02<00:19,  4.87s/it]Loading train:  99%|█████████▉| 244/247 [04:08<00:15,  5.16s/it]Loading train:  99%|█████████▉| 245/247 [04:12<00:09,  4.95s/it]Loading train: 100%|█████████▉| 246/247 [04:18<00:05,  5.21s/it]Loading train: 100%|██████████| 247/247 [04:24<00:00,  5.43s/it]Loading train: 100%|██████████| 247/247 [04:24<00:00,  1.07s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 50.77it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:04, 50.12it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:04, 50.04it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:04, 49.89it/s]concatenating: train:  11%|█         | 26/247 [00:00<00:04, 49.54it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:04, 49.48it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 49.28it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:04, 49.24it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 51.07it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:03, 52.59it/s]concatenating: train:  24%|██▍       | 59/247 [00:01<00:03, 54.06it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 54.35it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 54.39it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 54.11it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 53.54it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:02, 52.79it/s]concatenating: train:  38%|███▊      | 95/247 [00:01<00:02, 51.88it/s]concatenating: train:  41%|████      | 101/247 [00:01<00:02, 51.36it/s]concatenating: train:  43%|████▎     | 107/247 [00:02<00:02, 50.27it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:02, 49.71it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 49.70it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 49.62it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 50.62it/s]concatenating: train:  55%|█████▍    | 135/247 [00:02<00:02, 51.17it/s]concatenating: train:  57%|█████▋    | 141/247 [00:02<00:02, 51.91it/s]concatenating: train:  60%|█████▉    | 147/247 [00:02<00:01, 51.95it/s]concatenating: train:  62%|██████▏   | 153/247 [00:02<00:01, 52.42it/s]concatenating: train:  64%|██████▍   | 159/247 [00:03<00:01, 53.40it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 53.58it/s]concatenating: train:  69%|██████▉   | 171/247 [00:03<00:01, 54.24it/s]concatenating: train:  72%|███████▏  | 177/247 [00:03<00:01, 53.03it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:01, 51.54it/s]concatenating: train:  77%|███████▋  | 189/247 [00:03<00:01, 50.05it/s]concatenating: train:  79%|███████▉  | 195/247 [00:03<00:01, 49.87it/s]concatenating: train:  81%|████████▏ | 201/247 [00:03<00:00, 50.68it/s]concatenating: train:  84%|████████▍ | 207/247 [00:04<00:00, 50.38it/s]concatenating: train:  86%|████████▌ | 213/247 [00:04<00:00, 51.21it/s]concatenating: train:  89%|████████▊ | 219/247 [00:04<00:00, 52.64it/s]concatenating: train:  91%|█████████ | 225/247 [00:04<00:00, 52.51it/s]concatenating: train:  94%|█████████▎| 231/247 [00:04<00:00, 52.15it/s]concatenating: train:  96%|█████████▌| 237/247 [00:04<00:00, 48.63it/s]concatenating: train:  98%|█████████▊| 243/247 [00:04<00:00, 49.33it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 51.30it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:16<01:06, 16.74s/it]Loading test:  40%|████      | 2/5 [00:30<00:47, 15.97s/it]Loading test:  60%|██████    | 3/5 [00:41<00:28, 14.47s/it]Loading test:  80%|████████  | 4/5 [00:49<00:12, 12.46s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.49s/it]Loading test: 100%|██████████| 5/5 [01:02<00:00, 12.44s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 49.09it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 48.89it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-21 21:41:02.483407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 21:41:02.483499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 21:41:02.483514: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 21:41:02.483522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 21:41:02.483812: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.22978091e-02 3.14230748e-02 7.86419473e-02 9.57850394e-03
 2.85410320e-02 7.22356813e-03 8.63041801e-02 1.15057218e-01
 8.99993538e-02 1.30534322e-02 2.93829656e-01 1.83800657e-01
 2.49568117e-04]
Train on 8968 samples, validate on 180 samples
Epoch 1/300
 - 23s - loss: 0.6694 - acc: 0.8713 - mDice: 0.2796 - val_loss: 0.7375 - val_acc: 0.9219 - val_mDice: 0.2043

Epoch 00001: val_mDice improved from -inf to 0.20427, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 18s - loss: 0.4610 - acc: 0.9235 - mDice: 0.5040 - val_loss: 0.6223 - val_acc: 0.9330 - val_mDice: 0.3281

Epoch 00002: val_mDice improved from 0.20427 to 0.32808, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 18s - loss: 0.4046 - acc: 0.9312 - mDice: 0.5648 - val_loss: 0.6091 - val_acc: 0.9365 - val_mDice: 0.3221

Epoch 00003: val_mDice did not improve from 0.32808
Epoch 4/300
 - 17s - loss: 0.3847 - acc: 0.9354 - mDice: 0.5860 - val_loss: 0.5518 - val_acc: 0.9194 - val_mDice: 0.2892

Epoch 00004: val_mDice did not improve from 0.32808
Epoch 5/300
 - 17s - loss: 0.3686 - acc: 0.9377 - mDice: 0.6033 - val_loss: 0.5407 - val_acc: 0.9391 - val_mDice: 0.3666

Epoch 00005: val_mDice improved from 0.32808 to 0.36659, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 18s - loss: 0.3561 - acc: 0.9396 - mDice: 0.6168 - val_loss: 0.4450 - val_acc: 0.9420 - val_mDice: 0.3686

Epoch 00006: val_mDice improved from 0.36659 to 0.36859, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_b/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 7/300
 - 17s - loss: 0.3484 - acc: 0.9410 - mDice: 0.6250 - val_loss: 0.4133 - val_acc: 0.9323 - val_mDice: 0.3520

Epoch 00007: val_mDice did not improve from 0.36859
Epoch 8/300
 - 17s - loss: 0.3410 - acc: 0.9419 - mDice: 0.6331 - val_loss: 0.2960 - val_acc: 0.9429 - val_mDice: 0.3380

Epoch 00008: val_mDice did not improve from 0.36859
Epoch 9/300
 - 18s - loss: 0.3335 - acc: 0.9429 - mDice: 0.6411 - val_loss: 0.3710 - val_acc: 0.9328 - val_mDice: 0.2537

Epoch 00009: val_mDice did not improve from 0.36859
Epoch 10/300
 - 17s - loss: 0.3285 - acc: 0.9434 - mDice: 0.6465 - val_loss: 0.4512 - val_acc: 0.9363 - val_mDice: 0.3544

Epoch 00010: val_mDice did not improve from 0.36859
Epoch 11/300
 - 17s - loss: 0.3266 - acc: 0.9441 - mDice: 0.6485 - val_loss: 0.2260 - val_acc: 0.9397 - val_mDice: 0.3573

Epoch 00011: val_mDice did not improve from 0.36859
Epoch 12/300
 - 17s - loss: 0.3192 - acc: 0.9445 - mDice: 0.6566 - val_loss: 0.2086 - val_acc: 0.9432 - val_mDice: 0.3529

Epoch 00012: val_mDice did not improve from 0.36859
Epoch 13/300
 - 18s - loss: 0.3147 - acc: 0.9453 - mDice: 0.6614 - val_loss: 0.2444 - val_acc: 0.9384 - val_mDice: 0.3586

Epoch 00013: val_mDice did not improve from 0.36859
Epoch 14/300
 - 17s - loss: 0.3125 - acc: 0.9455 - mDice: 0.6639 - val_loss: 0.1436 - val_acc: 0.9469 - val_mDice: 0.3661

Epoch 00014: val_mDice did not improve from 0.36859
Epoch 15/300
 - 17s - loss: 0.3120 - acc: 0.9459 - mDice: 0.6644 - val_loss: 0.2112 - val_acc: 0.9427 - val_mDice: 0.3595

Epoch 00015: val_mDice did not improve from 0.36859
Epoch 16/300
 - 18s - loss: 0.3064 - acc: 0.9464 - mDice: 0.6704 - val_loss: 0.1877 - val_acc: 0.9441 - val_mDice: 0.3549

Epoch 00016: val_mDice did not improve from 0.36859
Epoch 17/300
 - 18s - loss: 0.3060 - acc: 0.9465 - mDice: 0.6708 - val_loss: 0.2073 - val_acc: 0.9461 - val_mDice: 0.3479

Epoch 00017: val_mDice did not improve from 0.36859
Epoch 18/300
 - 17s - loss: 0.3037 - acc: 0.9468 - mDice: 0.6733 - val_loss: 0.1772 - val_acc: 0.9422 - val_mDice: 0.3424

Epoch 00018: val_mDice did not improve from 0.36859
Epoch 19/300
 - 17s - loss: 0.2982 - acc: 0.9474 - mDice: 0.6792 - val_loss: 0.1779 - val_acc: 0.9399 - val_mDice: 0.3561

Epoch 00019: val_mDice did not improve from 0.36859
Epoch 20/300
 - 18s - loss: 0.2993 - acc: 0.9472 - mDice: 0.6780 - val_loss: 0.3632 - val_acc: 0.9317 - val_mDice: 0.3495

Epoch 00020: val_mDice did not improve from 0.36859
Epoch 21/300
 - 18s - loss: 0.3007 - acc: 0.9472 - mDice: 0.6765 - val_loss: 0.2096 - val_acc: 0.9426 - val_mDice: 0.3584

Epoch 00021: val_mDice did not improve from 0.36859

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 22/300
 - 17s - loss: 0.2871 - acc: 0.9486 - mDice: 0.6913 - val_loss: 0.1409 - val_acc: 0.9463 - val_mDice: 0.3627

Epoch 00022: val_mDice did not improve from 0.36859
Epoch 23/300
 - 17s - loss: 0.2819 - acc: 0.9491 - mDice: 0.6969 - val_loss: 0.2027 - val_acc: 0.9437 - val_mDice: 0.3606

Epoch 00023: val_mDice did not improve from 0.36859
Epoch 24/300
 - 18s - loss: 0.2792 - acc: 0.9493 - mDice: 0.6998 - val_loss: 0.2069 - val_acc: 0.9392 - val_mDice: 0.3547

Epoch 00024: val_mDice did not improve from 0.36859
Epoch 25/300
 - 18s - loss: 0.2764 - acc: 0.9495 - mDice: 0.7028 - val_loss: 0.1469 - val_acc: 0.9444 - val_mDice: 0.3582

Epoch 00025: val_mDice did not improve from 0.36859
Epoch 26/300
 - 17s - loss: 0.2770 - acc: 0.9493 - mDice: 0.7022 - val_loss: 0.3611 - val_acc: 0.9298 - val_mDice: 0.3445

Epoch 00026: val_mDice did not improve from 0.36859
Epoch 27/300
 - 17s - loss: 0.2747 - acc: 0.9497 - mDice: 0.7046 - val_loss: 0.2369 - val_acc: 0.9376 - val_mDice: 0.3555

Epoch 00027: val_mDice did not improve from 0.36859
Epoch 28/300
 - 17s - loss: 0.2756 - acc: 0.9497 - mDice: 0.7036 - val_loss: 0.1485 - val_acc: 0.9431 - val_mDice: 0.3621

Epoch 00028: val_mDice did not improve from 0.36859
Epoch 29/300
 - 18s - loss: 0.2747 - acc: 0.9497 - mDice: 0.7046 - val_loss: 0.1961 - val_acc: 0.9410 - val_mDice: 0.3624

Epoch 00029: val_mDice did not improve from 0.36859
Epoch 30/300
 - 17s - loss: 0.2758 - acc: 0.9499 - mDice: 0.7034 - val_loss: 0.1962 - val_acc: 0.9428 - val_mDice: 0.3638

Epoch 00030: val_mDice did not improve from 0.36859
Epoch 31/300
 - 17s - loss: 0.2718 - acc: 0.9501 - mDice: 0.7078 - val_loss: 0.1773 - val_acc: 0.9390 - val_mDice: 0.3538

Epoch 00031: val_mDice did not improve from 0.36859
Epoch 32/300
 - 17s - loss: 0.2736 - acc: 0.9499 - mDice: 0.7058 - val_loss: 0.1541 - val_acc: 0.9440 - val_mDice: 0.3628

Epoch 00032: val_mDice did not improve from 0.36859
Epoch 33/300
 - 18s - loss: 0.2714 - acc: 0.9503 - mDice: 0.7082 - val_loss: 0.1487 - val_acc: 0.9434 - val_mDice: 0.3522

Epoch 00033: val_mDice did not improve from 0.36859
Epoch 34/300
 - 18s - loss: 0.2734 - acc: 0.9503 - mDice: 0.7060 - val_loss: 0.1617 - val_acc: 0.9429 - val_mDice: 0.3596

Epoch 00034: val_mDice did not improve from 0.36859
Epoch 35/300
 - 17s - loss: 0.2673 - acc: 0.9503 - mDice: 0.7126 - val_loss: 0.1365 - val_acc: 0.9457 - val_mDice: 0.3541

Epoch 00035: val_mDice did not improve from 0.36859
Epoch 36/300
 - 18s - loss: 0.2669 - acc: 0.9505 - mDice: 0.7130 - val_loss: 0.1603 - val_acc: 0.9420 - val_mDice: 0.3625

Epoch 00036: val_mDice did not improve from 0.36859

Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 37/300
 - 18s - loss: 0.2639 - acc: 0.9510 - mDice: 0.7163 - val_loss: 0.1398 - val_acc: 0.9431 - val_mDice: 0.3625

Epoch 00037: val_mDice did not improve from 0.36859
Epoch 38/300
 - 17s - loss: 0.2622 - acc: 0.9513 - mDice: 0.7181 - val_loss: 0.1348 - val_acc: 0.9440 - val_mDice: 0.3657

Epoch 00038: val_mDice did not improve from 0.36859
Epoch 39/300
 - 17s - loss: 0.2621 - acc: 0.9513 - mDice: 0.7182 - val_loss: 0.1609 - val_acc: 0.9430 - val_mDice: 0.3636

Epoch 00039: val_mDice did not improve from 0.36859
Epoch 40/300
 - 17s - loss: 0.2632 - acc: 0.9514 - mDice: 0.7170 - val_loss: 0.2143 - val_acc: 0.9432 - val_mDice: 0.3639

Epoch 00040: val_mDice did not improve from 0.36859
Epoch 41/300
 - 17s - loss: 0.2599 - acc: 0.9515 - mDice: 0.7206 - val_loss: 0.1471 - val_acc: 0.9425 - val_mDice: 0.3646

Epoch 00041: val_mDice did not improve from 0.36859
Epoch 42/300
 - 18s - loss: 0.2596 - acc: 0.9516 - mDice: 0.7209 - val_loss: 0.1438 - val_acc: 0.9450 - val_mDice: 0.3646

Epoch 00042: val_mDice did not improve from 0.36859
Epoch 43/300
 - 17s - loss: 0.2574 - acc: 0.9517 - mDice: 0.7232 - val_loss: 0.1375 - val_acc: 0.9445 - val_mDice: 0.3632

Epoch 00043: val_mDice did not improve from 0.36859
Epoch 44/300
 - 17s - loss: 0.2574 - acc: 0.9518 - mDice: 0.7233 - val_loss: 0.1724 - val_acc: 0.9435 - val_mDice: 0.3621

Epoch 00044: val_mDice did not improve from 0.36859
Epoch 45/300
 - 17s - loss: 0.2555 - acc: 0.9517 - mDice: 0.7254 - val_loss: 0.1962 - val_acc: 0.9428 - val_mDice: 0.3550

Epoch 00045: val_mDice did not improve from 0.36859
Epoch 46/300
 - 18s - loss: 0.2581 - acc: 0.9517 - mDice: 0.7225 - val_loss: 0.1471 - val_acc: 0.9433 - val_mDice: 0.3602

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.55s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.40s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.24s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.12s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.10s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.07s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_b/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_b/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_b/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  2.57it/s] 40%|████      | 2/5 [00:00<00:01,  2.69it/s] 60%|██████    | 3/5 [00:01<00:00,  2.90it/s] 80%|████████  | 4/5 [00:01<00:00,  3.15it/s]100%|██████████| 5/5 [00:01<00:00,  3.06it/s]100%|██████████| 5/5 [00:01<00:00,  3.11it/s]

Epoch 00046: val_mDice did not improve from 0.36859
Restoring model weights from the end of the best epoch
Epoch 00046: early stopping
{'val_loss': [0.7375344898965623, 0.6223274817069372, 0.6090725776222017, 0.5517754952112833, 0.5407102588150237, 0.44503044254249996, 0.41330278995964265, 0.29597942034403485, 0.3710350254421226, 0.451226853662067, 0.22598802639792362, 0.20863599899328417, 0.24436080331603685, 0.1435742664228504, 0.21116805769917038, 0.18773451633751392, 0.20725975961734852, 0.1772092789825466, 0.17785710313667855, 0.36319804729686844, 0.20958730806079176, 0.14093940725757015, 0.202741338354018, 0.2069052777046131, 0.14686599270337158, 0.3611256314648522, 0.23686275124135944, 0.1485120649643553, 0.19605563746558297, 0.19618853057424226, 0.1772934958959619, 0.15411236840817663, 0.14865150002555716, 0.16166865556604332, 0.136487342003319, 0.16031034791376442, 0.13976603226425746, 0.1347915797183911, 0.16091120950618965, 0.21428162107865015, 0.1470920036857327, 0.14378420946498713, 0.1374666341063049, 0.172403728382455, 0.19615308795538214, 0.14705821437140307], 'val_acc': [0.9219462275505066, 0.9330102735095553, 0.9364545179737939, 0.91943934890959, 0.9390860233041975, 0.9420189758141836, 0.9322891235351562, 0.9429156515333388, 0.9328156809012095, 0.9363158841927847, 0.9397117926014794, 0.9432387053966522, 0.9384004904164208, 0.9468597372372946, 0.9427006973160638, 0.9440908663802676, 0.9461322195000119, 0.9422110219796499, 0.9399280183845096, 0.9317027860217624, 0.9425811502668593, 0.9462886651357015, 0.9436711404058669, 0.939229753282335, 0.9444240993923612, 0.9297848012712266, 0.9375890294710795, 0.943086071146859, 0.9410129255718656, 0.942752844757504, 0.938974099026786, 0.9440234469042884, 0.943448566728168, 0.942888942029741, 0.9456832475132413, 0.9420355127917396, 0.9431115157074399, 0.9440234469042884, 0.9429512619972229, 0.9432437916596731, 0.9424997468789419, 0.9450333250893487, 0.9444635212421417, 0.9434511098596785, 0.9427617523405287, 0.9432577821943495], 'val_mDice': [0.2042652057069871, 0.32808476376036805, 0.3220820880184571, 0.289221817575809, 0.3665940571162436, 0.36858563125133514, 0.3520450569275353, 0.3380178641527891, 0.25372055090136, 0.35441302756468457, 0.3572528209123347, 0.35287986592286164, 0.3586153845406241, 0.36611950066354537, 0.35948546706802315, 0.354931583835019, 0.3478649701509211, 0.3424031352624297, 0.35613383259624243, 0.34954335333572495, 0.35843937740557724, 0.36272668797108865, 0.36057265951401657, 0.3546798007769717, 0.35822055116295815, 0.34450794259707135, 0.35547808795753455, 0.36211303828491104, 0.36238150505556, 0.36375845854894984, 0.3537899132611023, 0.36279801848447985, 0.3522416850965884, 0.3596301643798749, 0.35405400881750715, 0.36246255081560874, 0.36247127451416516, 0.36574559400065076, 0.3636198350124889, 0.3639076061339842, 0.3646361546383964, 0.3646052469395929, 0.36322526530259186, 0.36208610650565887, 0.3549625414113204, 0.360164162185457], 'loss': [0.6693837971598522, 0.4610289676541946, 0.4045547085891442, 0.3847209143649245, 0.36864312655765175, 0.3560837409147506, 0.34844588903738494, 0.34097461623408026, 0.33354650520246865, 0.3285409145781656, 0.3266441619869431, 0.3192193975022443, 0.3146825546662952, 0.3124537564927079, 0.31195861531170643, 0.30638558515592623, 0.3060309967785462, 0.30371447448867117, 0.29823749135584837, 0.2993339219236087, 0.3006988834559811, 0.28705010865877295, 0.28185042541184985, 0.2791866939597955, 0.2763745580749199, 0.27695789592910514, 0.27474341390656104, 0.2755918137224044, 0.27466793211108864, 0.2758132953804907, 0.2717645461808136, 0.27356774646067705, 0.27135434295453736, 0.2733798034249886, 0.26728909337073964, 0.2669092799461281, 0.26391838688692487, 0.26216917659133593, 0.262060386184387, 0.26315894592669686, 0.259898494061724, 0.25955753582700036, 0.2574228584553704, 0.2573888358775523, 0.2554786446887292, 0.2581017729390104], 'acc': [0.8712506083361173, 0.9235394446048005, 0.9312195798496813, 0.935389422631285, 0.9377325368608139, 0.9396230099086353, 0.9409805024233808, 0.9419467975314869, 0.9428781743006022, 0.9434348948559094, 0.944123111020551, 0.9444844134676998, 0.9452873534596892, 0.9455277797476082, 0.9458881116652468, 0.9463759069060982, 0.9465347180852499, 0.9467712127662578, 0.9473565255128094, 0.9472063411887898, 0.9472084615668689, 0.9486413628766837, 0.9490717704358854, 0.9492698700884216, 0.9495144818479945, 0.9493110981719182, 0.9496556282256141, 0.9496812085080211, 0.9497463043835629, 0.9498667986157959, 0.9500950463215865, 0.9498904632549006, 0.9502541654935168, 0.9503433360360117, 0.95033246080701, 0.9505279555079343, 0.9510234595807294, 0.9512786161516735, 0.951335493192728, 0.951367147180462, 0.9515044377995431, 0.9516395598809492, 0.9517148429798719, 0.9517851985665329, 0.9517456040942807, 0.951721632818257], 'mDice': [0.2796314780070321, 0.5039591968332041, 0.5648080056847259, 0.5860167310758428, 0.6033085753657688, 0.6168360644079127, 0.6250494130879614, 0.6331208267188518, 0.6411331001466454, 0.6465326013919183, 0.6485492685123494, 0.6565829634560101, 0.6614479474012177, 0.6638540663988223, 0.664387329429202, 0.6703958684889256, 0.6707646327623291, 0.6732590352247381, 0.6791774524470507, 0.6780053222025217, 0.6765405661380791, 0.6912663554196162, 0.6968847807765964, 0.6997750150463499, 0.7028026498462024, 0.7021745092814571, 0.7045517500479981, 0.7036464495399932, 0.704645357421208, 0.7034114555694183, 0.707788582030521, 0.7058442148191391, 0.7082087099685082, 0.7060167457140736, 0.7126103482216624, 0.7130265109819243, 0.7162515106914195, 0.7181360459322381, 0.7182433646268658, 0.7170486354487586, 0.7205828123532375, 0.7209346597145223, 0.7232492598011279, 0.7232928411581493, 0.7253512491560961, 0.7225131438804141], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
CrossVal ['b']
Error in label values min 0.0 max 2.0      1-THALAMUS
2020-01-21 21:54:56.002477: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-21 21:54:59.440522: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-21 21:54:59.440578: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-21 21:54:59.858972: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-21 21:54:59.859032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-21 21:54:59.859043: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-21 21:54:59.860656: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:23,  2.94it/s]Loading train:   1%|          | 2/247 [00:00<01:46,  2.31it/s]Loading train:   1%|          | 3/247 [00:01<01:55,  2.11it/s]Loading train:   2%|▏         | 4/247 [00:02<02:08,  1.89it/s]Loading train:   2%|▏         | 5/247 [00:02<02:19,  1.73it/s]Loading train:   2%|▏         | 6/247 [00:03<02:30,  1.61it/s]Loading train:   3%|▎         | 7/247 [00:04<02:40,  1.49it/s]Loading train:   3%|▎         | 8/247 [00:05<02:44,  1.46it/s]Loading train:   4%|▎         | 9/247 [00:05<02:41,  1.47it/s]Loading train:   4%|▍         | 10/247 [00:06<02:45,  1.44it/s]Loading train:   4%|▍         | 11/247 [00:07<02:45,  1.43it/s]Loading train:   5%|▍         | 12/247 [00:07<02:44,  1.43it/s]Loading train:   5%|▌         | 13/247 [00:08<02:47,  1.40it/s]Loading train:   6%|▌         | 14/247 [00:09<02:48,  1.38it/s]Loading train:   6%|▌         | 15/247 [00:10<02:46,  1.39it/s]Loading train:   6%|▋         | 16/247 [00:10<02:49,  1.37it/s]Loading train:   7%|▋         | 17/247 [00:11<02:47,  1.37it/s]Loading train:   7%|▋         | 18/247 [00:12<02:35,  1.48it/s]Loading train:   8%|▊         | 19/247 [00:12<02:38,  1.44it/s]Loading train:   8%|▊         | 20/247 [00:13<02:39,  1.42it/s]Loading train:   9%|▊         | 21/247 [00:14<02:36,  1.44it/s]Loading train:   9%|▉         | 22/247 [00:14<02:34,  1.46it/s]Loading train:   9%|▉         | 23/247 [00:15<02:32,  1.47it/s]Loading train:  10%|▉         | 24/247 [00:16<02:23,  1.56it/s]Loading train:  10%|█         | 25/247 [00:16<02:23,  1.55it/s]Loading train:  11%|█         | 26/247 [00:17<02:25,  1.52it/s]Loading train:  11%|█         | 27/247 [00:18<02:23,  1.53it/s]Loading train:  11%|█▏        | 28/247 [00:18<02:25,  1.50it/s]Loading train:  12%|█▏        | 29/247 [00:19<02:31,  1.44it/s]Loading train:  12%|█▏        | 30/247 [00:20<02:24,  1.50it/s]Loading train:  13%|█▎        | 31/247 [00:20<02:28,  1.45it/s]Loading train:  13%|█▎        | 32/247 [00:21<02:25,  1.48it/s]Loading train:  13%|█▎        | 33/247 [00:22<02:26,  1.46it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:23,  1.49it/s]Loading train:  14%|█▍        | 35/247 [00:23<02:17,  1.55it/s]Loading train:  15%|█▍        | 36/247 [00:24<02:16,  1.55it/s]Loading train:  15%|█▍        | 37/247 [00:24<02:20,  1.50it/s]Loading train:  15%|█▌        | 38/247 [00:25<02:23,  1.45it/s]Loading train:  16%|█▌        | 39/247 [00:26<02:20,  1.48it/s]Loading train:  16%|█▌        | 40/247 [00:27<02:23,  1.44it/s]Loading train:  17%|█▋        | 41/247 [00:27<02:22,  1.44it/s]Loading train:  17%|█▋        | 42/247 [00:28<02:25,  1.41it/s]Loading train:  17%|█▋        | 43/247 [00:29<02:21,  1.44it/s]Loading train:  18%|█▊        | 44/247 [00:29<02:16,  1.48it/s]Loading train:  18%|█▊        | 45/247 [00:30<02:15,  1.49it/s]Loading train:  19%|█▊        | 46/247 [00:31<02:21,  1.42it/s]Loading train:  19%|█▉        | 47/247 [00:31<02:21,  1.42it/s]Loading train:  19%|█▉        | 48/247 [00:32<02:15,  1.47it/s]Loading train:  20%|█▉        | 49/247 [00:33<02:16,  1.45it/s]Loading train:  20%|██        | 50/247 [00:33<02:15,  1.46it/s]Loading train:  21%|██        | 51/247 [00:34<02:08,  1.52it/s]Loading train:  21%|██        | 52/247 [00:35<02:12,  1.47it/s]Loading train:  21%|██▏       | 53/247 [00:35<02:08,  1.51it/s]Loading train:  22%|██▏       | 54/247 [00:36<02:05,  1.54it/s]Loading train:  22%|██▏       | 55/247 [00:37<02:08,  1.49it/s]Loading train:  23%|██▎       | 56/247 [00:37<02:10,  1.46it/s]Loading train:  23%|██▎       | 57/247 [00:38<02:09,  1.46it/s]Loading train:  23%|██▎       | 58/247 [00:39<02:11,  1.44it/s]Loading train:  24%|██▍       | 59/247 [00:40<02:08,  1.46it/s]Loading train:  24%|██▍       | 60/247 [00:40<02:12,  1.41it/s]Loading train:  25%|██▍       | 61/247 [00:41<01:59,  1.56it/s]Loading train:  25%|██▌       | 62/247 [00:41<01:48,  1.70it/s]Loading train:  26%|██▌       | 63/247 [00:42<01:41,  1.81it/s]Loading train:  26%|██▌       | 64/247 [00:42<01:46,  1.72it/s]Loading train:  26%|██▋       | 65/247 [00:43<01:47,  1.69it/s]Loading train:  27%|██▋       | 66/247 [00:44<01:51,  1.63it/s]Loading train:  27%|██▋       | 67/247 [00:44<01:53,  1.59it/s]Loading train:  28%|██▊       | 68/247 [00:45<01:51,  1.60it/s]Loading train:  28%|██▊       | 69/247 [00:46<01:53,  1.56it/s]Loading train:  28%|██▊       | 70/247 [00:46<01:57,  1.51it/s]Loading train:  29%|██▊       | 71/247 [00:47<01:56,  1.51it/s]Loading train:  29%|██▉       | 72/247 [00:48<01:56,  1.50it/s]Loading train:  30%|██▉       | 73/247 [00:48<01:54,  1.52it/s]Loading train:  30%|██▉       | 74/247 [00:49<01:52,  1.53it/s]Loading train:  30%|███       | 75/247 [00:50<01:53,  1.52it/s]Loading train:  31%|███       | 76/247 [00:50<01:55,  1.48it/s]Loading train:  31%|███       | 77/247 [00:51<02:20,  1.21it/s]Loading train:  32%|███▏      | 78/247 [00:52<02:21,  1.20it/s]Loading train:  32%|███▏      | 79/247 [00:53<02:12,  1.27it/s]Loading train:  32%|███▏      | 80/247 [00:54<02:03,  1.35it/s]Loading train:  33%|███▎      | 81/247 [00:54<01:56,  1.42it/s]Loading train:  33%|███▎      | 82/247 [00:55<02:03,  1.33it/s]Loading train:  34%|███▎      | 83/247 [00:56<02:01,  1.35it/s]Loading train:  34%|███▍      | 84/247 [00:57<02:07,  1.28it/s]Loading train:  34%|███▍      | 85/247 [00:58<02:10,  1.25it/s]Loading train:  35%|███▍      | 86/247 [00:58<02:04,  1.29it/s]Loading train:  35%|███▌      | 87/247 [00:59<02:07,  1.25it/s]Loading train:  36%|███▌      | 88/247 [01:00<02:06,  1.25it/s]Loading train:  36%|███▌      | 89/247 [01:01<02:01,  1.31it/s]Loading train:  36%|███▋      | 90/247 [01:01<02:02,  1.28it/s]Loading train:  37%|███▋      | 91/247 [01:02<01:57,  1.32it/s]Loading train:  37%|███▋      | 92/247 [01:03<01:54,  1.35it/s]Loading train:  38%|███▊      | 93/247 [01:04<01:55,  1.33it/s]Loading train:  38%|███▊      | 94/247 [01:04<02:00,  1.27it/s]Loading train:  38%|███▊      | 95/247 [01:05<02:00,  1.26it/s]Loading train:  39%|███▉      | 96/247 [01:06<01:59,  1.26it/s]Loading train:  39%|███▉      | 97/247 [01:07<01:58,  1.27it/s]Loading train:  40%|███▉      | 98/247 [01:08<01:56,  1.28it/s]Loading train:  40%|████      | 99/247 [01:08<01:57,  1.26it/s]Loading train:  40%|████      | 100/247 [01:09<01:50,  1.33it/s]Loading train:  41%|████      | 101/247 [01:10<01:49,  1.33it/s]Loading train:  41%|████▏     | 102/247 [01:11<01:49,  1.32it/s]Loading train:  42%|████▏     | 103/247 [01:11<01:47,  1.34it/s]Loading train:  42%|████▏     | 104/247 [01:12<01:48,  1.32it/s]Loading train:  43%|████▎     | 105/247 [01:13<01:53,  1.25it/s]Loading train:  43%|████▎     | 106/247 [01:14<01:47,  1.31it/s]Loading train:  43%|████▎     | 107/247 [01:14<01:45,  1.33it/s]Loading train:  44%|████▎     | 108/247 [01:15<01:45,  1.32it/s]Loading train:  44%|████▍     | 109/247 [01:16<01:43,  1.34it/s]Loading train:  45%|████▍     | 110/247 [01:17<01:40,  1.36it/s]Loading train:  45%|████▍     | 111/247 [01:17<01:39,  1.36it/s]Loading train:  45%|████▌     | 112/247 [01:18<01:36,  1.39it/s]Loading train:  46%|████▌     | 113/247 [01:19<01:36,  1.39it/s]Loading train:  46%|████▌     | 114/247 [01:19<01:36,  1.38it/s]Loading train:  47%|████▋     | 115/247 [01:20<01:34,  1.39it/s]Loading train:  47%|████▋     | 116/247 [01:21<01:40,  1.30it/s]Loading train:  47%|████▋     | 117/247 [01:22<01:39,  1.31it/s]Loading train:  48%|████▊     | 118/247 [01:22<01:28,  1.46it/s]Loading train:  48%|████▊     | 119/247 [01:23<01:26,  1.48it/s]Loading train:  49%|████▊     | 120/247 [01:24<01:25,  1.48it/s]Loading train:  49%|████▉     | 121/247 [01:24<01:23,  1.50it/s]Loading train:  49%|████▉     | 122/247 [01:25<01:21,  1.53it/s]Loading train:  50%|████▉     | 123/247 [01:25<01:17,  1.59it/s]Loading train:  50%|█████     | 124/247 [01:26<01:16,  1.61it/s]Loading train:  51%|█████     | 125/247 [01:27<01:14,  1.64it/s]Loading train:  51%|█████     | 126/247 [01:27<01:12,  1.66it/s]Loading train:  51%|█████▏    | 127/247 [01:28<01:16,  1.56it/s]Loading train:  52%|█████▏    | 128/247 [01:29<01:16,  1.55it/s]Loading train:  52%|█████▏    | 129/247 [01:29<01:15,  1.56it/s]Loading train:  53%|█████▎    | 130/247 [01:30<01:12,  1.62it/s]Loading train:  53%|█████▎    | 131/247 [01:30<01:12,  1.61it/s]Loading train:  53%|█████▎    | 132/247 [01:31<01:09,  1.65it/s]Loading train:  54%|█████▍    | 133/247 [01:32<01:09,  1.65it/s]Loading train:  54%|█████▍    | 134/247 [01:32<01:10,  1.61it/s]Loading train:  55%|█████▍    | 135/247 [01:33<01:10,  1.58it/s]Loading train:  55%|█████▌    | 136/247 [01:34<01:13,  1.52it/s]Loading train:  55%|█████▌    | 137/247 [01:34<01:13,  1.49it/s]Loading train:  56%|█████▌    | 138/247 [01:35<01:13,  1.48it/s]Loading train:  56%|█████▋    | 139/247 [01:36<01:13,  1.46it/s]Loading train:  57%|█████▋    | 140/247 [01:37<01:16,  1.39it/s]Loading train:  57%|█████▋    | 141/247 [01:37<01:16,  1.39it/s]Loading train:  57%|█████▋    | 142/247 [01:38<01:12,  1.45it/s]Loading train:  58%|█████▊    | 143/247 [01:39<01:09,  1.50it/s]Loading train:  58%|█████▊    | 144/247 [01:39<01:08,  1.51it/s]Loading train:  59%|█████▊    | 145/247 [01:40<01:05,  1.56it/s]Loading train:  59%|█████▉    | 146/247 [01:41<01:09,  1.45it/s]Loading train:  60%|█████▉    | 147/247 [01:41<01:06,  1.50it/s]Loading train:  60%|█████▉    | 148/247 [01:42<01:04,  1.53it/s]Loading train:  60%|██████    | 149/247 [01:42<00:56,  1.72it/s]Loading train:  61%|██████    | 150/247 [01:43<00:51,  1.87it/s]Loading train:  61%|██████    | 151/247 [01:43<00:51,  1.87it/s]Loading train:  62%|██████▏   | 152/247 [01:44<00:54,  1.74it/s]Loading train:  62%|██████▏   | 153/247 [01:45<00:58,  1.61it/s]Loading train:  62%|██████▏   | 154/247 [01:45<01:02,  1.49it/s]Loading train:  63%|██████▎   | 155/247 [01:46<01:04,  1.44it/s]Loading train:  63%|██████▎   | 156/247 [01:47<01:06,  1.37it/s]Loading train:  64%|██████▎   | 157/247 [01:48<01:05,  1.38it/s]Loading train:  64%|██████▍   | 158/247 [01:48<01:04,  1.38it/s]Loading train:  64%|██████▍   | 159/247 [01:49<01:05,  1.35it/s]Loading train:  65%|██████▍   | 160/247 [01:50<01:06,  1.31it/s]Loading train:  65%|██████▌   | 161/247 [01:51<01:04,  1.34it/s]Loading train:  66%|██████▌   | 162/247 [01:51<01:02,  1.37it/s]Loading train:  66%|██████▌   | 163/247 [01:52<01:03,  1.33it/s]Loading train:  66%|██████▋   | 164/247 [01:53<00:58,  1.43it/s]Loading train:  67%|██████▋   | 165/247 [01:53<00:52,  1.56it/s]Loading train:  67%|██████▋   | 166/247 [01:54<00:49,  1.63it/s]Loading train:  68%|██████▊   | 167/247 [01:55<00:53,  1.50it/s]Loading train:  68%|██████▊   | 168/247 [01:55<00:53,  1.47it/s]Loading train:  68%|██████▊   | 169/247 [01:56<00:55,  1.40it/s]Loading train:  69%|██████▉   | 170/247 [01:57<00:54,  1.41it/s]Loading train:  69%|██████▉   | 171/247 [01:58<00:55,  1.38it/s]Loading train:  70%|██████▉   | 172/247 [01:58<00:55,  1.34it/s]Loading train:  70%|███████   | 173/247 [01:59<00:52,  1.42it/s]Loading train:  70%|███████   | 174/247 [02:00<00:48,  1.49it/s]Loading train:  71%|███████   | 175/247 [02:00<00:51,  1.40it/s]Loading train:  71%|███████▏  | 176/247 [02:01<00:50,  1.40it/s]Loading train:  72%|███████▏  | 177/247 [02:02<00:46,  1.52it/s]Loading train:  72%|███████▏  | 178/247 [02:02<00:46,  1.48it/s]Loading train:  72%|███████▏  | 179/247 [02:03<00:44,  1.52it/s]Loading train:  73%|███████▎  | 180/247 [02:04<00:45,  1.48it/s]Loading train:  73%|███████▎  | 181/247 [02:04<00:44,  1.47it/s]Loading train:  74%|███████▎  | 182/247 [02:05<00:44,  1.47it/s]Loading train:  74%|███████▍  | 183/247 [02:06<00:44,  1.44it/s]Loading train:  74%|███████▍  | 184/247 [02:07<00:44,  1.41it/s]Loading train:  75%|███████▍  | 185/247 [02:07<00:42,  1.45it/s]Loading train:  75%|███████▌  | 186/247 [02:08<00:41,  1.47it/s]Loading train:  76%|███████▌  | 187/247 [02:08<00:39,  1.50it/s]Loading train:  76%|███████▌  | 188/247 [02:09<00:38,  1.54it/s]Loading train:  77%|███████▋  | 189/247 [02:10<00:38,  1.50it/s]Loading train:  77%|███████▋  | 190/247 [02:10<00:35,  1.59it/s]Loading train:  77%|███████▋  | 191/247 [02:11<00:37,  1.48it/s]Loading train:  78%|███████▊  | 192/247 [02:12<00:36,  1.49it/s]Loading train:  78%|███████▊  | 193/247 [02:12<00:35,  1.54it/s]Loading train:  79%|███████▊  | 194/247 [02:13<00:35,  1.50it/s]Loading train:  79%|███████▉  | 195/247 [02:14<00:34,  1.52it/s]Loading train:  79%|███████▉  | 196/247 [02:14<00:33,  1.52it/s]Loading train:  80%|███████▉  | 197/247 [02:15<00:34,  1.44it/s]Loading train:  80%|████████  | 198/247 [02:16<00:34,  1.44it/s]Loading train:  81%|████████  | 199/247 [02:17<00:33,  1.42it/s]Loading train:  81%|████████  | 200/247 [02:17<00:31,  1.50it/s]Loading train:  81%|████████▏ | 201/247 [02:18<00:29,  1.54it/s]Loading train:  82%|████████▏ | 202/247 [02:18<00:29,  1.50it/s]Loading train:  82%|████████▏ | 203/247 [02:19<00:28,  1.52it/s]Loading train:  83%|████████▎ | 204/247 [02:20<00:27,  1.56it/s]Loading train:  83%|████████▎ | 205/247 [02:20<00:27,  1.54it/s]Loading train:  83%|████████▎ | 206/247 [02:21<00:27,  1.51it/s]Loading train:  84%|████████▍ | 207/247 [02:22<00:27,  1.47it/s]Loading train:  84%|████████▍ | 208/247 [02:22<00:26,  1.47it/s]Loading train:  85%|████████▍ | 209/247 [02:23<00:26,  1.44it/s]Loading train:  85%|████████▌ | 210/247 [02:24<00:24,  1.51it/s]Loading train:  85%|████████▌ | 211/247 [02:24<00:23,  1.56it/s]Loading train:  86%|████████▌ | 212/247 [02:25<00:22,  1.59it/s]Loading train:  86%|████████▌ | 213/247 [02:26<00:21,  1.58it/s]Loading train:  87%|████████▋ | 214/247 [02:26<00:21,  1.52it/s]Loading train:  87%|████████▋ | 215/247 [02:27<00:20,  1.53it/s]Loading train:  87%|████████▋ | 216/247 [02:28<00:20,  1.49it/s]Loading train:  88%|████████▊ | 217/247 [02:28<00:20,  1.47it/s]Loading train:  88%|████████▊ | 218/247 [02:29<00:19,  1.48it/s]Loading train:  89%|████████▊ | 219/247 [02:30<00:18,  1.52it/s]Loading train:  89%|████████▉ | 220/247 [02:30<00:17,  1.52it/s]Loading train:  89%|████████▉ | 221/247 [02:31<00:17,  1.46it/s]Loading train:  90%|████████▉ | 222/247 [02:32<00:16,  1.51it/s]Loading train:  90%|█████████ | 223/247 [02:32<00:15,  1.50it/s]Loading train:  91%|█████████ | 224/247 [02:33<00:15,  1.45it/s]Loading train:  91%|█████████ | 225/247 [02:34<00:15,  1.41it/s]Loading train:  91%|█████████▏| 226/247 [02:35<00:14,  1.43it/s]Loading train:  92%|█████████▏| 227/247 [02:35<00:13,  1.45it/s]Loading train:  92%|█████████▏| 228/247 [02:36<00:12,  1.49it/s]Loading train:  93%|█████████▎| 229/247 [02:36<00:11,  1.54it/s]Loading train:  93%|█████████▎| 230/247 [02:37<00:11,  1.45it/s]Loading train:  94%|█████████▎| 231/247 [02:38<00:10,  1.46it/s]Loading train:  94%|█████████▍| 232/247 [02:39<00:10,  1.40it/s]Loading train:  94%|█████████▍| 233/247 [02:39<00:09,  1.40it/s]Loading train:  95%|█████████▍| 234/247 [02:40<00:09,  1.36it/s]Loading train:  95%|█████████▌| 235/247 [02:41<00:09,  1.32it/s]Loading train:  96%|█████████▌| 236/247 [02:42<00:08,  1.33it/s]Loading train:  96%|█████████▌| 237/247 [02:42<00:07,  1.33it/s]Loading train:  96%|█████████▋| 238/247 [02:43<00:06,  1.34it/s]Loading train:  97%|█████████▋| 239/247 [02:44<00:05,  1.35it/s]Loading train:  97%|█████████▋| 240/247 [02:45<00:05,  1.32it/s]Loading train:  98%|█████████▊| 241/247 [02:45<00:04,  1.39it/s]Loading train:  98%|█████████▊| 242/247 [02:46<00:03,  1.35it/s]Loading train:  98%|█████████▊| 243/247 [02:47<00:03,  1.27it/s]Loading train:  99%|█████████▉| 244/247 [02:48<00:02,  1.34it/s]Loading train:  99%|█████████▉| 245/247 [02:48<00:01,  1.36it/s]Loading train: 100%|█████████▉| 246/247 [02:49<00:00,  1.37it/s]Loading train: 100%|██████████| 247/247 [02:50<00:00,  1.37it/s]Loading train: 100%|██████████| 247/247 [02:50<00:00,  1.45it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 49.94it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:04, 48.39it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:04, 46.40it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:04, 45.82it/s]concatenating: train:  11%|█         | 26/247 [00:00<00:04, 45.91it/s]concatenating: train:  13%|█▎        | 31/247 [00:00<00:04, 45.77it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 46.66it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:04, 46.00it/s]concatenating: train:  19%|█▊        | 46/247 [00:00<00:04, 46.72it/s]concatenating: train:  21%|██        | 51/247 [00:01<00:04, 46.36it/s]concatenating: train:  23%|██▎       | 56/247 [00:01<00:04, 46.34it/s]concatenating: train:  25%|██▍       | 61/247 [00:01<00:04, 45.31it/s]concatenating: train:  27%|██▋       | 66/247 [00:01<00:03, 46.18it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 46.84it/s]concatenating: train:  31%|███       | 76/247 [00:01<00:03, 47.40it/s]concatenating: train:  33%|███▎      | 81/247 [00:01<00:03, 47.22it/s]concatenating: train:  35%|███▍      | 86/247 [00:01<00:03, 43.26it/s]concatenating: train:  37%|███▋      | 91/247 [00:02<00:03, 40.03it/s]concatenating: train:  39%|███▉      | 96/247 [00:02<00:03, 40.58it/s]concatenating: train:  41%|████      | 101/247 [00:02<00:03, 40.39it/s]concatenating: train:  43%|████▎     | 106/247 [00:02<00:03, 41.37it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:03, 41.09it/s]concatenating: train:  47%|████▋     | 116/247 [00:02<00:03, 41.37it/s]concatenating: train:  49%|████▉     | 121/247 [00:02<00:03, 41.35it/s]concatenating: train:  51%|█████     | 126/247 [00:02<00:02, 42.86it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 44.71it/s]concatenating: train:  55%|█████▌    | 136/247 [00:03<00:02, 44.50it/s]concatenating: train:  57%|█████▋    | 141/247 [00:03<00:02, 42.86it/s]concatenating: train:  59%|█████▉    | 146/247 [00:03<00:02, 41.28it/s]concatenating: train:  61%|██████    | 151/247 [00:03<00:02, 39.48it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:02, 39.60it/s]concatenating: train:  64%|██████▍   | 159/247 [00:03<00:02, 38.55it/s]concatenating: train:  66%|██████▌   | 163/247 [00:03<00:02, 37.28it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:02, 36.29it/s]concatenating: train:  69%|██████▉   | 171/247 [00:04<00:02, 34.74it/s]concatenating: train:  71%|███████   | 175/247 [00:04<00:02, 35.96it/s]concatenating: train:  72%|███████▏  | 179/247 [00:04<00:01, 36.92it/s]concatenating: train:  74%|███████▍  | 184/247 [00:04<00:01, 37.87it/s]concatenating: train:  77%|███████▋  | 189/247 [00:04<00:01, 38.43it/s]concatenating: train:  79%|███████▊  | 194/247 [00:04<00:01, 39.00it/s]concatenating: train:  81%|████████  | 199/247 [00:04<00:01, 39.31it/s]concatenating: train:  83%|████████▎ | 204/247 [00:04<00:01, 39.71it/s]concatenating: train:  84%|████████▍ | 208/247 [00:04<00:00, 39.33it/s]concatenating: train:  86%|████████▌ | 212/247 [00:05<00:00, 39.19it/s]concatenating: train:  87%|████████▋ | 216/247 [00:05<00:00, 38.21it/s]concatenating: train:  89%|████████▉ | 220/247 [00:05<00:00, 37.79it/s]concatenating: train:  91%|█████████ | 224/247 [00:05<00:00, 37.79it/s]concatenating: train:  92%|█████████▏| 228/247 [00:05<00:00, 37.60it/s]concatenating: train:  94%|█████████▍| 232/247 [00:05<00:00, 37.32it/s]concatenating: train:  96%|█████████▌| 236/247 [00:05<00:00, 36.38it/s]concatenating: train:  97%|█████████▋| 240/247 [00:05<00:00, 35.51it/s]concatenating: train:  99%|█████████▉| 244/247 [00:05<00:00, 35.41it/s]concatenating: train: 100%|██████████| 247/247 [00:06<00:00, 40.83it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:03,  1.00it/s]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.10s/it]Loading test:  60%|██████    | 3/5 [00:03<00:01,  1.01it/s]Loading test:  80%|████████  | 4/5 [00:03<00:00,  1.26it/s]Loading test: 100%|██████████| 5/5 [00:04<00:00,  1.31it/s]Loading test: 100%|██████████| 5/5 [00:04<00:00,  1.22it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 55.79it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<02:41,  1.52it/s]Loading trainS:   1%|          | 2/247 [00:01<02:40,  1.53it/s]Loading trainS:   1%|          | 3/247 [00:02<02:47,  1.46it/s]Loading trainS:   2%|▏         | 4/247 [00:02<02:46,  1.46it/s]Loading trainS:   2%|▏         | 5/247 [00:03<02:47,  1.44it/s]Loading trainS:   2%|▏         | 6/247 [00:04<02:44,  1.46it/s]Loading trainS:   3%|▎         | 7/247 [00:04<02:37,  1.53it/s]Loading trainS:   3%|▎         | 8/247 [00:05<02:36,  1.53it/s]Loading trainS:   4%|▎         | 9/247 [00:06<02:44,  1.45it/s]Loading trainS:   4%|▍         | 10/247 [00:06<02:39,  1.48it/s]Loading trainS:   4%|▍         | 11/247 [00:07<02:42,  1.45it/s]Loading trainS:   5%|▍         | 12/247 [00:08<02:58,  1.32it/s]Loading trainS:   5%|▌         | 13/247 [00:09<02:50,  1.37it/s]Loading trainS:   6%|▌         | 14/247 [00:09<02:44,  1.42it/s]Loading trainS:   6%|▌         | 15/247 [00:10<02:45,  1.40it/s]Loading trainS:   6%|▋         | 16/247 [00:11<02:38,  1.46it/s]Loading trainS:   7%|▋         | 17/247 [00:11<02:35,  1.48it/s]Loading trainS:   7%|▋         | 18/247 [00:12<02:42,  1.41it/s]Loading trainS:   8%|▊         | 19/247 [00:13<02:40,  1.42it/s]Loading trainS:   8%|▊         | 20/247 [00:13<02:33,  1.48it/s]Loading trainS:   9%|▊         | 21/247 [00:14<02:19,  1.62it/s]Loading trainS:   9%|▉         | 22/247 [00:14<02:10,  1.72it/s]Loading trainS:   9%|▉         | 23/247 [00:15<02:07,  1.76it/s]Loading trainS:  10%|▉         | 24/247 [00:15<02:11,  1.69it/s]Loading trainS:  10%|█         | 25/247 [00:16<02:17,  1.61it/s]Loading trainS:  11%|█         | 26/247 [00:17<02:25,  1.52it/s]Loading trainS:  11%|█         | 27/247 [00:18<02:23,  1.54it/s]Loading trainS:  11%|█▏        | 28/247 [00:18<02:24,  1.51it/s]Loading trainS:  12%|█▏        | 29/247 [00:19<02:19,  1.57it/s]Loading trainS:  12%|█▏        | 30/247 [00:19<02:19,  1.56it/s]Loading trainS:  13%|█▎        | 31/247 [00:20<02:23,  1.51it/s]Loading trainS:  13%|█▎        | 32/247 [00:21<02:25,  1.48it/s]Loading trainS:  13%|█▎        | 33/247 [00:22<02:20,  1.52it/s]Loading trainS:  14%|█▍        | 34/247 [00:22<02:23,  1.49it/s]Loading trainS:  14%|█▍        | 35/247 [00:23<02:19,  1.52it/s]Loading trainS:  15%|█▍        | 36/247 [00:24<02:28,  1.43it/s]Loading trainS:  15%|█▍        | 37/247 [00:24<02:21,  1.48it/s]Loading trainS:  15%|█▌        | 38/247 [00:25<02:08,  1.62it/s]Loading trainS:  16%|█▌        | 39/247 [00:25<01:57,  1.77it/s]Loading trainS:  16%|█▌        | 40/247 [00:26<01:50,  1.88it/s]Loading trainS:  17%|█▋        | 41/247 [00:26<01:54,  1.79it/s]Loading trainS:  17%|█▋        | 42/247 [00:27<01:58,  1.72it/s]Loading trainS:  17%|█▋        | 43/247 [00:28<02:02,  1.67it/s]Loading trainS:  18%|█▊        | 44/247 [00:28<02:07,  1.59it/s]Loading trainS:  18%|█▊        | 45/247 [00:29<02:10,  1.54it/s]Loading trainS:  19%|█▊        | 46/247 [00:30<02:13,  1.51it/s]Loading trainS:  19%|█▉        | 47/247 [00:30<02:13,  1.50it/s]Loading trainS:  19%|█▉        | 48/247 [00:31<02:10,  1.52it/s]Loading trainS:  20%|█▉        | 49/247 [00:32<02:14,  1.48it/s]Loading trainS:  20%|██        | 50/247 [00:32<02:06,  1.55it/s]Loading trainS:  21%|██        | 51/247 [00:33<02:05,  1.56it/s]Loading trainS:  21%|██        | 52/247 [00:34<02:07,  1.53it/s]Loading trainS:  21%|██▏       | 53/247 [00:34<02:10,  1.49it/s]Loading trainS:  22%|██▏       | 54/247 [00:35<02:08,  1.50it/s]Loading trainS:  22%|██▏       | 55/247 [00:36<02:07,  1.51it/s]Loading trainS:  23%|██▎       | 56/247 [00:36<02:01,  1.57it/s]Loading trainS:  23%|██▎       | 57/247 [00:37<02:02,  1.55it/s]Loading trainS:  23%|██▎       | 58/247 [00:37<02:03,  1.53it/s]Loading trainS:  24%|██▍       | 59/247 [00:38<02:04,  1.51it/s]Loading trainS:  24%|██▍       | 60/247 [00:39<01:58,  1.58it/s]Loading trainS:  25%|██▍       | 61/247 [00:39<01:58,  1.57it/s]Loading trainS:  25%|██▌       | 62/247 [00:40<02:00,  1.53it/s]Loading trainS:  26%|██▌       | 63/247 [00:41<02:02,  1.50it/s]Loading trainS:  26%|██▌       | 64/247 [00:41<02:03,  1.48it/s]Loading trainS:  26%|██▋       | 65/247 [00:42<01:59,  1.52it/s]Loading trainS:  27%|██▋       | 66/247 [00:43<01:59,  1.51it/s]Loading trainS:  27%|██▋       | 67/247 [00:43<02:00,  1.49it/s]Loading trainS:  28%|██▊       | 68/247 [00:44<02:04,  1.44it/s]Loading trainS:  28%|██▊       | 69/247 [00:45<02:01,  1.47it/s]Loading trainS:  28%|██▊       | 70/247 [00:46<01:59,  1.48it/s]Loading trainS:  29%|██▊       | 71/247 [00:46<01:57,  1.49it/s]Loading trainS:  29%|██▉       | 72/247 [00:47<01:56,  1.50it/s]Loading trainS:  30%|██▉       | 73/247 [00:47<01:55,  1.50it/s]Loading trainS:  30%|██▉       | 74/247 [00:48<01:54,  1.51it/s]Loading trainS:  30%|███       | 75/247 [00:49<01:54,  1.50it/s]Loading trainS:  31%|███       | 76/247 [00:49<01:55,  1.48it/s]Loading trainS:  31%|███       | 77/247 [00:50<02:00,  1.41it/s]Loading trainS:  32%|███▏      | 78/247 [00:51<02:05,  1.34it/s]Loading trainS:  32%|███▏      | 79/247 [00:52<01:57,  1.43it/s]Loading trainS:  32%|███▏      | 80/247 [00:52<01:52,  1.49it/s]Loading trainS:  33%|███▎      | 81/247 [00:53<01:48,  1.52it/s]Loading trainS:  33%|███▎      | 82/247 [00:54<01:53,  1.45it/s]Loading trainS:  34%|███▎      | 83/247 [00:55<02:00,  1.37it/s]Loading trainS:  34%|███▍      | 84/247 [00:55<02:03,  1.32it/s]Loading trainS:  34%|███▍      | 85/247 [00:56<02:02,  1.32it/s]Loading trainS:  35%|███▍      | 86/247 [00:57<02:02,  1.31it/s]Loading trainS:  35%|███▌      | 87/247 [00:58<02:06,  1.26it/s]Loading trainS:  36%|███▌      | 88/247 [00:59<02:04,  1.27it/s]Loading trainS:  36%|███▌      | 89/247 [00:59<02:03,  1.28it/s]Loading trainS:  36%|███▋      | 90/247 [01:00<02:01,  1.29it/s]Loading trainS:  37%|███▋      | 91/247 [01:01<02:03,  1.26it/s]Loading trainS:  37%|███▋      | 92/247 [01:02<02:00,  1.28it/s]Loading trainS:  38%|███▊      | 93/247 [01:02<01:57,  1.31it/s]Loading trainS:  38%|███▊      | 94/247 [01:03<02:00,  1.27it/s]Loading trainS:  38%|███▊      | 95/247 [01:04<01:58,  1.28it/s]Loading trainS:  39%|███▉      | 96/247 [01:05<01:55,  1.31it/s]Loading trainS:  39%|███▉      | 97/247 [01:05<01:52,  1.33it/s]Loading trainS:  40%|███▉      | 98/247 [01:06<01:50,  1.34it/s]Loading trainS:  40%|████      | 99/247 [01:07<01:50,  1.34it/s]Loading trainS:  40%|████      | 100/247 [01:08<01:52,  1.31it/s]Loading trainS:  41%|████      | 101/247 [01:08<01:51,  1.31it/s]Loading trainS:  41%|████▏     | 102/247 [01:09<01:54,  1.27it/s]Loading trainS:  42%|████▏     | 103/247 [01:10<01:54,  1.26it/s]Loading trainS:  42%|████▏     | 104/247 [01:11<01:49,  1.31it/s]Loading trainS:  43%|████▎     | 105/247 [01:12<01:48,  1.31it/s]Loading trainS:  43%|████▎     | 106/247 [01:12<01:44,  1.34it/s]Loading trainS:  43%|████▎     | 107/247 [01:13<01:44,  1.35it/s]Loading trainS:  44%|████▎     | 108/247 [01:14<01:46,  1.30it/s]Loading trainS:  44%|████▍     | 109/247 [01:15<01:44,  1.32it/s]Loading trainS:  45%|████▍     | 110/247 [01:15<01:44,  1.31it/s]Loading trainS:  45%|████▍     | 111/247 [01:16<01:42,  1.32it/s]Loading trainS:  45%|████▌     | 112/247 [01:17<01:40,  1.34it/s]Loading trainS:  46%|████▌     | 113/247 [01:18<01:41,  1.32it/s]Loading trainS:  46%|████▌     | 114/247 [01:18<01:40,  1.32it/s]Loading trainS:  47%|████▋     | 115/247 [01:19<01:36,  1.37it/s]Loading trainS:  47%|████▋     | 116/247 [01:20<01:38,  1.33it/s]Loading trainS:  47%|████▋     | 117/247 [01:21<01:37,  1.34it/s]Loading trainS:  48%|████▊     | 118/247 [01:21<01:29,  1.45it/s]Loading trainS:  48%|████▊     | 119/247 [01:22<01:29,  1.43it/s]Loading trainS:  49%|████▊     | 120/247 [01:22<01:26,  1.46it/s]Loading trainS:  49%|████▉     | 121/247 [01:23<01:26,  1.45it/s]Loading trainS:  49%|████▉     | 122/247 [01:24<01:24,  1.48it/s]Loading trainS:  50%|████▉     | 123/247 [01:24<01:19,  1.56it/s]Loading trainS:  50%|█████     | 124/247 [01:25<01:14,  1.66it/s]Loading trainS:  51%|█████     | 125/247 [01:25<01:06,  1.84it/s]Loading trainS:  51%|█████     | 126/247 [01:26<01:01,  1.96it/s]Loading trainS:  51%|█████▏    | 127/247 [01:26<00:58,  2.04it/s]Loading trainS:  52%|█████▏    | 128/247 [01:27<01:02,  1.91it/s]Loading trainS:  52%|█████▏    | 129/247 [01:27<01:06,  1.76it/s]Loading trainS:  53%|█████▎    | 130/247 [01:28<01:08,  1.70it/s]Loading trainS:  53%|█████▎    | 131/247 [01:29<01:07,  1.71it/s]Loading trainS:  53%|█████▎    | 132/247 [01:29<01:11,  1.62it/s]Loading trainS:  54%|█████▍    | 133/247 [01:30<01:09,  1.65it/s]Loading trainS:  54%|█████▍    | 134/247 [01:31<01:10,  1.60it/s]Loading trainS:  55%|█████▍    | 135/247 [01:31<01:10,  1.59it/s]Loading trainS:  55%|█████▌    | 136/247 [01:32<01:10,  1.57it/s]Loading trainS:  55%|█████▌    | 137/247 [01:33<01:10,  1.55it/s]Loading trainS:  56%|█████▌    | 138/247 [01:33<01:14,  1.47it/s]Loading trainS:  56%|█████▋    | 139/247 [01:34<01:13,  1.46it/s]Loading trainS:  57%|█████▋    | 140/247 [01:35<01:12,  1.48it/s]Loading trainS:  57%|█████▋    | 141/247 [01:35<01:12,  1.47it/s]Loading trainS:  57%|█████▋    | 142/247 [01:36<01:11,  1.46it/s]Loading trainS:  58%|█████▊    | 143/247 [01:37<01:08,  1.52it/s]Loading trainS:  58%|█████▊    | 144/247 [01:37<01:07,  1.52it/s]Loading trainS:  59%|█████▊    | 145/247 [01:38<01:06,  1.53it/s]Loading trainS:  59%|█████▉    | 146/247 [01:39<01:04,  1.56it/s]Loading trainS:  60%|█████▉    | 147/247 [01:39<01:07,  1.48it/s]Loading trainS:  60%|█████▉    | 148/247 [01:40<01:07,  1.47it/s]Loading trainS:  60%|██████    | 149/247 [01:41<01:08,  1.44it/s]Loading trainS:  61%|██████    | 150/247 [01:41<01:08,  1.41it/s]Loading trainS:  61%|██████    | 151/247 [01:42<01:06,  1.44it/s]Loading trainS:  62%|██████▏   | 152/247 [01:43<01:03,  1.51it/s]Loading trainS:  62%|██████▏   | 153/247 [01:43<01:02,  1.49it/s]Loading trainS:  62%|██████▏   | 154/247 [01:44<01:04,  1.45it/s]Loading trainS:  63%|██████▎   | 155/247 [01:45<01:04,  1.43it/s]Loading trainS:  63%|██████▎   | 156/247 [01:46<01:02,  1.45it/s]Loading trainS:  64%|██████▎   | 157/247 [01:46<00:57,  1.57it/s]Loading trainS:  64%|██████▍   | 158/247 [01:47<00:54,  1.63it/s]Loading trainS:  64%|██████▍   | 159/247 [01:47<00:57,  1.54it/s]Loading trainS:  65%|██████▍   | 160/247 [01:48<00:58,  1.48it/s]Loading trainS:  65%|██████▌   | 161/247 [01:49<00:59,  1.45it/s]Loading trainS:  66%|██████▌   | 162/247 [01:50<01:00,  1.41it/s]Loading trainS:  66%|██████▌   | 163/247 [01:50<01:03,  1.32it/s]Loading trainS:  66%|██████▋   | 164/247 [01:51<01:03,  1.31it/s]Loading trainS:  67%|██████▋   | 165/247 [01:52<01:02,  1.30it/s]Loading trainS:  67%|██████▋   | 166/247 [01:53<01:02,  1.30it/s]Loading trainS:  68%|██████▊   | 167/247 [01:54<01:03,  1.27it/s]Loading trainS:  68%|██████▊   | 168/247 [01:54<01:02,  1.27it/s]Loading trainS:  68%|██████▊   | 169/247 [01:55<01:01,  1.28it/s]Loading trainS:  69%|██████▉   | 170/247 [01:56<01:02,  1.24it/s]Loading trainS:  69%|██████▉   | 171/247 [01:57<00:57,  1.32it/s]Loading trainS:  70%|██████▉   | 172/247 [01:57<00:54,  1.37it/s]Loading trainS:  70%|███████   | 173/247 [01:58<00:51,  1.44it/s]Loading trainS:  70%|███████   | 174/247 [01:59<00:51,  1.43it/s]Loading trainS:  71%|███████   | 175/247 [01:59<00:52,  1.38it/s]Loading trainS:  71%|███████▏  | 176/247 [02:00<00:49,  1.42it/s]Loading trainS:  72%|███████▏  | 177/247 [02:01<00:48,  1.44it/s]Loading trainS:  72%|███████▏  | 178/247 [02:02<00:49,  1.40it/s]Loading trainS:  72%|███████▏  | 179/247 [02:02<00:51,  1.32it/s]Loading trainS:  73%|███████▎  | 180/247 [02:03<00:50,  1.33it/s]Loading trainS:  73%|███████▎  | 181/247 [02:04<00:49,  1.33it/s]Loading trainS:  74%|███████▎  | 182/247 [02:05<00:47,  1.38it/s]Loading trainS:  74%|███████▍  | 183/247 [02:05<00:47,  1.35it/s]Loading trainS:  74%|███████▍  | 184/247 [02:06<00:45,  1.37it/s]Loading trainS:  75%|███████▍  | 185/247 [02:07<00:44,  1.39it/s]Loading trainS:  75%|███████▌  | 186/247 [02:07<00:43,  1.39it/s]Loading trainS:  76%|███████▌  | 187/247 [02:08<00:42,  1.42it/s]Loading trainS:  76%|███████▌  | 188/247 [02:09<00:42,  1.38it/s]Loading trainS:  77%|███████▋  | 189/247 [02:10<00:41,  1.41it/s]Loading trainS:  77%|███████▋  | 190/247 [02:10<00:39,  1.43it/s]Loading trainS:  77%|███████▋  | 191/247 [02:11<00:38,  1.45it/s]Loading trainS:  78%|███████▊  | 192/247 [02:11<00:36,  1.51it/s]Loading trainS:  78%|███████▊  | 193/247 [02:12<00:37,  1.46it/s]Loading trainS:  79%|███████▊  | 194/247 [02:13<00:36,  1.44it/s]Loading trainS:  79%|███████▉  | 195/247 [02:14<00:34,  1.50it/s]Loading trainS:  79%|███████▉  | 196/247 [02:14<00:35,  1.43it/s]Loading trainS:  80%|███████▉  | 197/247 [02:15<00:35,  1.42it/s]Loading trainS:  80%|████████  | 198/247 [02:16<00:34,  1.41it/s]Loading trainS:  81%|████████  | 199/247 [02:16<00:33,  1.43it/s]Loading trainS:  81%|████████  | 200/247 [02:17<00:32,  1.45it/s]Loading trainS:  81%|████████▏ | 201/247 [02:18<00:32,  1.41it/s]Loading trainS:  82%|████████▏ | 202/247 [02:19<00:32,  1.37it/s]Loading trainS:  82%|████████▏ | 203/247 [02:19<00:32,  1.37it/s]Loading trainS:  83%|████████▎ | 204/247 [02:20<00:30,  1.40it/s]Loading trainS:  83%|████████▎ | 205/247 [02:21<00:29,  1.42it/s]Loading trainS:  83%|████████▎ | 206/247 [02:22<00:30,  1.36it/s]Loading trainS:  84%|████████▍ | 207/247 [02:22<00:28,  1.43it/s]Loading trainS:  84%|████████▍ | 208/247 [02:23<00:27,  1.43it/s]Loading trainS:  85%|████████▍ | 209/247 [02:24<00:26,  1.41it/s]Loading trainS:  85%|████████▌ | 210/247 [02:24<00:27,  1.33it/s]Loading trainS:  85%|████████▌ | 211/247 [02:25<00:26,  1.36it/s]Loading trainS:  86%|████████▌ | 212/247 [02:26<00:26,  1.34it/s]Loading trainS:  86%|████████▌ | 213/247 [02:27<00:24,  1.36it/s]Loading trainS:  87%|████████▋ | 214/247 [02:27<00:24,  1.35it/s]Loading trainS:  87%|████████▋ | 215/247 [02:28<00:23,  1.36it/s]Loading trainS:  87%|████████▋ | 216/247 [02:29<00:21,  1.41it/s]Loading trainS:  88%|████████▊ | 217/247 [02:30<00:22,  1.33it/s]Loading trainS:  88%|████████▊ | 218/247 [02:30<00:23,  1.25it/s]Loading trainS:  89%|████████▊ | 219/247 [02:31<00:21,  1.29it/s]Loading trainS:  89%|████████▉ | 220/247 [02:32<00:22,  1.21it/s]Loading trainS:  89%|████████▉ | 221/247 [02:33<00:22,  1.18it/s]Loading trainS:  90%|████████▉ | 222/247 [02:34<00:21,  1.16it/s]Loading trainS:  90%|█████████ | 223/247 [02:35<00:19,  1.22it/s]Loading trainS:  91%|█████████ | 224/247 [02:35<00:18,  1.21it/s]Loading trainS:  91%|█████████ | 225/247 [02:36<00:17,  1.23it/s]Loading trainS:  91%|█████████▏| 226/247 [02:37<00:16,  1.30it/s]Loading trainS:  92%|█████████▏| 227/247 [02:38<00:14,  1.34it/s]Loading trainS:  92%|█████████▏| 228/247 [02:38<00:14,  1.31it/s]Loading trainS:  93%|█████████▎| 229/247 [02:39<00:13,  1.37it/s]Loading trainS:  93%|█████████▎| 230/247 [02:40<00:12,  1.33it/s]Loading trainS:  94%|█████████▎| 231/247 [02:41<00:12,  1.28it/s]Loading trainS:  94%|█████████▍| 232/247 [02:42<00:12,  1.22it/s]Loading trainS:  94%|█████████▍| 233/247 [02:42<00:11,  1.26it/s]Loading trainS:  95%|█████████▍| 234/247 [02:43<00:10,  1.26it/s]Loading trainS:  95%|█████████▌| 235/247 [02:44<00:09,  1.23it/s]Loading trainS:  96%|█████████▌| 236/247 [02:45<00:08,  1.23it/s]Loading trainS:  96%|█████████▌| 237/247 [02:46<00:08,  1.18it/s]Loading trainS:  96%|█████████▋| 238/247 [02:46<00:06,  1.33it/s]Loading trainS:  97%|█████████▋| 239/247 [02:47<00:05,  1.47it/s]Loading trainS:  97%|█████████▋| 240/247 [02:47<00:04,  1.51it/s]Loading trainS:  98%|█████████▊| 241/247 [02:48<00:04,  1.49it/s]Loading trainS:  98%|█████████▊| 242/247 [02:49<00:03,  1.44it/s]Loading trainS:  98%|█████████▊| 243/247 [02:50<00:02,  1.43it/s]Loading trainS:  99%|█████████▉| 244/247 [02:50<00:02,  1.40it/s]Loading trainS:  99%|█████████▉| 245/247 [02:51<00:01,  1.39it/s]Loading trainS: 100%|█████████▉| 246/247 [02:52<00:00,  1.33it/s]Loading trainS: 100%|██████████| 247/247 [02:53<00:00,  1.23it/s]Loading trainS: 100%|██████████| 247/247 [02:53<00:00,  1.42it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:03,  1.30it/s]Loading testS:  40%|████      | 2/5 [00:01<00:02,  1.29it/s]Loading testS:  60%|██████    | 3/5 [00:02<00:01,  1.35it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.64it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.51it/s]Loading testS: 100%|██████████| 5/5 [00:03<00:00,  1.51it/s]----------+++ 
CrossVal ['c']
CrossVal ['c']
(0/5) test vimp2_ANON972_CSFn2
(1/5) test vimp2_H_CSFn2
(2/5) test vimp2_I_CSFn2
(3/5) test vimp2_K_CSFn2
(4/5) test vimp2_ANON765_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 78s - loss: 0.1208 - acc: 0.9870 - mDice: 0.7668 - val_loss: 0.2819 - val_acc: 0.9922 - val_mDice: 0.4404

Epoch 00001: val_mDice improved from -inf to 0.44036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 72s - loss: 0.0761 - acc: 0.9921 - mDice: 0.8519 - val_loss: 0.2821 - val_acc: 0.9925 - val_mDice: 0.4396

Epoch 00002: val_mDice did not improve from 0.44036
Epoch 3/300
 - 73s - loss: 0.0669 - acc: 0.9930 - mDice: 0.8698 - val_loss: 0.2748 - val_acc: 0.9931 - val_mDice: 0.4534

Epoch 00003: val_mDice improved from 0.44036 to 0.45336, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 76s - loss: 0.0610 - acc: 0.9936 - mDice: 0.8813 - val_loss: 0.2673 - val_acc: 0.9931 - val_mDice: 0.4685

Epoch 00004: val_mDice improved from 0.45336 to 0.46846, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 78s - loss: 0.0603 - acc: 0.9937 - mDice: 0.8826 - val_loss: 0.2589 - val_acc: 0.9930 - val_mDice: 0.4847

Epoch 00005: val_mDice improved from 0.46846 to 0.48471, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 6/300
 - 77s - loss: 0.0527 - acc: 0.9943 - mDice: 0.8975 - val_loss: 0.2708 - val_acc: 0.9927 - val_mDice: 0.4568

Epoch 00006: val_mDice did not improve from 0.48471
Epoch 7/300
 - 78s - loss: 0.0512 - acc: 0.9945 - mDice: 0.9004 - val_loss: 0.2528 - val_acc: 0.9934 - val_mDice: 0.4949

Epoch 00007: val_mDice improved from 0.48471 to 0.49486, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 78s - loss: 0.0485 - acc: 0.9948 - mDice: 0.9057 - val_loss: 0.2144 - val_acc: 0.9936 - val_mDice: 0.4963

Epoch 00008: val_mDice improved from 0.49486 to 0.49630, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 78s - loss: 0.0467 - acc: 0.9949 - mDice: 0.9092 - val_loss: 0.2438 - val_acc: 0.9921 - val_mDice: 0.4747

Epoch 00009: val_mDice did not improve from 0.49630
Epoch 10/300
 - 78s - loss: 0.0435 - acc: 0.9951 - mDice: 0.9154 - val_loss: 0.2349 - val_acc: 0.9938 - val_mDice: 0.4944

Epoch 00010: val_mDice did not improve from 0.49630
Epoch 11/300
 - 77s - loss: 0.0432 - acc: 0.9952 - mDice: 0.9161 - val_loss: 0.1885 - val_acc: 0.9934 - val_mDice: 0.4774

Epoch 00011: val_mDice did not improve from 0.49630
Epoch 12/300
 - 77s - loss: 0.0419 - acc: 0.9953 - mDice: 0.9185 - val_loss: 0.1936 - val_acc: 0.9935 - val_mDice: 0.4898

Epoch 00012: val_mDice did not improve from 0.49630
Epoch 13/300
 - 78s - loss: 0.0421 - acc: 0.9954 - mDice: 0.9181 - val_loss: 0.1929 - val_acc: 0.9937 - val_mDice: 0.4997

Epoch 00013: val_mDice improved from 0.49630 to 0.49966, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 14/300
 - 78s - loss: 0.0395 - acc: 0.9955 - mDice: 0.9233 - val_loss: 0.0579 - val_acc: 0.9921 - val_mDice: 0.4523

Epoch 00014: val_mDice did not improve from 0.49966
Epoch 15/300
 - 78s - loss: 0.0389 - acc: 0.9956 - mDice: 0.9245 - val_loss: 0.1685 - val_acc: 0.9933 - val_mDice: 0.4926

Epoch 00015: val_mDice did not improve from 0.49966
Epoch 16/300
 - 78s - loss: 0.0402 - acc: 0.9954 - mDice: 0.9218 - val_loss: 0.1583 - val_acc: 0.9812 - val_mDice: 0.2185

Epoch 00016: val_mDice did not improve from 0.49966
Epoch 17/300
 - 77s - loss: 0.0388 - acc: 0.9956 - mDice: 0.9246 - val_loss: 0.0414 - val_acc: 0.9937 - val_mDice: 0.4981

Epoch 00017: val_mDice did not improve from 0.49966
Epoch 18/300
 - 77s - loss: 0.0386 - acc: 0.9957 - mDice: 0.9249 - val_loss: 0.0651 - val_acc: 0.9932 - val_mDice: 0.4836

Epoch 00018: val_mDice did not improve from 0.49966
Epoch 19/300
 - 77s - loss: 0.0393 - acc: 0.9955 - mDice: 0.9237 - val_loss: 0.0656 - val_acc: 0.9938 - val_mDice: 0.5073

Epoch 00019: val_mDice improved from 0.49966 to 0.50731, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 77s - loss: 0.0370 - acc: 0.9958 - mDice: 0.9282 - val_loss: 0.0460 - val_acc: 0.9939 - val_mDice: 0.5028

Epoch 00020: val_mDice did not improve from 0.50731
Epoch 21/300
 - 77s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9304 - val_loss: 0.0352 - val_acc: 0.9939 - val_mDice: 0.4991

Epoch 00021: val_mDice did not improve from 0.50731
Epoch 22/300
 - 77s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9303 - val_loss: 0.0986 - val_acc: 0.9936 - val_mDice: 0.5047

Epoch 00022: val_mDice did not improve from 0.50731
Epoch 23/300
 - 77s - loss: 0.0358 - acc: 0.9959 - mDice: 0.9305 - val_loss: 0.0113 - val_acc: 0.9932 - val_mDice: 0.4910

Epoch 00023: val_mDice did not improve from 0.50731
Epoch 24/300
 - 77s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9341 - val_loss: -1.3440e-02 - val_acc: 0.9934 - val_mDice: 0.4772

Epoch 00024: val_mDice did not improve from 0.50731
Epoch 25/300
 - 77s - loss: 0.0339 - acc: 0.9959 - mDice: 0.9341 - val_loss: 0.1016 - val_acc: 0.9939 - val_mDice: 0.5068

Epoch 00025: val_mDice did not improve from 0.50731
Epoch 26/300
 - 77s - loss: 0.0343 - acc: 0.9960 - mDice: 0.9334 - val_loss: -7.9950e-03 - val_acc: 0.9934 - val_mDice: 0.4716

Epoch 00026: val_mDice did not improve from 0.50731
Epoch 27/300
 - 77s - loss: 0.0334 - acc: 0.9960 - mDice: 0.9351 - val_loss: 0.1303 - val_acc: 0.9938 - val_mDice: 0.5007

Epoch 00027: val_mDice did not improve from 0.50731
Epoch 28/300
 - 77s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9355 - val_loss: 0.1276 - val_acc: 0.9937 - val_mDice: 0.5116

Epoch 00028: val_mDice improved from 0.50731 to 0.51161, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 29/300
 - 77s - loss: 0.0359 - acc: 0.9958 - mDice: 0.9303 - val_loss: 0.0758 - val_acc: 0.9930 - val_mDice: 0.4868

Epoch 00029: val_mDice did not improve from 0.51161
Epoch 30/300
 - 78s - loss: 0.0327 - acc: 0.9961 - mDice: 0.9365 - val_loss: 0.0137 - val_acc: 0.9939 - val_mDice: 0.5144

Epoch 00030: val_mDice improved from 0.51161 to 0.51435, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 31/300
 - 77s - loss: 0.0317 - acc: 0.9962 - mDice: 0.9385 - val_loss: 0.0233 - val_acc: 0.9929 - val_mDice: 0.4867

Epoch 00031: val_mDice did not improve from 0.51435
Epoch 32/300
 - 77s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9366 - val_loss: 0.0311 - val_acc: 0.9941 - val_mDice: 0.5019

Epoch 00032: val_mDice did not improve from 0.51435
Epoch 33/300
 - 77s - loss: 0.0324 - acc: 0.9961 - mDice: 0.9372 - val_loss: 0.0393 - val_acc: 0.9936 - val_mDice: 0.5037

Epoch 00033: val_mDice did not improve from 0.51435
Epoch 34/300
 - 77s - loss: 0.0319 - acc: 0.9961 - mDice: 0.9381 - val_loss: -2.1671e-02 - val_acc: 0.9940 - val_mDice: 0.4939

Epoch 00034: val_mDice did not improve from 0.51435
Epoch 35/300
 - 77s - loss: 0.0322 - acc: 0.9962 - mDice: 0.9376 - val_loss: 0.0377 - val_acc: 0.9941 - val_mDice: 0.5100

Epoch 00035: val_mDice did not improve from 0.51435
Epoch 36/300
 - 77s - loss: 0.0312 - acc: 0.9962 - mDice: 0.9395 - val_loss: 0.0743 - val_acc: 0.9934 - val_mDice: 0.4944

Epoch 00036: val_mDice did not improve from 0.51435
Epoch 37/300
 - 77s - loss: 0.0309 - acc: 0.9962 - mDice: 0.9400 - val_loss: 0.1560 - val_acc: 0.9940 - val_mDice: 0.5148

Epoch 00037: val_mDice improved from 0.51435 to 0.51480, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 38/300
 - 77s - loss: 0.0308 - acc: 0.9962 - mDice: 0.9402 - val_loss: 0.0297 - val_acc: 0.9939 - val_mDice: 0.5006

Epoch 00038: val_mDice did not improve from 0.51480
Epoch 39/300
 - 76s - loss: 0.0305 - acc: 0.9962 - mDice: 0.9409 - val_loss: 0.0708 - val_acc: 0.9937 - val_mDice: 0.4965

Epoch 00039: val_mDice did not improve from 0.51480
Epoch 40/300
 - 77s - loss: 0.0322 - acc: 0.9962 - mDice: 0.9376 - val_loss: -5.2904e-03 - val_acc: 0.9934 - val_mDice: 0.4672

Epoch 00040: val_mDice did not improve from 0.51480
Epoch 41/300
 - 77s - loss: 0.0311 - acc: 0.9962 - mDice: 0.9396 - val_loss: -2.4293e-02 - val_acc: 0.9937 - val_mDice: 0.4985

Epoch 00041: val_mDice did not improve from 0.51480
Epoch 42/300
 - 77s - loss: 0.0311 - acc: 0.9963 - mDice: 0.9396 - val_loss: -1.6717e-02 - val_acc: 0.9933 - val_mDice: 0.4835

Epoch 00042: val_mDice did not improve from 0.51480
Epoch 43/300
 - 76s - loss: 0.0312 - acc: 0.9963 - mDice: 0.9394 - val_loss: 0.0013 - val_acc: 0.9924 - val_mDice: 0.4624

Epoch 00043: val_mDice did not improve from 0.51480
Epoch 44/300
 - 77s - loss: 0.0306 - acc: 0.9963 - mDice: 0.9407 - val_loss: 0.0092 - val_acc: 0.9938 - val_mDice: 0.5084

Epoch 00044: val_mDice did not improve from 0.51480
Epoch 45/300
 - 77s - loss: 0.0299 - acc: 0.9963 - mDice: 0.9419 - val_loss: -1.5979e-02 - val_acc: 0.9935 - val_mDice: 0.4827

Epoch 00045: val_mDice did not improve from 0.51480

Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 46/300
 - 77s - loss: 0.0285 - acc: 0.9965 - mDice: 0.9448 - val_loss: 0.0494 - val_acc: 0.9932 - val_mDice: 0.4892

Epoch 00046: val_mDice did not improve from 0.51480
Epoch 47/300
 - 77s - loss: 0.0280 - acc: 0.9965 - mDice: 0.9456 - val_loss: -1.4445e-02 - val_acc: 0.9936 - val_mDice: 0.4829

Epoch 00047: val_mDice did not improve from 0.51480
Epoch 48/300
 - 77s - loss: 0.0274 - acc: 0.9965 - mDice: 0.9469 - val_loss: -2.2915e-02 - val_acc: 0.9939 - val_mDice: 0.4977

Epoch 00048: val_mDice did not improve from 0.51480
Epoch 49/300
 - 76s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9462 - val_loss: -1.9232e-02 - val_acc: 0.9939 - val_mDice: 0.4888

Epoch 00049: val_mDice did not improve from 0.51480
Epoch 50/300
 - 76s - loss: 0.0278 - acc: 0.9965 - mDice: 0.9461 - val_loss: -8.4832e-04 - val_acc: 0.9939 - val_mDice: 0.5152

Epoch 00050: val_mDice improved from 0.51480 to 0.51524, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 51/300
 - 76s - loss: 0.0277 - acc: 0.9965 - mDice: 0.9462 - val_loss: -2.0033e-02 - val_acc: 0.9940 - val_mDice: 0.4928

Epoch 00051: val_mDice did not improve from 0.51524
Epoch 52/300
 - 76s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9476 - val_loss: 0.0010 - val_acc: 0.9940 - val_mDice: 0.5127

Epoch 00052: val_mDice did not improve from 0.51524
Epoch 53/300
 - 77s - loss: 0.0268 - acc: 0.9966 - mDice: 0.9481 - val_loss: -2.6856e-02 - val_acc: 0.9939 - val_mDice: 0.5041

Epoch 00053: val_mDice did not improve from 0.51524
Epoch 54/300
 - 76s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9477 - val_loss: -2.0340e-02 - val_acc: 0.9939 - val_mDice: 0.4925

Epoch 00054: val_mDice did not improve from 0.51524
Epoch 55/300
 - 76s - loss: 0.0283 - acc: 0.9966 - mDice: 0.9449 - val_loss: -1.7652e-02 - val_acc: 0.9938 - val_mDice: 0.5035

Epoch 00055: val_mDice did not improve from 0.51524
Epoch 56/300
 - 75s - loss: 0.0267 - acc: 0.9966 - mDice: 0.9483 - val_loss: 0.0031 - val_acc: 0.9939 - val_mDice: 0.5065

Epoch 00056: val_mDice did not improve from 0.51524
Epoch 57/300
 - 76s - loss: 0.0268 - acc: 0.9966 - mDice: 0.9479 - val_loss: 0.0155 - val_acc: 0.9940 - val_mDice: 0.5074

Epoch 00057: val_mDice did not improve from 0.51524
Epoch 58/300
 - 76s - loss: 0.0269 - acc: 0.9966 - mDice: 0.9478 - val_loss: -2.3871e-02 - val_acc: 0.9940 - val_mDice: 0.4975

Epoch 00058: val_mDice did not improve from 0.51524
Epoch 59/300
 - 76s - loss: 0.0270 - acc: 0.9966 - mDice: 0.9477 - val_loss: -1.5293e-02 - val_acc: 0.9932 - val_mDice: 0.4807

Epoch 00059: val_mDice did not improve from 0.51524
Epoch 60/300
 - 76s - loss: 0.0275 - acc: 0.9965 - mDice: 0.9467 - val_loss: 0.0031 - val_acc: 0.9941 - val_mDice: 0.5064

Epoch 00060: val_mDice did not improve from 0.51524

Epoch 00060: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 61/300
 - 76s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9504 - val_loss: 0.0037 - val_acc: 0.9940 - val_mDice: 0.5057

Epoch 00061: val_mDice did not improve from 0.51524
Epoch 62/300
 - 76s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9506 - val_loss: 0.0012 - val_acc: 0.9941 - val_mDice: 0.5110

Epoch 00062: val_mDice did not improve from 0.51524
Epoch 63/300
 - 77s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: 0.0043 - val_acc: 0.9939 - val_mDice: 0.5041

Epoch 00063: val_mDice did not improve from 0.51524
Epoch 64/300
 - 76s - loss: 0.0250 - acc: 0.9967 - mDice: 0.9515 - val_loss: 0.0036 - val_acc: 0.9940 - val_mDice: 0.5055

Epoch 00064: val_mDice did not improve from 0.51524
Epoch 65/300
 - 76s - loss: 0.0247 - acc: 0.9967 - mDice: 0.9521 - val_loss: 0.0126 - val_acc: 0.9933 - val_mDice: 0.4879

Epoch 00065: val_mDice did not improve from 0.51524
Epoch 66/300
 - 76s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9503 - val_loss: 0.0046 - val_acc: 0.9939 - val_mDice: 0.5041

Epoch 00066: val_mDice did not improve from 0.51524
Epoch 67/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9518 - val_loss: 0.0110 - val_acc: 0.9936 - val_mDice: 0.5002

Epoch 00067: val_mDice did not improve from 0.51524
Epoch 68/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9518 - val_loss: -1.6243e-02 - val_acc: 0.9935 - val_mDice: 0.4926

Epoch 00068: val_mDice did not improve from 0.51524
Epoch 69/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9517 - val_loss: -2.0965e-02 - val_acc: 0.9940 - val_mDice: 0.4918

Epoch 00069: val_mDice did not improve from 0.51524
Epoch 70/300
 - 76s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9533 - val_loss: -1.9247e-02 - val_acc: 0.9934 - val_mDice: 0.4885

Epoch 00070: val_mDice did not improve from 0.51524
Epoch 71/300
 - 77s - loss: 0.0251 - acc: 0.9967 - mDice: 0.9513 - val_loss: -2.4594e-02 - val_acc: 0.9939 - val_mDice: 0.4995

Epoch 00071: val_mDice did not improve from 0.51524
Epoch 72/300
 - 76s - loss: 0.0255 - acc: 0.9967 - mDice: 0.9506 - val_loss: -1.3911e-02 - val_acc: 0.9941 - val_mDice: 0.5099

Epoch 00072: val_mDice did not improve from 0.51524
Epoch 73/300
 - 76s - loss: 0.0242 - acc: 0.9967 - mDice: 0.9531 - val_loss: 0.0020 - val_acc: 0.9938 - val_mDice: 0.5087

Epoch 00073: val_mDice did not improve from 0.51524
Epoch 74/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9517 - val_loss: 0.0042 - val_acc: 0.9936 - val_mDice: 0.5044

Epoch 00074: val_mDice did not improve from 0.51524
Epoch 75/300
 - 76s - loss: 0.0249 - acc: 0.9967 - mDice: 0.9517 - val_loss: 1.0327e-04 - val_acc: 0.9939 - val_mDice: 0.5125

Epoch 00075: val_mDice did not improve from 0.51524

Epoch 00075: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 76/300
 - 76s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9527 - val_loss: 0.0285 - val_acc: 0.9940 - val_mDice: 0.5187

Epoch 00076: val_mDice improved from 0.51524 to 0.51867, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 77/300
 - 77s - loss: 0.0245 - acc: 0.9968 - mDice: 0.9525 - val_loss: -6.6930e-04 - val_acc: 0.9940 - val_mDice: 0.5140

Epoch 00077: val_mDice did not improve from 0.51867
Epoch 78/300
 - 77s - loss: 0.0247 - acc: 0.9968 - mDice: 0.9522 - val_loss: 0.0031 - val_acc: 0.9937 - val_mDice: 0.5083

Epoch 00078: val_mDice did not improve from 0.51867
Epoch 79/300
 - 77s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9532 - val_loss: 0.0381 - val_acc: 0.9937 - val_mDice: 0.4994

Epoch 00079: val_mDice did not improve from 0.51867
Epoch 80/300
 - 76s - loss: 0.0246 - acc: 0.9968 - mDice: 0.9523 - val_loss: 0.0372 - val_acc: 0.9939 - val_mDice: 0.5012

Epoch 00080: val_mDice did not improve from 0.51867
Epoch 81/300
 - 77s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9539 - val_loss: 0.0319 - val_acc: 0.9938 - val_mDice: 0.5120

Epoch 00081: val_mDice did not improve from 0.51867
Epoch 82/300
 - 76s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9545 - val_loss: 0.0351 - val_acc: 0.9938 - val_mDice: 0.5055

Epoch 00082: val_mDice did not improve from 0.51867
Epoch 83/300
 - 76s - loss: 0.0242 - acc: 0.9968 - mDice: 0.9531 - val_loss: 0.0313 - val_acc: 0.9940 - val_mDice: 0.5129

Epoch 00083: val_mDice did not improve from 0.51867
Epoch 84/300
 - 77s - loss: 0.0248 - acc: 0.9968 - mDice: 0.9518 - val_loss: -1.6284e-04 - val_acc: 0.9939 - val_mDice: 0.5133

Epoch 00084: val_mDice did not improve from 0.51867
Epoch 85/300
 - 76s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9545 - val_loss: 0.0348 - val_acc: 0.9940 - val_mDice: 0.5070

Epoch 00085: val_mDice did not improve from 0.51867
Epoch 86/300
 - 76s - loss: 0.0236 - acc: 0.9968 - mDice: 0.9543 - val_loss: -2.3651e-02 - val_acc: 0.9936 - val_mDice: 0.4979

Epoch 00086: val_mDice did not improve from 0.51867
Epoch 87/300
 - 76s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9529 - val_loss: -2.5273e-02 - val_acc: 0.9938 - val_mDice: 0.5051

Epoch 00087: val_mDice did not improve from 0.51867
Epoch 88/300
 - 76s - loss: 0.0243 - acc: 0.9968 - mDice: 0.9528 - val_loss: -2.5959e-02 - val_acc: 0.9939 - val_mDice: 0.5018

Epoch 00088: val_mDice did not improve from 0.51867
Epoch 89/300
 - 77s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: -2.2718e-02 - val_acc: 0.9937 - val_mDice: 0.4963

Epoch 00089: val_mDice did not improve from 0.51867
Epoch 90/300
 - 76s - loss: 0.0233 - acc: 0.9968 - mDice: 0.9549 - val_loss: 0.0032 - val_acc: 0.9939 - val_mDice: 0.5122

Epoch 00090: val_mDice did not improve from 0.51867
Epoch 91/300
 - 76s - loss: 0.0234 - acc: 0.9968 - mDice: 0.9547 - val_loss: 0.0023 - val_acc: 0.9939 - val_mDice: 0.5081

Epoch 00091: val_mDice did not improve from 0.51867

Epoch 00091: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.
Epoch 92/300
 - 76s - loss: 0.0237 - acc: 0.9968 - mDice: 0.9541 - val_loss: 0.0255 - val_acc: 0.9939 - val_mDice: 0.5039

Epoch 00092: val_mDice did not improve from 0.51867
Epoch 93/300
 - 76s - loss: 0.0232 - acc: 0.9968 - mDice: 0.9551 - val_loss: -5.3375e-03 - val_acc: 0.9938 - val_mDice: 0.5079

Epoch 00093: val_mDice did not improve from 0.51867
Epoch 94/300
 - 76s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9556 - val_loss: -2.5042e-02 - val_acc: 0.9938 - val_mDice: 0.5011

Epoch 00094: val_mDice did not improve from 0.51867
Epoch 95/300
 - 76s - loss: 0.0233 - acc: 0.9968 - mDice: 0.9549 - val_loss: -1.8972e-02 - val_acc: 0.9937 - val_mDice: 0.4984

Epoch 00095: val_mDice did not improve from 0.51867
Epoch 96/300
 - 76s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: 0.0352 - val_acc: 0.9940 - val_mDice: 0.5044

Epoch 00096: val_mDice did not improve from 0.51867
Epoch 97/300
 - 76s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9556 - val_loss: 0.0056 - val_acc: 0.9937 - val_mDice: 0.5019

Epoch 00097: val_mDice did not improve from 0.51867
Epoch 98/300
 - 76s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9557 - val_loss: 0.0015 - val_acc: 0.9938 - val_mDice: 0.5093

Epoch 00098: val_mDice did not improve from 0.51867
Epoch 99/300
 - 77s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9546 - val_loss: -2.3683e-02 - val_acc: 0.9938 - val_mDice: 0.5017

Epoch 00099: val_mDice did not improve from 0.51867
Epoch 100/300
 - 76s - loss: 0.0236 - acc: 0.9968 - mDice: 0.9543 - val_loss: -2.4639e-02 - val_acc: 0.9938 - val_mDice: 0.4999

Epoch 00100: val_mDice did not improve from 0.51867
Epoch 101/300
 - 76s - loss: 0.0233 - acc: 0.9968 - mDice: 0.9548 - val_loss: -2.4230e-02 - val_acc: 0.9938 - val_mDice: 0.5000

Epoch 00101: val_mDice did not improve from 0.51867
Epoch 102/300
 - 76s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9539 - val_loss: -1.8225e-02 - val_acc: 0.9937 - val_mDice: 0.5016

Epoch 00102: val_mDice did not improve from 0.51867
Epoch 103/300
 - 76s - loss: 0.0233 - acc: 0.9968 - mDice: 0.9549 - val_loss: 0.0054 - val_acc: 0.9936 - val_mDice: 0.5033

Epoch 00103: val_mDice did not improve from 0.51867
Epoch 104/300
 - 76s - loss: 0.0231 - acc: 0.9968 - mDice: 0.9552 - val_loss: 0.0046 - val_acc: 0.9938 - val_mDice: 0.5091

Epoch 00104: val_mDice did not improve from 0.51867
Epoch 105/300
 - 77s - loss: 0.0229 - acc: 0.9969 - mDice: 0.9556 - val_loss: 0.0069 - val_acc: 0.9938 - val_mDice: 0.5021

Epoch 00105: val_mDice did not improve from 0.51867
Epoch 106/300
 - 77s - loss: 0.0237 - acc: 0.9968 - mDice: 0.9541 - val_loss: 2.6148e-04 - val_acc: 0.9940 - val_mDice: 0.5128

Epoch 00106: val_mDice did not improve from 0.51867

Epoch 00106: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.
Epoch 107/300
 - 77s - loss: 0.0224 - acc: 0.9969 - mDice: 0.9567 - val_loss: 0.0048 - val_acc: 0.9938 - val_mDice: 0.5035

Epoch 00107: val_mDice did not improve from 0.51867
Epoch 108/300
 - 76s - loss: 0.0224 - acc: 0.9968 - mDice: 0.9566 - val_loss: 0.0027 - val_acc: 0.9938 - val_mDice: 0.5080

Epoch 00108: val_mDice did not improve from 0.51867
Epoch 109/300
 - 76s - loss: 0.0232 - acc: 0.9968 - mDice: 0.9550 - val_loss: 2.5124e-04 - val_acc: 0.9939 - val_mDice: 0.5124

Epoch 00109: val_mDice did not improve from 0.51867
Epoch 110/300
 - 76s - loss: 0.0232 - acc: 0.9968 - mDice: 0.9551 - val_loss: 1.5253e-05 - val_acc: 0.9939 - val_mDice: 0.5129

Epoch 00110: val_mDice did not improve from 0.51867
Epoch 111/300
 - 77s - loss: 0.0233 - acc: 0.9968 - mDice: 0.9549 - val_loss: 0.0074 - val_acc: 0.9938 - val_mDice: 0.4981

Epoch 00111: val_mDice did not improve from 0.51867
Epoch 112/300
 - 77s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9557 - val_loss: 0.0063 - val_acc: 0.9938 - val_mDice: 0.5004

Epoch 00112: val_mDice did not improve from 0.51867
Epoch 113/300
 - 78s - loss: 0.0226 - acc: 0.9968 - mDice: 0.9562 - val_loss: 0.0065 - val_acc: 0.9938 - val_mDice: 0.5000

Epoch 00113: val_mDice did not improve from 0.51867
Epoch 114/300
 - 77s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9557 - val_loss: 0.0067 - val_acc: 0.9938 - val_mDice: 0.4996

Epoch 00114: val_mDice did not improve from 0.51867
Epoch 115/300
 - 76s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9556 - val_loss: 0.0076 - val_acc: 0.9938 - val_mDice: 0.4982

Epoch 00115: val_mDice did not improve from 0.51867
Epoch 116/300
 - 77s - loss: 0.0232 - acc: 0.9968 - mDice: 0.9550 - val_loss: 0.0060 - val_acc: 0.9939 - val_mDice: 0.5016

Epoch 00116: val_mDice did not improve from 0.51867
Restoring model weights from the end of the best epoch
Epoch 00116: early stopping
{'val_loss': [0.2819097636255828, 0.28207928167199187, 0.27475192313486674, 0.267263872724659, 0.25889139200718897, 0.2708115576760574, 0.2527883633877496, 0.21444697284473563, 0.24377930989055513, 0.23492753969610863, 0.18853901715586022, 0.19363690519107962, 0.19291594966590028, 0.05787319807136584, 0.1685415653031577, 0.1582860421834502, 0.041441310923429404, 0.06513657730143026, 0.06559080368130461, 0.04595099666021155, 0.03516566505034765, 0.09856492744864158, 0.011260411227649113, -0.013440285510611985, 0.10163782644759184, -0.007994979807415849, 0.13031210263007842, 0.12756513986947401, 0.0757671299408067, 0.013736775461232887, 0.02331507088815641, 0.031081022612703672, 0.03933116414074628, -0.021671426746080507, 0.037664468230316474, 0.07432194133787035, 0.15600246523723663, 0.02965128220289758, 0.07082043972405248, -0.005290432874136751, -0.02429313212633133, -0.01671706383708138, 0.0013448883246325847, 0.009166795549527654, -0.015979025020914257, 0.04937582017865571, -0.014444888387836, -0.022914774950195407, -0.019232424596945446, -0.0008483236222147192, -0.020033217919697553, 0.001016059527232212, -0.026855583835697774, -0.02033977744714269, -0.01765233428223328, 0.0030790036954219985, 0.015478511323344032, -0.023870890151779605, -0.01529302030989209, 0.0031443712940006138, 0.0036941686141415964, 0.0012014030285601347, 0.004307845759691682, 0.0035864772661676945, 0.012586120258337297, 0.00458829568804435, 0.010992233249001533, -0.016243124907871463, -0.020964861244150677, -0.01924724117764887, -0.02459403413271754, -0.013910871772271282, 0.0020426523010685757, 0.0042371036683988275, 0.00010326921752413864, 0.028462791592819885, -0.0006693025711197523, 0.0031023141723009024, 0.03810230122422272, 0.0372257188618558, 0.03185022523942983, 0.035147493740297714, 0.03133529546500752, -0.00016284373196415931, 0.03476149509163023, -0.023651040153308486, -0.02527310816371966, -0.025958795170739013, -0.022718375068415637, 0.0032269251327844534, 0.0023215781405286967, 0.025533926655661385, -0.005337539287108295, -0.025041921802286832, -0.018972348492100555, 0.03522135874947662, 0.005632229102482586, 0.0015213548574807508, -0.02368343986992566, -0.02463872918167954, -0.024230038594899687, -0.018224607286213328, 0.00538394811018458, 0.004575748254293166, 0.0068737659720504805, 0.00026147971925495557, 0.00479206789589528, 0.0027095080827766994, 0.00025124149689884307, 1.5253493995786463e-05, 0.007407158660063954, 0.006338630129331313, 0.006462879806944409, 0.006665944443933619, 0.00755578321668337, 0.005974345002909127], 'val_acc': [0.992172250207865, 0.9925362197857983, 0.9931358728768691, 0.993122325003522, 0.9929589145588424, 0.992742047369855, 0.9933916574004311, 0.9935999943775201, 0.9921478996486783, 0.993822640218075, 0.9933530006018825, 0.9935384966292471, 0.9937232410382925, 0.9920748577177899, 0.9933394508541755, 0.9812073752565204, 0.9936750512452995, 0.9932146990824046, 0.9938143555473231, 0.9939192840888066, 0.9939130031087864, 0.9935856873884141, 0.9931737836801781, 0.993445873260498, 0.9939340877832856, 0.9933801075947359, 0.9937792150479443, 0.9937224875456132, 0.9929905406334115, 0.9939320840925541, 0.9928688047067175, 0.9940548246761538, 0.9935769078866491, 0.993964967862615, 0.9941100470674863, 0.9934408537246896, 0.9939524171487341, 0.9938575314275874, 0.9937495982871866, 0.9934343290778825, 0.9937259982217033, 0.9933241354594441, 0.9924157306833087, 0.9938462384091983, 0.9934529039844777, 0.9932207214007588, 0.993581419470925, 0.9938919165599271, 0.9938796188846324, 0.9939245547888413, 0.9940435297834048, 0.99400110552146, 0.9938713360882405, 0.9938730923634655, 0.9937699257202868, 0.9939426292413436, 0.9940093939409316, 0.9939729994947806, 0.9932415511623118, 0.9941474480449028, 0.9939815334553989, 0.9941017661454543, 0.99392605989984, 0.9939652190268414, 0.9932935121674208, 0.9938758532955961, 0.9935989915949743, 0.9935465338844923, 0.9939521584870681, 0.9933537559689216, 0.993862048634943, 0.994096744735286, 0.9937598885230299, 0.9935899553059032, 0.9938615463064902, 0.9940267130263947, 0.9939968451014105, 0.993673786052368, 0.9937297713081792, 0.9938881603426903, 0.9938449844624262, 0.9937772076084929, 0.9940046236949897, 0.9939182738088211, 0.993979773431454, 0.9935598343423327, 0.9938196281217179, 0.9939220412722174, 0.9936790623754825, 0.9939265622282928, 0.9938500002495148, 0.9939162682437297, 0.9937691759763274, 0.9938168690639472, 0.9937372987375319, 0.9939579408873552, 0.9937485936302809, 0.9938477435201969, 0.993813101600551, 0.9938045732630124, 0.9938294179034683, 0.9937147089520341, 0.9936451795715956, 0.993788000172789, 0.9938133527647774, 0.9939812785424527, 0.9938444802596135, 0.9938457304576658, 0.9938690812332825, 0.9939192803400867, 0.9937900094866002, 0.9938065807024637, 0.9938349378933696, 0.9938274067152971, 0.9937601359385364, 0.9938874031012913], 'val_mDice': [0.44036291412042566, 0.4396321347070445, 0.45336493539546435, 0.4684557318431556, 0.4847078151413922, 0.4568151663698605, 0.49485796857508285, 0.4962985212885432, 0.4746849601178991, 0.4943750920602084, 0.47738690345120505, 0.4898216807355676, 0.49966383432536005, 0.45228312975205714, 0.4926389677204051, 0.21851483567068056, 0.4981450757609223, 0.483628973224253, 0.5073061768176421, 0.5027577707415107, 0.4990613877585849, 0.5047081161913572, 0.4910395635960248, 0.4771873971812699, 0.5068370360154776, 0.47160138664648793, 0.5006650343256177, 0.5116084030592586, 0.48681744801923166, 0.5143505946364043, 0.48670457547190804, 0.5019040485410571, 0.503734937113411, 0.49385378102086624, 0.5099707420142192, 0.4943652736878245, 0.514797204835903, 0.5006406344262135, 0.49648780481151816, 0.4672341521993573, 0.4985443043446391, 0.4834982434158805, 0.462367500898973, 0.5083693804090503, 0.48274993761764756, 0.48919486419454233, 0.4829496490247782, 0.4976906336305089, 0.48875816823239127, 0.5152362512436303, 0.4927839484042342, 0.5126690524835257, 0.5041356869744804, 0.4924695008674508, 0.5035488286389495, 0.5065172451472132, 0.5073517214202281, 0.497486301984802, 0.4807017530379055, 0.5063754015561169, 0.5057070889281776, 0.511009211669553, 0.5041204519429296, 0.5055321029053544, 0.48792368328233937, 0.5040507293398556, 0.5002268853614915, 0.49262874437665427, 0.4917792277703495, 0.48852821987754896, 0.49947428276891226, 0.5099440865078062, 0.5086763064910031, 0.5043608111874113, 0.5125443424162625, 0.5186740470663557, 0.5140293731629474, 0.5082619061353821, 0.49942866038039047, 0.5011641724183775, 0.5119767499232443, 0.5054727887863633, 0.5129398796824539, 0.5132596246289007, 0.5069971344662163, 0.49794855990312387, 0.5050948723775786, 0.5018373827139536, 0.49629025208125327, 0.5121768692379478, 0.5081287852295164, 0.5038744969141242, 0.507906842859661, 0.5010891001261818, 0.4983833104770326, 0.5043838353116565, 0.5019090741685721, 0.5092741925058499, 0.5016520085518796, 0.4998858823622548, 0.5000285291165676, 0.5015731687253376, 0.5032867265853492, 0.5090514351408811, 0.5020936652315113, 0.512777521808005, 0.5034770945426803, 0.5080448203491714, 0.5123730645802036, 0.512917355382405, 0.4981267958879269, 0.5003668121852964, 0.4999777042078522, 0.49957608206654497, 0.4981625978629919, 0.5015968980045064], 'loss': [0.12077213087379114, 0.07610985609763399, 0.06690411551872463, 0.061030039860664624, 0.0603134668759498, 0.05272353897983964, 0.05119626868091548, 0.04850078291910401, 0.046708981661011256, 0.043531957106842725, 0.043150965802707886, 0.04191434518409715, 0.042121740543588075, 0.03947833295745218, 0.038857879011663425, 0.040239570026320094, 0.03878097473575189, 0.03864272985487515, 0.039257123076720975, 0.03696579989124843, 0.035821487066394285, 0.03586474739072715, 0.03578677519423672, 0.033923601992307505, 0.033948998495910376, 0.03428981883972177, 0.03340319559688014, 0.033226654875766135, 0.035878256063682536, 0.03269731374092755, 0.03168735245693857, 0.032635914791355886, 0.03236454900239851, 0.031886639856368894, 0.03215338441574178, 0.031174286497474817, 0.03090782887466116, 0.030796121140576324, 0.030462869035763524, 0.03215134470082632, 0.031097793126937365, 0.03110999307725518, 0.031205245865851335, 0.03055554558029345, 0.029935977679330473, 0.02846154746483109, 0.028017403941204732, 0.02739990402889329, 0.02772920676380448, 0.02776538610205623, 0.027714034773355472, 0.02701994112417953, 0.026781607656206505, 0.02694956678037603, 0.02834079580473971, 0.026678223593123804, 0.026846300939738707, 0.02691944657243467, 0.02695805879287007, 0.027456278232757692, 0.025596250277909294, 0.025463620956683284, 0.025190585229455695, 0.025046289491219304, 0.024704972204461186, 0.025624525195963813, 0.02485366100220051, 0.024877384331948027, 0.024930863701834824, 0.02412901705386009, 0.025101602742814103, 0.02545529993120409, 0.024197255835275336, 0.024941144846091695, 0.02493113201380103, 0.024390603482805008, 0.02450380470704991, 0.024656335848559464, 0.024137190836984696, 0.024621703063320656, 0.023788378303315344, 0.023500585550826576, 0.024185280574136735, 0.024831098333153532, 0.023491152922510656, 0.023571866100998286, 0.024273298381569677, 0.02432252539623316, 0.023870083188647848, 0.02329024992814442, 0.023384383587126245, 0.02366791420980236, 0.023179388060760666, 0.022924311382867477, 0.02329823313883547, 0.02386540485219368, 0.022937187808362527, 0.0228697236197106, 0.023452135474307485, 0.023585446117583817, 0.023320518076293456, 0.023793602304198136, 0.023277724538547612, 0.023113131374455236, 0.02292572503436025, 0.023664507470387536, 0.022385888561758802, 0.022441161785764448, 0.0232416369526441, 0.02320357562449544, 0.02327159718032132, 0.02289485776214773, 0.02260381271786213, 0.02288565801976476, 0.022939767266641563, 0.02321726962808779], 'acc': [0.9869713839835792, 0.9921458202069702, 0.9930454312000646, 0.9935828550375141, 0.993741512447261, 0.9942955018041377, 0.9945240198569751, 0.9947824182505024, 0.9948711547955041, 0.9951046454873754, 0.995208846605398, 0.9953168848634926, 0.9953561845816529, 0.9955089225394972, 0.9955894612379875, 0.9953915501999778, 0.995595533135943, 0.995661884799031, 0.9955157018653411, 0.9957532198032437, 0.995847904100832, 0.9958087497145257, 0.9958532008261834, 0.9959541761643216, 0.9959460527678623, 0.9960038674520001, 0.9960039468455654, 0.9960326632304988, 0.9958227714656088, 0.9961031719347163, 0.9961825045423633, 0.996124510085324, 0.9961088560382217, 0.9961301799455644, 0.9961746104357099, 0.9962011701479669, 0.9962428083411474, 0.9962443564710667, 0.996247851415952, 0.996176134063645, 0.9962304154367749, 0.9962684741993145, 0.9962542215378453, 0.9962876016554258, 0.9963253029908109, 0.9964517391168081, 0.9964839500080294, 0.9964936512846934, 0.99651664227106, 0.9964902764783294, 0.9965319393593405, 0.9965644683080233, 0.996559141393789, 0.9965546269329387, 0.996558814214988, 0.9965579281664454, 0.9965697246080742, 0.9965777978631855, 0.9965717405281509, 0.9965432832130443, 0.9966408492294325, 0.9966619455270204, 0.9966804562408331, 0.9967019606867643, 0.9967000583262478, 0.9966772912624442, 0.9967267383257032, 0.9966821335042376, 0.9966998536648016, 0.9967173312438281, 0.9967170722409061, 0.9967079782506777, 0.9967143089880103, 0.9967202380667544, 0.9967267390765225, 0.9967669877708033, 0.9967827612204753, 0.9967594366324576, 0.996736225499926, 0.9967664846475358, 0.9967858976156939, 0.9967676744136349, 0.9967827867780668, 0.9967767238453399, 0.9967662562126232, 0.9967749715446088, 0.9967807258088323, 0.9968074311131282, 0.9967872964515149, 0.9967753046704932, 0.9967951453082964, 0.9967929763474587, 0.9967908307958285, 0.9968183316637911, 0.9967979386088318, 0.9968190378576599, 0.9967976001008367, 0.9968038916022857, 0.9968397653542959, 0.9968058631571192, 0.9968319109369912, 0.9968244847394369, 0.9968145640674272, 0.9968331352630795, 0.9968534734264577, 0.9968435878199394, 0.9968529812235224, 0.9968277598355113, 0.9968367043680965, 0.9968292677408443, 0.9968367292269057, 0.9968183466653093, 0.9968328262005818, 0.9968449377261305, 0.9968481475306615, 0.9968269777717244], 'mDice': [0.7667981860538199, 0.8519202590046073, 0.8698063736599372, 0.8812596143100984, 0.8825919905398204, 0.897468909807085, 0.9003964390584316, 0.9056502220621131, 0.9091818680539336, 0.9154072176729184, 0.9161135113857785, 0.9185231808423401, 0.918083361212706, 0.9232865868549331, 0.9244838578277587, 0.9218228149701009, 0.9246317822013184, 0.9248707867524169, 0.9237294235915117, 0.92817379949797, 0.930404878913033, 0.9303482612578701, 0.9304718879593016, 0.934144884429688, 0.9340948813735889, 0.9333769224191967, 0.9351479913728081, 0.9354877522771474, 0.9303141593762126, 0.9365047384457684, 0.9384786009966926, 0.9366165018789367, 0.9371676736934788, 0.9381083498856884, 0.9375536453102438, 0.939489267627091, 0.9400078730337577, 0.9402229849404307, 0.9408912742545285, 0.9375605894279141, 0.939632195699658, 0.9395765720586224, 0.9394032381870825, 0.9406792561842575, 0.9419016072832757, 0.9447741747333629, 0.9456365585854952, 0.9468684955914736, 0.9461962900931296, 0.9461315132809506, 0.946216773528891, 0.9475905535211585, 0.9480719785272228, 0.9477311863479908, 0.9449456496506624, 0.9482689792971921, 0.9479280961930647, 0.9477709712203705, 0.9477026206384308, 0.9467146386103571, 0.9503868751750084, 0.9506343457207593, 0.9511674350561065, 0.9514508999384201, 0.9521375433796212, 0.950306177607615, 0.9518300227005008, 0.9517922502008273, 0.9516779719876304, 0.953277049099724, 0.9513273689775997, 0.9506282979685148, 0.9531374069023204, 0.9516502720494093, 0.9516665225806276, 0.9527274126437395, 0.9524951266748823, 0.9521942965688179, 0.9532372644600888, 0.9522545600166402, 0.953923679477528, 0.9544929618043297, 0.9531217414070823, 0.951825697048402, 0.9545085450588363, 0.95434622031312, 0.9529453547600351, 0.9528415206737071, 0.9537490022453057, 0.9549112379417124, 0.954721278972119, 0.9541493804117603, 0.9551202132089919, 0.9556231399030274, 0.9548795902244347, 0.9537455589805763, 0.9556009326084619, 0.9557321654290266, 0.9545642992792417, 0.9543031022476716, 0.9548251928460065, 0.9538768492351003, 0.9549111273333925, 0.9552386540387092, 0.9556119910616266, 0.954134482647838, 0.9566871880533452, 0.9565759391283923, 0.9549747323656832, 0.95505798989886, 0.9549160798266833, 0.9556696204420753, 0.9562497339393766, 0.9556865515807645, 0.9555722818421616, 0.9550278916133553], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 6.25e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05, 3.125e-05]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.07it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.36it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.73it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.05it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.59it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.73it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:38,  6.33it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:38,  6.43it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:37,  6.53it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:37,  6.48it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:37,  6.46it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:37,  6.46it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:36,  6.50it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:36,  6.51it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:36,  6.52it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.54it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:36,  6.41it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.39it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.45it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.48it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:36,  6.44it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:35,  6.43it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:35,  6.40it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:35,  6.39it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:35,  6.39it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:35,  6.42it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:35,  6.37it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:38,  5.87it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:36,  6.11it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:35,  6.31it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:34,  6.47it/s]predicting train subjects:  11%|█         | 26/247 [00:04<00:33,  6.55it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:33,  6.53it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:33,  6.62it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:33,  6.58it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:32,  6.62it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:32,  6.70it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:32,  6.55it/s]predicting train subjects:  13%|█▎        | 33/247 [00:05<00:32,  6.62it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:32,  6.65it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:31,  6.73it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:31,  6.73it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:31,  6.77it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:30,  6.80it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:30,  6.80it/s]predicting train subjects:  16%|█▌        | 40/247 [00:06<00:30,  6.77it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:30,  6.81it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:30,  6.80it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:30,  6.79it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:29,  6.80it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:29,  6.81it/s]predicting train subjects:  19%|█▊        | 46/247 [00:07<00:29,  6.82it/s]predicting train subjects:  19%|█▉        | 47/247 [00:07<00:29,  6.84it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:29,  6.85it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:29,  6.82it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:29,  6.78it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:29,  6.75it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.77it/s]predicting train subjects:  21%|██▏       | 53/247 [00:08<00:28,  6.77it/s]predicting train subjects:  22%|██▏       | 54/247 [00:08<00:28,  6.76it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:29,  6.55it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:29,  6.58it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:28,  6.66it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:28,  6.72it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:28,  6.59it/s]predicting train subjects:  24%|██▍       | 60/247 [00:09<00:28,  6.51it/s]predicting train subjects:  25%|██▍       | 61/247 [00:09<00:28,  6.43it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:28,  6.44it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:28,  6.42it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:29,  6.29it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.30it/s]predicting train subjects:  27%|██▋       | 66/247 [00:10<00:28,  6.31it/s]predicting train subjects:  27%|██▋       | 67/247 [00:10<00:28,  6.31it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:28,  6.31it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.34it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.35it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.34it/s]predicting train subjects:  29%|██▉       | 72/247 [00:11<00:28,  6.25it/s]predicting train subjects:  30%|██▉       | 73/247 [00:11<00:27,  6.27it/s]predicting train subjects:  30%|██▉       | 74/247 [00:11<00:27,  6.24it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:27,  6.25it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:27,  6.29it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:28,  6.04it/s]predicting train subjects:  32%|███▏      | 78/247 [00:12<00:28,  5.95it/s]predicting train subjects:  32%|███▏      | 79/247 [00:12<00:35,  4.75it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:41,  4.01it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:42,  3.93it/s]predicting train subjects:  33%|███▎      | 82/247 [00:13<00:38,  4.28it/s]predicting train subjects:  34%|███▎      | 83/247 [00:13<00:35,  4.58it/s]predicting train subjects:  34%|███▍      | 84/247 [00:13<00:33,  4.84it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:32,  5.03it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:31,  5.19it/s]predicting train subjects:  35%|███▌      | 87/247 [00:14<00:30,  5.28it/s]predicting train subjects:  36%|███▌      | 88/247 [00:14<00:29,  5.32it/s]predicting train subjects:  36%|███▌      | 89/247 [00:14<00:29,  5.39it/s]predicting train subjects:  36%|███▋      | 90/247 [00:14<00:31,  5.06it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:30,  5.15it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:29,  5.26it/s]predicting train subjects:  38%|███▊      | 93/247 [00:15<00:29,  5.29it/s]predicting train subjects:  38%|███▊      | 94/247 [00:15<00:28,  5.37it/s]predicting train subjects:  38%|███▊      | 95/247 [00:15<00:27,  5.43it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:27,  5.47it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:27,  5.45it/s]predicting train subjects:  40%|███▉      | 98/247 [00:16<00:27,  5.46it/s]predicting train subjects:  40%|████      | 99/247 [00:16<00:27,  5.41it/s]predicting train subjects:  40%|████      | 100/247 [00:16<00:27,  5.38it/s]predicting train subjects:  41%|████      | 101/247 [00:16<00:27,  5.39it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:26,  5.42it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:26,  5.50it/s]predicting train subjects:  42%|████▏     | 104/247 [00:17<00:25,  5.57it/s]predicting train subjects:  43%|████▎     | 105/247 [00:17<00:25,  5.61it/s]predicting train subjects:  43%|████▎     | 106/247 [00:17<00:24,  5.64it/s]predicting train subjects:  43%|████▎     | 107/247 [00:17<00:24,  5.67it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:24,  5.67it/s]predicting train subjects:  44%|████▍     | 109/247 [00:18<00:24,  5.57it/s]predicting train subjects:  45%|████▍     | 110/247 [00:18<00:24,  5.60it/s]predicting train subjects:  45%|████▍     | 111/247 [00:18<00:24,  5.64it/s]predicting train subjects:  45%|████▌     | 112/247 [00:18<00:24,  5.61it/s]predicting train subjects:  46%|████▌     | 113/247 [00:18<00:24,  5.42it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:24,  5.35it/s]predicting train subjects:  47%|████▋     | 115/247 [00:19<00:24,  5.46it/s]predicting train subjects:  47%|████▋     | 116/247 [00:19<00:23,  5.53it/s]predicting train subjects:  47%|████▋     | 117/247 [00:19<00:23,  5.59it/s]predicting train subjects:  48%|████▊     | 118/247 [00:19<00:21,  5.94it/s]predicting train subjects:  48%|████▊     | 119/247 [00:19<00:20,  6.22it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:19,  6.43it/s]predicting train subjects:  49%|████▉     | 121/247 [00:20<00:19,  6.52it/s]predicting train subjects:  49%|████▉     | 122/247 [00:20<00:19,  6.51it/s]predicting train subjects:  50%|████▉     | 123/247 [00:20<00:18,  6.57it/s]predicting train subjects:  50%|█████     | 124/247 [00:20<00:18,  6.62it/s]predicting train subjects:  51%|█████     | 125/247 [00:20<00:18,  6.70it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:17,  6.75it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:17,  6.78it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:21<00:17,  6.62it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:21<00:17,  6.69it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:21<00:17,  6.69it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:21<00:17,  6.68it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:21<00:17,  6.74it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:16,  6.75it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:22<00:16,  6.78it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:22<00:16,  6.62it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:22<00:16,  6.63it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:22<00:16,  6.64it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:22<00:16,  6.53it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:16,  6.57it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:16,  6.53it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:23<00:16,  6.28it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:23<00:16,  6.30it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:23<00:16,  6.41it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:23<00:15,  6.46it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:23<00:15,  6.54it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:15,  6.59it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:24<00:15,  6.66it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:24<00:14,  6.65it/s]predicting train subjects:  60%|██████    | 149/247 [00:24<00:14,  6.64it/s]predicting train subjects:  61%|██████    | 150/247 [00:24<00:14,  6.66it/s]predicting train subjects:  61%|██████    | 151/247 [00:24<00:14,  6.68it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:24<00:14,  6.70it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:13,  6.73it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:25<00:14,  6.38it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:25<00:15,  6.08it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:25<00:15,  5.98it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:25<00:15,  5.91it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:25<00:15,  5.82it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:15,  5.68it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:26<00:15,  5.64it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:26<00:15,  5.57it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:26<00:15,  5.63it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:26<00:15,  5.54it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:26<00:14,  5.54it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:27<00:14,  5.59it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:27<00:14,  5.57it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:27<00:14,  5.62it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:27<00:13,  5.67it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:27<00:13,  5.66it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:27<00:13,  5.52it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:28<00:14,  5.40it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:28<00:13,  5.71it/s]predicting train subjects:  70%|███████   | 173/247 [00:28<00:16,  4.55it/s]predicting train subjects:  70%|███████   | 174/247 [00:28<00:14,  5.03it/s]predicting train subjects:  71%|███████   | 175/247 [00:29<00:15,  4.74it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:29<00:13,  5.15it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:29<00:12,  5.48it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:29<00:12,  5.71it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:29<00:11,  5.83it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:29<00:11,  6.01it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:29<00:10,  6.12it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:30<00:10,  6.26it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:30<00:10,  6.32it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:30<00:09,  6.42it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:30<00:09,  6.46it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:30<00:09,  6.44it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:30<00:09,  6.45it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:31<00:09,  6.37it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:31<00:09,  6.39it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:31<00:08,  6.45it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:31<00:08,  6.49it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:31<00:08,  6.39it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:31<00:08,  6.45it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:31<00:08,  6.50it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:32<00:07,  6.60it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:32<00:07,  6.67it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:32<00:07,  6.60it/s]predicting train subjects:  80%|████████  | 198/247 [00:32<00:07,  6.73it/s]predicting train subjects:  81%|████████  | 199/247 [00:32<00:07,  6.69it/s]predicting train subjects:  81%|████████  | 200/247 [00:32<00:06,  6.79it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:32<00:06,  6.85it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:33<00:06,  6.82it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:33<00:06,  6.80it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:33<00:06,  6.84it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:33<00:06,  6.48it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:33<00:06,  6.60it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:33<00:06,  6.66it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:34<00:05,  6.54it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:34<00:05,  6.63it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:34<00:05,  6.74it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:34<00:05,  6.71it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:34<00:05,  6.63it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:34<00:05,  6.63it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:34<00:04,  6.65it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:35<00:04,  6.64it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:35<00:04,  6.64it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:35<00:04,  6.64it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:35<00:04,  6.59it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:35<00:04,  6.66it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:35<00:04,  6.62it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:35<00:03,  6.70it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:36<00:03,  6.73it/s]predicting train subjects:  90%|█████████ | 223/247 [00:36<00:03,  6.62it/s]predicting train subjects:  91%|█████████ | 224/247 [00:36<00:03,  6.67it/s]predicting train subjects:  91%|█████████ | 225/247 [00:36<00:03,  6.63it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:36<00:03,  6.49it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:36<00:03,  6.45it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:37<00:02,  6.41it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:37<00:02,  6.43it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:37<00:02,  6.25it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:37<00:02,  6.10it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:37<00:02,  6.02it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:37<00:02,  5.82it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:38<00:02,  5.79it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:38<00:02,  5.78it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:38<00:01,  5.79it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:38<00:01,  5.67it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:38<00:01,  5.71it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:38<00:01,  5.77it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:39<00:01,  5.69it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:39<00:01,  5.66it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:39<00:00,  5.74it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:39<00:00,  5.80it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:39<00:00,  5.79it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:40<00:00,  5.80it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:40<00:00,  5.67it/s]predicting train subjects: 100%|██████████| 247/247 [00:40<00:00,  5.69it/s]predicting train subjects: 100%|██████████| 247/247 [00:40<00:00,  6.12it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  6.13it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  5.85it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  5.76it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  6.06it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.22it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  6.04it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:37,  6.51it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:37,  6.62it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:36,  6.65it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:37,  6.55it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:37,  6.53it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:36,  6.53it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:01<00:36,  6.53it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:01<00:37,  6.41it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:36,  6.44it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:38,  6.23it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:38,  6.19it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:37,  6.29it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:02<00:36,  6.37it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:02<00:37,  6.26it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:02<00:36,  6.33it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:02<00:36,  6.30it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:36,  6.32it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:36,  6.35it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:35,  6.41it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:03<00:35,  6.46it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:03<00:35,  6.35it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:03<00:35,  6.32it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:03<00:34,  6.44it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:03<00:34,  6.38it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:34,  6.35it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:04<00:33,  6.50it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:04<00:34,  6.37it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:04<00:33,  6.47it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:04<00:33,  6.53it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:04<00:32,  6.59it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:04<00:32,  6.69it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:04<00:31,  6.72it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:05<00:31,  6.77it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:05<00:31,  6.82it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:05<00:31,  6.84it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:05<00:31,  6.80it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:05<00:30,  6.80it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:05<00:30,  6.78it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:05<00:30,  6.76it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:06<00:30,  6.76it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:06<00:31,  6.64it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:06<00:31,  6.57it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:06<00:30,  6.64it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:06<00:30,  6.69it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:06<00:30,  6.69it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:07<00:30,  6.70it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:07<00:30,  6.66it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:07<00:29,  6.72it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:07<00:29,  6.72it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:07<00:29,  6.57it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:07<00:29,  6.57it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:07<00:29,  6.63it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:08<00:29,  6.63it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:08<00:29,  6.49it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:08<00:29,  6.42it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:08<00:29,  6.52it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:08<00:29,  6.36it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:08<00:29,  6.42it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:09<00:29,  6.35it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:09<00:30,  6.21it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:09<00:29,  6.24it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:09<00:29,  6.21it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:09<00:29,  6.27it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:09<00:29,  6.28it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:10<00:28,  6.31it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:10<00:28,  6.33it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:10<00:28,  6.29it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:10<00:28,  6.30it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:10<00:28,  6.35it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:10<00:28,  6.26it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:10<00:28,  6.24it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:11<00:27,  6.30it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:11<00:27,  6.33it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:11<00:27,  6.31it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:11<00:27,  6.19it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:11<00:27,  6.26it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:11<00:28,  6.03it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:12<00:28,  5.91it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:12<00:27,  6.17it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:12<00:26,  6.34it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:12<00:28,  5.86it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:12<00:28,  5.76it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:12<00:28,  5.66it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:13<00:28,  5.62it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:13<00:28,  5.62it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:13<00:28,  5.62it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:13<00:28,  5.55it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:13<00:28,  5.55it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:14<00:28,  5.57it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:14<00:28,  5.57it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:14<00:28,  5.54it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:14<00:28,  5.45it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:14<00:28,  5.44it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:14<00:28,  5.37it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:15<00:28,  5.31it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:15<00:28,  5.36it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:15<00:28,  5.31it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:15<00:27,  5.39it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:15<00:27,  5.42it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:16<00:26,  5.50it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:16<00:26,  5.50it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:16<00:26,  5.53it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:16<00:25,  5.58it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:16<00:25,  5.60it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:16<00:25,  5.61it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:17<00:25,  5.61it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:17<00:25,  5.54it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:17<00:24,  5.60it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:17<00:24,  5.62it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:17<00:25,  5.34it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:18<00:25,  5.39it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:18<00:24,  5.49it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:18<00:24,  5.53it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:18<00:23,  5.56it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:18<00:23,  5.58it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:18<00:23,  5.47it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:19<00:23,  5.57it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:19<00:21,  5.90it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:19<00:20,  6.15it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:19<00:19,  6.38it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:19<00:19,  6.33it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:19<00:19,  6.49it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:20<00:19,  6.51it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:20<00:18,  6.63it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:20<00:18,  6.45it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:20<00:18,  6.62it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:20<00:17,  6.73it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:20<00:17,  6.76it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:20<00:17,  6.56it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:21<00:17,  6.68it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:21<00:17,  6.78it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:21<00:17,  6.71it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:21<00:16,  6.75it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:21<00:16,  6.80it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:21<00:16,  6.66it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:21<00:16,  6.66it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:22<00:17,  6.37it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:22<00:16,  6.50it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:22<00:16,  6.61it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:22<00:16,  6.49it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:22<00:16,  6.59it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:22<00:16,  6.52it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:23<00:15,  6.57it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:23<00:15,  6.60it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:23<00:15,  6.59it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:23<00:15,  6.68it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:23<00:14,  6.72it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:23<00:14,  6.76it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:23<00:14,  6.74it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:24<00:14,  6.61it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:24<00:14,  6.42it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:24<00:15,  6.24it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:24<00:15,  6.14it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:24<00:15,  5.96it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:24<00:16,  5.74it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:25<00:16,  5.54it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:25<00:16,  5.56it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:25<00:16,  5.28it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:25<00:16,  5.40it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:25<00:16,  5.42it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:26<00:16,  5.35it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:26<00:15,  5.42it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:26<00:15,  5.51it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:26<00:14,  5.55it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:26<00:14,  5.64it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:26<00:14,  5.71it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:27<00:13,  5.72it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:27<00:13,  5.73it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:27<00:13,  5.70it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:27<00:14,  5.47it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:27<00:13,  5.51it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:28<00:12,  5.81it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:28<00:12,  6.03it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:28<00:11,  6.24it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:28<00:11,  6.09it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:28<00:11,  6.25it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:28<00:10,  6.37it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:28<00:10,  6.47it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:29<00:10,  6.56it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:29<00:10,  6.63it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:29<00:09,  6.67it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:29<00:09,  6.51it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:29<00:09,  6.49it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:29<00:09,  6.55it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:30<00:09,  6.57it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:30<00:09,  6.48it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:30<00:09,  6.56it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:30<00:09,  6.37it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:30<00:09,  6.40it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:30<00:08,  6.45it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:30<00:08,  6.47it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:31<00:08,  6.39it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:31<00:08,  6.41it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:31<00:08,  6.60it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:31<00:07,  6.74it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:31<00:07,  6.85it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:31<00:07,  6.89it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:31<00:07,  6.92it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:32<00:06,  6.92it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:32<00:06,  6.84it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:32<00:06,  6.90it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:32<00:06,  6.95it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:32<00:06,  6.85it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:32<00:06,  6.81it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:33<00:06,  6.82it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:33<00:05,  6.91it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:33<00:05,  6.98it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:33<00:05,  6.81it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:33<00:05,  6.83it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:33<00:05,  6.80it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:33<00:05,  6.80it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:34<00:05,  6.49it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:34<00:05,  6.15it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:34<00:05,  5.69it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:34<00:05,  5.84it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:34<00:05,  6.06it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:34<00:04,  6.17it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:35<00:04,  6.35it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:35<00:04,  6.39it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:35<00:04,  6.38it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:35<00:03,  6.51it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:35<00:03,  6.54it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:35<00:03,  6.63it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:35<00:03,  6.57it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:36<00:03,  6.61it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:36<00:03,  6.62it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:36<00:02,  6.67it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:36<00:02,  6.59it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:36<00:02,  6.61it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:36<00:02,  6.35it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:37<00:02,  6.09it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:37<00:02,  5.92it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:37<00:02,  5.89it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:37<00:02,  5.89it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:37<00:02,  5.82it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:37<00:01,  5.68it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:38<00:01,  5.67it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:38<00:01,  5.72it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:38<00:01,  5.75it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:38<00:01,  5.75it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:38<00:01,  5.81it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:39<00:00,  5.65it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:39<00:00,  5.64it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:39<00:00,  5.69it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:39<00:00,  5.71it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:39<00:00,  5.74it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  5.71it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:39<00:00,  6.19it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 63.34it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 79.61it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/247 [00:00<00:02, 79.95it/s]saving BB  train1-THALAMUS:  11%|█         | 27/247 [00:00<00:02, 80.28it/s]saving BB  train1-THALAMUS:  15%|█▍        | 36/247 [00:00<00:02, 82.66it/s]saving BB  train1-THALAMUS:  18%|█▊        | 45/247 [00:00<00:02, 84.36it/s]saving BB  train1-THALAMUS:  22%|██▏       | 55/247 [00:00<00:02, 86.22it/s]saving BB  train1-THALAMUS:  26%|██▌       | 63/247 [00:00<00:02, 83.69it/s]saving BB  train1-THALAMUS:  29%|██▊       | 71/247 [00:00<00:02, 81.06it/s]saving BB  train1-THALAMUS:  32%|███▏      | 79/247 [00:00<00:02, 79.93it/s]saving BB  train1-THALAMUS:  35%|███▌      | 87/247 [00:01<00:02, 77.80it/s]saving BB  train1-THALAMUS:  38%|███▊      | 95/247 [00:01<00:02, 75.71it/s]saving BB  train1-THALAMUS:  42%|████▏     | 103/247 [00:01<00:01, 75.65it/s]saving BB  train1-THALAMUS:  45%|████▍     | 111/247 [00:01<00:01, 75.60it/s]saving BB  train1-THALAMUS:  48%|████▊     | 119/247 [00:01<00:01, 76.47it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 128/247 [00:01<00:01, 77.71it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 136/247 [00:01<00:01, 74.50it/s]saving BB  train1-THALAMUS:  59%|█████▊    | 145/247 [00:01<00:01, 78.22it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 155/247 [00:01<00:01, 81.50it/s]saving BB  train1-THALAMUS:  66%|██████▋   | 164/247 [00:02<00:01, 80.25it/s]saving BB  train1-THALAMUS:  70%|███████   | 173/247 [00:02<00:00, 75.43it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 181/247 [00:02<00:00, 71.81it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 189/247 [00:02<00:00, 72.75it/s]saving BB  train1-THALAMUS:  80%|████████  | 198/247 [00:02<00:00, 75.43it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 207/247 [00:02<00:00, 78.67it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 216/247 [00:02<00:00, 81.47it/s]saving BB  train1-THALAMUS:  91%|█████████ | 225/247 [00:02<00:00, 83.30it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 234/247 [00:02<00:00, 83.18it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 243/247 [00:03<00:00, 81.66it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 79.39it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 79.30it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 85.15it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 85.15it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 86.19it/s]saving BB  train1-THALAMUS Sagittal:  14%|█▍        | 35/247 [00:00<00:02, 82.95it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 45/247 [00:00<00:02, 85.89it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 55/247 [00:00<00:02, 87.45it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 64/247 [00:00<00:02, 86.65it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 72/247 [00:00<00:02, 84.32it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 81/247 [00:00<00:01, 83.15it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 89/247 [00:01<00:02, 78.49it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▉      | 97/247 [00:01<00:01, 75.98it/s]saving BB  train1-THALAMUS Sagittal:  43%|████▎     | 105/247 [00:01<00:01, 75.71it/s]saving BB  train1-THALAMUS Sagittal:  46%|████▌     | 113/247 [00:01<00:01, 76.66it/s]saving BB  train1-THALAMUS Sagittal:  49%|████▉     | 122/247 [00:01<00:01, 77.98it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 130/247 [00:01<00:01, 77.78it/s]saving BB  train1-THALAMUS Sagittal:  56%|█████▋    | 139/247 [00:01<00:01, 79.51it/s]saving BB  train1-THALAMUS Sagittal:  60%|██████    | 149/247 [00:01<00:01, 82.60it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▍   | 158/247 [00:01<00:01, 81.94it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 167/247 [00:02<00:00, 81.45it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████▏  | 176/247 [00:02<00:00, 79.75it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▍  | 184/247 [00:02<00:00, 76.31it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 193/247 [00:02<00:00, 78.05it/s]saving BB  train1-THALAMUS Sagittal:  82%|████████▏ | 202/247 [00:02<00:00, 80.22it/s]saving BB  train1-THALAMUS Sagittal:  85%|████████▌ | 211/247 [00:02<00:00, 81.75it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▉ | 220/247 [00:02<00:00, 82.03it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 229/247 [00:02<00:00, 82.86it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▋| 238/247 [00:02<00:00, 80.87it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 79.03it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 80.98it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:34,  1.15it/s]Loading train:   1%|          | 2/247 [00:01<03:25,  1.19it/s]Loading train:   1%|          | 3/247 [00:02<03:16,  1.24it/s]Loading train:   2%|▏         | 4/247 [00:03<03:22,  1.20it/s]Loading train:   2%|▏         | 5/247 [00:03<03:00,  1.34it/s]Loading train:   2%|▏         | 6/247 [00:04<02:42,  1.49it/s]Loading train:   3%|▎         | 7/247 [00:04<02:28,  1.62it/s]Loading train:   3%|▎         | 8/247 [00:05<02:19,  1.71it/s]Loading train:   4%|▎         | 9/247 [00:05<02:15,  1.76it/s]Loading train:   4%|▍         | 10/247 [00:06<02:12,  1.78it/s]Loading train:   4%|▍         | 11/247 [00:06<02:11,  1.80it/s]Loading train:   5%|▍         | 12/247 [00:07<02:08,  1.83it/s]Loading train:   5%|▌         | 13/247 [00:07<02:07,  1.84it/s]Loading train:   6%|▌         | 14/247 [00:08<02:06,  1.85it/s]Loading train:   6%|▌         | 15/247 [00:09<02:08,  1.80it/s]Loading train:   6%|▋         | 16/247 [00:09<02:06,  1.83it/s]Loading train:   7%|▋         | 17/247 [00:10<02:02,  1.89it/s]Loading train:   7%|▋         | 18/247 [00:10<02:00,  1.91it/s]Loading train:   8%|▊         | 19/247 [00:11<01:56,  1.95it/s]Loading train:   8%|▊         | 20/247 [00:11<01:57,  1.93it/s]Loading train:   9%|▊         | 21/247 [00:12<02:03,  1.83it/s]Loading train:   9%|▉         | 22/247 [00:12<02:04,  1.81it/s]Loading train:   9%|▉         | 23/247 [00:13<02:02,  1.83it/s]Loading train:  10%|▉         | 24/247 [00:13<01:56,  1.91it/s]Loading train:  10%|█         | 25/247 [00:14<01:53,  1.96it/s]Loading train:  11%|█         | 26/247 [00:14<01:52,  1.96it/s]Loading train:  11%|█         | 27/247 [00:15<01:54,  1.93it/s]Loading train:  11%|█▏        | 28/247 [00:15<01:53,  1.93it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:54,  1.90it/s]Loading train:  12%|█▏        | 30/247 [00:16<01:52,  1.93it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:50,  1.95it/s]Loading train:  13%|█▎        | 32/247 [00:17<01:48,  1.98it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:47,  2.00it/s]Loading train:  14%|█▍        | 34/247 [00:18<01:48,  1.96it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:46,  1.98it/s]Loading train:  15%|█▍        | 36/247 [00:19<01:47,  1.97it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:46,  1.97it/s]Loading train:  15%|█▌        | 38/247 [00:20<01:44,  2.00it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:42,  2.03it/s]Loading train:  16%|█▌        | 40/247 [00:21<01:42,  2.02it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:42,  2.01it/s]Loading train:  17%|█▋        | 42/247 [00:22<01:42,  2.01it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:45,  1.93it/s]Loading train:  18%|█▊        | 44/247 [00:23<01:45,  1.93it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:43,  1.96it/s]Loading train:  19%|█▊        | 46/247 [00:24<01:39,  2.03it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:36,  2.07it/s]Loading train:  19%|█▉        | 48/247 [00:25<01:35,  2.09it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:34,  2.09it/s]Loading train:  20%|██        | 50/247 [00:26<01:34,  2.07it/s]Loading train:  21%|██        | 51/247 [00:27<01:36,  2.03it/s]Loading train:  21%|██        | 52/247 [00:27<01:35,  2.05it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:35,  2.02it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:34,  2.04it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:32,  2.07it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:31,  2.08it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:32,  2.06it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:31,  2.06it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:36,  1.94it/s]Loading train:  24%|██▍       | 60/247 [00:31<01:41,  1.84it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:46,  1.75it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:46,  1.73it/s]Loading train:  26%|██▌       | 63/247 [00:33<01:46,  1.73it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:44,  1.76it/s]Loading train:  26%|██▋       | 65/247 [00:34<01:42,  1.78it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:40,  1.80it/s]Loading train:  27%|██▋       | 67/247 [00:35<01:40,  1.80it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:40,  1.78it/s]Loading train:  28%|██▊       | 69/247 [00:37<01:42,  1.74it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:42,  1.72it/s]Loading train:  29%|██▊       | 71/247 [00:38<01:43,  1.69it/s]Loading train:  29%|██▉       | 72/247 [00:38<01:44,  1.67it/s]Loading train:  30%|██▉       | 73/247 [00:39<01:43,  1.68it/s]Loading train:  30%|██▉       | 74/247 [00:40<01:42,  1.68it/s]Loading train:  30%|███       | 75/247 [00:40<01:40,  1.71it/s]Loading train:  31%|███       | 76/247 [00:41<01:40,  1.70it/s]Loading train:  31%|███       | 77/247 [00:42<02:02,  1.39it/s]Loading train:  32%|███▏      | 78/247 [00:43<02:14,  1.26it/s]Loading train:  32%|███▏      | 79/247 [00:44<02:14,  1.25it/s]Loading train:  32%|███▏      | 80/247 [00:44<02:12,  1.26it/s]Loading train:  33%|███▎      | 81/247 [00:45<02:22,  1.16it/s]Loading train:  33%|███▎      | 82/247 [00:46<02:10,  1.26it/s]Loading train:  34%|███▎      | 83/247 [00:47<02:01,  1.35it/s]Loading train:  34%|███▍      | 84/247 [00:47<01:53,  1.44it/s]Loading train:  34%|███▍      | 85/247 [00:48<01:48,  1.50it/s]Loading train:  35%|███▍      | 86/247 [00:48<01:47,  1.49it/s]Loading train:  35%|███▌      | 87/247 [00:49<01:47,  1.49it/s]Loading train:  36%|███▌      | 88/247 [00:50<01:47,  1.48it/s]Loading train:  36%|███▌      | 89/247 [00:51<01:45,  1.49it/s]Loading train:  36%|███▋      | 90/247 [00:51<01:42,  1.53it/s]Loading train:  37%|███▋      | 91/247 [00:52<01:39,  1.57it/s]Loading train:  37%|███▋      | 92/247 [00:52<01:39,  1.56it/s]Loading train:  38%|███▊      | 93/247 [00:53<01:36,  1.59it/s]Loading train:  38%|███▊      | 94/247 [00:54<01:34,  1.62it/s]Loading train:  38%|███▊      | 95/247 [00:54<01:34,  1.62it/s]Loading train:  39%|███▉      | 96/247 [00:55<01:34,  1.59it/s]Loading train:  39%|███▉      | 97/247 [00:56<01:36,  1.56it/s]Loading train:  40%|███▉      | 98/247 [00:56<01:36,  1.55it/s]Loading train:  40%|████      | 99/247 [00:57<01:35,  1.55it/s]Loading train:  40%|████      | 100/247 [00:57<01:33,  1.57it/s]Loading train:  41%|████      | 101/247 [00:58<01:31,  1.60it/s]Loading train:  41%|████▏     | 102/247 [00:59<01:29,  1.63it/s]Loading train:  42%|████▏     | 103/247 [00:59<01:27,  1.65it/s]Loading train:  42%|████▏     | 104/247 [01:00<01:27,  1.64it/s]Loading train:  43%|████▎     | 105/247 [01:00<01:27,  1.63it/s]Loading train:  43%|████▎     | 106/247 [01:01<01:25,  1.65it/s]Loading train:  43%|████▎     | 107/247 [01:02<01:25,  1.64it/s]Loading train:  44%|████▎     | 108/247 [01:02<01:25,  1.62it/s]Loading train:  44%|████▍     | 109/247 [01:03<01:25,  1.62it/s]Loading train:  45%|████▍     | 110/247 [01:04<01:25,  1.60it/s]Loading train:  45%|████▍     | 111/247 [01:04<01:22,  1.65it/s]Loading train:  45%|████▌     | 112/247 [01:05<01:20,  1.68it/s]Loading train:  46%|████▌     | 113/247 [01:05<01:20,  1.67it/s]Loading train:  46%|████▌     | 114/247 [01:06<01:19,  1.68it/s]Loading train:  47%|████▋     | 115/247 [01:06<01:19,  1.66it/s]Loading train:  47%|████▋     | 116/247 [01:07<01:18,  1.68it/s]Loading train:  47%|████▋     | 117/247 [01:08<01:19,  1.64it/s]Loading train:  48%|████▊     | 118/247 [01:08<01:19,  1.62it/s]Loading train:  48%|████▊     | 119/247 [01:09<01:18,  1.64it/s]Loading train:  49%|████▊     | 120/247 [01:10<01:16,  1.67it/s]Loading train:  49%|████▉     | 121/247 [01:10<01:15,  1.67it/s]Loading train:  49%|████▉     | 122/247 [01:11<01:12,  1.71it/s]Loading train:  50%|████▉     | 123/247 [01:11<01:10,  1.75it/s]Loading train:  50%|█████     | 124/247 [01:12<01:10,  1.74it/s]Loading train:  51%|█████     | 125/247 [01:12<01:09,  1.74it/s]Loading train:  51%|█████     | 126/247 [01:13<01:11,  1.70it/s]Loading train:  51%|█████▏    | 127/247 [01:14<01:09,  1.71it/s]Loading train:  52%|█████▏    | 128/247 [01:14<01:09,  1.70it/s]Loading train:  52%|█████▏    | 129/247 [01:15<01:09,  1.71it/s]Loading train:  53%|█████▎    | 130/247 [01:15<01:07,  1.74it/s]Loading train:  53%|█████▎    | 131/247 [01:16<01:06,  1.74it/s]Loading train:  53%|█████▎    | 132/247 [01:16<01:06,  1.73it/s]Loading train:  54%|█████▍    | 133/247 [01:17<01:05,  1.74it/s]Loading train:  54%|█████▍    | 134/247 [01:18<01:05,  1.73it/s]Loading train:  55%|█████▍    | 135/247 [01:18<01:05,  1.72it/s]Loading train:  55%|█████▌    | 136/247 [01:19<01:02,  1.76it/s]Loading train:  55%|█████▌    | 137/247 [01:19<01:01,  1.80it/s]Loading train:  56%|█████▌    | 138/247 [01:20<00:58,  1.85it/s]Loading train:  56%|█████▋    | 139/247 [01:20<00:57,  1.88it/s]Loading train:  57%|█████▋    | 140/247 [01:21<00:56,  1.90it/s]Loading train:  57%|█████▋    | 141/247 [01:21<00:54,  1.93it/s]Loading train:  57%|█████▋    | 142/247 [01:22<00:55,  1.89it/s]Loading train:  58%|█████▊    | 143/247 [01:22<00:55,  1.89it/s]Loading train:  58%|█████▊    | 144/247 [01:23<00:54,  1.88it/s]Loading train:  59%|█████▊    | 145/247 [01:23<00:55,  1.85it/s]Loading train:  59%|█████▉    | 146/247 [01:24<00:54,  1.86it/s]Loading train:  60%|█████▉    | 147/247 [01:25<00:53,  1.88it/s]Loading train:  60%|█████▉    | 148/247 [01:25<00:51,  1.92it/s]Loading train:  60%|██████    | 149/247 [01:26<00:50,  1.93it/s]Loading train:  61%|██████    | 150/247 [01:26<00:50,  1.92it/s]Loading train:  61%|██████    | 151/247 [01:27<00:50,  1.90it/s]Loading train:  62%|██████▏   | 152/247 [01:27<00:49,  1.92it/s]Loading train:  62%|██████▏   | 153/247 [01:28<00:48,  1.93it/s]Loading train:  62%|██████▏   | 154/247 [01:28<00:51,  1.81it/s]Loading train:  63%|██████▎   | 155/247 [01:29<00:52,  1.77it/s]Loading train:  63%|██████▎   | 156/247 [01:29<00:51,  1.75it/s]Loading train:  64%|██████▎   | 157/247 [01:30<00:51,  1.75it/s]Loading train:  64%|██████▍   | 158/247 [01:31<00:51,  1.73it/s]Loading train:  64%|██████▍   | 159/247 [01:31<00:51,  1.71it/s]Loading train:  65%|██████▍   | 160/247 [01:32<00:51,  1.69it/s]Loading train:  65%|██████▌   | 161/247 [01:32<00:50,  1.69it/s]Loading train:  66%|██████▌   | 162/247 [01:33<00:50,  1.69it/s]Loading train:  66%|██████▌   | 163/247 [01:34<00:50,  1.66it/s]Loading train:  66%|██████▋   | 164/247 [01:34<00:49,  1.67it/s]Loading train:  67%|██████▋   | 165/247 [01:35<00:49,  1.66it/s]Loading train:  67%|██████▋   | 166/247 [01:35<00:47,  1.69it/s]Loading train:  68%|██████▊   | 167/247 [01:36<00:47,  1.68it/s]Loading train:  68%|██████▊   | 168/247 [01:37<00:47,  1.66it/s]Loading train:  68%|██████▊   | 169/247 [01:37<00:47,  1.63it/s]Loading train:  69%|██████▉   | 170/247 [01:38<00:47,  1.63it/s]Loading train:  69%|██████▉   | 171/247 [01:38<00:45,  1.65it/s]Loading train:  70%|██████▉   | 172/247 [01:39<00:51,  1.45it/s]Loading train:  70%|███████   | 173/247 [01:40<00:52,  1.41it/s]Loading train:  70%|███████   | 174/247 [01:41<00:53,  1.37it/s]Loading train:  71%|███████   | 175/247 [01:42<00:57,  1.25it/s]Loading train:  71%|███████▏  | 176/247 [01:42<00:52,  1.36it/s]Loading train:  72%|███████▏  | 177/247 [01:43<00:48,  1.46it/s]Loading train:  72%|███████▏  | 178/247 [01:44<00:45,  1.52it/s]Loading train:  72%|███████▏  | 179/247 [01:44<00:42,  1.61it/s]Loading train:  73%|███████▎  | 180/247 [01:45<00:40,  1.66it/s]Loading train:  73%|███████▎  | 181/247 [01:45<00:38,  1.72it/s]Loading train:  74%|███████▎  | 182/247 [01:46<00:36,  1.76it/s]Loading train:  74%|███████▍  | 183/247 [01:46<00:36,  1.78it/s]Loading train:  74%|███████▍  | 184/247 [01:47<00:35,  1.79it/s]Loading train:  75%|███████▍  | 185/247 [01:47<00:34,  1.81it/s]Loading train:  75%|███████▌  | 186/247 [01:48<00:33,  1.82it/s]Loading train:  76%|███████▌  | 187/247 [01:48<00:33,  1.80it/s]Loading train:  76%|███████▌  | 188/247 [01:49<00:32,  1.80it/s]Loading train:  77%|███████▋  | 189/247 [01:50<00:32,  1.79it/s]Loading train:  77%|███████▋  | 190/247 [01:50<00:31,  1.79it/s]Loading train:  77%|███████▋  | 191/247 [01:51<00:30,  1.82it/s]Loading train:  78%|███████▊  | 192/247 [01:51<00:30,  1.81it/s]Loading train:  78%|███████▊  | 193/247 [01:52<00:29,  1.81it/s]Loading train:  79%|███████▊  | 194/247 [01:52<00:28,  1.85it/s]Loading train:  79%|███████▉  | 195/247 [01:53<00:28,  1.84it/s]Loading train:  79%|███████▉  | 196/247 [01:53<00:28,  1.82it/s]Loading train:  80%|███████▉  | 197/247 [01:54<00:27,  1.83it/s]Loading train:  80%|████████  | 198/247 [01:54<00:26,  1.84it/s]Loading train:  81%|████████  | 199/247 [01:55<00:25,  1.85it/s]Loading train:  81%|████████  | 200/247 [01:56<00:25,  1.86it/s]Loading train:  81%|████████▏ | 201/247 [01:56<00:24,  1.85it/s]Loading train:  82%|████████▏ | 202/247 [01:57<00:24,  1.85it/s]Loading train:  82%|████████▏ | 203/247 [01:57<00:23,  1.85it/s]Loading train:  83%|████████▎ | 204/247 [01:58<00:23,  1.83it/s]Loading train:  83%|████████▎ | 205/247 [01:58<00:22,  1.84it/s]Loading train:  83%|████████▎ | 206/247 [01:59<00:22,  1.85it/s]Loading train:  84%|████████▍ | 207/247 [01:59<00:21,  1.87it/s]Loading train:  84%|████████▍ | 208/247 [02:00<00:21,  1.85it/s]Loading train:  85%|████████▍ | 209/247 [02:00<00:20,  1.88it/s]Loading train:  85%|████████▌ | 210/247 [02:02<00:26,  1.40it/s]Loading train:  85%|████████▌ | 211/247 [02:05<00:50,  1.40s/it]Loading train:  86%|████████▌ | 212/247 [02:08<01:15,  2.16s/it]Loading train:  86%|████████▌ | 213/247 [02:12<01:27,  2.57s/it]Loading train:  87%|████████▋ | 214/247 [02:15<01:33,  2.83s/it]Loading train:  87%|████████▋ | 215/247 [02:19<01:41,  3.19s/it]Loading train:  87%|████████▋ | 216/247 [02:23<01:45,  3.40s/it]Loading train:  88%|████████▊ | 217/247 [02:27<01:45,  3.52s/it]Loading train:  88%|████████▊ | 218/247 [02:31<01:44,  3.60s/it]Loading train:  89%|████████▊ | 219/247 [02:35<01:40,  3.59s/it]Loading train:  89%|████████▉ | 220/247 [02:38<01:39,  3.68s/it]Loading train:  89%|████████▉ | 221/247 [02:42<01:37,  3.75s/it]Loading train:  90%|████████▉ | 222/247 [02:46<01:35,  3.81s/it]Loading train:  90%|█████████ | 223/247 [02:50<01:32,  3.84s/it]Loading train:  91%|█████████ | 224/247 [02:54<01:28,  3.85s/it]Loading train:  91%|█████████ | 225/247 [02:58<01:25,  3.89s/it]Loading train:  91%|█████████▏| 226/247 [03:02<01:20,  3.85s/it]Loading train:  92%|█████████▏| 227/247 [03:06<01:16,  3.84s/it]Loading train:  92%|█████████▏| 228/247 [03:09<01:12,  3.83s/it]Loading train:  93%|█████████▎| 229/247 [03:13<01:06,  3.71s/it]Loading train:  93%|█████████▎| 230/247 [03:18<01:12,  4.24s/it]Loading train:  94%|█████████▎| 231/247 [03:24<01:16,  4.78s/it]Loading train:  94%|█████████▍| 232/247 [03:31<01:18,  5.21s/it]Loading train:  94%|█████████▍| 233/247 [03:36<01:13,  5.27s/it]Loading train:  95%|█████████▍| 234/247 [03:42<01:12,  5.56s/it]Loading train:  95%|█████████▌| 235/247 [03:48<01:08,  5.72s/it]Loading train:  96%|█████████▌| 236/247 [03:54<01:03,  5.73s/it]Loading train:  96%|█████████▌| 237/247 [04:00<00:58,  5.83s/it]Loading train:  96%|█████████▋| 238/247 [04:06<00:53,  5.91s/it]Loading train:  97%|█████████▋| 239/247 [04:12<00:47,  5.92s/it]Loading train:  97%|█████████▋| 240/247 [04:18<00:41,  5.94s/it]Loading train:  98%|█████████▊| 241/247 [04:24<00:35,  5.96s/it]Loading train:  98%|█████████▊| 242/247 [04:30<00:30,  6.03s/it]Loading train:  98%|█████████▊| 243/247 [04:36<00:23,  5.78s/it]Loading train:  99%|█████████▉| 244/247 [04:41<00:17,  5.80s/it]Loading train:  99%|█████████▉| 245/247 [04:46<00:11,  5.58s/it]Loading train: 100%|█████████▉| 246/247 [04:53<00:05,  5.73s/it]Loading train: 100%|██████████| 247/247 [04:59<00:00,  5.81s/it]Loading train: 100%|██████████| 247/247 [04:59<00:00,  1.21s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 51.03it/s]concatenating: train:   5%|▍         | 12/247 [00:00<00:04, 50.78it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:04, 50.84it/s]concatenating: train:   9%|▉         | 23/247 [00:00<00:04, 50.30it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:04, 50.56it/s]concatenating: train:  14%|█▍        | 35/247 [00:00<00:04, 50.61it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:04, 50.82it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 51.24it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:03, 51.97it/s]concatenating: train:  23%|██▎       | 58/247 [00:01<00:03, 51.18it/s]concatenating: train:  26%|██▌       | 63/247 [00:01<00:03, 49.55it/s]concatenating: train:  28%|██▊       | 68/247 [00:01<00:03, 48.31it/s]concatenating: train:  30%|██▉       | 73/247 [00:01<00:03, 47.75it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:03, 47.67it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 46.30it/s]concatenating: train:  36%|███▌      | 88/247 [00:01<00:03, 45.85it/s]concatenating: train:  38%|███▊      | 93/247 [00:01<00:03, 45.36it/s]concatenating: train:  40%|███▉      | 98/247 [00:02<00:03, 45.36it/s]concatenating: train:  42%|████▏     | 103/247 [00:02<00:03, 45.99it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:02, 46.80it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:03, 44.63it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:02, 44.48it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 43.67it/s]concatenating: train:  52%|█████▏    | 128/247 [00:02<00:02, 42.21it/s]concatenating: train:  54%|█████▍    | 133/247 [00:02<00:02, 42.07it/s]concatenating: train:  56%|█████▌    | 138/247 [00:02<00:02, 43.21it/s]concatenating: train:  58%|█████▊    | 143/247 [00:03<00:02, 44.86it/s]concatenating: train:  60%|█████▉    | 148/247 [00:03<00:02, 45.27it/s]concatenating: train:  62%|██████▏   | 153/247 [00:03<00:02, 45.67it/s]concatenating: train:  64%|██████▍   | 158/247 [00:03<00:01, 46.46it/s]concatenating: train:  66%|██████▌   | 163/247 [00:03<00:01, 47.00it/s]concatenating: train:  68%|██████▊   | 168/247 [00:03<00:01, 47.09it/s]concatenating: train:  70%|███████   | 173/247 [00:03<00:01, 47.00it/s]concatenating: train:  72%|███████▏  | 178/247 [00:03<00:01, 45.16it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:01, 44.64it/s]concatenating: train:  76%|███████▌  | 188/247 [00:04<00:01, 42.42it/s]concatenating: train:  78%|███████▊  | 193/247 [00:04<00:01, 42.92it/s]concatenating: train:  80%|████████  | 198/247 [00:04<00:01, 41.71it/s]concatenating: train:  82%|████████▏ | 203/247 [00:04<00:01, 41.30it/s]concatenating: train:  84%|████████▍ | 208/247 [00:04<00:00, 40.92it/s]concatenating: train:  86%|████████▌ | 213/247 [00:04<00:00, 39.97it/s]concatenating: train:  88%|████████▊ | 218/247 [00:04<00:00, 41.65it/s]concatenating: train:  90%|█████████ | 223/247 [00:04<00:00, 42.76it/s]concatenating: train:  92%|█████████▏| 228/247 [00:04<00:00, 44.41it/s]concatenating: train:  94%|█████████▍| 233/247 [00:05<00:00, 43.80it/s]concatenating: train:  96%|█████████▋| 238/247 [00:05<00:00, 42.88it/s]concatenating: train:  98%|█████████▊| 243/247 [00:05<00:00, 44.42it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 45.47it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:11<00:46, 11.68s/it]Loading test:  40%|████      | 2/5 [00:28<00:40, 13.36s/it]Loading test:  60%|██████    | 3/5 [00:37<00:24, 12.04s/it]Loading test:  80%|████████  | 4/5 [00:41<00:09,  9.60s/it]Loading test: 100%|██████████| 5/5 [00:52<00:00, 10.03s/it]Loading test: 100%|██████████| 5/5 [00:52<00:00, 10.57s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 46.21it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 46.07it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 52, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 26, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 26, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 26, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 26, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 26, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 26, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 26, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 26, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 26, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 13, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 13, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 13, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 13, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 13, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 13, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 13, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 13, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 13, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 13, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 26, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 26, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 26, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 26, 80)   320         conv2d_7[0][0]                   2020-01-22 00:41:57.237667: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 00:41:57.237760: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 00:41:57.237773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 00:41:57.237781: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 00:41:57.238074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 26, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 26, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 26, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 26, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 26, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 26, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 52, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 52, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 52, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 52, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 52, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 52, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 52, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 52, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 52, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 52, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 52, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.52997920e-02 3.19720498e-02 7.71503694e-02 9.61885161e-03
 2.75395773e-02 7.05332582e-03 8.86433156e-02 1.14531344e-01
 8.20678880e-02 1.27702352e-02 2.89867370e-01 1.93255749e-01
 2.30132480e-04]
Train on 9671 samples, validate on 190 samples
Epoch 1/300
 - 30s - loss: 0.5381 - acc: 0.9170 - mDice: 0.4201 - val_loss: 0.6750 - val_acc: 0.9428 - val_mDice: 0.2708

Epoch 00001: val_mDice improved from -inf to 0.27079, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 25s - loss: 0.3941 - acc: 0.9424 - mDice: 0.5751 - val_loss: 0.6572 - val_acc: 0.9450 - val_mDice: 0.2901

Epoch 00002: val_mDice improved from 0.27079 to 0.29008, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 24s - loss: 0.3549 - acc: 0.9466 - mDice: 0.6175 - val_loss: 0.6683 - val_acc: 0.9478 - val_mDice: 0.2773

Epoch 00003: val_mDice did not improve from 0.29008
Epoch 4/300
 - 25s - loss: 0.3387 - acc: 0.9487 - mDice: 0.6349 - val_loss: 0.6839 - val_acc: 0.9467 - val_mDice: 0.2583

Epoch 00004: val_mDice did not improve from 0.29008
Epoch 5/300
 - 25s - loss: 0.3247 - acc: 0.9506 - mDice: 0.6501 - val_loss: 0.6601 - val_acc: 0.9480 - val_mDice: 0.2781

Epoch 00005: val_mDice did not improve from 0.29008
Epoch 6/300
 - 24s - loss: 0.3121 - acc: 0.9518 - mDice: 0.6636 - val_loss: 0.6270 - val_acc: 0.9488 - val_mDice: 0.2900

Epoch 00006: val_mDice did not improve from 0.29008
Epoch 7/300
 - 25s - loss: 0.3034 - acc: 0.9527 - mDice: 0.6730 - val_loss: 0.6604 - val_acc: 0.9448 - val_mDice: 0.2852

Epoch 00007: val_mDice did not improve from 0.29008
Epoch 8/300
 - 24s - loss: 0.3025 - acc: 0.9532 - mDice: 0.6739 - val_loss: 0.6173 - val_acc: 0.9501 - val_mDice: 0.2992

Epoch 00008: val_mDice improved from 0.29008 to 0.29921, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 9/300
 - 24s - loss: 0.2940 - acc: 0.9539 - mDice: 0.6832 - val_loss: 0.6543 - val_acc: 0.9512 - val_mDice: 0.2791

Epoch 00009: val_mDice did not improve from 0.29921
Epoch 10/300
 - 24s - loss: 0.2866 - acc: 0.9548 - mDice: 0.6911 - val_loss: 0.4798 - val_acc: 0.9501 - val_mDice: 0.3022

Epoch 00010: val_mDice improved from 0.29921 to 0.30216, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 11/300
 - 24s - loss: 0.2849 - acc: 0.9552 - mDice: 0.6930 - val_loss: 0.6481 - val_acc: 0.9501 - val_mDice: 0.2781

Epoch 00011: val_mDice did not improve from 0.30216
Epoch 12/300
 - 24s - loss: 0.2753 - acc: 0.9556 - mDice: 0.7033 - val_loss: 0.3736 - val_acc: 0.9494 - val_mDice: 0.2870

Epoch 00012: val_mDice did not improve from 0.30216
Epoch 13/300
 - 24s - loss: 0.2738 - acc: 0.9563 - mDice: 0.7050 - val_loss: 0.5778 - val_acc: 0.9515 - val_mDice: 0.2905

Epoch 00013: val_mDice did not improve from 0.30216
Epoch 14/300
 - 24s - loss: 0.2697 - acc: 0.9567 - mDice: 0.7094 - val_loss: 0.5278 - val_acc: 0.9391 - val_mDice: 0.2515

Epoch 00014: val_mDice did not improve from 0.30216
Epoch 15/300
 - 24s - loss: 0.2672 - acc: 0.9566 - mDice: 0.7122 - val_loss: 0.4574 - val_acc: 0.9491 - val_mDice: 0.2571

Epoch 00015: val_mDice did not improve from 0.30216
Epoch 16/300
 - 25s - loss: 0.2690 - acc: 0.9567 - mDice: 0.7101 - val_loss: 0.2655 - val_acc: 0.9514 - val_mDice: 0.2711

Epoch 00016: val_mDice did not improve from 0.30216
Epoch 17/300
 - 24s - loss: 0.2617 - acc: 0.9573 - mDice: 0.7181 - val_loss: 0.3685 - val_acc: 0.9497 - val_mDice: 0.2749

Epoch 00017: val_mDice did not improve from 0.30216
Epoch 18/300
 - 25s - loss: 0.2625 - acc: 0.9576 - mDice: 0.7172 - val_loss: 0.2844 - val_acc: 0.9520 - val_mDice: 0.2923

Epoch 00018: val_mDice did not improve from 0.30216
Epoch 19/300
 - 24s - loss: 0.2601 - acc: 0.9576 - mDice: 0.7198 - val_loss: 0.3305 - val_acc: 0.9482 - val_mDice: 0.2963

Epoch 00019: val_mDice did not improve from 0.30216
Epoch 20/300
 - 24s - loss: 0.2566 - acc: 0.9580 - mDice: 0.7236 - val_loss: 0.1520 - val_acc: 0.9515 - val_mDice: 0.2845

Epoch 00020: val_mDice did not improve from 0.30216
Epoch 21/300
 - 25s - loss: 0.2513 - acc: 0.9582 - mDice: 0.7293 - val_loss: 0.1667 - val_acc: 0.9502 - val_mDice: 0.2806

Epoch 00021: val_mDice did not improve from 0.30216
Epoch 22/300
 - 25s - loss: 0.2564 - acc: 0.9583 - mDice: 0.7237 - val_loss: 0.1497 - val_acc: 0.9508 - val_mDice: 0.2903

Epoch 00022: val_mDice did not improve from 0.30216
Epoch 23/300
 - 25s - loss: 0.2529 - acc: 0.9583 - mDice: 0.7275 - val_loss: 0.1522 - val_acc: 0.9490 - val_mDice: 0.2568

Epoch 00023: val_mDice did not improve from 0.30216
Epoch 24/300
 - 26s - loss: 0.2512 - acc: 0.9587 - mDice: 0.7294 - val_loss: 0.1408 - val_acc: 0.9501 - val_mDice: 0.2824

Epoch 00024: val_mDice did not improve from 0.30216
Epoch 25/300
 - 26s - loss: 0.2482 - acc: 0.9590 - mDice: 0.7326 - val_loss: 0.0374 - val_acc: 0.9513 - val_mDice: 0.2784

Epoch 00025: val_mDice did not improve from 0.30216

Epoch 00025: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 26/300
 - 26s - loss: 0.2387 - acc: 0.9599 - mDice: 0.7428 - val_loss: 0.0639 - val_acc: 0.9518 - val_mDice: 0.2875

Epoch 00026: val_mDice did not improve from 0.30216
Epoch 27/300
 - 26s - loss: 0.2329 - acc: 0.9604 - mDice: 0.7492 - val_loss: 0.1211 - val_acc: 0.9507 - val_mDice: 0.2850

Epoch 00027: val_mDice did not improve from 0.30216
Epoch 28/300
 - 26s - loss: 0.2317 - acc: 0.9604 - mDice: 0.7504 - val_loss: 0.0995 - val_acc: 0.9509 - val_mDice: 0.2715

Epoch 00028: val_mDice did not improve from 0.30216
Epoch 29/300
 - 26s - loss: 0.2302 - acc: 0.9606 - mDice: 0.7521 - val_loss: 0.0803 - val_acc: 0.9514 - val_mDice: 0.2808

Epoch 00029: val_mDice did not improve from 0.30216
Epoch 30/300
 - 24s - loss: 0.2287 - acc: 0.9607 - mDice: 0.7537 - val_loss: 0.0741 - val_acc: 0.9511 - val_mDice: 0.2755

Epoch 00030: val_mDice did not improve from 0.30216
Epoch 31/300
 - 25s - loss: 0.2283 - acc: 0.9609 - mDice: 0.7541 - val_loss: 0.0739 - val_acc: 0.9507 - val_mDice: 0.2868

Epoch 00031: val_mDice did not improve from 0.30216
Epoch 32/300
 - 24s - loss: 0.2269 - acc: 0.9610 - mDice: 0.7556 - val_loss: 0.0201 - val_acc: 0.9527 - val_mDice: 0.2853

Epoch 00032: val_mDice did not improve from 0.30216
Epoch 33/300
 - 24s - loss: 0.2286 - acc: 0.9608 - mDice: 0.7538 - val_loss: 0.2260 - val_acc: 0.9525 - val_mDice: 0.2833

Epoch 00033: val_mDice did not improve from 0.30216
Epoch 34/300
 - 24s - loss: 0.2260 - acc: 0.9611 - mDice: 0.7565 - val_loss: 0.0598 - val_acc: 0.9522 - val_mDice: 0.2859

Epoch 00034: val_mDice did not improve from 0.30216
Epoch 35/300
 - 24s - loss: 0.2248 - acc: 0.9612 - mDice: 0.7579 - val_loss: 0.0922 - val_acc: 0.9527 - val_mDice: 0.2868

Epoch 00035: val_mDice did not improve from 0.30216
Epoch 36/300
 - 24s - loss: 0.2265 - acc: 0.9613 - mDice: 0.7560 - val_loss: 0.1917 - val_acc: 0.9466 - val_mDice: 0.2681

Epoch 00036: val_mDice did not improve from 0.30216
Epoch 37/300
 - 24s - loss: 0.2262 - acc: 0.9615 - mDice: 0.7562 - val_loss: 0.1849 - val_acc: 0.9455 - val_mDice: 0.2744

Epoch 00037: val_mDice did not improve from 0.30216
Epoch 38/300
 - 24s - loss: 0.2249 - acc: 0.9613 - mDice: 0.7577 - val_loss: 0.0590 - val_acc: 0.9522 - val_mDice: 0.2866

Epoch 00038: val_mDice did not improve from 0.30216
Epoch 39/300
 - 25s - loss: 0.2239 - acc: 0.9611 - mDice: 0.7551 - val_loss: 0.0262 - val_acc: 0.9495 - val_mDice: 0.2715

Epoch 00039: val_mDice did not improve from 0.30216
Epoch 40/300
 - 25s - loss: 0.2234 - acc: 0.9593 - mDice: 0.7386 - val_loss: -8.0905e-03 - val_acc: 0.9522 - val_mDice: 0.2708

Epoch 00040: val_mDice did not improve from 0.30216

Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 41/300
 - 25s - loss: 0.2122 - acc: 0.9601 - mDice: 0.7431 - val_loss: 0.0098 - val_acc: 0.9510 - val_mDice: 0.2720

Epoch 00041: val_mDice did not improve from 0.30216
Epoch 42/300
 - 25s - loss: 0.2028 - acc: 0.9607 - mDice: 0.7500 - val_loss: -6.2824e-03 - val_acc: 0.9509 - val_mDice: 0.2706

Epoch 00042: val_mDice did not improve from 0.30216
Epoch 43/300
 - 25s - loss: 0.2047 - acc: 0.9609 - mDice: 0.7548 - val_loss: 0.0023 - val_acc: 0.9451 - val_mDice: 0.2365

Epoch 00043: val_mDice did not improve from 0.30216
Epoch 44/300
 - 24s - loss: 0.1995 - acc: 0.9608 - mDice: 0.7513 - val_loss: 0.0060 - val_acc: 0.9518 - val_mDice: 0.2795

Epoch 00044: val_mDice did not improve from 0.30216
Epoch 45/300
 - 25s - loss: 0.1958 - acc: 0.9608 - mDice: 0.7509 - val_loss: -1.7871e-02 - val_acc: 0.9527 - val_mDice: 0.2794

Epoch 00045: val_mDice did not improve from 0.30216
Epoch 46/300
 - 25s - loss: 0.1944 - acc: 0.9610 - mDice: 0.7574 - val_loss: 0.0123 - val_acc: 0.9520 - val_mDice: 0.2770

Epoch 00046: val_mDice did not improve from 0.30216
Epoch 47/300
 - 25s - loss: 0.1940 - acc: 0.9609 - mDice: 0.7544 - val_loss: -1.0810e-02 - val_acc: 0.9520 - val_mDice: 0.2768

Epoch 00047: val_mDice did not improve from 0.30216
Epoch 48/300
 - 25s - loss: 0.1873 - acc: 0.9611 - mDice: 0.7546 - val_loss: 0.0046 - val_acc: 0.9507 - val_mDice: 0.2776

Epoch 00048: val_mDice did not improve from 0.30216
Epoch 49/300
 - 25s - loss: 0.1862 - acc: 0.9610 - mDice: 0.7543 - val_loss: -1.1548e-02 - val_acc: 0.9526 - val_mDice: 0.2772

Epoch 00049: val_mDice did not improve from 0.30216
Epoch 50/300
 - 25s - loss: 0.1858 - acc: 0.9608 - mDice: 0.7542 - val_loss: -3.1748e-03 - val_acc: 0.9516 - val_mDice: 0.2792

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.48s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.36s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.28s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.15s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.09s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:21,  3.00it/s]Loading train:   1%|          | 2/247 [00:00<01:18,  3.11it/s]Loading train:   1%|          | 3/247 [00:00<01:16,  3.19it/s]Loading train:   2%|▏         | 4/247 [00:01<01:15,  3.20it/s]Loading train:   2%|▏         | 5/247 [00:01<01:13,  3.28it/s]Loading train:   2%|▏         | 6/247 [00:01<01:13,  3.27it/s]Loading train:   3%|▎         | 7/247 [00:02<01:12,  3.29it/s]Loading train:   3%|▎         | 8/247 [00:02<01:13,  3.27it/s]Loading train:   4%|▎         | 9/247 [00:02<01:11,  3.33it/s]Loading train:   4%|▍         | 10/247 [00:03<01:11,  3.33it/s]Loading train:   4%|▍         | 11/247 [00:03<01:11,  3.32it/s]Loading train:   5%|▍         | 12/247 [00:03<01:09,  3.37it/s]Loading train:   5%|▌         | 13/247 [00:03<01:09,  3.36it/s]Loading train:   6%|▌         | 14/247 [00:04<01:08,  3.40it/s]Loading train:   6%|▌         | 15/247 [00:04<01:07,  3.42it/s]Loading train:   6%|▋         | 16/247 [00:04<01:07,  3.40it/s]Loading train:   7%|▋         | 17/247 [00:05<01:08,  3.38it/s]Loading train:   7%|▋         | 18/247 [00:05<01:07,  3.38it/s]Loading train:   8%|▊         | 19/247 [00:05<01:06,  3.41it/s]Loading train:   8%|▊         | 20/247 [00:05<01:07,  3.39it/s]Loading train:   9%|▊         | 21/247 [00:06<01:06,  3.39it/s]Loading train:   9%|▉         | 22/247 [00:06<01:06,  3.39it/s]Loading train:   9%|▉         | 23/247 [00:06<01:03,  3.52it/s]Loading train:  10%|▉         | 24/247 [00:07<01:01,  3.64it/s]Loading train:  10%|█         | 25/247 [00:07<01:00,  3.68it/s]Loading train:  11%|█         | 26/247 [00:07<00:58,  3.75it/s]Loading train:  11%|█         | 27/247 [00:07<00:57,  3.79it/s]Loading train:  11%|█▏        | 28/247 [00:08<00:57,  3.83it/s]Loading train:  12%|█▏        | 29/247 [00:08<00:56,  3.87it/s]Loading train:  12%|█▏        | 30/247 [00:08<00:55,  3.90it/s]Loading train:  13%|█▎        | 31/247 [00:08<00:55,  3.92it/s]Loading train:  13%|█▎        | 32/247 [00:09<00:54,  3.91it/s]Loading train:  13%|█▎        | 33/247 [00:09<00:54,  3.94it/s]Loading train:  14%|█▍        | 34/247 [00:09<00:53,  3.95it/s]Loading train:  14%|█▍        | 35/247 [00:09<00:53,  3.95it/s]Loading train:  15%|█▍        | 36/247 [00:10<00:53,  3.95it/s]Loading train:  15%|█▍        | 37/247 [00:10<00:54,  3.85it/s]Loading train:  15%|█▌        | 38/247 [00:10<00:53,  3.88it/s]Loading train:  16%|█▌        | 39/247 [00:10<00:53,  3.87it/s]Loading train:  16%|█▌        | 40/247 [00:11<00:54,  3.80it/s]Loading train:  17%|█▋        | 41/247 [00:11<00:57,  3.57it/s]Loading train:  17%|█▋        | 42/247 [00:11<00:56,  3.63it/s]Loading train:  17%|█▋        | 43/247 [00:12<00:55,  3.67it/s]Loading train:  18%|█▊        | 44/247 [00:12<00:54,  3.70it/s]Loading train:  18%|█▊        | 45/247 [00:12<00:53,  3.75it/s]Loading train:  19%|█▊        | 46/247 [00:12<00:53,  3.75it/s]Loading train:  19%|█▉        | 47/247 [00:13<00:54,  3.70it/s]Loading train:  19%|█▉        | 48/247 [00:13<00:53,  3.73it/s]Loading train:  20%|█▉        | 49/247 [00:13<00:52,  3.77it/s]Loading train:  20%|██        | 50/247 [00:13<00:52,  3.73it/s]Loading train:  21%|██        | 51/247 [00:14<00:52,  3.72it/s]Loading train:  21%|██        | 52/247 [00:14<00:52,  3.70it/s]Loading train:  21%|██▏       | 53/247 [00:14<00:52,  3.73it/s]Loading train:  22%|██▏       | 54/247 [00:14<00:52,  3.68it/s]Loading train:  22%|██▏       | 55/247 [00:15<00:52,  3.66it/s]Loading train:  23%|██▎       | 56/247 [00:15<00:51,  3.68it/s]Loading train:  23%|██▎       | 57/247 [00:15<00:51,  3.72it/s]Loading train:  23%|██▎       | 58/247 [00:16<00:50,  3.73it/s]Loading train:  24%|██▍       | 59/247 [00:16<00:53,  3.54it/s]Loading train:  24%|██▍       | 60/247 [00:16<00:53,  3.48it/s]Loading train:  25%|██▍       | 61/247 [00:16<00:54,  3.42it/s]Loading train:  25%|██▌       | 62/247 [00:17<00:54,  3.41it/s]Loading train:  26%|██▌       | 63/247 [00:17<00:53,  3.41it/s]Loading train:  26%|██▌       | 64/247 [00:17<00:53,  3.44it/s]Loading train:  26%|██▋       | 65/247 [00:18<00:52,  3.45it/s]Loading train:  27%|██▋       | 66/247 [00:18<00:51,  3.48it/s]Loading train:  27%|██▋       | 67/247 [00:18<00:51,  3.47it/s]Loading train:  28%|██▊       | 68/247 [00:19<00:52,  3.44it/s]Loading train:  28%|██▊       | 69/247 [00:19<00:51,  3.47it/s]Loading train:  28%|██▊       | 70/247 [00:19<00:51,  3.43it/s]Loading train:  29%|██▊       | 71/247 [00:19<00:51,  3.41it/s]Loading train:  29%|██▉       | 72/247 [00:20<00:51,  3.42it/s]Loading train:  30%|██▉       | 73/247 [00:20<00:50,  3.44it/s]Loading train:  30%|██▉       | 74/247 [00:20<00:49,  3.46it/s]Loading train:  30%|███       | 75/247 [00:21<00:49,  3.49it/s]Loading train:  31%|███       | 76/247 [00:21<00:48,  3.51it/s]Loading train:  31%|███       | 77/247 [00:21<00:51,  3.29it/s]Loading train:  32%|███▏      | 78/247 [00:21<00:52,  3.22it/s]Loading train:  32%|███▏      | 79/247 [00:22<00:51,  3.28it/s]Loading train:  32%|███▏      | 80/247 [00:22<00:49,  3.37it/s]Loading train:  33%|███▎      | 81/247 [00:22<00:51,  3.25it/s]Loading train:  33%|███▎      | 82/247 [00:23<00:51,  3.21it/s]Loading train:  34%|███▎      | 83/247 [00:23<00:51,  3.18it/s]Loading train:  34%|███▍      | 84/247 [00:23<00:52,  3.13it/s]Loading train:  34%|███▍      | 85/247 [00:24<00:52,  3.11it/s]Loading train:  35%|███▍      | 86/247 [00:24<00:52,  3.08it/s]Loading train:  35%|███▌      | 87/247 [00:24<00:51,  3.08it/s]Loading train:  36%|███▌      | 88/247 [00:25<00:51,  3.08it/s]Loading train:  36%|███▌      | 89/247 [00:25<00:51,  3.06it/s]Loading train:  36%|███▋      | 90/247 [00:25<00:51,  3.04it/s]Loading train:  37%|███▋      | 91/247 [00:26<00:51,  3.06it/s]Loading train:  37%|███▋      | 92/247 [00:26<00:50,  3.06it/s]Loading train:  38%|███▊      | 93/247 [00:26<00:50,  3.08it/s]Loading train:  38%|███▊      | 94/247 [00:27<00:49,  3.08it/s]Loading train:  38%|███▊      | 95/247 [00:27<00:49,  3.08it/s]Loading train:  39%|███▉      | 96/247 [00:27<00:50,  3.00it/s]Loading train:  39%|███▉      | 97/247 [00:28<00:49,  3.02it/s]Loading train:  40%|███▉      | 98/247 [00:28<00:49,  3.02it/s]Loading train:  40%|████      | 99/247 [00:28<00:48,  3.02it/s]Loading train:  40%|████      | 100/247 [00:29<00:47,  3.10it/s]Loading train:  41%|████      | 101/247 [00:29<00:46,  3.16it/s]Loading train:  41%|████▏     | 102/247 [00:29<00:45,  3.19it/s]Loading train:  42%|████▏     | 103/247 [00:30<00:45,  3.19it/s]Loading train:  42%|████▏     | 104/247 [00:30<00:44,  3.18it/s]Loading train:  43%|████▎     | 105/247 [00:30<00:44,  3.21it/s]Loading train:  43%|████▎     | 106/247 [00:30<00:43,  3.24it/s]Loading train:  43%|████▎     | 107/247 [00:31<00:44,  3.17it/s]Loading train:  44%|████▎     | 108/247 [00:31<00:43,  3.17it/s]Loading train:  44%|████▍     | 109/247 [00:31<00:43,  3.17it/s]Loading train:  45%|████▍     | 110/247 [00:32<00:43,  3.16it/s]Loading train:  45%|████▍     | 111/247 [00:32<00:43,  3.13it/s]Loading train:  45%|████▌     | 112/247 [00:32<00:43,  3.12it/s]Loading train:  46%|████▌     | 113/247 [00:33<00:43,  3.10it/s]Loading train:  46%|████▌     | 114/247 [00:33<00:43,  3.08it/s]Loading train:  47%|████▋     | 115/247 [00:33<00:42,  3.14it/s]Loading train:  47%|████▋     | 116/247 [00:34<00:41,  3.18it/s]Loading train:  47%|████▋     | 117/247 [00:34<00:40,  3.20it/s]Loading train:  48%|████▊     | 118/247 [00:34<00:40,  3.22it/s]Loading train:  48%|████▊     | 119/247 [00:35<00:38,  3.31it/s]Loading train:  49%|████▊     | 120/247 [00:35<00:37,  3.41it/s]Loading train:  49%|████▉     | 121/247 [00:35<00:36,  3.46it/s]Loading train:  49%|████▉     | 122/247 [00:35<00:36,  3.41it/s]Loading train:  50%|████▉     | 123/247 [00:36<00:36,  3.41it/s]Loading train:  50%|█████     | 124/247 [00:36<00:35,  3.44it/s]Loading train:  51%|█████     | 125/247 [00:36<00:35,  3.46it/s]Loading train:  51%|█████     | 126/247 [00:37<00:35,  3.38it/s]Loading train:  51%|█████▏    | 127/247 [00:37<00:35,  3.38it/s]Loading train:  52%|█████▏    | 128/247 [00:37<00:35,  3.38it/s]Loading train:  52%|█████▏    | 129/247 [00:37<00:35,  3.30it/s]Loading train:  53%|█████▎    | 130/247 [00:38<00:35,  3.32it/s]Loading train:  53%|█████▎    | 131/247 [00:38<00:34,  3.40it/s]Loading train:  53%|█████▎    | 132/247 [00:38<00:33,  3.45it/s]Loading train:  54%|█████▍    | 133/247 [00:39<00:33,  3.42it/s]Loading train:  54%|█████▍    | 134/247 [00:39<00:33,  3.40it/s]Loading train:  55%|█████▍    | 135/247 [00:39<00:33,  3.37it/s]Loading train:  55%|█████▌    | 136/247 [00:40<00:32,  3.40it/s]Loading train:  55%|█████▌    | 137/247 [00:40<00:31,  3.45it/s]Loading train:  56%|█████▌    | 138/247 [00:40<00:31,  3.45it/s]Loading train:  56%|█████▋    | 139/247 [00:40<00:30,  3.52it/s]Loading train:  57%|█████▋    | 140/247 [00:41<00:30,  3.51it/s]Loading train:  57%|█████▋    | 141/247 [00:41<00:29,  3.59it/s]Loading train:  57%|█████▋    | 142/247 [00:41<00:29,  3.61it/s]Loading train:  58%|█████▊    | 143/247 [00:41<00:28,  3.66it/s]Loading train:  58%|█████▊    | 144/247 [00:42<00:28,  3.67it/s]Loading train:  59%|█████▊    | 145/247 [00:42<00:27,  3.69it/s]Loading train:  59%|█████▉    | 146/247 [00:42<00:27,  3.71it/s]Loading train:  60%|█████▉    | 147/247 [00:43<00:27,  3.70it/s]Loading train:  60%|█████▉    | 148/247 [00:43<00:26,  3.73it/s]Loading train:  60%|██████    | 149/247 [00:43<00:26,  3.74it/s]Loading train:  61%|██████    | 150/247 [00:43<00:26,  3.70it/s]Loading train:  61%|██████    | 151/247 [00:44<00:25,  3.73it/s]Loading train:  62%|██████▏   | 152/247 [00:44<00:25,  3.71it/s]Loading train:  62%|██████▏   | 153/247 [00:44<00:25,  3.73it/s]Loading train:  62%|██████▏   | 154/247 [00:44<00:26,  3.55it/s]Loading train:  63%|██████▎   | 155/247 [00:45<00:26,  3.41it/s]Loading train:  63%|██████▎   | 156/247 [00:45<00:27,  3.36it/s]Loading train:  64%|██████▎   | 157/247 [00:45<00:27,  3.31it/s]Loading train:  64%|██████▍   | 158/247 [00:46<00:27,  3.24it/s]Loading train:  64%|██████▍   | 159/247 [00:46<00:27,  3.22it/s]Loading train:  65%|██████▍   | 160/247 [00:46<00:27,  3.20it/s]Loading train:  65%|██████▌   | 161/247 [00:47<00:26,  3.20it/s]Loading train:  66%|██████▌   | 162/247 [00:47<00:26,  3.19it/s]Loading train:  66%|██████▌   | 163/247 [00:47<00:26,  3.18it/s]Loading train:  66%|██████▋   | 164/247 [00:48<00:26,  3.17it/s]Loading train:  67%|██████▋   | 165/247 [00:48<00:26,  3.15it/s]Loading train:  67%|██████▋   | 166/247 [00:48<00:25,  3.15it/s]Loading train:  68%|██████▊   | 167/247 [00:49<00:25,  3.16it/s]Loading train:  68%|██████▊   | 168/247 [00:49<00:24,  3.16it/s]Loading train:  68%|██████▊   | 169/247 [00:49<00:24,  3.17it/s]Loading train:  69%|██████▉   | 170/247 [00:50<00:24,  3.14it/s]Loading train:  69%|██████▉   | 171/247 [00:50<00:23,  3.17it/s]Loading train:  70%|██████▉   | 172/247 [00:50<00:23,  3.24it/s]Loading train:  70%|███████   | 173/247 [00:50<00:21,  3.38it/s]Loading train:  70%|███████   | 174/247 [00:51<00:21,  3.44it/s]Loading train:  71%|███████   | 175/247 [00:51<00:21,  3.28it/s]Loading train:  71%|███████▏  | 176/247 [00:51<00:20,  3.39it/s]Loading train:  72%|███████▏  | 177/247 [00:52<00:20,  3.42it/s]Loading train:  72%|███████▏  | 178/247 [00:52<00:19,  3.49it/s]Loading train:  72%|███████▏  | 179/247 [00:52<00:19,  3.54it/s]Loading train:  73%|███████▎  | 180/247 [00:52<00:18,  3.57it/s]Loading train:  73%|███████▎  | 181/247 [00:53<00:18,  3.63it/s]Loading train:  74%|███████▎  | 182/247 [00:53<00:17,  3.65it/s]Loading train:  74%|███████▍  | 183/247 [00:53<00:17,  3.67it/s]Loading train:  74%|███████▍  | 184/247 [00:53<00:17,  3.67it/s]Loading train:  75%|███████▍  | 185/247 [00:54<00:16,  3.66it/s]Loading train:  75%|███████▌  | 186/247 [00:54<00:16,  3.67it/s]Loading train:  76%|███████▌  | 187/247 [00:54<00:16,  3.68it/s]Loading train:  76%|███████▌  | 188/247 [00:55<00:16,  3.68it/s]Loading train:  77%|███████▋  | 189/247 [00:55<00:15,  3.68it/s]Loading train:  77%|███████▋  | 190/247 [00:55<00:15,  3.69it/s]Loading train:  77%|███████▋  | 191/247 [00:55<00:15,  3.69it/s]Loading train:  78%|███████▊  | 192/247 [00:56<00:14,  3.71it/s]Loading train:  78%|███████▊  | 193/247 [00:56<00:14,  3.70it/s]Loading train:  79%|███████▊  | 194/247 [00:56<00:14,  3.78it/s]Loading train:  79%|███████▉  | 195/247 [00:56<00:13,  3.80it/s]Loading train:  79%|███████▉  | 196/247 [00:57<00:13,  3.86it/s]Loading train:  80%|███████▉  | 197/247 [00:57<00:13,  3.83it/s]Loading train:  80%|████████  | 198/247 [00:57<00:12,  3.85it/s]Loading train:  81%|████████  | 199/247 [00:57<00:12,  3.88it/s]Loading train:  81%|████████  | 200/247 [00:58<00:12,  3.90it/s]Loading train:  81%|████████▏ | 201/247 [00:58<00:11,  3.91it/s]Loading train:  82%|████████▏ | 202/247 [00:58<00:11,  3.90it/s]Loading train:  82%|████████▏ | 203/247 [00:58<00:11,  3.93it/s]Loading train:  83%|████████▎ | 204/247 [00:59<00:10,  3.91it/s]Loading train:  83%|████████▎ | 205/247 [00:59<00:10,  3.94it/s]Loading train:  83%|████████▎ | 206/247 [00:59<00:10,  3.97it/s]Loading train:  84%|████████▍ | 207/247 [00:59<00:10,  3.99it/s]Loading train:  84%|████████▍ | 208/247 [01:00<00:09,  4.00it/s]Loading train:  85%|████████▍ | 209/247 [01:00<00:09,  4.00it/s]Loading train:  85%|████████▌ | 210/247 [01:00<00:09,  4.00it/s]Loading train:  85%|████████▌ | 211/247 [01:00<00:08,  4.01it/s]Loading train:  86%|████████▌ | 212/247 [01:01<00:08,  3.94it/s]Loading train:  86%|████████▌ | 213/247 [01:01<00:08,  3.91it/s]Loading train:  87%|████████▋ | 214/247 [01:01<00:08,  3.87it/s]Loading train:  87%|████████▋ | 215/247 [01:01<00:08,  3.84it/s]Loading train:  87%|████████▋ | 216/247 [01:02<00:08,  3.83it/s]Loading train:  88%|████████▊ | 217/247 [01:02<00:07,  3.82it/s]Loading train:  88%|████████▊ | 218/247 [01:02<00:07,  3.81it/s]Loading train:  89%|████████▊ | 219/247 [01:03<00:07,  3.81it/s]Loading train:  89%|████████▉ | 220/247 [01:03<00:07,  3.74it/s]Loading train:  89%|████████▉ | 221/247 [01:03<00:07,  3.69it/s]Loading train:  90%|████████▉ | 222/247 [01:03<00:06,  3.71it/s]Loading train:  90%|█████████ | 223/247 [01:04<00:06,  3.71it/s]Loading train:  91%|█████████ | 224/247 [01:04<00:06,  3.74it/s]Loading train:  91%|█████████ | 225/247 [01:04<00:05,  3.73it/s]Loading train:  91%|█████████▏| 226/247 [01:04<00:05,  3.75it/s]Loading train:  92%|█████████▏| 227/247 [01:05<00:05,  3.74it/s]Loading train:  92%|█████████▏| 228/247 [01:05<00:05,  3.75it/s]Loading train:  93%|█████████▎| 229/247 [01:05<00:04,  3.74it/s]Loading train:  93%|█████████▎| 230/247 [01:06<00:04,  3.58it/s]Loading train:  94%|█████████▎| 231/247 [01:06<00:04,  3.48it/s]Loading train:  94%|█████████▍| 232/247 [01:06<00:04,  3.41it/s]Loading train:  94%|█████████▍| 233/247 [01:06<00:04,  3.36it/s]Loading train:  95%|█████████▍| 234/247 [01:07<00:03,  3.33it/s]Loading train:  95%|█████████▌| 235/247 [01:07<00:03,  3.30it/s]Loading train:  96%|█████████▌| 236/247 [01:07<00:03,  3.29it/s]Loading train:  96%|█████████▌| 237/247 [01:08<00:03,  3.27it/s]Loading train:  96%|█████████▋| 238/247 [01:08<00:02,  3.27it/s]Loading train:  97%|█████████▋| 239/247 [01:08<00:02,  3.26it/s]Loading train:  97%|█████████▋| 240/247 [01:09<00:02,  3.27it/s]Loading train:  98%|█████████▊| 241/247 [01:09<00:01,  3.27it/s]Loading train:  98%|█████████▊| 242/247 [01:09<00:01,  3.27it/s]Loading train:  98%|█████████▊| 243/247 [01:10<00:01,  3.26it/s]Loading train:  99%|█████████▉| 244/247 [01:10<00:00,  3.23it/s]Loading train:  99%|█████████▉| 245/247 [01:10<00:00,  3.23it/s]Loading train: 100%|█████████▉| 246/247 [01:10<00:00,  3.18it/s]Loading train: 100%|██████████| 247/247 [01:11<00:00,  3.15it/s]Loading train: 100%|██████████| 247/247 [01:11<00:00,  3.46it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 4/247 [00:00<00:06, 39.08it/s]concatenating: train:   4%|▎         | 9/247 [00:00<00:05, 40.32it/s]concatenating: train:   6%|▌         | 14/247 [00:00<00:05, 41.25it/s]concatenating: train:   8%|▊         | 19/247 [00:00<00:05, 41.93it/s]concatenating: train:  10%|▉         | 24/247 [00:00<00:05, 42.88it/s]concatenating: train:  12%|█▏        | 29/247 [00:00<00:04, 44.64it/s]concatenating: train:  14%|█▍        | 34/247 [00:00<00:04, 46.00it/s]concatenating: train:  16%|█▌        | 39/247 [00:00<00:04, 46.99it/s]concatenating: train:  18%|█▊        | 44/247 [00:00<00:04, 46.75it/s]concatenating: train:  20%|█▉        | 49/247 [00:01<00:04, 46.49it/s]concatenating: train:  22%|██▏       | 54/247 [00:01<00:04, 46.17it/s]concatenating: train:  24%|██▍       | 59/247 [00:01<00:04, 46.11it/s]concatenating: train:  26%|██▌       | 64/247 [00:01<00:04, 45.48it/s]concatenating: train:  28%|██▊       | 69/247 [00:01<00:03, 45.13it/s]concatenating: train:  30%|██▉       | 74/247 [00:01<00:03, 44.04it/s]concatenating: train:  32%|███▏      | 79/247 [00:01<00:03, 43.29it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:03, 41.92it/s]concatenating: train:  36%|███▌      | 89/247 [00:02<00:03, 40.92it/s]concatenating: train:  38%|███▊      | 94/247 [00:02<00:03, 40.25it/s]concatenating: train:  40%|████      | 99/247 [00:02<00:04, 36.93it/s]concatenating: train:  42%|████▏     | 104/247 [00:02<00:03, 38.03it/s]concatenating: train:  44%|████▍     | 109/247 [00:02<00:03, 37.47it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:03, 38.49it/s]concatenating: train:  48%|████▊     | 119/247 [00:02<00:03, 39.41it/s]concatenating: train:  50%|█████     | 124/247 [00:02<00:03, 40.57it/s]concatenating: train:  52%|█████▏    | 129/247 [00:03<00:02, 41.60it/s]concatenating: train:  54%|█████▍    | 134/247 [00:03<00:02, 41.65it/s]concatenating: train:  56%|█████▋    | 139/247 [00:03<00:02, 42.71it/s]concatenating: train:  58%|█████▊    | 144/247 [00:03<00:02, 44.04it/s]concatenating: train:  60%|██████    | 149/247 [00:03<00:02, 45.07it/s]concatenating: train:  62%|██████▏   | 154/247 [00:03<00:02, 45.51it/s]concatenating: train:  64%|██████▍   | 159/247 [00:03<00:01, 44.46it/s]concatenating: train:  66%|██████▋   | 164/247 [00:03<00:01, 43.29it/s]concatenating: train:  68%|██████▊   | 169/247 [00:03<00:01, 42.55it/s]concatenating: train:  70%|███████   | 174/247 [00:04<00:01, 43.28it/s]concatenating: train:  72%|███████▏  | 179/247 [00:04<00:01, 44.03it/s]concatenating: train:  74%|███████▍  | 184/247 [00:04<00:01, 45.01it/s]concatenating: train:  77%|███████▋  | 189/247 [00:04<00:01, 45.76it/s]concatenating: train:  79%|███████▊  | 194/247 [00:04<00:01, 46.15it/s]concatenating: train:  81%|████████  | 199/247 [00:04<00:01, 45.32it/s]concatenating: train:  83%|████████▎ | 204/247 [00:04<00:00, 45.67it/s]concatenating: train:  85%|████████▍ | 209/247 [00:04<00:00, 46.75it/s]concatenating: train:  87%|████████▋ | 214/247 [00:04<00:00, 46.72it/s]concatenating: train:  89%|████████▊ | 219/247 [00:05<00:00, 47.06it/s]concatenating: train:  91%|█████████▏| 226/247 [00:05<00:00, 51.58it/s]concatenating: train:  94%|█████████▍| 233/247 [00:05<00:00, 54.40it/s]concatenating: train:  97%|█████████▋| 239/247 [00:05<00:00, 49.08it/s]concatenating: train:  99%|█████████▉| 245/247 [00:05<00:00, 46.07it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 44.27it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.05it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.94it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.97it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  3.12it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.16it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  3.09it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 323.08it/s]
Epoch 00050: val_mDice did not improve from 0.30216
Restoring model weights from the end of the best epoch
Epoch 00050: early stopping
{'val_loss': [0.6750068193987796, 0.6571662865186992, 0.6682811975479126, 0.6838738855562712, 0.6600897374906038, 0.6270229847807633, 0.6603577058566245, 0.6173092581723866, 0.6542583547140423, 0.4798167049884796, 0.6480749312200045, 0.3736402886478524, 0.5778241298700634, 0.5277962276810094, 0.4573670170809093, 0.26549069936338227, 0.36851704120635986, 0.2843674254407616, 0.3305387975353944, 0.15204718826632752, 0.1667450964941006, 0.14968056839547658, 0.15216226669910707, 0.1407807649015204, 0.037423687441715675, 0.06385147042180363, 0.12113588264113978, 0.09949971225700881, 0.080312949850371, 0.07413262275880889, 0.07391908647198427, 0.020071224946724742, 0.2260039878126822, 0.059805915543907566, 0.0921943544802305, 0.19170919227364816, 0.18492622997023558, 0.05904958838302838, 0.026160547509789467, -0.008090484247077256, 0.009823591423858153, -0.006282367400432888, 0.0022967525996806983, 0.006019415627968938, -0.017871425732185964, 0.012303626458895834, -0.010809715052968577, 0.004575046073449285, -0.011547576832143884, -0.0031747947397984958], 'val_acc': [0.9428294238291288, 0.9450428925062481, 0.9478395424391094, 0.9466719658751237, 0.9479901727877165, 0.9487504770881251, 0.9447874520954332, 0.9500602421007658, 0.9512025243357608, 0.950098803168849, 0.9500976016646937, 0.949444526120236, 0.9514772484177038, 0.9390676209801122, 0.9491384656805741, 0.9513663900525946, 0.9496686458587646, 0.9520001850630108, 0.9482408009077373, 0.9514989413713154, 0.9501891794957613, 0.9507627204844826, 0.9490059300472862, 0.9501457998627111, 0.9513061548534193, 0.9518471642544395, 0.950689224820388, 0.9509326250929582, 0.951356756059747, 0.9511398704428422, 0.9507350137359217, 0.9527231517590975, 0.9524713189978349, 0.9521809345797488, 0.952726771956996, 0.9465791896769875, 0.9454766762884039, 0.9522279218623513, 0.9494818794099908, 0.952230337419008, 0.9509663581848145, 0.9508651400867262, 0.9450669978794298, 0.9517652329645658, 0.9527062836446261, 0.9520062145433927, 0.9520182703670702, 0.9507350137359217, 0.952601454759899, 0.9516302755004481], 'val_mDice': [0.27079331865044015, 0.29007659342728165, 0.27733657509088516, 0.25826164273741214, 0.2781388792944582, 0.29002014782867935, 0.285163065516635, 0.29920829087495804, 0.27909642046219424, 0.3021646665507241, 0.27812087163329124, 0.28698550498015, 0.2904525669781785, 0.2514744224516969, 0.2571094581171086, 0.2711114577556911, 0.2749275823711957, 0.2923466929871785, 0.2963091093850763, 0.284466273298389, 0.28057290152891684, 0.29030023515224457, 0.2568442278394574, 0.2824416103723802, 0.27839508691900655, 0.2875271118000934, 0.2850353590359813, 0.27147979054011795, 0.28080354356452036, 0.27551425571896526, 0.286792753264308, 0.28529446983807966, 0.2832656289009671, 0.28585375021947057, 0.2867604780353998, 0.2680826914545737, 0.2743757596533549, 0.2866316014214566, 0.2714875287523395, 0.27084419278329924, 0.2720126754751331, 0.2705543050052304, 0.23648452601934733, 0.2794679195473069, 0.279357894764919, 0.27696329737572295, 0.2767902985215187, 0.27761027334552063, 0.2772415583267024, 0.27919193925826175], 'loss': [0.5381453861717896, 0.39407123470735356, 0.3548549987971259, 0.3386973903629331, 0.3246537792671554, 0.3120880583525567, 0.3034233603768629, 0.30254183633043236, 0.2939857971753296, 0.2866278911910226, 0.2848697264140745, 0.2753460930577356, 0.27379854306194973, 0.26971879586686814, 0.26715575162448063, 0.2690205261004944, 0.26166376620977916, 0.2624628908347472, 0.2600807969935763, 0.2565679728873895, 0.25128172342169064, 0.25643762211163085, 0.2529365343732482, 0.2511978008769042, 0.24820770326204056, 0.23873112025668686, 0.2328544986178988, 0.23171214694173614, 0.23015946579403523, 0.2286867053225743, 0.22832075269241242, 0.22686216658575065, 0.2285528480236218, 0.22602637367144499, 0.22477206626927984, 0.22653662414514295, 0.22624217193038668, 0.22486892365371414, 0.22386443167354783, 0.22335312892533102, 0.21218417809141538, 0.20282737276069154, 0.20467054372655868, 0.19949397716740372, 0.19584392453276608, 0.19436216616385846, 0.19402960457929258, 0.18731753057726083, 0.1862418074628835, 0.18577624242351698], 'acc': [0.916971309800612, 0.9424071177961957, 0.9465636717300604, 0.9487220682238438, 0.950609578032144, 0.9517778921689406, 0.9526844821441212, 0.9532383269625654, 0.9538959522563365, 0.9548409384269032, 0.9551848290982531, 0.9556443865858107, 0.9563082369687133, 0.9566633267494358, 0.9565690850079978, 0.956651797284509, 0.9572506182542102, 0.9576092349522709, 0.9576465906271976, 0.9579651065639941, 0.9582187819229436, 0.9583338073374579, 0.958340387613817, 0.9586894395876271, 0.958986767555464, 0.9599194211731059, 0.9604315309067963, 0.9604378275017792, 0.9605876986384577, 0.9607385646321882, 0.9609104516266815, 0.9610001222385441, 0.9608101974770222, 0.961134062362129, 0.9611757019167417, 0.961268569632753, 0.9614943588683529, 0.9612841696924587, 0.961068394536403, 0.9593361277649782, 0.960128120423941, 0.9606717602936192, 0.9609165818266483, 0.9607787360056346, 0.9608183884223754, 0.9610308741428603, 0.9609269504401173, 0.9611476975209142, 0.9609990576506524, 0.9607659301039426], 'mDice': [0.42006403713510876, 0.5750979541894039, 0.6174500618623413, 0.6348937614302319, 0.6500584413055278, 0.6636278898050837, 0.6729911304921722, 0.673936652780972, 0.683178456501906, 0.6911210000434862, 0.6930135231688134, 0.7033188189059671, 0.704980253430609, 0.7093753582466574, 0.7121508908104149, 0.7101346842244325, 0.7180767178457651, 0.7171912181495745, 0.7197751084338939, 0.7235580572802406, 0.7292907283337184, 0.7237019411855123, 0.7274923857550699, 0.7293653872334798, 0.732566309269052, 0.7428101699184131, 0.7491537623347029, 0.7504114078404233, 0.7520895845673439, 0.7536772343972121, 0.7540523825199253, 0.7556252688671783, 0.7538072953684206, 0.7565255913101102, 0.7578836538197274, 0.7559737688308541, 0.75623841951828, 0.757741910208715, 0.7551081454327996, 0.7386264338628692, 0.7430835295310251, 0.749951220698298, 0.7548212886362013, 0.7513416539166955, 0.7509001547698151, 0.7574406096631054, 0.7544063752278857, 0.754588903805522, 0.7543108076771633, 0.7541727741567564], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  2020-01-22 01:07:14.316229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 01:07:14.316320: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 01:07:14.316333: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 01:07:14.316340: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 01:07:14.316681: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97436874 0.02563126]
Train on 25479 samples, validate on 528 samples
Epoch 1/300
 - 68s - loss: 0.0746 - acc: 0.9909 - mDice: 0.8568 - val_loss: 0.2505 - val_acc: 0.9938 - val_mDice: 0.5023

Epoch 00001: val_mDice improved from -inf to 0.50235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 64s - loss: 0.0502 - acc: 0.9943 - mDice: 0.9027 - val_loss: 0.2512 - val_acc: 0.9941 - val_mDice: 0.5002

Epoch 00002: val_mDice did not improve from 0.50235
Epoch 3/300
 - 64s - loss: 0.0447 - acc: 0.9949 - mDice: 0.9132 - val_loss: 0.2479 - val_acc: 0.9938 - val_mDice: 0.5032

Epoch 00003: val_mDice improved from 0.50235 to 0.50324, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 4/300
 - 65s - loss: 0.0414 - acc: 0.9952 - mDice: 0.9197 - val_loss: 0.2478 - val_acc: 0.9940 - val_mDice: 0.4974

Epoch 00004: val_mDice did not improve from 0.50324
Epoch 5/300
 - 64s - loss: 0.0389 - acc: 0.9954 - mDice: 0.9245 - val_loss: 0.2229 - val_acc: 0.9942 - val_mDice: 0.5031

Epoch 00005: val_mDice did not improve from 0.50324
Epoch 6/300
 - 65s - loss: 0.0385 - acc: 0.9955 - mDice: 0.9253 - val_loss: 0.0204 - val_acc: 0.9945 - val_mDice: 0.5069

Epoch 00006: val_mDice improved from 0.50324 to 0.50694, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 7/300
 - 65s - loss: 0.0357 - acc: 0.9957 - mDice: 0.9307 - val_loss: 0.0982 - val_acc: 0.9942 - val_mDice: 0.5016

Epoch 00007: val_mDice did not improve from 0.50694
Epoch 8/300
 - 65s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9306 - val_loss: -4.2544e-03 - val_acc: 0.9941 - val_mDice: 0.4947

Epoch 00008: val_mDice did not improve from 0.50694
Epoch 9/300
 - 65s - loss: 0.0343 - acc: 0.9959 - mDice: 0.9334 - val_loss: -1.9728e-02 - val_acc: 0.9943 - val_mDice: 0.5086

Epoch 00009: val_mDice improved from 0.50694 to 0.50856, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 10/300
 - 65s - loss: 0.0335 - acc: 0.9960 - mDice: 0.9349 - val_loss: 0.0185 - val_acc: 0.9939 - val_mDice: 0.4879

Epoch 00010: val_mDice did not improve from 0.50856
Epoch 11/300
 - 65s - loss: 0.0332 - acc: 0.9960 - mDice: 0.9355 - val_loss: -1.9046e-02 - val_acc: 0.9946 - val_mDice: 0.5093

Epoch 00011: val_mDice improved from 0.50856 to 0.50932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 12/300
 - 65s - loss: 0.0324 - acc: 0.9961 - mDice: 0.9372 - val_loss: 0.0063 - val_acc: 0.9941 - val_mDice: 0.5043

Epoch 00012: val_mDice did not improve from 0.50932
Epoch 13/300
 - 66s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9374 - val_loss: 0.0112 - val_acc: 0.9942 - val_mDice: 0.5026

Epoch 00013: val_mDice did not improve from 0.50932
Epoch 14/300
 - 66s - loss: 0.0323 - acc: 0.9961 - mDice: 0.9372 - val_loss: -4.2218e-02 - val_acc: 0.9947 - val_mDice: 0.5172

Epoch 00014: val_mDice improved from 0.50932 to 0.51721, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 15/300
 - 65s - loss: 0.0311 - acc: 0.9962 - mDice: 0.9396 - val_loss: -5.0443e-02 - val_acc: 0.9945 - val_mDice: 0.5100

Epoch 00015: val_mDice did not improve from 0.51721
Epoch 16/300
 - 65s - loss: 0.0307 - acc: 0.9962 - mDice: 0.9404 - val_loss: -1.4709e-02 - val_acc: 0.9945 - val_mDice: 0.5098

Epoch 00016: val_mDice did not improve from 0.51721
Epoch 17/300
 - 65s - loss: 0.0306 - acc: 0.9962 - mDice: 0.9407 - val_loss: 0.0942 - val_acc: 0.9942 - val_mDice: 0.5192

Epoch 00017: val_mDice improved from 0.51721 to 0.51920, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 18/300
 - 65s - loss: 0.0307 - acc: 0.9962 - mDice: 0.9405 - val_loss: 0.0747 - val_acc: 0.9942 - val_mDice: 0.5231

Epoch 00018: val_mDice improved from 0.51920 to 0.52311, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd1/best_model_weights.h5
Epoch 19/300
 - 65s - loss: 0.0301 - acc: 0.9963 - mDice: 0.9416 - val_loss: -8.2042e-03 - val_acc: 0.9946 - val_mDice: 0.5044

Epoch 00019: val_mDice did not improve from 0.52311
Epoch 20/300
 - 65s - loss: 0.0300 - acc: 0.9963 - mDice: 0.9418 - val_loss: 0.0370 - val_acc: 0.9941 - val_mDice: 0.5116

Epoch 00020: val_mDice did not improve from 0.52311
Epoch 21/300
 - 65s - loss: 0.0295 - acc: 0.9963 - mDice: 0.9429 - val_loss: -3.2983e-02 - val_acc: 0.9947 - val_mDice: 0.5083

Epoch 00021: val_mDice did not improve from 0.52311
Epoch 22/300
 - 65s - loss: 0.0296 - acc: 0.9963 - mDice: 0.9426 - val_loss: -4.0508e-02 - val_acc: 0.9947 - val_mDice: 0.5076

Epoch 00022: val_mDice did not improve from 0.52311
Epoch 23/300
 - 66s - loss: 0.0293 - acc: 0.9963 - mDice: 0.9432 - val_loss: 0.0192 - val_acc: 0.9945 - val_mDice: 0.5177

Epoch 00023: val_mDice did not improve from 0.52311
Epoch 24/300
 - 65s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9433 - val_loss: -1.5176e-02 - val_acc: 0.9943 - val_mDice: 0.4965

Epoch 00024: val_mDice did not improve from 0.52311
Epoch 25/300
 - 65s - loss: 0.0289 - acc: 0.9964 - mDice: 0.9440 - val_loss: -8.3790e-03 - val_acc: 0.9944 - val_mDice: 0.5052

Epoch 00025: val_mDice did not improve from 0.52311
Epoch 26/300
 - 65s - loss: 0.0286 - acc: 0.9964 - mDice: 0.9445 - val_loss: -1.1719e-02 - val_acc: 0.9944 - val_mDice: 0.5044

Epoch 00026: val_mDice did not improve from 0.52311
Epoch 27/300
 - 65s - loss: 0.0285 - acc: 0.9964 - mDice: 0.9448 - val_loss: -8.2473e-02 - val_acc: 0.9945 - val_mDice: 0.4936

Epoch 00027: val_mDice did not improve from 0.52311
Epoch 28/300
 - 65s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9452 - val_loss: -2.4315e-02 - val_acc: 0.9944 - val_mDice: 0.4984

Epoch 00028: val_mDice did not improve from 0.52311
Epoch 29/300
 - 65s - loss: 0.0284 - acc: 0.9964 - mDice: 0.9450 - val_loss: -2.8878e-02 - val_acc: 0.9944 - val_mDice: 0.5002

Epoch 00029: val_mDice did not improve from 0.52311
Epoch 30/300
 - 65s - loss: 0.0282 - acc: 0.9965 - mDice: 0.9453 - val_loss: -1.2432e-02 - val_acc: 0.9943 - val_mDice: 0.5052

Epoch 00030: val_mDice did not improve from 0.52311
Epoch 31/300
 - 65s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9452 - val_loss: -3.2234e-02 - val_acc: 0.9946 - val_mDice: 0.5067

Epoch 00031: val_mDice did not improve from 0.52311
Epoch 32/300
 - 66s - loss: 0.0284 - acc: 0.9965 - mDice: 0.9449 - val_loss: -2.1596e-02 - val_acc: 0.9946 - val_mDice: 0.4925

Epoch 00032: val_mDice did not improve from 0.52311
Epoch 33/300
 - 67s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9452 - val_loss: -9.7171e-03 - val_acc: 0.9944 - val_mDice: 0.5001

Epoch 00033: val_mDice did not improve from 0.52311

Epoch 00033: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 34/300
 - 66s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9486 - val_loss: -2.9161e-02 - val_acc: 0.9947 - val_mDice: 0.5006

Epoch 00034: val_mDice did not improve from 0.52311
Epoch 35/300
 - 66s - loss: 0.0262 - acc: 0.9966 - mDice: 0.9492 - val_loss: -1.6148e-02 - val_acc: 0.9946 - val_mDice: 0.5075

Epoch 00035: val_mDice did not improve from 0.52311
Epoch 36/300
 - 67s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9494 - val_loss: 0.0073 - val_acc: 0.9946 - val_mDice: 0.4983

Epoch 00036: val_mDice did not improve from 0.52311
Epoch 37/300
 - 67s - loss: 0.0261 - acc: 0.9967 - mDice: 0.9493 - val_loss: -3.3374e-02 - val_acc: 0.9946 - val_mDice: 0.5091

Epoch 00037: val_mDice did not improve from 0.52311
Epoch 38/300
 - 67s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -1.3669e-02 - val_acc: 0.9947 - val_mDice: 0.5075

Epoch 00038: val_mDice did not improve from 0.52311
Epoch 39/300
 - 66s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -3.0718e-02 - val_acc: 0.9946 - val_mDice: 0.5040

Epoch 00039: val_mDice did not improve from 0.52311
Epoch 40/300
 - 66s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9509 - val_loss: -2.7950e-02 - val_acc: 0.9946 - val_mDice: 0.4982

Epoch 00040: val_mDice did not improve from 0.52311
Epoch 41/300
 - 66s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: -2.6847e-02 - val_acc: 0.9944 - val_mDice: 0.4961

Epoch 00041: val_mDice did not improve from 0.52311
Epoch 42/300
 - 67s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: 0.0071 - val_acc: 0.9947 - val_mDice: 0.5035

Epoch 00042: val_mDice did not improve from 0.52311
Epoch 43/300
 - 67s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9507 - val_loss: 0.0063 - val_acc: 0.9946 - val_mDice: 0.5057

Epoch 00043: val_mDice did not improve from 0.52311
Epoch 44/300
 - 67s - loss: 0.0253 - acc: 0.9967 - mDice: 0.9510 - val_loss: -2.8984e-02 - val_acc: 0.9945 - val_mDice: 0.5003

Epoch 00044: val_mDice did not improve from 0.52311
Epoch 45/300
 - 67s - loss: 0.0254 - acc: 0.9967 - mDice: 0.9508 - val_loss: -2.5247e-02 - val_acc: 0.9946 - val_mDice: 0.4949

Epoch 00045: val_mDice did not improve from 0.52311
Epoch 46/300
 - 67s - loss: 0.0250 - acc: 0.9968 - mDice: 0.9515 - val_loss: -1.3124e-02 - val_acc: 0.9947 - val_mDice: 0.5062

Epoch 00046: val_mDice did not improve from 0.52311
Epoch 47/300
 - 67s - loss: 0.0249 - acc: 0.9968 - mDice: 0.9517 - val_loss: -3.0020e-02 - val_acc: 0.9946 - val_mDice: 0.5023

Epoch 00047: val_mDice did not improve from 0.52311
Epoch 48/300
 - 66s - loss: 0.0249 - acc: 0.9968 - mDice: 0.9517 - val_loss: -1.2196e-02 - val_acc: 0.9946 - val_mDice: 0.5048

Epoch 00048: val_mDice did not improve from 0.52311

Epoch 00048: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 49/300
 - 65s - loss: 0.0244 - acc: 0.9968 - mDice: 0.9526 - val_loss: 0.0203 - val_acc: 0.9945 - val_mDice: 0.5156

Epoch 00049: val_mDice did not improve from 0.52311
Epoch 50/300
 - 66s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: -2.8815e-02 - val_acc: 0.9946 - val_mDice: 0.5000

Epoch 00050: val_mDice did not improve from 0.52311
Epoch 51/300
 - 65s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9539 - val_loss: -1.8635e-02 - val_acc: 0.9946 - val_mDice: 0.5054

Epoch 00051: val_mDice did not improve from 0.52311
Epoch 52/300
 - 66s - loss: 0.0238 - acc: 0.9968 - mDice: 0.9538 - val_loss: -2.7206e-02 - val_acc: 0.9946 - val_mDice: 0.4998

Epoch 00052: val_mDice did not improve from 0.52311
Epoch 53/300
 - 65s - loss: 0.0239 - acc: 0.9968 - mDice: 0.9537 - val_loss: -2.9173e-02 - val_acc: 0.9946 - val_mDice: 0.5006

Epoch 00053: val_mDice did not improve from 0.52311
Epoch 54/300
 - 65s - loss: 0.0237 - acc: 0.9969 - mDice: 0.9542 - val_loss: 0.0053 - val_acc: 0.9946 - val_mDice: 0.5077

Epoch 00054: val_mDice did not improve from 0.52311
Epoch 55/300
 - 65s - loss: 0.0236 - acc: 0.9968 - mDice: 0.9542 - val_loss: -2.7294e-02 - val_acc: 0.9946 - val_mDice: 0.4971

Epoch 00055: val_mDice did not improve from 0.52311
Epoch 56/300
 - 66s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9545 - val_loss: -1.0676e-02 - val_acc: 0.9945 - val_mDice: 0.5016

Epoch 00056: val_mDice did not improve from 0.52311
Epoch 57/300
 - 65s - loss: 0.0235 - acc: 0.9968 - mDice: 0.9545 - val_loss: -1.4475e-02 - val_acc: 0.9946 - val_mDice: 0.5092

Epoch 00057: val_mDice did not improve from 0.52311
Epoch 58/300
 - 65s - loss: 0.0237 - acc: 0.9969 - mDice: 0.9541 - val_loss: -1.3382e-02 - val_acc: 0.9946 - val_mDice: 0.5010

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.38it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.74it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.15it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.66it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.15it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.31it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:36,  6.70it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:35,  6.87it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:41,  5.94it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:42,  5.67it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:40,  5.92it/s]predicting train subjects:   2%|▏         | 6/247 [00:01<00:40,  6.00it/s]predicting train subjects:   3%|▎         | 7/247 [00:01<00:38,  6.20it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:37,  6.33it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:37,  6.32it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:36,  6.43it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:36,  6.48it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:36,  6.47it/s]predicting train subjects:   5%|▌         | 13/247 [00:02<00:36,  6.48it/s]predicting train subjects:   6%|▌         | 14/247 [00:02<00:35,  6.52it/s]predicting train subjects:   6%|▌         | 15/247 [00:02<00:35,  6.56it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:34,  6.62it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:35,  6.56it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:34,  6.56it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:34,  6.52it/s]predicting train subjects:   8%|▊         | 20/247 [00:03<00:34,  6.54it/s]predicting train subjects:   9%|▊         | 21/247 [00:03<00:34,  6.56it/s]predicting train subjects:   9%|▉         | 22/247 [00:03<00:34,  6.55it/s]predicting train subjects:   9%|▉         | 23/247 [00:03<00:33,  6.78it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:31,  6.97it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:31,  7.08it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:30,  7.21it/s]predicting train subjects:  11%|█         | 27/247 [00:04<00:30,  7.31it/s]predicting train subjects:  11%|█▏        | 28/247 [00:04<00:29,  7.37it/s]predicting train subjects:  12%|█▏        | 29/247 [00:04<00:29,  7.38it/s]predicting train subjects:  12%|█▏        | 30/247 [00:04<00:29,  7.42it/s]predicting train subjects:  13%|█▎        | 31/247 [00:04<00:29,  7.42it/s]predicting train subjects:  13%|█▎        | 32/247 [00:04<00:29,  7.41it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:28,  7.44it/s]predicting train subjects:  14%|█▍        | 34/247 [00:05<00:28,  7.46it/s]predicting train subjects:  14%|█▍        | 35/247 [00:05<00:28,  7.52it/s]predicting train subjects:  15%|█▍        | 36/247 [00:05<00:28,  7.51it/s]predicting train subjects:  15%|█▍        | 37/247 [00:05<00:28,  7.40it/s]predicting train subjects:  15%|█▌        | 38/247 [00:05<00:28,  7.45it/s]predicting train subjects:  16%|█▌        | 39/247 [00:05<00:28,  7.38it/s]predicting train subjects:  16%|█▌        | 40/247 [00:05<00:27,  7.42it/s]predicting train subjects:  17%|█▋        | 41/247 [00:06<00:28,  7.28it/s]predicting train subjects:  17%|█▋        | 42/247 [00:06<00:28,  7.14it/s]predicting train subjects:  17%|█▋        | 43/247 [00:06<00:28,  7.10it/s]predicting train subjects:  18%|█▊        | 44/247 [00:06<00:28,  7.05it/s]predicting train subjects:  18%|█▊        | 45/247 [00:06<00:28,  7.07it/s]predicting train subjects:  19%|█▊        | 46/247 [00:06<00:28,  7.09it/s]predicting train subjects:  19%|█▉        | 47/247 [00:06<00:28,  7.08it/s]predicting train subjects:  19%|█▉        | 48/247 [00:07<00:27,  7.12it/s]predicting train subjects:  20%|█▉        | 49/247 [00:07<00:28,  6.99it/s]predicting train subjects:  20%|██        | 50/247 [00:07<00:27,  7.08it/s]predicting train subjects:  21%|██        | 51/247 [00:07<00:28,  6.95it/s]predicting train subjects:  21%|██        | 52/247 [00:07<00:28,  6.93it/s]predicting train subjects:  21%|██▏       | 53/247 [00:07<00:27,  7.04it/s]predicting train subjects:  22%|██▏       | 54/247 [00:07<00:27,  6.95it/s]predicting train subjects:  22%|██▏       | 55/247 [00:08<00:27,  7.04it/s]predicting train subjects:  23%|██▎       | 56/247 [00:08<00:27,  7.06it/s]predicting train subjects:  23%|██▎       | 57/247 [00:08<00:26,  7.05it/s]predicting train subjects:  23%|██▎       | 58/247 [00:08<00:26,  7.13it/s]predicting train subjects:  24%|██▍       | 59/247 [00:08<00:28,  6.63it/s]predicting train subjects:  24%|██▍       | 60/247 [00:08<00:28,  6.55it/s]predicting train subjects:  25%|██▍       | 61/247 [00:08<00:28,  6.54it/s]predicting train subjects:  25%|██▌       | 62/247 [00:09<00:28,  6.51it/s]predicting train subjects:  26%|██▌       | 63/247 [00:09<00:29,  6.33it/s]predicting train subjects:  26%|██▌       | 64/247 [00:09<00:28,  6.34it/s]predicting train subjects:  26%|██▋       | 65/247 [00:09<00:28,  6.39it/s]predicting train subjects:  27%|██▋       | 66/247 [00:09<00:28,  6.34it/s]predicting train subjects:  27%|██▋       | 67/247 [00:09<00:27,  6.44it/s]predicting train subjects:  28%|██▊       | 68/247 [00:10<00:27,  6.48it/s]predicting train subjects:  28%|██▊       | 69/247 [00:10<00:28,  6.29it/s]predicting train subjects:  28%|██▊       | 70/247 [00:10<00:27,  6.38it/s]predicting train subjects:  29%|██▊       | 71/247 [00:10<00:27,  6.37it/s]predicting train subjects:  29%|██▉       | 72/247 [00:10<00:27,  6.41it/s]predicting train subjects:  30%|██▉       | 73/247 [00:10<00:27,  6.39it/s]predicting train subjects:  30%|██▉       | 74/247 [00:10<00:26,  6.43it/s]predicting train subjects:  30%|███       | 75/247 [00:11<00:27,  6.33it/s]predicting train subjects:  31%|███       | 76/247 [00:11<00:26,  6.38it/s]predicting train subjects:  31%|███       | 77/247 [00:11<00:31,  5.40it/s]predicting train subjects:  32%|███▏      | 78/247 [00:11<00:34,  4.95it/s]predicting train subjects:  32%|███▏      | 79/247 [00:11<00:31,  5.41it/s]predicting train subjects:  32%|███▏      | 80/247 [00:12<00:30,  5.43it/s]predicting train subjects:  33%|███▎      | 81/247 [00:12<00:33,  5.03it/s]predicting train subjects:  33%|███▎      | 82/247 [00:12<00:32,  5.09it/s]predicting train subjects:  34%|███▎      | 83/247 [00:12<00:31,  5.28it/s]predicting train subjects:  34%|███▍      | 84/247 [00:12<00:30,  5.33it/s]predicting train subjects:  34%|███▍      | 85/247 [00:13<00:29,  5.44it/s]predicting train subjects:  35%|███▍      | 86/247 [00:13<00:28,  5.57it/s]predicting train subjects:  35%|███▌      | 87/247 [00:13<00:28,  5.57it/s]predicting train subjects:  36%|███▌      | 88/247 [00:13<00:28,  5.62it/s]predicting train subjects:  36%|███▌      | 89/247 [00:13<00:27,  5.66it/s]predicting train subjects:  36%|███▋      | 90/247 [00:13<00:28,  5.59it/s]predicting train subjects:  37%|███▋      | 91/247 [00:14<00:27,  5.62it/s]predicting train subjects:  37%|███▋      | 92/247 [00:14<00:28,  5.45it/s]predicting train subjects:  38%|███▊      | 93/247 [00:14<00:28,  5.32it/s]predicting train subjects:  38%|███▊      | 94/247 [00:14<00:29,  5.24it/s]predicting train subjects:  38%|███▊      | 95/247 [00:14<00:29,  5.21it/s]predicting train subjects:  39%|███▉      | 96/247 [00:15<00:28,  5.35it/s]predicting train subjects:  39%|███▉      | 97/247 [00:15<00:27,  5.38it/s]predicting train subjects:  40%|███▉      | 98/247 [00:15<00:27,  5.34it/s]predicting train subjects:  40%|████      | 99/247 [00:15<00:27,  5.40it/s]predicting train subjects:  40%|████      | 100/247 [00:15<00:26,  5.57it/s]predicting train subjects:  41%|████      | 101/247 [00:15<00:25,  5.71it/s]predicting train subjects:  41%|████▏     | 102/247 [00:16<00:24,  5.82it/s]predicting train subjects:  42%|████▏     | 103/247 [00:16<00:24,  5.87it/s]predicting train subjects:  42%|████▏     | 104/247 [00:16<00:24,  5.93it/s]predicting train subjects:  43%|████▎     | 105/247 [00:16<00:23,  5.97it/s]predicting train subjects:  43%|████▎     | 106/247 [00:16<00:23,  5.96it/s]predicting train subjects:  43%|████▎     | 107/247 [00:16<00:23,  5.92it/s]predicting train subjects:  44%|████▎     | 108/247 [00:17<00:23,  5.81it/s]predicting train subjects:  44%|████▍     | 109/247 [00:17<00:23,  5.86it/s]predicting train subjects:  45%|████▍     | 110/247 [00:17<00:23,  5.92it/s]predicting train subjects:  45%|████▍     | 111/247 [00:17<00:22,  5.94it/s]predicting train subjects:  45%|████▌     | 112/247 [00:17<00:22,  5.98it/s]predicting train subjects:  46%|████▌     | 113/247 [00:17<00:22,  5.98it/s]predicting train subjects:  46%|████▌     | 114/247 [00:18<00:22,  6.00it/s]predicting train subjects:  47%|████▋     | 115/247 [00:18<00:21,  6.01it/s]predicting train subjects:  47%|████▋     | 116/247 [00:18<00:22,  5.93it/s]predicting train subjects:  47%|████▋     | 117/247 [00:18<00:22,  5.75it/s]predicting train subjects:  48%|████▊     | 118/247 [00:18<00:21,  5.95it/s]predicting train subjects:  48%|████▊     | 119/247 [00:18<00:21,  6.06it/s]predicting train subjects:  49%|████▊     | 120/247 [00:19<00:20,  6.18it/s]predicting train subjects:  49%|████▉     | 121/247 [00:19<00:19,  6.34it/s]predicting train subjects:  49%|████▉     | 122/247 [00:19<00:19,  6.39it/s]predicting train subjects:  50%|████▉     | 123/247 [00:19<00:19,  6.24it/s]predicting train subjects:  50%|█████     | 124/247 [00:19<00:19,  6.35it/s]predicting train subjects:  51%|█████     | 125/247 [00:19<00:19,  6.32it/s]predicting train subjects:  51%|█████     | 126/247 [00:20<00:18,  6.44it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:20<00:18,  6.42it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:20<00:18,  6.42it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:20<00:18,  6.52it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:20<00:17,  6.60it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:20<00:17,  6.66it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:20<00:17,  6.59it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:21<00:17,  6.65it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:21<00:16,  6.70it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:21<00:17,  6.58it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:21<00:16,  6.64it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:21<00:16,  6.74it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:21<00:15,  6.83it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:22<00:16,  6.65it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:22<00:16,  6.67it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:22<00:15,  6.78it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:22<00:15,  6.86it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:22<00:15,  6.92it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:22<00:14,  6.96it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:22<00:14,  6.88it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:23<00:14,  6.95it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:23<00:14,  6.98it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:23<00:14,  6.78it/s]predicting train subjects:  60%|██████    | 149/247 [00:23<00:14,  6.71it/s]predicting train subjects:  61%|██████    | 150/247 [00:23<00:14,  6.82it/s]predicting train subjects:  61%|██████    | 151/247 [00:23<00:14,  6.85it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:23<00:13,  6.91it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:24<00:13,  6.98it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:24<00:14,  6.47it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:24<00:14,  6.21it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:24<00:15,  6.06it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:24<00:15,  5.97it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:24<00:15,  5.90it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:25<00:15,  5.86it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:25<00:14,  5.85it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:25<00:14,  5.82it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:25<00:14,  5.81it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:25<00:14,  5.79it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:25<00:14,  5.75it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:26<00:15,  5.42it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:26<00:14,  5.47it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:26<00:14,  5.46it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:26<00:14,  5.44it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:26<00:14,  5.45it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:27<00:13,  5.53it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:27<00:13,  5.55it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:27<00:13,  5.49it/s]predicting train subjects:  70%|███████   | 173/247 [00:27<00:14,  5.15it/s]predicting train subjects:  70%|███████   | 174/247 [00:27<00:12,  5.63it/s]predicting train subjects:  71%|███████   | 175/247 [00:28<00:13,  5.24it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:28<00:12,  5.66it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:28<00:11,  5.89it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:28<00:11,  5.97it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:28<00:10,  6.19it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:28<00:10,  6.34it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:28<00:10,  6.46it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:29<00:10,  6.50it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:29<00:09,  6.64it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:29<00:09,  6.70it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:29<00:09,  6.75it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:29<00:09,  6.73it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:29<00:08,  6.70it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:29<00:08,  6.79it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:30<00:08,  6.84it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:30<00:08,  6.85it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:30<00:08,  6.90it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:30<00:07,  6.92it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:30<00:07,  6.86it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:30<00:07,  7.05it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:30<00:07,  7.04it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:31<00:07,  7.15it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:31<00:06,  7.27it/s]predicting train subjects:  80%|████████  | 198/247 [00:31<00:06,  7.34it/s]predicting train subjects:  81%|████████  | 199/247 [00:31<00:06,  7.43it/s]predicting train subjects:  81%|████████  | 200/247 [00:31<00:06,  7.45it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:31<00:06,  7.40it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:31<00:06,  7.46it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:32<00:05,  7.48it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:32<00:05,  7.52it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:32<00:05,  7.57it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:32<00:05,  7.33it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:32<00:05,  7.38it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:32<00:05,  7.40it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:32<00:05,  7.40it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:32<00:05,  7.31it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:33<00:04,  7.38it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:33<00:04,  7.22it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:33<00:04,  7.22it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:33<00:04,  7.22it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:33<00:04,  7.02it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:33<00:04,  7.06it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:33<00:04,  7.03it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:34<00:04,  7.07it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:34<00:03,  7.01it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:34<00:03,  6.97it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:34<00:03,  6.99it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:34<00:03,  7.07it/s]predicting train subjects:  90%|█████████ | 223/247 [00:34<00:03,  7.01it/s]predicting train subjects:  91%|█████████ | 224/247 [00:34<00:03,  7.02it/s]predicting train subjects:  91%|█████████ | 225/247 [00:35<00:03,  7.00it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:35<00:02,  7.03it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:35<00:02,  7.03it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:35<00:02,  7.04it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:35<00:02,  7.07it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:35<00:02,  6.49it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:36<00:02,  6.37it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:36<00:02,  6.25it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:36<00:02,  6.14it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:36<00:02,  6.11it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:36<00:01,  6.00it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:36<00:01,  5.95it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:37<00:01,  5.96it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:37<00:01,  5.95it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:37<00:01,  5.87it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:37<00:01,  5.70it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:37<00:01,  5.75it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:37<00:00,  5.72it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:38<00:00,  5.74it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:38<00:00,  5.82it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:38<00:00,  5.89it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:38<00:00,  5.93it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  5.98it/s]predicting train subjects: 100%|██████████| 247/247 [00:38<00:00,  6.38it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 75.19it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   4%|▎         | 9/247 [00:00<00:02, 80.02it/s]saving BB  train1-THALAMUS:   7%|▋         | 17/247 [00:00<00:02, 79.62it/s]saving BB  train1-THALAMUS:  11%|█         | 26/247 [00:00<00:02, 81.20it/s]saving BB  train1-THALAMUS:  14%|█▍        | 35/247 [00:00<00:02, 82.20it/s]saving BB  train1-THALAMUS:  18%|█▊        | 44/247 [00:00<00:02, 84.27it/s]saving BB  train1-THALAMUS:  21%|██▏       | 53/247 [00:00<00:02, 85.63it/s]saving BB  train1-THALAMUS:  25%|██▌       | 62/247 [00:00<00:02, 85.48it/s]saving BB  train1-THALAMUS:  28%|██▊       | 70/247 [00:00<00:02, 82.05it/s]saving BB  train1-THALAMUS:  32%|███▏      | 78/247 [00:00<00:02, 77.81it/s]saving BB  train1-THALAMUS:  35%|███▍      | 86/247 [00:01<00:02, 74.94it/s]saving BB  train1-THALAMUS:  38%|███▊      | 94/247 [00:01<00:02, 72.73it/s]saving BB  train1-THALAMUS:  41%|████▏     | 102/247 [00:01<00:02, 70.29it/s]saving BB  train1-THALAMUS:  45%|████▍     | 110/247 [00:01<00:01, 71.83it/s]saving BB  train1-THALAMUS:  48%|████▊     | 118/247 [00:01<00:01, 71.69it/s]saving BB  train1-THALAMUS:  51%|█████▏    | 127/247 [00:01<00:01, 74.10it/s]saving BB  train1-THALAMUS:  55%|█████▌    | 136/247 [00:01<00:01, 76.46it/s]saving BB  train1-THALAMUS:  59%|█████▊    | 145/247 [00:01<00:01, 77.77it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 154/247 [00:01<00:01, 79.22it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 162/247 [00:02<00:01, 75.05it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 170/247 [00:02<00:01, 75.59it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 178/247 [00:02<00:00, 76.77it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 186/247 [00:02<00:00, 76.00it/s]saving BB  train1-THALAMUS:  79%|███████▊  | 194/247 [00:02<00:00, 75.56it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 203/247 [00:02<00:00, 77.42it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 212/247 [00:02<00:00, 78.93it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 220/247 [00:02<00:00, 79.23it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 229/247 [00:02<00:00, 81.16it/s]saving BB  train1-THALAMUS:  96%|█████████▋| 238/247 [00:03<00:00, 79.77it/s]saving BB  train1-THALAMUS: 100%|█████████▉| 246/247 [00:03<00:00, 78.48it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 77.96it/s]
Epoch 00058: val_mDice did not improve from 0.52311
Restoring model weights from the end of the best epoch
Epoch 00058: early stopping
{'val_loss': [0.2504661600528793, 0.25122954992746765, 0.24790177358822388, 0.24779750720005145, 0.22290062938224187, 0.020445913923057644, 0.09816294648882115, -0.0042544070236159096, -0.01972795780183691, 0.01847432268727006, -0.019045762379061092, 0.006260099792570779, 0.011153174423132881, -0.04221777076070959, -0.05044338005510243, -0.014708781473790154, 0.09423140154191942, 0.07472466369808624, -0.008204162346594261, 0.03699342689166466, -0.03298311722888188, -0.04050785181761691, 0.01920580482957038, -0.015175763743393349, -0.008379010878729097, -0.01171928740134745, -0.08247280693754103, -0.024314659224315124, -0.02887774631381035, -0.012432313129080065, -0.03223355405145523, -0.02159643407459512, -0.009717110911327782, -0.029160978216113465, -0.0161478291124557, 0.007338446903635155, -0.033374450113059895, -0.013668998737226833, -0.03071759268641472, -0.02794958603088603, -0.026846555259191628, 0.007112254670849352, 0.006291147885900556, -0.02898447181690823, -0.025246742661252167, -0.013123565155899885, -0.03001991253007542, -0.012196222376642805, 0.02029083863916722, -0.02881465016892462, -0.018634845361565098, -0.027206019865292492, -0.029172730575682537, 0.005250642273687955, -0.027293831730882328, -0.010675700889392332, -0.014474539932879534, -0.013382302935827862], 'val_acc': [0.993807544762438, 0.9941469740235445, 0.9937955470699252, 0.9940036812966521, 0.9942071950345328, 0.9945096987666506, 0.9941797317429022, 0.9941229775096431, 0.9943193330457716, 0.9939049204642122, 0.9945752311385039, 0.9940966701868809, 0.994199350476265, 0.994748749516227, 0.9945450066165491, 0.9945120073177598, 0.9942166561430151, 0.9942030385136604, 0.9945950733892845, 0.9940703651218703, 0.9946509154908585, 0.9946553000446522, 0.9944910068403591, 0.9943020330234007, 0.9943774848273306, 0.9944448608792189, 0.9945053175994845, 0.9943654848770662, 0.9943608689037237, 0.994278262284669, 0.9946285343982957, 0.9946163030284824, 0.9944199395902229, 0.9946737549070156, 0.9945816883083546, 0.9946315315636721, 0.9946248339432658, 0.9946712171941092, 0.9946239150383256, 0.9945706185517889, 0.9943809448318048, 0.9946935994155479, 0.9946119207324404, 0.9945406186761279, 0.9946292263991905, 0.9946802177212455, 0.9945713105526838, 0.994638685249921, 0.9945078485391357, 0.9945544632095279, 0.9945793854016246, 0.9946271458810027, 0.9946303733370521, 0.9945595442797198, 0.9946163007707307, 0.9945403895143307, 0.9946340692765785, 0.9945909213839155], 'val_mDice': [0.5023499501332866, 0.5002213674581802, 0.50324200984147, 0.49735837505426334, 0.5030517629830049, 0.5069361488923712, 0.5015508277399661, 0.4947054356807688, 0.5085610722502073, 0.4879297171084382, 0.5093249244259134, 0.5043271150223315, 0.5025937650917209, 0.5172142911363732, 0.5100372803369255, 0.5098131838939012, 0.5191958769051648, 0.5231104387591282, 0.5043606953977635, 0.5116345135099962, 0.5083177800318508, 0.5075611481725266, 0.5177472876102636, 0.4964844006198374, 0.5051916264787781, 0.5044341737238662, 0.49357972065494854, 0.4984249693877769, 0.5002078528967545, 0.5052252771795562, 0.5067132505772668, 0.4924704972654581, 0.5000526520119962, 0.5005869794677128, 0.5075284686278213, 0.4983426430474289, 0.5090906414572001, 0.5074955448578817, 0.5039583640455296, 0.4981833801091731, 0.4961314186627936, 0.5034913298611801, 0.5056520230443319, 0.5003280452462989, 0.49486184097600705, 0.5062279480361295, 0.5023162797883605, 0.5047585181775062, 0.5155565231248285, 0.4999606960424871, 0.5053501886627174, 0.499813336737685, 0.5006420804725529, 0.5076670996543202, 0.4970855011858811, 0.5015700485461242, 0.509176644440176, 0.5009617357820921], 'loss': [0.07461088343181567, 0.050150668154009294, 0.04470928247436548, 0.0413787660614335, 0.03890907498683111, 0.03846799138962809, 0.0356873279136449, 0.03576566893543776, 0.034299585863130845, 0.03353955819246612, 0.0332329269334685, 0.03236411610677668, 0.03225812244824204, 0.0323446570348457, 0.03114374830849228, 0.030736858877087086, 0.03057449676514308, 0.0306678367230005, 0.030123030968834175, 0.03000129177862857, 0.029463907960136915, 0.029605474696016567, 0.029280854758617806, 0.02922181141606221, 0.0288552688913193, 0.028640781646106284, 0.028484243141191384, 0.028273145880615504, 0.028372807550984258, 0.02820875436340117, 0.02826782452909963, 0.02840330044297503, 0.02826109752535628, 0.02653606794328591, 0.026194519117089147, 0.026096329720513713, 0.02612090998567289, 0.02540997135788442, 0.02542745383719016, 0.02535283941924841, 0.025424223044490445, 0.025378380432959473, 0.025407293904795694, 0.025269800779925133, 0.02537353550336477, 0.025014039404917476, 0.024914483229319256, 0.024929029500869525, 0.02443894644262484, 0.02391367336495564, 0.023822964103326977, 0.02383427502685179, 0.02389513914404234, 0.023666018663777152, 0.023647925371960712, 0.023512296963160994, 0.02347939209373982, 0.023699505990283018], 'acc': [0.9909298848734344, 0.9943357977155398, 0.9948908344201837, 0.9951954562635305, 0.9954375340821694, 0.9955169866128003, 0.9957493709298607, 0.9957760149967801, 0.99590172906457, 0.9959691037370578, 0.9959797039689438, 0.9960641972222046, 0.9960973335307136, 0.9960812905565658, 0.9961899782425802, 0.9962354098133083, 0.9962396413056264, 0.9962165361998655, 0.9962891315575452, 0.9962976480200328, 0.9963372786802374, 0.9963355760142214, 0.9963489453999091, 0.9963923296485236, 0.9964115660902404, 0.9964240560834237, 0.9964455783734437, 0.9964562890092545, 0.9964418622639777, 0.9964657191195477, 0.996477481273557, 0.9964820484926218, 0.9964636534895748, 0.9965973441391848, 0.9966151708312787, 0.9966638092788077, 0.996677418070286, 0.9967139975406755, 0.9967066630392997, 0.9967130223278385, 0.9967035980332033, 0.9967277978886016, 0.9967128887618747, 0.9967410816489034, 0.996734946485432, 0.9967500468410958, 0.9967504821732652, 0.996755651333974, 0.9968191419657809, 0.9968372548205254, 0.9968226083177727, 0.9968420798351179, 0.996848425265267, 0.9968595806889549, 0.9968476835723817, 0.9968431845598016, 0.9968483484265306, 0.9968657011284718], 'mDice': [0.85675328418922, 0.9026690682093564, 0.913205434173934, 0.9196784643476736, 0.9244742769172051, 0.9253131950957569, 0.9307473157221268, 0.9305665940484941, 0.933430446408842, 0.934907071453524, 0.935509513447613, 0.9372054317143598, 0.9373956994090725, 0.9372394074403284, 0.9395752901947476, 0.9403667097268718, 0.9406843241756679, 0.9405148159817094, 0.9415634658138355, 0.9418027639328215, 0.9428513133898743, 0.9425710057219454, 0.9432051009265149, 0.9433137659745078, 0.9440260889733332, 0.9444541476918117, 0.9447527997857468, 0.9451673090132745, 0.9449710538297561, 0.945292231091862, 0.9451661111444902, 0.9448989327043532, 0.9451918833984433, 0.948551338912694, 0.949224476528119, 0.9494007796843332, 0.9493432724334095, 0.9507491140768158, 0.950716550442173, 0.9508638441401237, 0.9507218851619821, 0.9508040822667218, 0.950743358049322, 0.9510088904816594, 0.9508099627296434, 0.9515200686785091, 0.9517205780648873, 0.9516802425497559, 0.9526308091198932, 0.9536706620045166, 0.9538540461242206, 0.9538251182840133, 0.9536999868815115, 0.9541564561835151, 0.9541903948750188, 0.9544609607686015, 0.9545256952002572, 0.9540812461331929], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:01<04:10,  1.02s/it]Loading train:   1%|          | 2/247 [00:01<04:01,  1.01it/s]Loading train:   1%|          | 3/247 [00:02<03:48,  1.07it/s]Loading train:   2%|▏         | 4/247 [00:03<03:51,  1.05it/s]Loading train:   2%|▏         | 5/247 [00:04<03:29,  1.15it/s]Loading train:   2%|▏         | 6/247 [00:05<03:11,  1.26it/s]Loading train:   3%|▎         | 7/247 [00:05<03:01,  1.33it/s]Loading train:   3%|▎         | 8/247 [00:06<02:51,  1.40it/s]Loading train:   4%|▎         | 9/247 [00:07<02:48,  1.41it/s]Loading train:   4%|▍         | 10/247 [00:07<02:44,  1.44it/s]Loading train:   4%|▍         | 11/247 [00:08<02:42,  1.45it/s]Loading train:   5%|▍         | 12/247 [00:08<02:38,  1.48it/s]Loading train:   5%|▌         | 13/247 [00:09<02:33,  1.52it/s]Loading train:   6%|▌         | 14/247 [00:10<02:30,  1.54it/s]Loading train:   6%|▌         | 15/247 [00:10<02:32,  1.52it/s]Loading train:   6%|▋         | 16/247 [00:11<02:34,  1.50it/s]Loading train:   7%|▋         | 17/247 [00:12<02:34,  1.49it/s]Loading train:   7%|▋         | 18/247 [00:12<02:34,  1.48it/s]Loading train:   8%|▊         | 19/247 [00:13<02:32,  1.49it/s]Loading train:   8%|▊         | 20/247 [00:14<02:30,  1.51it/s]Loading train:   9%|▊         | 21/247 [00:14<02:26,  1.55it/s]Loading train:   9%|▉         | 22/247 [00:15<02:24,  1.55it/s]Loading train:   9%|▉         | 23/247 [00:16<02:20,  1.59it/s]Loading train:  10%|▉         | 24/247 [00:16<02:13,  1.67it/s]Loading train:  10%|█         | 25/247 [00:17<02:12,  1.67it/s]Loading train:  11%|█         | 26/247 [00:17<02:09,  1.71it/s]Loading train:  11%|█         | 27/247 [00:18<02:10,  1.68it/s]Loading train:  11%|█▏        | 28/247 [00:18<02:08,  1.70it/s]Loading train:  12%|█▏        | 29/247 [00:19<02:08,  1.70it/s]Loading train:  12%|█▏        | 30/247 [00:20<02:06,  1.71it/s]Loading train:  13%|█▎        | 31/247 [00:20<02:03,  1.75it/s]Loading train:  13%|█▎        | 32/247 [00:21<02:01,  1.76it/s]Loading train:  13%|█▎        | 33/247 [00:21<02:00,  1.78it/s]Loading train:  14%|█▍        | 34/247 [00:22<02:02,  1.74it/s]Loading train:  14%|█▍        | 35/247 [00:22<02:04,  1.71it/s]Loading train:  15%|█▍        | 36/247 [00:23<02:04,  1.69it/s]Loading train:  15%|█▍        | 37/247 [00:24<02:04,  1.69it/s]Loading train:  15%|█▌        | 38/247 [00:24<02:03,  1.69it/s]Loading train:  16%|█▌        | 39/247 [00:25<02:02,  1.69it/s]Loading train:  16%|█▌        | 40/247 [00:25<01:59,  1.73it/s]Loading train:  17%|█▋        | 41/247 [00:26<02:00,  1.71it/s]Loading train:  17%|█▋        | 42/247 [00:27<01:59,  1.72it/s]Loading train:  17%|█▋        | 43/247 [00:27<01:58,  1.72it/s]Loading train:  18%|█▊        | 44/247 [00:28<02:02,  1.66it/s]Loading train:  18%|█▊        | 45/247 [00:28<02:00,  1.67it/s]Loading train:  19%|█▊        | 46/247 [00:29<02:02,  1.64it/s]Loading train:  19%|█▉        | 47/247 [00:30<02:03,  1.62it/s]Loading train:  19%|█▉        | 48/247 [00:30<02:02,  1.62it/s]Loading train:  20%|█▉        | 49/247 [00:31<02:01,  1.62it/s]Loading train:  20%|██        | 50/247 [00:31<01:59,  1.65it/s]Loading train:  21%|██        | 51/247 [00:32<01:55,  1.70it/s]Loading train:  21%|██        | 52/247 [00:33<01:58,  1.64it/s]Loading train:  21%|██▏       | 53/247 [00:33<01:58,  1.64it/s]Loading train:  22%|██▏       | 54/247 [00:34<01:57,  1.65it/s]Loading train:  22%|██▏       | 55/247 [00:35<01:58,  1.62it/s]Loading train:  23%|██▎       | 56/247 [00:35<01:57,  1.62it/s]Loading train:  23%|██▎       | 57/247 [00:36<01:57,  1.62it/s]Loading train:  23%|██▎       | 58/247 [00:36<01:54,  1.65it/s]Loading train:  24%|██▍       | 59/247 [00:37<01:58,  1.59it/s]Loading train:  24%|██▍       | 60/247 [00:38<01:59,  1.56it/s]Loading train:  25%|██▍       | 61/247 [00:38<02:03,  1.51it/s]Loading train:  25%|██▌       | 62/247 [00:39<02:01,  1.53it/s]Loading train:  26%|██▌       | 63/247 [00:40<02:01,  1.52it/s]Loading train:  26%|██▌       | 64/247 [00:40<02:05,  1.46it/s]Loading train:  26%|██▋       | 65/247 [00:41<02:03,  1.48it/s]Loading train:  27%|██▋       | 66/247 [00:42<02:01,  1.48it/s]Loading train:  27%|██▋       | 67/247 [00:42<01:59,  1.51it/s]Loading train:  28%|██▊       | 68/247 [00:43<01:58,  1.51it/s]Loading train:  28%|██▊       | 69/247 [00:44<01:55,  1.54it/s]Loading train:  28%|██▊       | 70/247 [00:44<01:54,  1.54it/s]Loading train:  29%|██▊       | 71/247 [00:45<01:55,  1.53it/s]Loading train:  29%|██▉       | 72/247 [00:46<01:54,  1.53it/s]Loading train:  30%|██▉       | 73/247 [00:46<01:54,  1.52it/s]Loading train:  30%|██▉       | 74/247 [00:47<01:55,  1.50it/s]Loading train:  30%|███       | 75/247 [00:48<01:52,  1.52it/s]Loading train:  31%|███       | 76/247 [00:48<01:52,  1.52it/s]Loading train:  31%|███       | 77/247 [00:50<02:17,  1.23it/s]Loading train:  32%|███▏      | 78/247 [00:51<02:27,  1.14it/s]Loading train:  32%|███▏      | 79/247 [00:52<02:32,  1.10it/s]Loading train:  32%|███▏      | 80/247 [00:52<02:27,  1.13it/s]Loading train:  33%|███▎      | 81/247 [00:53<02:31,  1.10it/s]Loading train:  33%|███▎      | 82/247 [00:54<02:25,  1.13it/s]Loading train:  34%|███▎      | 83/247 [00:55<02:20,  1.17it/s]Loading train:  34%|███▍      | 84/247 [00:56<02:17,  1.19it/s]Loading train:  34%|███▍      | 85/247 [00:57<02:13,  1.21it/s]Loading train:  35%|███▍      | 86/247 [00:57<02:10,  1.23it/s]Loading train:  35%|███▌      | 87/247 [00:58<02:07,  1.26it/s]Loading train:  36%|███▌      | 88/247 [00:59<02:04,  1.28it/s]Loading train:  36%|███▌      | 89/247 [01:00<02:04,  1.27it/s]Loading train:  36%|███▋      | 90/247 [01:00<02:02,  1.28it/s]Loading train:  37%|███▋      | 91/247 [01:01<02:05,  1.24it/s]Loading train:  37%|███▋      | 92/247 [01:02<02:01,  1.27it/s]Loading train:  38%|███▊      | 93/247 [01:03<02:02,  1.26it/s]Loading train:  38%|███▊      | 94/247 [01:04<01:59,  1.28it/s]Loading train:  38%|███▊      | 95/247 [01:04<01:56,  1.30it/s]Loading train:  39%|███▉      | 96/247 [01:05<01:59,  1.27it/s]Loading train:  39%|███▉      | 97/247 [01:06<01:59,  1.26it/s]Loading train:  40%|███▉      | 98/247 [01:07<01:58,  1.25it/s]Loading train:  40%|████      | 99/247 [01:08<01:58,  1.25it/s]Loading train:  40%|████      | 100/247 [01:08<01:52,  1.30it/s]Loading train:  41%|████      | 101/247 [01:09<01:46,  1.37it/s]Loading train:  41%|████▏     | 102/247 [01:10<01:42,  1.42it/s]Loading train:  42%|████▏     | 103/247 [01:10<01:40,  1.43it/s]Loading train:  42%|████▏     | 104/247 [01:11<01:38,  1.45it/s]Loading train:  43%|████▎     | 105/247 [01:12<01:38,  1.44it/s]Loading train:  43%|████▎     | 106/247 [01:12<01:37,  1.44it/s]Loading train:  43%|████▎     | 107/247 [01:13<01:35,  1.46it/s]Loading train:  44%|████▎     | 108/247 [01:14<01:35,  1.46it/s]Loading train:  44%|████▍     | 109/247 [01:14<01:35,  1.45it/s]Loading train:  45%|████▍     | 110/247 [01:15<01:32,  1.49it/s]Loading train:  45%|████▍     | 111/247 [01:16<01:32,  1.47it/s]Loading train:  45%|████▌     | 112/247 [01:16<01:30,  1.49it/s]Loading train:  46%|████▌     | 113/247 [01:17<01:31,  1.47it/s]Loading train:  46%|████▌     | 114/247 [01:18<01:31,  1.46it/s]Loading train:  47%|████▋     | 115/247 [01:18<01:30,  1.46it/s]Loading train:  47%|████▋     | 116/247 [01:19<01:28,  1.47it/s]Loading train:  47%|████▋     | 117/247 [01:20<01:27,  1.49it/s]Loading train:  48%|████▊     | 118/247 [01:20<01:25,  1.51it/s]Loading train:  48%|████▊     | 119/247 [01:21<01:24,  1.52it/s]Loading train:  49%|████▊     | 120/247 [01:22<01:23,  1.51it/s]Loading train:  49%|████▉     | 121/247 [01:22<01:23,  1.50it/s]Loading train:  49%|████▉     | 122/247 [01:23<01:22,  1.51it/s]Loading train:  50%|████▉     | 123/247 [01:24<01:22,  1.51it/s]Loading train:  50%|█████     | 124/247 [01:24<01:20,  1.53it/s]Loading train:  51%|█████     | 125/247 [01:25<01:18,  1.55it/s]Loading train:  51%|█████     | 126/247 [01:26<01:17,  1.55it/s]Loading train:  51%|█████▏    | 127/247 [01:26<01:17,  1.55it/s]Loading train:  52%|█████▏    | 128/247 [01:27<01:17,  1.54it/s]Loading train:  52%|█████▏    | 129/247 [01:28<01:16,  1.54it/s]Loading train:  53%|█████▎    | 130/247 [01:28<01:15,  1.55it/s]Loading train:  53%|█████▎    | 131/247 [01:29<01:15,  1.55it/s]Loading train:  53%|█████▎    | 132/247 [01:29<01:13,  1.56it/s]Loading train:  54%|█████▍    | 133/247 [01:30<01:13,  1.56it/s]Loading train:  54%|█████▍    | 134/247 [01:31<01:13,  1.54it/s]Loading train:  55%|█████▍    | 135/247 [01:31<01:11,  1.57it/s]Loading train:  55%|█████▌    | 136/247 [01:32<01:08,  1.61it/s]Loading train:  55%|█████▌    | 137/247 [01:33<01:07,  1.63it/s]Loading train:  56%|█████▌    | 138/247 [01:33<01:06,  1.64it/s]Loading train:  56%|█████▋    | 139/247 [01:34<01:05,  1.64it/s]Loading train:  57%|█████▋    | 140/247 [01:34<01:04,  1.66it/s]Loading train:  57%|█████▋    | 141/247 [01:35<01:03,  1.67it/s]Loading train:  57%|█████▋    | 142/247 [01:35<01:02,  1.68it/s]Loading train:  58%|█████▊    | 143/247 [01:36<01:01,  1.68it/s]Loading train:  58%|█████▊    | 144/247 [01:37<01:00,  1.71it/s]Loading train:  59%|█████▊    | 145/247 [01:37<00:59,  1.72it/s]Loading train:  59%|█████▉    | 146/247 [01:38<01:00,  1.67it/s]Loading train:  60%|█████▉    | 147/247 [01:38<00:59,  1.68it/s]Loading train:  60%|█████▉    | 148/247 [01:39<00:59,  1.67it/s]Loading train:  60%|██████    | 149/247 [01:40<00:58,  1.68it/s]Loading train:  61%|██████    | 150/247 [01:40<00:58,  1.67it/s]Loading train:  61%|██████    | 151/247 [01:41<00:57,  1.68it/s]Loading train:  62%|██████▏   | 152/247 [01:41<00:56,  1.69it/s]Loading train:  62%|██████▏   | 153/247 [01:42<00:55,  1.68it/s]Loading train:  62%|██████▏   | 154/247 [01:43<00:57,  1.62it/s]Loading train:  63%|██████▎   | 155/247 [01:43<00:57,  1.59it/s]Loading train:  63%|██████▎   | 156/247 [01:44<00:59,  1.54it/s]Loading train:  64%|██████▎   | 157/247 [01:45<00:59,  1.50it/s]Loading train:  64%|██████▍   | 158/247 [01:45<00:58,  1.51it/s]Loading train:  64%|██████▍   | 159/247 [01:46<00:57,  1.52it/s]Loading train:  65%|██████▍   | 160/247 [01:47<00:57,  1.51it/s]Loading train:  65%|██████▌   | 161/247 [01:47<00:56,  1.53it/s]Loading train:  66%|██████▌   | 162/247 [01:48<00:55,  1.53it/s]Loading train:  66%|██████▌   | 163/247 [01:49<00:55,  1.52it/s]Loading train:  66%|██████▋   | 164/247 [01:49<00:54,  1.51it/s]Loading train:  67%|██████▋   | 165/247 [01:50<00:55,  1.49it/s]Loading train:  67%|██████▋   | 166/247 [01:51<00:54,  1.50it/s]Loading train:  68%|██████▊   | 167/247 [01:51<00:53,  1.51it/s]Loading train:  68%|██████▊   | 168/247 [01:52<00:51,  1.53it/s]Loading train:  68%|██████▊   | 169/247 [01:53<00:50,  1.54it/s]Loading train:  69%|██████▉   | 170/247 [01:53<00:49,  1.54it/s]Loading train:  69%|██████▉   | 171/247 [01:54<00:49,  1.52it/s]Loading train:  70%|██████▉   | 172/247 [01:55<00:55,  1.36it/s]Loading train:  70%|███████   | 173/247 [01:56<00:57,  1.29it/s]Loading train:  70%|███████   | 174/247 [01:57<00:57,  1.26it/s]Loading train:  71%|███████   | 175/247 [01:58<01:01,  1.17it/s]Loading train:  71%|███████▏  | 176/247 [01:58<00:55,  1.28it/s]Loading train:  72%|███████▏  | 177/247 [01:59<00:50,  1.38it/s]Loading train:  72%|███████▏  | 178/247 [01:59<00:47,  1.46it/s]Loading train:  72%|███████▏  | 179/247 [02:00<00:44,  1.51it/s]Loading train:  73%|███████▎  | 180/247 [02:01<00:42,  1.57it/s]Loading train:  73%|███████▎  | 181/247 [02:01<00:41,  1.61it/s]Loading train:  74%|███████▎  | 182/247 [02:02<00:39,  1.63it/s]Loading train:  74%|███████▍  | 183/247 [02:02<00:39,  1.62it/s]Loading train:  74%|███████▍  | 184/247 [02:03<00:39,  1.61it/s]Loading train:  75%|███████▍  | 185/247 [02:04<00:38,  1.61it/s]Loading train:  75%|███████▌  | 186/247 [02:04<00:37,  1.61it/s]Loading train:  76%|███████▌  | 187/247 [02:05<00:37,  1.61it/s]Loading train:  76%|███████▌  | 188/247 [02:05<00:37,  1.59it/s]Loading train:  77%|███████▋  | 189/247 [02:06<00:36,  1.60it/s]Loading train:  77%|███████▋  | 190/247 [02:07<00:35,  1.61it/s]Loading train:  77%|███████▋  | 191/247 [02:07<00:35,  1.60it/s]Loading train:  78%|███████▊  | 192/247 [02:08<00:34,  1.60it/s]Loading train:  78%|███████▊  | 193/247 [02:09<00:34,  1.57it/s]Loading train:  79%|███████▊  | 194/247 [02:09<00:33,  1.58it/s]Loading train:  79%|███████▉  | 195/247 [02:10<00:32,  1.58it/s]Loading train:  79%|███████▉  | 196/247 [02:11<00:32,  1.59it/s]Loading train:  80%|███████▉  | 197/247 [02:11<00:30,  1.63it/s]Loading train:  80%|████████  | 198/247 [02:12<00:29,  1.64it/s]Loading train:  81%|████████  | 199/247 [02:12<00:28,  1.67it/s]Loading train:  81%|████████  | 200/247 [02:13<00:27,  1.70it/s]Loading train:  81%|████████▏ | 201/247 [02:13<00:27,  1.69it/s]Loading train:  82%|████████▏ | 202/247 [02:14<00:26,  1.70it/s]Loading train:  82%|████████▏ | 203/247 [02:15<00:25,  1.70it/s]Loading train:  83%|████████▎ | 204/247 [02:15<00:25,  1.70it/s]Loading train:  83%|████████▎ | 205/247 [02:16<00:25,  1.67it/s]Loading train:  83%|████████▎ | 206/247 [02:16<00:24,  1.66it/s]Loading train:  84%|████████▍ | 207/247 [02:17<00:24,  1.65it/s]Loading train:  84%|████████▍ | 208/247 [02:18<00:23,  1.65it/s]Loading train:  85%|████████▍ | 209/247 [02:18<00:23,  1.65it/s]Loading train:  85%|████████▌ | 210/247 [02:19<00:22,  1.67it/s]Loading train:  85%|████████▌ | 211/247 [02:19<00:21,  1.64it/s]Loading train:  86%|████████▌ | 212/247 [02:20<00:21,  1.61it/s]Loading train:  86%|████████▌ | 213/247 [02:21<00:20,  1.64it/s]Loading train:  87%|████████▋ | 214/247 [02:21<00:21,  1.50it/s]Loading train:  87%|████████▋ | 215/247 [02:24<00:34,  1.08s/it]Loading train:  87%|████████▋ | 216/247 [02:27<00:57,  1.85s/it]Loading train:  88%|████████▊ | 217/247 [02:31<01:14,  2.49s/it]Loading train:  88%|████████▊ | 218/247 [02:35<01:27,  3.01s/it]Loading train:  89%|████████▊ | 219/247 [02:39<01:32,  3.30s/it]Loading train:  89%|████████▉ | 220/247 [02:43<01:32,  3.41s/it]Loading train:  89%|████████▉ | 221/247 [02:47<01:33,  3.59s/it]Loading train:  90%|████████▉ | 222/247 [02:51<01:30,  3.64s/it]Loading train:  90%|█████████ | 223/247 [02:54<01:27,  3.63s/it]Loading train:  91%|█████████ | 224/247 [02:58<01:24,  3.69s/it]Loading train:  91%|█████████ | 225/247 [03:02<01:23,  3.79s/it]Loading train:  91%|█████████▏| 226/247 [03:06<01:20,  3.84s/it]Loading train:  92%|█████████▏| 227/247 [03:10<01:18,  3.93s/it]Loading train:  92%|█████████▏| 228/247 [03:14<01:15,  3.99s/it]Loading train:  93%|█████████▎| 229/247 [03:18<01:10,  3.89s/it]Loading train:  93%|█████████▎| 230/247 [03:24<01:16,  4.52s/it]Loading train:  94%|█████████▎| 231/247 [03:30<01:19,  4.95s/it]Loading train:  94%|█████████▍| 232/247 [03:36<01:19,  5.27s/it]Loading train:  94%|█████████▍| 233/247 [03:42<01:17,  5.51s/it]Loading train:  95%|█████████▍| 234/247 [03:48<01:13,  5.63s/it]Loading train:  95%|█████████▌| 235/247 [03:54<01:09,  5.83s/it]Loading train:  96%|█████████▌| 236/247 [04:01<01:05,  5.97s/it]Loading train:  96%|█████████▌| 237/247 [04:06<00:57,  5.76s/it]Loading train:  96%|█████████▋| 238/247 [04:12<00:52,  5.84s/it]Loading train:  97%|█████████▋| 239/247 [04:18<00:47,  5.92s/it]Loading train:  97%|█████████▋| 240/247 [04:24<00:41,  5.92s/it]Loading train:  98%|█████████▊| 241/247 [04:30<00:35,  5.86s/it]Loading train:  98%|█████████▊| 242/247 [04:36<00:29,  5.88s/it]Loading train:  98%|█████████▊| 243/247 [04:42<00:23,  5.94s/it]Loading train:  99%|█████████▉| 244/247 [04:48<00:17,  5.93s/it]Loading train:  99%|█████████▉| 245/247 [04:54<00:11,  5.93s/it]Loading train: 100%|█████████▉| 246/247 [05:00<00:05,  5.98s/it]Loading train: 100%|██████████| 247/247 [05:05<00:00,  5.71s/it]Loading train: 100%|██████████| 247/247 [05:05<00:00,  1.24s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/247 [00:00<00:04, 48.56it/s]concatenating: train:   4%|▍         | 11/247 [00:00<00:04, 48.41it/s]concatenating: train:   6%|▋         | 16/247 [00:00<00:04, 48.85it/s]concatenating: train:   9%|▊         | 21/247 [00:00<00:04, 48.13it/s]concatenating: train:  11%|█         | 27/247 [00:00<00:04, 49.92it/s]concatenating: train:  13%|█▎        | 33/247 [00:00<00:04, 51.68it/s]concatenating: train:  16%|█▌        | 39/247 [00:00<00:04, 51.55it/s]concatenating: train:  18%|█▊        | 45/247 [00:00<00:03, 51.49it/s]concatenating: train:  20%|██        | 50/247 [00:00<00:03, 50.52it/s]concatenating: train:  23%|██▎       | 56/247 [00:01<00:03, 50.91it/s]concatenating: train:  25%|██▌       | 62/247 [00:01<00:03, 51.25it/s]concatenating: train:  28%|██▊       | 68/247 [00:01<00:03, 51.46it/s]concatenating: train:  30%|██▉       | 74/247 [00:01<00:03, 50.37it/s]concatenating: train:  32%|███▏      | 79/247 [00:01<00:03, 49.51it/s]concatenating: train:  34%|███▍      | 84/247 [00:01<00:03, 48.03it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:03, 46.39it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:03, 45.34it/s]concatenating: train:  40%|████      | 99/247 [00:02<00:03, 44.31it/s]concatenating: train:  43%|████▎     | 105/247 [00:02<00:03, 46.73it/s]concatenating: train:  45%|████▍     | 111/247 [00:02<00:02, 48.19it/s]concatenating: train:  47%|████▋     | 116/247 [00:02<00:02, 48.30it/s]concatenating: train:  49%|████▉     | 122/247 [00:02<00:02, 48.86it/s]concatenating: train:  51%|█████▏    | 127/247 [00:02<00:02, 48.91it/s]concatenating: train:  53%|█████▎    | 132/247 [00:02<00:02, 49.08it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:02, 49.27it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:02, 50.85it/s]concatenating: train:  60%|██████    | 149/247 [00:02<00:01, 52.31it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 53.31it/s]concatenating: train:  65%|██████▌   | 161/247 [00:03<00:01, 53.97it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:01, 54.20it/s]concatenating: train:  70%|███████   | 173/247 [00:03<00:01, 53.66it/s]concatenating: train:  72%|███████▏  | 179/247 [00:03<00:01, 53.01it/s]concatenating: train:  75%|███████▍  | 185/247 [00:03<00:01, 52.50it/s]concatenating: train:  77%|███████▋  | 191/247 [00:03<00:01, 52.06it/s]concatenating: train:  80%|███████▉  | 197/247 [00:03<00:00, 50.59it/s]concatenating: train:  82%|████████▏ | 203/247 [00:04<00:00, 49.89it/s]concatenating: train:  85%|████████▍ | 209/247 [00:04<00:00, 49.09it/s]concatenating: train:  87%|████████▋ | 215/247 [00:04<00:00, 49.81it/s]concatenating: train:  89%|████████▉ | 220/247 [00:04<00:00, 47.10it/s]concatenating: train:  91%|█████████ | 225/247 [00:04<00:00, 47.30it/s]concatenating: train:  93%|█████████▎| 230/247 [00:04<00:00, 46.92it/s]concatenating: train:  95%|█████████▌| 235/247 [00:04<00:00, 47.56it/s]concatenating: train:  97%|█████████▋| 240/247 [00:04<00:00, 46.62it/s]concatenating: train:  99%|█████████▉| 245/247 [00:04<00:00, 47.32it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 49.69it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:12<00:49, 12.39s/it]Loading test:  40%|████      | 2/5 [00:27<00:40, 13.34s/it]Loading test:  60%|██████    | 3/5 [00:33<00:22, 11.09s/it]Loading test:  80%|████████  | 4/5 [00:37<00:09,  9.01s/it]Loading test: 100%|██████████| 5/5 [00:49<00:00,  9.64s/it]Loading test: 100%|██████████| 5/5 [00:49<00:00,  9.81s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 54.65it/s]  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   2020-01-22 02:19:16.810054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 02:19:16.810159: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 02:19:16.810173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 02:19:16.810180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 02:19:16.810499: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.53195294e-02 3.19817136e-02 7.71736888e-02 9.62175898e-03
 2.75479014e-02 7.05545775e-03 8.86701087e-02 1.14565962e-01
 8.20926937e-02 1.27740951e-02 2.89954984e-01 1.92989519e-01
 2.52586982e-04]
Train on 15595 samples, validate on 322 samples
Epoch 1/300
 - 39s - loss: 0.5383 - acc: 0.9039 - mDice: 0.4198 - val_loss: 0.7486 - val_acc: 0.9458 - val_mDice: 0.1900

Epoch 00001: val_mDice improved from -inf to 0.18999, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 34s - loss: 0.4007 - acc: 0.9398 - mDice: 0.5680 - val_loss: 0.7198 - val_acc: 0.9482 - val_mDice: 0.2216

Epoch 00002: val_mDice improved from 0.18999 to 0.22157, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 34s - loss: 0.3688 - acc: 0.9436 - mDice: 0.6026 - val_loss: 0.6915 - val_acc: 0.9479 - val_mDice: 0.2103

Epoch 00003: val_mDice did not improve from 0.22157
Epoch 4/300
 - 34s - loss: 0.3588 - acc: 0.9454 - mDice: 0.6133 - val_loss: 0.6830 - val_acc: 0.9496 - val_mDice: 0.2177

Epoch 00004: val_mDice did not improve from 0.22157
Epoch 5/300
 - 34s - loss: 0.3455 - acc: 0.9469 - mDice: 0.6277 - val_loss: 0.5352 - val_acc: 0.9507 - val_mDice: 0.2120

Epoch 00005: val_mDice did not improve from 0.22157
Epoch 6/300
 - 35s - loss: 0.3367 - acc: 0.9480 - mDice: 0.6372 - val_loss: 0.3832 - val_acc: 0.9502 - val_mDice: 0.2140

Epoch 00006: val_mDice did not improve from 0.22157
Epoch 7/300
 - 35s - loss: 0.3305 - acc: 0.9488 - mDice: 0.6439 - val_loss: 0.4993 - val_acc: 0.9507 - val_mDice: 0.2139

Epoch 00007: val_mDice did not improve from 0.22157
Epoch 8/300
 - 35s - loss: 0.3242 - acc: 0.9497 - mDice: 0.6508 - val_loss: 0.2571 - val_acc: 0.9506 - val_mDice: 0.2073

Epoch 00008: val_mDice did not improve from 0.22157
Epoch 9/300
 - 35s - loss: 0.3209 - acc: 0.9501 - mDice: 0.6542 - val_loss: 0.1813 - val_acc: 0.9481 - val_mDice: 0.2141

Epoch 00009: val_mDice did not improve from 0.22157
Epoch 10/300
 - 35s - loss: 0.3121 - acc: 0.9507 - mDice: 0.6637 - val_loss: 0.0461 - val_acc: 0.9503 - val_mDice: 0.2142

Epoch 00010: val_mDice did not improve from 0.22157
Epoch 11/300
 - 35s - loss: 0.3122 - acc: 0.9512 - mDice: 0.6636 - val_loss: -7.4705e-02 - val_acc: 0.9513 - val_mDice: 0.2154

Epoch 00011: val_mDice did not improve from 0.22157
Epoch 12/300
 - 35s - loss: 0.3099 - acc: 0.9513 - mDice: 0.6662 - val_loss: -1.4157e-01 - val_acc: 0.9528 - val_mDice: 0.2135

Epoch 00012: val_mDice did not improve from 0.22157
Epoch 13/300
 - 36s - loss: 0.3047 - acc: 0.9517 - mDice: 0.6717 - val_loss: -8.5704e-02 - val_acc: 0.9515 - val_mDice: 0.2096

Epoch 00013: val_mDice did not improve from 0.22157
Epoch 14/300
 - 35s - loss: 0.3059 - acc: 0.9519 - mDice: 0.6705 - val_loss: -7.4160e-02 - val_acc: 0.9511 - val_mDice: 0.2132

Epoch 00014: val_mDice did not improve from 0.22157
Epoch 15/300
 - 36s - loss: 0.3024 - acc: 0.9521 - mDice: 0.6742 - val_loss: -9.9486e-02 - val_acc: 0.9511 - val_mDice: 0.2149

Epoch 00015: val_mDice did not improve from 0.22157
Epoch 16/300
 - 34s - loss: 0.2993 - acc: 0.9527 - mDice: 0.6776 - val_loss: -1.5530e-01 - val_acc: 0.9517 - val_mDice: 0.2160

Epoch 00016: val_mDice did not improve from 0.22157
Epoch 17/300
 - 34s - loss: 0.3014 - acc: 0.9525 - mDice: 0.6753 - val_loss: -1.3872e-01 - val_acc: 0.9509 - val_mDice: 0.1984

Epoch 00017: val_mDice did not improve from 0.22157

Epoch 00017: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 18/300
 - 34s - loss: 0.2874 - acc: 0.9537 - mDice: 0.6904 - val_loss: -1.8072e-01 - val_acc: 0.9523 - val_mDice: 0.2110

Epoch 00018: val_mDice did not improve from 0.22157
Epoch 19/300
 - 34s - loss: 0.2830 - acc: 0.9545 - mDice: 0.6951 - val_loss: -1.9905e-01 - val_acc: 0.9520 - val_mDice: 0.2094

Epoch 00019: val_mDice did not improve from 0.22157
Epoch 20/300
 - 34s - loss: 0.2843 - acc: 0.9545 - mDice: 0.6937 - val_loss: -1.6652e-01 - val_acc: 0.9513 - val_mDice: 0.2115

Epoch 00020: val_mDice did not improve from 0.22157
Epoch 21/300
 - 34s - loss: 0.2807 - acc: 0.9548 - mDice: 0.6976 - val_loss: -1.4225e-01 - val_acc: 0.9521 - val_mDice: 0.2115

Epoch 00021: val_mDice did not improve from 0.22157
Epoch 22/300
 - 34s - loss: 0.2782 - acc: 0.9550 - mDice: 0.7003 - val_loss: -1.5664e-01 - val_acc: 0.9531 - val_mDice: 0.2130

Epoch 00022: val_mDice did not improve from 0.22157
Epoch 23/300
 - 34s - loss: 0.2787 - acc: 0.9551 - mDice: 0.6998 - val_loss: -1.7330e-01 - val_acc: 0.9525 - val_mDice: 0.2119

Epoch 00023: val_mDice did not improve from 0.22157
Epoch 24/300
 - 34s - loss: 0.2757 - acc: 0.9552 - mDice: 0.7029 - val_loss: -2.0259e-01 - val_acc: 0.9525 - val_mDice: 0.2107

Epoch 00024: val_mDice did not improve from 0.22157
Epoch 25/300
 - 35s - loss: 0.2737 - acc: 0.9555 - mDice: 0.7049 - val_loss: -1.8164e-01 - val_acc: 0.9526 - val_mDice: 0.2091

Epoch 00025: val_mDice did not improve from 0.22157
Epoch 26/300
 - 34s - loss: 0.2736 - acc: 0.9532 - mDice: 0.6855 - val_loss: -1.9654e-01 - val_acc: 0.9507 - val_mDice: 0.2009

Epoch 00026: val_mDice did not improve from 0.22157
Epoch 27/300
 - 33s - loss: 0.2546 - acc: 0.9526 - mDice: 0.6810 - val_loss: -2.4235e-01 - val_acc: 0.9516 - val_mDice: 0.2064

Epoch 00027: val_mDice did not improve from 0.22157
Epoch 28/300
 - 33s - loss: 0.2452 - acc: 0.9526 - mDice: 0.6749 - val_loss: -1.1795e-01 - val_acc: 0.9404 - val_mDice: 0.1591

Epoch 00028: val_mDice did not improve from 0.22157
Epoch 29/300
 - 33s - loss: 0.2472 - acc: 0.9521 - mDice: 0.6626 - val_loss: -2.4095e-01 - val_acc: 0.9525 - val_mDice: 0.1994

Epoch 00029: val_mDice did not improve from 0.22157
Epoch 30/300
 - 33s - loss: 0.2333 - acc: 0.9521 - mDice: 0.6658 - val_loss: -2.5236e-01 - val_acc: 0.9526 - val_mDice: 0.1989

Epoch 00030: val_mDice did not improve from 0.22157
Epoch 31/300
 - 34s - loss: 0.2347 - acc: 0.9523 - mDice: 0.6604 - val_loss: -2.3880e-01 - val_acc: 0.9535 - val_mDice: 0.2124

Epoch 00031: val_mDice did not improve from 0.22157
Epoch 32/300
 - 33s - loss: 0.2323 - acc: 0.9523 - mDice: 0.6677 - val_loss: -2.3562e-01 - val_acc: 0.9528 - val_mDice: 0.2042

Epoch 00032: val_mDice did not improve from 0.22157

Epoch 00032: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 33/300
 - 34s - loss: 0.2131 - acc: 0.9532 - mDice: 0.6766 - val_loss: -2.4764e-01 - val_acc: 0.9532 - val_mDice: 0.2083

Epoch 00033: val_mDice did not improve from 0.22157
Epoch 34/300
 - 34s - loss: 0.2045 - acc: 0.9535 - mDice: 0.6812 - val_loss: -2.4126e-01 - val_acc: 0.9532 - val_mDice: 0.2061

Epoch 00034: val_mDice did not improve from 0.22157
Epoch 35/300
 - 34s - loss: 0.2073 - acc: 0.9533 - mDice: 0.6796 - val_loss: -2.5722e-01 - val_acc: 0.9522 - val_mDice: 0.2022

Epoch 00035: val_mDice did not improve from 0.22157
Epoch 36/300
 - 33s - loss: 0.2025 - acc: 0.9533 - mDice: 0.6771 - val_loss: -2.6418e-01 - val_acc: 0.9536 - val_mDice: 0.2105

Epoch 00036: val_mDice did not improve from 0.22157
Epoch 37/300
 - 34s - loss: 0.1990 - acc: 0.9535 - mDice: 0.6799 - val_loss: -2.5764e-01 - val_acc: 0.9540 - val_mDice: 0.2116

Epoch 00037: val_mDice did not improve from 0.22157
Epoch 38/300
 - 33s - loss: 0.1986 - acc: 0.9535 - mDice: 0.6871 - val_loss: -2.6589e-01 - val_acc: 0.9540 - val_mDice: 0.2114

Epoch 00038: val_mDice did not improve from 0.22157
Epoch 39/300
 - 34s - loss: 0.1969 - acc: 0.9534 - mDice: 0.6788 - val_loss: -2.2950e-01 - val_acc: 0.9514 - val_mDice: 0.2016

Epoch 00039: val_mDice did not improve from 0.22157
Epoch 40/300
 - 34s - loss: 0.1978 - acc: 0.9534 - mDice: 0.6807 - val_loss: -2.5046e-01 - val_acc: 0.9527 - val_mDice: 0.2067

Epoch 00040: val_mDice did not improve from 0.22157
Epoch 41/300
 - 34s - loss: 0.1996 - acc: 0.9535 - mDice: 0.6810 - val_loss: -2.6429e-01 - val_acc: 0.9533 - val_mDice: 0.2043

Epoch 00041: val_mDice did not improve from 0.22157
Epoch 42/300
 - 34s - loss: 0.1934 - acc: 0.9536 - mDice: 0.6817 - val_loss: -2.7060e-01 - val_acc: 0.9537 - val_mDice: 0.2103

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:06,  1.54s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.44s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.33s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.19s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<01:06,  3.72it/s]Loading train:   1%|          | 2/247 [00:00<01:04,  3.81it/s]Loading train:   1%|          | 3/247 [00:00<01:02,  3.92it/s]Loading train:   2%|▏         | 4/247 [00:01<01:01,  3.96it/s]Loading train:   2%|▏         | 5/247 [00:01<00:59,  4.07it/s]Loading train:   2%|▏         | 6/247 [00:01<00:58,  4.14it/s]Loading train:   3%|▎         | 7/247 [00:01<00:57,  4.19it/s]Loading train:   3%|▎         | 8/247 [00:01<00:57,  4.18it/s]Loading train:   4%|▎         | 9/247 [00:02<00:56,  4.25it/s]Loading train:   4%|▍         | 10/247 [00:02<00:54,  4.31it/s]Loading train:   4%|▍         | 11/247 [00:02<00:55,  4.25it/s]Loading train:   5%|▍         | 12/247 [00:02<00:54,  4.31it/s]Loading train:   5%|▌         | 13/247 [00:03<00:53,  4.36it/s]Loading train:   6%|▌         | 14/247 [00:03<00:53,  4.38it/s]Loading train:   6%|▌         | 15/247 [00:03<00:52,  4.38it/s]Loading train:   6%|▋         | 16/247 [00:03<00:52,  4.38it/s]Loading train:   7%|▋         | 17/247 [00:03<00:52,  4.35it/s]Loading train:   7%|▋         | 18/247 [00:04<00:52,  4.35it/s]Loading train:   8%|▊         | 19/247 [00:04<00:52,  4.35it/s]Loading train:   8%|▊         | 20/247 [00:04<00:52,  4.36it/s]Loading train:   9%|▊         | 21/247 [00:04<00:52,  4.28it/s]Loading train:   9%|▉         | 22/247 [00:05<00:52,  4.25it/s]Loading train:   9%|▉         | 23/247 [00:05<00:51,  4.31it/s]Loading train:  10%|▉         | 24/247 [00:05<00:51,  4.32it/s]Loading train:  10%|█         | 25/247 [00:05<00:51,  4.35it/s]Loading train:  11%|█         | 26/247 [00:06<00:50,  4.38it/s]Loading train:  11%|█         | 27/247 [00:06<00:49,  4.41it/s]Loading train:  11%|█▏        | 28/247 [00:06<00:49,  4.40it/s]Loading train:  12%|█▏        | 29/247 [00:06<00:49,  4.39it/s]Loading train:  12%|█▏        | 30/247 [00:06<00:49,  4.40it/s]Loading train:  13%|█▎        | 31/247 [00:07<00:49,  4.39it/s]Loading train:  13%|█▎        | 32/247 [00:07<00:48,  4.41it/s]Loading train:  13%|█▎        | 33/247 [00:07<00:48,  4.45it/s]Loading train:  14%|█▍        | 34/247 [00:07<00:47,  4.48it/s]Loading train:  14%|█▍        | 35/247 [00:08<00:47,  4.49it/s]Loading train:  15%|█▍        | 36/247 [00:08<00:46,  4.50it/s]Loading train:  15%|█▍        | 37/247 [00:08<00:46,  4.52it/s]Loading train:  15%|█▌        | 38/247 [00:08<00:46,  4.53it/s]Loading train:  16%|█▌        | 39/247 [00:08<00:46,  4.50it/s]Loading train:  16%|█▌        | 40/247 [00:09<00:46,  4.48it/s]Loading train:  17%|█▋        | 41/247 [00:09<00:46,  4.40it/s]Loading train:  17%|█▋        | 42/247 [00:09<00:46,  4.40it/s]Loading train:  17%|█▋        | 43/247 [00:09<00:47,  4.32it/s]Loading train:  18%|█▊        | 44/247 [00:10<00:46,  4.33it/s]Loading train:  18%|█▊        | 45/247 [00:10<00:46,  4.35it/s]Loading train:  19%|█▊        | 46/247 [00:10<00:46,  4.34it/s]Loading train:  19%|█▉        | 47/247 [00:10<00:47,  4.24it/s]Loading train:  19%|█▉        | 48/247 [00:11<00:47,  4.21it/s]Loading train:  20%|█▉        | 49/247 [00:11<00:47,  4.18it/s]Loading train:  20%|██        | 50/247 [00:11<00:46,  4.23it/s]Loading train:  21%|██        | 51/247 [00:11<00:45,  4.28it/s]Loading train:  21%|██        | 52/247 [00:12<00:44,  4.36it/s]Loading train:  21%|██▏       | 53/247 [00:12<00:43,  4.42it/s]Loading train:  22%|██▏       | 54/247 [00:12<00:43,  4.45it/s]Loading train:  22%|██▏       | 55/247 [00:12<00:43,  4.45it/s]Loading train:  23%|██▎       | 56/247 [00:12<00:42,  4.48it/s]Loading train:  23%|██▎       | 57/247 [00:13<00:42,  4.51it/s]Loading train:  23%|██▎       | 58/247 [00:13<00:41,  4.52it/s]Loading train:  24%|██▍       | 59/247 [00:13<00:41,  4.49it/s]Loading train:  24%|██▍       | 60/247 [00:13<00:42,  4.42it/s]Loading train:  25%|██▍       | 61/247 [00:14<00:42,  4.40it/s]Loading train:  25%|██▌       | 62/247 [00:14<00:41,  4.41it/s]Loading train:  26%|██▌       | 63/247 [00:14<00:41,  4.43it/s]Loading train:  26%|██▌       | 64/247 [00:14<00:41,  4.43it/s]Loading train:  26%|██▋       | 65/247 [00:14<00:41,  4.42it/s]Loading train:  27%|██▋       | 66/247 [00:15<00:41,  4.41it/s]Loading train:  27%|██▋       | 67/247 [00:15<00:40,  4.43it/s]Loading train:  28%|██▊       | 68/247 [00:15<00:40,  4.44it/s]Loading train:  28%|██▊       | 69/247 [00:15<00:40,  4.45it/s]Loading train:  28%|██▊       | 70/247 [00:16<00:39,  4.45it/s]Loading train:  29%|██▊       | 71/247 [00:16<00:40,  4.38it/s]Loading train:  29%|██▉       | 72/247 [00:16<00:40,  4.35it/s]Loading train:  30%|██▉       | 73/247 [00:16<00:39,  4.37it/s]Loading train:  30%|██▉       | 74/247 [00:16<00:39,  4.38it/s]Loading train:  30%|███       | 75/247 [00:17<00:39,  4.40it/s]Loading train:  31%|███       | 76/247 [00:17<00:39,  4.37it/s]Loading train:  31%|███       | 77/247 [00:17<00:41,  4.07it/s]Loading train:  32%|███▏      | 78/247 [00:17<00:42,  3.96it/s]Loading train:  32%|███▏      | 79/247 [00:18<00:41,  4.06it/s]Loading train:  32%|███▏      | 80/247 [00:18<00:40,  4.08it/s]Loading train:  33%|███▎      | 81/247 [00:18<00:41,  4.00it/s]Loading train:  33%|███▎      | 82/247 [00:18<00:41,  3.93it/s]Loading train:  34%|███▎      | 83/247 [00:19<00:41,  3.91it/s]Loading train:  34%|███▍      | 84/247 [00:19<00:41,  3.89it/s]Loading train:  34%|███▍      | 85/247 [00:19<00:42,  3.85it/s]Loading train:  35%|███▍      | 86/247 [00:20<00:42,  3.81it/s]Loading train:  35%|███▌      | 87/247 [00:20<00:41,  3.85it/s]Loading train:  36%|███▌      | 88/247 [00:20<00:41,  3.85it/s]Loading train:  36%|███▌      | 89/247 [00:20<00:41,  3.80it/s]Loading train:  36%|███▋      | 90/247 [00:21<00:41,  3.79it/s]Loading train:  37%|███▋      | 91/247 [00:21<00:41,  3.74it/s]Loading train:  37%|███▋      | 92/247 [00:21<00:41,  3.74it/s]Loading train:  38%|███▊      | 93/247 [00:21<00:41,  3.70it/s]Loading train:  38%|███▊      | 94/247 [00:22<00:41,  3.69it/s]Loading train:  38%|███▊      | 95/247 [00:22<00:40,  3.73it/s]Loading train:  39%|███▉      | 96/247 [00:22<00:40,  3.74it/s]Loading train:  39%|███▉      | 97/247 [00:22<00:40,  3.72it/s]Loading train:  40%|███▉      | 98/247 [00:23<00:40,  3.69it/s]Loading train:  40%|████      | 99/247 [00:23<00:40,  3.69it/s]Loading train:  40%|████      | 100/247 [00:23<00:38,  3.77it/s]Loading train:  41%|████      | 101/247 [00:24<00:37,  3.88it/s]Loading train:  41%|████▏     | 102/247 [00:24<00:37,  3.92it/s]Loading train:  42%|████▏     | 103/247 [00:24<00:36,  3.95it/s]Loading train:  42%|████▏     | 104/247 [00:24<00:36,  3.96it/s]Loading train:  43%|████▎     | 105/247 [00:25<00:35,  3.95it/s]Loading train:  43%|████▎     | 106/247 [00:25<00:35,  3.93it/s]Loading train:  43%|████▎     | 107/247 [00:25<00:35,  3.92it/s]Loading train:  44%|████▎     | 108/247 [00:25<00:35,  3.91it/s]Loading train:  44%|████▍     | 109/247 [00:26<00:35,  3.92it/s]Loading train:  45%|████▍     | 110/247 [00:26<00:34,  3.94it/s]Loading train:  45%|████▍     | 111/247 [00:26<00:34,  3.93it/s]Loading train:  45%|████▌     | 112/247 [00:26<00:34,  3.94it/s]Loading train:  46%|████▌     | 113/247 [00:27<00:33,  3.98it/s]Loading train:  46%|████▌     | 114/247 [00:27<00:33,  3.94it/s]Loading train:  47%|████▋     | 115/247 [00:27<00:33,  3.96it/s]Loading train:  47%|████▋     | 116/247 [00:27<00:33,  3.96it/s]Loading train:  47%|████▋     | 117/247 [00:28<00:32,  3.96it/s]Loading train:  48%|████▊     | 118/247 [00:28<00:31,  4.14it/s]Loading train:  48%|████▊     | 119/247 [00:28<00:30,  4.26it/s]Loading train:  49%|████▊     | 120/247 [00:28<00:28,  4.40it/s]Loading train:  49%|████▉     | 121/247 [00:28<00:27,  4.52it/s]Loading train:  49%|████▉     | 122/247 [00:29<00:27,  4.58it/s]Loading train:  50%|████▉     | 123/247 [00:29<00:26,  4.67it/s]Loading train:  50%|█████     | 124/247 [00:29<00:26,  4.72it/s]Loading train:  51%|█████     | 125/247 [00:29<00:25,  4.74it/s]Loading train:  51%|█████     | 126/247 [00:29<00:25,  4.75it/s]Loading train:  51%|█████▏    | 127/247 [00:30<00:25,  4.74it/s]Loading train:  52%|█████▏    | 128/247 [00:30<00:25,  4.75it/s]Loading train:  52%|█████▏    | 129/247 [00:30<00:24,  4.73it/s]Loading train:  53%|█████▎    | 130/247 [00:30<00:24,  4.71it/s]Loading train:  53%|█████▎    | 131/247 [00:31<00:24,  4.75it/s]Loading train:  53%|█████▎    | 132/247 [00:31<00:24,  4.77it/s]Loading train:  54%|█████▍    | 133/247 [00:31<00:23,  4.77it/s]Loading train:  54%|█████▍    | 134/247 [00:31<00:23,  4.76it/s]Loading train:  55%|█████▍    | 135/247 [00:31<00:23,  4.75it/s]Loading train:  55%|█████▌    | 136/247 [00:32<00:23,  4.67it/s]Loading train:  55%|█████▌    | 137/247 [00:32<00:23,  4.61it/s]Loading train:  56%|█████▌    | 138/247 [00:32<00:23,  4.61it/s]Loading train:  56%|█████▋    | 139/247 [00:32<00:23,  4.62it/s]Loading train:  57%|█████▋    | 140/247 [00:32<00:23,  4.62it/s]Loading train:  57%|█████▋    | 141/247 [00:33<00:23,  4.55it/s]Loading train:  57%|█████▋    | 142/247 [00:33<00:23,  4.56it/s]Loading train:  58%|█████▊    | 143/247 [00:33<00:22,  4.54it/s]Loading train:  58%|█████▊    | 144/247 [00:33<00:22,  4.55it/s]Loading train:  59%|█████▊    | 145/247 [00:34<00:22,  4.55it/s]Loading train:  59%|█████▉    | 146/247 [00:34<00:22,  4.56it/s]Loading train:  60%|█████▉    | 147/247 [00:34<00:21,  4.59it/s]Loading train:  60%|█████▉    | 148/247 [00:34<00:21,  4.56it/s]Loading train:  60%|██████    | 149/247 [00:34<00:21,  4.59it/s]Loading train:  61%|██████    | 150/247 [00:35<00:21,  4.54it/s]Loading train:  61%|██████    | 151/247 [00:35<00:21,  4.57it/s]Loading train:  62%|██████▏   | 152/247 [00:35<00:20,  4.55it/s]Loading train:  62%|██████▏   | 153/247 [00:35<00:20,  4.56it/s]Loading train:  62%|██████▏   | 154/247 [00:36<00:21,  4.41it/s]Loading train:  63%|██████▎   | 155/247 [00:36<00:21,  4.30it/s]Loading train:  63%|██████▎   | 156/247 [00:36<00:21,  4.22it/s]Loading train:  64%|██████▎   | 157/247 [00:36<00:21,  4.16it/s]Loading train:  64%|██████▍   | 158/247 [00:37<00:21,  4.11it/s]Loading train:  64%|██████▍   | 159/247 [00:37<00:21,  4.10it/s]Loading train:  65%|██████▍   | 160/247 [00:37<00:21,  4.08it/s]Loading train:  65%|██████▌   | 161/247 [00:37<00:21,  4.05it/s]Loading train:  66%|██████▌   | 162/247 [00:38<00:21,  3.99it/s]Loading train:  66%|██████▌   | 163/247 [00:38<00:20,  4.02it/s]Loading train:  66%|██████▋   | 164/247 [00:38<00:20,  4.02it/s]Loading train:  67%|██████▋   | 165/247 [00:38<00:20,  4.04it/s]Loading train:  67%|██████▋   | 166/247 [00:39<00:20,  3.93it/s]Loading train:  68%|██████▊   | 167/247 [00:39<00:20,  3.90it/s]Loading train:  68%|██████▊   | 168/247 [00:39<00:20,  3.94it/s]Loading train:  68%|██████▊   | 169/247 [00:39<00:19,  3.97it/s]Loading train:  69%|██████▉   | 170/247 [00:40<00:19,  4.03it/s]Loading train:  69%|██████▉   | 171/247 [00:40<00:18,  4.05it/s]Loading train:  70%|██████▉   | 172/247 [00:40<00:18,  4.09it/s]Loading train:  70%|███████   | 173/247 [00:40<00:17,  4.21it/s]Loading train:  70%|███████   | 174/247 [00:40<00:17,  4.24it/s]Loading train:  71%|███████   | 175/247 [00:41<00:17,  4.12it/s]Loading train:  71%|███████▏  | 176/247 [00:41<00:16,  4.22it/s]Loading train:  72%|███████▏  | 177/247 [00:41<00:16,  4.33it/s]Loading train:  72%|███████▏  | 178/247 [00:41<00:15,  4.40it/s]Loading train:  72%|███████▏  | 179/247 [00:42<00:15,  4.42it/s]Loading train:  73%|███████▎  | 180/247 [00:42<00:14,  4.49it/s]Loading train:  73%|███████▎  | 181/247 [00:42<00:14,  4.48it/s]Loading train:  74%|███████▎  | 182/247 [00:42<00:14,  4.48it/s]Loading train:  74%|███████▍  | 183/247 [00:43<00:14,  4.53it/s]Loading train:  74%|███████▍  | 184/247 [00:43<00:13,  4.55it/s]Loading train:  75%|███████▍  | 185/247 [00:43<00:13,  4.56it/s]Loading train:  75%|███████▌  | 186/247 [00:43<00:13,  4.57it/s]Loading train:  76%|███████▌  | 187/247 [00:43<00:13,  4.54it/s]Loading train:  76%|███████▌  | 188/247 [00:44<00:13,  4.52it/s]Loading train:  77%|███████▋  | 189/247 [00:44<00:12,  4.47it/s]Loading train:  77%|███████▋  | 190/247 [00:44<00:12,  4.50it/s]Loading train:  77%|███████▋  | 191/247 [00:44<00:12,  4.48it/s]Loading train:  78%|███████▊  | 192/247 [00:45<00:12,  4.24it/s]Loading train:  78%|███████▊  | 193/247 [00:45<00:12,  4.25it/s]Loading train:  79%|███████▊  | 194/247 [00:45<00:12,  4.35it/s]Loading train:  79%|███████▉  | 195/247 [00:45<00:11,  4.46it/s]Loading train:  79%|███████▉  | 196/247 [00:45<00:11,  4.44it/s]Loading train:  80%|███████▉  | 197/247 [00:46<00:11,  4.49it/s]Loading train:  80%|████████  | 198/247 [00:46<00:10,  4.57it/s]Loading train:  81%|████████  | 199/247 [00:46<00:10,  4.59it/s]Loading train:  81%|████████  | 200/247 [00:46<00:10,  4.49it/s]Loading train:  81%|████████▏ | 201/247 [00:47<00:10,  4.55it/s]Loading train:  82%|████████▏ | 202/247 [00:47<00:09,  4.64it/s]Loading train:  82%|████████▏ | 203/247 [00:47<00:09,  4.68it/s]Loading train:  83%|████████▎ | 204/247 [00:47<00:09,  4.71it/s]Loading train:  83%|████████▎ | 205/247 [00:47<00:08,  4.73it/s]Loading train:  83%|████████▎ | 206/247 [00:48<00:08,  4.74it/s]Loading train:  84%|████████▍ | 207/247 [00:48<00:08,  4.77it/s]Loading train:  84%|████████▍ | 208/247 [00:48<00:08,  4.78it/s]Loading train:  85%|████████▍ | 209/247 [00:48<00:07,  4.79it/s]Loading train:  85%|████████▌ | 210/247 [00:48<00:07,  4.80it/s]Loading train:  85%|████████▌ | 211/247 [00:49<00:07,  4.82it/s]Loading train:  86%|████████▌ | 212/247 [00:49<00:07,  4.73it/s]Loading train:  86%|████████▌ | 213/247 [00:49<00:07,  4.69it/s]Loading train:  87%|████████▋ | 214/247 [00:49<00:07,  4.61it/s]Loading train:  87%|████████▋ | 215/247 [00:49<00:06,  4.59it/s]Loading train:  87%|████████▋ | 216/247 [00:50<00:06,  4.60it/s]Loading train:  88%|████████▊ | 217/247 [00:50<00:06,  4.59it/s]Loading train:  88%|████████▊ | 218/247 [00:50<00:06,  4.51it/s]Loading train:  89%|████████▊ | 219/247 [00:50<00:06,  4.46it/s]Loading train:  89%|████████▉ | 220/247 [00:51<00:06,  4.45it/s]Loading train:  89%|████████▉ | 221/247 [00:51<00:05,  4.44it/s]Loading train:  90%|████████▉ | 222/247 [00:51<00:05,  4.45it/s]Loading train:  90%|█████████ | 223/247 [00:51<00:05,  4.46it/s]Loading train:  91%|█████████ | 224/247 [00:52<00:05,  4.46it/s]Loading train:  91%|█████████ | 225/247 [00:52<00:04,  4.45it/s]Loading train:  91%|█████████▏| 226/247 [00:52<00:04,  4.45it/s]Loading train:  92%|█████████▏| 227/247 [00:52<00:04,  4.45it/s]Loading train:  92%|█████████▏| 228/247 [00:52<00:04,  4.46it/s]Loading train:  93%|█████████▎| 229/247 [00:53<00:04,  4.44it/s]Loading train:  93%|█████████▎| 230/247 [00:53<00:03,  4.29it/s]Loading train:  94%|█████████▎| 231/247 [00:53<00:03,  4.22it/s]Loading train:  94%|█████████▍| 232/247 [00:53<00:03,  4.18it/s]Loading train:  94%|█████████▍| 233/247 [00:54<00:03,  4.14it/s]Loading train:  95%|█████████▍| 234/247 [00:54<00:03,  4.12it/s]Loading train:  95%|█████████▌| 235/247 [00:54<00:02,  4.09it/s]Loading train:  96%|█████████▌| 236/247 [00:54<00:02,  4.07it/s]Loading train:  96%|█████████▌| 237/247 [00:55<00:02,  4.08it/s]Loading train:  96%|█████████▋| 238/247 [00:55<00:02,  4.08it/s]Loading train:  97%|█████████▋| 239/247 [00:55<00:01,  4.04it/s]Loading train:  97%|█████████▋| 240/247 [00:55<00:01,  4.02it/s]Loading train:  98%|█████████▊| 241/247 [00:56<00:01,  4.06it/s]Loading train:  98%|█████████▊| 242/247 [00:56<00:01,  4.06it/s]Loading train:  98%|█████████▊| 243/247 [00:56<00:00,  4.06it/s]Loading train:  99%|█████████▉| 244/247 [00:56<00:00,  4.02it/s]Loading train:  99%|█████████▉| 245/247 [00:57<00:00,  4.00it/s]Loading train: 100%|█████████▉| 246/247 [00:57<00:00,  4.00it/s]Loading train: 100%|██████████| 247/247 [00:57<00:00,  3.99it/s]Loading train: 100%|██████████| 247/247 [00:57<00:00,  4.29it/s]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/247 [00:00<00:08, 27.54it/s]concatenating: train:   3%|▎         | 8/247 [00:00<00:07, 31.28it/s]concatenating: train:   5%|▌         | 13/247 [00:00<00:06, 34.63it/s]concatenating: train:   7%|▋         | 18/247 [00:00<00:06, 37.15it/s]concatenating: train:   9%|▉         | 23/247 [00:00<00:05, 38.93it/s]concatenating: train:  11%|█▏        | 28/247 [00:00<00:05, 40.07it/s]concatenating: train:  13%|█▎        | 33/247 [00:00<00:05, 41.14it/s]concatenating: train:  15%|█▌        | 38/247 [00:00<00:04, 42.35it/s]concatenating: train:  17%|█▋        | 43/247 [00:01<00:04, 43.04it/s]concatenating: train:  19%|█▉        | 48/247 [00:01<00:04, 43.93it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:04, 44.69it/s]concatenating: train:  23%|██▎       | 58/247 [00:01<00:04, 43.59it/s]concatenating: train:  26%|██▌       | 63/247 [00:01<00:04, 44.36it/s]concatenating: train:  28%|██▊       | 68/247 [00:01<00:04, 43.98it/s]concatenating: train:  30%|██▉       | 73/247 [00:01<00:03, 44.48it/s]concatenating: train:  32%|███▏      | 78/247 [00:01<00:03, 44.48it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 43.38it/s]concatenating: train:  36%|███▌      | 88/247 [00:02<00:03, 41.98it/s]concatenating: train:  38%|███▊      | 93/247 [00:02<00:03, 41.94it/s]concatenating: train:  40%|███▉      | 98/247 [00:02<00:03, 40.80it/s]concatenating: train:  42%|████▏     | 103/247 [00:02<00:03, 41.29it/s]concatenating: train:  44%|████▎     | 108/247 [00:02<00:03, 41.77it/s]concatenating: train:  46%|████▌     | 113/247 [00:02<00:03, 41.19it/s]concatenating: train:  48%|████▊     | 118/247 [00:02<00:03, 41.69it/s]concatenating: train:  50%|████▉     | 123/247 [00:02<00:02, 43.11it/s]concatenating: train:  52%|█████▏    | 129/247 [00:02<00:02, 45.23it/s]concatenating: train:  55%|█████▍    | 135/247 [00:03<00:02, 46.62it/s]concatenating: train:  57%|█████▋    | 140/247 [00:03<00:02, 46.56it/s]concatenating: train:  59%|█████▊    | 145/247 [00:03<00:02, 46.73it/s]concatenating: train:  61%|██████    | 150/247 [00:03<00:02, 46.20it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 46.16it/s]concatenating: train:  65%|██████▍   | 160/247 [00:03<00:01, 44.67it/s]concatenating: train:  67%|██████▋   | 165/247 [00:03<00:01, 44.32it/s]concatenating: train:  69%|██████▉   | 170/247 [00:03<00:01, 44.22it/s]concatenating: train:  71%|███████   | 175/247 [00:03<00:01, 44.66it/s]concatenating: train:  73%|███████▎  | 180/247 [00:04<00:01, 45.42it/s]concatenating: train:  75%|███████▍  | 185/247 [00:04<00:01, 46.64it/s]concatenating: train:  77%|███████▋  | 190/247 [00:04<00:01, 47.42it/s]concatenating: train:  79%|███████▉  | 195/247 [00:04<00:01, 48.08it/s]concatenating: train:  81%|████████▏ | 201/247 [00:04<00:00, 48.81it/s]concatenating: train:  83%|████████▎ | 206/247 [00:04<00:00, 48.95it/s]concatenating: train:  86%|████████▌ | 212/247 [00:04<00:00, 49.19it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 48.81it/s]concatenating: train:  90%|████████▉ | 222/247 [00:04<00:00, 48.49it/s]concatenating: train:  92%|█████████▏| 227/247 [00:05<00:00, 48.48it/s]concatenating: train:  94%|█████████▍| 232/247 [00:05<00:00, 47.61it/s]concatenating: train:  96%|█████████▌| 237/247 [00:05<00:00, 46.76it/s]concatenating: train:  98%|█████████▊| 242/247 [00:05<00:00, 46.13it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 45.12it/s]concatenating: train: 100%|██████████| 247/247 [00:05<00:00, 44.84it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  3.99it/s]Loading test:  40%|████      | 2/5 [00:00<00:00,  3.88it/s]Loading test:  60%|██████    | 3/5 [00:00<00:00,  3.96it/s]Loading test:  80%|████████  | 4/5 [00:00<00:00,  4.22it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.24it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  4.17it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 394.48it/s]
Loading trainS:   0%|          | 0/247 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/247 [00:00<00:57,  4.28it/s]Loading trainS:   1%|          | 2/247 [00:00<00:56,  4.32it/s]Loading trainS:   1%|          | 3/247 [00:00<00:56,  4.34it/s]Loading trainS:   2%|▏         | 4/247 [00:00<00:56,  4.27it/s]Loading trainS:   2%|▏         | 5/247 [00:01<00:56,  4.32it/s]Loading trainS:   2%|▏         | 6/247 [00:01<00:55,  4.37it/s]Loading trainS:   3%|▎         | 7/247 [00:01<00:54,  4.40it/s]Loading trainS:   3%|▎         | 8/247 [00:01<00:54,  4.39it/s]Loading trainS:   4%|▎         | 9/247 [00:02<00:54,  4.39it/s]Loading trainS:   4%|▍         | 10/247 [00:02<00:53,  4.42it/s]Loading trainS:   4%|▍         | 11/247 [00:02<00:53,  4.44it/s]Loading trainS:   5%|▍         | 12/247 [00:02<00:52,  4.45it/s]Loading trainS:   5%|▌         | 13/247 [00:02<00:52,  4.46it/s]Loading trainS:   6%|▌         | 14/247 [00:03<00:52,  4.47it/s]Loading trainS:   6%|▌         | 15/247 [00:03<00:51,  4.47it/s]Loading trainS:   6%|▋         | 16/247 [00:03<00:51,  4.47it/s]Loading trainS:   7%|▋         | 17/247 [00:03<00:51,  4.47it/s]Loading trainS:   7%|▋         | 18/247 [00:04<00:51,  4.47it/s]Loading trainS:   8%|▊         | 19/247 [00:04<00:50,  4.47it/s]Loading trainS:   8%|▊         | 20/247 [00:04<00:50,  4.47it/s]Loading trainS:   9%|▊         | 21/247 [00:04<00:50,  4.46it/s]Loading trainS:   9%|▉         | 22/247 [00:04<00:50,  4.47it/s]Loading trainS:   9%|▉         | 23/247 [00:05<00:49,  4.50it/s]Loading trainS:  10%|▉         | 24/247 [00:05<00:49,  4.51it/s]Loading trainS:  10%|█         | 25/247 [00:05<00:49,  4.52it/s]Loading trainS:  11%|█         | 26/247 [00:05<00:48,  4.53it/s]Loading trainS:  11%|█         | 27/247 [00:06<00:48,  4.54it/s]Loading trainS:  11%|█▏        | 28/247 [00:06<00:48,  4.55it/s]Loading trainS:  12%|█▏        | 29/247 [00:06<00:47,  4.56it/s]Loading trainS:  12%|█▏        | 30/247 [00:06<00:47,  4.55it/s]Loading trainS:  13%|█▎        | 31/247 [00:06<00:47,  4.54it/s]Loading trainS:  13%|█▎        | 32/247 [00:07<00:47,  4.55it/s]Loading trainS:  13%|█▎        | 33/247 [00:07<00:47,  4.55it/s]Loading trainS:  14%|█▍        | 34/247 [00:07<00:46,  4.56it/s]Loading trainS:  14%|█▍        | 35/247 [00:07<00:46,  4.56it/s]Loading trainS:  15%|█▍        | 36/247 [00:08<00:46,  4.56it/s]Loading trainS:  15%|█▍        | 37/247 [00:08<00:46,  4.56it/s]Loading trainS:  15%|█▌        | 38/247 [00:08<00:45,  4.56it/s]Loading trainS:  16%|█▌        | 39/247 [00:08<00:45,  4.57it/s]Loading trainS:  16%|█▌        | 40/247 [00:08<00:45,  4.54it/s]Loading trainS:  17%|█▋        | 41/247 [00:09<00:45,  4.56it/s]Loading trainS:  17%|█▋        | 42/247 [00:09<00:44,  4.57it/s]Loading trainS:  17%|█▋        | 43/247 [00:09<00:44,  4.55it/s]Loading trainS:  18%|█▊        | 44/247 [00:09<00:44,  4.54it/s]Loading trainS:  18%|█▊        | 45/247 [00:10<00:44,  4.56it/s]Loading trainS:  19%|█▊        | 46/247 [00:10<00:44,  4.57it/s]Loading trainS:  19%|█▉        | 47/247 [00:10<00:44,  4.54it/s]Loading trainS:  19%|█▉        | 48/247 [00:10<00:43,  4.55it/s]Loading trainS:  20%|█▉        | 49/247 [00:10<00:43,  4.56it/s]Loading trainS:  20%|██        | 50/247 [00:11<00:43,  4.57it/s]Loading trainS:  21%|██        | 51/247 [00:11<00:43,  4.55it/s]Loading trainS:  21%|██        | 52/247 [00:11<00:43,  4.48it/s]Loading trainS:  21%|██▏       | 53/247 [00:11<00:42,  4.52it/s]Loading trainS:  22%|██▏       | 54/247 [00:11<00:42,  4.54it/s]Loading trainS:  22%|██▏       | 55/247 [00:12<00:42,  4.55it/s]Loading trainS:  23%|██▎       | 56/247 [00:12<00:41,  4.55it/s]Loading trainS:  23%|██▎       | 57/247 [00:12<00:41,  4.55it/s]Loading trainS:  23%|██▎       | 58/247 [00:12<00:41,  4.56it/s]Loading trainS:  24%|██▍       | 59/247 [00:13<00:41,  4.52it/s]Loading trainS:  24%|██▍       | 60/247 [00:13<00:41,  4.47it/s]Loading trainS:  25%|██▍       | 61/247 [00:13<00:41,  4.47it/s]Loading trainS:  25%|██▌       | 62/247 [00:13<00:41,  4.47it/s]Loading trainS:  26%|██▌       | 63/247 [00:14<00:41,  4.47it/s]Loading trainS:  26%|██▌       | 64/247 [00:14<00:41,  4.45it/s]Loading trainS:  26%|██▋       | 65/247 [00:14<00:40,  4.45it/s]Loading trainS:  27%|██▋       | 66/247 [00:14<00:40,  4.43it/s]Loading trainS:  27%|██▋       | 67/247 [00:14<00:40,  4.44it/s]Loading trainS:  28%|██▊       | 68/247 [00:15<00:40,  4.44it/s]Loading trainS:  28%|██▊       | 69/247 [00:15<00:40,  4.37it/s]Loading trainS:  28%|██▊       | 70/247 [00:15<00:40,  4.38it/s]Loading trainS:  29%|██▊       | 71/247 [00:15<00:39,  4.40it/s]Loading trainS:  29%|██▉       | 72/247 [00:16<00:39,  4.42it/s]Loading trainS:  30%|██▉       | 73/247 [00:16<00:39,  4.39it/s]Loading trainS:  30%|██▉       | 74/247 [00:16<00:39,  4.41it/s]Loading trainS:  30%|███       | 75/247 [00:16<00:38,  4.42it/s]Loading trainS:  31%|███       | 76/247 [00:16<00:38,  4.44it/s]Loading trainS:  31%|███       | 77/247 [00:17<00:41,  4.11it/s]Loading trainS:  32%|███▏      | 78/247 [00:17<00:41,  4.04it/s]Loading trainS:  32%|███▏      | 79/247 [00:17<00:40,  4.18it/s]Loading trainS:  32%|███▏      | 80/247 [00:17<00:39,  4.24it/s]Loading trainS:  33%|███▎      | 81/247 [00:18<00:40,  4.11it/s]Loading trainS:  33%|███▎      | 82/247 [00:18<00:40,  4.04it/s]Loading trainS:  34%|███▎      | 83/247 [00:18<00:41,  3.99it/s]Loading trainS:  34%|███▍      | 84/247 [00:18<00:41,  3.96it/s]Loading trainS:  34%|███▍      | 85/247 [00:19<00:41,  3.92it/s]Loading trainS:  35%|███▍      | 86/247 [00:19<00:41,  3.91it/s]Loading trainS:  35%|███▌      | 87/247 [00:19<00:40,  3.90it/s]Loading trainS:  36%|███▌      | 88/247 [00:20<00:40,  3.90it/s]Loading trainS:  36%|███▌      | 89/247 [00:20<00:40,  3.88it/s]Loading trainS:  36%|███▋      | 90/247 [00:20<00:40,  3.89it/s]Loading trainS:  37%|███▋      | 91/247 [00:20<00:40,  3.86it/s]Loading trainS:  37%|███▋      | 92/247 [00:21<00:40,  3.85it/s]Loading trainS:  38%|███▊      | 93/247 [00:21<00:39,  3.86it/s]Loading trainS:  38%|███▊      | 94/247 [00:21<00:39,  3.87it/s]Loading trainS:  38%|███▊      | 95/247 [00:21<00:39,  3.87it/s]Loading trainS:  39%|███▉      | 96/247 [00:22<00:39,  3.85it/s]Loading trainS:  39%|███▉      | 97/247 [00:22<00:38,  3.86it/s]Loading trainS:  40%|███▉      | 98/247 [00:22<00:38,  3.87it/s]Loading trainS:  40%|████      | 99/247 [00:22<00:38,  3.87it/s]Loading trainS:  40%|████      | 100/247 [00:23<00:37,  3.92it/s]Loading trainS:  41%|████      | 101/247 [00:23<00:36,  3.96it/s]Loading trainS:  41%|████▏     | 102/247 [00:23<00:36,  3.99it/s]Loading trainS:  42%|████▏     | 103/247 [00:23<00:35,  4.01it/s]Loading trainS:  42%|████▏     | 104/247 [00:24<00:35,  4.03it/s]Loading trainS:  43%|████▎     | 105/247 [00:24<00:35,  4.04it/s]Loading trainS:  43%|████▎     | 106/247 [00:24<00:34,  4.03it/s]Loading trainS:  43%|████▎     | 107/247 [00:24<00:34,  4.04it/s]Loading trainS:  44%|████▎     | 108/247 [00:25<00:34,  4.02it/s]Loading trainS:  44%|████▍     | 109/247 [00:25<00:34,  4.04it/s]Loading trainS:  45%|████▍     | 110/247 [00:25<00:33,  4.05it/s]Loading trainS:  45%|████▍     | 111/247 [00:25<00:33,  4.01it/s]Loading trainS:  45%|████▌     | 112/247 [00:26<00:33,  4.02it/s]Loading trainS:  46%|████▌     | 113/247 [00:26<00:33,  4.03it/s]Loading trainS:  46%|████▌     | 114/247 [00:26<00:33,  4.03it/s]Loading trainS:  47%|████▋     | 115/247 [00:26<00:32,  4.03it/s]Loading trainS:  47%|████▋     | 116/247 [00:27<00:32,  4.04it/s]Loading trainS:  47%|████▋     | 117/247 [00:27<00:32,  4.06it/s]Loading trainS:  48%|████▊     | 118/247 [00:27<00:30,  4.26it/s]Loading trainS:  48%|████▊     | 119/247 [00:27<00:28,  4.42it/s]Loading trainS:  49%|████▊     | 120/247 [00:27<00:27,  4.54it/s]Loading trainS:  49%|████▉     | 121/247 [00:28<00:27,  4.62it/s]Loading trainS:  49%|████▉     | 122/247 [00:28<00:26,  4.70it/s]Loading trainS:  50%|████▉     | 123/247 [00:28<00:26,  4.75it/s]Loading trainS:  50%|█████     | 124/247 [00:28<00:25,  4.73it/s]Loading trainS:  51%|█████     | 125/247 [00:28<00:25,  4.75it/s]Loading trainS:  51%|█████     | 126/247 [00:29<00:25,  4.78it/s]Loading trainS:  51%|█████▏    | 127/247 [00:29<00:24,  4.80it/s]Loading trainS:  52%|█████▏    | 128/247 [00:29<00:24,  4.81it/s]Loading trainS:  52%|█████▏    | 129/247 [00:29<00:25,  4.69it/s]Loading trainS:  53%|█████▎    | 130/247 [00:30<00:24,  4.70it/s]Loading trainS:  53%|█████▎    | 131/247 [00:30<00:24,  4.74it/s]Loading trainS:  53%|█████▎    | 132/247 [00:30<00:24,  4.76it/s]Loading trainS:  54%|█████▍    | 133/247 [00:30<00:23,  4.77it/s]Loading trainS:  54%|█████▍    | 134/247 [00:30<00:23,  4.78it/s]Loading trainS:  55%|█████▍    | 135/247 [00:31<00:23,  4.80it/s]Loading trainS:  55%|█████▌    | 136/247 [00:31<00:23,  4.73it/s]Loading trainS:  55%|█████▌    | 137/247 [00:31<00:23,  4.67it/s]Loading trainS:  56%|█████▌    | 138/247 [00:31<00:23,  4.64it/s]Loading trainS:  56%|█████▋    | 139/247 [00:31<00:23,  4.60it/s]Loading trainS:  57%|█████▋    | 140/247 [00:32<00:23,  4.59it/s]Loading trainS:  57%|█████▋    | 141/247 [00:32<00:23,  4.58it/s]Loading trainS:  57%|█████▋    | 142/247 [00:32<00:22,  4.58it/s]Loading trainS:  58%|█████▊    | 143/247 [00:32<00:22,  4.57it/s]Loading trainS:  58%|█████▊    | 144/247 [00:33<00:22,  4.57it/s]Loading trainS:  59%|█████▊    | 145/247 [00:33<00:22,  4.57it/s]Loading trainS:  59%|█████▉    | 146/247 [00:33<00:22,  4.57it/s]Loading trainS:  60%|█████▉    | 147/247 [00:33<00:21,  4.60it/s]Loading trainS:  60%|█████▉    | 148/247 [00:33<00:21,  4.59it/s]Loading trainS:  60%|██████    | 149/247 [00:34<00:21,  4.61it/s]Loading trainS:  61%|██████    | 150/247 [00:34<00:21,  4.62it/s]Loading trainS:  61%|██████    | 151/247 [00:34<00:20,  4.59it/s]Loading trainS:  62%|██████▏   | 152/247 [00:34<00:20,  4.60it/s]Loading trainS:  62%|██████▏   | 153/247 [00:34<00:20,  4.61it/s]Loading trainS:  62%|██████▏   | 154/247 [00:35<00:20,  4.43it/s]Loading trainS:  63%|██████▎   | 155/247 [00:35<00:21,  4.30it/s]Loading trainS:  63%|██████▎   | 156/247 [00:35<00:21,  4.23it/s]Loading trainS:  64%|██████▎   | 157/247 [00:35<00:21,  4.19it/s]Loading trainS:  64%|██████▍   | 158/247 [00:36<00:21,  4.16it/s]Loading trainS:  64%|██████▍   | 159/247 [00:36<00:21,  4.12it/s]Loading trainS:  65%|██████▍   | 160/247 [00:36<00:21,  4.12it/s]Loading trainS:  65%|██████▌   | 161/247 [00:36<00:20,  4.11it/s]Loading trainS:  66%|██████▌   | 162/247 [00:37<00:20,  4.10it/s]Loading trainS:  66%|██████▌   | 163/247 [00:37<00:20,  4.04it/s]Loading trainS:  66%|██████▋   | 164/247 [00:37<00:20,  4.03it/s]Loading trainS:  67%|██████▋   | 165/247 [00:37<00:20,  4.00it/s]Loading trainS:  67%|██████▋   | 166/247 [00:38<00:20,  4.00it/s]Loading trainS:  68%|██████▊   | 167/247 [00:38<00:20,  3.98it/s]Loading trainS:  68%|██████▊   | 168/247 [00:38<00:19,  3.98it/s]Loading trainS:  68%|██████▊   | 169/247 [00:38<00:19,  3.91it/s]Loading trainS:  69%|██████▉   | 170/247 [00:39<00:19,  3.90it/s]Loading trainS:  69%|██████▉   | 171/247 [00:39<00:19,  3.92it/s]Loading trainS:  70%|██████▉   | 172/247 [00:39<00:18,  4.00it/s]Loading trainS:  70%|███████   | 173/247 [00:39<00:18,  4.11it/s]Loading trainS:  70%|███████   | 174/247 [00:40<00:17,  4.11it/s]Loading trainS:  71%|███████   | 175/247 [00:40<00:18,  3.96it/s]Loading trainS:  71%|███████▏  | 176/247 [00:40<00:17,  4.14it/s]Loading trainS:  72%|███████▏  | 177/247 [00:40<00:16,  4.27it/s]Loading trainS:  72%|███████▏  | 178/247 [00:41<00:15,  4.39it/s]Loading trainS:  72%|███████▏  | 179/247 [00:41<00:15,  4.45it/s]Loading trainS:  73%|███████▎  | 180/247 [00:41<00:14,  4.51it/s]Loading trainS:  73%|███████▎  | 181/247 [00:41<00:14,  4.53it/s]Loading trainS:  74%|███████▎  | 182/247 [00:41<00:14,  4.58it/s]Loading trainS:  74%|███████▍  | 183/247 [00:42<00:13,  4.60it/s]Loading trainS:  74%|███████▍  | 184/247 [00:42<00:13,  4.61it/s]Loading trainS:  75%|███████▍  | 185/247 [00:42<00:13,  4.62it/s]Loading trainS:  75%|███████▌  | 186/247 [00:42<00:13,  4.64it/s]Loading trainS:  76%|███████▌  | 187/247 [00:43<00:12,  4.62it/s]Loading trainS:  76%|███████▌  | 188/247 [00:43<00:12,  4.63it/s]Loading trainS:  77%|███████▋  | 189/247 [00:43<00:12,  4.64it/s]Loading trainS:  77%|███████▋  | 190/247 [00:43<00:12,  4.64it/s]Loading trainS:  77%|███████▋  | 191/247 [00:43<00:12,  4.64it/s]Loading trainS:  78%|███████▊  | 192/247 [00:44<00:11,  4.62it/s]Loading trainS:  78%|███████▊  | 193/247 [00:44<00:11,  4.61it/s]Loading trainS:  79%|███████▊  | 194/247 [00:44<00:11,  4.68it/s]Loading trainS:  79%|███████▉  | 195/247 [00:44<00:10,  4.73it/s]Loading trainS:  79%|███████▉  | 196/247 [00:44<00:10,  4.71it/s]Loading trainS:  80%|███████▉  | 197/247 [00:45<00:10,  4.74it/s]Loading trainS:  80%|████████  | 198/247 [00:45<00:10,  4.77it/s]Loading trainS:  81%|████████  | 199/247 [00:45<00:09,  4.81it/s]Loading trainS:  81%|████████  | 200/247 [00:45<00:09,  4.79it/s]Loading trainS:  81%|████████▏ | 201/247 [00:46<00:09,  4.76it/s]Loading trainS:  82%|████████▏ | 202/247 [00:46<00:09,  4.76it/s]Loading trainS:  82%|████████▏ | 203/247 [00:46<00:09,  4.79it/s]Loading trainS:  83%|████████▎ | 204/247 [00:46<00:08,  4.81it/s]Loading trainS:  83%|████████▎ | 205/247 [00:46<00:08,  4.82it/s]Loading trainS:  83%|████████▎ | 206/247 [00:47<00:08,  4.81it/s]Loading trainS:  84%|████████▍ | 207/247 [00:47<00:08,  4.79it/s]Loading trainS:  84%|████████▍ | 208/247 [00:47<00:08,  4.79it/s]Loading trainS:  85%|████████▍ | 209/247 [00:47<00:07,  4.79it/s]Loading trainS:  85%|████████▌ | 210/247 [00:47<00:07,  4.79it/s]Loading trainS:  85%|████████▌ | 211/247 [00:48<00:07,  4.81it/s]Loading trainS:  86%|████████▌ | 212/247 [00:48<00:07,  4.73it/s]Loading trainS:  86%|████████▌ | 213/247 [00:48<00:07,  4.68it/s]Loading trainS:  87%|████████▋ | 214/247 [00:48<00:07,  4.64it/s]Loading trainS:  87%|████████▋ | 215/247 [00:48<00:06,  4.62it/s]Loading trainS:  87%|████████▋ | 216/247 [00:49<00:06,  4.61it/s]Loading trainS:  88%|████████▊ | 217/247 [00:49<00:06,  4.61it/s]Loading trainS:  88%|████████▊ | 218/247 [00:49<00:06,  4.55it/s]Loading trainS:  89%|████████▊ | 219/247 [00:49<00:06,  4.40it/s]Loading trainS:  89%|████████▉ | 220/247 [00:50<00:06,  4.41it/s]Loading trainS:  89%|████████▉ | 221/247 [00:50<00:06,  4.27it/s]Loading trainS:  90%|████████▉ | 222/247 [00:50<00:05,  4.38it/s]Loading trainS:  90%|█████████ | 223/247 [00:50<00:05,  4.43it/s]Loading trainS:  91%|█████████ | 224/247 [00:51<00:05,  4.49it/s]Loading trainS:  91%|█████████ | 225/247 [00:51<00:04,  4.53it/s]Loading trainS:  91%|█████████▏| 226/247 [00:51<00:04,  4.55it/s]Loading trainS:  92%|█████████▏| 227/247 [00:51<00:04,  4.58it/s]Loading trainS:  92%|█████████▏| 228/247 [00:51<00:04,  4.59it/s]Loading trainS:  93%|█████████▎| 229/247 [00:52<00:03,  4.60it/s]Loading trainS:  93%|█████████▎| 230/247 [00:52<00:03,  4.48it/s]Loading trainS:  94%|█████████▎| 231/247 [00:52<00:03,  4.40it/s]Loading trainS:  94%|█████████▍| 232/247 [00:52<00:03,  4.34it/s]Loading trainS:  94%|█████████▍| 233/247 [00:53<00:03,  4.30it/s]Loading trainS:  95%|█████████▍| 234/247 [00:53<00:03,  4.25it/s]Loading trainS:  95%|█████████▌| 235/247 [00:53<00:02,  4.24it/s]Loading trainS:  96%|█████████▌| 236/247 [00:54<00:04,  2.60it/s]Loading trainS:  96%|█████████▌| 237/247 [00:54<00:04,  2.20it/s]Loading trainS:  96%|█████████▋| 238/247 [00:55<00:04,  1.93it/s]Loading trainS:  97%|█████████▋| 239/247 [00:56<00:04,  1.68it/s]Loading trainS:  97%|█████████▋| 240/247 [00:56<00:04,  1.62it/s]Loading trainS:  98%|█████████▊| 241/247 [00:57<00:03,  1.59it/s]Loading trainS:  98%|█████████▊| 242/247 [00:58<00:03,  1.58it/s]Loading trainS:  98%|█████████▊| 243/247 [00:58<00:02,  1.60it/s]Loading trainS:  99%|█████████▉| 244/247 [00:59<00:02,  1.49it/s]Loading trainS:  99%|█████████▉| 245/247 [01:00<00:01,  1.51it/s]Loading trainS: 100%|█████████▉| 246/247 [01:00<00:00,  1.52it/s]Loading trainS: 100%|██████████| 247/247 [01:01<00:00,  1.49it/s]Loading trainS: 100%|██████████| 247/247 [01:01<00:00,  4.01it/s]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:00<00:02,  1.64it/s]Loading testS:  40%|████      | 2/5 [00:01<00:01,  1.54it/s]Loading testS:  60%|██████    | 3/5 [00:01<00:01,  1.58it/s]Loading testS:  80%|████████  | 4/5 [00:02<00:00,  1.80it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  1.70it/s]Loading testS: 100%|██████████| 5/5 [00:02<00:00,  1.68it/s]
Epoch 00042: val_mDice did not improve from 0.22157
Restoring model weights from the end of the best epoch
Epoch 00042: early stopping
{'val_loss': [0.7486159116585062, 0.7197783663406135, 0.6915446723470037, 0.6829573425076763, 0.5351797243267853, 0.3831696192392651, 0.4993084238275238, 0.25707189647353584, 0.1812632704466026, 0.04606767628133667, -0.07470526381956864, -0.14157353895745292, -0.0857043161710597, -0.07416047755432148, -0.09948596971178925, -0.15529684463272925, -0.13871604968469753, -0.1807218229057201, -0.1990472977743802, -0.16652270412847678, -0.14224814142242237, -0.15664140040182178, -0.17329854414052104, -0.20259266888711208, -0.18164458328291125, -0.19653772309376216, -0.24234704500764193, -0.11795265042285943, -0.24095421042640386, -0.2523570738744384, -0.23879552075222876, -0.23561712465341556, -0.2476445152395353, -0.24126334103136698, -0.25721929520831344, -0.26417502808320964, -0.25764040623014933, -0.265893192210174, -0.22949891005885303, -0.25045758735400087, -0.2642862381939979, -0.2706010727911771], 'val_acc': [0.9457902863899373, 0.9481592896562185, 0.9478556983959601, 0.9495789630812888, 0.9506763586346407, 0.950150049621274, 0.9507074715187831, 0.9505992224497825, 0.9480560218325312, 0.9503055844247711, 0.9512897681745683, 0.9527940339183215, 0.9515236793837932, 0.9510794878005981, 0.9510956717574078, 0.9516916534175044, 0.9509388948819653, 0.9523299377157081, 0.9519691126687186, 0.9513146484860723, 0.9520810923961379, 0.9530938915584398, 0.9524854688170534, 0.9525427022335692, 0.9526472139802779, 0.9507236388159095, 0.9515871398197198, 0.9404401086872409, 0.9524556054091602, 0.9526260617356863, 0.9534684030906014, 0.9528388262535474, 0.9531648173835707, 0.9532009022576469, 0.9522391146754626, 0.9536065100142674, 0.953962364552184, 0.9539847644219487, 0.9513581987493527, 0.9526596606147956, 0.9532991925381725, 0.9536687320804004], 'val_mDice': [0.1899916654371697, 0.2215744494836523, 0.21026320929020087, 0.21770289885053723, 0.2120262229387064, 0.21400375511520398, 0.2138943373231414, 0.2072672454513008, 0.2140940267662084, 0.21420812893728292, 0.21542973631287213, 0.21348214378545743, 0.20956991911397216, 0.21323025781915794, 0.21489174770457403, 0.21602934237962923, 0.1983519503557534, 0.21096161896397608, 0.2094314765671025, 0.21152041297151436, 0.2115288094519088, 0.21302450482982285, 0.21186311596206256, 0.2106821666593137, 0.20913050689312243, 0.2009237201317497, 0.20639794815030899, 0.15907998607488152, 0.19939910643589423, 0.19890052341618894, 0.21237855858129004, 0.2042283248503386, 0.20831947741301163, 0.20606350847838087, 0.20215009344938378, 0.21046203277681186, 0.21158596743708072, 0.21141066800178207, 0.2016216884396091, 0.20669363601052243, 0.20433093010453704, 0.21033008553966973], 'loss': [0.5382584911216027, 0.4007437784307161, 0.36876164927586563, 0.3588346174585777, 0.3455440222395273, 0.33668818402917156, 0.3305339346179675, 0.32415011758298284, 0.3209213337366227, 0.31214131025520414, 0.31220840208612216, 0.30985020084348996, 0.30471508917268864, 0.3058724640347553, 0.3024050630163252, 0.29929766729689056, 0.3013648509253061, 0.28738593638573906, 0.28298922196990905, 0.284345226224396, 0.2807202221931422, 0.278164120343833, 0.2786885662008532, 0.27570304797222384, 0.2737262629763214, 0.2736090305582305, 0.25458914038682495, 0.24522631465086822, 0.24720986444713877, 0.23329334441833088, 0.23471345887547787, 0.23227229161456295, 0.2130614510678312, 0.20448725312249064, 0.20731985548441872, 0.20248210370313985, 0.19896014688953595, 0.19864786014732114, 0.1969209201355489, 0.19779865828765633, 0.19957628139166586, 0.19338376153582654], 'acc': [0.9039267449949979, 0.9397679956420257, 0.9435583499617667, 0.9454455372995961, 0.9468795219152621, 0.9480304745345133, 0.9487967408020629, 0.9496859349322342, 0.9501075653091154, 0.9506789447979195, 0.9511514932882255, 0.9513180691028643, 0.95168107253078, 0.9518983114526302, 0.9520773477720962, 0.9527250783456446, 0.9525409557376775, 0.9536561469651064, 0.9545149244571122, 0.9545378659963225, 0.9547574164470674, 0.9550412427389151, 0.9550633885112089, 0.9552307605705188, 0.955526457015579, 0.95318416463293, 0.9526384503614371, 0.952635830336941, 0.9520998014284655, 0.9520904241406256, 0.9522678922788957, 0.952260853102208, 0.9532040237577805, 0.9534820963954956, 0.95329900107425, 0.9532923213026775, 0.9534854096225838, 0.9534846390428815, 0.9533729635205319, 0.9534318958501397, 0.9534904198334667, 0.953629224374532], 'mDice': [0.41981042296102833, 0.5680307598594061, 0.6026105757858861, 0.6133161468664856, 0.6276657955315527, 0.637226698967309, 0.6438678215619423, 0.6507785777779641, 0.6542398242011748, 0.6637242949708374, 0.6636398545478008, 0.6661789450327453, 0.671732635060806, 0.6704547801588009, 0.6742279999681908, 0.6775717905657763, 0.6753238097869956, 0.6904265535454904, 0.6951478980183028, 0.6936770945682323, 0.6975997015236661, 0.7003429892277939, 0.6997795517760311, 0.7029377280251649, 0.7049016461191976, 0.6854606703826731, 0.6810483653868724, 0.6749252905903736, 0.6625693685812001, 0.6657860674950586, 0.6603501539996283, 0.6677148755103512, 0.6766038292415175, 0.6812179213190889, 0.6796007605461251, 0.6770610378964966, 0.6798629143674544, 0.6871253577666849, 0.6787841548786671, 0.6807020741630418, 0.6809942172902943, 0.6817125891905329], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  2020-01-22 02:47:56.577084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 02:47:56.577179: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 02:47:56.577192: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 02:47:56.577200: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 02:47:56.577487: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97331515 0.02668485]
Train on 16036 samples, validate on 318 samples
Epoch 1/300
 - 46s - loss: 0.1456 - acc: 0.9831 - mDice: 0.7216 - val_loss: 0.2814 - val_acc: 0.9916 - val_mDice: 0.4414

Epoch 00001: val_mDice improved from -inf to 0.44143, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 42s - loss: 0.0862 - acc: 0.9911 - mDice: 0.8325 - val_loss: 0.2792 - val_acc: 0.9920 - val_mDice: 0.4452

Epoch 00002: val_mDice improved from 0.44143 to 0.44520, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 43s - loss: 0.0752 - acc: 0.9922 - mDice: 0.8537 - val_loss: 0.2830 - val_acc: 0.9928 - val_mDice: 0.4355

Epoch 00003: val_mDice did not improve from 0.44520
Epoch 4/300
 - 44s - loss: 0.0706 - acc: 0.9926 - mDice: 0.8626 - val_loss: 0.3227 - val_acc: 0.9878 - val_mDice: 0.3583

Epoch 00004: val_mDice did not improve from 0.44520
Epoch 5/300
 - 44s - loss: 0.0670 - acc: 0.9930 - mDice: 0.8695 - val_loss: 0.2583 - val_acc: 0.9922 - val_mDice: 0.4370

Epoch 00005: val_mDice did not improve from 0.44520
Epoch 6/300
 - 44s - loss: 0.0608 - acc: 0.9935 - mDice: 0.8817 - val_loss: 0.1993 - val_acc: 0.9918 - val_mDice: 0.4303

Epoch 00006: val_mDice did not improve from 0.44520
Epoch 7/300
 - 43s - loss: 0.0582 - acc: 0.9937 - mDice: 0.8868 - val_loss: 0.2200 - val_acc: 0.9933 - val_mDice: 0.4620

Epoch 00007: val_mDice improved from 0.44520 to 0.46197, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 44s - loss: 0.0561 - acc: 0.9940 - mDice: 0.8909 - val_loss: 0.1462 - val_acc: 0.9937 - val_mDice: 0.4808

Epoch 00008: val_mDice improved from 0.46197 to 0.48079, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 9/300
 - 58s - loss: 0.0545 - acc: 0.9942 - mDice: 0.8939 - val_loss: 0.1351 - val_acc: 0.9918 - val_mDice: 0.4534

Epoch 00009: val_mDice did not improve from 0.48079
Epoch 10/300
 - 61s - loss: 0.0539 - acc: 0.9942 - mDice: 0.8952 - val_loss: 0.0194 - val_acc: 0.9932 - val_mDice: 0.4538

Epoch 00010: val_mDice did not improve from 0.48079
Epoch 11/300
 - 61s - loss: 0.0542 - acc: 0.9942 - mDice: 0.8945 - val_loss: -1.0216e-03 - val_acc: 0.9932 - val_mDice: 0.4645

Epoch 00011: val_mDice did not improve from 0.48079
Epoch 12/300
 - 57s - loss: 0.0504 - acc: 0.9945 - mDice: 0.9021 - val_loss: 0.0623 - val_acc: 0.9937 - val_mDice: 0.4887

Epoch 00012: val_mDice improved from 0.48079 to 0.48868, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 13/300
 - 59s - loss: 0.0505 - acc: 0.9946 - mDice: 0.9018 - val_loss: 0.0593 - val_acc: 0.9936 - val_mDice: 0.4759

Epoch 00013: val_mDice did not improve from 0.48868
Epoch 14/300
 - 59s - loss: 0.0481 - acc: 0.9947 - mDice: 0.9064 - val_loss: 0.1516 - val_acc: 0.9831 - val_mDice: 0.2483

Epoch 00014: val_mDice did not improve from 0.48868
Epoch 15/300
 - 59s - loss: 0.0498 - acc: 0.9946 - mDice: 0.9031 - val_loss: 0.1194 - val_acc: 0.9934 - val_mDice: 0.4790

Epoch 00015: val_mDice did not improve from 0.48868
Epoch 16/300
 - 59s - loss: 0.0484 - acc: 0.9948 - mDice: 0.9059 - val_loss: 0.0204 - val_acc: 0.9931 - val_mDice: 0.4537

Epoch 00016: val_mDice did not improve from 0.48868
Epoch 17/300
 - 59s - loss: 0.0457 - acc: 0.9950 - mDice: 0.9112 - val_loss: 0.0467 - val_acc: 0.9933 - val_mDice: 0.4672

Epoch 00017: val_mDice did not improve from 0.48868
Epoch 18/300
 - 60s - loss: 0.0460 - acc: 0.9949 - mDice: 0.9107 - val_loss: 0.0749 - val_acc: 0.9936 - val_mDice: 0.4889

Epoch 00018: val_mDice improved from 0.48868 to 0.48890, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 19/300
 - 59s - loss: 0.0468 - acc: 0.9948 - mDice: 0.9090 - val_loss: 0.0405 - val_acc: 0.9933 - val_mDice: 0.4950

Epoch 00019: val_mDice improved from 0.48890 to 0.49495, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 58s - loss: 0.0459 - acc: 0.9950 - mDice: 0.9107 - val_loss: 0.0707 - val_acc: 0.9934 - val_mDice: 0.4787

Epoch 00020: val_mDice did not improve from 0.49495
Epoch 21/300
 - 59s - loss: 0.0429 - acc: 0.9951 - mDice: 0.9166 - val_loss: 0.1840 - val_acc: 0.9928 - val_mDice: 0.4597

Epoch 00021: val_mDice did not improve from 0.49495
Epoch 22/300
 - 59s - loss: 0.0434 - acc: 0.9951 - mDice: 0.9157 - val_loss: -1.5159e-02 - val_acc: 0.9932 - val_mDice: 0.4804

Epoch 00022: val_mDice did not improve from 0.49495
Epoch 23/300
 - 60s - loss: 0.0443 - acc: 0.9951 - mDice: 0.9138 - val_loss: 0.0716 - val_acc: 0.9919 - val_mDice: 0.4388

Epoch 00023: val_mDice did not improve from 0.49495
Epoch 24/300
 - 59s - loss: 0.0436 - acc: 0.9952 - mDice: 0.9153 - val_loss: 0.0101 - val_acc: 0.9932 - val_mDice: 0.4653

Epoch 00024: val_mDice did not improve from 0.49495
Epoch 25/300
 - 59s - loss: 0.0446 - acc: 0.9951 - mDice: 0.9133 - val_loss: 0.1362 - val_acc: 0.9933 - val_mDice: 0.4798

Epoch 00025: val_mDice did not improve from 0.49495
Epoch 26/300
 - 59s - loss: 0.0434 - acc: 0.9953 - mDice: 0.9155 - val_loss: 0.0226 - val_acc: 0.9939 - val_mDice: 0.4911

Epoch 00026: val_mDice did not improve from 0.49495
Epoch 27/300
 - 59s - loss: 0.0460 - acc: 0.9950 - mDice: 0.9105 - val_loss: -1.1837e-02 - val_acc: 0.9937 - val_mDice: 0.4736

Epoch 00027: val_mDice did not improve from 0.49495
Epoch 28/300
 - 60s - loss: 0.0446 - acc: 0.9953 - mDice: 0.9132 - val_loss: 0.0343 - val_acc: 0.9926 - val_mDice: 0.4445

Epoch 00028: val_mDice did not improve from 0.49495
Epoch 29/300
 - 60s - loss: 0.0414 - acc: 0.9953 - mDice: 0.9195 - val_loss: 0.0261 - val_acc: 0.9929 - val_mDice: 0.4612

Epoch 00029: val_mDice did not improve from 0.49495
Epoch 30/300
 - 58s - loss: 0.0417 - acc: 0.9954 - mDice: 0.9189 - val_loss: 0.0037 - val_acc: 0.9934 - val_mDice: 0.4735

Epoch 00030: val_mDice did not improve from 0.49495
Epoch 31/300
 - 59s - loss: 0.0413 - acc: 0.9954 - mDice: 0.9196 - val_loss: 0.0053 - val_acc: 0.9937 - val_mDice: 0.4913

Epoch 00031: val_mDice did not improve from 0.49495
Epoch 32/300
 - 59s - loss: 0.0411 - acc: 0.9954 - mDice: 0.9200 - val_loss: 0.0050 - val_acc: 0.9924 - val_mDice: 0.4412

Epoch 00032: val_mDice did not improve from 0.49495
Epoch 33/300
 - 60s - loss: 0.0408 - acc: 0.9955 - mDice: 0.9206 - val_loss: 0.0122 - val_acc: 0.9937 - val_mDice: 0.4885

Epoch 00033: val_mDice did not improve from 0.49495
Epoch 34/300
 - 59s - loss: 0.0403 - acc: 0.9954 - mDice: 0.9217 - val_loss: -9.7111e-03 - val_acc: 0.9937 - val_mDice: 0.4693

Epoch 00034: val_mDice did not improve from 0.49495

Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 35/300
 - 59s - loss: 0.0389 - acc: 0.9956 - mDice: 0.9244 - val_loss: 0.0145 - val_acc: 0.9927 - val_mDice: 0.4547

Epoch 00035: val_mDice did not improve from 0.49495
Epoch 36/300
 - 59s - loss: 0.0381 - acc: 0.9957 - mDice: 0.9260 - val_loss: 0.0361 - val_acc: 0.9938 - val_mDice: 0.5041

Epoch 00036: val_mDice improved from 0.49495 to 0.50407, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/1-THALAMUS/sd2/best_model_weights.h5
Epoch 37/300
 - 58s - loss: 0.0375 - acc: 0.9957 - mDice: 0.9270 - val_loss: -1.5265e-02 - val_acc: 0.9939 - val_mDice: 0.4958

Epoch 00037: val_mDice did not improve from 0.50407
Epoch 38/300
 - 58s - loss: 0.0382 - acc: 0.9957 - mDice: 0.9258 - val_loss: -1.9513e-02 - val_acc: 0.9936 - val_mDice: 0.4895

Epoch 00038: val_mDice did not improve from 0.50407
Epoch 39/300
 - 60s - loss: 0.0369 - acc: 0.9957 - mDice: 0.9284 - val_loss: -1.6556e-02 - val_acc: 0.9938 - val_mDice: 0.4864

Epoch 00039: val_mDice did not improve from 0.50407
Epoch 40/300
 - 59s - loss: 0.0367 - acc: 0.9958 - mDice: 0.9287 - val_loss: 0.0775 - val_acc: 0.9938 - val_mDice: 0.5024

Epoch 00040: val_mDice did not improve from 0.50407
Epoch 41/300
 - 59s - loss: 0.0366 - acc: 0.9958 - mDice: 0.9288 - val_loss: -1.2548e-02 - val_acc: 0.9935 - val_mDice: 0.4750

Epoch 00041: val_mDice did not improve from 0.50407
Epoch 42/300
 - 59s - loss: 0.0365 - acc: 0.9958 - mDice: 0.9291 - val_loss: 0.1918 - val_acc: 0.9894 - val_mDice: 0.4437

Epoch 00042: val_mDice did not improve from 0.50407
Epoch 43/300
 - 59s - loss: 0.0371 - acc: 0.9958 - mDice: 0.9279 - val_loss: 0.0162 - val_acc: 0.9940 - val_mDice: 0.4818

Epoch 00043: val_mDice did not improve from 0.50407
Epoch 44/300
 - 59s - loss: 0.0368 - acc: 0.9958 - mDice: 0.9285 - val_loss: -1.3386e-02 - val_acc: 0.9935 - val_mDice: 0.4786

Epoch 00044: val_mDice did not improve from 0.50407
Epoch 45/300
 - 59s - loss: 0.0362 - acc: 0.9958 - mDice: 0.9296 - val_loss: 0.0127 - val_acc: 0.9926 - val_mDice: 0.4486

Epoch 00045: val_mDice did not improve from 0.50407
Epoch 46/300
 - 59s - loss: 0.0356 - acc: 0.9959 - mDice: 0.9308 - val_loss: 0.0419 - val_acc: 0.9935 - val_mDice: 0.4796

Epoch 00046: val_mDice did not improve from 0.50407
Epoch 47/300
 - 59s - loss: 0.0358 - acc: 0.9958 - mDice: 0.9304 - val_loss: -9.9259e-03 - val_acc: 0.9940 - val_mDice: 0.4752

Epoch 00047: val_mDice did not improve from 0.50407
Epoch 48/300
 - 59s - loss: 0.0356 - acc: 0.9959 - mDice: 0.9308 - val_loss: -2.9749e-03 - val_acc: 0.9930 - val_mDice: 0.4561

Epoch 00048: val_mDice did not improve from 0.50407
Epoch 49/300
 - 59s - loss: 0.0369 - acc: 0.9958 - mDice: 0.9283 - val_loss: -9.8555e-03 - val_acc: 0.9931 - val_mDice: 0.4700

Epoch 00049: val_mDice did not improve from 0.50407
Epoch 50/300
 - 60s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9299 - val_loss: 0.0195 - val_acc: 0.9939 - val_mDice: 0.4736

Epoch 00050: val_mDice did not improve from 0.50407
Epoch 51/300
 - 59s - loss: 0.0350 - acc: 0.9959 - mDice: 0.9320 - val_loss: -1.2630e-02 - val_acc: 0.9936 - val_mDice: 0.4751

Epoch 00051: val_mDice did not improve from 0.50407

Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 52/300
 - 56s - loss: 0.0340 - acc: 0.9960 - mDice: 0.9340 - val_loss: 0.0198 - val_acc: 0.9937 - val_mDice: 0.4732

Epoch 00052: val_mDice did not improve from 0.50407
Epoch 53/300
 - 60s - loss: 0.0337 - acc: 0.9960 - mDice: 0.9345 - val_loss: 0.0153 - val_acc: 0.9940 - val_mDice: 0.4817

Epoch 00053: val_mDice did not improve from 0.50407
Epoch 54/300
 - 59s - loss: 0.0339 - acc: 0.9960 - mDice: 0.9341 - val_loss: 0.0147 - val_acc: 0.9940 - val_mDice: 0.4815

Epoch 00054: val_mDice did not improve from 0.50407
Epoch 55/300
 - 59s - loss: 0.0336 - acc: 0.9960 - mDice: 0.9348 - val_loss: -1.4140e-02 - val_acc: 0.9939 - val_mDice: 0.4780

Epoch 00055: val_mDice did not improve from 0.50407
Epoch 56/300
 - 59s - loss: 0.0337 - acc: 0.9960 - mDice: 0.9345 - val_loss: -1.0810e-02 - val_acc: 0.9937 - val_mDice: 0.4744

Epoch 00056: val_mDice did not improve from 0.50407
Epoch 57/300
 - 59s - loss: 0.0334 - acc: 0.9960 - mDice: 0.9352 - val_loss: -7.4791e-05 - val_acc: 0.9926 - val_mDice: 0.4517

Epoch 00057: val_mDice did not improve from 0.50407
Epoch 58/300
 - 60s - loss: 0.0328 - acc: 0.9960 - mDice: 0.9364 - val_loss: 0.0034 - val_acc: 0.9921 - val_mDice: 0.4438

Epoch 00058: val_mDice did not improve from 0.50407
Epoch 59/300
 - 59s - loss: 0.0334 - acc: 0.9960 - mDice: 0.9351 - val_loss: -1.6474e-03 - val_acc: 0.9925 - val_mDice: 0.4536

Epoch 00059: val_mDice did not improve from 0.50407
Epoch 60/300
 - 60s - loss: 0.0336 - acc: 0.9960 - mDice: 0.9347 - val_loss: -7.4137e-03 - val_acc: 0.9936 - val_mDice: 0.4647

Epoch 00060: val_mDice did not improve from 0.50407
Epoch 61/300
 - 60s - loss: 0.0342 - acc: 0.9960 - mDice: 0.9336 - val_loss: -1.3213e-02 - val_acc: 0.9938 - val_mDice: 0.4762

Epoch 00061: val_mDice did not improve from 0.50407
Epoch 62/300
 - 60s - loss: 0.0328 - acc: 0.9961 - mDice: 0.9364 - val_loss: 0.0781 - val_acc: 0.9942 - val_mDice: 0.4822

Epoch 00062: val_mDice did not improve from 0.50407
Epoch 63/300
 - 56s - loss: 0.0334 - acc: 0.9961 - mDice: 0.9352 - val_loss: -2.4887e-03 - val_acc: 0.9937 - val_mDice: 0.4760

Epoch 00063: val_mDice did not improve from 0.50407
Epoch 64/300
 - 57s - loss: 0.0334 - acc: 0.9961 - mDice: 0.9352 - val_loss: -1.4439e-02 - val_acc: 0.9938 - val_mDice: 0.4786

Epoch 00064: val_mDice did not improve from 0.50407
Epoch 65/300
 - 60s - loss: 0.0327 - acc: 0.9961 - mDice: 0.9365 - val_loss: -8.6506e-03 - val_acc: 0.9935 - val_mDice: 0.4672

Epoch 00065: val_mDice did not improve from 0.50407
Epoch 66/300
 - 60s - loss: 0.0327 - acc: 0.9961 - mDice: 0.9365 - val_loss: 0.0021 - val_acc: 0.9940 - val_mDice: 0.4965

Epoch 00066: val_mDice did not improve from 0.50407

Epoch 00066: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 67/300
 - 60s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9368 - val_loss: -1.3850e-02 - val_acc: 0.9939 - val_mDice: 0.4872

Epoch 00067: val_mDice did not improve from 0.50407
Epoch 68/300
 - 56s - loss: 0.0326 - acc: 0.9961 - mDice: 0.9366 - val_loss: -8.4468e-03 - val_acc: 0.9934 - val_mDice: 0.4668

Epoch 00068: val_mDice did not improve from 0.50407
Epoch 69/300
 - 44s - loss: 0.0322 - acc: 0.9961 - mDice: 0.9376 - val_loss: -1.7145e-02 - val_acc: 0.9939 - val_mDice: 0.4840

Epoch 00069: val_mDice did not improve from 0.50407
Epoch 70/300
 - 44s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9378 - val_loss: -1.3692e-02 - val_acc: 0.9937 - val_mDice: 0.4773

Epoch 00070: val_mDice did not improve from 0.50407
Epoch 71/300
 - 43s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9370 - val_loss: 0.0194 - val_acc: 0.9938 - val_mDice: 0.4740

Epoch 00071: val_mDice did not improve from 0.50407
Epoch 72/300
 - 43s - loss: 0.0318 - acc: 0.9961 - mDice: 0.9383 - val_loss: -9.7567e-03 - val_acc: 0.9935 - val_mDice: 0.4700

Epoch 00072: val_mDice did not improve from 0.50407
Epoch 73/300
 - 43s - loss: 0.0321 - acc: 0.9961 - mDice: 0.9377 - val_loss: -1.2346e-02 - val_acc: 0.9937 - val_mDice: 0.4750

Epoch 00073: val_mDice did not improve from 0.50407
Epoch 74/300
 - 43s - loss: 0.0325 - acc: 0.9961 - mDice: 0.9368 - val_loss: 0.0020 - val_acc: 0.9938 - val_mDice: 0.4792

Epoch 00074: val_mDice did not improve from 0.50407
Epoch 75/300
 - 43s - loss: 0.0323 - acc: 0.9962 - mDice: 0.9373 - val_loss: 0.0148 - val_acc: 0.9938 - val_mDice: 0.4831

Epoch 00075: val_mDice did not improve from 0.50407
Epoch 76/300
 - 43s - loss: 0.0318 - acc: 0.9962 - mDice: 0.9383 - val_loss: 0.0112 - val_acc: 0.9937 - val_mDice: 0.4759

Epoch 00076: val_mDice did not improve from 0.50407
Restoring model weights from the end of the best epoch
Epoch 00076: early stopping
{'val_loss': [0.2814390106396105, 0.2792118525823707, 0.2830010292665014, 0.3227179482485513, 0.25830053411564735, 0.1993215060646429, 0.22001755546848728, 0.14618063947689608, 0.13506593906654502, 0.019380750052584043, -0.0010215625541764985, 0.06226853866997005, 0.05928970086124708, 0.15162079814095167, 0.11936069767242707, 0.020360632278259447, 0.04666123534523466, 0.07486012235939878, 0.040523185670000954, 0.07073615613223622, 0.18397036438468117, -0.01515928402824222, 0.07155622134231171, 0.010115545875621293, 0.13620369328455356, 0.022594787977026694, -0.01183705819102953, 0.034340282843547794, 0.02610707737552295, 0.003715452064508162, 0.005284565893359155, 0.0050421531470316765, 0.012154494207235252, -0.009711088624390416, 0.014457301476841452, 0.036083656380761345, -0.015264863206905389, -0.019512850346055422, -0.01655632182487152, 0.0774718223127929, -0.012548038981995493, 0.19179028708417462, 0.01620136398189473, -0.013385588642936083, 0.012705460284491005, 0.041890684772962296, -0.009925936940331129, -0.0029748748027303685, -0.009855459368078964, 0.01951452339970091, -0.012630219823159513, 0.01976163699379507, 0.015280358446469097, 0.014671281636136133, -0.014140170184696245, -0.01081043688006371, -7.479108354580478e-05, 0.0033801371852556863, -0.0016474328325979364, -0.007413745723055594, -0.013212817738640983, 0.07806689901359426, -0.00248871532813558, -0.014438665278677671, -0.00865063136853512, 0.002126811482246567, -0.013849715626089828, -0.00844682125175524, -0.017144939668898313, -0.013692428012314083, 0.019350088570477826, -0.009756722633943617, -0.012346243567811619, 0.0020226356368394766, 0.014801681885179484, 0.011220960356529404], 'val_acc': [0.9915592842881784, 0.9920216446402688, 0.9927545943350162, 0.9878272676617844, 0.9922119090392155, 0.9917814248013046, 0.9933346806082336, 0.993665006550603, 0.9918411662743526, 0.9932493353789708, 0.9931883380847907, 0.9936572298313837, 0.993597480860896, 0.9831122965932643, 0.9934308202761524, 0.9931183082502593, 0.9932533483835136, 0.9936496949045913, 0.9933130879822017, 0.9934079755777083, 0.9928321590963399, 0.9932026488226164, 0.9919059310319289, 0.993213692551139, 0.9933474806119811, 0.9939265641026527, 0.9937019070739266, 0.992569848051611, 0.9928883842702182, 0.9933723308755167, 0.9937157117345798, 0.9923820934205685, 0.9936534586192677, 0.9937403070851691, 0.9927277347576693, 0.993765412261651, 0.9938751016772768, 0.9935992446335606, 0.9937809731975291, 0.9937802215792099, 0.9935078733372238, 0.9894021048485858, 0.9940181790657763, 0.9934968333574211, 0.9926102611253846, 0.9934699737800742, 0.9940154218823655, 0.9930194113989296, 0.9931097761640009, 0.9938974402985483, 0.9936494474890847, 0.9936567275029309, 0.9940249548768098, 0.9940116514199935, 0.9938562718577355, 0.9936504483972706, 0.9925964564647315, 0.9920693396022485, 0.992506594028113, 0.9935513003817145, 0.9938261565172447, 0.9941768155157941, 0.9937332819842692, 0.9938412188733898, 0.9934586751386054, 0.9940073891255841, 0.9938949361537237, 0.9934350825705618, 0.9939298198657965, 0.9936624949083388, 0.993754119243262, 0.993518167321787, 0.9936747982067132, 0.9938321807099588, 0.993825153734699, 0.9936752975361902], 'val_mDice': [0.44143420525595606, 0.44520208680946766, 0.4354737659273049, 0.3583021246418778, 0.4370412924005423, 0.4302689840771173, 0.4619680864021949, 0.4807878331333961, 0.4533746411274158, 0.4538372477645475, 0.4644820611314766, 0.4886797773388197, 0.47586784422773387, 0.2483478815839556, 0.47899840341051036, 0.4537433627445112, 0.46715523255561237, 0.4889026813724506, 0.4949549347185676, 0.478658434355034, 0.4596872814562702, 0.4804059816231518, 0.438812974334198, 0.4652626800373485, 0.4797637373583872, 0.4910812447281004, 0.47356868051462225, 0.44449128541486255, 0.46119320645647227, 0.47348853153815057, 0.49131978607789656, 0.4412348530952286, 0.48848266871470325, 0.4692646323450549, 0.45465151974820617, 0.5040746370810758, 0.49576449131815686, 0.4895045246387855, 0.4863803107408663, 0.5024382197913134, 0.4750187025063137, 0.44374852048807173, 0.4818165953616979, 0.4785729793205461, 0.4486268761812317, 0.4795697176793836, 0.47520156151389564, 0.4561022758805885, 0.4699542692074384, 0.47362389507089664, 0.4750934668449471, 0.4732464796295331, 0.48174385145400306, 0.4815313149735613, 0.47801204011736886, 0.4744027592476059, 0.4517467430084007, 0.4438176488726394, 0.4536214012816642, 0.464681735109983, 0.47620307029599807, 0.4822428673271488, 0.4759834820416369, 0.47863923799941627, 0.4672164455915177, 0.4964590091375435, 0.4872483403990104, 0.4668272309863366, 0.4840211054813937, 0.47730969979703053, 0.4740310734454191, 0.46995479882981794, 0.4750305121331095, 0.47916233422433807, 0.48308336462989543, 0.47592709414988943], 'loss': [0.14560003197120294, 0.08622004448471744, 0.07521095344214614, 0.07063117736230827, 0.06703529732167557, 0.060836701774000974, 0.05823262033151938, 0.056064375010652416, 0.054544484656769664, 0.053852048556416315, 0.054238839752843895, 0.05037557242828939, 0.05049225151070516, 0.048148800737655914, 0.04979843406360267, 0.04839882317509518, 0.045680095008385095, 0.0459511958203892, 0.0468271352215044, 0.04592801629196054, 0.04291608195726816, 0.04340260986579746, 0.04434586135146921, 0.04358593365848882, 0.04456460191762546, 0.043439006831995954, 0.04599612522995748, 0.0445790380837912, 0.041430750110480044, 0.04172024327911293, 0.041341027497211934, 0.0411270322372459, 0.040825080136745524, 0.04029710078368046, 0.03886761612136425, 0.03806931502052185, 0.0375491820710664, 0.038170297442194114, 0.03685795162853442, 0.036675815237976424, 0.036641526292664775, 0.03648378754563836, 0.037090971196164634, 0.03677101697086039, 0.03624289215491965, 0.035625389327608045, 0.035837399898978294, 0.03560063306564671, 0.03687659614429298, 0.03606711068866883, 0.035031320716294605, 0.03401193370167738, 0.033728639699516824, 0.033927584302547296, 0.03357231000149806, 0.03373061878019867, 0.03336202235877083, 0.032789645316513676, 0.03343273663415252, 0.03362111492376579, 0.034168309818541624, 0.03276642907134878, 0.03337146509898723, 0.03336496248815267, 0.03272029074793089, 0.032695680563067465, 0.03256686823616809, 0.03262814581598627, 0.0321584466122784, 0.03206659704688393, 0.03246653059543472, 0.031808066850188485, 0.03206854164284433, 0.032536227331327425, 0.032280437348154487, 0.03179724792603484], 'acc': [0.9831367255848047, 0.9911147347335716, 0.9921912858910797, 0.9926115715331227, 0.9930492339808615, 0.9935360711303011, 0.9937466450479745, 0.9940075265347259, 0.9941641127982916, 0.994230862648358, 0.9941833561258918, 0.9944820282286199, 0.9945669660665769, 0.9947257879429192, 0.9946072402738461, 0.994758022852924, 0.9949575256724463, 0.9948876607102864, 0.9948474212339853, 0.9950029715825032, 0.9951242820212716, 0.9951230281381781, 0.9950948237153651, 0.9951716137217833, 0.9951371983210325, 0.9952651976230704, 0.9950106668558523, 0.9953126401103146, 0.9953272388028397, 0.9953504847778468, 0.9953707785090772, 0.9954075825633656, 0.9954551348189042, 0.9954394697548297, 0.9956474849769795, 0.995691378103524, 0.9957414076092773, 0.9956567382895759, 0.995747917933665, 0.9957525070527153, 0.9957669327148448, 0.995791447410919, 0.9957565442898471, 0.9958128610894875, 0.9958147633756655, 0.9958525974648229, 0.9958406660169639, 0.9958857836108399, 0.9958364207062468, 0.9958712637320395, 0.9958914283892555, 0.9959524490197539, 0.9959862760532285, 0.9959833897031374, 0.996007158047661, 0.9960285375899702, 0.9960237286592785, 0.9960466808557926, 0.996005729855549, 0.9960382824215873, 0.9960410363152604, 0.9960541866327587, 0.9960612702039627, 0.9960760485578815, 0.9960629317893682, 0.9960893985635773, 0.9961040377929105, 0.9961301060084483, 0.996108537326581, 0.9961376765714557, 0.9961331417938812, 0.9961413298277048, 0.9961409956164775, 0.9961438489602551, 0.9961857199520208, 0.9961506633664581], 'mDice': [0.7215596578050282, 0.8324580645588937, 0.8537384757775047, 0.8626129561145883, 0.8695448808757081, 0.8816698373263541, 0.8867513468829614, 0.8909422958882544, 0.893896455111397, 0.8952440545167255, 0.8944964995203799, 0.9020586807432244, 0.9017810457497352, 0.9063784140813794, 0.9031439695232467, 0.9058569682621248, 0.9111878747995371, 0.9106846255152473, 0.9089562155799529, 0.9106662897070199, 0.9166268735462426, 0.9156576457888029, 0.9137794572862791, 0.9152560643377848, 0.9133207235893248, 0.9155033959949751, 0.9105287121869503, 0.9131953630590708, 0.919484488571276, 0.918893287322131, 0.9196350416709848, 0.9200429163258044, 0.9206244455895302, 0.9216901192301733, 0.924433536906549, 0.9260060503599381, 0.9270191582235263, 0.9258205258592045, 0.9283874588629408, 0.9287474807077705, 0.9288117453756997, 0.9291186302335341, 0.9279150301216547, 0.9285316499399408, 0.9295846142291343, 0.9308037079236965, 0.9303793491798912, 0.9308297304953682, 0.928310384652834, 0.9299120894652051, 0.9319634876009769, 0.9339638953421234, 0.934510005995293, 0.9341168300332081, 0.9348097761823936, 0.9344900466016653, 0.9352232124233638, 0.9363601030510065, 0.9350949253010673, 0.934694608649758, 0.933606668388674, 0.9364014216293329, 0.9351799491101553, 0.9351964045058584, 0.9364897069282203, 0.936531179658669, 0.9367719324308906, 0.9366273367737974, 0.937576292027378, 0.9377513656178506, 0.936956189576528, 0.9382673943316321, 0.9377485508248805, 0.9368045539905318, 0.9373058469984173, 0.9382849025604403], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:02,  1.49it/s]predicting test subjects:  40%|████      | 2/5 [00:00<00:01,  1.90it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:00,  2.40it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.90it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.61it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  3.81it/s]
predicting train subjects:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/247 [00:00<00:34,  7.21it/s]predicting train subjects:   1%|          | 2/247 [00:00<00:33,  7.38it/s]predicting train subjects:   1%|          | 3/247 [00:00<00:31,  7.74it/s]predicting train subjects:   2%|▏         | 4/247 [00:00<00:31,  7.78it/s]predicting train subjects:   2%|▏         | 5/247 [00:00<00:30,  7.86it/s]predicting train subjects:   2%|▏         | 6/247 [00:00<00:30,  7.89it/s]predicting train subjects:   3%|▎         | 7/247 [00:00<00:30,  8.00it/s]predicting train subjects:   3%|▎         | 8/247 [00:01<00:29,  8.02it/s]predicting train subjects:   4%|▎         | 9/247 [00:01<00:29,  8.01it/s]predicting train subjects:   4%|▍         | 10/247 [00:01<00:29,  8.03it/s]predicting train subjects:   4%|▍         | 11/247 [00:01<00:29,  8.04it/s]predicting train subjects:   5%|▍         | 12/247 [00:01<00:29,  8.05it/s]predicting train subjects:   5%|▌         | 13/247 [00:01<00:28,  8.11it/s]predicting train subjects:   6%|▌         | 14/247 [00:01<00:28,  8.10it/s]predicting train subjects:   6%|▌         | 15/247 [00:01<00:28,  8.08it/s]predicting train subjects:   6%|▋         | 16/247 [00:02<00:29,  7.84it/s]predicting train subjects:   7%|▋         | 17/247 [00:02<00:29,  7.67it/s]predicting train subjects:   7%|▋         | 18/247 [00:02<00:29,  7.85it/s]predicting train subjects:   8%|▊         | 19/247 [00:02<00:28,  7.96it/s]predicting train subjects:   8%|▊         | 20/247 [00:02<00:29,  7.66it/s]predicting train subjects:   9%|▊         | 21/247 [00:02<00:28,  7.80it/s]predicting train subjects:   9%|▉         | 22/247 [00:02<00:28,  7.90it/s]predicting train subjects:   9%|▉         | 23/247 [00:02<00:27,  8.10it/s]predicting train subjects:  10%|▉         | 24/247 [00:03<00:27,  8.25it/s]predicting train subjects:  10%|█         | 25/247 [00:03<00:26,  8.34it/s]predicting train subjects:  11%|█         | 26/247 [00:03<00:26,  8.41it/s]predicting train subjects:  11%|█         | 27/247 [00:03<00:25,  8.50it/s]predicting train subjects:  11%|█▏        | 28/247 [00:03<00:25,  8.52it/s]predicting train subjects:  12%|█▏        | 29/247 [00:03<00:25,  8.53it/s]predicting train subjects:  12%|█▏        | 30/247 [00:03<00:25,  8.53it/s]predicting train subjects:  13%|█▎        | 31/247 [00:03<00:25,  8.52it/s]predicting train subjects:  13%|█▎        | 32/247 [00:03<00:25,  8.55it/s]predicting train subjects:  13%|█▎        | 33/247 [00:04<00:25,  8.38it/s]predicting train subjects:  14%|█▍        | 34/247 [00:04<00:25,  8.30it/s]predicting train subjects:  14%|█▍        | 35/247 [00:04<00:25,  8.37it/s]predicting train subjects:  15%|█▍        | 36/247 [00:04<00:24,  8.46it/s]predicting train subjects:  15%|█▍        | 37/247 [00:04<00:24,  8.54it/s]predicting train subjects:  15%|█▌        | 38/247 [00:04<00:24,  8.59it/s]predicting train subjects:  16%|█▌        | 39/247 [00:04<00:24,  8.61it/s]predicting train subjects:  16%|█▌        | 40/247 [00:04<00:24,  8.62it/s]predicting train subjects:  17%|█▋        | 41/247 [00:05<00:24,  8.45it/s]predicting train subjects:  17%|█▋        | 42/247 [00:05<00:24,  8.49it/s]predicting train subjects:  17%|█▋        | 43/247 [00:05<00:23,  8.51it/s]predicting train subjects:  18%|█▊        | 44/247 [00:05<00:23,  8.53it/s]predicting train subjects:  18%|█▊        | 45/247 [00:05<00:23,  8.57it/s]predicting train subjects:  19%|█▊        | 46/247 [00:05<00:23,  8.52it/s]predicting train subjects:  19%|█▉        | 47/247 [00:05<00:24,  8.29it/s]predicting train subjects:  19%|█▉        | 48/247 [00:05<00:24,  8.29it/s]predicting train subjects:  20%|█▉        | 49/247 [00:05<00:24,  8.21it/s]predicting train subjects:  20%|██        | 50/247 [00:06<00:23,  8.33it/s]predicting train subjects:  21%|██        | 51/247 [00:06<00:23,  8.38it/s]predicting train subjects:  21%|██        | 52/247 [00:06<00:23,  8.30it/s]predicting train subjects:  21%|██▏       | 53/247 [00:06<00:23,  8.43it/s]predicting train subjects:  22%|██▏       | 54/247 [00:06<00:23,  8.25it/s]predicting train subjects:  22%|██▏       | 55/247 [00:06<00:22,  8.35it/s]predicting train subjects:  23%|██▎       | 56/247 [00:06<00:22,  8.41it/s]predicting train subjects:  23%|██▎       | 57/247 [00:06<00:22,  8.47it/s]predicting train subjects:  23%|██▎       | 58/247 [00:07<00:22,  8.54it/s]predicting train subjects:  24%|██▍       | 59/247 [00:07<00:22,  8.39it/s]predicting train subjects:  24%|██▍       | 60/247 [00:07<00:22,  8.27it/s]predicting train subjects:  25%|██▍       | 61/247 [00:07<00:22,  8.13it/s]predicting train subjects:  25%|██▌       | 62/247 [00:07<00:23,  7.99it/s]predicting train subjects:  26%|██▌       | 63/247 [00:07<00:24,  7.65it/s]predicting train subjects:  26%|██▌       | 64/247 [00:07<00:23,  7.78it/s]predicting train subjects:  26%|██▋       | 65/247 [00:07<00:23,  7.84it/s]predicting train subjects:  27%|██▋       | 66/247 [00:08<00:22,  7.88it/s]predicting train subjects:  27%|██▋       | 67/247 [00:08<00:22,  7.91it/s]predicting train subjects:  28%|██▊       | 68/247 [00:08<00:22,  7.91it/s]predicting train subjects:  28%|██▊       | 69/247 [00:08<00:22,  7.91it/s]predicting train subjects:  28%|██▊       | 70/247 [00:08<00:22,  7.92it/s]predicting train subjects:  29%|██▊       | 71/247 [00:08<00:22,  7.86it/s]predicting train subjects:  29%|██▉       | 72/247 [00:08<00:22,  7.91it/s]predicting train subjects:  30%|██▉       | 73/247 [00:08<00:21,  7.92it/s]predicting train subjects:  30%|██▉       | 74/247 [00:09<00:21,  7.97it/s]predicting train subjects:  30%|███       | 75/247 [00:09<00:22,  7.80it/s]predicting train subjects:  31%|███       | 76/247 [00:09<00:21,  7.87it/s]predicting train subjects:  31%|███       | 77/247 [00:09<00:22,  7.57it/s]predicting train subjects:  32%|███▏      | 78/247 [00:09<00:22,  7.43it/s]predicting train subjects:  32%|███▏      | 79/247 [00:09<00:25,  6.61it/s]predicting train subjects:  32%|███▏      | 80/247 [00:09<00:27,  6.01it/s]predicting train subjects:  33%|███▎      | 81/247 [00:10<00:27,  5.95it/s]predicting train subjects:  33%|███▎      | 82/247 [00:10<00:27,  6.06it/s]predicting train subjects:  34%|███▎      | 83/247 [00:10<00:26,  6.28it/s]predicting train subjects:  34%|███▍      | 84/247 [00:10<00:25,  6.50it/s]predicting train subjects:  34%|███▍      | 85/247 [00:10<00:24,  6.62it/s]predicting train subjects:  35%|███▍      | 86/247 [00:10<00:24,  6.67it/s]predicting train subjects:  35%|███▌      | 87/247 [00:11<00:23,  6.75it/s]predicting train subjects:  36%|███▌      | 88/247 [00:11<00:23,  6.84it/s]predicting train subjects:  36%|███▌      | 89/247 [00:11<00:22,  6.90it/s]predicting train subjects:  36%|███▋      | 90/247 [00:11<00:22,  6.95it/s]predicting train subjects:  37%|███▋      | 91/247 [00:11<00:22,  6.93it/s]predicting train subjects:  37%|███▋      | 92/247 [00:11<00:22,  6.95it/s]predicting train subjects:  38%|███▊      | 93/247 [00:11<00:22,  6.98it/s]predicting train subjects:  38%|███▊      | 94/247 [00:12<00:21,  7.00it/s]predicting train subjects:  38%|███▊      | 95/247 [00:12<00:21,  6.94it/s]predicting train subjects:  39%|███▉      | 96/247 [00:12<00:21,  6.88it/s]predicting train subjects:  39%|███▉      | 97/247 [00:12<00:22,  6.81it/s]predicting train subjects:  40%|███▉      | 98/247 [00:12<00:21,  6.87it/s]predicting train subjects:  40%|████      | 99/247 [00:12<00:21,  6.90it/s]predicting train subjects:  40%|████      | 100/247 [00:12<00:21,  6.99it/s]predicting train subjects:  41%|████      | 101/247 [00:13<00:20,  7.05it/s]predicting train subjects:  41%|████▏     | 102/247 [00:13<00:20,  7.07it/s]predicting train subjects:  42%|████▏     | 103/247 [00:13<00:20,  7.09it/s]predicting train subjects:  42%|████▏     | 104/247 [00:13<00:20,  7.13it/s]predicting train subjects:  43%|████▎     | 105/247 [00:13<00:19,  7.13it/s]predicting train subjects:  43%|████▎     | 106/247 [00:13<00:19,  7.14it/s]predicting train subjects:  43%|████▎     | 107/247 [00:13<00:19,  7.14it/s]predicting train subjects:  44%|████▎     | 108/247 [00:14<00:19,  7.11it/s]predicting train subjects:  44%|████▍     | 109/247 [00:14<00:19,  6.97it/s]predicting train subjects:  45%|████▍     | 110/247 [00:14<00:19,  6.97it/s]predicting train subjects:  45%|████▍     | 111/247 [00:14<00:19,  7.09it/s]predicting train subjects:  45%|████▌     | 112/247 [00:14<00:18,  7.16it/s]predicting train subjects:  46%|████▌     | 113/247 [00:14<00:18,  7.06it/s]predicting train subjects:  46%|████▌     | 114/247 [00:14<00:18,  7.09it/s]predicting train subjects:  47%|████▋     | 115/247 [00:15<00:18,  7.17it/s]predicting train subjects:  47%|████▋     | 116/247 [00:15<00:18,  7.09it/s]predicting train subjects:  47%|████▋     | 117/247 [00:15<00:18,  7.12it/s]predicting train subjects:  48%|████▊     | 118/247 [00:15<00:17,  7.55it/s]predicting train subjects:  48%|████▊     | 119/247 [00:15<00:16,  7.89it/s]predicting train subjects:  49%|████▊     | 120/247 [00:15<00:15,  8.16it/s]predicting train subjects:  49%|████▉     | 121/247 [00:15<00:15,  8.18it/s]predicting train subjects:  49%|████▉     | 122/247 [00:15<00:15,  8.31it/s]predicting train subjects:  50%|████▉     | 123/247 [00:15<00:14,  8.43it/s]predicting train subjects:  50%|█████     | 124/247 [00:16<00:14,  8.50it/s]predicting train subjects:  51%|█████     | 125/247 [00:16<00:14,  8.52it/s]predicting train subjects:  51%|█████     | 126/247 [00:16<00:14,  8.47it/s]predicting train subjects:  51%|█████▏    | 127/247 [00:16<00:14,  8.57it/s]predicting train subjects:  52%|█████▏    | 128/247 [00:16<00:13,  8.66it/s]predicting train subjects:  52%|█████▏    | 129/247 [00:16<00:13,  8.70it/s]predicting train subjects:  53%|█████▎    | 130/247 [00:16<00:13,  8.68it/s]predicting train subjects:  53%|█████▎    | 131/247 [00:16<00:13,  8.70it/s]predicting train subjects:  53%|█████▎    | 132/247 [00:17<00:13,  8.71it/s]predicting train subjects:  54%|█████▍    | 133/247 [00:17<00:13,  8.70it/s]predicting train subjects:  54%|█████▍    | 134/247 [00:17<00:12,  8.70it/s]predicting train subjects:  55%|█████▍    | 135/247 [00:17<00:12,  8.69it/s]predicting train subjects:  55%|█████▌    | 136/247 [00:17<00:12,  8.67it/s]predicting train subjects:  55%|█████▌    | 137/247 [00:17<00:12,  8.67it/s]predicting train subjects:  56%|█████▌    | 138/247 [00:17<00:12,  8.57it/s]predicting train subjects:  56%|█████▋    | 139/247 [00:17<00:12,  8.56it/s]predicting train subjects:  57%|█████▋    | 140/247 [00:17<00:12,  8.60it/s]predicting train subjects:  57%|█████▋    | 141/247 [00:18<00:12,  8.64it/s]predicting train subjects:  57%|█████▋    | 142/247 [00:18<00:12,  8.68it/s]predicting train subjects:  58%|█████▊    | 143/247 [00:18<00:11,  8.67it/s]predicting train subjects:  58%|█████▊    | 144/247 [00:18<00:11,  8.65it/s]predicting train subjects:  59%|█████▊    | 145/247 [00:18<00:11,  8.55it/s]predicting train subjects:  59%|█████▉    | 146/247 [00:18<00:11,  8.54it/s]predicting train subjects:  60%|█████▉    | 147/247 [00:18<00:11,  8.36it/s]predicting train subjects:  60%|█████▉    | 148/247 [00:18<00:11,  8.35it/s]predicting train subjects:  60%|██████    | 149/247 [00:19<00:11,  8.36it/s]predicting train subjects:  61%|██████    | 150/247 [00:19<00:11,  8.46it/s]predicting train subjects:  61%|██████    | 151/247 [00:19<00:11,  8.54it/s]predicting train subjects:  62%|██████▏   | 152/247 [00:19<00:11,  8.57it/s]predicting train subjects:  62%|██████▏   | 153/247 [00:19<00:11,  8.52it/s]predicting train subjects:  62%|██████▏   | 154/247 [00:19<00:11,  8.07it/s]predicting train subjects:  63%|██████▎   | 155/247 [00:19<00:11,  7.83it/s]predicting train subjects:  63%|██████▎   | 156/247 [00:19<00:11,  7.62it/s]predicting train subjects:  64%|██████▎   | 157/247 [00:20<00:11,  7.50it/s]predicting train subjects:  64%|██████▍   | 158/247 [00:20<00:11,  7.44it/s]predicting train subjects:  64%|██████▍   | 159/247 [00:20<00:11,  7.39it/s]predicting train subjects:  65%|██████▍   | 160/247 [00:20<00:11,  7.30it/s]predicting train subjects:  65%|██████▌   | 161/247 [00:20<00:11,  7.28it/s]predicting train subjects:  66%|██████▌   | 162/247 [00:20<00:11,  7.26it/s]predicting train subjects:  66%|██████▌   | 163/247 [00:20<00:11,  7.25it/s]predicting train subjects:  66%|██████▋   | 164/247 [00:21<00:11,  7.27it/s]predicting train subjects:  67%|██████▋   | 165/247 [00:21<00:11,  7.25it/s]predicting train subjects:  67%|██████▋   | 166/247 [00:21<00:11,  7.26it/s]predicting train subjects:  68%|██████▊   | 167/247 [00:21<00:11,  7.26it/s]predicting train subjects:  68%|██████▊   | 168/247 [00:21<00:10,  7.22it/s]predicting train subjects:  68%|██████▊   | 169/247 [00:21<00:10,  7.23it/s]predicting train subjects:  69%|██████▉   | 170/247 [00:21<00:10,  7.24it/s]predicting train subjects:  69%|██████▉   | 171/247 [00:21<00:10,  7.20it/s]predicting train subjects:  70%|██████▉   | 172/247 [00:22<00:09,  7.51it/s]predicting train subjects:  70%|███████   | 173/247 [00:22<00:11,  6.61it/s]predicting train subjects:  70%|███████   | 174/247 [00:22<00:10,  7.07it/s]predicting train subjects:  71%|███████   | 175/247 [00:22<00:10,  6.72it/s]predicting train subjects:  71%|███████▏  | 176/247 [00:22<00:09,  7.13it/s]predicting train subjects:  72%|███████▏  | 177/247 [00:22<00:09,  7.45it/s]predicting train subjects:  72%|███████▏  | 178/247 [00:22<00:08,  7.70it/s]predicting train subjects:  72%|███████▏  | 179/247 [00:23<00:08,  7.89it/s]predicting train subjects:  73%|███████▎  | 180/247 [00:23<00:08,  8.00it/s]predicting train subjects:  73%|███████▎  | 181/247 [00:23<00:08,  8.14it/s]predicting train subjects:  74%|███████▎  | 182/247 [00:23<00:07,  8.26it/s]predicting train subjects:  74%|███████▍  | 183/247 [00:23<00:07,  8.35it/s]predicting train subjects:  74%|███████▍  | 184/247 [00:23<00:07,  8.34it/s]predicting train subjects:  75%|███████▍  | 185/247 [00:23<00:07,  8.35it/s]predicting train subjects:  75%|███████▌  | 186/247 [00:23<00:07,  8.30it/s]predicting train subjects:  76%|███████▌  | 187/247 [00:24<00:07,  8.27it/s]predicting train subjects:  76%|███████▌  | 188/247 [00:24<00:07,  8.30it/s]predicting train subjects:  77%|███████▋  | 189/247 [00:24<00:06,  8.32it/s]predicting train subjects:  77%|███████▋  | 190/247 [00:24<00:06,  8.30it/s]predicting train subjects:  77%|███████▋  | 191/247 [00:24<00:06,  8.19it/s]predicting train subjects:  78%|███████▊  | 192/247 [00:24<00:06,  8.13it/s]predicting train subjects:  78%|███████▊  | 193/247 [00:24<00:06,  8.09it/s]predicting train subjects:  79%|███████▊  | 194/247 [00:24<00:06,  8.19it/s]predicting train subjects:  79%|███████▉  | 195/247 [00:24<00:06,  8.37it/s]predicting train subjects:  79%|███████▉  | 196/247 [00:25<00:05,  8.53it/s]predicting train subjects:  80%|███████▉  | 197/247 [00:25<00:05,  8.63it/s]predicting train subjects:  80%|████████  | 198/247 [00:25<00:05,  8.65it/s]predicting train subjects:  81%|████████  | 199/247 [00:25<00:05,  8.72it/s]predicting train subjects:  81%|████████  | 200/247 [00:25<00:05,  8.76it/s]predicting train subjects:  81%|████████▏ | 201/247 [00:25<00:05,  8.86it/s]predicting train subjects:  82%|████████▏ | 202/247 [00:25<00:05,  8.92it/s]predicting train subjects:  82%|████████▏ | 203/247 [00:25<00:04,  8.95it/s]predicting train subjects:  83%|████████▎ | 204/247 [00:25<00:04,  8.96it/s]predicting train subjects:  83%|████████▎ | 205/247 [00:26<00:04,  8.96it/s]predicting train subjects:  83%|████████▎ | 206/247 [00:26<00:04,  8.83it/s]predicting train subjects:  84%|████████▍ | 207/247 [00:26<00:04,  8.70it/s]predicting train subjects:  84%|████████▍ | 208/247 [00:26<00:04,  8.69it/s]predicting train subjects:  85%|████████▍ | 209/247 [00:26<00:04,  8.74it/s]predicting train subjects:  85%|████████▌ | 210/247 [00:26<00:04,  8.78it/s]predicting train subjects:  85%|████████▌ | 211/247 [00:26<00:04,  8.82it/s]predicting train subjects:  86%|████████▌ | 212/247 [00:26<00:04,  8.73it/s]predicting train subjects:  86%|████████▌ | 213/247 [00:27<00:03,  8.60it/s]predicting train subjects:  87%|████████▋ | 214/247 [00:27<00:03,  8.56it/s]predicting train subjects:  87%|████████▋ | 215/247 [00:27<00:03,  8.55it/s]predicting train subjects:  87%|████████▋ | 216/247 [00:27<00:03,  8.54it/s]predicting train subjects:  88%|████████▊ | 217/247 [00:27<00:03,  8.57it/s]predicting train subjects:  88%|████████▊ | 218/247 [00:27<00:03,  8.54it/s]predicting train subjects:  89%|████████▊ | 219/247 [00:27<00:03,  8.54it/s]predicting train subjects:  89%|████████▉ | 220/247 [00:27<00:03,  8.55it/s]predicting train subjects:  89%|████████▉ | 221/247 [00:27<00:03,  8.57it/s]predicting train subjects:  90%|████████▉ | 222/247 [00:28<00:02,  8.54it/s]predicting train subjects:  90%|█████████ | 223/247 [00:28<00:02,  8.56it/s]predicting train subjects:  91%|█████████ | 224/247 [00:28<00:02,  8.55it/s]predicting train subjects:  91%|█████████ | 225/247 [00:28<00:02,  8.57it/s]predicting train subjects:  91%|█████████▏| 226/247 [00:28<00:02,  8.52it/s]predicting train subjects:  92%|█████████▏| 227/247 [00:28<00:02,  8.55it/s]predicting train subjects:  92%|█████████▏| 228/247 [00:28<00:02,  8.55it/s]predicting train subjects:  93%|█████████▎| 229/247 [00:28<00:02,  8.56it/s]predicting train subjects:  93%|█████████▎| 230/247 [00:29<00:02,  8.10it/s]predicting train subjects:  94%|█████████▎| 231/247 [00:29<00:02,  7.91it/s]predicting train subjects:  94%|█████████▍| 232/247 [00:29<00:01,  7.79it/s]predicting train subjects:  94%|█████████▍| 233/247 [00:29<00:01,  7.69it/s]predicting train subjects:  95%|█████████▍| 234/247 [00:29<00:01,  7.46it/s]predicting train subjects:  95%|█████████▌| 235/247 [00:29<00:01,  7.38it/s]predicting train subjects:  96%|█████████▌| 236/247 [00:29<00:01,  7.40it/s]predicting train subjects:  96%|█████████▌| 237/247 [00:29<00:01,  7.39it/s]predicting train subjects:  96%|█████████▋| 238/247 [00:30<00:01,  7.40it/s]predicting train subjects:  97%|█████████▋| 239/247 [00:30<00:01,  7.40it/s]predicting train subjects:  97%|█████████▋| 240/247 [00:30<00:00,  7.36it/s]predicting train subjects:  98%|█████████▊| 241/247 [00:30<00:00,  7.28it/s]predicting train subjects:  98%|█████████▊| 242/247 [00:30<00:00,  7.32it/s]predicting train subjects:  98%|█████████▊| 243/247 [00:30<00:00,  7.32it/s]predicting train subjects:  99%|█████████▉| 244/247 [00:30<00:00,  7.33it/s]predicting train subjects:  99%|█████████▉| 245/247 [00:31<00:00,  7.33it/s]predicting train subjects: 100%|█████████▉| 246/247 [00:31<00:00,  7.34it/s]predicting train subjects: 100%|██████████| 247/247 [00:31<00:00,  7.33it/s]predicting train subjects: 100%|██████████| 247/247 [00:31<00:00,  7.88it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  8.28it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  7.80it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  7.72it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  8.07it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  8.16it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:00<00:00,  7.94it/s]
predicting train subjects sagittal:   0%|          | 0/247 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/247 [00:00<00:30,  8.14it/s]predicting train subjects sagittal:   1%|          | 2/247 [00:00<00:29,  8.26it/s]predicting train subjects sagittal:   1%|          | 3/247 [00:00<00:28,  8.45it/s]predicting train subjects sagittal:   2%|▏         | 4/247 [00:00<00:29,  8.34it/s]predicting train subjects sagittal:   2%|▏         | 5/247 [00:00<00:29,  8.34it/s]predicting train subjects sagittal:   2%|▏         | 6/247 [00:00<00:28,  8.32it/s]predicting train subjects sagittal:   3%|▎         | 7/247 [00:00<00:28,  8.28it/s]predicting train subjects sagittal:   3%|▎         | 8/247 [00:00<00:28,  8.26it/s]predicting train subjects sagittal:   4%|▎         | 9/247 [00:01<00:28,  8.28it/s]predicting train subjects sagittal:   4%|▍         | 10/247 [00:01<00:28,  8.18it/s]predicting train subjects sagittal:   4%|▍         | 11/247 [00:01<00:28,  8.22it/s]predicting train subjects sagittal:   5%|▍         | 12/247 [00:01<00:28,  8.25it/s]predicting train subjects sagittal:   5%|▌         | 13/247 [00:01<00:28,  8.27it/s]predicting train subjects sagittal:   6%|▌         | 14/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   6%|▌         | 15/247 [00:01<00:28,  8.28it/s]predicting train subjects sagittal:   6%|▋         | 16/247 [00:01<00:28,  8.23it/s]predicting train subjects sagittal:   7%|▋         | 17/247 [00:02<00:27,  8.27it/s]predicting train subjects sagittal:   7%|▋         | 18/247 [00:02<00:27,  8.28it/s]predicting train subjects sagittal:   8%|▊         | 19/247 [00:02<00:27,  8.29it/s]predicting train subjects sagittal:   8%|▊         | 20/247 [00:02<00:27,  8.30it/s]predicting train subjects sagittal:   9%|▊         | 21/247 [00:02<00:27,  8.27it/s]predicting train subjects sagittal:   9%|▉         | 22/247 [00:02<00:27,  8.23it/s]predicting train subjects sagittal:   9%|▉         | 23/247 [00:02<00:26,  8.37it/s]predicting train subjects sagittal:  10%|▉         | 24/247 [00:02<00:26,  8.49it/s]predicting train subjects sagittal:  10%|█         | 25/247 [00:03<00:26,  8.31it/s]predicting train subjects sagittal:  11%|█         | 26/247 [00:03<00:26,  8.42it/s]predicting train subjects sagittal:  11%|█         | 27/247 [00:03<00:25,  8.46it/s]predicting train subjects sagittal:  11%|█▏        | 28/247 [00:03<00:26,  8.37it/s]predicting train subjects sagittal:  12%|█▏        | 29/247 [00:03<00:25,  8.50it/s]predicting train subjects sagittal:  12%|█▏        | 30/247 [00:03<00:25,  8.59it/s]predicting train subjects sagittal:  13%|█▎        | 31/247 [00:03<00:24,  8.65it/s]predicting train subjects sagittal:  13%|█▎        | 32/247 [00:03<00:24,  8.66it/s]predicting train subjects sagittal:  13%|█▎        | 33/247 [00:03<00:24,  8.67it/s]predicting train subjects sagittal:  14%|█▍        | 34/247 [00:04<00:24,  8.70it/s]predicting train subjects sagittal:  14%|█▍        | 35/247 [00:04<00:24,  8.70it/s]predicting train subjects sagittal:  15%|█▍        | 36/247 [00:04<00:24,  8.61it/s]predicting train subjects sagittal:  15%|█▍        | 37/247 [00:04<00:24,  8.56it/s]predicting train subjects sagittal:  15%|█▌        | 38/247 [00:04<00:24,  8.54it/s]predicting train subjects sagittal:  16%|█▌        | 39/247 [00:04<00:24,  8.57it/s]predicting train subjects sagittal:  16%|█▌        | 40/247 [00:04<00:24,  8.60it/s]predicting train subjects sagittal:  17%|█▋        | 41/247 [00:04<00:23,  8.63it/s]predicting train subjects sagittal:  17%|█▋        | 42/247 [00:04<00:23,  8.66it/s]predicting train subjects sagittal:  17%|█▋        | 43/247 [00:05<00:23,  8.62it/s]predicting train subjects sagittal:  18%|█▊        | 44/247 [00:05<00:23,  8.61it/s]predicting train subjects sagittal:  18%|█▊        | 45/247 [00:05<00:23,  8.61it/s]predicting train subjects sagittal:  19%|█▊        | 46/247 [00:05<00:23,  8.63it/s]predicting train subjects sagittal:  19%|█▉        | 47/247 [00:05<00:23,  8.66it/s]predicting train subjects sagittal:  19%|█▉        | 48/247 [00:05<00:22,  8.66it/s]predicting train subjects sagittal:  20%|█▉        | 49/247 [00:05<00:22,  8.62it/s]predicting train subjects sagittal:  20%|██        | 50/247 [00:05<00:23,  8.54it/s]predicting train subjects sagittal:  21%|██        | 51/247 [00:06<00:22,  8.64it/s]predicting train subjects sagittal:  21%|██        | 52/247 [00:06<00:22,  8.60it/s]predicting train subjects sagittal:  21%|██▏       | 53/247 [00:06<00:23,  8.32it/s]predicting train subjects sagittal:  22%|██▏       | 54/247 [00:06<00:22,  8.43it/s]predicting train subjects sagittal:  22%|██▏       | 55/247 [00:06<00:22,  8.44it/s]predicting train subjects sagittal:  23%|██▎       | 56/247 [00:06<00:22,  8.34it/s]predicting train subjects sagittal:  23%|██▎       | 57/247 [00:06<00:22,  8.50it/s]predicting train subjects sagittal:  23%|██▎       | 58/247 [00:06<00:22,  8.46it/s]predicting train subjects sagittal:  24%|██▍       | 59/247 [00:07<00:23,  7.91it/s]predicting train subjects sagittal:  24%|██▍       | 60/247 [00:07<00:23,  7.88it/s]predicting train subjects sagittal:  25%|██▍       | 61/247 [00:07<00:24,  7.72it/s]predicting train subjects sagittal:  25%|██▌       | 62/247 [00:07<00:23,  7.75it/s]predicting train subjects sagittal:  26%|██▌       | 63/247 [00:07<00:23,  7.78it/s]predicting train subjects sagittal:  26%|██▌       | 64/247 [00:07<00:23,  7.89it/s]predicting train subjects sagittal:  26%|██▋       | 65/247 [00:07<00:22,  7.94it/s]predicting train subjects sagittal:  27%|██▋       | 66/247 [00:07<00:22,  7.95it/s]predicting train subjects sagittal:  27%|██▋       | 67/247 [00:08<00:22,  8.03it/s]predicting train subjects sagittal:  28%|██▊       | 68/247 [00:08<00:22,  8.06it/s]predicting train subjects sagittal:  28%|██▊       | 69/247 [00:08<00:22,  8.06it/s]predicting train subjects sagittal:  28%|██▊       | 70/247 [00:08<00:21,  8.06it/s]predicting train subjects sagittal:  29%|██▊       | 71/247 [00:08<00:21,  8.07it/s]predicting train subjects sagittal:  29%|██▉       | 72/247 [00:08<00:21,  8.08it/s]predicting train subjects sagittal:  30%|██▉       | 73/247 [00:08<00:21,  8.10it/s]predicting train subjects sagittal:  30%|██▉       | 74/247 [00:08<00:21,  8.09it/s]predicting train subjects sagittal:  30%|███       | 75/247 [00:09<00:21,  8.08it/s]predicting train subjects sagittal:  31%|███       | 76/247 [00:09<00:21,  8.12it/s]predicting train subjects sagittal:  31%|███       | 77/247 [00:09<00:22,  7.48it/s]predicting train subjects sagittal:  32%|███▏      | 78/247 [00:09<00:23,  7.07it/s]predicting train subjects sagittal:  32%|███▏      | 79/247 [00:09<00:22,  7.49it/s]predicting train subjects sagittal:  32%|███▏      | 80/247 [00:09<00:21,  7.83it/s]predicting train subjects sagittal:  33%|███▎      | 81/247 [00:09<00:21,  7.66it/s]predicting train subjects sagittal:  33%|███▎      | 82/247 [00:09<00:23,  7.17it/s]predicting train subjects sagittal:  34%|███▎      | 83/247 [00:10<00:22,  7.14it/s]predicting train subjects sagittal:  34%|███▍      | 84/247 [00:10<00:23,  7.07it/s]predicting train subjects sagittal:  34%|███▍      | 85/247 [00:10<00:23,  7.01it/s]predicting train subjects sagittal:  35%|███▍      | 86/247 [00:10<00:22,  7.04it/s]predicting train subjects sagittal:  35%|███▌      | 87/247 [00:10<00:22,  7.03it/s]predicting train subjects sagittal:  36%|███▌      | 88/247 [00:10<00:22,  6.93it/s]predicting train subjects sagittal:  36%|███▌      | 89/247 [00:10<00:22,  6.89it/s]predicting train subjects sagittal:  36%|███▋      | 90/247 [00:11<00:22,  6.87it/s]predicting train subjects sagittal:  37%|███▋      | 91/247 [00:11<00:22,  6.81it/s]predicting train subjects sagittal:  37%|███▋      | 92/247 [00:11<00:22,  6.77it/s]predicting train subjects sagittal:  38%|███▊      | 93/247 [00:11<00:22,  6.82it/s]predicting train subjects sagittal:  38%|███▊      | 94/247 [00:11<00:22,  6.88it/s]predicting train subjects sagittal:  38%|███▊      | 95/247 [00:11<00:22,  6.88it/s]predicting train subjects sagittal:  39%|███▉      | 96/247 [00:12<00:22,  6.82it/s]predicting train subjects sagittal:  39%|███▉      | 97/247 [00:12<00:21,  6.87it/s]predicting train subjects sagittal:  40%|███▉      | 98/247 [00:12<00:21,  6.91it/s]predicting train subjects sagittal:  40%|████      | 99/247 [00:12<00:21,  6.86it/s]predicting train subjects sagittal:  40%|████      | 100/247 [00:12<00:21,  6.96it/s]predicting train subjects sagittal:  41%|████      | 101/247 [00:12<00:20,  7.02it/s]predicting train subjects sagittal:  41%|████▏     | 102/247 [00:12<00:20,  7.05it/s]predicting train subjects sagittal:  42%|████▏     | 103/247 [00:13<00:20,  7.11it/s]predicting train subjects sagittal:  42%|████▏     | 104/247 [00:13<00:20,  7.14it/s]predicting train subjects sagittal:  43%|████▎     | 105/247 [00:13<00:19,  7.12it/s]predicting train subjects sagittal:  43%|████▎     | 106/247 [00:13<00:19,  7.15it/s]predicting train subjects sagittal:  43%|████▎     | 107/247 [00:13<00:19,  7.15it/s]predicting train subjects sagittal:  44%|████▎     | 108/247 [00:13<00:19,  7.07it/s]predicting train subjects sagittal:  44%|████▍     | 109/247 [00:13<00:19,  7.11it/s]predicting train subjects sagittal:  45%|████▍     | 110/247 [00:13<00:19,  7.10it/s]predicting train subjects sagittal:  45%|████▍     | 111/247 [00:14<00:19,  7.07it/s]predicting train subjects sagittal:  45%|████▌     | 112/247 [00:14<00:19,  7.09it/s]predicting train subjects sagittal:  46%|████▌     | 113/247 [00:14<00:18,  7.13it/s]predicting train subjects sagittal:  46%|████▌     | 114/247 [00:14<00:18,  7.14it/s]predicting train subjects sagittal:  47%|████▋     | 115/247 [00:14<00:18,  7.17it/s]predicting train subjects sagittal:  47%|████▋     | 116/247 [00:14<00:18,  7.19it/s]predicting train subjects sagittal:  47%|████▋     | 117/247 [00:14<00:18,  7.20it/s]predicting train subjects sagittal:  48%|████▊     | 118/247 [00:15<00:17,  7.58it/s]predicting train subjects sagittal:  48%|████▊     | 119/247 [00:15<00:16,  7.87it/s]predicting train subjects sagittal:  49%|████▊     | 120/247 [00:15<00:15,  8.12it/s]predicting train subjects sagittal:  49%|████▉     | 121/247 [00:15<00:15,  8.30it/s]predicting train subjects sagittal:  49%|████▉     | 122/247 [00:15<00:14,  8.44it/s]predicting train subjects sagittal:  50%|████▉     | 123/247 [00:15<00:14,  8.48it/s]predicting train subjects sagittal:  50%|█████     | 124/247 [00:15<00:14,  8.49it/s]predicting train subjects sagittal:  51%|█████     | 125/247 [00:15<00:14,  8.58it/s]predicting train subjects sagittal:  51%|█████     | 126/247 [00:15<00:14,  8.61it/s]predicting train subjects sagittal:  51%|█████▏    | 127/247 [00:16<00:13,  8.60it/s]predicting train subjects sagittal:  52%|█████▏    | 128/247 [00:16<00:13,  8.63it/s]predicting train subjects sagittal:  52%|█████▏    | 129/247 [00:16<00:13,  8.66it/s]predicting train subjects sagittal:  53%|█████▎    | 130/247 [00:16<00:13,  8.68it/s]predicting train subjects sagittal:  53%|█████▎    | 131/247 [00:16<00:13,  8.69it/s]predicting train subjects sagittal:  53%|█████▎    | 132/247 [00:16<00:13,  8.69it/s]predicting train subjects sagittal:  54%|█████▍    | 133/247 [00:16<00:13,  8.66it/s]predicting train subjects sagittal:  54%|█████▍    | 134/247 [00:16<00:13,  8.67it/s]predicting train subjects sagittal:  55%|█████▍    | 135/247 [00:17<00:12,  8.69it/s]predicting train subjects sagittal:  55%|█████▌    | 136/247 [00:17<00:12,  8.66it/s]predicting train subjects sagittal:  55%|█████▌    | 137/247 [00:17<00:12,  8.59it/s]predicting train subjects sagittal:  56%|█████▌    | 138/247 [00:17<00:12,  8.62it/s]predicting train subjects sagittal:  56%|█████▋    | 139/247 [00:17<00:12,  8.63it/s]predicting train subjects sagittal:  57%|█████▋    | 140/247 [00:17<00:12,  8.51it/s]predicting train subjects sagittal:  57%|█████▋    | 141/247 [00:17<00:12,  8.59it/s]predicting train subjects sagittal:  57%|█████▋    | 142/247 [00:17<00:12,  8.30it/s]predicting train subjects sagittal:  58%|█████▊    | 143/247 [00:17<00:12,  8.22it/s]predicting train subjects sagittal:  58%|█████▊    | 144/247 [00:18<00:12,  8.25it/s]predicting train subjects sagittal:  59%|█████▊    | 145/247 [00:18<00:12,  8.35it/s]predicting train subjects sagittal:  59%|█████▉    | 146/247 [00:18<00:12,  8.40it/s]predicting train subjects sagittal:  60%|█████▉    | 147/247 [00:18<00:11,  8.41it/s]predicting train subjects sagittal:  60%|█████▉    | 148/247 [00:18<00:11,  8.49it/s]predicting train subjects sagittal:  60%|██████    | 149/247 [00:18<00:11,  8.57it/s]predicting train subjects sagittal:  61%|██████    | 150/247 [00:18<00:11,  8.61it/s]predicting train subjects sagittal:  61%|██████    | 151/247 [00:18<00:11,  8.63it/s]predicting train subjects sagittal:  62%|██████▏   | 152/247 [00:19<00:10,  8.69it/s]predicting train subjects sagittal:  62%|██████▏   | 153/247 [00:19<00:10,  8.71it/s]predicting train subjects sagittal:  62%|██████▏   | 154/247 [00:19<00:11,  8.14it/s]predicting train subjects sagittal:  63%|██████▎   | 155/247 [00:19<00:11,  7.86it/s]predicting train subjects sagittal:  63%|██████▎   | 156/247 [00:19<00:11,  7.64it/s]predicting train subjects sagittal:  64%|██████▎   | 157/247 [00:19<00:12,  7.14it/s]predicting train subjects sagittal:  64%|██████▍   | 158/247 [00:19<00:12,  6.98it/s]predicting train subjects sagittal:  64%|██████▍   | 159/247 [00:20<00:12,  6.97it/s]predicting train subjects sagittal:  65%|██████▍   | 160/247 [00:20<00:12,  6.84it/s]predicting train subjects sagittal:  65%|██████▌   | 161/247 [00:20<00:12,  6.85it/s]predicting train subjects sagittal:  66%|██████▌   | 162/247 [00:20<00:12,  6.88it/s]predicting train subjects sagittal:  66%|██████▌   | 163/247 [00:20<00:12,  6.99it/s]predicting train subjects sagittal:  66%|██████▋   | 164/247 [00:20<00:11,  7.05it/s]predicting train subjects sagittal:  67%|██████▋   | 165/247 [00:20<00:11,  7.11it/s]predicting train subjects sagittal:  67%|██████▋   | 166/247 [00:21<00:11,  7.16it/s]predicting train subjects sagittal:  68%|██████▊   | 167/247 [00:21<00:11,  7.21it/s]predicting train subjects sagittal:  68%|██████▊   | 168/247 [00:21<00:10,  7.25it/s]predicting train subjects sagittal:  68%|██████▊   | 169/247 [00:21<00:10,  7.22it/s]predicting train subjects sagittal:  69%|██████▉   | 170/247 [00:21<00:10,  7.23it/s]predicting train subjects sagittal:  69%|██████▉   | 171/247 [00:21<00:10,  7.24it/s]predicting train subjects sagittal:  70%|██████▉   | 172/247 [00:21<00:09,  7.58it/s]predicting train subjects sagittal:  70%|███████   | 173/247 [00:21<00:09,  7.96it/s]predicting train subjects sagittal:  70%|███████   | 174/247 [00:22<00:08,  8.12it/s]predicting train subjects sagittal:  71%|███████   | 175/247 [00:22<00:09,  7.87it/s]predicting train subjects sagittal:  71%|███████▏  | 176/247 [00:22<00:08,  7.99it/s]predicting train subjects sagittal:  72%|███████▏  | 177/247 [00:22<00:08,  8.07it/s]predicting train subjects sagittal:  72%|███████▏  | 178/247 [00:22<00:08,  7.68it/s]predicting train subjects sagittal:  72%|███████▏  | 179/247 [00:22<00:08,  7.91it/s]predicting train subjects sagittal:  73%|███████▎  | 180/247 [00:22<00:08,  8.03it/s]predicting train subjects sagittal:  73%|███████▎  | 181/247 [00:22<00:08,  8.16it/s]predicting train subjects sagittal:  74%|███████▎  | 182/247 [00:23<00:08,  8.04it/s]predicting train subjects sagittal:  74%|███████▍  | 183/247 [00:23<00:07,  8.15it/s]predicting train subjects sagittal:  74%|███████▍  | 184/247 [00:23<00:07,  8.09it/s]predicting train subjects sagittal:  75%|███████▍  | 185/247 [00:23<00:07,  8.18it/s]predicting train subjects sagittal:  75%|███████▌  | 186/247 [00:23<00:07,  8.03it/s]predicting train subjects sagittal:  76%|███████▌  | 187/247 [00:23<00:07,  8.06it/s]predicting train subjects sagittal:  76%|███████▌  | 188/247 [00:23<00:07,  7.95it/s]predicting train subjects sagittal:  77%|███████▋  | 189/247 [00:23<00:07,  8.10it/s]predicting train subjects sagittal:  77%|███████▋  | 190/247 [00:24<00:07,  7.99it/s]predicting train subjects sagittal:  77%|███████▋  | 191/247 [00:24<00:06,  8.07it/s]predicting train subjects sagittal:  78%|███████▊  | 192/247 [00:24<00:06,  8.17it/s]predicting train subjects sagittal:  78%|███████▊  | 193/247 [00:24<00:06,  8.04it/s]predicting train subjects sagittal:  79%|███████▊  | 194/247 [00:24<00:06,  8.27it/s]predicting train subjects sagittal:  79%|███████▉  | 195/247 [00:24<00:06,  8.42it/s]predicting train subjects sagittal:  79%|███████▉  | 196/247 [00:24<00:06,  8.46it/s]predicting train subjects sagittal:  80%|███████▉  | 197/247 [00:24<00:05,  8.38it/s]predicting train subjects sagittal:  80%|████████  | 198/247 [00:25<00:05,  8.23it/s]predicting train subjects sagittal:  81%|████████  | 199/247 [00:25<00:05,  8.37it/s]predicting train subjects sagittal:  81%|████████  | 200/247 [00:25<00:05,  8.52it/s]predicting train subjects sagittal:  81%|████████▏ | 201/247 [00:25<00:05,  8.68it/s]predicting train subjects sagittal:  82%|████████▏ | 202/247 [00:25<00:05,  8.81it/s]predicting train subjects sagittal:  82%|████████▏ | 203/247 [00:25<00:05,  8.78it/s]predicting train subjects sagittal:  83%|████████▎ | 204/247 [00:25<00:04,  8.73it/s]predicting train subjects sagittal:  83%|████████▎ | 205/247 [00:25<00:04,  8.75it/s]predicting train subjects sagittal:  83%|████████▎ | 206/247 [00:25<00:04,  8.74it/s]predicting train subjects sagittal:  84%|████████▍ | 207/247 [00:26<00:04,  8.63it/s]predicting train subjects sagittal:  84%|████████▍ | 208/247 [00:26<00:04,  8.32it/s]predicting train subjects sagittal:  85%|████████▍ | 209/247 [00:26<00:04,  8.40it/s]predicting train subjects sagittal:  85%|████████▌ | 210/247 [00:26<00:04,  8.43it/s]predicting train subjects sagittal:  85%|████████▌ | 211/247 [00:26<00:04,  8.22it/s]predicting train subjects sagittal:  86%|████████▌ | 212/247 [00:26<00:04,  8.22it/s]predicting train subjects sagittal:  86%|████████▌ | 213/247 [00:26<00:04,  8.23it/s]predicting train subjects sagittal:  87%|████████▋ | 214/247 [00:26<00:04,  8.24it/s]predicting train subjects sagittal:  87%|████████▋ | 215/247 [00:27<00:03,  8.32it/s]predicting train subjects sagittal:  87%|████████▋ | 216/247 [00:27<00:03,  8.31it/s]predicting train subjects sagittal:  88%|████████▊ | 217/247 [00:27<00:03,  8.36it/s]predicting train subjects sagittal:  88%|████████▊ | 218/247 [00:27<00:03,  8.42it/s]predicting train subjects sagittal:  89%|████████▊ | 219/247 [00:27<00:03,  8.48it/s]predicting train subjects sagittal:  89%|████████▉ | 220/247 [00:27<00:03,  8.53it/s]predicting train subjects sagittal:  89%|████████▉ | 221/247 [00:27<00:03,  8.55it/s]predicting train subjects sagittal:  90%|████████▉ | 222/247 [00:27<00:02,  8.55it/s]predicting train subjects sagittal:  90%|█████████ | 223/247 [00:27<00:02,  8.42it/s]predicting train subjects sagittal:  91%|█████████ | 224/247 [00:28<00:02,  8.47it/s]predicting train subjects sagittal:  91%|█████████ | 225/247 [00:28<00:02,  8.48it/s]predicting train subjects sagittal:  91%|█████████▏| 226/247 [00:28<00:02,  8.54it/s]predicting train subjects sagittal:  92%|█████████▏| 227/247 [00:28<00:02,  8.54it/s]predicting train subjects sagittal:  92%|█████████▏| 228/247 [00:28<00:02,  8.55it/s]predicting train subjects sagittal:  93%|█████████▎| 229/247 [00:28<00:02,  8.60it/s]predicting train subjects sagittal:  93%|█████████▎| 230/247 [00:28<00:02,  8.17it/s]predicting train subjects sagittal:  94%|█████████▎| 231/247 [00:28<00:02,  7.98it/s]predicting train subjects sagittal:  94%|█████████▍| 232/247 [00:29<00:01,  7.72it/s]predicting train subjects sagittal:  94%|█████████▍| 233/247 [00:29<00:01,  7.53it/s]predicting train subjects sagittal:  95%|█████████▍| 234/247 [00:29<00:01,  7.48it/s]predicting train subjects sagittal:  95%|█████████▌| 235/247 [00:29<00:01,  7.42it/s]predicting train subjects sagittal:  96%|█████████▌| 236/247 [00:29<00:01,  7.30it/s]predicting train subjects sagittal:  96%|█████████▌| 237/247 [00:29<00:01,  7.13it/s]predicting train subjects sagittal:  96%|█████████▋| 238/247 [00:29<00:01,  7.04it/s]predicting train subjects sagittal:  97%|█████████▋| 239/247 [00:30<00:01,  7.12it/s]predicting train subjects sagittal:  97%|█████████▋| 240/247 [00:30<00:00,  7.16it/s]predicting train subjects sagittal:  98%|█████████▊| 241/247 [00:30<00:00,  7.22it/s]predicting train subjects sagittal:  98%|█████████▊| 242/247 [00:30<00:00,  7.04it/s]predicting train subjects sagittal:  98%|█████████▊| 243/247 [00:30<00:00,  7.08it/s]predicting train subjects sagittal:  99%|█████████▉| 244/247 [00:30<00:00,  6.95it/s]predicting train subjects sagittal:  99%|█████████▉| 245/247 [00:30<00:00,  7.08it/s]predicting train subjects sagittal: 100%|█████████▉| 246/247 [00:31<00:00,  6.94it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:31<00:00,  7.08it/s]predicting train subjects sagittal: 100%|██████████| 247/247 [00:31<00:00,  7.92it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 75.63it/s]
saving BB  train1-THALAMUS:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/247 [00:00<00:03, 76.68it/s]saving BB  train1-THALAMUS:   6%|▋         | 16/247 [00:00<00:03, 76.93it/s]saving BB  train1-THALAMUS:  10%|█         | 25/247 [00:00<00:02, 78.35it/s]saving BB  train1-THALAMUS:  14%|█▍        | 34/247 [00:00<00:02, 80.92it/s]saving BB  train1-THALAMUS:  17%|█▋        | 43/247 [00:00<00:02, 82.40it/s]saving BB  train1-THALAMUS:  21%|██        | 52/247 [00:00<00:02, 84.00it/s]saving BB  train1-THALAMUS:  25%|██▍       | 61/247 [00:00<00:02, 84.35it/s]saving BB  train1-THALAMUS:  28%|██▊       | 69/247 [00:00<00:02, 82.54it/s]saving BB  train1-THALAMUS:  31%|███       | 77/247 [00:00<00:02, 79.40it/s]saving BB  train1-THALAMUS:  34%|███▍      | 85/247 [00:01<00:02, 76.16it/s]saving BB  train1-THALAMUS:  38%|███▊      | 93/247 [00:01<00:02, 71.91it/s]saving BB  train1-THALAMUS:  41%|████      | 101/247 [00:01<00:02, 70.33it/s]saving BB  train1-THALAMUS:  44%|████▍     | 109/247 [00:01<00:01, 70.89it/s]saving BB  train1-THALAMUS:  47%|████▋     | 117/247 [00:01<00:01, 70.58it/s]saving BB  train1-THALAMUS:  51%|█████     | 125/247 [00:01<00:01, 72.10it/s]saving BB  train1-THALAMUS:  54%|█████▍    | 133/247 [00:01<00:01, 71.06it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 142/247 [00:01<00:01, 73.56it/s]saving BB  train1-THALAMUS:  61%|██████    | 150/247 [00:01<00:01, 75.32it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 158/247 [00:02<00:01, 72.31it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 166/247 [00:02<00:01, 72.69it/s]saving BB  train1-THALAMUS:  70%|███████   | 174/247 [00:02<00:00, 73.19it/s]saving BB  train1-THALAMUS:  74%|███████▎  | 182/247 [00:02<00:00, 74.40it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 190/247 [00:02<00:00, 75.71it/s]saving BB  train1-THALAMUS:  81%|████████  | 199/247 [00:02<00:00, 78.00it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 208/247 [00:02<00:00, 80.57it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 217/247 [00:02<00:00, 82.96it/s]saving BB  train1-THALAMUS:  91%|█████████▏| 226/247 [00:02<00:00, 84.71it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 235/247 [00:03<00:00, 80.52it/s]saving BB  train1-THALAMUS:  99%|█████████▉| 244/247 [00:03<00:00, 79.18it/s]saving BB  train1-THALAMUS: 100%|██████████| 247/247 [00:03<00:00, 77.15it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 78.79it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/247 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   4%|▎         | 9/247 [00:00<00:02, 81.45it/s]saving BB  train1-THALAMUS Sagittal:   7%|▋         | 18/247 [00:00<00:02, 81.67it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 27/247 [00:00<00:02, 81.48it/s]saving BB  train1-THALAMUS Sagittal:  15%|█▍        | 36/247 [00:00<00:02, 82.53it/s]saving BB  train1-THALAMUS Sagittal:  18%|█▊        | 45/247 [00:00<00:02, 84.29it/s]saving BB  train1-THALAMUS Sagittal:  22%|██▏       | 54/247 [00:00<00:02, 85.70it/s]saving BB  train1-THALAMUS Sagittal:  25%|██▌       | 62/247 [00:00<00:02, 83.81it/s]saving BB  train1-THALAMUS Sagittal:  28%|██▊       | 70/247 [00:00<00:02, 81.66it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 78/247 [00:00<00:02, 79.27it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 86/247 [00:01<00:02, 75.87it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 94/247 [00:01<00:02, 71.43it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 102/247 [00:01<00:02, 70.07it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 110/247 [00:01<00:01, 71.30it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 118/247 [00:01<00:01, 72.05it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 126/247 [00:01<00:01, 73.74it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▍    | 135/247 [00:01<00:01, 75.34it/s]saving BB  train1-THALAMUS Sagittal:  58%|█████▊    | 144/247 [00:01<00:01, 78.61it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 153/247 [00:01<00:01, 81.15it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 162/247 [00:02<00:01, 78.53it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 170/247 [00:02<00:00, 77.55it/s]saving BB  train1-THALAMUS Sagittal:  72%|███████▏  | 178/247 [00:02<00:00, 77.54it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▌  | 186/247 [00:02<00:00, 76.97it/s]saving BB  train1-THALAMUS Sagittal:  79%|███████▉  | 195/247 [00:02<00:00, 78.19it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 204/247 [00:02<00:00, 80.09it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 213/247 [00:02<00:00, 80.78it/s]saving BB  train1-THALAMUS Sagittal:  90%|████████▉ | 222/247 [00:02<00:00, 79.52it/s]saving BB  train1-THALAMUS Sagittal:  94%|█████████▎| 231/247 [00:02<00:00, 80.96it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 240/247 [00:03<00:00, 79.04it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 247/247 [00:03<00:00, 78.39it/s]
Loading train:   0%|          | 0/247 [00:00<?, ?it/s]Loading train:   0%|          | 1/247 [00:00<03:54,  1.05it/s]Loading train:   1%|          | 2/247 [00:01<03:39,  1.12it/s]Loading train:   1%|          | 3/247 [00:02<03:27,  1.18it/s]Loading train:   2%|▏         | 4/247 [00:03<03:26,  1.18it/s]Loading train:   2%|▏         | 5/247 [00:03<03:07,  1.29it/s]Loading train:   2%|▏         | 6/247 [00:04<02:50,  1.42it/s]Loading train:   3%|▎         | 7/247 [00:05<02:40,  1.50it/s]Loading train:   3%|▎         | 8/247 [00:05<02:31,  1.58it/s]Loading train:   4%|▎         | 9/247 [00:06<02:24,  1.64it/s]Loading train:   4%|▍         | 10/247 [00:06<02:16,  1.74it/s]Loading train:   4%|▍         | 11/247 [00:07<02:12,  1.78it/s]Loading train:   5%|▍         | 12/247 [00:07<02:10,  1.81it/s]Loading train:   5%|▌         | 13/247 [00:08<02:08,  1.82it/s]Loading train:   6%|▌         | 14/247 [00:08<02:07,  1.83it/s]Loading train:   6%|▌         | 15/247 [00:09<02:06,  1.84it/s]Loading train:   6%|▋         | 16/247 [00:09<02:04,  1.85it/s]Loading train:   7%|▋         | 17/247 [00:10<02:03,  1.87it/s]Loading train:   7%|▋         | 18/247 [00:10<02:02,  1.87it/s]Loading train:   8%|▊         | 19/247 [00:11<02:03,  1.85it/s]Loading train:   8%|▊         | 20/247 [00:12<02:02,  1.85it/s]Loading train:   9%|▊         | 21/247 [00:12<02:04,  1.81it/s]Loading train:   9%|▉         | 22/247 [00:13<02:05,  1.79it/s]Loading train:   9%|▉         | 23/247 [00:13<02:04,  1.80it/s]Loading train:  10%|▉         | 24/247 [00:14<02:02,  1.81it/s]Loading train:  10%|█         | 25/247 [00:14<02:01,  1.83it/s]Loading train:  11%|█         | 26/247 [00:15<01:58,  1.86it/s]Loading train:  11%|█         | 27/247 [00:15<01:57,  1.88it/s]Loading train:  11%|█▏        | 28/247 [00:16<01:53,  1.94it/s]Loading train:  12%|█▏        | 29/247 [00:16<01:52,  1.95it/s]Loading train:  12%|█▏        | 30/247 [00:17<01:49,  1.98it/s]Loading train:  13%|█▎        | 31/247 [00:17<01:48,  2.00it/s]Loading train:  13%|█▎        | 32/247 [00:18<01:47,  1.99it/s]Loading train:  13%|█▎        | 33/247 [00:18<01:47,  1.99it/s]Loading train:  14%|█▍        | 34/247 [00:19<01:47,  1.99it/s]Loading train:  14%|█▍        | 35/247 [00:19<01:46,  1.98it/s]Loading train:  15%|█▍        | 36/247 [00:20<01:47,  1.97it/s]Loading train:  15%|█▍        | 37/247 [00:20<01:50,  1.91it/s]Loading train:  15%|█▌        | 38/247 [00:21<01:50,  1.88it/s]Loading train:  16%|█▌        | 39/247 [00:21<01:48,  1.91it/s]Loading train:  16%|█▌        | 40/247 [00:22<01:47,  1.93it/s]Loading train:  17%|█▋        | 41/247 [00:22<01:45,  1.96it/s]Loading train:  17%|█▋        | 42/247 [00:23<01:41,  2.02it/s]Loading train:  17%|█▋        | 43/247 [00:23<01:37,  2.10it/s]Loading train:  18%|█▊        | 44/247 [00:24<01:35,  2.12it/s]Loading train:  18%|█▊        | 45/247 [00:24<01:34,  2.14it/s]Loading train:  19%|█▊        | 46/247 [00:25<01:33,  2.15it/s]Loading train:  19%|█▉        | 47/247 [00:25<01:33,  2.14it/s]Loading train:  19%|█▉        | 48/247 [00:26<01:35,  2.09it/s]Loading train:  20%|█▉        | 49/247 [00:26<01:34,  2.09it/s]Loading train:  20%|██        | 50/247 [00:27<01:34,  2.09it/s]Loading train:  21%|██        | 51/247 [00:27<01:34,  2.08it/s]Loading train:  21%|██        | 52/247 [00:28<01:33,  2.09it/s]Loading train:  21%|██▏       | 53/247 [00:28<01:31,  2.13it/s]Loading train:  22%|██▏       | 54/247 [00:28<01:30,  2.14it/s]Loading train:  22%|██▏       | 55/247 [00:29<01:30,  2.12it/s]Loading train:  23%|██▎       | 56/247 [00:29<01:30,  2.11it/s]Loading train:  23%|██▎       | 57/247 [00:30<01:29,  2.12it/s]Loading train:  23%|██▎       | 58/247 [00:30<01:29,  2.11it/s]Loading train:  24%|██▍       | 59/247 [00:31<01:35,  1.98it/s]Loading train:  24%|██▍       | 60/247 [00:32<01:35,  1.95it/s]Loading train:  25%|██▍       | 61/247 [00:32<01:36,  1.93it/s]Loading train:  25%|██▌       | 62/247 [00:33<01:37,  1.89it/s]Loading train:  26%|██▌       | 63/247 [00:33<01:39,  1.84it/s]Loading train:  26%|██▌       | 64/247 [00:34<01:40,  1.83it/s]Loading train:  26%|██▋       | 65/247 [00:34<01:39,  1.84it/s]Loading train:  27%|██▋       | 66/247 [00:35<01:39,  1.82it/s]Loading train:  27%|██▋       | 67/247 [00:35<01:38,  1.82it/s]Loading train:  28%|██▊       | 68/247 [00:36<01:37,  1.83it/s]Loading train:  28%|██▊       | 69/247 [00:36<01:35,  1.86it/s]Loading train:  28%|██▊       | 70/247 [00:37<01:36,  1.84it/s]Loading train:  29%|██▊       | 71/247 [00:38<01:36,  1.83it/s]Loading train:  29%|██▉       | 72/247 [00:38<01:34,  1.84it/s]Loading train:  30%|██▉       | 73/247 [00:39<01:34,  1.85it/s]Loading train:  30%|██▉       | 74/247 [00:39<01:33,  1.84it/s]Loading train:  30%|███       | 75/247 [00:40<01:32,  1.85it/s]Loading train:  31%|███       | 76/247 [00:40<01:33,  1.83it/s]Loading train:  31%|███       | 77/247 [00:41<01:56,  1.46it/s]Loading train:  32%|███▏      | 78/247 [00:42<02:08,  1.32it/s]Loading train:  32%|███▏      | 79/247 [00:43<02:10,  1.28it/s]Loading train:  32%|███▏      | 80/247 [00:44<02:07,  1.30it/s]Loading train:  33%|███▎      | 81/247 [00:45<02:17,  1.21it/s]Loading train:  33%|███▎      | 82/247 [00:45<02:06,  1.31it/s]Loading train:  34%|███▎      | 83/247 [00:46<01:58,  1.39it/s]Loading train:  34%|███▍      | 84/247 [00:47<01:52,  1.44it/s]Loading train:  34%|███▍      | 85/247 [00:47<01:49,  1.48it/s]Loading train:  35%|███▍      | 86/247 [00:48<01:46,  1.51it/s]Loading train:  35%|███▌      | 87/247 [00:49<01:45,  1.52it/s]Loading train:  36%|███▌      | 88/247 [00:49<01:43,  1.53it/s]Loading train:  36%|███▌      | 89/247 [00:50<01:40,  1.57it/s]Loading train:  36%|███▋      | 90/247 [00:50<01:40,  1.56it/s]Loading train:  37%|███▋      | 91/247 [00:51<01:39,  1.57it/s]Loading train:  37%|███▋      | 92/247 [00:52<01:38,  1.58it/s]Loading train:  38%|███▊      | 93/247 [00:52<01:39,  1.55it/s]Loading train:  38%|███▊      | 94/247 [00:53<01:37,  1.57it/s]Loading train:  38%|███▊      | 95/247 [00:54<01:36,  1.58it/s]Loading train:  39%|███▉      | 96/247 [00:54<01:35,  1.59it/s]Loading train:  39%|███▉      | 97/247 [00:55<01:34,  1.60it/s]Loading train:  40%|███▉      | 98/247 [00:55<01:34,  1.57it/s]Loading train:  40%|████      | 99/247 [00:56<01:34,  1.57it/s]Loading train:  40%|████      | 100/247 [00:57<01:33,  1.58it/s]Loading train:  41%|████      | 101/247 [00:57<01:31,  1.60it/s]Loading train:  41%|████▏     | 102/247 [00:58<01:31,  1.58it/s]Loading train:  42%|████▏     | 103/247 [00:59<01:29,  1.61it/s]Loading train:  42%|████▏     | 104/247 [00:59<01:27,  1.64it/s]Loading train:  43%|████▎     | 105/247 [01:00<01:25,  1.67it/s]Loading train:  43%|████▎     | 106/247 [01:00<01:23,  1.69it/s]Loading train:  43%|████▎     | 107/247 [01:01<01:23,  1.68it/s]Loading train:  44%|████▎     | 108/247 [01:02<01:23,  1.66it/s]Loading train:  44%|████▍     | 109/247 [01:02<01:24,  1.63it/s]Loading train:  45%|████▍     | 110/247 [01:03<01:23,  1.64it/s]Loading train:  45%|████▍     | 111/247 [01:03<01:24,  1.61it/s]Loading train:  45%|████▌     | 112/247 [01:04<01:24,  1.60it/s]Loading train:  46%|████▌     | 113/247 [01:05<01:22,  1.62it/s]Loading train:  46%|████▌     | 114/247 [01:05<01:19,  1.66it/s]Loading train:  47%|████▋     | 115/247 [01:06<01:18,  1.68it/s]Loading train:  47%|████▋     | 116/247 [01:06<01:19,  1.66it/s]Loading train:  47%|████▋     | 117/247 [01:07<01:18,  1.67it/s]Loading train:  48%|████▊     | 118/247 [01:08<01:16,  1.69it/s]Loading train:  48%|████▊     | 119/247 [01:08<01:13,  1.75it/s]Loading train:  49%|████▊     | 120/247 [01:09<01:10,  1.81it/s]Loading train:  49%|████▉     | 121/247 [01:09<01:08,  1.83it/s]Loading train:  49%|████▉     | 122/247 [01:10<01:06,  1.87it/s]Loading train:  50%|████▉     | 123/247 [01:10<01:05,  1.88it/s]Loading train:  50%|█████     | 124/247 [01:11<01:05,  1.88it/s]Loading train:  51%|█████     | 125/247 [01:11<01:04,  1.89it/s]Loading train:  51%|█████     | 126/247 [01:12<01:03,  1.91it/s]Loading train:  51%|█████▏    | 127/247 [01:12<01:01,  1.94it/s]Loading train:  52%|█████▏    | 128/247 [01:13<01:00,  1.95it/s]Loading train:  52%|█████▏    | 129/247 [01:13<01:00,  1.95it/s]Loading train:  53%|█████▎    | 130/247 [01:14<00:59,  1.97it/s]Loading train:  53%|█████▎    | 131/247 [01:14<00:58,  1.97it/s]Loading train:  53%|█████▎    | 132/247 [01:15<00:58,  1.96it/s]Loading train:  54%|█████▍    | 133/247 [01:15<00:58,  1.95it/s]Loading train:  54%|█████▍    | 134/247 [01:16<00:58,  1.94it/s]Loading train:  55%|█████▍    | 135/247 [01:16<00:57,  1.94it/s]Loading train:  55%|█████▌    | 136/247 [01:17<00:57,  1.92it/s]Loading train:  55%|█████▌    | 137/247 [01:17<00:55,  1.98it/s]Loading train:  56%|█████▌    | 138/247 [01:18<00:55,  1.98it/s]Loading train:  56%|█████▋    | 139/247 [01:18<00:55,  1.95it/s]Loading train:  57%|█████▋    | 140/247 [01:19<00:53,  1.99it/s]Loading train:  57%|█████▋    | 141/247 [01:19<00:53,  2.00it/s]Loading train:  57%|█████▋    | 142/247 [01:20<00:51,  2.04it/s]Loading train:  58%|█████▊    | 143/247 [01:20<00:50,  2.06it/s]Loading train:  58%|█████▊    | 144/247 [01:21<00:49,  2.08it/s]Loading train:  59%|█████▊    | 145/247 [01:21<00:48,  2.08it/s]Loading train:  59%|█████▉    | 146/247 [01:22<00:48,  2.09it/s]Loading train:  60%|█████▉    | 147/247 [01:22<00:47,  2.11it/s]Loading train:  60%|█████▉    | 148/247 [01:23<00:47,  2.08it/s]Loading train:  60%|██████    | 149/247 [01:23<00:46,  2.09it/s]Loading train:  61%|██████    | 150/247 [01:24<00:46,  2.09it/s]Loading train:  61%|██████    | 151/247 [01:24<00:45,  2.09it/s]Loading train:  62%|██████▏   | 152/247 [01:25<00:46,  2.06it/s]Loading train:  62%|██████▏   | 153/247 [01:25<00:47,  1.98it/s]Loading train:  62%|██████▏   | 154/247 [01:29<02:19,  1.50s/it]Loading train:  63%|██████▎   | 155/247 [01:33<03:31,  2.30s/it]Loading train:  63%|██████▎   | 156/247 [01:37<04:01,  2.65s/it]Loading train:  64%|██████▎   | 157/247 [01:40<04:15,  2.84s/it]Loading train:  64%|██████▍   | 158/247 [01:43<04:25,  2.99s/it]Loading train:  64%|██████▍   | 159/247 [01:47<04:34,  3.11s/it]Loading train:  65%|██████▍   | 160/247 [01:50<04:40,  3.22s/it]Loading train:  65%|██████▌   | 161/247 [01:53<04:35,  3.21s/it]Loading train:  66%|██████▌   | 162/247 [01:57<04:43,  3.33s/it]Loading train:  66%|██████▌   | 163/247 [02:00<04:29,  3.21s/it]Loading train:  66%|██████▋   | 164/247 [02:03<04:29,  3.25s/it]Loading train:  67%|██████▋   | 165/247 [02:07<04:33,  3.34s/it]Loading train:  67%|██████▋   | 166/247 [02:10<04:35,  3.40s/it]Loading train:  68%|██████▊   | 167/247 [02:13<04:07,  3.09s/it]Loading train:  68%|██████▊   | 168/247 [02:16<04:14,  3.23s/it]Loading train:  68%|██████▊   | 169/247 [02:20<04:21,  3.36s/it]Loading train:  69%|██████▉   | 170/247 [02:23<04:19,  3.37s/it]Loading train:  69%|██████▉   | 171/247 [02:27<04:17,  3.39s/it]Loading train:  70%|██████▉   | 172/247 [02:36<06:24,  5.13s/it]Loading train:  70%|███████   | 173/247 [02:43<06:55,  5.62s/it]Loading train:  70%|███████   | 174/247 [02:51<07:53,  6.48s/it]Loading train:  71%|███████   | 175/247 [03:04<09:57,  8.30s/it]Loading train:  71%|███████▏  | 176/247 [03:07<08:07,  6.87s/it]Loading train:  72%|███████▏  | 177/247 [03:11<06:59,  6.00s/it]Loading train:  72%|███████▏  | 178/247 [03:15<06:00,  5.22s/it]Loading train:  72%|███████▏  | 179/247 [03:18<05:23,  4.76s/it]Loading train:  73%|███████▎  | 180/247 [03:22<04:56,  4.43s/it]Loading train:  73%|███████▎  | 181/247 [03:25<04:26,  4.03s/it]Loading train:  74%|███████▎  | 182/247 [03:29<04:24,  4.06s/it]Loading train:  74%|███████▍  | 183/247 [03:33<04:23,  4.11s/it]Loading train:  74%|███████▍  | 184/247 [03:38<04:20,  4.13s/it]Loading train:  75%|███████▍  | 185/247 [03:42<04:18,  4.17s/it]Loading train:  75%|███████▌  | 186/247 [03:46<04:17,  4.22s/it]Loading train:  76%|███████▌  | 187/247 [03:51<04:15,  4.25s/it]Loading train:  76%|███████▌  | 188/247 [03:55<04:07,  4.20s/it]Loading train:  77%|███████▋  | 189/247 [03:59<04:03,  4.19s/it]Loading train:  77%|███████▋  | 190/247 [04:03<03:56,  4.15s/it]Loading train:  77%|███████▋  | 191/247 [04:07<03:56,  4.22s/it]Loading train:  78%|███████▊  | 192/247 [04:12<03:55,  4.28s/it]Loading train:  78%|███████▊  | 193/247 [04:16<03:51,  4.29s/it]Loading train:  79%|███████▊  | 194/247 [04:18<03:08,  3.56s/it]Loading train:  79%|███████▉  | 195/247 [04:19<02:27,  2.85s/it]Loading train:  79%|███████▉  | 196/247 [04:20<02:00,  2.36s/it]Loading train:  80%|███████▉  | 197/247 [04:21<01:41,  2.02s/it]Loading train:  80%|████████  | 198/247 [04:23<01:26,  1.77s/it]Loading train:  81%|████████  | 199/247 [04:23<01:10,  1.47s/it]Loading train:  81%|████████  | 200/247 [04:24<00:58,  1.24s/it]Loading train:  81%|████████▏ | 201/247 [04:25<00:56,  1.22s/it]Loading train:  82%|████████▏ | 202/247 [04:27<00:56,  1.25s/it]Loading train:  82%|████████▏ | 203/247 [04:28<00:53,  1.22s/it]Loading train:  83%|████████▎ | 204/247 [04:29<00:53,  1.24s/it]Loading train:  83%|████████▎ | 205/247 [04:30<00:52,  1.24s/it]Loading train:  83%|████████▎ | 206/247 [04:32<00:51,  1.26s/it]Loading train:  84%|████████▍ | 207/247 [04:33<00:49,  1.23s/it]Loading train:  84%|████████▍ | 208/247 [04:34<00:47,  1.22s/it]Loading train:  85%|████████▍ | 209/247 [04:35<00:41,  1.08s/it]Loading train:  85%|████████▌ | 210/247 [04:35<00:35,  1.04it/s]Loading train:  85%|████████▌ | 211/247 [04:37<00:37,  1.05s/it]Loading train:  86%|████████▌ | 212/247 [04:40<01:00,  1.73s/it]Loading train:  86%|████████▌ | 213/247 [04:44<01:23,  2.47s/it]Loading train:  87%|████████▋ | 214/247 [04:48<01:33,  2.84s/it]Loading train:  87%|████████▋ | 215/247 [04:52<01:41,  3.16s/it]Loading train:  87%|████████▋ | 216/247 [04:56<01:46,  3.42s/it]Loading train:  88%|████████▊ | 217/247 [05:00<01:47,  3.59s/it]Loading train:  88%|████████▊ | 218/247 [05:04<01:46,  3.68s/it]Loading train:  89%|████████▊ | 219/247 [05:08<01:44,  3.74s/it]Loading train:  89%|████████▉ | 220/247 [05:11<01:42,  3.78s/it]Loading train:  89%|████████▉ | 221/247 [05:15<01:39,  3.82s/it]Loading train:  90%|████████▉ | 222/247 [05:19<01:35,  3.84s/it]Loading train:  90%|█████████ | 223/247 [05:23<01:34,  3.94s/it]Loading train:  91%|█████████ | 224/247 [05:27<01:31,  3.97s/it]Loading train:  91%|█████████ | 225/247 [05:31<01:27,  3.98s/it]Loading train:  91%|█████████▏| 226/247 [05:35<01:21,  3.88s/it]Loading train:  92%|█████████▏| 227/247 [05:39<01:15,  3.77s/it]Loading train:  92%|█████████▏| 228/247 [05:43<01:16,  4.00s/it]Loading train:  93%|█████████▎| 229/247 [05:47<01:09,  3.83s/it]Loading train:  93%|█████████▎| 230/247 [05:51<01:09,  4.06s/it]Loading train:  94%|█████████▎| 231/247 [05:57<01:12,  4.56s/it]Loading train:  94%|█████████▍| 232/247 [06:02<01:12,  4.84s/it]Loading train:  94%|█████████▍| 233/247 [06:08<01:11,  5.12s/it]Loading train:  95%|█████████▍| 234/247 [06:14<01:08,  5.29s/it]Loading train:  95%|█████████▌| 235/247 [06:19<01:04,  5.40s/it]Loading train:  96%|█████████▌| 236/247 [06:25<01:00,  5.51s/it]Loading train:  96%|█████████▌| 237/247 [06:31<00:56,  5.63s/it]Loading train:  96%|█████████▋| 238/247 [06:37<00:50,  5.64s/it]Loading train:  97%|█████████▋| 239/247 [06:43<00:45,  5.66s/it]Loading train:  97%|█████████▋| 240/247 [06:48<00:39,  5.60s/it]Loading train:  98%|█████████▊| 241/247 [06:53<00:31,  5.28s/it]Loading train:  98%|█████████▊| 242/247 [06:58<00:27,  5.40s/it]Loading train:  98%|█████████▊| 243/247 [07:03<00:20,  5.19s/it]Loading train:  99%|█████████▉| 244/247 [07:09<00:16,  5.36s/it]Loading train:  99%|█████████▉| 245/247 [07:14<00:10,  5.43s/it]Loading train: 100%|█████████▉| 246/247 [07:20<00:05,  5.54s/it]Loading train: 100%|██████████| 247/247 [07:26<00:00,  5.58s/it]Loading train: 100%|██████████| 247/247 [07:26<00:00,  1.81s/it]
concatenating: train:   0%|          | 0/247 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/247 [00:00<00:04, 49.09it/s]concatenating: train:   4%|▍         | 10/247 [00:00<00:04, 48.77it/s]concatenating: train:   6%|▌         | 15/247 [00:00<00:04, 48.78it/s]concatenating: train:   8%|▊         | 20/247 [00:00<00:04, 48.87it/s]concatenating: train:  10%|█         | 25/247 [00:00<00:04, 48.70it/s]concatenating: train:  12%|█▏        | 30/247 [00:00<00:04, 49.06it/s]concatenating: train:  15%|█▍        | 36/247 [00:00<00:04, 49.41it/s]concatenating: train:  17%|█▋        | 41/247 [00:00<00:04, 48.03it/s]concatenating: train:  19%|█▉        | 47/247 [00:00<00:03, 50.06it/s]concatenating: train:  21%|██▏       | 53/247 [00:01<00:03, 51.76it/s]concatenating: train:  24%|██▍       | 59/247 [00:01<00:03, 52.90it/s]concatenating: train:  26%|██▋       | 65/247 [00:01<00:03, 52.45it/s]concatenating: train:  29%|██▊       | 71/247 [00:01<00:03, 52.60it/s]concatenating: train:  31%|███       | 77/247 [00:01<00:03, 51.93it/s]concatenating: train:  34%|███▎      | 83/247 [00:01<00:03, 50.55it/s]concatenating: train:  36%|███▌      | 89/247 [00:01<00:03, 47.46it/s]concatenating: train:  38%|███▊      | 94/247 [00:01<00:03, 45.93it/s]concatenating: train:  40%|████      | 99/247 [00:02<00:03, 45.31it/s]concatenating: train:  42%|████▏     | 104/247 [00:02<00:03, 45.69it/s]concatenating: train:  44%|████▍     | 109/247 [00:02<00:02, 46.59it/s]concatenating: train:  46%|████▌     | 114/247 [00:02<00:02, 46.83it/s]concatenating: train:  48%|████▊     | 119/247 [00:02<00:02, 47.35it/s]concatenating: train:  51%|█████     | 125/247 [00:02<00:02, 48.50it/s]concatenating: train:  53%|█████▎    | 131/247 [00:02<00:02, 49.36it/s]concatenating: train:  55%|█████▌    | 137/247 [00:02<00:02, 50.73it/s]concatenating: train:  58%|█████▊    | 143/247 [00:02<00:02, 50.99it/s]concatenating: train:  60%|██████    | 149/247 [00:03<00:01, 50.37it/s]concatenating: train:  63%|██████▎   | 155/247 [00:03<00:01, 51.63it/s]concatenating: train:  65%|██████▌   | 161/247 [00:03<00:01, 51.58it/s]concatenating: train:  68%|██████▊   | 167/247 [00:03<00:01, 48.94it/s]concatenating: train:  70%|███████   | 173/247 [00:03<00:01, 49.57it/s]concatenating: train:  72%|███████▏  | 178/247 [00:03<00:01, 49.28it/s]concatenating: train:  74%|███████▍  | 183/247 [00:03<00:01, 48.96it/s]concatenating: train:  76%|███████▌  | 188/247 [00:03<00:01, 47.66it/s]concatenating: train:  78%|███████▊  | 193/247 [00:03<00:01, 47.33it/s]concatenating: train:  81%|████████  | 199/247 [00:04<00:00, 49.31it/s]concatenating: train:  83%|████████▎ | 205/247 [00:04<00:00, 49.49it/s]concatenating: train:  85%|████████▌ | 211/247 [00:04<00:00, 50.24it/s]concatenating: train:  88%|████████▊ | 217/247 [00:04<00:00, 51.19it/s]concatenating: train:  90%|█████████ | 223/247 [00:04<00:00, 51.93it/s]concatenating: train:  93%|█████████▎| 229/247 [00:04<00:00, 52.73it/s]concatenating: train:  95%|█████████▌| 235/247 [00:04<00:00, 50.79it/s]concatenating: train:  98%|█████████▊| 241/247 [00:04<00:00, 49.43it/s]concatenating: train: 100%|█████████▉| 246/247 [00:04<00:00, 48.83it/s]concatenating: train: 100%|██████████| 247/247 [00:04<00:00, 49.61it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:12<00:49, 12.29s/it]Loading test:  40%|████      | 2/5 [00:27<00:39, 13.04s/it]Loading test:  60%|██████    | 3/5 [00:33<00:22, 11.04s/it]Loading test:  80%|████████  | 4/5 [00:37<00:09,  9.03s/it]Loading test: 100%|██████████| 5/5 [00:47<00:00,  9.15s/it]Loading test: 100%|██████████| 5/5 [00:47<00:00,  9.44s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 55.38it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-22 04:10:04.029561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 04:10:04.029660: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 04:10:04.029674: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 04:10:04.029682: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 04:10:04.029971: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.52300117e-02 3.19378840e-02 7.70679254e-02 9.60857276e-03
 2.75101481e-02 7.04578854e-03 8.85485900e-02 1.14408954e-01
 8.19801890e-02 1.27565887e-02 2.89557613e-01 1.94102791e-01
 2.44943459e-04]
Train on 9144 samples, validate on 180 samples
Epoch 1/300
 - 25s - loss: 0.6664 - acc: 0.8939 - mDice: 0.2821 - val_loss: 0.6649 - val_acc: 0.9299 - val_mDice: 0.2826

Epoch 00001: val_mDice improved from -inf to 0.28259, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.4574 - acc: 0.9244 - mDice: 0.5075 - val_loss: 0.6160 - val_acc: 0.9398 - val_mDice: 0.3349

Epoch 00002: val_mDice improved from 0.28259 to 0.33494, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 20s - loss: 0.4033 - acc: 0.9330 - mDice: 0.5659 - val_loss: 0.6006 - val_acc: 0.9456 - val_mDice: 0.3511

Epoch 00003: val_mDice improved from 0.33494 to 0.35105, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 20s - loss: 0.3805 - acc: 0.9367 - mDice: 0.5904 - val_loss: 0.6266 - val_acc: 0.9426 - val_mDice: 0.3213

Epoch 00004: val_mDice did not improve from 0.35105
Epoch 5/300
 - 20s - loss: 0.3659 - acc: 0.9387 - mDice: 0.6062 - val_loss: 0.5816 - val_acc: 0.9494 - val_mDice: 0.3527

Epoch 00005: val_mDice improved from 0.35105 to 0.35267, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 6/300
 - 21s - loss: 0.3559 - acc: 0.9403 - mDice: 0.6170 - val_loss: 0.6003 - val_acc: 0.9470 - val_mDice: 0.3352

Epoch 00006: val_mDice did not improve from 0.35267
Epoch 7/300
 - 21s - loss: 0.3490 - acc: 0.9413 - mDice: 0.6245 - val_loss: 0.5517 - val_acc: 0.9464 - val_mDice: 0.3444

Epoch 00007: val_mDice did not improve from 0.35267
Epoch 8/300
 - 20s - loss: 0.3373 - acc: 0.9428 - mDice: 0.6371 - val_loss: 0.5430 - val_acc: 0.9440 - val_mDice: 0.3476

Epoch 00008: val_mDice did not improve from 0.35267
Epoch 9/300
 - 20s - loss: 0.3327 - acc: 0.9433 - mDice: 0.6420 - val_loss: 0.3975 - val_acc: 0.9497 - val_mDice: 0.3457

Epoch 00009: val_mDice did not improve from 0.35267
Epoch 10/300
 - 20s - loss: 0.3282 - acc: 0.9441 - mDice: 0.6468 - val_loss: 0.4445 - val_acc: 0.9482 - val_mDice: 0.3503

Epoch 00010: val_mDice did not improve from 0.35267
Epoch 11/300
 - 21s - loss: 0.3232 - acc: 0.9444 - mDice: 0.6522 - val_loss: 0.4018 - val_acc: 0.9439 - val_mDice: 0.3182

Epoch 00011: val_mDice did not improve from 0.35267
Epoch 12/300
 - 21s - loss: 0.3204 - acc: 0.9448 - mDice: 0.6552 - val_loss: 0.3100 - val_acc: 0.9487 - val_mDice: 0.3484

Epoch 00012: val_mDice did not improve from 0.35267
Epoch 13/300
 - 21s - loss: 0.3160 - acc: 0.9454 - mDice: 0.6600 - val_loss: 0.2866 - val_acc: 0.9500 - val_mDice: 0.3618

Epoch 00013: val_mDice improved from 0.35267 to 0.36175, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 21s - loss: 0.3142 - acc: 0.9460 - mDice: 0.6620 - val_loss: 0.3295 - val_acc: 0.9496 - val_mDice: 0.3537

Epoch 00014: val_mDice did not improve from 0.36175
Epoch 15/300
 - 20s - loss: 0.3083 - acc: 0.9464 - mDice: 0.6683 - val_loss: 0.3438 - val_acc: 0.9461 - val_mDice: 0.3197

Epoch 00015: val_mDice did not improve from 0.36175
Epoch 16/300
 - 21s - loss: 0.3064 - acc: 0.9468 - mDice: 0.6703 - val_loss: 0.2596 - val_acc: 0.9421 - val_mDice: 0.3021

Epoch 00016: val_mDice did not improve from 0.36175
Epoch 17/300
 - 20s - loss: 0.3047 - acc: 0.9468 - mDice: 0.6722 - val_loss: 0.3051 - val_acc: 0.9444 - val_mDice: 0.3416

Epoch 00017: val_mDice did not improve from 0.36175
Epoch 18/300
 - 20s - loss: 0.3029 - acc: 0.9469 - mDice: 0.6741 - val_loss: 0.3408 - val_acc: 0.9466 - val_mDice: 0.3301

Epoch 00018: val_mDice did not improve from 0.36175
Epoch 19/300
 - 21s - loss: 0.3022 - acc: 0.9471 - mDice: 0.6748 - val_loss: 0.2689 - val_acc: 0.9503 - val_mDice: 0.3427

Epoch 00019: val_mDice did not improve from 0.36175
Epoch 20/300
 - 20s - loss: 0.3022 - acc: 0.9475 - mDice: 0.6749 - val_loss: 0.2029 - val_acc: 0.9513 - val_mDice: 0.3614

Epoch 00020: val_mDice did not improve from 0.36175
Epoch 21/300
 - 20s - loss: 0.2992 - acc: 0.9480 - mDice: 0.6781 - val_loss: 0.2652 - val_acc: 0.9480 - val_mDice: 0.3458

Epoch 00021: val_mDice did not improve from 0.36175
Epoch 22/300
 - 20s - loss: 0.2959 - acc: 0.9482 - mDice: 0.6817 - val_loss: 0.2024 - val_acc: 0.9496 - val_mDice: 0.3576

Epoch 00022: val_mDice did not improve from 0.36175
Epoch 23/300
 - 21s - loss: 0.2957 - acc: 0.9482 - mDice: 0.6818 - val_loss: 0.2538 - val_acc: 0.9491 - val_mDice: 0.3550

Epoch 00023: val_mDice did not improve from 0.36175
Epoch 24/300
 - 21s - loss: 0.2982 - acc: 0.9479 - mDice: 0.6792 - val_loss: 0.2504 - val_acc: 0.9500 - val_mDice: 0.3597

Epoch 00024: val_mDice did not improve from 0.36175
Epoch 25/300
 - 23s - loss: 0.2899 - acc: 0.9489 - mDice: 0.6880 - val_loss: 0.1054 - val_acc: 0.9483 - val_mDice: 0.3374

Epoch 00025: val_mDice did not improve from 0.36175
Epoch 26/300
 - 24s - loss: 0.2905 - acc: 0.9489 - mDice: 0.6874 - val_loss: 0.2510 - val_acc: 0.9476 - val_mDice: 0.3600

Epoch 00026: val_mDice did not improve from 0.36175
Epoch 27/300
 - 20s - loss: 0.2891 - acc: 0.9489 - mDice: 0.6889 - val_loss: 0.2021 - val_acc: 0.9491 - val_mDice: 0.3454

Epoch 00027: val_mDice did not improve from 0.36175
Epoch 28/300
 - 20s - loss: 0.2877 - acc: 0.9492 - mDice: 0.6904 - val_loss: 0.1699 - val_acc: 0.9503 - val_mDice: 0.3654

Epoch 00028: val_mDice improved from 0.36175 to 0.36541, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 29/300
 - 20s - loss: 0.2880 - acc: 0.9491 - mDice: 0.6901 - val_loss: 0.2659 - val_acc: 0.9475 - val_mDice: 0.3439

Epoch 00029: val_mDice did not improve from 0.36541
Epoch 30/300
 - 19s - loss: 0.2828 - acc: 0.9495 - mDice: 0.6957 - val_loss: 0.2286 - val_acc: 0.9491 - val_mDice: 0.3453

Epoch 00030: val_mDice did not improve from 0.36541
Epoch 31/300
 - 19s - loss: 0.2835 - acc: 0.9494 - mDice: 0.6950 - val_loss: 0.1934 - val_acc: 0.9479 - val_mDice: 0.3520

Epoch 00031: val_mDice did not improve from 0.36541
Epoch 32/300
 - 20s - loss: 0.2786 - acc: 0.9500 - mDice: 0.7003 - val_loss: 0.1589 - val_acc: 0.9514 - val_mDice: 0.3677

Epoch 00032: val_mDice improved from 0.36541 to 0.36771, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_c/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 33/300
 - 19s - loss: 0.2818 - acc: 0.9497 - mDice: 0.6968 - val_loss: 0.1119 - val_acc: 0.9442 - val_mDice: 0.2920

Epoch 00033: val_mDice did not improve from 0.36771
Epoch 34/300
 - 20s - loss: 0.2838 - acc: 0.9500 - mDice: 0.6947 - val_loss: 0.1531 - val_acc: 0.9510 - val_mDice: 0.3590

Epoch 00034: val_mDice did not improve from 0.36771
Epoch 35/300
 - 20s - loss: 0.2817 - acc: 0.9496 - mDice: 0.6969 - val_loss: 0.2578 - val_acc: 0.9478 - val_mDice: 0.3193

Epoch 00035: val_mDice did not improve from 0.36771
Epoch 36/300
 - 19s - loss: 0.2792 - acc: 0.9503 - mDice: 0.6996 - val_loss: 0.1188 - val_acc: 0.9505 - val_mDice: 0.3561

Epoch 00036: val_mDice did not improve from 0.36771
Epoch 37/300
 - 19s - loss: 0.2794 - acc: 0.9502 - mDice: 0.6994 - val_loss: 0.1983 - val_acc: 0.9503 - val_mDice: 0.3452

Epoch 00037: val_mDice did not improve from 0.36771
Epoch 38/300
 - 20s - loss: 0.2774 - acc: 0.9503 - mDice: 0.7016 - val_loss: 0.1309 - val_acc: 0.9446 - val_mDice: 0.3072

Epoch 00038: val_mDice did not improve from 0.36771
Epoch 39/300
 - 20s - loss: 0.2768 - acc: 0.9504 - mDice: 0.7022 - val_loss: 0.1280 - val_acc: 0.9510 - val_mDice: 0.3670

Epoch 00039: val_mDice did not improve from 0.36771
Epoch 40/300
 - 19s - loss: 0.2789 - acc: 0.9502 - mDice: 0.6999 - val_loss: 0.1485 - val_acc: 0.9514 - val_mDice: 0.3651

Epoch 00040: val_mDice did not improve from 0.36771
Epoch 41/300
 - 20s - loss: 0.2755 - acc: 0.9504 - mDice: 0.7036 - val_loss: 0.0914 - val_acc: 0.9517 - val_mDice: 0.3593

Epoch 00041: val_mDice did not improve from 0.36771
Epoch 42/300
 - 20s - loss: 0.2751 - acc: 0.9505 - mDice: 0.7040 - val_loss: 0.1750 - val_acc: 0.9510 - val_mDice: 0.3507

Epoch 00042: val_mDice did not improve from 0.36771
Epoch 43/300
 - 20s - loss: 0.2766 - acc: 0.9507 - mDice: 0.7024 - val_loss: 0.2283 - val_acc: 0.9459 - val_mDice: 0.3212

Epoch 00043: val_mDice did not improve from 0.36771
Epoch 44/300
 - 20s - loss: 0.2717 - acc: 0.9509 - mDice: 0.7077 - val_loss: 0.1453 - val_acc: 0.9472 - val_mDice: 0.3221

Epoch 00044: val_mDice did not improve from 0.36771
Epoch 45/300
 - 20s - loss: 0.2761 - acc: 0.9506 - mDice: 0.7029 - val_loss: 0.2639 - val_acc: 0.9497 - val_mDice: 0.3561

Epoch 00045: val_mDice did not improve from 0.36771
Epoch 46/300
 - 20s - loss: 0.2765 - acc: 0.9505 - mDice: 0.7025 - val_loss: 0.1438 - val_acc: 0.9494 - val_mDice: 0.3379

Epoch 00046: val_mDice did not improve from 0.36771
Epoch 47/300
 - 19s - loss: 0.2713 - acc: 0.9511 - mDice: 0.7081 - val_loss: 0.1940 - val_acc: 0.9511 - val_mDice: 0.3595

Epoch 00047: val_mDice did not improve from 0.36771

Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 48/300
 - 21s - loss: 0.2641 - acc: 0.9518 - mDice: 0.7159 - val_loss: 0.1944 - val_acc: 0.9507 - val_mDice: 0.3543

Epoch 00048: val_mDice did not improve from 0.36771
Epoch 49/300
 - 21s - loss: 0.2611 - acc: 0.9520 - mDice: 0.7191 - val_loss: 0.1043 - val_acc: 0.9518 - val_mDice: 0.3628

Epoch 00049: val_mDice did not improve from 0.36771
Epoch 50/300
 - 20s - loss: 0.2629 - acc: 0.9524 - mDice: 0.7172 - val_loss: 0.1466 - val_acc: 0.9505 - val_mDice: 0.3505

Epoch 00050: val_mDice did not improve from 0.36771
Epoch 51/300
 - 19s - loss: 0.2575 - acc: 0.9525 - mDice: 0.7230 - val_loss: 0.1665 - val_acc: 0.9497 - val_mDice: 0.3363

Epoch 00051: val_mDice did not improve from 0.36771
Epoch 52/300
 - 20s - loss: 0.2591 - acc: 0.9526 - mDice: 0.7213 - val_loss: 0.2095 - val_acc: 0.9492 - val_mDice: 0.3416

Epoch 00052: val_mDice did not improve from 0.36771
Epoch 53/300
 - 20s - loss: 0.2609 - acc: 0.9525 - mDice: 0.7193 - val_loss: 0.2103 - val_acc: 0.9488 - val_mDice: 0.3336

Epoch 00053: val_mDice did not improve from 0.36771
Epoch 54/300
 - 20s - loss: 0.2608 - acc: 0.9525 - mDice: 0.7195 - val_loss: 0.2040 - val_acc: 0.9506 - val_mDice: 0.3652

Epoch 00054: val_mDice did not improve from 0.36771
Epoch 55/300
 - 19s - loss: 0.2602 - acc: 0.9524 - mDice: 0.7201 - val_loss: 0.1905 - val_acc: 0.9491 - val_mDice: 0.3297

Epoch 00055: val_mDice did not improve from 0.36771
Epoch 56/300
 - 19s - loss: 0.2601 - acc: 0.9526 - mDice: 0.7202 - val_loss: 0.1868 - val_acc: 0.9512 - val_mDice: 0.3542

Epoch 00056: val_mDice did not improve from 0.36771
Epoch 57/300
 - 20s - loss: 0.2553 - acc: 0.9527 - mDice: 0.7253 - val_loss: 0.1347 - val_acc: 0.9523 - val_mDice: 0.3648

Epoch 00057: val_mDice did not improve from 0.36771
Epoch 58/300
 - 20s - loss: 0.2551 - acc: 0.9528 - mDice: 0.7256 - val_loss: 0.1602 - val_acc: 0.9511 - val_mDice: 0.3623

Epoch 00058: val_mDice did not improve from 0.36771
Epoch 59/300
 - 19s - loss: 0.2550 - acc: 0.9530 - mDice: 0.7257 - val_loss: 0.1958 - val_acc: 0.9494 - val_mDice: 0.3462

Epoch 00059: val_mDice did not improve from 0.36771
Epoch 60/300
 - 19s - loss: 0.2531 - acc: 0.9530 - mDice: 0.7276 - val_loss: 0.1670 - val_acc: 0.9499 - val_mDice: 0.3503

Epoch 00060: val_mDice did not improve from 0.36771
Epoch 61/300
 - 20s - loss: 0.2541 - acc: 0.9530 - mDice: 0.7266 - val_loss: 0.1973 - val_acc: 0.9509 - val_mDice: 0.3553

Epoch 00061: val_mDice did not improve from 0.36771
Epoch 62/300
 - 20s - loss: 0.2552 - acc: 0.9531 - mDice: 0.7255 - val_loss: 0.2061 - val_acc: 0.9493 - val_mDice: 0.3458

Epoch 00062: val_mDice did not improve from 0.36771

Epoch 00062: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 63/300
 - 19s - loss: 0.2491 - acc: 0.9533 - mDice: 0.7320 - val_loss: 0.1617 - val_acc: 0.9504 - val_mDice: 0.3532

Epoch 00063: val_mDice did not improve from 0.36771
Epoch 64/300
 - 19s - loss: 0.2489 - acc: 0.9534 - mDice: 0.7323 - val_loss: 0.1313 - val_acc: 0.9510 - val_mDice: 0.3568

Epoch 00064: val_mDice did not improve from 0.36771
Epoch 65/300
 - 19s - loss: 0.2469 - acc: 0.9536 - mDice: 0.7343 - val_loss: 0.1697 - val_acc: 0.9513 - val_mDice: 0.3649

Epoch 00065: val_mDice did not improve from 0.36771
Epoch 66/300
 - 20s - loss: 0.2451 - acc: 0.9538 - mDice: 0.7363 - val_loss: 0.1742 - val_acc: 0.9502 - val_mDice: 0.3437

Epoch 00066: val_mDice did not improve from 0.36771
Epoch 67/300
 - 20s - loss: 0.2438 - acc: 0.9537 - mDice: 0.7377 - val_loss: 0.1691 - val_acc: 0.9511 - val_mDice: 0.3572

Epoch 00067: val_mDice did not improve from 0.36771
Epoch 68/300
 - 20s - loss: 0.2468 - acc: 0.9537 - mDice: 0.7345 - val_loss: 0.1385 - val_acc: 0.9513 - val_mDice: 0.3540

Epoch 00068: val_mDice did not improve from 0.36771
Epoch 69/300
 - 20s - loss: 0.2453 - acc: 0.9538 - mDice: 0.7362 - val_loss: 0.1265 - val_acc: 0.9518 - val_mDice: 0.3536

Epoch 00069: val_mDice did not improve from 0.36771
Epoch 70/300
 - 21s - loss: 0.2441 - acc: 0.9539 - mDice: 0.7373 - val_loss: 0.1497 - val_acc: 0.9514 - val_mDice: 0.3554

Epoch 00070: val_mDice did not improve from 0.36771
Epoch 71/300
 - 20s - loss: 0.2453 - acc: 0.9537 - mDice: 0.7361 - val_loss: 0.1305 - val_acc: 0.9520 - val_mDice: 0.3592

Epoch 00071: val_mDice did not improve from 0.36771
Epoch 72/300
 - 21s - loss: 0.2462 - acc: 0.9538 - mDice: 0.7351 - val_loss: 0.1709 - val_acc: 0.9506 - val_mDice: 0.3478

Epoch 00072: val_mDice did not improve from 0.36771
Restoring model weights from the end of the best epoch
Epoch 00072: early stopping
{'val_loss': [0.664876714348793, 0.6159998377164205, 0.6006088770098157, 0.6265559395154318, 0.5816075172689226, 0.6002541035413742, 0.5516771839724647, 0.5430047826634513, 0.39748295810487533, 0.4445334043767717, 0.40180807809034985, 0.30999923683702946, 0.28656953956103987, 0.3295055033846034, 0.3437969888974395, 0.2596113874266545, 0.30509221540867454, 0.3407575326661269, 0.26891929169909823, 0.20288784210828859, 0.26518550887703896, 0.2023951963831981, 0.2537555108364258, 0.25038244513173896, 0.10544430402417977, 0.25098520589785445, 0.20212851053414246, 0.16991978314601713, 0.2658694398382472, 0.2286153944571399, 0.19341357248938745, 0.15885463905417258, 0.11192002292308542, 0.1530994525593188, 0.25778136267844176, 0.11880075505986396, 0.19825486197239822, 0.13088020868599415, 0.12795061328344876, 0.148540988823192, 0.09141230779803461, 0.17500017640284365, 0.22834376504437792, 0.14532621432509688, 0.2639358623160256, 0.1437597396887011, 0.19396999530080292, 0.1944453346853455, 0.10434590642237002, 0.14660463937454754, 0.16645985593398413, 0.20954409448636901, 0.21027923985901806, 0.2039745185369005, 0.19048579199524182, 0.1868310652466284, 0.13472626296182474, 0.1602171083084411, 0.1957642294259535, 0.16697815308968225, 0.1973172938451171, 0.20613491918063825, 0.16174358067413172, 0.13131219158983892, 0.16973370768957668, 0.17416015670945248, 0.16905708476487133, 0.13850037784626087, 0.12652211688044998, 0.14971122249133056, 0.13052081275317404, 0.17090532390607727], 'val_acc': [0.9299005236890581, 0.939752482705646, 0.9455535180038876, 0.942619307173623, 0.9493844078646766, 0.9469703965716891, 0.9464387430085076, 0.944001833597819, 0.9496883915530311, 0.948158323764801, 0.943877187040117, 0.9486708905961778, 0.9499618510405222, 0.9496197005112966, 0.9461169640223185, 0.9420507715808021, 0.9444215496381124, 0.9466371503141191, 0.9503166907363467, 0.9512553380595313, 0.9479853477742937, 0.9496476882033877, 0.9490778843561808, 0.9499516718917422, 0.9483325713210635, 0.9476393991046481, 0.949068996641371, 0.9503446817398071, 0.9475083980295393, 0.9491274952888489, 0.9479281107584635, 0.9513812628057268, 0.9442409409417046, 0.9510493079821268, 0.9477907551659478, 0.9505469070540534, 0.9502658214834001, 0.9446225066979727, 0.951016237338384, 0.951404160923428, 0.9517132143179575, 0.9509844382603964, 0.9459109140766991, 0.94721077548133, 0.9497023787763383, 0.9493716988298628, 0.9511205322212644, 0.9506944417953491, 0.9518149627579583, 0.9504884017838372, 0.9497049252192179, 0.9492470522721609, 0.9488324191835191, 0.9506206810474396, 0.9491491152180566, 0.9512031939294603, 0.9522817465994093, 0.9511434204048581, 0.9494263860914443, 0.9498804476526048, 0.9509399169021182, 0.9492534101009369, 0.9503586689631144, 0.9510467582278781, 0.9512807726860046, 0.9501780602667067, 0.9511345161332024, 0.951338016324573, 0.9518429504500495, 0.95136472913954, 0.9520413643783994, 0.9505647122859955], 'val_mDice': [0.2825859404272503, 0.33494002785947585, 0.35105372137493557, 0.32131584733724594, 0.35266727291875416, 0.3351509951882892, 0.3443707567122247, 0.34758728825383717, 0.3456740954683887, 0.3502507847216394, 0.3182391979628139, 0.34840618901782566, 0.36175085190269685, 0.3537449555264579, 0.3197201333112187, 0.3021320295002725, 0.34159128699037766, 0.33011147048738265, 0.3426579030023681, 0.3613603777355618, 0.34575137661563027, 0.35762718237108654, 0.3550192076298926, 0.35969894544945824, 0.33741581439971924, 0.3600072960058848, 0.3453865150610606, 0.36541176421774757, 0.3439296277032958, 0.34525962587859893, 0.35203836775488323, 0.36771341578827965, 0.2919803493552738, 0.35903609461254543, 0.3193387496802542, 0.35610616621043945, 0.3452267684042454, 0.30718010581201977, 0.3670404942499267, 0.36513107352786595, 0.3592914839585622, 0.35074100146691006, 0.32119269255134797, 0.3220715940826469, 0.3560581256945928, 0.3378777528802554, 0.3594979867339134, 0.35430743793646496, 0.3627777215507295, 0.35047555673453545, 0.3362751255432765, 0.34160928262604606, 0.33356089765826863, 0.36518307195769417, 0.3297207330663999, 0.3541749260491795, 0.36482004614339936, 0.362319999270969, 0.3461654964420531, 0.3503152144451936, 0.35531764063570237, 0.345750105049875, 0.35322093963623047, 0.35675985034969115, 0.3648722651931975, 0.3436976820230484, 0.3572070776588387, 0.35395898587173885, 0.35357599457105, 0.35542653335465324, 0.35917747186289894, 0.347754814558559], 'loss': [0.6663630956544337, 0.45744379008170916, 0.4032798827294185, 0.38054279906126043, 0.3658816323844571, 0.3558621296360893, 0.34896528386459574, 0.3372624482102334, 0.3326832939979025, 0.3282299541321535, 0.3232309705270609, 0.32040829217665984, 0.31595083544143227, 0.31415556253554106, 0.30828074358683977, 0.3064296936171418, 0.30469663712674344, 0.30292542859559923, 0.3022078193906672, 0.3021815255942672, 0.2991721619047674, 0.29587133897897033, 0.2956918182237724, 0.29815598928279136, 0.2899295151468337, 0.2905107739488232, 0.2891407638188527, 0.2877180774159214, 0.2880111336382147, 0.2828496462866755, 0.28348811527784207, 0.27856948394866127, 0.2818109079745654, 0.28375456140605587, 0.2816930597881059, 0.2791947274520172, 0.27941555206192137, 0.277388142273547, 0.27675831591350303, 0.2788954422184228, 0.275532665224917, 0.27514100098560385, 0.2766239201798318, 0.27167777578596575, 0.27611212439228855, 0.2765298277980543, 0.27126594154410266, 0.2641364125044379, 0.26109643704204943, 0.26289726075107656, 0.2575113314317176, 0.2590572234383301, 0.26087089425257604, 0.2607774931940715, 0.2602241836090622, 0.26007859148117707, 0.25532327592698817, 0.2550720018925421, 0.2549968949850724, 0.2531282893452901, 0.25414233310889595, 0.25517720635247043, 0.24910068348675887, 0.24885977707861914, 0.24690026357079012, 0.24512425235497878, 0.24378913272032066, 0.2467910556916281, 0.24527134085994798, 0.2441484693336779, 0.245257449914047, 0.24618548627418066], 'acc': [0.89390701619698, 0.9244439149778971, 0.9329755248229752, 0.9367250581504166, 0.9387141906005295, 0.9403303752499302, 0.9413017824826695, 0.9428390765909761, 0.9432556914297614, 0.944052566432786, 0.9443958475729508, 0.9447588339799972, 0.9453758181366916, 0.9459502906102625, 0.9463837795865608, 0.9467806907228911, 0.9467846215918517, 0.9468707488434208, 0.9471280023859763, 0.9475337774056879, 0.9479684189470421, 0.9482107255689324, 0.9482230197439461, 0.9479263552765208, 0.94892633167256, 0.9489441323676656, 0.9488932573263413, 0.9492143802312207, 0.9491124814498456, 0.9495376831772864, 0.9494121984651187, 0.9499507179697251, 0.9497441122746739, 0.9499937804743374, 0.9496151480435908, 0.9503179851036163, 0.9501923987167714, 0.9502988320792441, 0.9503518598885883, 0.9501784279329779, 0.9503897152912794, 0.9504828273806777, 0.9506726578881839, 0.9508995660698841, 0.9506270399191665, 0.9504621474500925, 0.9510799823679219, 0.9517659698519285, 0.95198779762417, 0.9524016582772905, 0.9525392853499294, 0.9526239119906855, 0.9524737898055025, 0.9524630234623206, 0.9523842818285432, 0.9526162503037866, 0.9526949162584382, 0.9528427086737943, 0.9529853195004159, 0.9529812124118613, 0.9529785339965804, 0.9530847905788731, 0.9533432467611651, 0.953382679718373, 0.9535775175635895, 0.9537690003269718, 0.9537408334819872, 0.9537484199330145, 0.9537954144799073, 0.9538777100601847, 0.9537225308015694, 0.953836199166685], 'mDice': [0.28211391441220923, 0.5075021329207944, 0.5659058021344017, 0.590417333429619, 0.6062441902008634, 0.6170363040381842, 0.6244717792054592, 0.6370770624811881, 0.6420086243060317, 0.6468041882648973, 0.6522067970452033, 0.6552367709440197, 0.6600417494122021, 0.6619569847681287, 0.668310767683353, 0.6702978698535124, 0.6721671893214929, 0.6740640032048927, 0.6748330307275395, 0.6748558504674795, 0.6780837743248944, 0.6816589416364046, 0.6818402204287751, 0.6791816771695307, 0.6880477324962512, 0.6874121892105459, 0.6889057933684514, 0.6904351038700223, 0.6901189818430761, 0.6956898716921256, 0.695019449031572, 0.7003142833709717, 0.6968073585084521, 0.6946820261141029, 0.6969310349327685, 0.6996169045228553, 0.6993843964378457, 0.7015723320390713, 0.7022437287766685, 0.6999357538273329, 0.7035721373839641, 0.7039925219101647, 0.7023680036918489, 0.7077217255364566, 0.7029178433400544, 0.7024685324137918, 0.7081470822464032, 0.7158509252408776, 0.7191076903348937, 0.7171582979714777, 0.7229821645994512, 0.7213026679211402, 0.7193467340848473, 0.7194565842914039, 0.72005382975464, 0.7201959390000929, 0.7253475600001276, 0.7255767589126985, 0.725656909697012, 0.7276028846753134, 0.7266125007746831, 0.7254629803272266, 0.7319965016712823, 0.732290908205384, 0.7343473985712985, 0.7363377230751963, 0.7376761553989933, 0.7344737749673876, 0.7361795337103171, 0.7372918952051111, 0.7360956599627893, 0.7351021979033477], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:05,  1.43s/it]predicting test subjects:  40%|████      | 2/5 [00:02<00:04,  1.33s/it]predicting test subjects:  60%|██████    | 3/5 [00:03<00:02,  1.24s/it]predicting test subjects:  80%|████████  | 4/5 [00:04<00:01,  1.11s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]predicting test subjects: 100%|██████████| 5/5 [00:05<00:00,  1.06s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_c/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_c/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_c/sd2/vimp*': No such file or directory

  0%|          | 0/5 [00:00<?, ?it/s] 20%|██        | 1/5 [00:00<00:01,  3.07it/s] 40%|████      | 2/5 [00:00<00:01,  2.96it/s] 60%|██████    | 3/5 [00:01<00:00,  2.88it/s] 80%|████████  | 4/5 [00:01<00:00,  3.13it/s]100%|██████████| 5/5 [00:01<00:00,  3.23it/s]100%|██████████| 5/5 [00:01<00:00,  3.12it/s]

CrossVal ['c']
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
2020-01-22 04:34:37.199770: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: SSE4.1 SSE4.2 AVX AVX2 FMA
2020-01-22 04:34:40.895622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1432] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:84:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2020-01-22 04:34:40.895679: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 04:34:41.334780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 04:34:41.334851: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 04:34:41.334862: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 04:34:41.335354: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  np_resource = np.dtype([("resource", np.ubyte, 1)])
Using TensorFlow backend.
/array/ssd/msmajdi/anaconda3/envs/new-env-fb/lib/python3.6/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.
  warnings.warn(msg, category=DeprecationWarning)
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:07,  3.90it/s]Loading train:   1%|          | 2/266 [00:00<01:06,  3.96it/s]Loading train:   1%|          | 3/266 [00:00<01:05,  4.02it/s]Loading train:   2%|▏         | 4/266 [00:00<01:04,  4.06it/s]Loading train:   2%|▏         | 5/266 [00:01<01:02,  4.20it/s]Loading train:   2%|▏         | 6/266 [00:01<01:00,  4.29it/s]Loading train:   3%|▎         | 7/266 [00:01<00:59,  4.36it/s]Loading train:   3%|▎         | 8/266 [00:01<00:58,  4.40it/s]Loading train:   3%|▎         | 9/266 [00:02<00:57,  4.44it/s]Loading train:   4%|▍         | 10/266 [00:02<00:57,  4.46it/s]Loading train:   4%|▍         | 11/266 [00:02<00:56,  4.50it/s]Loading train:   5%|▍         | 12/266 [00:02<00:56,  4.51it/s]Loading train:   5%|▍         | 13/266 [00:02<00:55,  4.52it/s]Loading train:   5%|▌         | 14/266 [00:03<00:56,  4.50it/s]Loading train:   6%|▌         | 15/266 [00:03<01:05,  3.81it/s]Loading train:   6%|▌         | 16/266 [00:03<01:13,  3.38it/s]Loading train:   6%|▋         | 17/266 [00:04<01:24,  2.95it/s]Loading train:   7%|▋         | 18/266 [00:05<02:28,  1.67it/s]Loading train:   7%|▋         | 19/266 [00:07<04:03,  1.02it/s]Loading train:   8%|▊         | 20/266 [00:08<03:36,  1.14it/s]Loading train:   8%|▊         | 21/266 [00:08<03:15,  1.25it/s]Loading train:   8%|▊         | 22/266 [00:09<03:22,  1.20it/s]Loading train:   9%|▊         | 23/266 [00:10<03:02,  1.33it/s]Loading train:   9%|▉         | 24/266 [00:10<02:52,  1.40it/s]Loading train:   9%|▉         | 25/266 [00:11<02:57,  1.36it/s]Loading train:  10%|▉         | 26/266 [00:12<03:05,  1.30it/s]Loading train:  10%|█         | 27/266 [00:13<02:56,  1.36it/s]Loading train:  11%|█         | 28/266 [00:14<03:25,  1.16it/s]Loading train:  11%|█         | 29/266 [00:14<03:10,  1.24it/s]Loading train:  11%|█▏        | 30/266 [00:15<02:57,  1.33it/s]Loading train:  12%|█▏        | 31/266 [00:16<02:49,  1.39it/s]Loading train:  12%|█▏        | 32/266 [00:16<02:42,  1.44it/s]Loading train:  12%|█▏        | 33/266 [00:17<02:39,  1.46it/s]Loading train:  13%|█▎        | 34/266 [00:18<02:35,  1.49it/s]Loading train:  13%|█▎        | 35/266 [00:18<02:30,  1.53it/s]Loading train:  14%|█▎        | 36/266 [00:19<02:53,  1.33it/s]Loading train:  14%|█▍        | 37/266 [00:21<03:37,  1.05it/s]Loading train:  14%|█▍        | 38/266 [00:22<03:53,  1.02s/it]Loading train:  15%|█▍        | 39/266 [00:24<04:52,  1.29s/it]Loading train:  15%|█▌        | 40/266 [00:24<03:55,  1.04s/it]Loading train:  15%|█▌        | 41/266 [00:25<03:33,  1.05it/s]Loading train:  16%|█▌        | 42/266 [00:26<03:08,  1.19it/s]Loading train:  16%|█▌        | 43/266 [00:27<03:27,  1.07it/s]Loading train:  17%|█▋        | 44/266 [00:28<03:50,  1.04s/it]Loading train:  17%|█▋        | 45/266 [00:29<03:19,  1.11it/s]Loading train:  17%|█▋        | 46/266 [00:29<03:08,  1.17it/s]Loading train:  18%|█▊        | 47/266 [00:31<03:48,  1.04s/it]Loading train:  18%|█▊        | 48/266 [00:32<04:17,  1.18s/it]Loading train:  18%|█▊        | 49/266 [00:33<04:17,  1.19s/it]Loading train:  19%|█▉        | 50/266 [00:35<04:07,  1.14s/it]Loading train:  19%|█▉        | 51/266 [00:36<04:28,  1.25s/it]Loading train:  20%|█▉        | 52/266 [00:37<04:33,  1.28s/it]Loading train:  20%|█▉        | 53/266 [00:39<04:43,  1.33s/it]Loading train:  20%|██        | 54/266 [00:40<04:37,  1.31s/it]Loading train:  21%|██        | 55/266 [00:41<04:25,  1.26s/it]Loading train:  21%|██        | 56/266 [00:43<04:55,  1.41s/it]Loading train:  21%|██▏       | 57/266 [00:44<04:44,  1.36s/it]Loading train:  22%|██▏       | 58/266 [00:46<04:55,  1.42s/it]Loading train:  22%|██▏       | 59/266 [00:47<04:40,  1.36s/it]Loading train:  23%|██▎       | 60/266 [00:48<04:27,  1.30s/it]Loading train:  23%|██▎       | 61/266 [00:49<04:05,  1.20s/it]Loading train:  23%|██▎       | 62/266 [00:50<04:00,  1.18s/it]Loading train:  24%|██▎       | 63/266 [00:52<04:15,  1.26s/it]Loading train:  24%|██▍       | 64/266 [00:53<04:27,  1.32s/it]Loading train:  24%|██▍       | 65/266 [00:54<04:19,  1.29s/it]Loading train:  25%|██▍       | 66/266 [00:56<04:28,  1.34s/it]Loading train:  25%|██▌       | 67/266 [00:57<04:03,  1.22s/it]Loading train:  26%|██▌       | 68/266 [00:58<04:19,  1.31s/it]Loading train:  26%|██▌       | 69/266 [01:00<04:22,  1.33s/it]Loading train:  26%|██▋       | 70/266 [01:01<04:25,  1.35s/it]Loading train:  27%|██▋       | 71/266 [01:02<04:10,  1.28s/it]Loading train:  27%|██▋       | 72/266 [01:03<03:58,  1.23s/it]Loading train:  27%|██▋       | 73/266 [01:04<03:49,  1.19s/it]Loading train:  28%|██▊       | 74/266 [01:05<03:40,  1.15s/it]Loading train:  28%|██▊       | 75/266 [01:07<04:03,  1.28s/it]Loading train:  29%|██▊       | 76/266 [01:08<04:11,  1.32s/it]Loading train:  29%|██▉       | 77/266 [01:10<04:30,  1.43s/it]Loading train:  29%|██▉       | 78/266 [01:12<04:44,  1.51s/it]Loading train:  30%|██▉       | 79/266 [01:13<04:20,  1.39s/it]Loading train:  30%|███       | 80/266 [01:14<03:57,  1.28s/it]Loading train:  30%|███       | 81/266 [01:15<03:47,  1.23s/it]Loading train:  31%|███       | 82/266 [01:16<03:41,  1.20s/it]Loading train:  31%|███       | 83/266 [01:17<03:40,  1.21s/it]Loading train:  32%|███▏      | 84/266 [01:19<03:35,  1.18s/it]Loading train:  32%|███▏      | 85/266 [01:19<03:14,  1.08s/it]Loading train:  32%|███▏      | 86/266 [01:21<03:23,  1.13s/it]Loading train:  33%|███▎      | 87/266 [01:22<03:39,  1.23s/it]Loading train:  33%|███▎      | 88/266 [01:24<03:52,  1.31s/it]Loading train:  33%|███▎      | 89/266 [01:25<03:40,  1.24s/it]Loading train:  34%|███▍      | 90/266 [01:26<03:39,  1.25s/it]Loading train:  34%|███▍      | 91/266 [01:27<03:31,  1.21s/it]Loading train:  35%|███▍      | 92/266 [01:28<03:28,  1.20s/it]Loading train:  35%|███▍      | 93/266 [01:29<03:29,  1.21s/it]Loading train:  35%|███▌      | 94/266 [01:31<03:27,  1.20s/it]Loading train:  36%|███▌      | 95/266 [01:32<03:19,  1.17s/it]Loading train:  36%|███▌      | 96/266 [01:33<03:27,  1.22s/it]Loading train:  36%|███▋      | 97/266 [01:34<03:01,  1.07s/it]Loading train:  37%|███▋      | 98/266 [01:35<03:15,  1.17s/it]Loading train:  37%|███▋      | 99/266 [01:36<03:11,  1.15s/it]Loading train:  38%|███▊      | 100/266 [01:37<02:56,  1.06s/it]Loading train:  38%|███▊      | 101/266 [01:38<02:48,  1.02s/it]Loading train:  38%|███▊      | 102/266 [01:39<02:49,  1.03s/it]Loading train:  39%|███▊      | 103/266 [01:40<02:44,  1.01s/it]Loading train:  39%|███▉      | 104/266 [01:41<02:51,  1.06s/it]Loading train:  39%|███▉      | 105/266 [01:42<02:43,  1.01s/it]Loading train:  40%|███▉      | 106/266 [01:43<02:47,  1.05s/it]Loading train:  40%|████      | 107/266 [01:44<02:31,  1.05it/s]Loading train:  41%|████      | 108/266 [01:45<02:22,  1.11it/s]Loading train:  41%|████      | 109/266 [01:46<02:37,  1.00s/it]Loading train:  41%|████▏     | 110/266 [01:47<02:46,  1.07s/it]Loading train:  42%|████▏     | 111/266 [01:48<02:41,  1.04s/it]Loading train:  42%|████▏     | 112/266 [01:49<02:34,  1.00s/it]Loading train:  42%|████▏     | 113/266 [01:50<02:46,  1.09s/it]Loading train:  43%|████▎     | 114/266 [01:51<02:30,  1.01it/s]Loading train:  43%|████▎     | 115/266 [01:52<02:17,  1.10it/s]Loading train:  44%|████▎     | 116/266 [01:53<02:10,  1.15it/s]Loading train:  44%|████▍     | 117/266 [01:54<02:05,  1.19it/s]Loading train:  44%|████▍     | 118/266 [01:54<01:51,  1.33it/s]Loading train:  45%|████▍     | 119/266 [01:55<01:45,  1.39it/s]Loading train:  45%|████▌     | 120/266 [01:56<01:56,  1.26it/s]Loading train:  45%|████▌     | 121/266 [01:57<02:04,  1.16it/s]Loading train:  46%|████▌     | 122/266 [01:58<02:07,  1.13it/s]Loading train:  46%|████▌     | 123/266 [01:59<02:10,  1.10it/s]Loading train:  47%|████▋     | 124/266 [01:59<02:08,  1.11it/s]Loading train:  47%|████▋     | 125/266 [02:00<02:00,  1.17it/s]Loading train:  47%|████▋     | 126/266 [02:01<02:00,  1.16it/s]Loading train:  48%|████▊     | 127/266 [02:02<02:01,  1.15it/s]Loading train:  48%|████▊     | 128/266 [02:03<01:59,  1.16it/s]Loading train:  48%|████▊     | 129/266 [02:04<01:56,  1.17it/s]Loading train:  49%|████▉     | 130/266 [02:05<01:58,  1.15it/s]Loading train:  49%|████▉     | 131/266 [02:05<01:51,  1.21it/s]Loading train:  50%|████▉     | 132/266 [02:06<01:51,  1.20it/s]Loading train:  50%|█████     | 133/266 [02:07<01:44,  1.27it/s]Loading train:  50%|█████     | 134/266 [02:08<01:51,  1.18it/s]Loading train:  51%|█████     | 135/266 [02:09<01:48,  1.21it/s]Loading train:  51%|█████     | 136/266 [02:09<01:48,  1.20it/s]Loading train:  52%|█████▏    | 137/266 [02:11<01:57,  1.10it/s]Loading train:  52%|█████▏    | 138/266 [02:12<01:58,  1.08it/s]Loading train:  52%|█████▏    | 139/266 [02:12<01:51,  1.14it/s]Loading train:  53%|█████▎    | 140/266 [02:13<01:41,  1.24it/s]Loading train:  53%|█████▎    | 141/266 [02:14<01:38,  1.27it/s]Loading train:  53%|█████▎    | 142/266 [02:15<01:41,  1.22it/s]Loading train:  54%|█████▍    | 143/266 [02:15<01:40,  1.22it/s]Loading train:  54%|█████▍    | 144/266 [02:16<01:37,  1.25it/s]Loading train:  55%|█████▍    | 145/266 [02:17<01:33,  1.29it/s]Loading train:  55%|█████▍    | 146/266 [02:18<01:32,  1.30it/s]Loading train:  55%|█████▌    | 147/266 [02:18<01:33,  1.27it/s]Loading train:  56%|█████▌    | 148/266 [02:19<01:32,  1.28it/s]Loading train:  56%|█████▌    | 149/266 [02:20<01:25,  1.37it/s]Loading train:  56%|█████▋    | 150/266 [02:21<01:28,  1.32it/s]Loading train:  57%|█████▋    | 151/266 [02:21<01:24,  1.35it/s]Loading train:  57%|█████▋    | 152/266 [02:22<01:21,  1.40it/s]Loading train:  58%|█████▊    | 153/266 [02:23<01:24,  1.34it/s]Loading train:  58%|█████▊    | 154/266 [02:24<01:22,  1.35it/s]Loading train:  58%|█████▊    | 155/266 [02:25<01:30,  1.22it/s]Loading train:  59%|█████▊    | 156/266 [02:25<01:29,  1.23it/s]Loading train:  59%|█████▉    | 157/266 [02:26<01:31,  1.19it/s]Loading train:  59%|█████▉    | 158/266 [02:27<01:40,  1.07it/s]Loading train:  60%|█████▉    | 159/266 [02:28<01:37,  1.09it/s]Loading train:  60%|██████    | 160/266 [02:29<01:33,  1.13it/s]Loading train:  61%|██████    | 161/266 [02:30<01:40,  1.05it/s]Loading train:  61%|██████    | 162/266 [02:31<01:32,  1.12it/s]Loading train:  61%|██████▏   | 163/266 [02:32<01:39,  1.03it/s]Loading train:  62%|██████▏   | 164/266 [02:33<01:43,  1.01s/it]Loading train:  62%|██████▏   | 165/266 [02:34<01:47,  1.06s/it]Loading train:  62%|██████▏   | 166/266 [02:35<01:45,  1.05s/it]Loading train:  63%|██████▎   | 167/266 [02:36<01:44,  1.05s/it]Loading train:  63%|██████▎   | 168/266 [02:37<01:42,  1.05s/it]Loading train:  64%|██████▎   | 169/266 [02:38<01:36,  1.00it/s]Loading train:  64%|██████▍   | 170/266 [02:39<01:35,  1.00it/s]Loading train:  64%|██████▍   | 171/266 [02:40<01:32,  1.03it/s]Loading train:  65%|██████▍   | 172/266 [02:41<01:28,  1.06it/s]Loading train:  65%|██████▌   | 173/266 [02:43<01:51,  1.20s/it]Loading train:  65%|██████▌   | 174/266 [02:44<01:46,  1.16s/it]Loading train:  66%|██████▌   | 175/266 [02:45<01:34,  1.04s/it]Loading train:  66%|██████▌   | 176/266 [02:46<01:26,  1.04it/s]Loading train:  67%|██████▋   | 177/266 [02:46<01:16,  1.17it/s]Loading train:  67%|██████▋   | 178/266 [02:47<01:15,  1.17it/s]Loading train:  67%|██████▋   | 179/266 [02:48<01:09,  1.24it/s]Loading train:  68%|██████▊   | 180/266 [02:48<01:08,  1.26it/s]Loading train:  68%|██████▊   | 181/266 [02:49<01:12,  1.17it/s]Loading train:  68%|██████▊   | 182/266 [02:50<01:11,  1.18it/s]Loading train:  69%|██████▉   | 183/266 [02:51<01:16,  1.09it/s]Loading train:  69%|██████▉   | 184/266 [02:52<01:14,  1.10it/s]Loading train:  70%|██████▉   | 185/266 [02:53<01:15,  1.07it/s]Loading train:  70%|██████▉   | 186/266 [02:54<01:15,  1.07it/s]Loading train:  70%|███████   | 187/266 [02:55<01:07,  1.17it/s]Loading train:  71%|███████   | 188/266 [02:56<01:03,  1.23it/s]Loading train:  71%|███████   | 189/266 [02:56<01:03,  1.21it/s]Loading train:  71%|███████▏  | 190/266 [02:57<01:05,  1.16it/s]Loading train:  72%|███████▏  | 191/266 [02:58<01:01,  1.21it/s]Loading train:  72%|███████▏  | 192/266 [02:59<01:05,  1.12it/s]Loading train:  73%|███████▎  | 193/266 [03:00<01:06,  1.10it/s]Loading train:  73%|███████▎  | 194/266 [03:01<00:59,  1.20it/s]Loading train:  73%|███████▎  | 195/266 [03:01<00:55,  1.27it/s]Loading train:  74%|███████▎  | 196/266 [03:02<00:55,  1.25it/s]Loading train:  74%|███████▍  | 197/266 [03:03<00:57,  1.20it/s]Loading train:  74%|███████▍  | 198/266 [03:04<00:57,  1.18it/s]Loading train:  75%|███████▍  | 199/266 [03:05<00:57,  1.16it/s]Loading train:  75%|███████▌  | 200/266 [03:06<00:56,  1.16it/s]Loading train:  76%|███████▌  | 201/266 [03:07<00:56,  1.14it/s]Loading train:  76%|███████▌  | 202/266 [03:08<00:56,  1.13it/s]Loading train:  76%|███████▋  | 203/266 [03:08<00:52,  1.21it/s]Loading train:  77%|███████▋  | 204/266 [03:09<00:51,  1.21it/s]Loading train:  77%|███████▋  | 205/266 [03:10<00:48,  1.25it/s]Loading train:  77%|███████▋  | 206/266 [03:11<00:48,  1.23it/s]Loading train:  78%|███████▊  | 207/266 [03:12<00:47,  1.24it/s]Loading train:  78%|███████▊  | 208/266 [03:12<00:46,  1.25it/s]Loading train:  79%|███████▊  | 209/266 [03:13<00:46,  1.22it/s]Loading train:  79%|███████▉  | 210/266 [03:14<00:45,  1.23it/s]Loading train:  79%|███████▉  | 211/266 [03:15<00:43,  1.25it/s]Loading train:  80%|███████▉  | 212/266 [03:16<00:43,  1.24it/s]Loading train:  80%|████████  | 213/266 [03:16<00:41,  1.28it/s]Loading train:  80%|████████  | 214/266 [03:17<00:38,  1.33it/s]Loading train:  81%|████████  | 215/266 [03:18<00:37,  1.38it/s]Loading train:  81%|████████  | 216/266 [03:18<00:35,  1.41it/s]Loading train:  82%|████████▏ | 217/266 [03:19<00:34,  1.43it/s]Loading train:  82%|████████▏ | 218/266 [03:20<00:33,  1.42it/s]Loading train:  82%|████████▏ | 219/266 [03:20<00:32,  1.45it/s]Loading train:  83%|████████▎ | 220/266 [03:21<00:31,  1.46it/s]Loading train:  83%|████████▎ | 221/266 [03:22<00:31,  1.41it/s]Loading train:  83%|████████▎ | 222/266 [03:22<00:29,  1.48it/s]Loading train:  84%|████████▍ | 223/266 [03:23<00:29,  1.47it/s]Loading train:  84%|████████▍ | 224/266 [03:24<00:29,  1.45it/s]Loading train:  85%|████████▍ | 225/266 [03:24<00:28,  1.46it/s]Loading train:  85%|████████▍ | 226/266 [03:25<00:27,  1.46it/s]Loading train:  85%|████████▌ | 227/266 [03:26<00:26,  1.49it/s]Loading train:  86%|████████▌ | 228/266 [03:26<00:24,  1.54it/s]Loading train:  86%|████████▌ | 229/266 [03:27<00:24,  1.54it/s]Loading train:  86%|████████▋ | 230/266 [03:28<00:23,  1.53it/s]Loading train:  87%|████████▋ | 231/266 [03:28<00:21,  1.61it/s]Loading train:  87%|████████▋ | 232/266 [03:29<00:20,  1.69it/s]Loading train:  88%|████████▊ | 233/266 [03:29<00:18,  1.74it/s]Loading train:  88%|████████▊ | 234/266 [03:30<00:17,  1.81it/s]Loading train:  88%|████████▊ | 235/266 [03:30<00:17,  1.80it/s]Loading train:  89%|████████▊ | 236/266 [03:31<00:16,  1.81it/s]Loading train:  89%|████████▉ | 237/266 [03:32<00:16,  1.77it/s]Loading train:  89%|████████▉ | 238/266 [03:32<00:15,  1.81it/s]Loading train:  90%|████████▉ | 239/266 [03:33<00:15,  1.76it/s]Loading train:  90%|█████████ | 240/266 [03:33<00:14,  1.77it/s]Loading train:  91%|█████████ | 241/266 [03:34<00:13,  1.79it/s]Loading train:  91%|█████████ | 242/266 [03:34<00:13,  1.85it/s]Loading train:  91%|█████████▏| 243/266 [03:35<00:12,  1.79it/s]Loading train:  92%|█████████▏| 244/266 [03:35<00:12,  1.81it/s]Loading train:  92%|█████████▏| 245/266 [03:36<00:11,  1.81it/s]Loading train:  92%|█████████▏| 246/266 [03:36<00:10,  1.83it/s]Loading train:  93%|█████████▎| 247/266 [03:37<00:10,  1.82it/s]Loading train:  93%|█████████▎| 248/266 [03:38<00:09,  1.83it/s]Loading train:  94%|█████████▎| 249/266 [03:38<00:09,  1.71it/s]Loading train:  94%|█████████▍| 250/266 [03:39<00:09,  1.64it/s]Loading train:  94%|█████████▍| 251/266 [03:40<00:09,  1.65it/s]Loading train:  95%|█████████▍| 252/266 [03:40<00:08,  1.60it/s]Loading train:  95%|█████████▌| 253/266 [03:41<00:08,  1.59it/s]Loading train:  95%|█████████▌| 254/266 [03:41<00:07,  1.61it/s]Loading train:  96%|█████████▌| 255/266 [03:42<00:06,  1.62it/s]Loading train:  96%|█████████▌| 256/266 [03:43<00:06,  1.58it/s]Loading train:  97%|█████████▋| 257/266 [03:43<00:05,  1.58it/s]Loading train:  97%|█████████▋| 258/266 [03:44<00:05,  1.57it/s]Loading train:  97%|█████████▋| 259/266 [03:45<00:04,  1.61it/s]Loading train:  98%|█████████▊| 260/266 [03:45<00:03,  1.61it/s]Loading train:  98%|█████████▊| 261/266 [03:46<00:03,  1.62it/s]Loading train:  98%|█████████▊| 262/266 [03:46<00:02,  1.66it/s]Loading train:  99%|█████████▉| 263/266 [03:47<00:01,  1.71it/s]Loading train:  99%|█████████▉| 264/266 [03:48<00:01,  1.66it/s]Loading train: 100%|█████████▉| 265/266 [03:48<00:00,  1.67it/s]Loading train: 100%|██████████| 266/266 [03:49<00:00,  1.62it/s]Loading train: 100%|██████████| 266/266 [03:49<00:00,  1.16it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 52.05it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 54.04it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 53.30it/s]concatenating: train:   8%|▊         | 22/266 [00:00<00:05, 47.46it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:05, 45.94it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:05, 46.31it/s]concatenating: train:  14%|█▍        | 37/266 [00:00<00:04, 46.79it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:04, 46.46it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:04, 47.61it/s]concatenating: train:  20%|█▉        | 53/266 [00:01<00:04, 45.21it/s]concatenating: train:  22%|██▏       | 58/266 [00:01<00:05, 41.54it/s]concatenating: train:  24%|██▎       | 63/266 [00:01<00:04, 42.73it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:04, 41.69it/s]concatenating: train:  27%|██▋       | 73/266 [00:01<00:04, 40.26it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:04, 40.03it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:04, 40.97it/s]concatenating: train:  33%|███▎      | 88/266 [00:02<00:04, 37.11it/s]concatenating: train:  35%|███▍      | 93/266 [00:02<00:04, 37.96it/s]concatenating: train:  36%|███▋      | 97/266 [00:02<00:04, 36.94it/s]concatenating: train:  38%|███▊      | 101/266 [00:02<00:04, 37.19it/s]concatenating: train:  39%|███▉      | 105/266 [00:02<00:04, 36.96it/s]concatenating: train:  41%|████▏     | 110/266 [00:02<00:04, 38.38it/s]concatenating: train:  43%|████▎     | 115/266 [00:02<00:04, 37.41it/s]concatenating: train:  45%|████▍     | 119/266 [00:02<00:04, 34.62it/s]concatenating: train:  47%|████▋     | 124/266 [00:02<00:03, 37.92it/s]concatenating: train:  49%|████▉     | 130/266 [00:03<00:03, 41.00it/s]concatenating: train:  51%|█████     | 135/266 [00:03<00:03, 40.37it/s]concatenating: train:  53%|█████▎    | 140/266 [00:03<00:03, 40.61it/s]concatenating: train:  55%|█████▍    | 145/266 [00:03<00:02, 41.38it/s]concatenating: train:  56%|█████▋    | 150/266 [00:03<00:02, 42.26it/s]concatenating: train:  58%|█████▊    | 155/266 [00:03<00:02, 42.41it/s]concatenating: train:  60%|██████    | 160/266 [00:03<00:02, 42.74it/s]concatenating: train:  62%|██████▏   | 165/266 [00:03<00:02, 43.36it/s]concatenating: train:  64%|██████▍   | 170/266 [00:04<00:02, 41.06it/s]concatenating: train:  66%|██████▌   | 175/266 [00:04<00:02, 41.93it/s]concatenating: train:  68%|██████▊   | 180/266 [00:04<00:02, 41.78it/s]concatenating: train:  70%|██████▉   | 185/266 [00:04<00:01, 43.76it/s]concatenating: train:  71%|███████▏  | 190/266 [00:04<00:01, 43.86it/s]concatenating: train:  73%|███████▎  | 195/266 [00:04<00:01, 43.70it/s]concatenating: train:  75%|███████▌  | 200/266 [00:04<00:01, 42.48it/s]concatenating: train:  77%|███████▋  | 205/266 [00:04<00:01, 40.93it/s]concatenating: train:  79%|███████▉  | 210/266 [00:05<00:01, 41.18it/s]concatenating: train:  81%|████████  | 215/266 [00:05<00:01, 41.82it/s]concatenating: train:  83%|████████▎ | 220/266 [00:05<00:01, 41.26it/s]concatenating: train:  85%|████████▍ | 225/266 [00:05<00:00, 41.94it/s]concatenating: train:  86%|████████▋ | 230/266 [00:05<00:00, 39.74it/s]concatenating: train:  88%|████████▊ | 235/266 [00:05<00:00, 41.30it/s]concatenating: train:  90%|█████████ | 240/266 [00:05<00:00, 43.49it/s]concatenating: train:  92%|█████████▏| 245/266 [00:05<00:00, 45.12it/s]concatenating: train:  94%|█████████▍| 250/266 [00:05<00:00, 46.09it/s]concatenating: train:  96%|█████████▌| 255/266 [00:06<00:00, 46.79it/s]concatenating: train:  98%|█████████▊| 260/266 [00:06<00:00, 44.63it/s]concatenating: train: 100%|█████████▉| 265/266 [00:06<00:00, 44.85it/s]concatenating: train: 100%|██████████| 266/266 [00:06<00:00, 42.33it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:01,  1.87it/s]Loading test:  50%|█████     | 2/4 [00:01<00:01,  1.92it/s]Loading test:  75%|███████▌  | 3/4 [00:01<00:00,  1.90it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.84it/s]Loading test: 100%|██████████| 4/4 [00:02<00:00,  1.86it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 71.80it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<02:39,  1.66it/s]Loading trainS:   1%|          | 2/266 [00:01<02:33,  1.72it/s]Loading trainS:   1%|          | 3/266 [00:01<02:33,  1.71it/s]Loading trainS:   2%|▏         | 4/266 [00:02<02:34,  1.70it/s]Loading trainS:   2%|▏         | 5/266 [00:02<02:29,  1.74it/s]Loading trainS:   2%|▏         | 6/266 [00:03<02:28,  1.75it/s]Loading trainS:   3%|▎         | 7/266 [00:03<02:26,  1.77it/s]Loading trainS:   3%|▎         | 8/266 [00:04<02:24,  1.78it/s]Loading trainS:   3%|▎         | 9/266 [00:05<02:27,  1.75it/s]Loading trainS:   4%|▍         | 10/266 [00:05<02:22,  1.80it/s]Loading trainS:   4%|▍         | 11/266 [00:06<02:18,  1.85it/s]Loading trainS:   5%|▍         | 12/266 [00:06<02:09,  1.96it/s]Loading trainS:   5%|▍         | 13/266 [00:07<02:06,  2.00it/s]Loading trainS:   5%|▌         | 14/266 [00:07<02:15,  1.86it/s]Loading trainS:   6%|▌         | 15/266 [00:08<02:15,  1.85it/s]Loading trainS:   6%|▌         | 16/266 [00:08<02:23,  1.74it/s]Loading trainS:   6%|▋         | 17/266 [00:09<02:20,  1.77it/s]Loading trainS:   7%|▋         | 18/266 [00:10<02:20,  1.77it/s]Loading trainS:   7%|▋         | 19/266 [00:10<02:24,  1.71it/s]Loading trainS:   8%|▊         | 20/266 [00:11<02:21,  1.74it/s]Loading trainS:   8%|▊         | 21/266 [00:11<02:23,  1.71it/s]Loading trainS:   8%|▊         | 22/266 [00:12<02:21,  1.72it/s]Loading trainS:   9%|▊         | 23/266 [00:12<02:16,  1.78it/s]Loading trainS:   9%|▉         | 24/266 [00:13<02:14,  1.80it/s]Loading trainS:   9%|▉         | 25/266 [00:13<02:14,  1.80it/s]Loading trainS:  10%|▉         | 26/266 [00:14<02:08,  1.87it/s]Loading trainS:  10%|█         | 27/266 [00:14<02:06,  1.90it/s]Loading trainS:  11%|█         | 28/266 [00:15<02:08,  1.86it/s]Loading trainS:  11%|█         | 29/266 [00:16<02:08,  1.84it/s]Loading trainS:  11%|█▏        | 30/266 [00:16<02:09,  1.82it/s]Loading trainS:  12%|█▏        | 31/266 [00:17<02:10,  1.80it/s]Loading trainS:  12%|█▏        | 32/266 [00:17<02:10,  1.79it/s]Loading trainS:  12%|█▏        | 33/266 [00:18<02:09,  1.81it/s]Loading trainS:  13%|█▎        | 34/266 [00:18<02:02,  1.89it/s]Loading trainS:  13%|█▎        | 35/266 [00:19<02:06,  1.82it/s]Loading trainS:  14%|█▎        | 36/266 [00:19<02:07,  1.80it/s]Loading trainS:  14%|█▍        | 37/266 [00:20<02:08,  1.78it/s]Loading trainS:  14%|█▍        | 38/266 [00:21<02:04,  1.83it/s]Loading trainS:  15%|█▍        | 39/266 [00:21<02:00,  1.88it/s]Loading trainS:  15%|█▌        | 40/266 [00:22<01:56,  1.94it/s]Loading trainS:  15%|█▌        | 41/266 [00:22<01:56,  1.94it/s]Loading trainS:  16%|█▌        | 42/266 [00:23<02:02,  1.83it/s]Loading trainS:  16%|█▌        | 43/266 [00:23<02:02,  1.82it/s]Loading trainS:  17%|█▋        | 44/266 [00:24<02:01,  1.83it/s]Loading trainS:  17%|█▋        | 45/266 [00:24<02:03,  1.79it/s]Loading trainS:  17%|█▋        | 46/266 [00:25<01:56,  1.89it/s]Loading trainS:  18%|█▊        | 47/266 [00:25<01:55,  1.89it/s]Loading trainS:  18%|█▊        | 48/266 [00:26<01:51,  1.95it/s]Loading trainS:  18%|█▊        | 49/266 [00:26<01:50,  1.97it/s]Loading trainS:  19%|█▉        | 50/266 [00:27<01:47,  2.00it/s]Loading trainS:  19%|█▉        | 51/266 [00:27<01:47,  1.99it/s]Loading trainS:  20%|█▉        | 52/266 [00:28<01:51,  1.92it/s]Loading trainS:  20%|█▉        | 53/266 [00:28<01:52,  1.90it/s]Loading trainS:  20%|██        | 54/266 [00:29<01:49,  1.93it/s]Loading trainS:  21%|██        | 55/266 [00:29<01:48,  1.95it/s]Loading trainS:  21%|██        | 56/266 [00:30<01:48,  1.93it/s]Loading trainS:  21%|██▏       | 57/266 [00:30<01:50,  1.88it/s]Loading trainS:  22%|██▏       | 58/266 [00:31<01:51,  1.87it/s]Loading trainS:  22%|██▏       | 59/266 [00:32<01:51,  1.86it/s]Loading trainS:  23%|██▎       | 60/266 [00:32<01:49,  1.88it/s]Loading trainS:  23%|██▎       | 61/266 [00:33<01:52,  1.82it/s]Loading trainS:  23%|██▎       | 62/266 [00:33<01:54,  1.78it/s]Loading trainS:  24%|██▎       | 63/266 [00:34<01:54,  1.78it/s]Loading trainS:  24%|██▍       | 64/266 [00:34<01:54,  1.76it/s]Loading trainS:  24%|██▍       | 65/266 [00:35<01:52,  1.78it/s]Loading trainS:  25%|██▍       | 66/266 [00:35<01:49,  1.83it/s]Loading trainS:  25%|██▌       | 67/266 [00:36<01:45,  1.89it/s]Loading trainS:  26%|██▌       | 68/266 [00:36<01:42,  1.93it/s]Loading trainS:  26%|██▌       | 69/266 [00:37<01:45,  1.88it/s]Loading trainS:  26%|██▋       | 70/266 [00:38<01:44,  1.88it/s]Loading trainS:  27%|██▋       | 71/266 [00:38<01:43,  1.88it/s]Loading trainS:  27%|██▋       | 72/266 [00:39<01:45,  1.84it/s]Loading trainS:  27%|██▋       | 73/266 [00:39<01:44,  1.84it/s]Loading trainS:  28%|██▊       | 74/266 [00:40<01:48,  1.77it/s]Loading trainS:  28%|██▊       | 75/266 [00:40<01:45,  1.81it/s]Loading trainS:  29%|██▊       | 76/266 [00:41<01:41,  1.87it/s]Loading trainS:  29%|██▉       | 77/266 [00:41<01:47,  1.75it/s]Loading trainS:  29%|██▉       | 78/266 [00:42<01:48,  1.73it/s]Loading trainS:  30%|██▉       | 79/266 [00:43<01:46,  1.76it/s]Loading trainS:  30%|███       | 80/266 [00:43<01:38,  1.88it/s]Loading trainS:  30%|███       | 81/266 [00:44<01:39,  1.85it/s]Loading trainS:  31%|███       | 82/266 [00:44<01:41,  1.80it/s]Loading trainS:  31%|███       | 83/266 [00:45<01:46,  1.73it/s]Loading trainS:  32%|███▏      | 84/266 [00:45<01:48,  1.68it/s]Loading trainS:  32%|███▏      | 85/266 [00:46<01:47,  1.68it/s]Loading trainS:  32%|███▏      | 86/266 [00:47<01:49,  1.65it/s]Loading trainS:  33%|███▎      | 87/266 [00:47<01:47,  1.66it/s]Loading trainS:  33%|███▎      | 88/266 [00:48<01:42,  1.73it/s]Loading trainS:  33%|███▎      | 89/266 [00:48<01:43,  1.71it/s]Loading trainS:  34%|███▍      | 90/266 [00:49<01:42,  1.71it/s]Loading trainS:  34%|███▍      | 91/266 [00:50<01:39,  1.76it/s]Loading trainS:  35%|███▍      | 92/266 [00:50<01:41,  1.72it/s]Loading trainS:  35%|███▍      | 93/266 [00:51<01:45,  1.64it/s]Loading trainS:  35%|███▌      | 94/266 [00:51<01:40,  1.71it/s]Loading trainS:  36%|███▌      | 95/266 [00:52<01:40,  1.70it/s]Loading trainS:  36%|███▌      | 96/266 [00:53<01:41,  1.67it/s]Loading trainS:  36%|███▋      | 97/266 [00:53<01:46,  1.59it/s]Loading trainS:  37%|███▋      | 98/266 [00:54<01:47,  1.56it/s]Loading trainS:  37%|███▋      | 99/266 [00:55<01:44,  1.60it/s]Loading trainS:  38%|███▊      | 100/266 [00:55<01:38,  1.69it/s]Loading trainS:  38%|███▊      | 101/266 [00:56<01:40,  1.64it/s]Loading trainS:  38%|███▊      | 102/266 [00:56<01:41,  1.61it/s]Loading trainS:  39%|███▊      | 103/266 [00:57<01:39,  1.63it/s]Loading trainS:  39%|███▉      | 104/266 [00:58<01:37,  1.66it/s]Loading trainS:  39%|███▉      | 105/266 [00:58<01:34,  1.70it/s]Loading trainS:  40%|███▉      | 106/266 [00:59<01:36,  1.66it/s]Loading trainS:  40%|████      | 107/266 [00:59<01:31,  1.74it/s]Loading trainS:  41%|████      | 108/266 [01:00<01:34,  1.67it/s]Loading trainS:  41%|████      | 109/266 [01:01<01:37,  1.62it/s]Loading trainS:  41%|████▏     | 110/266 [01:01<01:34,  1.64it/s]Loading trainS:  42%|████▏     | 111/266 [01:02<01:32,  1.67it/s]Loading trainS:  42%|████▏     | 112/266 [01:02<01:38,  1.57it/s]Loading trainS:  42%|████▏     | 113/266 [01:03<01:34,  1.62it/s]Loading trainS:  43%|████▎     | 114/266 [01:04<01:30,  1.68it/s]Loading trainS:  43%|████▎     | 115/266 [01:04<01:28,  1.70it/s]Loading trainS:  44%|████▎     | 116/266 [01:05<01:32,  1.62it/s]Loading trainS:  44%|████▍     | 117/266 [01:05<01:32,  1.60it/s]Loading trainS:  44%|████▍     | 118/266 [01:06<01:25,  1.74it/s]Loading trainS:  45%|████▍     | 119/266 [01:06<01:18,  1.87it/s]Loading trainS:  45%|████▌     | 120/266 [01:07<01:17,  1.89it/s]Loading trainS:  45%|████▌     | 121/266 [01:07<01:16,  1.90it/s]Loading trainS:  46%|████▌     | 122/266 [01:08<01:18,  1.83it/s]Loading trainS:  46%|████▌     | 123/266 [01:09<01:20,  1.79it/s]Loading trainS:  47%|████▋     | 124/266 [01:09<01:15,  1.89it/s]Loading trainS:  47%|████▋     | 125/266 [01:09<01:10,  2.01it/s]Loading trainS:  47%|████▋     | 126/266 [01:10<01:14,  1.88it/s]Loading trainS:  48%|████▊     | 127/266 [01:11<01:11,  1.95it/s]Loading trainS:  48%|████▊     | 128/266 [01:11<01:12,  1.90it/s]Loading trainS:  48%|████▊     | 129/266 [01:12<01:09,  1.98it/s]Loading trainS:  49%|████▉     | 130/266 [01:12<01:07,  2.01it/s]Loading trainS:  49%|████▉     | 131/266 [01:13<01:09,  1.93it/s]Loading trainS:  50%|████▉     | 132/266 [01:13<01:07,  1.97it/s]Loading trainS:  50%|█████     | 133/266 [01:14<01:06,  2.01it/s]Loading trainS:  50%|█████     | 134/266 [01:14<01:05,  2.02it/s]Loading trainS:  51%|█████     | 135/266 [01:14<01:02,  2.10it/s]Loading trainS:  51%|█████     | 136/266 [01:15<01:05,  1.99it/s]Loading trainS:  52%|█████▏    | 137/266 [01:16<01:11,  1.80it/s]Loading trainS:  52%|█████▏    | 138/266 [01:16<01:08,  1.87it/s]Loading trainS:  52%|█████▏    | 139/266 [01:17<01:07,  1.87it/s]Loading trainS:  53%|█████▎    | 140/266 [01:17<01:07,  1.86it/s]Loading trainS:  53%|█████▎    | 141/266 [01:18<01:08,  1.83it/s]Loading trainS:  53%|█████▎    | 142/266 [01:18<01:07,  1.85it/s]Loading trainS:  54%|█████▍    | 143/266 [01:19<01:02,  1.95it/s]Loading trainS:  54%|█████▍    | 144/266 [01:19<01:03,  1.91it/s]Loading trainS:  55%|█████▍    | 145/266 [01:20<01:05,  1.85it/s]Loading trainS:  55%|█████▍    | 146/266 [01:20<01:02,  1.92it/s]Loading trainS:  55%|█████▌    | 147/266 [01:21<01:02,  1.90it/s]Loading trainS:  56%|█████▌    | 148/266 [01:21<01:00,  1.94it/s]Loading trainS:  56%|█████▌    | 149/266 [01:22<00:59,  1.96it/s]Loading trainS:  56%|█████▋    | 150/266 [01:22<00:57,  2.00it/s]Loading trainS:  57%|█████▋    | 151/266 [01:23<00:58,  1.97it/s]Loading trainS:  57%|█████▋    | 152/266 [01:23<00:59,  1.92it/s]Loading trainS:  58%|█████▊    | 153/266 [01:24<00:57,  1.96it/s]Loading trainS:  58%|█████▊    | 154/266 [01:25<01:01,  1.83it/s]Loading trainS:  58%|█████▊    | 155/266 [01:25<01:01,  1.79it/s]Loading trainS:  59%|█████▊    | 156/266 [01:26<01:14,  1.49it/s]Loading trainS:  59%|█████▉    | 157/266 [01:27<01:15,  1.45it/s]Loading trainS:  59%|█████▉    | 158/266 [01:28<01:15,  1.44it/s]Loading trainS:  60%|█████▉    | 159/266 [01:28<01:18,  1.36it/s]Loading trainS:  60%|██████    | 160/266 [01:29<01:19,  1.34it/s]Loading trainS:  61%|██████    | 161/266 [01:30<01:20,  1.30it/s]Loading trainS:  61%|██████    | 162/266 [01:31<01:23,  1.25it/s]Loading trainS:  61%|██████▏   | 163/266 [01:32<01:18,  1.31it/s]Loading trainS:  62%|██████▏   | 164/266 [01:32<01:20,  1.26it/s]Loading trainS:  62%|██████▏   | 165/266 [01:33<01:15,  1.34it/s]Loading trainS:  62%|██████▏   | 166/266 [01:34<01:16,  1.30it/s]Loading trainS:  63%|██████▎   | 167/266 [01:35<01:15,  1.32it/s]Loading trainS:  63%|██████▎   | 168/266 [01:35<01:15,  1.30it/s]Loading trainS:  64%|██████▎   | 169/266 [01:36<01:09,  1.40it/s]Loading trainS:  64%|██████▍   | 170/266 [01:37<01:12,  1.32it/s]Loading trainS:  64%|██████▍   | 171/266 [01:38<01:15,  1.26it/s]Loading trainS:  65%|██████▍   | 172/266 [01:38<01:12,  1.30it/s]Loading trainS:  65%|██████▌   | 173/266 [01:39<01:12,  1.28it/s]Loading trainS:  65%|██████▌   | 174/266 [01:40<01:09,  1.32it/s]Loading trainS:  66%|██████▌   | 175/266 [01:40<01:00,  1.51it/s]Loading trainS:  66%|██████▌   | 176/266 [01:41<01:00,  1.49it/s]Loading trainS:  67%|██████▋   | 177/266 [01:42<00:58,  1.51it/s]Loading trainS:  67%|██████▋   | 178/266 [01:42<00:58,  1.49it/s]Loading trainS:  67%|██████▋   | 179/266 [01:43<00:57,  1.51it/s]Loading trainS:  68%|██████▊   | 180/266 [01:44<00:56,  1.51it/s]Loading trainS:  68%|██████▊   | 181/266 [01:44<00:57,  1.47it/s]Loading trainS:  68%|██████▊   | 182/266 [01:45<00:56,  1.50it/s]Loading trainS:  69%|██████▉   | 183/266 [01:46<00:54,  1.53it/s]Loading trainS:  69%|██████▉   | 184/266 [01:46<00:56,  1.45it/s]Loading trainS:  70%|██████▉   | 185/266 [01:47<00:53,  1.53it/s]Loading trainS:  70%|██████▉   | 186/266 [01:48<00:55,  1.44it/s]Loading trainS:  70%|███████   | 187/266 [01:49<00:54,  1.46it/s]Loading trainS:  71%|███████   | 188/266 [01:49<00:50,  1.53it/s]Loading trainS:  71%|███████   | 189/266 [01:50<00:51,  1.50it/s]Loading trainS:  71%|███████▏  | 190/266 [01:50<00:48,  1.57it/s]Loading trainS:  72%|███████▏  | 191/266 [01:51<00:47,  1.57it/s]Loading trainS:  72%|███████▏  | 192/266 [01:52<00:46,  1.58it/s]Loading trainS:  73%|███████▎  | 193/266 [01:52<00:44,  1.66it/s]Loading trainS:  73%|███████▎  | 194/266 [01:53<00:44,  1.62it/s]Loading trainS:  73%|███████▎  | 195/266 [01:54<00:46,  1.53it/s]Loading trainS:  74%|███████▎  | 196/266 [01:54<00:48,  1.46it/s]Loading trainS:  74%|███████▍  | 197/266 [01:55<00:49,  1.38it/s]Loading trainS:  74%|███████▍  | 198/266 [01:56<00:48,  1.39it/s]Loading trainS:  75%|███████▍  | 199/266 [01:57<00:49,  1.34it/s]Loading trainS:  75%|███████▌  | 200/266 [01:57<00:48,  1.36it/s]Loading trainS:  76%|███████▌  | 201/266 [01:58<00:48,  1.35it/s]Loading trainS:  76%|███████▌  | 202/266 [01:59<00:46,  1.36it/s]Loading trainS:  76%|███████▋  | 203/266 [02:00<00:45,  1.37it/s]Loading trainS:  77%|███████▋  | 204/266 [02:00<00:44,  1.38it/s]Loading trainS:  77%|███████▋  | 205/266 [02:01<00:44,  1.38it/s]Loading trainS:  77%|███████▋  | 206/266 [02:02<00:43,  1.38it/s]Loading trainS:  78%|███████▊  | 207/266 [02:02<00:40,  1.46it/s]Loading trainS:  78%|███████▊  | 208/266 [02:03<00:41,  1.41it/s]Loading trainS:  79%|███████▊  | 209/266 [02:04<00:40,  1.41it/s]Loading trainS:  79%|███████▉  | 210/266 [02:05<00:40,  1.38it/s]Loading trainS:  79%|███████▉  | 211/266 [02:05<00:40,  1.37it/s]Loading trainS:  80%|███████▉  | 212/266 [02:06<00:39,  1.36it/s]Loading trainS:  80%|████████  | 213/266 [02:07<00:37,  1.42it/s]Loading trainS:  80%|████████  | 214/266 [02:07<00:34,  1.49it/s]Loading trainS:  81%|████████  | 215/266 [02:08<00:34,  1.50it/s]Loading trainS:  81%|████████  | 216/266 [02:08<00:31,  1.56it/s]Loading trainS:  82%|████████▏ | 217/266 [02:09<00:31,  1.58it/s]Loading trainS:  82%|████████▏ | 218/266 [02:10<00:30,  1.56it/s]Loading trainS:  82%|████████▏ | 219/266 [02:10<00:30,  1.54it/s]Loading trainS:  83%|████████▎ | 220/266 [02:11<00:29,  1.58it/s]Loading trainS:  83%|████████▎ | 221/266 [02:12<00:28,  1.55it/s]Loading trainS:  83%|████████▎ | 222/266 [02:12<00:28,  1.57it/s]Loading trainS:  84%|████████▍ | 223/266 [02:13<00:28,  1.52it/s]Loading trainS:  84%|████████▍ | 224/266 [02:14<00:27,  1.50it/s]Loading trainS:  85%|████████▍ | 225/266 [02:14<00:26,  1.54it/s]Loading trainS:  85%|████████▍ | 226/266 [02:15<00:26,  1.52it/s]Loading trainS:  85%|████████▌ | 227/266 [02:16<00:25,  1.55it/s]Loading trainS:  86%|████████▌ | 228/266 [02:16<00:23,  1.62it/s]Loading trainS:  86%|████████▌ | 229/266 [02:17<00:23,  1.56it/s]Loading trainS:  86%|████████▋ | 230/266 [02:18<00:23,  1.52it/s]Loading trainS:  87%|████████▋ | 231/266 [02:18<00:21,  1.65it/s]Loading trainS:  87%|████████▋ | 232/266 [02:19<00:19,  1.75it/s]Loading trainS:  88%|████████▊ | 233/266 [02:19<00:19,  1.73it/s]Loading trainS:  88%|████████▊ | 234/266 [02:20<00:18,  1.76it/s]Loading trainS:  88%|████████▊ | 235/266 [02:20<00:16,  1.87it/s]Loading trainS:  89%|████████▊ | 236/266 [02:21<00:14,  2.01it/s]Loading trainS:  89%|████████▉ | 237/266 [02:21<00:14,  1.94it/s]Loading trainS:  89%|████████▉ | 238/266 [02:22<00:15,  1.86it/s]Loading trainS:  90%|████████▉ | 239/266 [02:22<00:14,  1.84it/s]Loading trainS:  90%|█████████ | 240/266 [02:23<00:14,  1.81it/s]Loading trainS:  91%|█████████ | 241/266 [02:23<00:13,  1.84it/s]Loading trainS:  91%|█████████ | 242/266 [02:24<00:13,  1.82it/s]Loading trainS:  91%|█████████▏| 243/266 [02:24<00:12,  1.87it/s]Loading trainS:  92%|█████████▏| 244/266 [02:25<00:11,  1.93it/s]Loading trainS:  92%|█████████▏| 245/266 [02:25<00:11,  1.89it/s]Loading trainS:  92%|█████████▏| 246/266 [02:26<00:10,  1.84it/s]Loading trainS:  93%|█████████▎| 247/266 [02:26<00:10,  1.87it/s]Loading trainS:  93%|█████████▎| 248/266 [02:27<00:09,  1.89it/s]Loading trainS:  94%|█████████▎| 249/266 [02:28<00:09,  1.76it/s]Loading trainS:  94%|█████████▍| 250/266 [02:28<00:09,  1.67it/s]Loading trainS:  94%|█████████▍| 251/266 [02:29<00:09,  1.61it/s]Loading trainS:  95%|█████████▍| 252/266 [02:30<00:08,  1.58it/s]Loading trainS:  95%|█████████▌| 253/266 [02:30<00:07,  1.65it/s]Loading trainS:  95%|█████████▌| 254/266 [02:31<00:07,  1.58it/s]Loading trainS:  96%|█████████▌| 255/266 [02:32<00:07,  1.54it/s]Loading trainS:  96%|█████████▌| 256/266 [02:32<00:06,  1.59it/s]Loading trainS:  97%|█████████▋| 257/266 [02:33<00:05,  1.56it/s]Loading trainS:  97%|█████████▋| 258/266 [02:33<00:05,  1.59it/s]Loading trainS:  97%|█████████▋| 259/266 [02:34<00:04,  1.61it/s]Loading trainS:  98%|█████████▊| 260/266 [02:35<00:03,  1.60it/s]Loading trainS:  98%|█████████▊| 261/266 [02:35<00:03,  1.60it/s]Loading trainS:  98%|█████████▊| 262/266 [02:36<00:02,  1.59it/s]Loading trainS:  99%|█████████▉| 263/266 [02:37<00:01,  1.62it/s]Loading trainS:  99%|█████████▉| 264/266 [02:37<00:01,  1.64it/s]Loading trainS: 100%|█████████▉| 265/266 [02:38<00:00,  1.63it/s]Loading trainS: 100%|██████████| 266/266 [02:38<00:00,  1.63it/s]Loading trainS: 100%|██████████| 266/266 [02:38<00:00,  1.67it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:01,  1.62it/s]Loading testS:  50%|█████     | 2/4 [00:01<00:01,  1.59it/s]Loading testS:  75%|███████▌  | 3/4 [00:01<00:00,  1.57it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]Loading testS: 100%|██████████| 4/4 [00:02<00:00,  1.48it/s]----------+++ 
CrossVal ['d']
CrossVal ['d']
(0/4) test vimp2_ANON988_CSFn2
(1/4) test vimp2_M_CSFn2
(2/4) test vimp2_N_CSFn2
(3/4) test vimp2_L_CSFn2
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 40) 400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 40) 160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 40) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 40) 14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 40) 160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 40) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 40) 44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 80) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 40) 28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 40) 160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 40) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 40) 14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 40) 160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 40) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 120 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 120 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  242         dropout_5[0][0]                  
==================================================================================================
Total params: 887,922
Trainable params: 886,322
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 83s - loss: 0.1163 - acc: 0.9875 - mDice: 0.7744 - val_loss: 0.4599 - val_acc: 0.9734 - val_mDice: 0.0940

Epoch 00001: val_mDice improved from -inf to 0.09401, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 79s - loss: 0.0773 - acc: 0.9923 - mDice: 0.8494 - val_loss: 0.2714 - val_acc: 0.9929 - val_mDice: 0.4607

Epoch 00002: val_mDice improved from 0.09401 to 0.46068, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 82s - loss: 0.0692 - acc: 0.9931 - mDice: 0.8652 - val_loss: 0.2654 - val_acc: 0.9928 - val_mDice: 0.4727

Epoch 00003: val_mDice improved from 0.46068 to 0.47273, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 4/300
 - 84s - loss: 0.0624 - acc: 0.9937 - mDice: 0.8784 - val_loss: 0.2582 - val_acc: 0.9926 - val_mDice: 0.4787

Epoch 00004: val_mDice improved from 0.47273 to 0.47871, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 85s - loss: 0.0566 - acc: 0.9942 - mDice: 0.8898 - val_loss: 0.2721 - val_acc: 0.9912 - val_mDice: 0.4603

Epoch 00005: val_mDice did not improve from 0.47871
Epoch 6/300
 - 85s - loss: 0.0560 - acc: 0.9942 - mDice: 0.8910 - val_loss: 0.2471 - val_acc: 0.9927 - val_mDice: 0.4780

Epoch 00006: val_mDice did not improve from 0.47871
Epoch 7/300
 - 85s - loss: 0.0507 - acc: 0.9947 - mDice: 0.9013 - val_loss: 0.1181 - val_acc: 0.9939 - val_mDice: 0.4919

Epoch 00007: val_mDice improved from 0.47871 to 0.49191, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 85s - loss: 0.0486 - acc: 0.9949 - mDice: 0.9053 - val_loss: 0.1778 - val_acc: 0.9931 - val_mDice: 0.4795

Epoch 00008: val_mDice did not improve from 0.49191
Epoch 9/300
 - 85s - loss: 0.0488 - acc: 0.9949 - mDice: 0.9050 - val_loss: 0.2308 - val_acc: 0.9933 - val_mDice: 0.4783

Epoch 00009: val_mDice did not improve from 0.49191
Epoch 10/300
 - 86s - loss: 0.0460 - acc: 0.9951 - mDice: 0.9105 - val_loss: 0.1351 - val_acc: 0.9925 - val_mDice: 0.4681

Epoch 00010: val_mDice did not improve from 0.49191
Epoch 11/300
 - 86s - loss: 0.0476 - acc: 0.9949 - mDice: 0.9073 - val_loss: 0.0821 - val_acc: 0.9938 - val_mDice: 0.4878

Epoch 00011: val_mDice did not improve from 0.49191
Epoch 12/300
 - 86s - loss: 0.0433 - acc: 0.9953 - mDice: 0.9157 - val_loss: 0.1176 - val_acc: 0.9937 - val_mDice: 0.4909

Epoch 00012: val_mDice did not improve from 0.49191
Epoch 13/300
 - 85s - loss: 0.0422 - acc: 0.9954 - mDice: 0.9179 - val_loss: 0.0699 - val_acc: 0.9925 - val_mDice: 0.4616

Epoch 00013: val_mDice did not improve from 0.49191
Epoch 14/300
 - 85s - loss: 0.0408 - acc: 0.9955 - mDice: 0.9206 - val_loss: 0.1492 - val_acc: 0.9932 - val_mDice: 0.4745

Epoch 00014: val_mDice did not improve from 0.49191
Epoch 15/300
 - 84s - loss: 0.0402 - acc: 0.9955 - mDice: 0.9219 - val_loss: 0.1414 - val_acc: 0.9931 - val_mDice: 0.4759

Epoch 00015: val_mDice did not improve from 0.49191
Epoch 16/300
 - 84s - loss: 0.0400 - acc: 0.9956 - mDice: 0.9222 - val_loss: 0.2078 - val_acc: 0.9886 - val_mDice: 0.4432

Epoch 00016: val_mDice did not improve from 0.49191
Epoch 17/300
 - 84s - loss: 0.0404 - acc: 0.9957 - mDice: 0.9213 - val_loss: 0.0435 - val_acc: 0.9924 - val_mDice: 0.4677

Epoch 00017: val_mDice did not improve from 0.49191
Epoch 18/300
 - 84s - loss: 0.0389 - acc: 0.9957 - mDice: 0.9243 - val_loss: -9.8743e-03 - val_acc: 0.9936 - val_mDice: 0.4890

Epoch 00018: val_mDice did not improve from 0.49191
Epoch 19/300
 - 84s - loss: 0.0384 - acc: 0.9957 - mDice: 0.9253 - val_loss: 0.0117 - val_acc: 0.9936 - val_mDice: 0.4805

Epoch 00019: val_mDice did not improve from 0.49191
Epoch 20/300
 - 84s - loss: 0.0366 - acc: 0.9959 - mDice: 0.9288 - val_loss: 0.2355 - val_acc: 0.9929 - val_mDice: 0.4821

Epoch 00020: val_mDice did not improve from 0.49191
Epoch 21/300
 - 85s - loss: 0.0358 - acc: 0.9959 - mDice: 0.9305 - val_loss: 0.0553 - val_acc: 0.9932 - val_mDice: 0.4711

Epoch 00021: val_mDice did not improve from 0.49191
Epoch 22/300
 - 85s - loss: 0.0365 - acc: 0.9959 - mDice: 0.9290 - val_loss: 0.1394 - val_acc: 0.9938 - val_mDice: 0.4873

Epoch 00022: val_mDice did not improve from 0.49191

Epoch 00022: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 23/300
 - 84s - loss: 0.0337 - acc: 0.9961 - mDice: 0.9344 - val_loss: 0.0804 - val_acc: 0.9934 - val_mDice: 0.4898

Epoch 00023: val_mDice did not improve from 0.49191
Epoch 24/300
 - 83s - loss: 0.0331 - acc: 0.9962 - mDice: 0.9357 - val_loss: 0.2035 - val_acc: 0.9936 - val_mDice: 0.4884

Epoch 00024: val_mDice did not improve from 0.49191
Epoch 25/300
 - 84s - loss: 0.0336 - acc: 0.9962 - mDice: 0.9346 - val_loss: 0.1899 - val_acc: 0.9937 - val_mDice: 0.4947

Epoch 00025: val_mDice improved from 0.49191 to 0.49474, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 26/300
 - 84s - loss: 0.0333 - acc: 0.9962 - mDice: 0.9352 - val_loss: 0.1676 - val_acc: 0.9929 - val_mDice: 0.4751

Epoch 00026: val_mDice did not improve from 0.49474
Epoch 27/300
 - 84s - loss: 0.0321 - acc: 0.9963 - mDice: 0.9376 - val_loss: 0.0424 - val_acc: 0.9937 - val_mDice: 0.4871

Epoch 00027: val_mDice did not improve from 0.49474
Epoch 28/300
 - 84s - loss: 0.0316 - acc: 0.9963 - mDice: 0.9385 - val_loss: 0.0765 - val_acc: 0.9937 - val_mDice: 0.4882

Epoch 00028: val_mDice did not improve from 0.49474
Epoch 29/300
 - 84s - loss: 0.0322 - acc: 0.9963 - mDice: 0.9373 - val_loss: 0.0781 - val_acc: 0.9937 - val_mDice: 0.4878

Epoch 00029: val_mDice did not improve from 0.49474
Epoch 30/300
 - 84s - loss: 0.0314 - acc: 0.9963 - mDice: 0.9391 - val_loss: -1.0780e-02 - val_acc: 0.9936 - val_mDice: 0.4844

Epoch 00030: val_mDice did not improve from 0.49474
Epoch 31/300
 - 84s - loss: 0.0318 - acc: 0.9963 - mDice: 0.9381 - val_loss: -5.4401e-03 - val_acc: 0.9936 - val_mDice: 0.4867

Epoch 00031: val_mDice did not improve from 0.49474
Epoch 32/300
 - 84s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9412 - val_loss: -4.8070e-02 - val_acc: 0.9935 - val_mDice: 0.4855

Epoch 00032: val_mDice did not improve from 0.49474
Epoch 33/300
 - 84s - loss: 0.0311 - acc: 0.9963 - mDice: 0.9396 - val_loss: 0.0424 - val_acc: 0.9938 - val_mDice: 0.4885

Epoch 00033: val_mDice did not improve from 0.49474
Epoch 34/300
 - 84s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9411 - val_loss: 0.0520 - val_acc: 0.9936 - val_mDice: 0.4844

Epoch 00034: val_mDice did not improve from 0.49474
Epoch 35/300
 - 84s - loss: 0.0310 - acc: 0.9964 - mDice: 0.9397 - val_loss: 0.0553 - val_acc: 0.9935 - val_mDice: 0.4869

Epoch 00035: val_mDice did not improve from 0.49474
Epoch 36/300
 - 84s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9420 - val_loss: 0.0470 - val_acc: 0.9937 - val_mDice: 0.4887

Epoch 00036: val_mDice did not improve from 0.49474
Epoch 37/300
 - 84s - loss: 0.0298 - acc: 0.9964 - mDice: 0.9421 - val_loss: 0.0635 - val_acc: 0.9937 - val_mDice: 0.4913

Epoch 00037: val_mDice did not improve from 0.49474
Epoch 38/300
 - 84s - loss: 0.0299 - acc: 0.9964 - mDice: 0.9419 - val_loss: 0.0705 - val_acc: 0.9936 - val_mDice: 0.4809

Epoch 00038: val_mDice did not improve from 0.49474
Epoch 39/300
 - 84s - loss: 0.0302 - acc: 0.9964 - mDice: 0.9413 - val_loss: 0.0912 - val_acc: 0.9933 - val_mDice: 0.4916

Epoch 00039: val_mDice did not improve from 0.49474
Epoch 40/300
 - 84s - loss: 0.0292 - acc: 0.9964 - mDice: 0.9433 - val_loss: 0.2059 - val_acc: 0.9894 - val_mDice: 0.4383

Epoch 00040: val_mDice did not improve from 0.49474

Epoch 00040: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 41/300
 - 84s - loss: 0.0291 - acc: 0.9965 - mDice: 0.9435 - val_loss: 0.0874 - val_acc: 0.9935 - val_mDice: 0.4907

Epoch 00041: val_mDice did not improve from 0.49474
Epoch 42/300
 - 84s - loss: 0.0282 - acc: 0.9965 - mDice: 0.9452 - val_loss: 0.0137 - val_acc: 0.9936 - val_mDice: 0.4841

Epoch 00042: val_mDice did not improve from 0.49474
Epoch 43/300
 - 84s - loss: 0.0283 - acc: 0.9965 - mDice: 0.9451 - val_loss: -5.5810e-02 - val_acc: 0.9920 - val_mDice: 0.4678

Epoch 00043: val_mDice did not improve from 0.49474
Epoch 44/300
 - 84s - loss: 0.0283 - acc: 0.9966 - mDice: 0.9451 - val_loss: 0.0450 - val_acc: 0.9939 - val_mDice: 0.4901

Epoch 00044: val_mDice did not improve from 0.49474
Epoch 45/300
 - 84s - loss: 0.0280 - acc: 0.9966 - mDice: 0.9457 - val_loss: 0.0196 - val_acc: 0.9939 - val_mDice: 0.4910

Epoch 00045: val_mDice did not improve from 0.49474
Epoch 46/300
 - 84s - loss: 0.0281 - acc: 0.9966 - mDice: 0.9454 - val_loss: 0.0744 - val_acc: 0.9937 - val_mDice: 0.4887

Epoch 00046: val_mDice did not improve from 0.49474
Epoch 47/300
 - 83s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9469 - val_loss: 0.0883 - val_acc: 0.9938 - val_mDice: 0.4901

Epoch 00047: val_mDice did not improve from 0.49474
Epoch 48/300
 - 84s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9467 - val_loss: 0.1440 - val_acc: 0.9938 - val_mDice: 0.4916

Epoch 00048: val_mDice did not improve from 0.49474
Epoch 49/300
 - 84s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9467 - val_loss: 0.0817 - val_acc: 0.9937 - val_mDice: 0.4863

Epoch 00049: val_mDice did not improve from 0.49474
Epoch 50/300
 - 84s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9474 - val_loss: 0.0976 - val_acc: 0.9937 - val_mDice: 0.4921

Epoch 00050: val_mDice did not improve from 0.49474
Epoch 51/300
 - 85s - loss: 0.0271 - acc: 0.9966 - mDice: 0.9474 - val_loss: 0.0520 - val_acc: 0.9938 - val_mDice: 0.4894

Epoch 00051: val_mDice did not improve from 0.49474
Epoch 52/300
 - 85s - loss: 0.0272 - acc: 0.9966 - mDice: 0.9471 - val_loss: 0.0674 - val_acc: 0.9934 - val_mDice: 0.4913

Epoch 00052: val_mDice did not improve from 0.49474
Epoch 53/300
 - 84s - loss: 0.0274 - acc: 0.9966 - mDice: 0.9469 - val_loss: 0.0512 - val_acc: 0.9935 - val_mDice: 0.4863

Epoch 00053: val_mDice did not improve from 0.49474
Epoch 54/300
 - 84s - loss: 0.0266 - acc: 0.9966 - mDice: 0.9484 - val_loss: 0.0581 - val_acc: 0.9935 - val_mDice: 0.4888

Epoch 00054: val_mDice did not improve from 0.49474
Epoch 55/300
 - 84s - loss: 0.0265 - acc: 0.9966 - mDice: 0.9485 - val_loss: 0.0784 - val_acc: 0.9937 - val_mDice: 0.4844

Epoch 00055: val_mDice did not improve from 0.49474

Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 56/300
 - 84s - loss: 0.0263 - acc: 0.9967 - mDice: 0.9489 - val_loss: 0.0465 - val_acc: 0.9938 - val_mDice: 0.4903

Epoch 00056: val_mDice did not improve from 0.49474
Epoch 57/300
 - 84s - loss: 0.0270 - acc: 0.9967 - mDice: 0.9475 - val_loss: 0.0812 - val_acc: 0.9936 - val_mDice: 0.4835

Epoch 00057: val_mDice did not improve from 0.49474
Epoch 58/300
 - 84s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9504 - val_loss: 0.0884 - val_acc: 0.9937 - val_mDice: 0.4884

Epoch 00058: val_mDice did not improve from 0.49474
Epoch 59/300
 - 84s - loss: 0.0267 - acc: 0.9967 - mDice: 0.9481 - val_loss: 0.0699 - val_acc: 0.9936 - val_mDice: 0.4871

Epoch 00059: val_mDice did not improve from 0.49474
Epoch 60/300
 - 84s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9496 - val_loss: 0.0721 - val_acc: 0.9938 - val_mDice: 0.4881

Epoch 00060: val_mDice did not improve from 0.49474
Epoch 61/300
 - 84s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9496 - val_loss: 0.1105 - val_acc: 0.9936 - val_mDice: 0.4852

Epoch 00061: val_mDice did not improve from 0.49474
Epoch 62/300
 - 84s - loss: 0.0252 - acc: 0.9967 - mDice: 0.9512 - val_loss: 0.0953 - val_acc: 0.9938 - val_mDice: 0.4885

Epoch 00062: val_mDice did not improve from 0.49474
Epoch 63/300
 - 84s - loss: 0.0257 - acc: 0.9967 - mDice: 0.9500 - val_loss: 0.0439 - val_acc: 0.9937 - val_mDice: 0.4837

Epoch 00063: val_mDice did not improve from 0.49474
Epoch 64/300
 - 84s - loss: 0.0256 - acc: 0.9967 - mDice: 0.9504 - val_loss: 0.0682 - val_acc: 0.9936 - val_mDice: 0.4883

Epoch 00064: val_mDice did not improve from 0.49474
Epoch 65/300
 - 84s - loss: 0.0260 - acc: 0.9967 - mDice: 0.9496 - val_loss: 0.0686 - val_acc: 0.9937 - val_mDice: 0.4862

Epoch 00065: val_mDice did not improve from 0.49474
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
{'val_loss': [0.45989130525028005, 0.27140963837212206, 0.26543981421227547, 0.25820396431520876, 0.2720520741799298, 0.24705969030950584, 0.11811250535880818, 0.17781531430926978, 0.2307586456630744, 0.13508710469685348, 0.08212617010462518, 0.11755039586740382, 0.06985071096934524, 0.14923614935547697, 0.14144115237628713, 0.2077997756354949, 0.04349663298504025, -0.009874316991544237, 0.011666858020950766, 0.23549574759660982, 0.055295259052631905, 0.13941427568594614, 0.08039571870775784, 0.203493149841533, 0.189859066231578, 0.16758057358218173, 0.04238419439278397, 0.07647025146905113, 0.07805878099273234, -0.010780326875985837, -0.005440141932637084, -0.048069532011069505, 0.042415338404038376, 0.051961238185564675, 0.055336459302434735, 0.04695748903003393, 0.06354458425559249, 0.07048716673664018, 0.09119837424334358, 0.2058981195384381, 0.08738607723338931, 0.013720546575153576, -0.055809612367667405, 0.044973067501012015, 0.019641707340876263, 0.07438925726740968, 0.08826316089606752, 0.1440426377104778, 0.08165335479904623, 0.09759850800037384, 0.05195920461533116, 0.06740685420877793, 0.051196141862401776, 0.05811599452121585, 0.07836713042913698, 0.046534128341020324, 0.08122734141116049, 0.0883706574346505, 0.0699376224302778, 0.07212971647580464, 0.11052094896634419, 0.09533880738651052, 0.043901990149535386, 0.06820752866127912, 0.06863025824228923], 'val_acc': [0.9733963784049539, 0.9928617909842846, 0.9928010643697253, 0.9926285907333973, 0.9912481553414288, 0.9926752249399821, 0.9938625307644114, 0.9931081439934525, 0.9933263180302638, 0.9925083856956631, 0.9938177665074667, 0.9936781607422174, 0.9925206011416865, 0.9931591655693802, 0.9930846714505962, 0.9886481761932373, 0.9924254370670692, 0.9936102301466698, 0.9935698532590679, 0.9929002944160911, 0.993210191820182, 0.9938027437995461, 0.9934164683024088, 0.9935898827571495, 0.9937451481819153, 0.9929196974810433, 0.9936737780477486, 0.9937360660702574, 0.9937476550831514, 0.9936105503755457, 0.99359771083383, 0.9935476359199075, 0.9937780183904311, 0.993580189405703, 0.9935088157653809, 0.9936737780477486, 0.9936806664747351, 0.9936049124773811, 0.9933256962720085, 0.9893549774207321, 0.993459986705406, 0.9935902006485883, 0.9920394771239337, 0.9938935158299465, 0.9938841286827537, 0.9937053942212871, 0.9937526665481866, 0.9938155763289508, 0.9937132176230935, 0.9937442120383767, 0.9938252790301454, 0.9934149068944594, 0.9935470071493411, 0.9935194604537066, 0.9936646994422463, 0.9937529750898773, 0.9935711084627638, 0.9936756550096998, 0.9936440435110354, 0.993773941900216, 0.9935798715142643, 0.993773009262833, 0.9937182314255658, 0.9935726745455873, 0.993677536646525], 'val_mDice': [0.09400780116555808, 0.4606778003172959, 0.47273189517291, 0.47871351008434737, 0.4603242031668832, 0.47804034457493005, 0.4919072143319927, 0.47950922895003767, 0.4783340723929452, 0.46808970020170887, 0.4877713047990612, 0.4908552199017768, 0.4616238818156953, 0.47451735711565207, 0.4759056424977733, 0.44319231813663945, 0.46768488545043796, 0.4890198768938289, 0.48047784095009166, 0.482105058709196, 0.4711454736397547, 0.48727179289448497, 0.48977044443873796, 0.48843126846294777, 0.49474362218204665, 0.47509906747761893, 0.48708029354319854, 0.48820548095539507, 0.48778004243093376, 0.48441247568995344, 0.48667601495981216, 0.4854573618401499, 0.48848690950841295, 0.4844140177410023, 0.4868754049507426, 0.48874952176622316, 0.49126485457607344, 0.4809145469985464, 0.4915716009689312, 0.4383158613654076, 0.49070579836181566, 0.484066192864203, 0.46779002833600136, 0.49010279248742494, 0.49104902717997045, 0.48871662789115716, 0.49009812170383976, 0.49163368461178797, 0.48629366453079614, 0.4920741326960863, 0.48944079883250535, 0.4913023410218896, 0.4862908209655799, 0.48883029701663, 0.4843880271940839, 0.49034207033629157, 0.48346476753552753, 0.4883846425104375, 0.4871095141359404, 0.4881445711559504, 0.4852278058727582, 0.4884502355228452, 0.48370838322329757, 0.4882982614103197, 0.486231785632816], 'loss': [0.11631671203647205, 0.07730817537901122, 0.06917675542833496, 0.062431769230987914, 0.05656881282643337, 0.05596363932103557, 0.05067733160190309, 0.048639572564955, 0.04878532547547593, 0.04595877107295283, 0.047638142546622096, 0.04330441177666087, 0.042220540703128126, 0.04081000987588858, 0.040154236002909995, 0.039985341685900025, 0.04042104691282578, 0.03890513808187146, 0.03839198895123446, 0.03663179943923754, 0.03575297951203702, 0.036523599468782496, 0.033740983488098605, 0.0330621940033812, 0.033614935401712745, 0.03331153857941789, 0.03209281830065333, 0.031634286811276655, 0.03223663477963914, 0.03135401587173458, 0.031832617337626365, 0.03025340449752613, 0.031071741654254054, 0.030339228912694242, 0.031035977564304627, 0.029882145894353365, 0.029794906474153143, 0.02991984145080179, 0.030227742880377013, 0.029207129306174234, 0.029093810902284897, 0.028238923490299942, 0.02826657882194279, 0.028254281793662815, 0.027968599958268444, 0.028116413832630843, 0.02736963488813106, 0.027472876372467668, 0.027446587370863255, 0.02707277359165844, 0.027121821525950097, 0.027232663091908742, 0.027353575191702284, 0.02658004957078151, 0.026548743800521208, 0.026315730112881335, 0.027017090290392266, 0.02556461301432645, 0.026704956237558548, 0.025985095379958956, 0.025954772631511778, 0.025190437961730112, 0.0257470996356817, 0.02558643377654573, 0.025975961773171272], 'acc': [0.9875335989151705, 0.9922677424996754, 0.9930832075006014, 0.993678668648245, 0.9941968002661337, 0.9942373986419353, 0.9947023977566767, 0.9948693582526433, 0.994865217128896, 0.9951145706544492, 0.994931133252887, 0.9953320237865702, 0.9953997266145229, 0.9954855513089851, 0.9955090295968936, 0.9956270974919115, 0.9956623594344323, 0.9957146724766118, 0.9957432278330297, 0.9958740596305554, 0.9958906837993646, 0.9958798674361687, 0.9961083076657791, 0.9961616392338442, 0.9961892637748266, 0.9961802174478747, 0.9962526926007611, 0.9963026661476629, 0.9962847365945905, 0.996299802696671, 0.9962958108525887, 0.9963746914866076, 0.9963336813707883, 0.996369258889691, 0.996351856847928, 0.996405735123367, 0.9964130163185831, 0.9964127849939011, 0.9964209368015439, 0.9964469257064035, 0.9964916564138091, 0.9965401618975837, 0.9965480291918815, 0.9965668262272117, 0.9965817695713248, 0.9965697214537431, 0.9965809872850058, 0.9966089639267739, 0.996599916876943, 0.9966126831556124, 0.9966101168389454, 0.99661269686264, 0.9966027008977333, 0.9966396770695611, 0.9966168047893015, 0.9966750597708917, 0.9966814067403446, 0.996690447201256, 0.996690628374058, 0.9966883117342026, 0.9966961956408783, 0.9967107904017549, 0.9967091551391771, 0.9967155845375683, 0.9967121288655064], 'mDice': [0.7743966805735335, 0.8494246721684204, 0.8652268125525516, 0.8783908164554561, 0.8898317424469782, 0.8910128790866955, 0.901337089914178, 0.905320127084501, 0.9050320207174252, 0.9105470876273695, 0.9072887092069555, 0.9157362198384164, 0.9178662927008364, 0.9206369828861035, 0.921937671553298, 0.9222037725382753, 0.9213134447848853, 0.9243152985194842, 0.9253281016759447, 0.9287736501942847, 0.930515792202024, 0.928982087298122, 0.9344209743854872, 0.9357371353261921, 0.9346226516349921, 0.9352361158306943, 0.9376274354810786, 0.9385247323604757, 0.9373191188951049, 0.939073971993579, 0.9381209296316319, 0.9412421698025982, 0.9396249098162943, 0.9410635366191066, 0.9396802752713737, 0.941959920990234, 0.9421273476877015, 0.9418787937491366, 0.9412561514999754, 0.9432900350555792, 0.9434873028238147, 0.9451662320694464, 0.9451125060412803, 0.9451146174665599, 0.945681748605747, 0.9453941804993445, 0.9468754922694105, 0.9466588115800052, 0.9467144562184953, 0.9474497631478419, 0.9473590289301959, 0.9471288475933295, 0.9468905108032974, 0.9484285080812662, 0.9484907103859043, 0.9489331696097534, 0.9475265791569322, 0.9504186727384568, 0.9481407259646858, 0.9495776078763691, 0.949641081240632, 0.9511566355211407, 0.950049998074284, 0.9503621698629487, 0.9495843250600832], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.06it/s]predicting test subjects:  50%|█████     | 2/4 [00:01<00:01,  1.32it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  1.73it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.10it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:43,  6.14it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:42,  6.18it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:41,  6.28it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:42,  6.23it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:41,  6.30it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:40,  6.38it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:40,  6.46it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:40,  6.37it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:39,  6.44it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:40,  6.31it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:39,  6.40it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:39,  6.45it/s]predicting train subjects:   5%|▍         | 13/266 [00:02<00:38,  6.49it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:38,  6.52it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:38,  6.48it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:38,  6.48it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:38,  6.48it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:38,  6.48it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:38,  6.49it/s]predicting train subjects:   8%|▊         | 20/266 [00:03<00:37,  6.52it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:37,  6.50it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:37,  6.50it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:36,  6.59it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:36,  6.66it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:36,  6.69it/s]predicting train subjects:  10%|▉         | 26/266 [00:04<00:35,  6.72it/s]predicting train subjects:  10%|█         | 27/266 [00:04<00:35,  6.73it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:35,  6.74it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:35,  6.72it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:35,  6.65it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:35,  6.66it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:34,  6.69it/s]predicting train subjects:  12%|█▏        | 33/266 [00:05<00:34,  6.74it/s]predicting train subjects:  13%|█▎        | 34/266 [00:05<00:34,  6.74it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:34,  6.75it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:33,  6.77it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:33,  6.75it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:33,  6.75it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:33,  6.78it/s]predicting train subjects:  15%|█▌        | 40/266 [00:06<00:33,  6.82it/s]predicting train subjects:  15%|█▌        | 41/266 [00:06<00:32,  6.82it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:32,  6.83it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:32,  6.81it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:32,  6.79it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:32,  6.82it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:32,  6.74it/s]predicting train subjects:  18%|█▊        | 47/266 [00:07<00:33,  6.60it/s]predicting train subjects:  18%|█▊        | 48/266 [00:07<00:33,  6.58it/s]predicting train subjects:  18%|█▊        | 49/266 [00:07<00:32,  6.60it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:32,  6.64it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:32,  6.67it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:31,  6.71it/s]predicting train subjects:  20%|█▉        | 53/266 [00:08<00:31,  6.75it/s]predicting train subjects:  20%|██        | 54/266 [00:08<00:31,  6.74it/s]predicting train subjects:  21%|██        | 55/266 [00:08<00:31,  6.70it/s]predicting train subjects:  21%|██        | 56/266 [00:08<00:31,  6.58it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:31,  6.63it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:31,  6.65it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:31,  6.58it/s]predicting train subjects:  23%|██▎       | 60/266 [00:09<00:31,  6.52it/s]predicting train subjects:  23%|██▎       | 61/266 [00:09<00:31,  6.41it/s]predicting train subjects:  23%|██▎       | 62/266 [00:09<00:32,  6.36it/s]predicting train subjects:  24%|██▎       | 63/266 [00:09<00:32,  6.33it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:32,  6.24it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:32,  6.25it/s]predicting train subjects:  25%|██▍       | 66/266 [00:10<00:32,  6.25it/s]predicting train subjects:  25%|██▌       | 67/266 [00:10<00:32,  6.06it/s]predicting train subjects:  26%|██▌       | 68/266 [00:10<00:32,  6.16it/s]predicting train subjects:  26%|██▌       | 69/266 [00:10<00:31,  6.20it/s]predicting train subjects:  26%|██▋       | 70/266 [00:10<00:31,  6.23it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:31,  6.28it/s]predicting train subjects:  27%|██▋       | 72/266 [00:11<00:31,  6.26it/s]predicting train subjects:  27%|██▋       | 73/266 [00:11<00:30,  6.26it/s]predicting train subjects:  28%|██▊       | 74/266 [00:11<00:30,  6.28it/s]predicting train subjects:  28%|██▊       | 75/266 [00:11<00:30,  6.30it/s]predicting train subjects:  29%|██▊       | 76/266 [00:11<00:30,  6.21it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:35,  5.32it/s]predicting train subjects:  29%|██▉       | 78/266 [00:12<00:38,  4.89it/s]predicting train subjects:  30%|██▉       | 79/266 [00:12<00:44,  4.24it/s]predicting train subjects:  30%|███       | 80/266 [00:12<00:48,  3.83it/s]predicting train subjects:  30%|███       | 81/266 [00:12<00:43,  4.25it/s]predicting train subjects:  31%|███       | 82/266 [00:13<00:40,  4.56it/s]predicting train subjects:  31%|███       | 83/266 [00:13<00:38,  4.80it/s]predicting train subjects:  32%|███▏      | 84/266 [00:13<00:36,  4.95it/s]predicting train subjects:  32%|███▏      | 85/266 [00:13<00:35,  5.07it/s]predicting train subjects:  32%|███▏      | 86/266 [00:13<00:34,  5.18it/s]predicting train subjects:  33%|███▎      | 87/266 [00:14<00:34,  5.24it/s]predicting train subjects:  33%|███▎      | 88/266 [00:14<00:33,  5.30it/s]predicting train subjects:  33%|███▎      | 89/266 [00:14<00:33,  5.27it/s]predicting train subjects:  34%|███▍      | 90/266 [00:14<00:33,  5.23it/s]predicting train subjects:  34%|███▍      | 91/266 [00:14<00:33,  5.16it/s]predicting train subjects:  35%|███▍      | 92/266 [00:15<00:33,  5.21it/s]predicting train subjects:  35%|███▍      | 93/266 [00:15<00:32,  5.26it/s]predicting train subjects:  35%|███▌      | 94/266 [00:15<00:32,  5.29it/s]predicting train subjects:  36%|███▌      | 95/266 [00:15<00:32,  5.29it/s]predicting train subjects:  36%|███▌      | 96/266 [00:15<00:31,  5.35it/s]predicting train subjects:  36%|███▋      | 97/266 [00:15<00:31,  5.38it/s]predicting train subjects:  37%|███▋      | 98/266 [00:16<00:30,  5.44it/s]predicting train subjects:  37%|███▋      | 99/266 [00:16<00:30,  5.43it/s]predicting train subjects:  38%|███▊      | 100/266 [00:16<00:30,  5.37it/s]predicting train subjects:  38%|███▊      | 101/266 [00:16<00:30,  5.48it/s]predicting train subjects:  38%|███▊      | 102/266 [00:16<00:29,  5.49it/s]predicting train subjects:  39%|███▊      | 103/266 [00:17<00:29,  5.50it/s]predicting train subjects:  39%|███▉      | 104/266 [00:17<00:29,  5.52it/s]predicting train subjects:  39%|███▉      | 105/266 [00:17<00:28,  5.57it/s]predicting train subjects:  40%|███▉      | 106/266 [00:17<00:28,  5.64it/s]predicting train subjects:  40%|████      | 107/266 [00:17<00:28,  5.58it/s]predicting train subjects:  41%|████      | 108/266 [00:17<00:28,  5.58it/s]predicting train subjects:  41%|████      | 109/266 [00:18<00:28,  5.55it/s]predicting train subjects:  41%|████▏     | 110/266 [00:18<00:28,  5.50it/s]predicting train subjects:  42%|████▏     | 111/266 [00:18<00:28,  5.50it/s]predicting train subjects:  42%|████▏     | 112/266 [00:18<00:28,  5.49it/s]predicting train subjects:  42%|████▏     | 113/266 [00:18<00:27,  5.54it/s]predicting train subjects:  43%|████▎     | 114/266 [00:19<00:27,  5.57it/s]predicting train subjects:  43%|████▎     | 115/266 [00:19<00:26,  5.61it/s]predicting train subjects:  44%|████▎     | 116/266 [00:19<00:26,  5.66it/s]predicting train subjects:  44%|████▍     | 117/266 [00:19<00:26,  5.69it/s]predicting train subjects:  44%|████▍     | 118/266 [00:19<00:24,  5.98it/s]predicting train subjects:  45%|████▍     | 119/266 [00:19<00:23,  6.23it/s]predicting train subjects:  45%|████▌     | 120/266 [00:19<00:23,  6.33it/s]predicting train subjects:  45%|████▌     | 121/266 [00:20<00:22,  6.46it/s]predicting train subjects:  46%|████▌     | 122/266 [00:20<00:21,  6.56it/s]predicting train subjects:  46%|████▌     | 123/266 [00:20<00:21,  6.66it/s]predicting train subjects:  47%|████▋     | 124/266 [00:20<00:21,  6.72it/s]predicting train subjects:  47%|████▋     | 125/266 [00:20<00:21,  6.70it/s]predicting train subjects:  47%|████▋     | 126/266 [00:20<00:20,  6.74it/s]predicting train subjects:  48%|████▊     | 127/266 [00:21<00:20,  6.73it/s]predicting train subjects:  48%|████▊     | 128/266 [00:21<00:20,  6.79it/s]predicting train subjects:  48%|████▊     | 129/266 [00:21<00:20,  6.82it/s]predicting train subjects:  49%|████▉     | 130/266 [00:21<00:19,  6.88it/s]predicting train subjects:  49%|████▉     | 131/266 [00:21<00:19,  6.84it/s]predicting train subjects:  50%|████▉     | 132/266 [00:21<00:19,  6.85it/s]predicting train subjects:  50%|█████     | 133/266 [00:21<00:19,  6.84it/s]predicting train subjects:  50%|█████     | 134/266 [00:22<00:19,  6.82it/s]predicting train subjects:  51%|█████     | 135/266 [00:22<00:19,  6.82it/s]predicting train subjects:  51%|█████     | 136/266 [00:22<00:19,  6.68it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:22<00:19,  6.59it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:22<00:19,  6.59it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:22<00:19,  6.60it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:22<00:19,  6.61it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:23<00:18,  6.59it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:23<00:18,  6.61it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:23<00:18,  6.60it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:23<00:18,  6.58it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:23<00:18,  6.53it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:23<00:18,  6.59it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:24<00:18,  6.55it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:24<00:18,  6.54it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:24<00:18,  6.46it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:24<00:18,  6.23it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:24<00:18,  6.32it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:24<00:17,  6.42it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:24<00:17,  6.50it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:25<00:18,  6.13it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:25<00:18,  5.85it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:25<00:19,  5.75it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:25<00:19,  5.69it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:25<00:19,  5.50it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:26<00:19,  5.55it/s]predicting train subjects:  60%|██████    | 160/266 [00:26<00:18,  5.62it/s]predicting train subjects:  61%|██████    | 161/266 [00:26<00:18,  5.66it/s]predicting train subjects:  61%|██████    | 162/266 [00:26<00:18,  5.66it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:26<00:18,  5.67it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:26<00:18,  5.65it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:27<00:17,  5.67it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:27<00:17,  5.68it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:27<00:17,  5.65it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:27<00:17,  5.64it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:27<00:17,  5.57it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:28<00:17,  5.58it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:28<00:16,  5.60it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:28<00:16,  5.82it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:28<00:18,  4.97it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:28<00:18,  4.89it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:29<00:20,  4.38it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:29<00:18,  4.85it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:29<00:16,  5.24it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:29<00:15,  5.54it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:29<00:15,  5.63it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:29<00:14,  5.74it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:30<00:14,  5.91it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:30<00:14,  5.95it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:30<00:14,  5.92it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:30<00:14,  5.76it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:30<00:13,  5.98it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:30<00:13,  6.11it/s]predicting train subjects:  70%|███████   | 187/266 [00:31<00:12,  6.20it/s]predicting train subjects:  71%|███████   | 188/266 [00:31<00:12,  6.23it/s]predicting train subjects:  71%|███████   | 189/266 [00:31<00:12,  6.33it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:31<00:11,  6.42it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:31<00:11,  6.45it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:31<00:11,  6.47it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:31<00:11,  6.50it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:32<00:11,  6.51it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:32<00:11,  6.07it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:32<00:12,  5.80it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:32<00:12,  5.67it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:32<00:12,  5.57it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:33<00:12,  5.53it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:33<00:11,  5.53it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:33<00:11,  5.50it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:33<00:11,  5.51it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:33<00:11,  5.51it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:33<00:11,  5.48it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:34<00:11,  5.47it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:34<00:11,  5.45it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:34<00:11,  5.33it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:34<00:10,  5.35it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:34<00:10,  5.35it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:35<00:10,  5.28it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:35<00:10,  5.33it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:35<00:10,  5.39it/s]predicting train subjects:  80%|████████  | 213/266 [00:35<00:09,  5.59it/s]predicting train subjects:  80%|████████  | 214/266 [00:35<00:09,  5.68it/s]predicting train subjects:  81%|████████  | 215/266 [00:35<00:08,  5.78it/s]predicting train subjects:  81%|████████  | 216/266 [00:36<00:08,  5.84it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:36<00:08,  5.87it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:36<00:08,  5.93it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:36<00:07,  5.97it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:36<00:07,  5.98it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:36<00:07,  6.01it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:37<00:07,  6.01it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:37<00:07,  6.01it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:37<00:06,  6.01it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:37<00:06,  5.95it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:37<00:06,  5.94it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:37<00:06,  5.97it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:38<00:06,  5.94it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:38<00:06,  5.95it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:38<00:06,  5.99it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:38<00:05,  6.33it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:38<00:05,  6.59it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:38<00:04,  6.79it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:39<00:04,  6.91it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:39<00:04,  7.01it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:39<00:04,  7.09it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:39<00:04,  7.16it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:39<00:03,  7.22it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:39<00:03,  7.26it/s]predicting train subjects:  90%|█████████ | 240/266 [00:39<00:03,  7.26it/s]predicting train subjects:  91%|█████████ | 241/266 [00:39<00:03,  7.26it/s]predicting train subjects:  91%|█████████ | 242/266 [00:40<00:03,  7.28it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:40<00:03,  7.34it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:40<00:02,  7.34it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:40<00:02,  7.37it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:40<00:02,  7.35it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:40<00:02,  7.39it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:40<00:02,  7.38it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:41<00:02,  7.13it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:41<00:02,  6.91it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:41<00:02,  6.84it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:41<00:02,  6.80it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:41<00:01,  6.77it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:41<00:01,  6.72it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:42<00:01,  6.17it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:42<00:01,  6.34it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:42<00:01,  6.44it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:42<00:01,  6.51it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:42<00:01,  6.51it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:42<00:00,  6.59it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:42<00:00,  6.65it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:43<00:00,  6.66it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:43<00:00,  6.60it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:43<00:00,  6.55it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:43<00:00,  6.41it/s]predicting train subjects: 100%|██████████| 266/266 [00:43<00:00,  6.51it/s]predicting train subjects: 100%|██████████| 266/266 [00:43<00:00,  6.09it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  5.84it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  6.11it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  6.27it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.12it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  6.25it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:40,  6.46it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:40,  6.52it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:40,  6.55it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:40,  6.47it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:40,  6.46it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:40,  6.43it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:01<00:40,  6.38it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:01<00:40,  6.33it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:40,  6.36it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:40,  6.33it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:40,  6.35it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:39,  6.41it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:02<00:39,  6.46it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:02<00:39,  6.35it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:02<00:39,  6.32it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:02<00:39,  6.29it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:39,  6.37it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:38,  6.42it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:38,  6.44it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:03<00:38,  6.40it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:03<00:38,  6.41it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:03<00:38,  6.42it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:03<00:37,  6.50it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:03<00:36,  6.59it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:36,  6.66it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:04<00:35,  6.68it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:04<00:35,  6.74it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:04<00:35,  6.75it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:04<00:35,  6.74it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:04<00:35,  6.65it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:04<00:35,  6.70it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:04<00:35,  6.68it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:05<00:36,  6.39it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:05<00:35,  6.46it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:05<00:36,  6.40it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:05<00:36,  6.31it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:05<00:35,  6.40it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:05<00:35,  6.46it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:06<00:34,  6.52it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:06<00:34,  6.52it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:06<00:34,  6.58it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:06<00:34,  6.52it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:06<00:33,  6.56it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:06<00:33,  6.58it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:06<00:33,  6.62it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:07<00:32,  6.68it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:07<00:32,  6.70it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:07<00:32,  6.62it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:07<00:32,  6.67it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:07<00:32,  6.71it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:07<00:31,  6.74it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:07<00:31,  6.76it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:08<00:31,  6.75it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:08<00:32,  6.61it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:08<00:31,  6.65it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:08<00:31,  6.71it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:08<00:31,  6.64it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:08<00:31,  6.62it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:09<00:31,  6.57it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:09<00:31,  6.48it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:09<00:31,  6.42it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:09<00:31,  6.38it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:09<00:31,  6.38it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:09<00:31,  6.35it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:09<00:31,  6.35it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:10<00:31,  6.37it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:10<00:31,  6.37it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:10<00:31,  6.33it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:10<00:31,  6.19it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:10<00:31,  6.13it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:10<00:32,  6.04it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:11<00:31,  6.09it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:11<00:31,  6.12it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:11<00:30,  6.20it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:11<00:30,  6.26it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:11<00:30,  6.28it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:11<00:31,  6.02it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:12<00:31,  5.92it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:12<00:30,  6.20it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:12<00:29,  6.38it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:12<00:29,  6.17it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:12<00:31,  5.90it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:12<00:31,  5.79it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:13<00:31,  5.69it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:13<00:32,  5.60it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:13<00:32,  5.52it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:13<00:32,  5.47it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:13<00:32,  5.49it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:14<00:32,  5.50it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:14<00:32,  5.50it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:14<00:31,  5.50it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:14<00:32,  5.33it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:14<00:32,  5.35it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:14<00:32,  5.31it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:15<00:31,  5.35it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:15<00:32,  5.31it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:15<00:31,  5.31it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:15<00:31,  5.26it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:15<00:31,  5.26it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:16<00:31,  5.35it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:16<00:30,  5.44it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:16<00:29,  5.51it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:16<00:29,  5.54it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:16<00:29,  5.58it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:17<00:29,  5.45it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:17<00:29,  5.50it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:17<00:28,  5.55it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:17<00:28,  5.60it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:17<00:27,  5.64it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:17<00:28,  5.57it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:18<00:27,  5.59it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:18<00:27,  5.63it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:18<00:27,  5.60it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:18<00:27,  5.63it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:18<00:26,  5.66it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:18<00:26,  5.68it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:19<00:26,  5.70it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:19<00:24,  6.00it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:19<00:23,  6.21it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:19<00:22,  6.41it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:19<00:22,  6.49it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:19<00:21,  6.57it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:20<00:21,  6.51it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:20<00:21,  6.60it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:20<00:21,  6.53it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:20<00:21,  6.60it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:20<00:20,  6.64it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:20<00:20,  6.69it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:20<00:20,  6.71it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:21<00:20,  6.67it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:21<00:20,  6.69it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:21<00:19,  6.72it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:21<00:19,  6.75it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:21<00:19,  6.78it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:21<00:20,  6.47it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:21<00:20,  6.50it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:22<00:19,  6.55it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:22<00:19,  6.58it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:22<00:19,  6.44it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:22<00:19,  6.50it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:22<00:19,  6.56it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:22<00:18,  6.58it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:23<00:18,  6.62it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:23<00:18,  6.68it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:23<00:18,  6.67it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:23<00:18,  6.65it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:23<00:17,  6.67it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:23<00:17,  6.67it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:23<00:17,  6.67it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:24<00:17,  6.60it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:24<00:17,  6.66it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:24<00:17,  6.66it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:24<00:16,  6.65it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:24<00:17,  6.29it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:24<00:18,  6.11it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:25<00:18,  5.99it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:25<00:18,  5.84it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:25<00:18,  5.74it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:25<00:19,  5.48it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:25<00:19,  5.52it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:26<00:18,  5.53it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:26<00:18,  5.53it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:26<00:18,  5.55it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:26<00:18,  5.49it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:26<00:18,  5.56it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:26<00:17,  5.60it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:27<00:17,  5.64it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:27<00:17,  5.64it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:27<00:17,  5.55it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:27<00:17,  5.62it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:27<00:16,  5.64it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:27<00:16,  5.87it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:28<00:16,  5.73it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:28<00:16,  5.75it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:28<00:14,  6.15it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:28<00:14,  6.30it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:28<00:14,  6.35it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:28<00:13,  6.40it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:29<00:13,  6.45it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:29<00:13,  6.40it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:29<00:13,  6.43it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:29<00:13,  6.45it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:29<00:13,  6.34it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:29<00:12,  6.37it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:29<00:12,  6.40it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:30<00:12,  6.42it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:30<00:12,  6.41it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:30<00:12,  6.39it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:30<00:12,  6.31it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:30<00:12,  6.32it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:30<00:11,  6.36it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:31<00:11,  6.40it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:31<00:11,  6.42it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:31<00:11,  6.45it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:31<00:11,  6.03it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:31<00:12,  5.77it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:31<00:12,  5.42it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:32<00:12,  5.37it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:32<00:12,  5.34it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:32<00:12,  5.41it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:32<00:11,  5.45it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:32<00:11,  5.46it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:33<00:11,  5.46it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:33<00:11,  5.45it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:33<00:11,  5.47it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:33<00:11,  5.45it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:33<00:10,  5.40it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:34<00:10,  5.41it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:34<00:10,  5.41it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:34<00:10,  5.41it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:34<00:10,  5.29it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:34<00:10,  5.36it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:34<00:09,  5.55it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:35<00:09,  5.61it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:35<00:08,  5.74it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:35<00:08,  5.76it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:35<00:08,  5.83it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:35<00:08,  5.86it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:35<00:08,  5.66it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:36<00:08,  5.61it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:36<00:08,  5.55it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:36<00:07,  5.63it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:36<00:07,  5.73it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:36<00:07,  5.80it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:37<00:07,  5.80it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:37<00:06,  5.85it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:37<00:06,  5.85it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:37<00:06,  5.90it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:37<00:06,  5.90it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:37<00:06,  5.86it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:37<00:05,  6.24it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:38<00:05,  6.57it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:38<00:04,  6.83it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:38<00:04,  7.03it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:38<00:04,  7.18it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:38<00:04,  7.25it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:38<00:03,  7.30it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:38<00:03,  7.21it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:39<00:03,  7.28it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:39<00:03,  7.30it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:39<00:03,  7.28it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:39<00:03,  7.19it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:39<00:03,  7.22it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:39<00:03,  7.17it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:39<00:02,  7.22it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:40<00:02,  7.28it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:40<00:02,  7.28it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:40<00:02,  7.26it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:40<00:02,  6.96it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:40<00:02,  6.83it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:40<00:02,  6.58it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:40<00:02,  6.50it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:41<00:01,  6.53it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:41<00:01,  6.53it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:41<00:01,  6.56it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:41<00:01,  6.53it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:41<00:01,  6.41it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:41<00:01,  6.31it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:42<00:01,  6.41it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:42<00:00,  6.46it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:42<00:00,  6.54it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:42<00:00,  6.49it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:42<00:00,  6.51it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:42<00:00,  6.54it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:42<00:00,  6.59it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:43<00:00,  6.58it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:43<00:00,  6.17it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 78.94it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 8/266 [00:00<00:03, 77.27it/s]saving BB  train1-THALAMUS:   6%|▋         | 17/266 [00:00<00:03, 77.91it/s]saving BB  train1-THALAMUS:  10%|▉         | 26/266 [00:00<00:03, 79.36it/s]saving BB  train1-THALAMUS:  13%|█▎        | 34/266 [00:00<00:02, 79.00it/s]saving BB  train1-THALAMUS:  16%|█▌        | 42/266 [00:00<00:02, 78.96it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:02, 80.54it/s]saving BB  train1-THALAMUS:  23%|██▎       | 61/266 [00:00<00:02, 82.66it/s]saving BB  train1-THALAMUS:  26%|██▋       | 70/266 [00:00<00:02, 81.98it/s]saving BB  train1-THALAMUS:  29%|██▉       | 78/266 [00:00<00:02, 79.99it/s]saving BB  train1-THALAMUS:  32%|███▏      | 86/266 [00:01<00:02, 77.59it/s]saving BB  train1-THALAMUS:  35%|███▌      | 94/266 [00:01<00:02, 75.39it/s]saving BB  train1-THALAMUS:  38%|███▊      | 102/266 [00:01<00:02, 72.60it/s]saving BB  train1-THALAMUS:  41%|████▏     | 110/266 [00:01<00:02, 72.71it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:01<00:02, 73.87it/s]saving BB  train1-THALAMUS:  48%|████▊     | 127/266 [00:01<00:01, 76.55it/s]saving BB  train1-THALAMUS:  51%|█████     | 136/266 [00:01<00:01, 78.67it/s]saving BB  train1-THALAMUS:  55%|█████▍    | 145/266 [00:01<00:01, 81.25it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 154/266 [00:01<00:01, 83.05it/s]saving BB  train1-THALAMUS:  61%|██████▏   | 163/266 [00:02<00:01, 80.97it/s]saving BB  train1-THALAMUS:  65%|██████▍   | 172/266 [00:02<00:01, 75.95it/s]saving BB  train1-THALAMUS:  68%|██████▊   | 180/266 [00:02<00:01, 77.10it/s]saving BB  train1-THALAMUS:  71%|███████   | 188/266 [00:02<00:01, 77.49it/s]saving BB  train1-THALAMUS:  74%|███████▎  | 196/266 [00:02<00:00, 77.82it/s]saving BB  train1-THALAMUS:  77%|███████▋  | 204/266 [00:02<00:00, 74.84it/s]saving BB  train1-THALAMUS:  80%|███████▉  | 212/266 [00:02<00:00, 74.27it/s]saving BB  train1-THALAMUS:  83%|████████▎ | 220/266 [00:02<00:00, 75.20it/s]saving BB  train1-THALAMUS:  86%|████████▌ | 228/266 [00:02<00:00, 76.17it/s]saving BB  train1-THALAMUS:  89%|████████▉ | 237/266 [00:03<00:00, 79.13it/s]saving BB  train1-THALAMUS:  93%|█████████▎| 247/266 [00:03<00:00, 83.03it/s]saving BB  train1-THALAMUS:  97%|█████████▋| 257/266 [00:03<00:00, 85.68it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 86.48it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 79.35it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 80.32it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 79.80it/s]saving BB  train1-THALAMUS Sagittal:   6%|▋         | 17/266 [00:00<00:03, 80.05it/s]saving BB  train1-THALAMUS Sagittal:  10%|▉         | 26/266 [00:00<00:02, 80.36it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 34/266 [00:00<00:02, 79.50it/s]saving BB  train1-THALAMUS Sagittal:  16%|█▌        | 43/266 [00:00<00:02, 80.71it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 53/266 [00:00<00:02, 83.78it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 62/266 [00:00<00:02, 84.63it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:00<00:02, 82.97it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▉       | 78/266 [00:00<00:02, 80.42it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 86/266 [00:01<00:02, 77.03it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▌      | 94/266 [00:01<00:02, 73.00it/s]saving BB  train1-THALAMUS Sagittal:  38%|███▊      | 102/266 [00:01<00:02, 71.15it/s]saving BB  train1-THALAMUS Sagittal:  41%|████▏     | 110/266 [00:01<00:02, 72.12it/s]saving BB  train1-THALAMUS Sagittal:  44%|████▍     | 118/266 [00:01<00:02, 71.98it/s]saving BB  train1-THALAMUS Sagittal:  47%|████▋     | 126/266 [00:01<00:01, 73.51it/s]saving BB  train1-THALAMUS Sagittal:  50%|█████     | 134/266 [00:01<00:01, 74.17it/s]saving BB  train1-THALAMUS Sagittal:  53%|█████▎    | 142/266 [00:01<00:01, 75.35it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 151/266 [00:01<00:01, 77.57it/s]saving BB  train1-THALAMUS Sagittal:  60%|█████▉    | 159/266 [00:02<00:01, 76.48it/s]saving BB  train1-THALAMUS Sagittal:  63%|██████▎   | 167/266 [00:02<00:01, 75.60it/s]saving BB  train1-THALAMUS Sagittal:  66%|██████▌   | 175/266 [00:02<00:01, 74.47it/s]saving BB  train1-THALAMUS Sagittal:  69%|██████▉   | 183/266 [00:02<00:01, 75.41it/s]saving BB  train1-THALAMUS Sagittal:  72%|███████▏  | 191/266 [00:02<00:00, 76.59it/s]saving BB  train1-THALAMUS Sagittal:  75%|███████▍  | 199/266 [00:02<00:00, 75.93it/s]saving BB  train1-THALAMUS Sagittal:  78%|███████▊  | 207/266 [00:02<00:00, 75.64it/s]saving BB  train1-THALAMUS Sagittal:  81%|████████  | 215/266 [00:02<00:00, 75.21it/s]saving BB  train1-THALAMUS Sagittal:  84%|████████▍ | 223/266 [00:02<00:00, 75.17it/s]saving BB  train1-THALAMUS Sagittal:  87%|████████▋ | 231/266 [00:03<00:00, 76.14it/s]saving BB  train1-THALAMUS Sagittal:  90%|█████████ | 240/266 [00:03<00:00, 78.61it/s]saving BB  train1-THALAMUS Sagittal:  94%|█████████▎| 249/266 [00:03<00:00, 81.53it/s]saving BB  train1-THALAMUS Sagittal:  97%|█████████▋| 258/266 [00:03<00:00, 83.53it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 77.65it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<03:47,  1.16it/s]Loading train:   1%|          | 2/266 [00:01<03:39,  1.20it/s]Loading train:   1%|          | 3/266 [00:02<03:27,  1.27it/s]Loading train:   2%|▏         | 4/266 [00:03<03:31,  1.24it/s]Loading train:   2%|▏         | 5/266 [00:03<03:10,  1.37it/s]Loading train:   2%|▏         | 6/266 [00:04<02:51,  1.51it/s]Loading train:   3%|▎         | 7/266 [00:04<02:42,  1.59it/s]Loading train:   3%|▎         | 8/266 [00:05<02:35,  1.66it/s]Loading train:   3%|▎         | 9/266 [00:05<02:30,  1.71it/s]Loading train:   4%|▍         | 10/266 [00:06<02:25,  1.76it/s]Loading train:   4%|▍         | 11/266 [00:06<02:22,  1.79it/s]Loading train:   5%|▍         | 12/266 [00:07<02:24,  1.76it/s]Loading train:   5%|▍         | 13/266 [00:08<02:23,  1.77it/s]Loading train:   5%|▌         | 14/266 [00:08<02:18,  1.81it/s]Loading train:   6%|▌         | 15/266 [00:09<02:15,  1.85it/s]Loading train:   6%|▌         | 16/266 [00:09<02:11,  1.90it/s]Loading train:   6%|▋         | 17/266 [00:10<02:07,  1.95it/s]Loading train:   7%|▋         | 18/266 [00:10<02:05,  1.97it/s]Loading train:   7%|▋         | 19/266 [00:11<02:04,  1.98it/s]Loading train:   8%|▊         | 20/266 [00:11<02:07,  1.94it/s]Loading train:   8%|▊         | 21/266 [00:12<02:09,  1.89it/s]Loading train:   8%|▊         | 22/266 [00:12<02:10,  1.88it/s]Loading train:   9%|▊         | 23/266 [00:13<02:07,  1.90it/s]Loading train:   9%|▉         | 24/266 [00:13<02:02,  1.98it/s]Loading train:   9%|▉         | 25/266 [00:14<01:58,  2.03it/s]Loading train:  10%|▉         | 26/266 [00:14<01:57,  2.05it/s]Loading train:  10%|█         | 27/266 [00:15<01:57,  2.04it/s]Loading train:  11%|█         | 28/266 [00:15<01:58,  2.01it/s]Loading train:  11%|█         | 29/266 [00:16<01:56,  2.03it/s]Loading train:  11%|█▏        | 30/266 [00:16<01:57,  2.00it/s]Loading train:  12%|█▏        | 31/266 [00:17<01:57,  2.01it/s]Loading train:  12%|█▏        | 32/266 [00:17<01:55,  2.02it/s]Loading train:  12%|█▏        | 33/266 [00:18<01:54,  2.04it/s]Loading train:  13%|█▎        | 34/266 [00:18<01:52,  2.06it/s]Loading train:  13%|█▎        | 35/266 [00:19<01:51,  2.08it/s]Loading train:  14%|█▎        | 36/266 [00:19<01:49,  2.10it/s]Loading train:  14%|█▍        | 37/266 [00:19<01:47,  2.13it/s]Loading train:  14%|█▍        | 38/266 [00:20<01:46,  2.13it/s]Loading train:  15%|█▍        | 39/266 [00:20<01:45,  2.15it/s]Loading train:  15%|█▌        | 40/266 [00:21<01:46,  2.12it/s]Loading train:  15%|█▌        | 41/266 [00:21<01:46,  2.11it/s]Loading train:  16%|█▌        | 42/266 [00:22<01:45,  2.13it/s]Loading train:  16%|█▌        | 43/266 [00:22<01:44,  2.14it/s]Loading train:  17%|█▋        | 44/266 [00:23<01:44,  2.12it/s]Loading train:  17%|█▋        | 45/266 [00:23<01:43,  2.13it/s]Loading train:  17%|█▋        | 46/266 [00:24<01:43,  2.13it/s]Loading train:  18%|█▊        | 47/266 [00:24<01:41,  2.15it/s]Loading train:  18%|█▊        | 48/266 [00:25<01:42,  2.13it/s]Loading train:  18%|█▊        | 49/266 [00:25<01:41,  2.13it/s]Loading train:  19%|█▉        | 50/266 [00:26<01:41,  2.12it/s]Loading train:  19%|█▉        | 51/266 [00:26<01:43,  2.08it/s]Loading train:  20%|█▉        | 52/266 [00:27<01:44,  2.04it/s]Loading train:  20%|█▉        | 53/266 [00:27<01:46,  2.01it/s]Loading train:  20%|██        | 54/266 [00:28<01:44,  2.03it/s]Loading train:  21%|██        | 55/266 [00:28<01:42,  2.06it/s]Loading train:  21%|██        | 56/266 [00:28<01:40,  2.09it/s]Loading train:  21%|██▏       | 57/266 [00:29<01:40,  2.08it/s]Loading train:  22%|██▏       | 58/266 [00:29<01:41,  2.04it/s]Loading train:  22%|██▏       | 59/266 [00:30<01:47,  1.93it/s]Loading train:  23%|██▎       | 60/266 [00:31<01:50,  1.86it/s]Loading train:  23%|██▎       | 61/266 [00:31<01:53,  1.80it/s]Loading train:  23%|██▎       | 62/266 [00:32<01:52,  1.81it/s]Loading train:  24%|██▎       | 63/266 [00:32<01:52,  1.80it/s]Loading train:  24%|██▍       | 64/266 [00:33<01:52,  1.79it/s]Loading train:  24%|██▍       | 65/266 [00:33<01:50,  1.82it/s]Loading train:  25%|██▍       | 66/266 [00:34<01:49,  1.83it/s]Loading train:  25%|██▌       | 67/266 [00:35<01:49,  1.82it/s]Loading train:  26%|██▌       | 68/266 [00:35<01:48,  1.83it/s]Loading train:  26%|██▌       | 69/266 [00:36<01:48,  1.81it/s]Loading train:  26%|██▋       | 70/266 [00:36<01:48,  1.80it/s]Loading train:  27%|██▋       | 71/266 [00:37<01:46,  1.83it/s]Loading train:  27%|██▋       | 72/266 [00:37<01:46,  1.83it/s]Loading train:  27%|██▋       | 73/266 [00:38<01:45,  1.83it/s]Loading train:  28%|██▊       | 74/266 [00:38<01:44,  1.83it/s]Loading train:  28%|██▊       | 75/266 [00:39<01:43,  1.84it/s]Loading train:  29%|██▊       | 76/266 [00:39<01:43,  1.84it/s]Loading train:  29%|██▉       | 77/266 [00:40<02:07,  1.49it/s]Loading train:  29%|██▉       | 78/266 [00:41<02:18,  1.36it/s]Loading train:  30%|██▉       | 79/266 [00:42<02:19,  1.34it/s]Loading train:  30%|███       | 80/266 [00:43<02:18,  1.35it/s]Loading train:  30%|███       | 81/266 [00:44<02:26,  1.26it/s]Loading train:  31%|███       | 82/266 [00:44<02:16,  1.35it/s]Loading train:  31%|███       | 83/266 [00:45<02:06,  1.44it/s]Loading train:  32%|███▏      | 84/266 [00:46<02:00,  1.51it/s]Loading train:  32%|███▏      | 85/266 [00:46<01:57,  1.55it/s]Loading train:  32%|███▏      | 86/266 [00:47<01:55,  1.56it/s]Loading train:  33%|███▎      | 87/266 [00:47<01:53,  1.58it/s]Loading train:  33%|███▎      | 88/266 [00:48<01:51,  1.59it/s]Loading train:  33%|███▎      | 89/266 [00:49<01:49,  1.62it/s]Loading train:  34%|███▍      | 90/266 [00:49<01:48,  1.63it/s]Loading train:  34%|███▍      | 91/266 [00:50<01:46,  1.64it/s]Loading train:  35%|███▍      | 92/266 [00:50<01:45,  1.64it/s]Loading train:  35%|███▍      | 93/266 [00:51<01:46,  1.63it/s]Loading train:  35%|███▌      | 94/266 [00:52<01:45,  1.64it/s]Loading train:  36%|███▌      | 95/266 [00:52<01:42,  1.66it/s]Loading train:  36%|███▌      | 96/266 [00:53<01:42,  1.66it/s]Loading train:  36%|███▋      | 97/266 [00:53<01:41,  1.66it/s]Loading train:  37%|███▋      | 98/266 [00:54<01:39,  1.68it/s]Loading train:  37%|███▋      | 99/266 [00:55<01:38,  1.69it/s]Loading train:  38%|███▊      | 100/266 [00:55<01:37,  1.71it/s]Loading train:  38%|███▊      | 101/266 [00:56<01:35,  1.73it/s]Loading train:  38%|███▊      | 102/266 [00:56<01:34,  1.74it/s]Loading train:  39%|███▊      | 103/266 [00:57<01:32,  1.77it/s]Loading train:  39%|███▉      | 104/266 [00:57<01:31,  1.78it/s]Loading train:  39%|███▉      | 105/266 [00:58<01:30,  1.78it/s]Loading train:  40%|███▉      | 106/266 [00:58<01:29,  1.79it/s]Loading train:  40%|████      | 107/266 [00:59<01:29,  1.78it/s]Loading train:  41%|████      | 108/266 [01:00<01:28,  1.79it/s]Loading train:  41%|████      | 109/266 [01:00<01:27,  1.79it/s]Loading train:  41%|████▏     | 110/266 [01:01<01:26,  1.80it/s]Loading train:  42%|████▏     | 111/266 [01:01<01:25,  1.80it/s]Loading train:  42%|████▏     | 112/266 [01:02<01:25,  1.80it/s]Loading train:  42%|████▏     | 113/266 [01:02<01:25,  1.79it/s]Loading train:  43%|████▎     | 114/266 [01:03<01:25,  1.79it/s]Loading train:  43%|████▎     | 115/266 [01:04<01:24,  1.80it/s]Loading train:  44%|████▎     | 116/266 [01:04<01:23,  1.80it/s]Loading train:  44%|████▍     | 117/266 [01:05<01:23,  1.78it/s]Loading train:  44%|████▍     | 118/266 [01:05<01:21,  1.82it/s]Loading train:  45%|████▍     | 119/266 [01:06<01:20,  1.83it/s]Loading train:  45%|████▌     | 120/266 [01:06<01:18,  1.86it/s]Loading train:  45%|████▌     | 121/266 [01:07<01:17,  1.87it/s]Loading train:  46%|████▌     | 122/266 [01:07<01:16,  1.89it/s]Loading train:  46%|████▌     | 123/266 [01:08<01:14,  1.92it/s]Loading train:  47%|████▋     | 124/266 [01:08<01:13,  1.92it/s]Loading train:  47%|████▋     | 125/266 [01:09<01:13,  1.92it/s]Loading train:  47%|████▋     | 126/266 [01:09<01:12,  1.93it/s]Loading train:  48%|████▊     | 127/266 [01:10<01:12,  1.92it/s]Loading train:  48%|████▊     | 128/266 [01:10<01:11,  1.92it/s]Loading train:  48%|████▊     | 129/266 [01:11<01:11,  1.92it/s]Loading train:  49%|████▉     | 130/266 [01:11<01:10,  1.92it/s]Loading train:  49%|████▉     | 131/266 [01:12<01:10,  1.92it/s]Loading train:  50%|████▉     | 132/266 [01:12<01:10,  1.90it/s]Loading train:  50%|█████     | 133/266 [01:13<01:09,  1.91it/s]Loading train:  50%|█████     | 134/266 [01:14<01:09,  1.90it/s]Loading train:  51%|█████     | 135/266 [01:14<01:09,  1.88it/s]Loading train:  51%|█████     | 136/266 [01:15<01:08,  1.89it/s]Loading train:  52%|█████▏    | 137/266 [01:15<01:06,  1.93it/s]Loading train:  52%|█████▏    | 138/266 [01:16<01:04,  1.97it/s]Loading train:  52%|█████▏    | 139/266 [01:16<01:03,  1.99it/s]Loading train:  53%|█████▎    | 140/266 [01:17<01:02,  2.01it/s]Loading train:  53%|█████▎    | 141/266 [01:17<01:02,  2.00it/s]Loading train:  53%|█████▎    | 142/266 [01:18<01:02,  1.97it/s]Loading train:  54%|█████▍    | 143/266 [01:18<01:02,  1.97it/s]Loading train:  54%|█████▍    | 144/266 [01:19<01:01,  1.98it/s]Loading train:  55%|█████▍    | 145/266 [01:19<01:01,  1.96it/s]Loading train:  55%|█████▍    | 146/266 [01:20<01:01,  1.96it/s]Loading train:  55%|█████▌    | 147/266 [01:20<01:00,  1.97it/s]Loading train:  56%|█████▌    | 148/266 [01:21<01:00,  1.96it/s]Loading train:  56%|█████▌    | 149/266 [01:21<00:58,  1.99it/s]Loading train:  56%|█████▋    | 150/266 [01:22<00:57,  2.00it/s]Loading train:  57%|█████▋    | 151/266 [01:22<00:57,  1.99it/s]Loading train:  57%|█████▋    | 152/266 [01:23<00:56,  2.03it/s]Loading train:  58%|█████▊    | 153/266 [01:23<00:56,  2.01it/s]Loading train:  58%|█████▊    | 154/266 [01:24<00:58,  1.90it/s]Loading train:  58%|█████▊    | 155/266 [01:24<01:00,  1.84it/s]Loading train:  59%|█████▊    | 156/266 [01:25<01:00,  1.81it/s]Loading train:  59%|█████▉    | 157/266 [01:25<01:00,  1.80it/s]Loading train:  59%|█████▉    | 158/266 [01:26<01:00,  1.79it/s]Loading train:  60%|█████▉    | 159/266 [01:27<01:00,  1.78it/s]Loading train:  60%|██████    | 160/266 [01:27<00:59,  1.78it/s]Loading train:  61%|██████    | 161/266 [01:28<00:59,  1.77it/s]Loading train:  61%|██████    | 162/266 [01:28<00:58,  1.77it/s]Loading train:  61%|██████▏   | 163/266 [01:29<00:57,  1.79it/s]Loading train:  62%|██████▏   | 164/266 [01:29<00:56,  1.80it/s]Loading train:  62%|██████▏   | 165/266 [01:30<00:56,  1.80it/s]Loading train:  62%|██████▏   | 166/266 [01:30<00:55,  1.81it/s]Loading train:  63%|██████▎   | 167/266 [01:31<00:54,  1.81it/s]Loading train:  63%|██████▎   | 168/266 [01:32<00:54,  1.79it/s]Loading train:  64%|██████▎   | 169/266 [01:32<00:53,  1.81it/s]Loading train:  64%|██████▍   | 170/266 [01:33<00:52,  1.84it/s]Loading train:  64%|██████▍   | 171/266 [01:33<00:51,  1.85it/s]Loading train:  65%|██████▍   | 172/266 [01:34<00:57,  1.65it/s]Loading train:  65%|██████▌   | 173/266 [01:35<01:03,  1.46it/s]Loading train:  65%|██████▌   | 174/266 [01:36<01:05,  1.40it/s]Loading train:  66%|██████▌   | 175/266 [01:36<01:02,  1.46it/s]Loading train:  66%|██████▌   | 176/266 [01:37<01:02,  1.43it/s]Loading train:  67%|██████▋   | 177/266 [01:37<00:56,  1.58it/s]Loading train:  67%|██████▋   | 178/266 [01:38<00:51,  1.71it/s]Loading train:  67%|██████▋   | 179/266 [01:38<00:48,  1.79it/s]Loading train:  68%|██████▊   | 180/266 [01:39<00:46,  1.86it/s]Loading train:  68%|██████▊   | 181/266 [01:39<00:44,  1.91it/s]Loading train:  68%|██████▊   | 182/266 [01:40<00:43,  1.94it/s]Loading train:  69%|██████▉   | 183/266 [01:40<00:41,  1.98it/s]Loading train:  69%|██████▉   | 184/266 [01:41<00:41,  1.99it/s]Loading train:  70%|██████▉   | 185/266 [01:41<00:40,  1.99it/s]Loading train:  70%|██████▉   | 186/266 [01:42<00:40,  1.99it/s]Loading train:  70%|███████   | 187/266 [01:42<00:39,  1.99it/s]Loading train:  71%|███████   | 188/266 [01:43<00:39,  1.97it/s]Loading train:  71%|███████   | 189/266 [01:43<00:38,  1.98it/s]Loading train:  71%|███████▏  | 190/266 [01:44<00:39,  1.94it/s]Loading train:  72%|███████▏  | 191/266 [01:44<00:39,  1.91it/s]Loading train:  72%|███████▏  | 192/266 [01:45<00:38,  1.92it/s]Loading train:  73%|███████▎  | 193/266 [01:45<00:38,  1.88it/s]Loading train:  73%|███████▎  | 194/266 [01:46<00:38,  1.86it/s]Loading train:  73%|███████▎  | 195/266 [01:47<00:39,  1.78it/s]Loading train:  74%|███████▎  | 196/266 [01:47<00:39,  1.78it/s]Loading train:  74%|███████▍  | 197/266 [01:48<00:39,  1.74it/s]Loading train:  74%|███████▍  | 198/266 [01:48<00:39,  1.72it/s]Loading train:  75%|███████▍  | 199/266 [01:49<00:38,  1.73it/s]Loading train:  75%|███████▌  | 200/266 [01:50<00:38,  1.73it/s]Loading train:  76%|███████▌  | 201/266 [01:50<00:37,  1.74it/s]Loading train:  76%|███████▌  | 202/266 [01:51<00:37,  1.73it/s]Loading train:  76%|███████▋  | 203/266 [01:51<00:35,  1.76it/s]Loading train:  77%|███████▋  | 204/266 [01:52<00:35,  1.75it/s]Loading train:  77%|███████▋  | 205/266 [01:52<00:34,  1.74it/s]Loading train:  77%|███████▋  | 206/266 [01:53<00:33,  1.77it/s]Loading train:  78%|███████▊  | 207/266 [01:54<00:34,  1.73it/s]Loading train:  78%|███████▊  | 208/266 [01:54<00:32,  1.76it/s]Loading train:  79%|███████▊  | 209/266 [01:55<00:32,  1.75it/s]Loading train:  79%|███████▉  | 210/266 [01:55<00:32,  1.74it/s]Loading train:  79%|███████▉  | 211/266 [01:56<00:31,  1.76it/s]Loading train:  80%|███████▉  | 212/266 [01:56<00:30,  1.78it/s]Loading train:  80%|████████  | 213/266 [01:57<00:30,  1.75it/s]Loading train:  80%|████████  | 214/266 [01:58<00:29,  1.74it/s]Loading train:  81%|████████  | 215/266 [01:58<00:29,  1.73it/s]Loading train:  81%|████████  | 216/266 [01:59<00:28,  1.74it/s]Loading train:  82%|████████▏ | 217/266 [01:59<00:28,  1.70it/s]Loading train:  82%|████████▏ | 218/266 [02:00<00:28,  1.70it/s]Loading train:  82%|████████▏ | 219/266 [02:00<00:27,  1.71it/s]Loading train:  83%|████████▎ | 220/266 [02:01<00:26,  1.73it/s]Loading train:  83%|████████▎ | 221/266 [02:02<00:26,  1.68it/s]Loading train:  83%|████████▎ | 222/266 [02:02<00:25,  1.70it/s]Loading train:  84%|████████▍ | 223/266 [02:03<00:25,  1.70it/s]Loading train:  84%|████████▍ | 224/266 [02:03<00:24,  1.72it/s]Loading train:  85%|████████▍ | 225/266 [02:04<00:23,  1.72it/s]Loading train:  85%|████████▍ | 226/266 [02:05<00:23,  1.73it/s]Loading train:  85%|████████▌ | 227/266 [02:08<00:51,  1.31s/it]Loading train:  86%|████████▌ | 228/266 [02:13<01:39,  2.63s/it]Loading train:  86%|████████▌ | 229/266 [02:18<02:01,  3.28s/it]Loading train:  86%|████████▋ | 230/266 [02:23<02:13,  3.70s/it]Loading train:  87%|████████▋ | 231/266 [02:27<02:13,  3.82s/it]Loading train:  87%|████████▋ | 232/266 [02:30<02:06,  3.72s/it]Loading train:  88%|████████▊ | 233/266 [02:34<02:00,  3.66s/it]Loading train:  88%|████████▊ | 234/266 [02:37<01:55,  3.62s/it]Loading train:  88%|████████▊ | 235/266 [02:41<01:48,  3.50s/it]Loading train:  89%|████████▊ | 236/266 [02:44<01:45,  3.53s/it]Loading train:  89%|████████▉ | 237/266 [02:50<02:00,  4.16s/it]Loading train:  89%|████████▉ | 238/266 [02:55<02:03,  4.41s/it]Loading train:  90%|████████▉ | 239/266 [03:00<02:05,  4.64s/it]Loading train:  90%|█████████ | 240/266 [03:05<02:01,  4.67s/it]Loading train:  91%|█████████ | 241/266 [03:09<01:50,  4.42s/it]Loading train:  91%|█████████ | 242/266 [03:12<01:41,  4.25s/it]Loading train:  91%|█████████▏| 243/266 [03:16<01:31,  3.97s/it]Loading train:  92%|█████████▏| 244/266 [03:19<01:22,  3.75s/it]Loading train:  92%|█████████▏| 245/266 [03:22<01:17,  3.67s/it]Loading train:  92%|█████████▏| 246/266 [03:26<01:11,  3.60s/it]Loading train:  93%|█████████▎| 247/266 [03:29<01:06,  3.52s/it]Loading train:  93%|█████████▎| 248/266 [03:33<01:02,  3.48s/it]Loading train:  94%|█████████▎| 249/266 [03:37<01:01,  3.64s/it]Loading train:  94%|█████████▍| 250/266 [03:41<01:00,  3.80s/it]Loading train:  94%|█████████▍| 251/266 [03:45<00:57,  3.84s/it]Loading train:  95%|█████████▍| 252/266 [03:48<00:53,  3.79s/it]Loading train:  95%|█████████▌| 253/266 [03:52<00:49,  3.82s/it]Loading train:  95%|█████████▌| 254/266 [03:56<00:45,  3.81s/it]Loading train:  96%|█████████▌| 255/266 [04:00<00:41,  3.78s/it]Loading train:  96%|█████████▌| 256/266 [04:04<00:38,  3.82s/it]Loading train:  97%|█████████▋| 257/266 [04:08<00:34,  3.87s/it]Loading train:  97%|█████████▋| 258/266 [04:11<00:30,  3.82s/it]Loading train:  97%|█████████▋| 259/266 [04:15<00:26,  3.83s/it]Loading train:  98%|█████████▊| 260/266 [04:19<00:22,  3.78s/it]Loading train:  98%|█████████▊| 261/266 [04:23<00:19,  3.85s/it]Loading train:  98%|█████████▊| 262/266 [04:27<00:15,  3.82s/it]Loading train:  99%|█████████▉| 263/266 [04:31<00:11,  3.83s/it]Loading train:  99%|█████████▉| 264/266 [04:34<00:07,  3.85s/it]Loading train: 100%|█████████▉| 265/266 [04:38<00:03,  3.78s/it]Loading train: 100%|██████████| 266/266 [04:42<00:00,  3.72s/it]Loading train: 100%|██████████| 266/266 [04:42<00:00,  1.06s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 53.00it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 52.50it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:04, 51.72it/s]concatenating: train:   9%|▊         | 23/266 [00:00<00:04, 53.49it/s]concatenating: train:  11%|█         | 29/266 [00:00<00:04, 54.39it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 55.02it/s]concatenating: train:  15%|█▌        | 41/266 [00:00<00:04, 55.64it/s]concatenating: train:  18%|█▊        | 47/266 [00:00<00:03, 56.21it/s]concatenating: train:  20%|█▉        | 53/266 [00:00<00:03, 56.36it/s]concatenating: train:  22%|██▏       | 59/266 [00:01<00:03, 55.28it/s]concatenating: train:  24%|██▍       | 65/266 [00:01<00:03, 53.80it/s]concatenating: train:  27%|██▋       | 71/266 [00:01<00:03, 52.65it/s]concatenating: train:  29%|██▉       | 77/266 [00:01<00:03, 51.62it/s]concatenating: train:  31%|███       | 83/266 [00:01<00:03, 50.52it/s]concatenating: train:  33%|███▎      | 89/266 [00:01<00:03, 50.65it/s]concatenating: train:  36%|███▌      | 95/266 [00:01<00:03, 49.66it/s]concatenating: train:  38%|███▊      | 101/266 [00:01<00:03, 50.24it/s]concatenating: train:  40%|████      | 107/266 [00:02<00:03, 48.84it/s]concatenating: train:  42%|████▏     | 113/266 [00:02<00:03, 49.16it/s]concatenating: train:  44%|████▍     | 118/266 [00:02<00:03, 47.88it/s]concatenating: train:  46%|████▌     | 123/266 [00:02<00:03, 47.56it/s]concatenating: train:  48%|████▊     | 129/266 [00:02<00:02, 48.55it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:02, 48.63it/s]concatenating: train:  53%|█████▎    | 140/266 [00:02<00:02, 49.80it/s]concatenating: train:  55%|█████▍    | 146/266 [00:02<00:02, 50.59it/s]concatenating: train:  57%|█████▋    | 152/266 [00:02<00:02, 51.24it/s]concatenating: train:  59%|█████▉    | 158/266 [00:03<00:02, 51.70it/s]concatenating: train:  62%|██████▏   | 164/266 [00:03<00:01, 52.63it/s]concatenating: train:  64%|██████▍   | 170/266 [00:03<00:01, 52.83it/s]concatenating: train:  67%|██████▋   | 177/266 [00:03<00:01, 55.43it/s]concatenating: train:  69%|██████▉   | 183/266 [00:03<00:01, 55.97it/s]concatenating: train:  71%|███████   | 189/266 [00:03<00:01, 56.31it/s]concatenating: train:  73%|███████▎  | 195/266 [00:03<00:01, 54.77it/s]concatenating: train:  76%|███████▌  | 201/266 [00:03<00:01, 55.91it/s]concatenating: train:  78%|███████▊  | 207/266 [00:03<00:01, 55.53it/s]concatenating: train:  80%|████████  | 213/266 [00:04<00:00, 54.37it/s]concatenating: train:  82%|████████▏ | 219/266 [00:04<00:00, 52.91it/s]concatenating: train:  85%|████████▍ | 225/266 [00:04<00:00, 50.99it/s]concatenating: train:  87%|████████▋ | 231/266 [00:04<00:00, 51.18it/s]concatenating: train:  89%|████████▉ | 237/266 [00:04<00:00, 51.94it/s]concatenating: train:  91%|█████████▏| 243/266 [00:04<00:00, 52.71it/s]concatenating: train:  94%|█████████▎| 249/266 [00:04<00:00, 53.71it/s]concatenating: train:  96%|█████████▌| 256/266 [00:04<00:00, 56.51it/s]concatenating: train:  99%|█████████▉| 263/266 [00:04<00:00, 57.54it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 53.05it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:07<00:21,  7.03s/it]Loading test:  50%|█████     | 2/4 [00:12<00:13,  6.54s/it]Loading test:  75%|███████▌  | 3/4 [00:23<00:07,  7.95s/it]Loading test: 100%|██████████| 4/4 [00:37<00:00,  9.84s/it]Loading test: 100%|██████████| 4/4 [00:37<00:00,  9.48s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 58.43it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 0  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 40 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   2020-01-22 06:24:19.586310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 06:24:19.586440: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 06:24:19.586456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 06:24:19.586465: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 06:24:19.586835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 887,653
Non-trainable params: 1,600
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.83334236e-02 3.27755634e-02 8.44757351e-02 1.02593841e-02
 2.87778567e-02 7.66326780e-03 8.71356285e-02 1.12862740e-01
 9.16407964e-02 1.37518217e-02 2.76798371e-01 1.85254091e-01
 2.71321148e-04]
Train on 10040 samples, validate on 150 samples
Epoch 1/300
 - 30s - loss: 0.5595 - acc: 0.9054 - mDice: 0.3973 - val_loss: 0.6601 - val_acc: 0.9392 - val_mDice: 0.2873

Epoch 00001: val_mDice improved from -inf to 0.28725, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 2/300
 - 25s - loss: 0.3955 - acc: 0.9352 - mDice: 0.5740 - val_loss: 0.6367 - val_acc: 0.9432 - val_mDice: 0.3116

Epoch 00002: val_mDice improved from 0.28725 to 0.31159, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 3/300
 - 25s - loss: 0.3610 - acc: 0.9398 - mDice: 0.6111 - val_loss: 0.6434 - val_acc: 0.9472 - val_mDice: 0.3046

Epoch 00003: val_mDice did not improve from 0.31159
Epoch 4/300
 - 25s - loss: 0.3416 - acc: 0.9423 - mDice: 0.6321 - val_loss: 0.6538 - val_acc: 0.9363 - val_mDice: 0.2874

Epoch 00004: val_mDice did not improve from 0.31159
Epoch 5/300
 - 25s - loss: 0.3269 - acc: 0.9443 - mDice: 0.6479 - val_loss: 0.6376 - val_acc: 0.9471 - val_mDice: 0.3094

Epoch 00005: val_mDice did not improve from 0.31159
Epoch 6/300
 - 25s - loss: 0.3200 - acc: 0.9453 - mDice: 0.6554 - val_loss: 0.6528 - val_acc: 0.9429 - val_mDice: 0.2903

Epoch 00006: val_mDice did not improve from 0.31159
Epoch 7/300
 - 25s - loss: 0.3071 - acc: 0.9466 - mDice: 0.6693 - val_loss: 0.6335 - val_acc: 0.9434 - val_mDice: 0.3019

Epoch 00007: val_mDice did not improve from 0.31159
Epoch 8/300
 - 25s - loss: 0.3014 - acc: 0.9478 - mDice: 0.6754 - val_loss: 0.6512 - val_acc: 0.9457 - val_mDice: 0.2858

Epoch 00008: val_mDice did not improve from 0.31159
Epoch 9/300
 - 25s - loss: 0.2953 - acc: 0.9482 - mDice: 0.6820 - val_loss: 0.6498 - val_acc: 0.9412 - val_mDice: 0.2747

Epoch 00009: val_mDice did not improve from 0.31159
Epoch 10/300
 - 25s - loss: 0.2945 - acc: 0.9484 - mDice: 0.6829 - val_loss: 0.5891 - val_acc: 0.9477 - val_mDice: 0.3031

Epoch 00010: val_mDice did not improve from 0.31159
Epoch 11/300
 - 25s - loss: 0.2855 - acc: 0.9495 - mDice: 0.6925 - val_loss: 0.6126 - val_acc: 0.9484 - val_mDice: 0.3169

Epoch 00011: val_mDice improved from 0.31159 to 0.31688, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 12/300
 - 25s - loss: 0.2801 - acc: 0.9501 - mDice: 0.6984 - val_loss: 0.5868 - val_acc: 0.9475 - val_mDice: 0.3131

Epoch 00012: val_mDice did not improve from 0.31688
Epoch 13/300
 - 24s - loss: 0.2755 - acc: 0.9505 - mDice: 0.7033 - val_loss: 0.5465 - val_acc: 0.9480 - val_mDice: 0.3189

Epoch 00013: val_mDice improved from 0.31688 to 0.31890, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 14/300
 - 25s - loss: 0.2767 - acc: 0.9509 - mDice: 0.7020 - val_loss: 0.4085 - val_acc: 0.9481 - val_mDice: 0.3076

Epoch 00014: val_mDice did not improve from 0.31890
Epoch 15/300
 - 24s - loss: 0.2692 - acc: 0.9514 - mDice: 0.7101 - val_loss: 0.4964 - val_acc: 0.9490 - val_mDice: 0.3219

Epoch 00015: val_mDice improved from 0.31890 to 0.32192, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 16/300
 - 24s - loss: 0.2661 - acc: 0.9516 - mDice: 0.7135 - val_loss: 0.4214 - val_acc: 0.9473 - val_mDice: 0.3112

Epoch 00016: val_mDice did not improve from 0.32192
Epoch 17/300
 - 24s - loss: 0.2680 - acc: 0.9516 - mDice: 0.7115 - val_loss: 0.2991 - val_acc: 0.9477 - val_mDice: 0.3109

Epoch 00017: val_mDice did not improve from 0.32192
Epoch 18/300
 - 24s - loss: 0.2682 - acc: 0.9521 - mDice: 0.7112 - val_loss: 0.4018 - val_acc: 0.9479 - val_mDice: 0.3059

Epoch 00018: val_mDice did not improve from 0.32192
Epoch 19/300
 - 25s - loss: 0.2607 - acc: 0.9525 - mDice: 0.7193 - val_loss: 0.3484 - val_acc: 0.9459 - val_mDice: 0.2974

Epoch 00019: val_mDice did not improve from 0.32192
Epoch 20/300
 - 25s - loss: 0.2582 - acc: 0.9529 - mDice: 0.7220 - val_loss: 0.4189 - val_acc: 0.9478 - val_mDice: 0.3175

Epoch 00020: val_mDice did not improve from 0.32192
Epoch 21/300
 - 25s - loss: 0.2600 - acc: 0.9529 - mDice: 0.7201 - val_loss: 0.1976 - val_acc: 0.9456 - val_mDice: 0.3046

Epoch 00021: val_mDice did not improve from 0.32192
Epoch 22/300
 - 25s - loss: 0.2591 - acc: 0.9531 - mDice: 0.7210 - val_loss: 0.2692 - val_acc: 0.9485 - val_mDice: 0.3086

Epoch 00022: val_mDice did not improve from 0.32192
Epoch 23/300
 - 25s - loss: 0.2540 - acc: 0.9535 - mDice: 0.7265 - val_loss: 0.3350 - val_acc: 0.9477 - val_mDice: 0.3122

Epoch 00023: val_mDice did not improve from 0.32192
Epoch 24/300
 - 25s - loss: 0.2530 - acc: 0.9535 - mDice: 0.7276 - val_loss: 0.2305 - val_acc: 0.9475 - val_mDice: 0.3004

Epoch 00024: val_mDice did not improve from 0.32192
Epoch 25/300
 - 25s - loss: 0.2505 - acc: 0.9539 - mDice: 0.7303 - val_loss: 0.1574 - val_acc: 0.9475 - val_mDice: 0.3065

Epoch 00025: val_mDice did not improve from 0.32192
Epoch 26/300
 - 24s - loss: 0.2491 - acc: 0.9541 - mDice: 0.7318 - val_loss: 0.1777 - val_acc: 0.9488 - val_mDice: 0.3121

Epoch 00026: val_mDice did not improve from 0.32192
Epoch 27/300
 - 24s - loss: 0.2467 - acc: 0.9543 - mDice: 0.7344 - val_loss: 0.1535 - val_acc: 0.9468 - val_mDice: 0.3006

Epoch 00027: val_mDice did not improve from 0.32192
Epoch 28/300
 - 24s - loss: 0.2495 - acc: 0.9541 - mDice: 0.7313 - val_loss: 0.0664 - val_acc: 0.9507 - val_mDice: 0.3135

Epoch 00028: val_mDice did not improve from 0.32192
Epoch 29/300
 - 24s - loss: 0.2481 - acc: 0.9543 - mDice: 0.7328 - val_loss: 0.0893 - val_acc: 0.9491 - val_mDice: 0.3182

Epoch 00029: val_mDice did not improve from 0.32192
Epoch 30/300
 - 24s - loss: 0.2472 - acc: 0.9542 - mDice: 0.7338 - val_loss: 0.0945 - val_acc: 0.9492 - val_mDice: 0.3152

Epoch 00030: val_mDice did not improve from 0.32192

Epoch 00030: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 31/300
 - 24s - loss: 0.2395 - acc: 0.9553 - mDice: 0.7421 - val_loss: 0.1336 - val_acc: 0.9494 - val_mDice: 0.3265

Epoch 00031: val_mDice improved from 0.32192 to 0.32650, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd0/best_model_weights.h5
Epoch 32/300
 - 24s - loss: 0.2346 - acc: 0.9561 - mDice: 0.7474 - val_loss: 0.1012 - val_acc: 0.9495 - val_mDice: 0.3243

Epoch 00032: val_mDice did not improve from 0.32650
Epoch 33/300
 - 24s - loss: 0.2300 - acc: 0.9565 - mDice: 0.7523 - val_loss: 0.0615 - val_acc: 0.9489 - val_mDice: 0.3178

Epoch 00033: val_mDice did not improve from 0.32650
Epoch 34/300
 - 24s - loss: 0.2284 - acc: 0.9565 - mDice: 0.7541 - val_loss: 0.1191 - val_acc: 0.9478 - val_mDice: 0.3121

Epoch 00034: val_mDice did not improve from 0.32650
Epoch 35/300
 - 23s - loss: 0.2273 - acc: 0.9565 - mDice: 0.7553 - val_loss: 0.0783 - val_acc: 0.9486 - val_mDice: 0.3150

Epoch 00035: val_mDice did not improve from 0.32650
Epoch 36/300
 - 24s - loss: 0.2273 - acc: 0.9568 - mDice: 0.7554 - val_loss: 0.1059 - val_acc: 0.9484 - val_mDice: 0.3144

Epoch 00036: val_mDice did not improve from 0.32650
Epoch 37/300
 - 24s - loss: 0.2242 - acc: 0.9566 - mDice: 0.7586 - val_loss: 0.1378 - val_acc: 0.9500 - val_mDice: 0.3189

Epoch 00037: val_mDice did not improve from 0.32650
Epoch 38/300
 - 23s - loss: 0.2226 - acc: 0.9568 - mDice: 0.7604 - val_loss: 0.0778 - val_acc: 0.9487 - val_mDice: 0.3194

Epoch 00038: val_mDice did not improve from 0.32650
Epoch 39/300
 - 24s - loss: 0.2262 - acc: 0.9569 - mDice: 0.7565 - val_loss: 0.1362 - val_acc: 0.9488 - val_mDice: 0.3050

Epoch 00039: val_mDice did not improve from 0.32650
Epoch 40/300
 - 23s - loss: 0.2200 - acc: 0.9572 - mDice: 0.7632 - val_loss: 0.0317 - val_acc: 0.9472 - val_mDice: 0.2937

Epoch 00040: val_mDice did not improve from 0.32650
Epoch 41/300
 - 23s - loss: 0.2267 - acc: 0.9571 - mDice: 0.7560 - val_loss: 0.1213 - val_acc: 0.9451 - val_mDice: 0.3027

Epoch 00041: val_mDice did not improve from 0.32650
Epoch 42/300
 - 24s - loss: 0.2231 - acc: 0.9573 - mDice: 0.7598 - val_loss: 0.0830 - val_acc: 0.9481 - val_mDice: 0.3163

Epoch 00042: val_mDice did not improve from 0.32650
Epoch 43/300
 - 23s - loss: 0.2195 - acc: 0.9573 - mDice: 0.7637 - val_loss: 0.0532 - val_acc: 0.9480 - val_mDice: 0.3111

Epoch 00043: val_mDice did not improve from 0.32650
Epoch 44/300
 - 23s - loss: 0.2215 - acc: 0.9574 - mDice: 0.7614 - val_loss: 0.0302 - val_acc: 0.9490 - val_mDice: 0.3204

Epoch 00044: val_mDice did not improve from 0.32650
Epoch 45/300
 - 24s - loss: 0.2216 - acc: 0.9563 - mDice: 0.7509 - val_loss: 0.0508 - val_acc: 0.9463 - val_mDice: 0.3078

Epoch 00045: val_mDice did not improve from 0.32650
Epoch 46/300
 - 24s - loss: 0.2148 - acc: 0.9559 - mDice: 0.7512 - val_loss: -7.2408e-03 - val_acc: 0.9498 - val_mDice: 0.3210

Epoch 00046: val_mDice did not improve from 0.32650

Epoch 00046: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 47/300
 - 24s - loss: 0.2061 - acc: 0.9565 - mDice: 0.7536 - val_loss: 0.0561 - val_acc: 0.9474 - val_mDice: 0.3155

Epoch 00047: val_mDice did not improve from 0.32650
Epoch 48/300
 - 24s - loss: 0.1939 - acc: 0.9569 - mDice: 0.7632 - val_loss: 0.0073 - val_acc: 0.9496 - val_mDice: 0.3149

Epoch 00048: val_mDice did not improve from 0.32650
Epoch 49/300
 - 24s - loss: 0.2008 - acc: 0.9570 - mDice: 0.7570 - val_loss: -5.7490e-03 - val_acc: 0.9491 - val_mDice: 0.3079

Epoch 00049: val_mDice did not improve from 0.32650
Epoch 50/300
 - 24s - loss: 0.1971 - acc: 0.9569 - mDice: 0.7565 - val_loss: -4.8854e-02 - val_acc: 0.9488 - val_mDice: 0.3101

Epoch 00050: val_mDice did not improve from 0.32650
Epoch 51/300
 - 24s - loss: 0.1943 - acc: 0.9569 - mDice: 0.7598 - val_loss: -1.9522e-02 - val_acc: 0.9491 - val_mDice: 0.3142

Epoch 00051: val_mDice did not improve from 0.32650
Epoch 52/300
 - 24s - loss: 0.1979 - acc: 0.9562 - mDice: 0.7522 - val_loss: -3.3678e-02 - val_acc: 0.9492 - val_mDice: 0.3051

Epoch 00052: val_mDice did not improve from 0.32650
Epoch 53/300
 - 24s - loss: 0.1911 - acc: 0.9561 - mDice: 0.7503 - val_loss: -8.8249e-03 - val_acc: 0.9493 - val_mDice: 0.3116

Epoch 00053: val_mDice did not improve from 0.32650
Epoch 54/300
 - 24s - loss: 0.1896 - acc: 0.9562 - mDice: 0.7532 - val_loss: -4.6309e-02 - val_acc: 0.9495 - val_mDice: 0.3078

Epoch 00054: val_mDice did not improve from 0.32650
Epoch 55/300
 - 24s - loss: 0.1879 - acc: 0.9564 - mDice: 0.7561 - val_loss: -1.1258e-02 - val_acc: 0.9490 - val_mDice: 0.3142

Epoch 00055: val_mDice did not improve from 0.32650
Epoch 56/300
 - 23s - loss: 0.1901 - acc: 0.9561 - mDice: 0.7517 - val_loss: -3.8576e-02 - val_acc: 0.9498 - val_mDice: 0.3105

Epoch 00056: val_mDice did not improve from 0.32650
Epoch 57/300
 - 24s - loss: 0.1880 - acc: 0.9558 - mDice: 0.7517 - val_loss: -4.7387e-02 - val_acc: 0.9484 - val_mDice: 0.2985

Epoch 00057: val_mDice did not improve from 0.32650
Epoch 58/300
 - 23s - loss: 0.1886 - acc: 0.9557 - mDice: 0.7469 - val_loss: -1.5555e-02 - val_acc: 0.9469 - val_mDice: 0.3078

Epoch 00058: val_mDice did not improve from 0.32650
Epoch 59/300
 - 24s - loss: 0.1835 - acc: 0.9563 - mDice: 0.7520 - val_loss: -1.9321e-02 - val_acc: 0.9496 - val_mDice: 0.3118

Epoch 00059: val_mDice did not improve from 0.32650
Epoch 60/300
 - 24s - loss: 0.1864 - acc: 0.9556 - mDice: 0.7497 - val_loss: -6.1270e-02 - val_acc: 0.9497 - val_mDice: 0.3128

Epoch 00060: val_mDice did not improve from 0.32650
Epoch 61/300
 - 24s - loss: 0.1837 - acc: 0.9562 - mDice: 0.7532 - val_loss: -4.3256e-02 - val_acc: 0.9499 - val_mDice: 0.3156

Epoch 00061: val_mDice did not improve from 0.32650

Epoch 00061: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 62/300
 - 24s - loss: 0.1806 - acc: 0.9564 - mDice: 0.7519 - val_loss: -7.4557e-02 - val_acc: 0.9496 - val_mDice: 0.3072

Epoch 00062: val_mDice did not improve from 0.32650
Epoch 63/300
 - 23s - loss: 0.1837 - acc: 0.9562 - mDice: 0.7529 - val_loss: -4.1815e-02 - val_acc: 0.9497 - val_mDice: 0.3029

Epoch 00063: val_mDice did not improve from 0.32650
Epoch 64/300
 - 23s - loss: 0.1778 - acc: 0.9563 - mDice: 0.7547 - val_loss: -1.7214e-02 - val_acc: 0.9497 - val_mDice: 0.3096

Epoch 00064: val_mDice did not improve from 0.32650
Epoch 65/300
 - 24s - loss: 0.1754 - acc: 0.9566 - mDice: 0.7578 - val_loss: -4.1213e-02 - val_acc: 0.9499 - val_mDice: 0.3120

Epoch 00065: val_mDice did not improve from 0.32650
Epoch 66/300
 - 23s - loss: 0.1738 - acc: 0.9569 - mDice: 0.7576 - val_loss: -2.1452e-02 - val_acc: 0.9493 - val_mDice: 0.3142

Epoch 00066: val_mDice did not improve from 0.32650
Epoch 67/300
 - 23s - loss: 0.1771 - acc: 0.9568 - mDice: 0.7563 - val_loss: -2.4344e-02 - val_acc: 0.9500 - val_mDice: 0.3173

Epoch 00067: val_mDice did not improve from 0.32650
Epoch 68/300
 - 24s - loss: 0.1766 - acc: 0.9568 - mDice: 0.7574 - val_loss: -3.3263e-02 - val_acc: 0.9497 - val_mDice: 0.3159

Epoch 00068: val_mDice did not improve from 0.32650
Epoch 69/300
 - 24s - loss: 0.1725 - acc: 0.9570 - mDice: 0.7578 - val_loss: -2.9262e-02 - val_acc: 0.9500 - val_mDice: 0.3127

Epoch 00069: val_mDice did not improve from 0.32650
Epoch 70/300
 - 24s - loss: 0.1789 - acc: 0.9567 - mDice: 0.7530 - val_loss: -5.1117e-02 - val_acc: 0.9495 - val_mDice: 0.3130

Epoch 00070: val_mDice did not improve from 0.32650
Epoch 71/300
 - 24s - loss: 0.1740 - acc: 0.9570 - mDice: 0.7578 - val_loss: -4.8353e-02 - val_acc: 0.9498 - val_mDice: 0.3100

Epoch 00071: val_mDice did not improve from 0.32650
Restoring model weights from the end of the best epoch
Epoch 00071: early stopping
{'val_loss': [0.6600771903991699, 0.6367219746112823, 0.6434226036071777, 0.6537764271100363, 0.6376202901204427, 0.6528322438398997, 0.6335148195425669, 0.65119336048762, 0.649751337369283, 0.5890516360600789, 0.6126152833302816, 0.5867636700471243, 0.5465191543102265, 0.40850795010725655, 0.4964158236980438, 0.4213965574900309, 0.29912811492880187, 0.4017796715100606, 0.34839654664198555, 0.418852432568868, 0.19755571261048316, 0.2691911660445233, 0.33499691685040794, 0.23045965001607935, 0.15737466973563036, 0.17772443977495034, 0.1535050785789887, 0.0663753258685271, 0.08931458406150342, 0.09453160849710306, 0.13360628647108871, 0.10119292611877123, 0.06146596198280652, 0.11914362646639347, 0.07825669075051943, 0.10594008810197314, 0.13778921756893397, 0.07784746649364631, 0.13618932981044055, 0.031655243349572024, 0.12125091329216957, 0.08301945114508272, 0.05320398087302844, 0.030170473052809635, 0.05079552298411727, -0.0072407507648070656, 0.056090927713861066, 0.007339045188079278, -0.005748966087897618, -0.048854018375277516, -0.019522244560842714, -0.03367756015310685, -0.00882488147666057, -0.046309365145862105, -0.011257810114572445, -0.038575742517908414, -0.047387118885914487, -0.01555491058776776, -0.01932061860958735, -0.06126950594286124, -0.043256159561375775, -0.07455745252470175, -0.0418148352454106, -0.01721428713450829, -0.04121337523683906, -0.021452161421378454, -0.024343588575720786, -0.03326306746651729, -0.029261817783117296, -0.0511172687013944, -0.048353395673135915], 'val_acc': [0.9391534368197123, 0.9431795676549276, 0.9471808950106303, 0.9362615704536438, 0.9470568736394246, 0.9429265936215718, 0.9434209585189819, 0.9457027077674866, 0.9412037094434103, 0.9477397561073303, 0.9483895500500997, 0.9474983374277751, 0.9479976852734884, 0.948057210445404, 0.9490426580111185, 0.9473445852597554, 0.9477430621782938, 0.9479414701461792, 0.9459490696589152, 0.9478108406066894, 0.945634925365448, 0.948458993434906, 0.9476769248644511, 0.9474520484606425, 0.9474504033724467, 0.9487615704536438, 0.9468055605888367, 0.9507423917452494, 0.9490674535433451, 0.9492179234822591, 0.9493931929270426, 0.9494973500569661, 0.9488624334335327, 0.9477678577105204, 0.9486276507377625, 0.9484176675478617, 0.9500231424967448, 0.948680559794108, 0.9487830678621928, 0.9471891562143961, 0.945090937614441, 0.948078699906667, 0.9479580005009969, 0.9490360458691914, 0.9462814172108968, 0.9497949759165446, 0.9474189718564351, 0.9496411999066671, 0.9491385579109192, 0.9488045612970988, 0.9491154154141744, 0.9492228786150615, 0.9492890159289042, 0.9494857867558797, 0.949024478594462, 0.9498429258664449, 0.9483647425969441, 0.9468948364257812, 0.9495568792025249, 0.9497288306554158, 0.9498627662658692, 0.9495750665664673, 0.9496593912442525, 0.9497089942296346, 0.949871031443278, 0.9492576042811076, 0.9500082651774089, 0.9496742765108744, 0.9500264565149943, 0.9494874278704325, 0.9497652093569438], 'val_mDice': [0.2872542291879654, 0.3115918253858884, 0.3046222363909086, 0.28743953903516134, 0.3094293226798375, 0.29032745907704033, 0.3018843134244283, 0.28578084881107013, 0.27469425946474074, 0.3031437625487646, 0.3168777391314507, 0.31309206287066144, 0.3189005672931671, 0.3076017931103706, 0.32191662887732186, 0.311229178806146, 0.3108815590540568, 0.3059143533309301, 0.2974079743027687, 0.3175477862358093, 0.3046023001273473, 0.30860154032707215, 0.31215628882249197, 0.3003756081064542, 0.30647360235452653, 0.31206089158852895, 0.3005989983677864, 0.3135247031847636, 0.31824445923169453, 0.3152378747860591, 0.326496484875679, 0.32432253658771515, 0.3177729547023773, 0.31208733121554055, 0.31497933467229206, 0.31436687111854555, 0.3188623304168383, 0.3194066693385442, 0.3049528772632281, 0.2936733951171239, 0.3026572277148565, 0.31633396397034325, 0.31113200485706327, 0.3204343914985657, 0.30782239039738973, 0.3210449695587158, 0.3154697259267171, 0.31487515072027844, 0.3079451223214467, 0.31014011601607006, 0.31420256743828456, 0.30510372718175255, 0.31161280125379565, 0.3077962338924408, 0.31421082516511284, 0.31050112197796503, 0.2984935072561105, 0.3078044732411703, 0.31184001863002775, 0.31284202337265016, 0.3156031290690104, 0.30717896570762, 0.30288980156183243, 0.3095601320266724, 0.31195089022318523, 0.3141664018233617, 0.3172740007440249, 0.3158711776137352, 0.3126973653833071, 0.3130216677983602, 0.30995579759279884], 'loss': [0.5595424944661053, 0.39547676406058657, 0.3610253503983952, 0.34159163130350795, 0.3269204197829938, 0.3199717639778477, 0.3070705649238896, 0.30140411218561497, 0.29528149236661505, 0.2944888753363811, 0.2855444453745724, 0.28005178116885315, 0.27551119216528547, 0.2767450548708439, 0.26922470086302414, 0.2660566106201168, 0.26796693846108427, 0.26815947407923374, 0.2607184099812669, 0.2582386572552155, 0.2599543149460597, 0.2590620157223536, 0.25401933826654555, 0.25301300572505986, 0.2505128762547476, 0.24908792424902498, 0.246682927413172, 0.24952565943933577, 0.24811811629400785, 0.2472364594529112, 0.23951453127827776, 0.23459308891301137, 0.2300486208284756, 0.228370059756525, 0.2272799650422368, 0.22725080149582183, 0.22422767249474013, 0.22256939657833946, 0.22620883546918036, 0.21995557650211323, 0.22669003731701004, 0.22308709990396441, 0.21949935973106152, 0.22147569376455836, 0.22161872091283835, 0.21476515802551074, 0.20605011027217268, 0.19387353153016226, 0.20082221549575727, 0.19707786785605627, 0.19431270193726016, 0.1979317582435943, 0.1910752232758833, 0.1895979350013067, 0.18789126571667644, 0.19010058097739377, 0.18796561707800952, 0.18864282621713113, 0.18347498309377402, 0.1863781347251298, 0.18373516879083432, 0.1806325949419478, 0.18374315661492302, 0.17775664346854284, 0.17536801482440414, 0.1737977934439353, 0.17707790987898547, 0.17663581061402597, 0.17247748551672265, 0.17893737237759036, 0.174039087524504], 'acc': [0.9054378958203759, 0.9351987627991643, 0.9398377970514069, 0.9422620783645318, 0.9442782196034474, 0.9453255432654187, 0.9465920298816674, 0.9477533810285933, 0.9482462022052818, 0.9484483434622031, 0.9495444066852212, 0.9500927089813695, 0.9505456098878526, 0.9508942400672996, 0.9514459031392853, 0.9516106202189191, 0.9515740368589461, 0.9520797515770354, 0.9524778862635928, 0.9529456825726536, 0.9528856300025347, 0.9530500760710097, 0.9535320763331485, 0.9534719505039344, 0.9538575610316608, 0.9541050082896335, 0.9543008518765173, 0.9540516748371353, 0.9543144135954845, 0.9542326965180051, 0.955347681366115, 0.9560520822902124, 0.9564632343580999, 0.9565177771793418, 0.9565306241175093, 0.9567874090011377, 0.9566373151255794, 0.9568308365060039, 0.956912281741184, 0.957157556279247, 0.9570655379281101, 0.9573073768876939, 0.9573144428877242, 0.9574385496130977, 0.9562749258313046, 0.9559010245291836, 0.9565053024140012, 0.9569204827228865, 0.9569894034430325, 0.9568992381789295, 0.9568902223233683, 0.9561570438730764, 0.956064506771555, 0.9562264828093023, 0.9564260326889882, 0.9561197180671995, 0.9557704698754497, 0.9556640248255901, 0.9562930567449782, 0.9556380132161288, 0.9561684314473217, 0.9563508115679145, 0.9562187756437704, 0.956313214157207, 0.9566053990942548, 0.9568872082518391, 0.9568041078004229, 0.9568478568972819, 0.9570195396464184, 0.9567215262181256, 0.9570200100719216], 'mDice': [0.3973195006276863, 0.5739908334446618, 0.6111430220632439, 0.6320897543661861, 0.6478937790391455, 0.6553694263278725, 0.6693020213053996, 0.6754000538967521, 0.6819993480743165, 0.6828501995103767, 0.6925009142948811, 0.6984287877659874, 0.7033317903004794, 0.7019980047269171, 0.7101116766077114, 0.7135323052149845, 0.7114715972150939, 0.711240075795774, 0.7192920284026647, 0.7219581349615557, 0.720087528792748, 0.7210467062979581, 0.7264867026611154, 0.7275837202114888, 0.7302754357219692, 0.7318053767381911, 0.7344012255093966, 0.7313196511857538, 0.7328420886361742, 0.7337995154330454, 0.7421245404864213, 0.7474273511197462, 0.7523317971077573, 0.7541492397626083, 0.7553379625913157, 0.7553503084111499, 0.7586323546164064, 0.7604316182701711, 0.7564791988032272, 0.7632355433536241, 0.7559524589622638, 0.7598210638203469, 0.7636960483642213, 0.7614065364478119, 0.7508506833379012, 0.7512477581125806, 0.7536096146619652, 0.7632292370456624, 0.7569511805575683, 0.7564843795095307, 0.7598211917566113, 0.7521784215334402, 0.7502697230097782, 0.7531722935428657, 0.7560835188603496, 0.751669650444709, 0.7517422189513051, 0.7468609431706577, 0.7519570066931238, 0.7496884912549262, 0.7532444212481795, 0.7519044210592589, 0.7529075617987321, 0.7547326758503914, 0.7578382636030832, 0.7575900780549087, 0.7562829104077768, 0.7573521450696239, 0.7577768120751438, 0.7530425248511758, 0.7577854177925691], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.45s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.26s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.11s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:24,  3.13it/s]Loading train:   1%|          | 2/266 [00:00<01:21,  3.24it/s]Loading train:   1%|          | 3/266 [00:00<01:17,  3.37it/s]Loading train:   2%|▏         | 4/266 [00:01<01:18,  3.35it/s]Loading train:   2%|▏         | 5/266 [00:01<01:16,  3.43it/s]Loading train:   2%|▏         | 6/266 [00:01<01:15,  3.46it/s]Loading train:   3%|▎         | 7/266 [00:02<01:14,  3.47it/s]Loading train:   3%|▎         | 8/266 [00:02<01:13,  3.49it/s]Loading train:   3%|▎         | 9/266 [00:02<01:13,  3.51it/s]Loading train:   4%|▍         | 10/266 [00:02<01:12,  3.52it/s]Loading train:   4%|▍         | 11/266 [00:03<01:12,  3.53it/s]Loading train:   5%|▍         | 12/266 [00:03<01:11,  3.54it/s]Loading train:   5%|▍         | 13/266 [00:03<01:10,  3.57it/s]Loading train:   5%|▌         | 14/266 [00:03<01:11,  3.55it/s]Loading train:   6%|▌         | 15/266 [00:04<01:10,  3.56it/s]Loading train:   6%|▌         | 16/266 [00:04<01:10,  3.55it/s]Loading train:   6%|▋         | 17/266 [00:04<01:09,  3.56it/s]Loading train:   7%|▋         | 18/266 [00:05<01:09,  3.56it/s]Loading train:   7%|▋         | 19/266 [00:05<01:09,  3.56it/s]Loading train:   8%|▊         | 20/266 [00:05<01:09,  3.56it/s]Loading train:   8%|▊         | 21/266 [00:05<01:08,  3.55it/s]Loading train:   8%|▊         | 22/266 [00:06<01:08,  3.56it/s]Loading train:   9%|▊         | 23/266 [00:06<01:07,  3.63it/s]Loading train:   9%|▉         | 24/266 [00:06<01:05,  3.72it/s]Loading train:   9%|▉         | 25/266 [00:06<01:03,  3.80it/s]Loading train:  10%|▉         | 26/266 [00:07<01:02,  3.87it/s]Loading train:  10%|█         | 27/266 [00:07<01:01,  3.90it/s]Loading train:  11%|█         | 28/266 [00:07<01:00,  3.90it/s]Loading train:  11%|█         | 29/266 [00:08<01:00,  3.93it/s]Loading train:  11%|█▏        | 30/266 [00:08<01:00,  3.89it/s]Loading train:  12%|█▏        | 31/266 [00:08<00:59,  3.93it/s]Loading train:  12%|█▏        | 32/266 [00:08<00:59,  3.96it/s]Loading train:  12%|█▏        | 33/266 [00:09<00:58,  3.99it/s]Loading train:  13%|█▎        | 34/266 [00:09<00:57,  4.00it/s]Loading train:  13%|█▎        | 35/266 [00:09<00:57,  4.00it/s]Loading train:  14%|█▎        | 36/266 [00:09<00:57,  4.00it/s]Loading train:  14%|█▍        | 37/266 [00:10<00:57,  4.01it/s]Loading train:  14%|█▍        | 38/266 [00:10<00:56,  4.01it/s]Loading train:  15%|█▍        | 39/266 [00:10<00:56,  4.02it/s]Loading train:  15%|█▌        | 40/266 [00:10<00:56,  4.03it/s]Loading train:  15%|█▌        | 41/266 [00:11<00:56,  3.96it/s]Loading train:  16%|█▌        | 42/266 [00:11<00:57,  3.91it/s]Loading train:  16%|█▌        | 43/266 [00:11<00:57,  3.88it/s]Loading train:  17%|█▋        | 44/266 [00:11<00:57,  3.84it/s]Loading train:  17%|█▋        | 45/266 [00:12<00:57,  3.83it/s]Loading train:  17%|█▋        | 46/266 [00:12<00:57,  3.80it/s]Loading train:  18%|█▊        | 47/266 [00:12<00:57,  3.80it/s]Loading train:  18%|█▊        | 48/266 [00:12<00:57,  3.79it/s]Loading train:  18%|█▊        | 49/266 [00:13<00:57,  3.80it/s]Loading train:  19%|█▉        | 50/266 [00:13<00:56,  3.79it/s]Loading train:  19%|█▉        | 51/266 [00:13<00:56,  3.81it/s]Loading train:  20%|█▉        | 52/266 [00:13<00:56,  3.82it/s]Loading train:  20%|█▉        | 53/266 [00:14<00:55,  3.83it/s]Loading train:  20%|██        | 54/266 [00:14<00:55,  3.82it/s]Loading train:  21%|██        | 55/266 [00:14<00:55,  3.83it/s]Loading train:  21%|██        | 56/266 [00:14<00:54,  3.83it/s]Loading train:  21%|██▏       | 57/266 [00:15<00:54,  3.83it/s]Loading train:  22%|██▏       | 58/266 [00:15<00:54,  3.83it/s]Loading train:  22%|██▏       | 59/266 [00:15<00:55,  3.73it/s]Loading train:  23%|██▎       | 60/266 [00:16<00:56,  3.68it/s]Loading train:  23%|██▎       | 61/266 [00:16<00:56,  3.62it/s]Loading train:  23%|██▎       | 62/266 [00:16<00:56,  3.61it/s]Loading train:  24%|██▎       | 63/266 [00:16<00:56,  3.60it/s]Loading train:  24%|██▍       | 64/266 [00:17<00:56,  3.57it/s]Loading train:  24%|██▍       | 65/266 [00:17<00:56,  3.55it/s]Loading train:  25%|██▍       | 66/266 [00:17<00:56,  3.56it/s]Loading train:  25%|██▌       | 67/266 [00:18<00:55,  3.57it/s]Loading train:  26%|██▌       | 68/266 [00:18<00:55,  3.57it/s]Loading train:  26%|██▌       | 69/266 [00:18<00:55,  3.56it/s]Loading train:  26%|██▋       | 70/266 [00:18<00:55,  3.56it/s]Loading train:  27%|██▋       | 71/266 [00:19<00:54,  3.57it/s]Loading train:  27%|██▋       | 72/266 [00:19<00:54,  3.55it/s]Loading train:  27%|██▋       | 73/266 [00:19<00:54,  3.57it/s]Loading train:  28%|██▊       | 74/266 [00:19<00:53,  3.57it/s]Loading train:  28%|██▊       | 75/266 [00:20<00:53,  3.58it/s]Loading train:  29%|██▊       | 76/266 [00:20<00:53,  3.58it/s]Loading train:  29%|██▉       | 77/266 [00:20<00:56,  3.34it/s]Loading train:  29%|██▉       | 78/266 [00:21<00:57,  3.28it/s]Loading train:  30%|██▉       | 79/266 [00:21<00:56,  3.32it/s]Loading train:  30%|███       | 80/266 [00:21<00:54,  3.40it/s]Loading train:  30%|███       | 81/266 [00:22<00:56,  3.27it/s]Loading train:  31%|███       | 82/266 [00:22<00:57,  3.21it/s]Loading train:  31%|███       | 83/266 [00:22<00:57,  3.19it/s]Loading train:  32%|███▏      | 84/266 [00:23<00:57,  3.17it/s]Loading train:  32%|███▏      | 85/266 [00:23<00:57,  3.16it/s]Loading train:  32%|███▏      | 86/266 [00:23<00:57,  3.15it/s]Loading train:  33%|███▎      | 87/266 [00:24<00:56,  3.15it/s]Loading train:  33%|███▎      | 88/266 [00:24<00:56,  3.14it/s]Loading train:  33%|███▎      | 89/266 [00:24<00:57,  3.08it/s]Loading train:  34%|███▍      | 90/266 [00:25<00:57,  3.08it/s]Loading train:  34%|███▍      | 91/266 [00:25<00:56,  3.09it/s]Loading train:  35%|███▍      | 92/266 [00:25<00:56,  3.10it/s]Loading train:  35%|███▍      | 93/266 [00:25<00:55,  3.11it/s]Loading train:  35%|███▌      | 94/266 [00:26<00:55,  3.10it/s]Loading train:  36%|███▌      | 95/266 [00:26<00:55,  3.10it/s]Loading train:  36%|███▌      | 96/266 [00:26<00:54,  3.10it/s]Loading train:  36%|███▋      | 97/266 [00:27<00:54,  3.08it/s]Loading train:  37%|███▋      | 98/266 [00:27<00:55,  3.05it/s]Loading train:  37%|███▋      | 99/266 [00:27<00:54,  3.07it/s]Loading train:  38%|███▊      | 100/266 [00:28<00:53,  3.12it/s]Loading train:  38%|███▊      | 101/266 [00:28<00:52,  3.17it/s]Loading train:  38%|███▊      | 102/266 [00:28<00:51,  3.20it/s]Loading train:  39%|███▊      | 103/266 [00:29<00:50,  3.23it/s]Loading train:  39%|███▉      | 104/266 [00:29<00:49,  3.25it/s]Loading train:  39%|███▉      | 105/266 [00:29<00:50,  3.21it/s]Loading train:  40%|███▉      | 106/266 [00:30<00:49,  3.23it/s]Loading train:  40%|████      | 107/266 [00:30<00:49,  3.21it/s]Loading train:  41%|████      | 108/266 [00:30<00:48,  3.24it/s]Loading train:  41%|████      | 109/266 [00:30<00:48,  3.26it/s]Loading train:  41%|████▏     | 110/266 [00:31<00:47,  3.26it/s]Loading train:  42%|████▏     | 111/266 [00:31<00:47,  3.25it/s]Loading train:  42%|████▏     | 112/266 [00:31<00:47,  3.25it/s]Loading train:  42%|████▏     | 113/266 [00:32<00:46,  3.26it/s]Loading train:  43%|████▎     | 114/266 [00:32<00:46,  3.24it/s]Loading train:  43%|████▎     | 115/266 [00:32<00:47,  3.21it/s]Loading train:  44%|████▎     | 116/266 [00:33<00:46,  3.22it/s]Loading train:  44%|████▍     | 117/266 [00:33<00:46,  3.19it/s]Loading train:  44%|████▍     | 118/266 [00:33<00:45,  3.28it/s]Loading train:  45%|████▍     | 119/266 [00:34<00:43,  3.35it/s]Loading train:  45%|████▌     | 120/266 [00:34<00:42,  3.41it/s]Loading train:  45%|████▌     | 121/266 [00:34<00:42,  3.44it/s]Loading train:  46%|████▌     | 122/266 [00:34<00:41,  3.45it/s]Loading train:  46%|████▌     | 123/266 [00:35<00:41,  3.44it/s]Loading train:  47%|████▋     | 124/266 [00:35<00:40,  3.48it/s]Loading train:  47%|████▋     | 125/266 [00:35<00:40,  3.51it/s]Loading train:  47%|████▋     | 126/266 [00:36<00:39,  3.53it/s]Loading train:  48%|████▊     | 127/266 [00:36<00:39,  3.56it/s]Loading train:  48%|████▊     | 128/266 [00:36<00:38,  3.56it/s]Loading train:  48%|████▊     | 129/266 [00:36<00:38,  3.54it/s]Loading train:  49%|████▉     | 130/266 [00:37<00:38,  3.53it/s]Loading train:  49%|████▉     | 131/266 [00:37<00:38,  3.55it/s]Loading train:  50%|████▉     | 132/266 [00:37<00:38,  3.51it/s]Loading train:  50%|█████     | 133/266 [00:38<00:37,  3.52it/s]Loading train:  50%|█████     | 134/266 [00:38<00:37,  3.50it/s]Loading train:  51%|█████     | 135/266 [00:38<00:36,  3.55it/s]Loading train:  51%|█████     | 136/266 [00:38<00:35,  3.61it/s]Loading train:  52%|█████▏    | 137/266 [00:39<00:35,  3.67it/s]Loading train:  52%|█████▏    | 138/266 [00:39<00:34,  3.72it/s]Loading train:  52%|█████▏    | 139/266 [00:39<00:33,  3.74it/s]Loading train:  53%|█████▎    | 140/266 [00:39<00:33,  3.77it/s]Loading train:  53%|█████▎    | 141/266 [00:40<00:33,  3.77it/s]Loading train:  53%|█████▎    | 142/266 [00:40<00:33,  3.72it/s]Loading train:  54%|█████▍    | 143/266 [00:40<00:32,  3.75it/s]Loading train:  54%|█████▍    | 144/266 [00:40<00:32,  3.73it/s]Loading train:  55%|█████▍    | 145/266 [00:41<00:32,  3.77it/s]Loading train:  55%|█████▍    | 146/266 [00:41<00:31,  3.81it/s]Loading train:  55%|█████▌    | 147/266 [00:41<00:31,  3.81it/s]Loading train:  56%|█████▌    | 148/266 [00:42<00:32,  3.65it/s]Loading train:  56%|█████▌    | 149/266 [00:42<00:31,  3.66it/s]Loading train:  56%|█████▋    | 150/266 [00:42<00:31,  3.68it/s]Loading train:  57%|█████▋    | 151/266 [00:42<00:31,  3.70it/s]Loading train:  57%|█████▋    | 152/266 [00:43<00:30,  3.74it/s]Loading train:  58%|█████▊    | 153/266 [00:43<00:30,  3.70it/s]Loading train:  58%|█████▊    | 154/266 [00:43<00:32,  3.41it/s]Loading train:  58%|█████▊    | 155/266 [00:44<00:33,  3.27it/s]Loading train:  59%|█████▊    | 156/266 [00:44<00:34,  3.16it/s]Loading train:  59%|█████▉    | 157/266 [00:44<00:34,  3.12it/s]Loading train:  59%|█████▉    | 158/266 [00:45<00:35,  3.06it/s]Loading train:  60%|█████▉    | 159/266 [00:45<00:34,  3.07it/s]Loading train:  60%|██████    | 160/266 [00:45<00:34,  3.06it/s]Loading train:  61%|██████    | 161/266 [00:46<00:33,  3.09it/s]Loading train:  61%|██████    | 162/266 [00:46<00:33,  3.11it/s]Loading train:  61%|██████▏   | 163/266 [00:46<00:32,  3.14it/s]Loading train:  62%|██████▏   | 164/266 [00:46<00:32,  3.16it/s]Loading train:  62%|██████▏   | 165/266 [00:47<00:32,  3.12it/s]Loading train:  62%|██████▏   | 166/266 [00:47<00:32,  3.12it/s]Loading train:  63%|██████▎   | 167/266 [00:47<00:31,  3.12it/s]Loading train:  63%|██████▎   | 168/266 [00:48<00:31,  3.13it/s]Loading train:  64%|██████▎   | 169/266 [00:48<00:30,  3.14it/s]Loading train:  64%|██████▍   | 170/266 [00:48<00:30,  3.15it/s]Loading train:  64%|██████▍   | 171/266 [00:49<00:30,  3.13it/s]Loading train:  65%|██████▍   | 172/266 [00:49<00:29,  3.15it/s]Loading train:  65%|██████▌   | 173/266 [00:49<00:30,  3.09it/s]Loading train:  65%|██████▌   | 174/266 [00:50<00:29,  3.09it/s]Loading train:  66%|██████▌   | 175/266 [00:50<00:27,  3.25it/s]Loading train:  66%|██████▌   | 176/266 [00:50<00:27,  3.30it/s]Loading train:  67%|██████▋   | 177/266 [00:51<00:26,  3.30it/s]Loading train:  67%|██████▋   | 178/266 [00:51<00:26,  3.32it/s]Loading train:  67%|██████▋   | 179/266 [00:51<00:26,  3.33it/s]Loading train:  68%|██████▊   | 180/266 [00:51<00:25,  3.35it/s]Loading train:  68%|██████▊   | 181/266 [00:52<00:25,  3.31it/s]Loading train:  68%|██████▊   | 182/266 [00:52<00:25,  3.32it/s]Loading train:  69%|██████▉   | 183/266 [00:52<00:24,  3.33it/s]Loading train:  69%|██████▉   | 184/266 [00:53<00:24,  3.33it/s]Loading train:  70%|██████▉   | 185/266 [00:53<00:24,  3.32it/s]Loading train:  70%|██████▉   | 186/266 [00:53<00:24,  3.33it/s]Loading train:  70%|███████   | 187/266 [00:54<00:23,  3.34it/s]Loading train:  71%|███████   | 188/266 [00:54<00:23,  3.36it/s]Loading train:  71%|███████   | 189/266 [00:54<00:22,  3.37it/s]Loading train:  71%|███████▏  | 190/266 [00:54<00:22,  3.38it/s]Loading train:  72%|███████▏  | 191/266 [00:55<00:22,  3.37it/s]Loading train:  72%|███████▏  | 192/266 [00:55<00:22,  3.33it/s]Loading train:  73%|███████▎  | 193/266 [00:55<00:21,  3.34it/s]Loading train:  73%|███████▎  | 194/266 [00:56<00:21,  3.35it/s]Loading train:  73%|███████▎  | 195/266 [00:56<00:21,  3.27it/s]Loading train:  74%|███████▎  | 196/266 [00:56<00:22,  3.15it/s]Loading train:  74%|███████▍  | 197/266 [00:57<00:22,  3.10it/s]Loading train:  74%|███████▍  | 198/266 [00:57<00:22,  3.06it/s]Loading train:  75%|███████▍  | 199/266 [00:57<00:21,  3.09it/s]Loading train:  75%|███████▌  | 200/266 [00:58<00:21,  3.07it/s]Loading train:  76%|███████▌  | 201/266 [00:58<00:21,  3.06it/s]Loading train:  76%|███████▌  | 202/266 [00:58<00:20,  3.06it/s]Loading train:  76%|███████▋  | 203/266 [00:59<00:20,  3.01it/s]Loading train:  77%|███████▋  | 204/266 [00:59<00:20,  3.03it/s]Loading train:  77%|███████▋  | 205/266 [00:59<00:20,  3.00it/s]Loading train:  77%|███████▋  | 206/266 [01:00<00:19,  3.00it/s]Loading train:  78%|███████▊  | 207/266 [01:00<00:19,  3.05it/s]Loading train:  78%|███████▊  | 208/266 [01:00<00:18,  3.09it/s]Loading train:  79%|███████▊  | 209/266 [01:01<00:18,  3.07it/s]Loading train:  79%|███████▉  | 210/266 [01:01<00:18,  3.03it/s]Loading train:  79%|███████▉  | 211/266 [01:01<00:17,  3.07it/s]Loading train:  80%|███████▉  | 212/266 [01:02<00:17,  3.10it/s]Loading train:  80%|████████  | 213/266 [01:02<00:16,  3.17it/s]Loading train:  80%|████████  | 214/266 [01:02<00:16,  3.22it/s]Loading train:  81%|████████  | 215/266 [01:02<00:15,  3.25it/s]Loading train:  81%|████████  | 216/266 [01:03<00:15,  3.27it/s]Loading train:  82%|████████▏ | 217/266 [01:03<00:15,  3.26it/s]Loading train:  82%|████████▏ | 218/266 [01:03<00:14,  3.29it/s]Loading train:  82%|████████▏ | 219/266 [01:04<00:14,  3.29it/s]Loading train:  83%|████████▎ | 220/266 [01:04<00:13,  3.33it/s]Loading train:  83%|████████▎ | 221/266 [01:04<00:13,  3.34it/s]Loading train:  83%|████████▎ | 222/266 [01:05<00:13,  3.34it/s]Loading train:  84%|████████▍ | 223/266 [01:05<00:12,  3.34it/s]Loading train:  84%|████████▍ | 224/266 [01:05<00:12,  3.29it/s]Loading train:  85%|████████▍ | 225/266 [01:05<00:12,  3.33it/s]Loading train:  85%|████████▍ | 226/266 [01:06<00:12,  3.30it/s]Loading train:  85%|████████▌ | 227/266 [01:06<00:11,  3.32it/s]Loading train:  86%|████████▌ | 228/266 [01:06<00:11,  3.28it/s]Loading train:  86%|████████▌ | 229/266 [01:07<00:11,  3.28it/s]Loading train:  86%|████████▋ | 230/266 [01:07<00:10,  3.32it/s]Loading train:  87%|████████▋ | 231/266 [01:07<00:10,  3.39it/s]Loading train:  87%|████████▋ | 232/266 [01:08<00:09,  3.48it/s]Loading train:  88%|████████▊ | 233/266 [01:08<00:09,  3.55it/s]Loading train:  88%|████████▊ | 234/266 [01:08<00:08,  3.60it/s]Loading train:  88%|████████▊ | 235/266 [01:08<00:08,  3.67it/s]Loading train:  89%|████████▊ | 236/266 [01:09<00:08,  3.69it/s]Loading train:  89%|████████▉ | 237/266 [01:09<00:07,  3.68it/s]Loading train:  89%|████████▉ | 238/266 [01:09<00:07,  3.67it/s]Loading train:  90%|████████▉ | 239/266 [01:09<00:07,  3.69it/s]Loading train:  90%|█████████ | 240/266 [01:10<00:07,  3.68it/s]Loading train:  91%|█████████ | 241/266 [01:10<00:06,  3.73it/s]Loading train:  91%|█████████ | 242/266 [01:10<00:06,  3.74it/s]Loading train:  91%|█████████▏| 243/266 [01:10<00:06,  3.75it/s]Loading train:  92%|█████████▏| 244/266 [01:11<00:05,  3.74it/s]Loading train:  92%|█████████▏| 245/266 [01:11<00:05,  3.70it/s]Loading train:  92%|█████████▏| 246/266 [01:11<00:05,  3.69it/s]Loading train:  93%|█████████▎| 247/266 [01:12<00:05,  3.73it/s]Loading train:  93%|█████████▎| 248/266 [01:12<00:04,  3.72it/s]Loading train:  94%|█████████▎| 249/266 [01:12<00:04,  3.68it/s]Loading train:  94%|█████████▍| 250/266 [01:12<00:04,  3.64it/s]Loading train:  94%|█████████▍| 251/266 [01:13<00:04,  3.64it/s]Loading train:  95%|█████████▍| 252/266 [01:13<00:03,  3.63it/s]Loading train:  95%|█████████▌| 253/266 [01:13<00:03,  3.60it/s]Loading train:  95%|█████████▌| 254/266 [01:14<00:03,  3.60it/s]Loading train:  96%|█████████▌| 255/266 [01:14<00:03,  3.61it/s]Loading train:  96%|█████████▌| 256/266 [01:14<00:02,  3.62it/s]Loading train:  97%|█████████▋| 257/266 [01:14<00:02,  3.60it/s]Loading train:  97%|█████████▋| 258/266 [01:15<00:02,  3.63it/s]Loading train:  97%|█████████▋| 259/266 [01:15<00:01,  3.62it/s]Loading train:  98%|█████████▊| 260/266 [01:15<00:01,  3.62it/s]Loading train:  98%|█████████▊| 261/266 [01:15<00:01,  3.59it/s]Loading train:  98%|█████████▊| 262/266 [01:16<00:01,  3.59it/s]Loading train:  99%|█████████▉| 263/266 [01:16<00:00,  3.59it/s]Loading train:  99%|█████████▉| 264/266 [01:16<00:00,  3.59it/s]Loading train: 100%|█████████▉| 265/266 [01:17<00:00,  3.59it/s]Loading train: 100%|██████████| 266/266 [01:17<00:00,  3.60it/s]Loading train: 100%|██████████| 266/266 [01:17<00:00,  3.44it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 45.46it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 44.94it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 44.50it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:05, 44.17it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:05, 44.94it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:05, 46.10it/s]concatenating: train:  13%|█▎        | 35/266 [00:00<00:04, 46.95it/s]concatenating: train:  15%|█▌        | 40/266 [00:00<00:04, 47.40it/s]concatenating: train:  17%|█▋        | 45/266 [00:00<00:04, 47.49it/s]concatenating: train:  19%|█▉        | 50/266 [00:01<00:04, 47.38it/s]concatenating: train:  21%|██        | 55/266 [00:01<00:04, 47.39it/s]concatenating: train:  23%|██▎       | 60/266 [00:01<00:04, 47.15it/s]concatenating: train:  24%|██▍       | 65/266 [00:01<00:04, 46.44it/s]concatenating: train:  26%|██▋       | 70/266 [00:01<00:04, 46.03it/s]concatenating: train:  28%|██▊       | 75/266 [00:01<00:04, 45.63it/s]concatenating: train:  30%|███       | 80/266 [00:01<00:04, 45.22it/s]concatenating: train:  32%|███▏      | 85/266 [00:01<00:04, 43.84it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:04, 42.79it/s]concatenating: train:  36%|███▌      | 95/266 [00:02<00:04, 42.29it/s]concatenating: train:  38%|███▊      | 100/266 [00:02<00:03, 42.06it/s]concatenating: train:  39%|███▉      | 105/266 [00:02<00:03, 42.43it/s]concatenating: train:  41%|████▏     | 110/266 [00:02<00:03, 42.43it/s]concatenating: train:  43%|████▎     | 115/266 [00:02<00:03, 42.57it/s]concatenating: train:  45%|████▌     | 120/266 [00:02<00:03, 43.33it/s]concatenating: train:  47%|████▋     | 125/266 [00:02<00:03, 44.18it/s]concatenating: train:  49%|████▉     | 130/266 [00:02<00:03, 44.69it/s]concatenating: train:  51%|█████     | 135/266 [00:03<00:02, 45.09it/s]concatenating: train:  53%|█████▎    | 140/266 [00:03<00:02, 46.03it/s]concatenating: train:  55%|█████▍    | 145/266 [00:03<00:02, 46.53it/s]concatenating: train:  57%|█████▋    | 151/266 [00:03<00:02, 47.56it/s]concatenating: train:  59%|█████▊    | 156/266 [00:03<00:02, 46.47it/s]concatenating: train:  61%|██████    | 161/266 [00:03<00:02, 44.87it/s]concatenating: train:  62%|██████▏   | 166/266 [00:03<00:02, 43.86it/s]concatenating: train:  64%|██████▍   | 171/266 [00:03<00:02, 43.16it/s]concatenating: train:  66%|██████▌   | 176/266 [00:03<00:02, 43.73it/s]concatenating: train:  68%|██████▊   | 181/266 [00:04<00:01, 43.56it/s]concatenating: train:  70%|██████▉   | 186/266 [00:04<00:01, 43.57it/s]concatenating: train:  72%|███████▏  | 191/266 [00:04<00:01, 43.68it/s]concatenating: train:  74%|███████▎  | 196/266 [00:04<00:01, 43.60it/s]concatenating: train:  76%|███████▌  | 201/266 [00:04<00:01, 43.11it/s]concatenating: train:  77%|███████▋  | 206/266 [00:04<00:01, 42.72it/s]concatenating: train:  79%|███████▉  | 211/266 [00:04<00:01, 42.47it/s]concatenating: train:  81%|████████  | 216/266 [00:04<00:01, 42.67it/s]concatenating: train:  83%|████████▎ | 221/266 [00:04<00:01, 43.28it/s]concatenating: train:  85%|████████▍ | 226/266 [00:05<00:00, 43.76it/s]concatenating: train:  87%|████████▋ | 231/266 [00:05<00:00, 44.37it/s]concatenating: train:  89%|████████▊ | 236/266 [00:05<00:00, 45.72it/s]concatenating: train:  91%|█████████ | 241/266 [00:05<00:00, 46.77it/s]concatenating: train:  92%|█████████▏| 246/266 [00:05<00:00, 47.41it/s]concatenating: train:  94%|█████████▍| 251/266 [00:05<00:00, 47.65it/s]concatenating: train:  96%|█████████▌| 256/266 [00:05<00:00, 47.20it/s]concatenating: train:  98%|█████████▊| 261/266 [00:05<00:00, 47.10it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 45.18it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  3.36it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  3.49it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  3.51it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.34it/s]Loading test: 100%|██████████| 4/4 [00:01<00:00,  3.41it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 362.41it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________2020-01-22 06:58:06.522811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 06:58:06.522927: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 06:58:06.522943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 06:58:06.522951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 06:58:06.523321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 499,142
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97555386 0.02444614]
Train on 27854 samples, validate on 403 samples
Epoch 1/300
 - 76s - loss: 0.0728 - acc: 0.9918 - mDice: 0.8595 - val_loss: 0.2403 - val_acc: 0.9930 - val_mDice: 0.5230

Epoch 00001: val_mDice improved from -inf to 0.52296, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 2/300
 - 71s - loss: 0.0526 - acc: 0.9944 - mDice: 0.8977 - val_loss: 0.2367 - val_acc: 0.9926 - val_mDice: 0.5303

Epoch 00002: val_mDice improved from 0.52296 to 0.53028, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 3/300
 - 72s - loss: 0.0456 - acc: 0.9950 - mDice: 0.9114 - val_loss: 0.2351 - val_acc: 0.9932 - val_mDice: 0.5332

Epoch 00003: val_mDice improved from 0.53028 to 0.53319, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 4/300
 - 72s - loss: 0.0424 - acc: 0.9953 - mDice: 0.9176 - val_loss: 0.1608 - val_acc: 0.9929 - val_mDice: 0.5320

Epoch 00004: val_mDice did not improve from 0.53319
Epoch 5/300
 - 74s - loss: 0.0403 - acc: 0.9955 - mDice: 0.9217 - val_loss: 0.2217 - val_acc: 0.9937 - val_mDice: 0.5451

Epoch 00005: val_mDice improved from 0.53319 to 0.54509, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd1/best_model_weights.h5
Epoch 6/300
 - 74s - loss: 0.0382 - acc: 0.9957 - mDice: 0.9257 - val_loss: 0.1372 - val_acc: 0.9937 - val_mDice: 0.5318

Epoch 00006: val_mDice did not improve from 0.54509
Epoch 7/300
 - 72s - loss: 0.0365 - acc: 0.9959 - mDice: 0.9291 - val_loss: 0.1263 - val_acc: 0.9935 - val_mDice: 0.5332

Epoch 00007: val_mDice did not improve from 0.54509
Epoch 8/300
 - 72s - loss: 0.0359 - acc: 0.9959 - mDice: 0.9302 - val_loss: 0.1898 - val_acc: 0.9935 - val_mDice: 0.5448

Epoch 00008: val_mDice did not improve from 0.54509
Epoch 9/300
 - 73s - loss: 0.0350 - acc: 0.9960 - mDice: 0.9320 - val_loss: 0.0987 - val_acc: 0.9934 - val_mDice: 0.5362

Epoch 00009: val_mDice did not improve from 0.54509
Epoch 10/300
 - 72s - loss: 0.0347 - acc: 0.9960 - mDice: 0.9326 - val_loss: 0.0199 - val_acc: 0.9932 - val_mDice: 0.5289

Epoch 00010: val_mDice did not improve from 0.54509
Epoch 11/300
 - 72s - loss: 0.0330 - acc: 0.9962 - mDice: 0.9359 - val_loss: 0.0712 - val_acc: 0.9938 - val_mDice: 0.5322

Epoch 00011: val_mDice did not improve from 0.54509
Epoch 12/300
 - 72s - loss: 0.0328 - acc: 0.9962 - mDice: 0.9363 - val_loss: -2.4611e-02 - val_acc: 0.9936 - val_mDice: 0.5276

Epoch 00012: val_mDice did not improve from 0.54509
Epoch 13/300
 - 72s - loss: 0.0325 - acc: 0.9962 - mDice: 0.9368 - val_loss: 0.0508 - val_acc: 0.9938 - val_mDice: 0.5345

Epoch 00013: val_mDice did not improve from 0.54509
Epoch 14/300
 - 72s - loss: 0.0318 - acc: 0.9963 - mDice: 0.9382 - val_loss: 0.0029 - val_acc: 0.9937 - val_mDice: 0.5386

Epoch 00014: val_mDice did not improve from 0.54509
Epoch 15/300
 - 72s - loss: 0.0318 - acc: 0.9963 - mDice: 0.9383 - val_loss: -2.7020e-02 - val_acc: 0.9938 - val_mDice: 0.5364

Epoch 00015: val_mDice did not improve from 0.54509
Epoch 16/300
 - 72s - loss: 0.0315 - acc: 0.9963 - mDice: 0.9387 - val_loss: 0.0389 - val_acc: 0.9936 - val_mDice: 0.5320

Epoch 00016: val_mDice did not improve from 0.54509
Epoch 17/300
 - 72s - loss: 0.0314 - acc: 0.9963 - mDice: 0.9389 - val_loss: 0.0568 - val_acc: 0.9931 - val_mDice: 0.5255

Epoch 00017: val_mDice did not improve from 0.54509
Epoch 18/300
 - 72s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9412 - val_loss: -1.6030e-02 - val_acc: 0.9935 - val_mDice: 0.5252

Epoch 00018: val_mDice did not improve from 0.54509
Epoch 19/300
 - 72s - loss: 0.0303 - acc: 0.9964 - mDice: 0.9413 - val_loss: 0.0072 - val_acc: 0.9935 - val_mDice: 0.5313

Epoch 00019: val_mDice did not improve from 0.54509
Epoch 20/300
 - 72s - loss: 0.0305 - acc: 0.9964 - mDice: 0.9407 - val_loss: 0.0262 - val_acc: 0.9937 - val_mDice: 0.5378

Epoch 00020: val_mDice did not improve from 0.54509

Epoch 00020: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 21/300
 - 72s - loss: 0.0286 - acc: 0.9966 - mDice: 0.9444 - val_loss: -6.3989e-03 - val_acc: 0.9939 - val_mDice: 0.5389

Epoch 00021: val_mDice did not improve from 0.54509
Epoch 22/300
 - 72s - loss: 0.0284 - acc: 0.9966 - mDice: 0.9448 - val_loss: 0.0040 - val_acc: 0.9937 - val_mDice: 0.5338

Epoch 00022: val_mDice did not improve from 0.54509
Epoch 23/300
 - 72s - loss: 0.0276 - acc: 0.9966 - mDice: 0.9463 - val_loss: -2.2440e-02 - val_acc: 0.9938 - val_mDice: 0.5386

Epoch 00023: val_mDice did not improve from 0.54509
Epoch 24/300
 - 72s - loss: 0.0275 - acc: 0.9966 - mDice: 0.9467 - val_loss: 0.0020 - val_acc: 0.9939 - val_mDice: 0.5351

Epoch 00024: val_mDice did not improve from 0.54509
Epoch 25/300
 - 72s - loss: 0.0274 - acc: 0.9967 - mDice: 0.9468 - val_loss: -1.9446e-02 - val_acc: 0.9936 - val_mDice: 0.5320

Epoch 00025: val_mDice did not improve from 0.54509
Epoch 26/300
 - 73s - loss: 0.0273 - acc: 0.9967 - mDice: 0.9469 - val_loss: 0.0057 - val_acc: 0.9936 - val_mDice: 0.5304

Epoch 00026: val_mDice did not improve from 0.54509
Epoch 27/300
 - 72s - loss: 0.0272 - acc: 0.9967 - mDice: 0.9472 - val_loss: -2.1336e-02 - val_acc: 0.9937 - val_mDice: 0.5350

Epoch 00027: val_mDice did not improve from 0.54509
Epoch 28/300
 - 72s - loss: 0.0274 - acc: 0.9967 - mDice: 0.9467 - val_loss: -2.4066e-02 - val_acc: 0.9939 - val_mDice: 0.5417

Epoch 00028: val_mDice did not improve from 0.54509
Epoch 29/300
 - 72s - loss: 0.0269 - acc: 0.9967 - mDice: 0.9479 - val_loss: 9.6918e-04 - val_acc: 0.9939 - val_mDice: 0.5398

Epoch 00029: val_mDice did not improve from 0.54509
Epoch 30/300
 - 72s - loss: 0.0269 - acc: 0.9967 - mDice: 0.9477 - val_loss: -2.2137e-02 - val_acc: 0.9938 - val_mDice: 0.5368

Epoch 00030: val_mDice did not improve from 0.54509
Epoch 31/300
 - 72s - loss: 0.0265 - acc: 0.9967 - mDice: 0.9485 - val_loss: 0.0035 - val_acc: 0.9937 - val_mDice: 0.5348

Epoch 00031: val_mDice did not improve from 0.54509
Epoch 32/300
 - 72s - loss: 0.0266 - acc: 0.9967 - mDice: 0.9483 - val_loss: 0.0289 - val_acc: 0.9938 - val_mDice: 0.5335

Epoch 00032: val_mDice did not improve from 0.54509
Epoch 33/300
 - 72s - loss: 0.0263 - acc: 0.9967 - mDice: 0.9490 - val_loss: 0.0500 - val_acc: 0.9936 - val_mDice: 0.5338

Epoch 00033: val_mDice did not improve from 0.54509
Epoch 34/300
 - 73s - loss: 0.0265 - acc: 0.9967 - mDice: 0.9485 - val_loss: -4.6141e-02 - val_acc: 0.9938 - val_mDice: 0.5347

Epoch 00034: val_mDice did not improve from 0.54509
Epoch 35/300
 - 73s - loss: 0.0265 - acc: 0.9967 - mDice: 0.9486 - val_loss: 0.0024 - val_acc: 0.9935 - val_mDice: 0.5325

Epoch 00035: val_mDice did not improve from 0.54509

Epoch 00035: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 36/300
 - 73s - loss: 0.0256 - acc: 0.9968 - mDice: 0.9504 - val_loss: 0.0043 - val_acc: 0.9937 - val_mDice: 0.5330

Epoch 00036: val_mDice did not improve from 0.54509
Epoch 37/300
 - 73s - loss: 0.0255 - acc: 0.9968 - mDice: 0.9504 - val_loss: 0.0288 - val_acc: 0.9936 - val_mDice: 0.5340

Epoch 00037: val_mDice did not improve from 0.54509
Epoch 38/300
 - 74s - loss: 0.0253 - acc: 0.9968 - mDice: 0.9508 - val_loss: 0.0049 - val_acc: 0.9936 - val_mDice: 0.5329

Epoch 00038: val_mDice did not improve from 0.54509
Epoch 39/300
 - 73s - loss: 0.0251 - acc: 0.9968 - mDice: 0.9512 - val_loss: 0.0278 - val_acc: 0.9937 - val_mDice: 0.5356

Epoch 00039: val_mDice did not improve from 0.54509
Epoch 40/300
 - 73s - loss: 0.0251 - acc: 0.9968 - mDice: 0.9513 - val_loss: 0.0273 - val_acc: 0.9938 - val_mDice: 0.5367

Epoch 00040: val_mDice did not improve from 0.54509
Epoch 41/300
 - 72s - loss: 0.0254 - acc: 0.9968 - mDice: 0.9507 - val_loss: 0.0277 - val_acc: 0.9939 - val_mDice: 0.5358

Epoch 00041: val_mDice did not improve from 0.54509
Epoch 42/300
 - 72s - loss: 0.0246 - acc: 0.9969 - mDice: 0.9522 - val_loss: 0.0275 - val_acc: 0.9938 - val_mDice: 0.5364

Epoch 00042: val_mDice did not improve from 0.54509
Epoch 43/300
 - 72s - loss: 0.0248 - acc: 0.9968 - mDice: 0.9518 - val_loss: 0.0281 - val_acc: 0.9938 - val_mDice: 0.5354

Epoch 00043: val_mDice did not improve from 0.54509
Epoch 44/300
 - 72s - loss: 0.0246 - acc: 0.9969 - mDice: 0.9522 - val_loss: 0.0286 - val_acc: 0.9938 - val_mDice: 0.5348

Epoch 00044: val_mDice did not improve from 0.54509
Epoch 45/300
 - 71s - loss: 0.0249 - acc: 0.9969 - mDice: 0.9517 - val_loss: 0.0293 - val_acc: 0.9936 - val_mDice: 0.5328

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:01,  1.62it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:00,  2.01it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:00<00:00,  2.55it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.91it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.30it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:51,  5.18it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:49,  5.33it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:51,  5.09it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:51,  5.08it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:47,  5.47it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<00:45,  5.71it/s]predicting train subjects:   3%|▎         | 7/266 [00:01<00:43,  5.93it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:42,  6.08it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:41,  6.20it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:40,  6.35it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:39,  6.40it/s]predicting train subjects:   5%|▍         | 12/266 [00:02<00:39,  6.51it/s]predicting train subjects:   5%|▍         | 13/266 [00:02<00:38,  6.60it/s]predicting train subjects:   5%|▌         | 14/266 [00:02<00:37,  6.64it/s]predicting train subjects:   6%|▌         | 15/266 [00:02<00:37,  6.64it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:37,  6.66it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:37,  6.66it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:37,  6.70it/s]predicting train subjects:   7%|▋         | 19/266 [00:03<00:36,  6.71it/s]predicting train subjects:   8%|▊         | 20/266 [00:03<00:36,  6.71it/s]predicting train subjects:   8%|▊         | 21/266 [00:03<00:36,  6.68it/s]predicting train subjects:   8%|▊         | 22/266 [00:03<00:36,  6.65it/s]predicting train subjects:   9%|▊         | 23/266 [00:03<00:35,  6.88it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:34,  7.10it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:33,  7.23it/s]predicting train subjects:  10%|▉         | 26/266 [00:04<00:33,  7.22it/s]predicting train subjects:  10%|█         | 27/266 [00:04<00:32,  7.27it/s]predicting train subjects:  11%|█         | 28/266 [00:04<00:32,  7.38it/s]predicting train subjects:  11%|█         | 29/266 [00:04<00:31,  7.48it/s]predicting train subjects:  11%|█▏        | 30/266 [00:04<00:31,  7.55it/s]predicting train subjects:  12%|█▏        | 31/266 [00:04<00:30,  7.60it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:30,  7.62it/s]predicting train subjects:  12%|█▏        | 33/266 [00:04<00:30,  7.60it/s]predicting train subjects:  13%|█▎        | 34/266 [00:05<00:30,  7.63it/s]predicting train subjects:  13%|█▎        | 35/266 [00:05<00:30,  7.64it/s]predicting train subjects:  14%|█▎        | 36/266 [00:05<00:30,  7.46it/s]predicting train subjects:  14%|█▍        | 37/266 [00:05<00:30,  7.39it/s]predicting train subjects:  14%|█▍        | 38/266 [00:05<00:30,  7.43it/s]predicting train subjects:  15%|█▍        | 39/266 [00:05<00:31,  7.30it/s]predicting train subjects:  15%|█▌        | 40/266 [00:05<00:30,  7.34it/s]predicting train subjects:  15%|█▌        | 41/266 [00:06<00:30,  7.35it/s]predicting train subjects:  16%|█▌        | 42/266 [00:06<00:30,  7.36it/s]predicting train subjects:  16%|█▌        | 43/266 [00:06<00:30,  7.32it/s]predicting train subjects:  17%|█▋        | 44/266 [00:06<00:30,  7.20it/s]predicting train subjects:  17%|█▋        | 45/266 [00:06<00:30,  7.13it/s]predicting train subjects:  17%|█▋        | 46/266 [00:06<00:30,  7.17it/s]predicting train subjects:  18%|█▊        | 47/266 [00:06<00:30,  7.18it/s]predicting train subjects:  18%|█▊        | 48/266 [00:07<00:30,  7.19it/s]predicting train subjects:  18%|█▊        | 49/266 [00:07<00:29,  7.24it/s]predicting train subjects:  19%|█▉        | 50/266 [00:07<00:29,  7.27it/s]predicting train subjects:  19%|█▉        | 51/266 [00:07<00:29,  7.28it/s]predicting train subjects:  20%|█▉        | 52/266 [00:07<00:29,  7.29it/s]predicting train subjects:  20%|█▉        | 53/266 [00:07<00:29,  7.29it/s]predicting train subjects:  20%|██        | 54/266 [00:07<00:29,  7.30it/s]predicting train subjects:  21%|██        | 55/266 [00:07<00:28,  7.28it/s]predicting train subjects:  21%|██        | 56/266 [00:08<00:28,  7.29it/s]predicting train subjects:  21%|██▏       | 57/266 [00:08<00:28,  7.28it/s]predicting train subjects:  22%|██▏       | 58/266 [00:08<00:28,  7.24it/s]predicting train subjects:  22%|██▏       | 59/266 [00:08<00:29,  7.02it/s]predicting train subjects:  23%|██▎       | 60/266 [00:08<00:29,  6.90it/s]predicting train subjects:  23%|██▎       | 61/266 [00:08<00:29,  6.84it/s]predicting train subjects:  23%|██▎       | 62/266 [00:08<00:30,  6.78it/s]predicting train subjects:  24%|██▎       | 63/266 [00:09<00:30,  6.75it/s]predicting train subjects:  24%|██▍       | 64/266 [00:09<00:29,  6.74it/s]predicting train subjects:  24%|██▍       | 65/266 [00:09<00:29,  6.70it/s]predicting train subjects:  25%|██▍       | 66/266 [00:09<00:31,  6.45it/s]predicting train subjects:  25%|██▌       | 67/266 [00:09<00:30,  6.43it/s]predicting train subjects:  26%|██▌       | 68/266 [00:09<00:31,  6.37it/s]predicting train subjects:  26%|██▌       | 69/266 [00:10<00:30,  6.40it/s]predicting train subjects:  26%|██▋       | 70/266 [00:10<00:30,  6.47it/s]predicting train subjects:  27%|██▋       | 71/266 [00:10<00:30,  6.48it/s]predicting train subjects:  27%|██▋       | 72/266 [00:10<00:30,  6.43it/s]predicting train subjects:  27%|██▋       | 73/266 [00:10<00:30,  6.39it/s]predicting train subjects:  28%|██▊       | 74/266 [00:10<00:29,  6.42it/s]predicting train subjects:  28%|██▊       | 75/266 [00:11<00:29,  6.46it/s]predicting train subjects:  29%|██▊       | 76/266 [00:11<00:29,  6.49it/s]predicting train subjects:  29%|██▉       | 77/266 [00:11<00:33,  5.56it/s]predicting train subjects:  29%|██▉       | 78/266 [00:11<00:35,  5.23it/s]predicting train subjects:  30%|██▉       | 79/266 [00:11<00:33,  5.52it/s]predicting train subjects:  30%|███       | 80/266 [00:11<00:33,  5.59it/s]predicting train subjects:  30%|███       | 81/266 [00:12<00:35,  5.14it/s]predicting train subjects:  31%|███       | 82/266 [00:12<00:34,  5.31it/s]predicting train subjects:  31%|███       | 83/266 [00:12<00:33,  5.43it/s]predicting train subjects:  32%|███▏      | 84/266 [00:12<00:32,  5.53it/s]predicting train subjects:  32%|███▏      | 85/266 [00:12<00:32,  5.62it/s]predicting train subjects:  32%|███▏      | 86/266 [00:13<00:32,  5.59it/s]predicting train subjects:  33%|███▎      | 87/266 [00:13<00:32,  5.53it/s]predicting train subjects:  33%|███▎      | 88/266 [00:13<00:32,  5.50it/s]predicting train subjects:  33%|███▎      | 89/266 [00:13<00:31,  5.59it/s]predicting train subjects:  34%|███▍      | 90/266 [00:13<00:31,  5.64it/s]predicting train subjects:  34%|███▍      | 91/266 [00:13<00:31,  5.54it/s]predicting train subjects:  35%|███▍      | 92/266 [00:14<00:31,  5.60it/s]predicting train subjects:  35%|███▍      | 93/266 [00:14<00:30,  5.65it/s]predicting train subjects:  35%|███▌      | 94/266 [00:14<00:30,  5.68it/s]predicting train subjects:  36%|███▌      | 95/266 [00:14<00:30,  5.68it/s]predicting train subjects:  36%|███▌      | 96/266 [00:14<00:29,  5.67it/s]predicting train subjects:  36%|███▋      | 97/266 [00:14<00:29,  5.72it/s]predicting train subjects:  37%|███▋      | 98/266 [00:15<00:29,  5.72it/s]predicting train subjects:  37%|███▋      | 99/266 [00:15<00:29,  5.72it/s]predicting train subjects:  38%|███▊      | 100/266 [00:15<00:28,  5.82it/s]predicting train subjects:  38%|███▊      | 101/266 [00:15<00:28,  5.86it/s]predicting train subjects:  38%|███▊      | 102/266 [00:15<00:27,  5.91it/s]predicting train subjects:  39%|███▊      | 103/266 [00:16<00:27,  5.94it/s]predicting train subjects:  39%|███▉      | 104/266 [00:16<00:27,  5.91it/s]predicting train subjects:  39%|███▉      | 105/266 [00:16<00:27,  5.94it/s]predicting train subjects:  40%|███▉      | 106/266 [00:16<00:26,  5.99it/s]predicting train subjects:  40%|████      | 107/266 [00:16<00:26,  5.97it/s]predicting train subjects:  41%|████      | 108/266 [00:16<00:26,  5.98it/s]predicting train subjects:  41%|████      | 109/266 [00:17<00:26,  5.98it/s]predicting train subjects:  41%|████▏     | 110/266 [00:17<00:26,  5.97it/s]predicting train subjects:  42%|████▏     | 111/266 [00:17<00:25,  6.00it/s]predicting train subjects:  42%|████▏     | 112/266 [00:17<00:25,  6.04it/s]predicting train subjects:  42%|████▏     | 113/266 [00:17<00:25,  6.02it/s]predicting train subjects:  43%|████▎     | 114/266 [00:17<00:25,  5.89it/s]predicting train subjects:  43%|████▎     | 115/266 [00:18<00:25,  5.84it/s]predicting train subjects:  44%|████▎     | 116/266 [00:18<00:25,  5.93it/s]predicting train subjects:  44%|████▍     | 117/266 [00:18<00:25,  5.94it/s]predicting train subjects:  44%|████▍     | 118/266 [00:18<00:24,  6.10it/s]predicting train subjects:  45%|████▍     | 119/266 [00:18<00:23,  6.23it/s]predicting train subjects:  45%|████▌     | 120/266 [00:18<00:23,  6.22it/s]predicting train subjects:  45%|████▌     | 121/266 [00:18<00:22,  6.37it/s]predicting train subjects:  46%|████▌     | 122/266 [00:19<00:22,  6.46it/s]predicting train subjects:  46%|████▌     | 123/266 [00:19<00:21,  6.56it/s]predicting train subjects:  47%|████▋     | 124/266 [00:19<00:21,  6.63it/s]predicting train subjects:  47%|████▋     | 125/266 [00:19<00:21,  6.67it/s]predicting train subjects:  47%|████▋     | 126/266 [00:19<00:20,  6.71it/s]predicting train subjects:  48%|████▊     | 127/266 [00:19<00:20,  6.76it/s]predicting train subjects:  48%|████▊     | 128/266 [00:20<00:20,  6.80it/s]predicting train subjects:  48%|████▊     | 129/266 [00:20<00:20,  6.75it/s]predicting train subjects:  49%|████▉     | 130/266 [00:20<00:20,  6.77it/s]predicting train subjects:  49%|████▉     | 131/266 [00:20<00:19,  6.76it/s]predicting train subjects:  50%|████▉     | 132/266 [00:20<00:19,  6.76it/s]predicting train subjects:  50%|█████     | 133/266 [00:20<00:19,  6.75it/s]predicting train subjects:  50%|█████     | 134/266 [00:20<00:19,  6.75it/s]predicting train subjects:  51%|█████     | 135/266 [00:21<00:19,  6.78it/s]predicting train subjects:  51%|█████     | 136/266 [00:21<00:19,  6.78it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:21<00:18,  6.85it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:21<00:18,  6.91it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:21<00:18,  6.89it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:21<00:18,  6.88it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:21<00:18,  6.94it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:22<00:18,  6.78it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:22<00:17,  6.84it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:22<00:17,  6.85it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:22<00:17,  6.93it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:22<00:17,  6.92it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:22<00:17,  6.95it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:22<00:16,  7.00it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:23<00:16,  6.98it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:23<00:16,  6.98it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:23<00:16,  7.01it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:23<00:16,  7.02it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:23<00:16,  6.97it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:23<00:17,  6.50it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:23<00:17,  6.19it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:24<00:18,  6.08it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:24<00:18,  5.90it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:24<00:18,  5.90it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:24<00:18,  5.82it/s]predicting train subjects:  60%|██████    | 160/266 [00:24<00:18,  5.80it/s]predicting train subjects:  61%|██████    | 161/266 [00:25<00:18,  5.79it/s]predicting train subjects:  61%|██████    | 162/266 [00:25<00:17,  5.79it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:25<00:17,  5.78it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:25<00:17,  5.82it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:25<00:17,  5.84it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:25<00:17,  5.83it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:26<00:16,  5.86it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:26<00:16,  5.89it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:26<00:16,  5.89it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:26<00:16,  5.89it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:26<00:16,  5.86it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:26<00:17,  5.49it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:27<00:18,  5.01it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:27<00:18,  4.92it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:27<00:16,  5.45it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:27<00:16,  5.47it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:27<00:15,  5.73it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:28<00:14,  5.93it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:28<00:14,  6.10it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:28<00:13,  6.19it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:28<00:13,  6.28it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:28<00:13,  6.32it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:28<00:12,  6.41it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:28<00:12,  6.47it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:29<00:12,  6.46it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:29<00:12,  6.47it/s]predicting train subjects:  70%|███████   | 187/266 [00:29<00:12,  6.42it/s]predicting train subjects:  71%|███████   | 188/266 [00:29<00:12,  6.39it/s]predicting train subjects:  71%|███████   | 189/266 [00:29<00:12,  6.40it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:29<00:11,  6.40it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:30<00:11,  6.43it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:30<00:11,  6.41it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:30<00:11,  6.43it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:30<00:11,  6.43it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:30<00:11,  6.28it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:30<00:11,  6.20it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:31<00:11,  6.12it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:31<00:11,  6.04it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:31<00:11,  6.02it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:31<00:11,  5.99it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:31<00:11,  5.84it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:31<00:10,  5.87it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:32<00:10,  5.90it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:32<00:10,  5.87it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:32<00:10,  5.84it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:32<00:10,  5.88it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:32<00:09,  5.94it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:32<00:09,  5.93it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:33<00:09,  5.96it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:33<00:09,  5.98it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:33<00:09,  6.00it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:33<00:09,  5.98it/s]predicting train subjects:  80%|████████  | 213/266 [00:33<00:08,  6.06it/s]predicting train subjects:  80%|████████  | 214/266 [00:33<00:08,  6.16it/s]predicting train subjects:  81%|████████  | 215/266 [00:34<00:08,  6.18it/s]predicting train subjects:  81%|████████  | 216/266 [00:34<00:08,  6.15it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:34<00:07,  6.16it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:34<00:07,  6.19it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:34<00:07,  6.21it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:34<00:07,  6.25it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:34<00:07,  6.28it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:35<00:07,  6.24it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:35<00:06,  6.27it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:35<00:06,  6.25it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:35<00:06,  6.30it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:35<00:06,  6.34it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:35<00:06,  6.26it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:36<00:06,  6.27it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:36<00:05,  6.26it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:36<00:05,  6.20it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:36<00:05,  6.35it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:36<00:05,  6.64it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:36<00:04,  6.88it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:36<00:04,  7.02it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:37<00:04,  7.16it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:37<00:04,  7.22it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:37<00:04,  7.16it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:37<00:03,  7.22it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:37<00:03,  7.25it/s]predicting train subjects:  90%|█████████ | 240/266 [00:37<00:03,  7.26it/s]predicting train subjects:  91%|█████████ | 241/266 [00:37<00:03,  7.30it/s]predicting train subjects:  91%|█████████ | 242/266 [00:38<00:03,  7.21it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:38<00:03,  7.29it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:38<00:02,  7.35it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:38<00:02,  7.34it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:38<00:02,  7.37it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:38<00:02,  7.34it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:38<00:02,  7.26it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:39<00:02,  7.11it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:39<00:02,  7.07it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:39<00:02,  6.76it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:39<00:02,  6.82it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:39<00:01,  6.84it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:39<00:01,  6.76it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:39<00:01,  6.63it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:40<00:01,  6.62it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:40<00:01,  6.65it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:40<00:01,  6.69it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:40<00:01,  6.70it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:40<00:00,  6.58it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:40<00:00,  6.65it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:41<00:00,  6.72it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:41<00:00,  6.79it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:41<00:00,  6.86it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:41<00:00,  6.85it/s]predicting train subjects: 100%|██████████| 266/266 [00:41<00:00,  6.79it/s]predicting train subjects: 100%|██████████| 266/266 [00:41<00:00,  6.40it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 80.49it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:03, 83.19it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:02, 83.55it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:02, 83.68it/s]saving BB  train1-THALAMUS:  14%|█▍        | 37/266 [00:00<00:02, 86.07it/s]saving BB  train1-THALAMUS:  17%|█▋        | 46/266 [00:00<00:02, 87.18it/s]saving BB  train1-THALAMUS:  21%|██        | 55/266 [00:00<00:02, 87.87it/s]saving BB  train1-THALAMUS:  24%|██▍       | 64/266 [00:00<00:02, 86.73it/s]saving BB  train1-THALAMUS:  27%|██▋       | 72/266 [00:00<00:02, 83.27it/s]saving BB  train1-THALAMUS:  30%|███       | 81/266 [00:00<00:02, 82.23it/s]saving BB  train1-THALAMUS:  33%|███▎      | 89/266 [00:01<00:02, 78.23it/s]saving BB  train1-THALAMUS:  36%|███▋      | 97/266 [00:01<00:02, 76.03it/s]saving BB  train1-THALAMUS:  39%|███▉      | 105/266 [00:01<00:02, 75.60it/s]saving BB  train1-THALAMUS:  42%|████▏     | 113/266 [00:01<00:02, 75.73it/s]saving BB  train1-THALAMUS:  45%|████▌     | 121/266 [00:01<00:01, 75.78it/s]saving BB  train1-THALAMUS:  49%|████▉     | 130/266 [00:01<00:01, 77.69it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 139/266 [00:01<00:01, 79.84it/s]saving BB  train1-THALAMUS:  56%|█████▌    | 148/266 [00:01<00:01, 81.74it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 157/266 [00:01<00:01, 81.32it/s]saving BB  train1-THALAMUS:  62%|██████▏   | 166/266 [00:02<00:01, 80.42it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 175/266 [00:02<00:01, 80.14it/s]saving BB  train1-THALAMUS:  69%|██████▉   | 184/266 [00:02<00:01, 77.89it/s]saving BB  train1-THALAMUS:  72%|███████▏  | 192/266 [00:02<00:00, 78.13it/s]saving BB  train1-THALAMUS:  75%|███████▌  | 200/266 [00:02<00:00, 77.36it/s]saving BB  train1-THALAMUS:  78%|███████▊  | 208/266 [00:02<00:00, 76.78it/s]saving BB  train1-THALAMUS:  81%|████████  | 216/266 [00:02<00:00, 77.06it/s]saving BB  train1-THALAMUS:  84%|████████▍ | 224/266 [00:02<00:00, 73.22it/s]saving BB  train1-THALAMUS:  87%|████████▋ | 232/266 [00:02<00:00, 72.52it/s]saving BB  train1-THALAMUS:  91%|█████████ | 242/266 [00:03<00:00, 77.51it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 252/266 [00:03<00:00, 81.01it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 261/266 [00:03<00:00, 83.15it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 80.37it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<04:45,  1.08s/it]Loading train:   1%|          | 2/266 [00:01<04:30,  1.03s/it]Loading train:   1%|          | 3/266 [00:02<04:11,  1.05it/s]Loading train:   2%|▏         | 4/266 [00:03<04:13,  1.03it/s]Loading train:   2%|▏         | 5/266 [00:04<03:56,  1.10it/s]Loading train:   2%|▏         | 6/266 [00:05<03:35,  1.21it/s]Loading train:   3%|▎         | 7/266 [00:05<03:23,  1.27it/s]Loading train:   3%|▎         | 8/266 [00:06<03:15,  1.32it/s]Loading train:   3%|▎         | 9/266 [00:07<03:08,  1.36it/s]Loading train:   4%|▍         | 10/266 [00:07<03:05,  1.38it/s]Loading train:   4%|▍         | 11/266 [00:08<02:59,  1.42it/s]Loading train:   5%|▍         | 12/266 [00:09<02:58,  1.42it/s]Loading train:   5%|▍         | 13/266 [00:09<02:56,  1.44it/s]Loading train:   5%|▌         | 14/266 [00:10<02:52,  1.46it/s]Loading train:   6%|▌         | 15/266 [00:11<02:47,  1.50it/s]Loading train:   6%|▌         | 16/266 [00:11<02:45,  1.51it/s]Loading train:   6%|▋         | 17/266 [00:12<02:46,  1.50it/s]Loading train:   7%|▋         | 18/266 [00:13<02:44,  1.51it/s]Loading train:   7%|▋         | 19/266 [00:13<02:44,  1.50it/s]Loading train:   8%|▊         | 20/266 [00:14<02:41,  1.52it/s]Loading train:   8%|▊         | 21/266 [00:15<02:39,  1.53it/s]Loading train:   8%|▊         | 22/266 [00:15<02:42,  1.50it/s]Loading train:   9%|▊         | 23/266 [00:16<02:36,  1.55it/s]Loading train:   9%|▉         | 24/266 [00:17<02:28,  1.63it/s]Loading train:   9%|▉         | 25/266 [00:17<02:25,  1.65it/s]Loading train:  10%|▉         | 26/266 [00:18<02:22,  1.69it/s]Loading train:  10%|█         | 27/266 [00:18<02:19,  1.72it/s]Loading train:  11%|█         | 28/266 [00:19<02:14,  1.77it/s]Loading train:  11%|█         | 29/266 [00:19<02:12,  1.79it/s]Loading train:  11%|█▏        | 30/266 [00:20<02:12,  1.79it/s]Loading train:  12%|█▏        | 31/266 [00:20<02:11,  1.79it/s]Loading train:  12%|█▏        | 32/266 [00:21<02:10,  1.79it/s]Loading train:  12%|█▏        | 33/266 [00:22<02:10,  1.78it/s]Loading train:  13%|█▎        | 34/266 [00:22<02:08,  1.80it/s]Loading train:  13%|█▎        | 35/266 [00:23<02:08,  1.79it/s]Loading train:  14%|█▎        | 36/266 [00:23<02:09,  1.78it/s]Loading train:  14%|█▍        | 37/266 [00:24<02:07,  1.79it/s]Loading train:  14%|█▍        | 38/266 [00:24<02:06,  1.81it/s]Loading train:  15%|█▍        | 39/266 [00:25<02:03,  1.83it/s]Loading train:  15%|█▌        | 40/266 [00:25<02:05,  1.80it/s]Loading train:  15%|█▌        | 41/266 [00:26<02:08,  1.75it/s]Loading train:  16%|█▌        | 42/266 [00:27<02:10,  1.71it/s]Loading train:  16%|█▌        | 43/266 [00:27<02:10,  1.71it/s]Loading train:  17%|█▋        | 44/266 [00:28<02:09,  1.72it/s]Loading train:  17%|█▋        | 45/266 [00:28<02:10,  1.69it/s]Loading train:  17%|█▋        | 46/266 [00:29<02:10,  1.68it/s]Loading train:  18%|█▊        | 47/266 [00:30<02:10,  1.68it/s]Loading train:  18%|█▊        | 48/266 [00:30<02:09,  1.68it/s]Loading train:  18%|█▊        | 49/266 [00:31<02:10,  1.66it/s]Loading train:  19%|█▉        | 50/266 [00:31<02:09,  1.66it/s]Loading train:  19%|█▉        | 51/266 [00:32<02:08,  1.68it/s]Loading train:  20%|█▉        | 52/266 [00:33<02:08,  1.67it/s]Loading train:  20%|█▉        | 53/266 [00:33<02:07,  1.67it/s]Loading train:  20%|██        | 54/266 [00:34<02:06,  1.68it/s]Loading train:  21%|██        | 55/266 [00:34<02:05,  1.68it/s]Loading train:  21%|██        | 56/266 [00:35<02:03,  1.70it/s]Loading train:  21%|██▏       | 57/266 [00:36<02:01,  1.72it/s]Loading train:  22%|██▏       | 58/266 [00:36<02:00,  1.72it/s]Loading train:  22%|██▏       | 59/266 [00:37<02:07,  1.63it/s]Loading train:  23%|██▎       | 60/266 [00:37<02:10,  1.57it/s]Loading train:  23%|██▎       | 61/266 [00:38<02:12,  1.55it/s]Loading train:  23%|██▎       | 62/266 [00:39<02:11,  1.55it/s]Loading train:  24%|██▎       | 63/266 [00:39<02:09,  1.56it/s]Loading train:  24%|██▍       | 64/266 [00:40<02:10,  1.55it/s]Loading train:  24%|██▍       | 65/266 [00:41<02:10,  1.54it/s]Loading train:  25%|██▍       | 66/266 [00:41<02:10,  1.53it/s]Loading train:  25%|██▌       | 67/266 [00:42<02:09,  1.54it/s]Loading train:  26%|██▌       | 68/266 [00:43<02:10,  1.52it/s]Loading train:  26%|██▌       | 69/266 [00:43<02:09,  1.53it/s]Loading train:  26%|██▋       | 70/266 [00:44<02:08,  1.53it/s]Loading train:  27%|██▋       | 71/266 [00:45<02:08,  1.52it/s]Loading train:  27%|██▋       | 72/266 [00:45<02:08,  1.51it/s]Loading train:  27%|██▋       | 73/266 [00:46<02:06,  1.53it/s]Loading train:  28%|██▊       | 74/266 [00:47<02:05,  1.53it/s]Loading train:  28%|██▊       | 75/266 [00:47<02:03,  1.55it/s]Loading train:  29%|██▊       | 76/266 [00:48<02:03,  1.54it/s]Loading train:  29%|██▉       | 77/266 [00:49<02:31,  1.25it/s]Loading train:  29%|██▉       | 78/266 [00:50<02:44,  1.14it/s]Loading train:  30%|██▉       | 79/266 [00:51<02:47,  1.12it/s]Loading train:  30%|███       | 80/266 [00:52<02:43,  1.14it/s]Loading train:  30%|███       | 81/266 [00:53<02:50,  1.09it/s]Loading train:  31%|███       | 82/266 [00:54<02:41,  1.14it/s]Loading train:  31%|███       | 83/266 [00:54<02:34,  1.19it/s]Loading train:  32%|███▏      | 84/266 [00:55<02:31,  1.20it/s]Loading train:  32%|███▏      | 85/266 [00:56<02:28,  1.22it/s]Loading train:  32%|███▏      | 86/266 [00:57<02:23,  1.25it/s]Loading train:  33%|███▎      | 87/266 [00:58<02:20,  1.27it/s]Loading train:  33%|███▎      | 88/266 [00:58<02:18,  1.29it/s]Loading train:  33%|███▎      | 89/266 [00:59<02:16,  1.30it/s]Loading train:  34%|███▍      | 90/266 [01:00<02:16,  1.29it/s]Loading train:  34%|███▍      | 91/266 [01:01<02:18,  1.27it/s]Loading train:  35%|███▍      | 92/266 [01:02<02:17,  1.27it/s]Loading train:  35%|███▍      | 93/266 [01:02<02:16,  1.27it/s]Loading train:  35%|███▌      | 94/266 [01:03<02:14,  1.28it/s]Loading train:  36%|███▌      | 95/266 [01:04<02:13,  1.28it/s]Loading train:  36%|███▌      | 96/266 [01:05<02:11,  1.29it/s]Loading train:  36%|███▋      | 97/266 [01:05<02:09,  1.30it/s]Loading train:  37%|███▋      | 98/266 [01:06<02:09,  1.30it/s]Loading train:  37%|███▋      | 99/266 [01:07<02:11,  1.27it/s]Loading train:  38%|███▊      | 100/266 [01:08<02:05,  1.32it/s]Loading train:  38%|███▊      | 101/266 [01:08<02:01,  1.36it/s]Loading train:  38%|███▊      | 102/266 [01:09<01:58,  1.38it/s]Loading train:  39%|███▊      | 103/266 [01:10<01:54,  1.42it/s]Loading train:  39%|███▉      | 104/266 [01:10<01:54,  1.41it/s]Loading train:  39%|███▉      | 105/266 [01:11<01:53,  1.42it/s]Loading train:  40%|███▉      | 106/266 [01:12<01:50,  1.45it/s]Loading train:  40%|████      | 107/266 [01:12<01:48,  1.46it/s]Loading train:  41%|████      | 108/266 [01:13<01:47,  1.47it/s]Loading train:  41%|████      | 109/266 [01:14<01:46,  1.47it/s]Loading train:  41%|████▏     | 110/266 [01:14<01:47,  1.45it/s]Loading train:  42%|████▏     | 111/266 [01:15<01:45,  1.47it/s]Loading train:  42%|████▏     | 112/266 [01:16<01:43,  1.49it/s]Loading train:  42%|████▏     | 113/266 [01:16<01:42,  1.49it/s]Loading train:  43%|████▎     | 114/266 [01:17<01:42,  1.48it/s]Loading train:  43%|████▎     | 115/266 [01:18<01:42,  1.48it/s]Loading train:  44%|████▎     | 116/266 [01:19<01:42,  1.46it/s]Loading train:  44%|████▍     | 117/266 [01:19<01:41,  1.47it/s]Loading train:  44%|████▍     | 118/266 [01:20<01:39,  1.49it/s]Loading train:  45%|████▍     | 119/266 [01:20<01:37,  1.50it/s]Loading train:  45%|████▌     | 120/266 [01:21<01:36,  1.51it/s]Loading train:  45%|████▌     | 121/266 [01:22<01:34,  1.54it/s]Loading train:  46%|████▌     | 122/266 [01:22<01:34,  1.53it/s]Loading train:  46%|████▌     | 123/266 [01:23<01:33,  1.54it/s]Loading train:  47%|████▋     | 124/266 [01:24<01:30,  1.56it/s]Loading train:  47%|████▋     | 125/266 [01:24<01:29,  1.57it/s]Loading train:  47%|████▋     | 126/266 [01:25<01:29,  1.56it/s]Loading train:  48%|████▊     | 127/266 [01:26<01:28,  1.56it/s]Loading train:  48%|████▊     | 128/266 [01:26<01:28,  1.56it/s]Loading train:  48%|████▊     | 129/266 [01:27<01:29,  1.54it/s]Loading train:  49%|████▉     | 130/266 [01:28<01:29,  1.53it/s]Loading train:  49%|████▉     | 131/266 [01:28<01:28,  1.53it/s]Loading train:  50%|████▉     | 132/266 [01:29<01:26,  1.55it/s]Loading train:  50%|█████     | 133/266 [01:30<01:25,  1.55it/s]Loading train:  50%|█████     | 134/266 [01:30<01:24,  1.56it/s]Loading train:  51%|█████     | 135/266 [01:31<01:24,  1.55it/s]Loading train:  51%|█████     | 136/266 [01:31<01:22,  1.58it/s]Loading train:  52%|█████▏    | 137/266 [01:32<01:20,  1.60it/s]Loading train:  52%|█████▏    | 138/266 [01:33<01:21,  1.58it/s]Loading train:  52%|█████▏    | 139/266 [01:33<01:18,  1.61it/s]Loading train:  53%|█████▎    | 140/266 [01:34<01:17,  1.63it/s]Loading train:  53%|█████▎    | 141/266 [01:34<01:16,  1.63it/s]Loading train:  53%|█████▎    | 142/266 [01:35<01:14,  1.65it/s]Loading train:  54%|█████▍    | 143/266 [01:36<01:13,  1.67it/s]Loading train:  54%|█████▍    | 144/266 [01:36<01:12,  1.68it/s]Loading train:  55%|█████▍    | 145/266 [01:37<01:11,  1.69it/s]Loading train:  55%|█████▍    | 146/266 [01:37<01:11,  1.68it/s]Loading train:  55%|█████▌    | 147/266 [01:38<01:11,  1.66it/s]Loading train:  56%|█████▌    | 148/266 [01:39<01:10,  1.67it/s]Loading train:  56%|█████▌    | 149/266 [01:39<01:09,  1.67it/s]Loading train:  56%|█████▋    | 150/266 [01:40<01:08,  1.69it/s]Loading train:  57%|█████▋    | 151/266 [01:40<01:08,  1.67it/s]Loading train:  57%|█████▋    | 152/266 [01:41<01:07,  1.68it/s]Loading train:  58%|█████▊    | 153/266 [01:42<01:07,  1.68it/s]Loading train:  58%|█████▊    | 154/266 [01:42<01:10,  1.60it/s]Loading train:  58%|█████▊    | 155/266 [01:43<01:10,  1.57it/s]Loading train:  59%|█████▊    | 156/266 [01:44<01:11,  1.54it/s]Loading train:  59%|█████▉    | 157/266 [01:44<01:10,  1.54it/s]Loading train:  59%|█████▉    | 158/266 [01:45<01:10,  1.53it/s]Loading train:  60%|█████▉    | 159/266 [01:46<01:12,  1.49it/s]Loading train:  60%|██████    | 160/266 [01:46<01:10,  1.51it/s]Loading train:  61%|██████    | 161/266 [01:47<01:09,  1.51it/s]Loading train:  61%|██████    | 162/266 [01:48<01:07,  1.53it/s]Loading train:  61%|██████▏   | 163/266 [01:48<01:07,  1.53it/s]Loading train:  62%|██████▏   | 164/266 [01:49<01:07,  1.52it/s]Loading train:  62%|██████▏   | 165/266 [01:50<01:05,  1.53it/s]Loading train:  62%|██████▏   | 166/266 [01:50<01:05,  1.52it/s]Loading train:  63%|██████▎   | 167/266 [01:51<01:05,  1.52it/s]Loading train:  63%|██████▎   | 168/266 [01:52<01:04,  1.52it/s]Loading train:  64%|██████▎   | 169/266 [01:52<01:03,  1.52it/s]Loading train:  64%|██████▍   | 170/266 [01:53<01:02,  1.53it/s]Loading train:  64%|██████▍   | 171/266 [01:54<01:02,  1.51it/s]Loading train:  65%|██████▍   | 172/266 [01:54<01:11,  1.32it/s]Loading train:  65%|██████▌   | 173/266 [01:56<01:18,  1.19it/s]Loading train:  65%|██████▌   | 174/266 [01:56<01:20,  1.15it/s]Loading train:  66%|██████▌   | 175/266 [01:57<01:17,  1.18it/s]Loading train:  66%|██████▌   | 176/266 [01:58<01:16,  1.18it/s]Loading train:  67%|██████▋   | 177/266 [01:59<01:12,  1.24it/s]Loading train:  67%|██████▋   | 178/266 [02:00<01:07,  1.30it/s]Loading train:  67%|██████▋   | 179/266 [02:00<01:04,  1.35it/s]Loading train:  68%|██████▊   | 180/266 [02:01<01:01,  1.39it/s]Loading train:  68%|██████▊   | 181/266 [02:02<01:00,  1.41it/s]Loading train:  68%|██████▊   | 182/266 [02:02<00:58,  1.44it/s]Loading train:  69%|██████▉   | 183/266 [02:03<00:57,  1.46it/s]Loading train:  69%|██████▉   | 184/266 [02:04<00:55,  1.47it/s]Loading train:  70%|██████▉   | 185/266 [02:04<00:54,  1.48it/s]Loading train:  70%|██████▉   | 186/266 [02:05<00:53,  1.49it/s]Loading train:  70%|███████   | 187/266 [02:06<00:52,  1.49it/s]Loading train:  71%|███████   | 188/266 [02:06<00:52,  1.49it/s]Loading train:  71%|███████   | 189/266 [02:07<00:50,  1.51it/s]Loading train:  71%|███████▏  | 190/266 [02:08<00:50,  1.52it/s]Loading train:  72%|███████▏  | 191/266 [02:08<00:50,  1.49it/s]Loading train:  72%|███████▏  | 192/266 [02:09<00:49,  1.49it/s]Loading train:  73%|███████▎  | 193/266 [02:10<00:49,  1.47it/s]Loading train:  73%|███████▎  | 194/266 [02:10<00:48,  1.49it/s]Loading train:  73%|███████▎  | 195/266 [02:11<00:48,  1.47it/s]Loading train:  74%|███████▎  | 196/266 [02:12<00:47,  1.48it/s]Loading train:  74%|███████▍  | 197/266 [02:12<00:46,  1.49it/s]Loading train:  74%|███████▍  | 198/266 [02:13<00:45,  1.49it/s]Loading train:  75%|███████▍  | 199/266 [02:14<00:44,  1.49it/s]Loading train:  75%|███████▌  | 200/266 [02:14<00:44,  1.48it/s]Loading train:  76%|███████▌  | 201/266 [02:15<00:43,  1.48it/s]Loading train:  76%|███████▌  | 202/266 [02:16<00:43,  1.47it/s]Loading train:  76%|███████▋  | 203/266 [02:16<00:43,  1.46it/s]Loading train:  77%|███████▋  | 204/266 [02:17<00:42,  1.46it/s]Loading train:  77%|███████▋  | 205/266 [02:18<00:41,  1.46it/s]Loading train:  77%|███████▋  | 206/266 [02:18<00:41,  1.46it/s]Loading train:  78%|███████▊  | 207/266 [02:19<00:40,  1.46it/s]Loading train:  78%|███████▊  | 208/266 [02:20<00:39,  1.47it/s]Loading train:  79%|███████▊  | 209/266 [02:20<00:38,  1.47it/s]Loading train:  79%|███████▉  | 210/266 [02:21<00:37,  1.48it/s]Loading train:  79%|███████▉  | 211/266 [02:23<00:53,  1.04it/s]Loading train:  80%|███████▉  | 212/266 [02:27<01:39,  1.84s/it]Loading train:  80%|████████  | 213/266 [02:30<02:00,  2.27s/it]Loading train:  80%|████████  | 214/266 [02:35<02:41,  3.10s/it]Loading train:  81%|████████  | 215/266 [02:40<03:04,  3.62s/it]Loading train:  81%|████████  | 216/266 [02:45<03:18,  3.97s/it]Loading train:  82%|████████▏ | 217/266 [02:49<03:25,  4.19s/it]Loading train:  82%|████████▏ | 218/266 [02:54<03:31,  4.41s/it]Loading train:  82%|████████▏ | 219/266 [02:59<03:32,  4.51s/it]Loading train:  83%|████████▎ | 220/266 [03:04<03:32,  4.62s/it]Loading train:  83%|████████▎ | 221/266 [03:09<03:29,  4.65s/it]Loading train:  83%|████████▎ | 222/266 [03:13<03:25,  4.67s/it]Loading train:  84%|████████▍ | 223/266 [03:18<03:22,  4.71s/it]Loading train:  84%|████████▍ | 224/266 [03:23<03:15,  4.66s/it]Loading train:  85%|████████▍ | 225/266 [03:27<03:12,  4.70s/it]Loading train:  85%|████████▍ | 226/266 [03:32<03:09,  4.75s/it]Loading train:  85%|████████▌ | 227/266 [03:37<03:06,  4.77s/it]Loading train:  86%|████████▌ | 228/266 [03:41<02:50,  4.50s/it]Loading train:  86%|████████▌ | 229/266 [03:45<02:46,  4.51s/it]Loading train:  86%|████████▋ | 230/266 [03:50<02:40,  4.47s/it]Loading train:  87%|████████▋ | 231/266 [03:53<02:25,  4.16s/it]Loading train:  87%|████████▋ | 232/266 [03:57<02:13,  3.92s/it]Loading train:  88%|████████▊ | 233/266 [04:00<01:59,  3.61s/it]Loading train:  88%|████████▊ | 234/266 [04:03<01:55,  3.60s/it]Loading train:  88%|████████▊ | 235/266 [04:07<01:49,  3.54s/it]Loading train:  89%|████████▊ | 236/266 [04:10<01:45,  3.53s/it]Loading train:  89%|████████▉ | 237/266 [04:13<01:41,  3.49s/it]Loading train:  89%|████████▉ | 238/266 [04:17<01:37,  3.48s/it]Loading train:  90%|████████▉ | 239/266 [04:20<01:33,  3.47s/it]Loading train:  90%|█████████ | 240/266 [04:24<01:28,  3.41s/it]Loading train:  91%|█████████ | 241/266 [04:27<01:25,  3.42s/it]Loading train:  91%|█████████ | 242/266 [04:31<01:23,  3.46s/it]Loading train:  91%|█████████▏| 243/266 [04:34<01:20,  3.49s/it]Loading train:  92%|█████████▏| 244/266 [04:37<01:15,  3.42s/it]Loading train:  92%|█████████▏| 245/266 [04:41<01:14,  3.53s/it]Loading train:  92%|█████████▏| 246/266 [04:45<01:09,  3.49s/it]Loading train:  93%|█████████▎| 247/266 [04:48<01:07,  3.53s/it]Loading train:  93%|█████████▎| 248/266 [04:52<01:04,  3.56s/it]Loading train:  94%|█████████▎| 249/266 [04:56<01:02,  3.70s/it]Loading train:  94%|█████████▍| 250/266 [05:00<00:59,  3.73s/it]Loading train:  94%|█████████▍| 251/266 [05:03<00:54,  3.66s/it]Loading train:  95%|█████████▍| 252/266 [05:06<00:47,  3.41s/it]Loading train:  95%|█████████▌| 253/266 [05:09<00:42,  3.25s/it]Loading train:  95%|█████████▌| 254/266 [05:12<00:37,  3.15s/it]Loading train:  96%|█████████▌| 255/266 [05:15<00:34,  3.13s/it]Loading train:  96%|█████████▌| 256/266 [05:18<00:29,  2.99s/it]Loading train:  97%|█████████▋| 257/266 [05:20<00:25,  2.89s/it]Loading train:  97%|█████████▋| 258/266 [05:23<00:23,  2.89s/it]Loading train:  97%|█████████▋| 259/266 [05:26<00:19,  2.80s/it]Loading train:  98%|█████████▊| 260/266 [05:28<00:16,  2.73s/it]Loading train:  98%|█████████▊| 261/266 [05:31<00:13,  2.76s/it]Loading train:  98%|█████████▊| 262/266 [05:34<00:10,  2.68s/it]Loading train:  99%|█████████▉| 263/266 [05:36<00:07,  2.61s/it]Loading train:  99%|█████████▉| 264/266 [05:39<00:05,  2.65s/it]Loading train: 100%|█████████▉| 265/266 [05:42<00:02,  2.70s/it]Loading train: 100%|██████████| 266/266 [05:44<00:00,  2.64s/it]Loading train: 100%|██████████| 266/266 [05:44<00:00,  1.30s/it]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:05, 48.75it/s]concatenating: train:   4%|▍         | 10/266 [00:00<00:05, 47.55it/s]concatenating: train:   6%|▌         | 15/266 [00:00<00:05, 48.05it/s]concatenating: train:   8%|▊         | 20/266 [00:00<00:05, 48.42it/s]concatenating: train:  10%|▉         | 26/266 [00:00<00:04, 50.22it/s]concatenating: train:  12%|█▏        | 32/266 [00:00<00:04, 52.32it/s]concatenating: train:  14%|█▍        | 38/266 [00:00<00:04, 54.02it/s]concatenating: train:  17%|█▋        | 44/266 [00:00<00:04, 54.53it/s]concatenating: train:  19%|█▉        | 50/266 [00:00<00:04, 53.77it/s]concatenating: train:  21%|██        | 56/266 [00:01<00:03, 53.68it/s]concatenating: train:  23%|██▎       | 62/266 [00:01<00:03, 53.20it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:03, 51.93it/s]concatenating: train:  28%|██▊       | 74/266 [00:01<00:03, 49.27it/s]concatenating: train:  30%|██▉       | 79/266 [00:01<00:03, 48.86it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:03, 48.16it/s]concatenating: train:  33%|███▎      | 89/266 [00:01<00:03, 46.72it/s]concatenating: train:  35%|███▌      | 94/266 [00:01<00:03, 45.68it/s]concatenating: train:  37%|███▋      | 99/266 [00:01<00:03, 44.96it/s]concatenating: train:  39%|███▉      | 105/266 [00:02<00:03, 47.11it/s]concatenating: train:  42%|████▏     | 111/266 [00:02<00:03, 49.17it/s]concatenating: train:  44%|████▍     | 117/266 [00:02<00:02, 50.91it/s]concatenating: train:  46%|████▌     | 123/266 [00:02<00:02, 49.78it/s]concatenating: train:  48%|████▊     | 129/266 [00:02<00:02, 49.31it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:02, 49.28it/s]concatenating: train:  53%|█████▎    | 140/266 [00:02<00:02, 50.51it/s]concatenating: train:  55%|█████▍    | 146/266 [00:02<00:02, 51.76it/s]concatenating: train:  57%|█████▋    | 152/266 [00:03<00:02, 52.73it/s]concatenating: train:  59%|█████▉    | 158/266 [00:03<00:02, 53.88it/s]concatenating: train:  62%|██████▏   | 164/266 [00:03<00:01, 54.69it/s]concatenating: train:  64%|██████▍   | 170/266 [00:03<00:01, 55.07it/s]concatenating: train:  66%|██████▌   | 176/266 [00:03<00:01, 54.38it/s]concatenating: train:  68%|██████▊   | 182/266 [00:03<00:01, 52.60it/s]concatenating: train:  71%|███████   | 188/266 [00:03<00:01, 51.21it/s]concatenating: train:  73%|███████▎  | 194/266 [00:03<00:01, 49.66it/s]concatenating: train:  75%|███████▍  | 199/266 [00:03<00:01, 49.72it/s]concatenating: train:  77%|███████▋  | 205/266 [00:04<00:01, 50.19it/s]concatenating: train:  79%|███████▉  | 211/266 [00:04<00:01, 50.26it/s]concatenating: train:  82%|████████▏ | 217/266 [00:04<00:01, 47.67it/s]concatenating: train:  83%|████████▎ | 222/266 [00:04<00:00, 46.34it/s]concatenating: train:  85%|████████▌ | 227/266 [00:04<00:00, 45.02it/s]concatenating: train:  87%|████████▋ | 232/266 [00:04<00:00, 44.80it/s]concatenating: train:  89%|████████▉ | 237/266 [00:04<00:00, 45.20it/s]concatenating: train:  91%|█████████ | 242/266 [00:04<00:00, 46.42it/s]concatenating: train:  93%|█████████▎| 247/266 [00:04<00:00, 42.73it/s]concatenating: train:  95%|█████████▌| 253/266 [00:05<00:00, 46.09it/s]concatenating: train:  97%|█████████▋| 259/266 [00:05<00:00, 47.74it/s]concatenating: train:  99%|█████████▉| 264/266 [00:05<00:00, 47.97it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 49.69it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:07<00:21,  7.22s/it]Loading test:  50%|█████     | 2/4 [00:12<00:13,  6.58s/it]Loading test:  75%|███████▌  | 3/4 [00:16<00:05,  5.92s/it]Loading test: 100%|██████████| 4/4 [00:26<00:00,  6.95s/it]Loading test: 100%|██████████| 4/4 [00:26<00:00,  6.51s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 57.55it/s]
Epoch 00045: val_mDice did not improve from 0.54509
Restoring model weights from the end of the best epoch
Epoch 00045: early stopping
{'val_loss': [0.24032015743533672, 0.23672870267413687, 0.23514129713214657, 0.1608210815389458, 0.2216959922174662, 0.1372335549101936, 0.1262665966678198, 0.18979374080822425, 0.09871017529857957, 0.01989744733048432, 0.07120300955127545, -0.024611111351337384, 0.05084834944817328, 0.002876350771700478, -0.027019705022535017, 0.03889182380056263, 0.056849657379959714, -0.016030161093837276, 0.007162405672499323, 0.026157963401626416, -0.006398939095419039, 0.003950414379536366, -0.02244035999473212, 0.0019622248396388353, -0.019446181341377145, 0.005718670729963714, -0.021335701381893963, -0.024066063221867565, 0.0009691843545762244, -0.022136804224835435, 0.0034943777633364087, 0.028911163508152548, 0.050038923659632285, -0.0461409894319681, 0.0023756978973265615, 0.004328904798249749, 0.028757759529366978, 0.004891551457918608, 0.027846140542042166, 0.027303827496675346, 0.027738354120301845, 0.02746710151655798, 0.028080090880393982, 0.028567848149363514, 0.029349493033832712], 'val_acc': [0.993020486890826, 0.992581222844183, 0.9931937130745824, 0.992930096373073, 0.9936855785899955, 0.9937003895307593, 0.9935202134158416, 0.9935087243617321, 0.9934497734453187, 0.9932375468923791, 0.9938394547100399, 0.9936154373822083, 0.9938068037884998, 0.9937006927305653, 0.9937889697238175, 0.9935737200469592, 0.9931290191101377, 0.9934500766451246, 0.9935183986540763, 0.9937136903885873, 0.9938890345339148, 0.9936928331999861, 0.9937950144926313, 0.9939256137417208, 0.9935894391081174, 0.9936136240994664, 0.9936828586658828, 0.9939250058630855, 0.9938545718086564, 0.9938001540990976, 0.9936728811737325, 0.9937659901365749, 0.9935573901491189, 0.9938442925957237, 0.993469117592937, 0.9937215484401428, 0.9935809761359733, 0.9936423467347403, 0.9937073453780143, 0.9937780855902962, 0.9938636382223655, 0.9937774791906844, 0.9937820197926561, 0.9937529909995294, 0.9936208861045742], 'val_mDice': [0.5229634490717434, 0.5302766497910171, 0.5331864237101291, 0.5319952299222165, 0.5450900631122494, 0.5317716901340792, 0.5331959303644099, 0.5447782653732868, 0.5362107205405721, 0.528865158188136, 0.532169428563887, 0.5276297914700827, 0.5344706049036447, 0.5385758807286435, 0.5363741468998694, 0.531983093290835, 0.5255441230885508, 0.5252478357691032, 0.5312754953321689, 0.5378066417449165, 0.5389143837149031, 0.5337821039609223, 0.5386452631974042, 0.5351156140527418, 0.5320405948990332, 0.5304181438965478, 0.5349928796956912, 0.5416832594362737, 0.5398435476548027, 0.5368386038923382, 0.5347534696162487, 0.5334672224580798, 0.5338150199974145, 0.5346725757231487, 0.5325488862639326, 0.5330486972781624, 0.534011120757749, 0.5328511219314547, 0.5356408455975298, 0.5367353358872179, 0.5358086907242428, 0.536425681253225, 0.5353917891423104, 0.5347732741099137, 0.5327744064644607], 'loss': [0.07277552994001431, 0.05263943546825107, 0.04558798209781784, 0.042368419575932605, 0.04026146117473972, 0.03821062806245027, 0.036459401326386816, 0.03591556959760979, 0.035005290701866594, 0.03470399020099414, 0.033006889665748225, 0.032807942520239386, 0.032508497295251584, 0.03182760782129519, 0.03175693358352644, 0.031546339209701, 0.031435358965782915, 0.03025699722550319, 0.030250551991275423, 0.03054078103370075, 0.028642166636757425, 0.028434036589408372, 0.027643106196782112, 0.02747116473320784, 0.027407151722142795, 0.027340008491434763, 0.02719382375185579, 0.027444087580373866, 0.026858920854304812, 0.026925646871758472, 0.02652651755031033, 0.026621596952038314, 0.026258933259124876, 0.02654281739631541, 0.026481360122170925, 0.025555739763043775, 0.02552994572569345, 0.0253348940194462, 0.025145628087320477, 0.025105287287542893, 0.025397869230489374, 0.024632596105942733, 0.024849203084935545, 0.024637608359256668, 0.024911045473904315], 'acc': [0.9917897046609526, 0.9943513721174149, 0.9950033294167652, 0.9953155036486855, 0.9955408543277696, 0.9957103190850379, 0.9958543450575408, 0.9959468677123177, 0.9960032605111423, 0.9960130711181119, 0.9961521729945692, 0.9961796319218508, 0.9962077916734156, 0.9962640934154138, 0.996287651664435, 0.9963090098956178, 0.9963131561011895, 0.9963929108007988, 0.9964020572741307, 0.9964105518326274, 0.9965703096308968, 0.9965873993743285, 0.9966033512797712, 0.9966318786139977, 0.9966537696620007, 0.9966644027505832, 0.9966744367112687, 0.9966563464512116, 0.9967034934085244, 0.9966983617725894, 0.9967058634496072, 0.9967279522025406, 0.9967326799760283, 0.9967254282687446, 0.9967439479587186, 0.9967999563852626, 0.9968169267225344, 0.9968330408234842, 0.9968392999445946, 0.9968465600188691, 0.9968429959204668, 0.9968514029572441, 0.9968436789750591, 0.9968578499825642, 0.9968707134070225], 'mDice': [0.8594774466151428, 0.8976620343707247, 0.9113760471061528, 0.917630753441313, 0.9217172084552624, 0.9257204019604782, 0.9291396433105162, 0.9301809337541943, 0.9319621880740782, 0.9325580936824803, 0.9358752960063811, 0.9362594747291684, 0.9368391538150793, 0.9381726927953107, 0.9383050290545498, 0.9387123941039889, 0.9389290922596423, 0.9412388821432935, 0.9412533087570172, 0.9406666369339565, 0.9443660691522804, 0.944772112114462, 0.9463446617400372, 0.9466727859429347, 0.9467904884166228, 0.9469183517639093, 0.9472074624734915, 0.9467172377865938, 0.9478621576662133, 0.9477280999125313, 0.9485216428776982, 0.9483289386344982, 0.9490401745826881, 0.9484768295921315, 0.9485892803728722, 0.9504053772647083, 0.9504482737211604, 0.9508321341612646, 0.9512039934809059, 0.9512791160175512, 0.9507048968874373, 0.9522216752125509, 0.9517899696368313, 0.9522053793146527, 0.9516555543151977], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 1  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 30 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________2020-01-22 08:00:51.921595: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 08:00:51.921680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 08:00:51.921696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 08:00:51.921705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 08:00:51.921984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 500,143
Non-trainable params: 1,200
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.84547306e-02 3.28337473e-02 8.46256982e-02 1.02775968e-02
 2.88289438e-02 7.67687179e-03 8.69161200e-02 1.13063096e-01
 9.18034792e-02 1.37762342e-02 2.77289750e-01 1.84195150e-01
 2.58582860e-04]
Train on 16945 samples, validate on 251 samples
Epoch 1/300
 - 39s - loss: 0.5485 - acc: 0.9175 - mDice: 0.4086 - val_loss: 0.7290 - val_acc: 0.9421 - val_mDice: 0.2117

Epoch 00001: val_mDice improved from -inf to 0.21166, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 2/300
 - 35s - loss: 0.4057 - acc: 0.9404 - mDice: 0.5627 - val_loss: 0.7103 - val_acc: 0.9489 - val_mDice: 0.2256

Epoch 00002: val_mDice improved from 0.21166 to 0.22564, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 3/300
 - 35s - loss: 0.3804 - acc: 0.9441 - mDice: 0.5900 - val_loss: 0.6962 - val_acc: 0.9478 - val_mDice: 0.2323

Epoch 00003: val_mDice improved from 0.22564 to 0.23232, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 4/300
 - 35s - loss: 0.3619 - acc: 0.9462 - mDice: 0.6099 - val_loss: 0.7037 - val_acc: 0.9460 - val_mDice: 0.2218

Epoch 00004: val_mDice did not improve from 0.23232
Epoch 5/300
 - 35s - loss: 0.3533 - acc: 0.9474 - mDice: 0.6193 - val_loss: 0.6001 - val_acc: 0.9512 - val_mDice: 0.2313

Epoch 00005: val_mDice did not improve from 0.23232
Epoch 6/300
 - 34s - loss: 0.3424 - acc: 0.9488 - mDice: 0.6310 - val_loss: 0.2859 - val_acc: 0.9515 - val_mDice: 0.2404

Epoch 00006: val_mDice improved from 0.23232 to 0.24036, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 7/300
 - 34s - loss: 0.3353 - acc: 0.9494 - mDice: 0.6387 - val_loss: 0.3922 - val_acc: 0.9506 - val_mDice: 0.2264

Epoch 00007: val_mDice did not improve from 0.24036
Epoch 8/300
 - 34s - loss: 0.3297 - acc: 0.9502 - mDice: 0.6446 - val_loss: 0.4038 - val_acc: 0.9518 - val_mDice: 0.2268

Epoch 00008: val_mDice did not improve from 0.24036
Epoch 9/300
 - 35s - loss: 0.3265 - acc: 0.9506 - mDice: 0.6481 - val_loss: 0.1830 - val_acc: 0.9515 - val_mDice: 0.2316

Epoch 00009: val_mDice did not improve from 0.24036
Epoch 10/300
 - 35s - loss: 0.3235 - acc: 0.9510 - mDice: 0.6513 - val_loss: 0.0932 - val_acc: 0.9517 - val_mDice: 0.2376

Epoch 00010: val_mDice did not improve from 0.24036
Epoch 11/300
 - 35s - loss: 0.3223 - acc: 0.9511 - mDice: 0.6527 - val_loss: 0.0597 - val_acc: 0.9497 - val_mDice: 0.2225

Epoch 00011: val_mDice did not improve from 0.24036
Epoch 12/300
 - 34s - loss: 0.3163 - acc: 0.9519 - mDice: 0.6591 - val_loss: 0.0916 - val_acc: 0.9513 - val_mDice: 0.2343

Epoch 00012: val_mDice did not improve from 0.24036
Epoch 13/300
 - 35s - loss: 0.3106 - acc: 0.9526 - mDice: 0.6653 - val_loss: 0.1262 - val_acc: 0.9512 - val_mDice: 0.2321

Epoch 00013: val_mDice did not improve from 0.24036
Epoch 14/300
 - 35s - loss: 0.3118 - acc: 0.9521 - mDice: 0.6640 - val_loss: -7.1400e-02 - val_acc: 0.9519 - val_mDice: 0.2392

Epoch 00014: val_mDice did not improve from 0.24036
Epoch 15/300
 - 35s - loss: 0.3062 - acc: 0.9529 - mDice: 0.6700 - val_loss: -6.4323e-02 - val_acc: 0.9513 - val_mDice: 0.2235

Epoch 00015: val_mDice did not improve from 0.24036
Epoch 16/300
 - 35s - loss: 0.3057 - acc: 0.9531 - mDice: 0.6705 - val_loss: -3.5615e-02 - val_acc: 0.9514 - val_mDice: 0.2273

Epoch 00016: val_mDice did not improve from 0.24036
Epoch 17/300
 - 35s - loss: 0.3035 - acc: 0.9534 - mDice: 0.6729 - val_loss: -9.8051e-02 - val_acc: 0.9495 - val_mDice: 0.2252

Epoch 00017: val_mDice did not improve from 0.24036
Epoch 18/300
 - 35s - loss: 0.3024 - acc: 0.9536 - mDice: 0.6742 - val_loss: -1.0609e-01 - val_acc: 0.9515 - val_mDice: 0.2361

Epoch 00018: val_mDice did not improve from 0.24036
Epoch 19/300
 - 35s - loss: 0.3007 - acc: 0.9537 - mDice: 0.6760 - val_loss: -1.7428e-01 - val_acc: 0.9513 - val_mDice: 0.2347

Epoch 00019: val_mDice did not improve from 0.24036
Epoch 20/300
 - 35s - loss: 0.3044 - acc: 0.9526 - mDice: 0.6680 - val_loss: 0.1331 - val_acc: 0.8925 - val_mDice: 0.0763

Epoch 00020: val_mDice did not improve from 0.24036
Epoch 21/300
 - 35s - loss: 0.3056 - acc: 0.9506 - mDice: 0.6392 - val_loss: -1.9745e-01 - val_acc: 0.9524 - val_mDice: 0.2338

Epoch 00021: val_mDice did not improve from 0.24036

Epoch 00021: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 22/300
 - 35s - loss: 0.2753 - acc: 0.9530 - mDice: 0.6686 - val_loss: -1.8841e-01 - val_acc: 0.9510 - val_mDice: 0.2405

Epoch 00022: val_mDice improved from 0.24036 to 0.24048, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd1/best_model_weights.h5
Epoch 23/300
 - 35s - loss: 0.2703 - acc: 0.9530 - mDice: 0.6654 - val_loss: -2.2158e-01 - val_acc: 0.9513 - val_mDice: 0.2340

Epoch 00023: val_mDice did not improve from 0.24048
Epoch 24/300
 - 34s - loss: 0.2627 - acc: 0.9529 - mDice: 0.6633 - val_loss: -1.9038e-01 - val_acc: 0.9505 - val_mDice: 0.2307

Epoch 00024: val_mDice did not improve from 0.24048
Epoch 25/300
 - 35s - loss: 0.2598 - acc: 0.9524 - mDice: 0.6531 - val_loss: -2.0631e-01 - val_acc: 0.9504 - val_mDice: 0.2282

Epoch 00025: val_mDice did not improve from 0.24048
Epoch 26/300
 - 35s - loss: 0.2523 - acc: 0.9523 - mDice: 0.6510 - val_loss: -1.9252e-01 - val_acc: 0.9511 - val_mDice: 0.2232

Epoch 00026: val_mDice did not improve from 0.24048
Epoch 27/300
 - 35s - loss: 0.2498 - acc: 0.9513 - mDice: 0.6438 - val_loss: -2.2208e-01 - val_acc: 0.9514 - val_mDice: 0.2305

Epoch 00027: val_mDice did not improve from 0.24048
Epoch 28/300
 - 34s - loss: 0.2420 - acc: 0.9517 - mDice: 0.6479 - val_loss: -2.4699e-01 - val_acc: 0.9504 - val_mDice: 0.2221

Epoch 00028: val_mDice did not improve from 0.24048
Epoch 29/300
 - 35s - loss: 0.2392 - acc: 0.9516 - mDice: 0.6506 - val_loss: -2.3057e-01 - val_acc: 0.9510 - val_mDice: 0.2275

Epoch 00029: val_mDice did not improve from 0.24048
Epoch 30/300
 - 35s - loss: 0.2355 - acc: 0.9516 - mDice: 0.6466 - val_loss: -1.9690e-01 - val_acc: 0.9489 - val_mDice: 0.2176

Epoch 00030: val_mDice did not improve from 0.24048
Epoch 31/300
 - 35s - loss: 0.2339 - acc: 0.9520 - mDice: 0.6498 - val_loss: -2.2844e-01 - val_acc: 0.9508 - val_mDice: 0.2321

Epoch 00031: val_mDice did not improve from 0.24048
Epoch 32/300
 - 34s - loss: 0.2373 - acc: 0.9519 - mDice: 0.6509 - val_loss: -2.2220e-01 - val_acc: 0.9513 - val_mDice: 0.2254

Epoch 00032: val_mDice did not improve from 0.24048
Epoch 33/300
 - 35s - loss: 0.2291 - acc: 0.9523 - mDice: 0.6522 - val_loss: -2.3793e-01 - val_acc: 0.9521 - val_mDice: 0.2222

Epoch 00033: val_mDice did not improve from 0.24048
Epoch 34/300
 - 35s - loss: 0.2382 - acc: 0.9509 - mDice: 0.6373 - val_loss: -2.3602e-01 - val_acc: 0.9495 - val_mDice: 0.2183

Epoch 00034: val_mDice did not improve from 0.24048
Epoch 35/300
 - 35s - loss: 0.2393 - acc: 0.9508 - mDice: 0.6360 - val_loss: -2.3089e-01 - val_acc: 0.9519 - val_mDice: 0.2215

Epoch 00035: val_mDice did not improve from 0.24048
Epoch 36/300
 - 37s - loss: 0.2336 - acc: 0.9519 - mDice: 0.6485 - val_loss: -2.3152e-01 - val_acc: 0.9489 - val_mDice: 0.2259

Epoch 00036: val_mDice did not improve from 0.24048

Epoch 00036: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 37/300
 - 35s - loss: 0.2209 - acc: 0.9523 - mDice: 0.6539 - val_loss: -2.5593e-01 - val_acc: 0.9515 - val_mDice: 0.2288

Epoch 00037: val_mDice did not improve from 0.24048
Epoch 38/300
 - 34s - loss: 0.2186 - acc: 0.9527 - mDice: 0.6604 - val_loss: -2.4396e-01 - val_acc: 0.9516 - val_mDice: 0.2271

Epoch 00038: val_mDice did not improve from 0.24048
Epoch 39/300
 - 36s - loss: 0.2179 - acc: 0.9526 - mDice: 0.6600 - val_loss: -2.5276e-01 - val_acc: 0.9521 - val_mDice: 0.2265

Epoch 00039: val_mDice did not improve from 0.24048
Epoch 40/300
 - 37s - loss: 0.2087 - acc: 0.9529 - mDice: 0.6599 - val_loss: -2.2737e-01 - val_acc: 0.9518 - val_mDice: 0.2245

Epoch 00040: val_mDice did not improve from 0.24048
Epoch 41/300
 - 37s - loss: 0.2140 - acc: 0.9530 - mDice: 0.6580 - val_loss: -2.4029e-01 - val_acc: 0.9515 - val_mDice: 0.2253

Epoch 00041: val_mDice did not improve from 0.24048
Epoch 42/300
 - 37s - loss: 0.2059 - acc: 0.9534 - mDice: 0.6635 - val_loss: -2.4353e-01 - val_acc: 0.9522 - val_mDice: 0.2282

Epoch 00042: val_mDice did not improve from 0.24048
Epoch 43/300
 - 36s - loss: 0.2092 - acc: 0.9535 - mDice: 0.6614 - val_loss: -2.4304e-01 - val_acc: 0.9520 - val_mDice: 0.2282

Epoch 00043: val_mDice did not improve from 0.24048
Epoch 44/300
 - 35s - loss: 0.2117 - acc: 0.9529 - mDice: 0.6520 - val_loss: -2.2820e-01 - val_acc: 0.9512 - val_mDice: 0.2252

Epoch 00044: val_mDice did not improve from 0.24048
Epoch 45/300
 - 34s - loss: 0.2061 - acc: 0.9534 - mDice: 0.6680 - val_loss: -2.4687e-01 - val_acc: 0.9515 - val_mDice: 0.2217

Epoch 00045: val_mDice did not improve from 0.24048
Epoch 46/300
 - 34s - loss: 0.2052 - acc: 0.9534 - mDice: 0.6671 - val_loss: -2.4423e-01 - val_acc: 0.9520 - val_mDice: 0.2295

Epoch 00046: val_mDice did not improve from 0.24048
Epoch 47/300
 - 34s - loss: 0.2056 - acc: 0.9532 - mDice: 0.6663 - val_loss: -2.2689e-01 - val_acc: 0.9506 - val_mDice: 0.2242

Epoch 00047: val_mDice did not improve from 0.24048
Epoch 48/300
 - 34s - loss: 0.2042 - acc: 0.9533 - mDice: 0.6681 - val_loss: -2.4804e-01 - val_acc: 0.9525 - val_mDice: 0.2311

Epoch 00048: val_mDice did not improve from 0.24048
Epoch 49/300
 - 35s - loss: 0.2014 - acc: 0.9537 - mDice: 0.6665 - val_loss: -2.3200e-01 - val_acc: 0.9509 - val_mDice: 0.2227

Epoch 00049: val_mDice did not improve from 0.24048
Epoch 50/300
 - 35s - loss: 0.2042 - acc: 0.9535 - mDice: 0.6680 - val_loss: -2.4909e-01 - val_acc: 0.9528 - val_mDice: 0.2317

Epoch 00050: val_mDice did not improve from 0.24048
Epoch 51/300
 - 35s - loss: 0.2037 - acc: 0.9538 - mDice: 0.6704 - val_loss: -2.3815e-01 - val_acc: 0.9526 - val_mDice: 0.2279

Epoch 00051: val_mDice did not improve from 0.24048

Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.
Epoch 52/300
 - 34s - loss: 0.2011 - acc: 0.9540 - mDice: 0.6732 - val_loss: -2.4904e-01 - val_acc: 0.9527 - val_mDice: 0.2260

Epoch 00052: val_mDice did not improve from 0.24048
Epoch 53/300
 - 35s - loss: 0.1966 - acc: 0.9541 - mDice: 0.6737 - val_loss: -2.4299e-01 - val_acc: 0.9524 - val_mDice: 0.2229

Epoch 00053: val_mDice did not improve from 0.24048
Epoch 54/300
 - 35s - loss: 0.1939 - acc: 0.9544 - mDice: 0.6757 - val_loss: -2.5176e-01 - val_acc: 0.9527 - val_mDice: 0.2309

Epoch 00054: val_mDice did not improve from 0.24048
Epoch 55/300
 - 34s - loss: 0.1940 - acc: 0.9543 - mDice: 0.6769 - val_loss: -2.4266e-01 - val_acc: 0.9529 - val_mDice: 0.2316

Epoch 00055: val_mDice did not improve from 0.24048
Epoch 56/300
 - 34s - loss: 0.1953 - acc: 0.9543 - mDice: 0.6768 - val_loss: -2.6582e-01 - val_acc: 0.9527 - val_mDice: 0.2262

Epoch 00056: val_mDice did not improve from 0.24048
Epoch 57/300
 - 34s - loss: 0.1935 - acc: 0.9544 - mDice: 0.6754 - val_loss: -2.4423e-01 - val_acc: 0.9528 - val_mDice: 0.2294

Epoch 00057: val_mDice did not improve from 0.24048
Epoch 58/300
 - 34s - loss: 0.1924 - acc: 0.9545 - mDice: 0.6764 - val_loss: -2.4231e-01 - val_acc: 0.9524 - val_mDice: 0.2272

Epoch 00058: val_mDice did not improve from 0.24048
Epoch 59/300
 - 34s - loss: 0.1917 - acc: 0.9545 - mDice: 0.6753 - val_loss: -2.5069e-01 - val_acc: 0.9528 - val_mDice: 0.2312

Epoch 00059: val_mDice did not improve from 0.24048
Epoch 60/300
 - 34s - loss: 0.1857 - acc: 0.9547 - mDice: 0.6827 - val_loss: -2.4532e-01 - val_acc: 0.9522 - val_mDice: 0.2244

Epoch 00060: val_mDice did not improve from 0.24048
Epoch 61/300
 - 34s - loss: 0.1940 - acc: 0.9548 - mDice: 0.6797 - val_loss: -2.4354e-01 - val_acc: 0.9528 - val_mDice: 0.2286

Epoch 00061: val_mDice did not improve from 0.24048
Epoch 62/300
 - 34s - loss: 0.1910 - acc: 0.9548 - mDice: 0.6794 - val_loss: -2.5223e-01 - val_acc: 0.9527 - val_mDice: 0.2247

Epoch 00062: val_mDice did not improve from 0.24048
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
{'val_loss': [0.729016457658365, 0.710250941643202, 0.6962082640108359, 0.7036841917797864, 0.6001417726515774, 0.28593736412040743, 0.3922489903481358, 0.40383253950046827, 0.18295869882778817, 0.09320952391541337, 0.05970287833555761, 0.09160559552265295, 0.12617450810048686, -0.07139989797515699, -0.06432269234581298, -0.035614690413156826, -0.09805088442753986, -0.10609454696485958, -0.17428055690579206, 0.1330534376471166, -0.19745254268743603, -0.18840936613658749, -0.2215843031338724, -0.1903810558870316, -0.20631489309805084, -0.19252422932847088, -0.22208297366194754, -0.24699488026924818, -0.2305674425574888, -0.19690301019950693, -0.22844212548250697, -0.22219604173623234, -0.23792862672492326, -0.23601732349609475, -0.23089353309803276, -0.23151573004475628, -0.25592543061570344, -0.24396216544318958, -0.2527553587706678, -0.2273685725858487, -0.24028681518428355, -0.24352503891485147, -0.24304319242854042, -0.22819865245624368, -0.24686555555498457, -0.24423097727070767, -0.22689249606958897, -0.2480364538862767, -0.23199822519167487, -0.24909302892081767, -0.23814726445779383, -0.24904157544497357, -0.24298949325939573, -0.2517604838566951, -0.2426595007741, -0.265817958965482, -0.2442329559786861, -0.2423079435331413, -0.2506937812642747, -0.2453212242914861, -0.24354276654729806, -0.2522283029924351], 'val_acc': [0.9421480701739094, 0.9488871458517127, 0.9477538573314469, 0.9459773040862672, 0.9511792531526421, 0.9514809405186262, 0.950603035341696, 0.9517698473189456, 0.9514537954710395, 0.95168684250805, 0.9496980041146753, 0.9513021669539797, 0.9512335289996934, 0.95188476554901, 0.9512606597991579, 0.9513819706867416, 0.9494920973758774, 0.9515176436815603, 0.9512590711335261, 0.8925356276006813, 0.9524194904532566, 0.9509733535379052, 0.9512718279523203, 0.9504753436700282, 0.9504162733298374, 0.9511425404909597, 0.9513995291227364, 0.9504434255014853, 0.9509669608803859, 0.9488839518976402, 0.9507881991891747, 0.9513133351071422, 0.9521002588994, 0.9495399781907222, 0.9518895600421495, 0.9489031037486407, 0.9515479731844716, 0.9515910713796122, 0.9521034481040985, 0.9517905925849519, 0.9515000923696267, 0.9521736770987036, 0.9519661721955257, 0.9511840452710946, 0.951488912343029, 0.9520491817557954, 0.9505695142593992, 0.9525152639563815, 0.9508536336906402, 0.9528488576174732, 0.9526477453718147, 0.9527435188749397, 0.9523891585756583, 0.9527004206797991, 0.9528680165925348, 0.9527115935823357, 0.9527913996897845, 0.9523684109349649, 0.9527578738581137, 0.9522391234736044, 0.9528089510017183, 0.9527099954179559], 'val_mDice': [0.2116593734854721, 0.2256377136327356, 0.23232221425292027, 0.22179814537920325, 0.23127039961249704, 0.24036204880214782, 0.22638947335609877, 0.2268306047199257, 0.23157615941834164, 0.23757984913677807, 0.22250686271257133, 0.23433343050964325, 0.23214755513041144, 0.23917488278858215, 0.22349150814264418, 0.2272746266715555, 0.2251730381373865, 0.23613217164320774, 0.23474466901613897, 0.0762641873972238, 0.2337915738265353, 0.24048413383770748, 0.23400856070665724, 0.23069337900891246, 0.2282150266358102, 0.22316322502386998, 0.23046128629925716, 0.22214184541151344, 0.22754500467938732, 0.2176485341264907, 0.23209838218897938, 0.22538952024809392, 0.22220087909247296, 0.2183171094532507, 0.22150383839213042, 0.22590484455287219, 0.22881014799454297, 0.2270649136062637, 0.22653503721928692, 0.22451736582109177, 0.2253055197012377, 0.22820532084461229, 0.22822027469417488, 0.22521673519891572, 0.22170506788796163, 0.22948998913347007, 0.22424079240318315, 0.2311263491670449, 0.22270079687297106, 0.2316829108028298, 0.22793642063421082, 0.22602935206605143, 0.22289477184830433, 0.23092847836919989, 0.2315655840464322, 0.2261580486755922, 0.22939415181063086, 0.22715993463043196, 0.2311672406842509, 0.22437270953360783, 0.2286208278510675, 0.2246889270159353], 'loss': [0.5484560102303494, 0.4057073690135699, 0.3803848335967369, 0.36193792129308644, 0.3532517243272332, 0.34237009493535725, 0.3352503948469857, 0.3297198603606287, 0.3265369172889809, 0.32351962753754865, 0.3222529430609602, 0.3163404489256492, 0.3105624576397933, 0.3117818805840065, 0.306236670735875, 0.3057429424673099, 0.3034945355734314, 0.3023562783528725, 0.30066108311408035, 0.3043704422816797, 0.3056142479489074, 0.2752700661858404, 0.2702587235594753, 0.26267234156032987, 0.25980834986115364, 0.2523048066145387, 0.2497676841501206, 0.24195783715019117, 0.23916131187241066, 0.23551400479070259, 0.23391203071692807, 0.2373358858626251, 0.22913239505214625, 0.2381873271846031, 0.23933602025260828, 0.23361879714283088, 0.220920795468159, 0.21856782017667978, 0.2178850672435863, 0.2087285381662952, 0.21402993387006516, 0.20585158468742396, 0.20922812927957715, 0.21174502089751818, 0.20610304738930627, 0.20516933383922045, 0.2055967564410295, 0.20424847912392888, 0.2013604075265745, 0.20420028954894384, 0.20373524183145808, 0.2011348267096018, 0.1966414222288611, 0.19393676028103402, 0.1939664471088767, 0.19530770367025993, 0.19353901929750777, 0.19240373331525382, 0.19173588782778275, 0.18569332393111004, 0.19399702690815726, 0.19100480231724534], 'acc': [0.9174522020606455, 0.9404260627672573, 0.9440555695271766, 0.9461680321469705, 0.9474177149306641, 0.948766158196243, 0.9493750047986224, 0.9502294137260491, 0.9506488277624405, 0.950977167009639, 0.9511412065723506, 0.9519466497476701, 0.9525881957149533, 0.9521496532834994, 0.9529434408400044, 0.9530628168783416, 0.9533938756731978, 0.9535704451382565, 0.9537106766465773, 0.9526124068437758, 0.9506427992512322, 0.953001839814196, 0.9530000434789941, 0.9528935054087927, 0.9524331398684214, 0.9522519351529245, 0.9513107311166328, 0.9516795954193539, 0.951592184759305, 0.9516193751882192, 0.9519688276176644, 0.9519105457950039, 0.9522530703848532, 0.9509495273738106, 0.9508499877401494, 0.9518855782376873, 0.9522761944895756, 0.9526541609087326, 0.9526273256981749, 0.9529288057276336, 0.9530446115726213, 0.9533507260786604, 0.9535015721383014, 0.9529153760396193, 0.9534193626650318, 0.9534258415967042, 0.9532247291760798, 0.9533468951831423, 0.9536528667189372, 0.953513440743911, 0.9538051786764634, 0.953965814020754, 0.9541176772286456, 0.9544083274687662, 0.9543015297692446, 0.9543288855223432, 0.9543608749605765, 0.9544611946429852, 0.9544857368950437, 0.954675902638614, 0.9547708077605195, 0.954813650010363], 'mDice': [0.4086219831607526, 0.5626528784830545, 0.5899722082103449, 0.609895652938853, 0.61926118231481, 0.6310040562263313, 0.638704851546728, 0.6446498768911421, 0.6480915405012295, 0.6513351225930352, 0.6527167629372514, 0.6591058650633057, 0.6653297865204348, 0.6640022922385298, 0.6699815881871375, 0.6705205061770569, 0.6729276853523694, 0.6741539506952331, 0.6759937541363126, 0.6679950104100263, 0.6391595661481878, 0.6686183294211563, 0.6654251335327799, 0.6633095989434126, 0.6531437189925839, 0.6509903934227749, 0.6437775801156045, 0.6478662051152747, 0.6506378261362005, 0.6465908371705719, 0.6498272226214866, 0.6509373199802544, 0.6522037538763836, 0.6373311359645273, 0.6360284076851355, 0.6484812412968284, 0.6538705775329025, 0.6604444969189346, 0.6600446481203814, 0.6599303075928855, 0.6580077979585068, 0.6635325136491421, 0.6614094038880586, 0.6520383384119413, 0.6680462017598212, 0.6671173482315489, 0.6663111613084518, 0.6681387362912117, 0.6665158974944965, 0.6679837837898827, 0.6704253677633808, 0.6732474598922572, 0.6737427757038905, 0.6756589229249715, 0.6769247718285093, 0.6768364014263947, 0.6753872066657077, 0.676441963881861, 0.6752578269489116, 0.6826636888137361, 0.6796921675765926, 0.6794422534793202], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125, 0.000125]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.53s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.34s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.23s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.22s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.15s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<01:08,  3.89it/s]Loading train:   1%|          | 2/266 [00:00<01:07,  3.94it/s]Loading train:   1%|          | 3/266 [00:00<01:05,  3.99it/s]Loading train:   2%|▏         | 4/266 [00:01<01:06,  3.93it/s]Loading train:   2%|▏         | 5/266 [00:01<01:05,  3.98it/s]Loading train:   2%|▏         | 6/266 [00:01<01:03,  4.07it/s]Loading train:   3%|▎         | 7/266 [00:01<01:02,  4.17it/s]Loading train:   3%|▎         | 8/266 [00:01<01:00,  4.24it/s]Loading train:   3%|▎         | 9/266 [00:02<00:59,  4.33it/s]Loading train:   4%|▍         | 10/266 [00:02<00:58,  4.36it/s]Loading train:   4%|▍         | 11/266 [00:02<00:58,  4.39it/s]Loading train:   5%|▍         | 12/266 [00:02<00:57,  4.43it/s]Loading train:   5%|▍         | 13/266 [00:03<00:57,  4.43it/s]Loading train:   5%|▌         | 14/266 [00:03<00:56,  4.43it/s]Loading train:   6%|▌         | 15/266 [00:03<00:56,  4.43it/s]Loading train:   6%|▌         | 16/266 [00:03<00:56,  4.43it/s]Loading train:   6%|▋         | 17/266 [00:03<00:56,  4.43it/s]Loading train:   7%|▋         | 18/266 [00:04<00:55,  4.44it/s]Loading train:   7%|▋         | 19/266 [00:04<00:55,  4.44it/s]Loading train:   8%|▊         | 20/266 [00:04<00:55,  4.43it/s]Loading train:   8%|▊         | 21/266 [00:04<00:55,  4.45it/s]Loading train:   8%|▊         | 22/266 [00:05<00:54,  4.45it/s]Loading train:   9%|▊         | 23/266 [00:05<00:54,  4.49it/s]Loading train:   9%|▉         | 24/266 [00:05<00:53,  4.53it/s]Loading train:   9%|▉         | 25/266 [00:05<00:53,  4.53it/s]Loading train:  10%|▉         | 26/266 [00:05<00:53,  4.52it/s]Loading train:  10%|█         | 27/266 [00:06<00:53,  4.49it/s]Loading train:  11%|█         | 28/266 [00:06<00:52,  4.50it/s]Loading train:  11%|█         | 29/266 [00:06<00:53,  4.47it/s]Loading train:  11%|█▏        | 30/266 [00:06<00:52,  4.50it/s]Loading train:  12%|█▏        | 31/266 [00:07<00:52,  4.50it/s]Loading train:  12%|█▏        | 32/266 [00:07<00:51,  4.51it/s]Loading train:  12%|█▏        | 33/266 [00:07<00:51,  4.53it/s]Loading train:  13%|█▎        | 34/266 [00:07<00:51,  4.53it/s]Loading train:  13%|█▎        | 35/266 [00:07<00:50,  4.53it/s]Loading train:  14%|█▎        | 36/266 [00:08<00:51,  4.50it/s]Loading train:  14%|█▍        | 37/266 [00:08<00:50,  4.51it/s]Loading train:  14%|█▍        | 38/266 [00:08<00:50,  4.50it/s]Loading train:  15%|█▍        | 39/266 [00:08<00:50,  4.53it/s]Loading train:  15%|█▌        | 40/266 [00:09<00:49,  4.55it/s]Loading train:  15%|█▌        | 41/266 [00:09<00:49,  4.56it/s]Loading train:  16%|█▌        | 42/266 [00:09<00:48,  4.58it/s]Loading train:  16%|█▌        | 43/266 [00:09<00:49,  4.53it/s]Loading train:  17%|█▋        | 44/266 [00:09<00:48,  4.54it/s]Loading train:  17%|█▋        | 45/266 [00:10<00:49,  4.49it/s]Loading train:  17%|█▋        | 46/266 [00:10<00:48,  4.52it/s]Loading train:  18%|█▊        | 47/266 [00:10<00:48,  4.53it/s]Loading train:  18%|█▊        | 48/266 [00:10<00:48,  4.54it/s]Loading train:  18%|█▊        | 49/266 [00:11<00:47,  4.55it/s]Loading train:  19%|█▉        | 50/266 [00:11<00:47,  4.52it/s]Loading train:  19%|█▉        | 51/266 [00:11<00:47,  4.54it/s]Loading train:  20%|█▉        | 52/266 [00:11<00:47,  4.54it/s]Loading train:  20%|█▉        | 53/266 [00:11<00:46,  4.56it/s]Loading train:  20%|██        | 54/266 [00:12<00:47,  4.49it/s]Loading train:  21%|██        | 55/266 [00:12<00:46,  4.52it/s]Loading train:  21%|██        | 56/266 [00:12<00:46,  4.55it/s]Loading train:  21%|██▏       | 57/266 [00:12<00:47,  4.43it/s]Loading train:  22%|██▏       | 58/266 [00:13<00:46,  4.47it/s]Loading train:  22%|██▏       | 59/266 [00:13<00:46,  4.48it/s]Loading train:  23%|██▎       | 60/266 [00:13<00:46,  4.47it/s]Loading train:  23%|██▎       | 61/266 [00:13<00:45,  4.47it/s]Loading train:  23%|██▎       | 62/266 [00:13<00:45,  4.48it/s]Loading train:  24%|██▎       | 63/266 [00:14<00:45,  4.49it/s]Loading train:  24%|██▍       | 64/266 [00:14<00:45,  4.48it/s]Loading train:  24%|██▍       | 65/266 [00:14<00:44,  4.47it/s]Loading train:  25%|██▍       | 66/266 [00:14<00:45,  4.44it/s]Loading train:  25%|██▌       | 67/266 [00:15<00:44,  4.43it/s]Loading train:  26%|██▌       | 68/266 [00:15<00:44,  4.43it/s]Loading train:  26%|██▌       | 69/266 [00:15<00:44,  4.45it/s]Loading train:  26%|██▋       | 70/266 [00:15<00:43,  4.46it/s]Loading train:  27%|██▋       | 71/266 [00:15<00:43,  4.47it/s]Loading train:  27%|██▋       | 72/266 [00:16<00:43,  4.47it/s]Loading train:  27%|██▋       | 73/266 [00:16<00:43,  4.45it/s]Loading train:  28%|██▊       | 74/266 [00:16<00:43,  4.45it/s]Loading train:  28%|██▊       | 75/266 [00:16<00:42,  4.46it/s]Loading train:  29%|██▊       | 76/266 [00:17<00:42,  4.46it/s]Loading train:  29%|██▉       | 77/266 [00:17<00:45,  4.14it/s]Loading train:  29%|██▉       | 78/266 [00:17<00:46,  4.04it/s]Loading train:  30%|██▉       | 79/266 [00:17<00:45,  4.16it/s]Loading train:  30%|███       | 80/266 [00:18<00:43,  4.24it/s]Loading train:  30%|███       | 81/266 [00:18<00:45,  4.08it/s]Loading train:  31%|███       | 82/266 [00:18<00:45,  4.01it/s]Loading train:  31%|███       | 83/266 [00:18<00:46,  3.97it/s]Loading train:  32%|███▏      | 84/266 [00:19<00:46,  3.93it/s]Loading train:  32%|███▏      | 85/266 [00:19<00:46,  3.91it/s]Loading train:  32%|███▏      | 86/266 [00:19<00:46,  3.91it/s]Loading train:  33%|███▎      | 87/266 [00:19<00:45,  3.91it/s]Loading train:  33%|███▎      | 88/266 [00:20<00:45,  3.90it/s]Loading train:  33%|███▎      | 89/266 [00:20<00:45,  3.87it/s]Loading train:  34%|███▍      | 90/266 [00:20<00:45,  3.88it/s]Loading train:  34%|███▍      | 91/266 [00:20<00:44,  3.90it/s]Loading train:  35%|███▍      | 92/266 [00:21<00:44,  3.90it/s]Loading train:  35%|███▍      | 93/266 [00:21<00:44,  3.91it/s]Loading train:  35%|███▌      | 94/266 [00:21<00:44,  3.88it/s]Loading train:  36%|███▌      | 95/266 [00:21<00:43,  3.89it/s]Loading train:  36%|███▌      | 96/266 [00:22<00:43,  3.91it/s]Loading train:  36%|███▋      | 97/266 [00:22<00:43,  3.89it/s]Loading train:  37%|███▋      | 98/266 [00:22<00:43,  3.82it/s]Loading train:  37%|███▋      | 99/266 [00:22<00:43,  3.84it/s]Loading train:  38%|███▊      | 100/266 [00:23<00:42,  3.88it/s]Loading train:  38%|███▊      | 101/266 [00:23<00:42,  3.92it/s]Loading train:  38%|███▊      | 102/266 [00:23<00:41,  3.94it/s]Loading train:  39%|███▊      | 103/266 [00:23<00:40,  4.00it/s]Loading train:  39%|███▉      | 104/266 [00:24<00:40,  4.02it/s]Loading train:  39%|███▉      | 105/266 [00:24<00:39,  4.04it/s]Loading train:  40%|███▉      | 106/266 [00:24<00:39,  4.04it/s]Loading train:  40%|████      | 107/266 [00:24<00:39,  4.02it/s]Loading train:  41%|████      | 108/266 [00:25<00:39,  4.01it/s]Loading train:  41%|████      | 109/266 [00:25<00:39,  3.99it/s]Loading train:  41%|████▏     | 110/266 [00:25<00:39,  4.00it/s]Loading train:  42%|████▏     | 111/266 [00:25<00:39,  3.96it/s]Loading train:  42%|████▏     | 112/266 [00:26<00:39,  3.94it/s]Loading train:  42%|████▏     | 113/266 [00:26<00:38,  3.94it/s]Loading train:  43%|████▎     | 114/266 [00:26<00:38,  3.96it/s]Loading train:  43%|████▎     | 115/266 [00:26<00:38,  3.96it/s]Loading train:  44%|████▎     | 116/266 [00:27<00:37,  3.99it/s]Loading train:  44%|████▍     | 117/266 [00:27<00:37,  3.99it/s]Loading train:  44%|████▍     | 118/266 [00:27<00:35,  4.19it/s]Loading train:  45%|████▍     | 119/266 [00:27<00:33,  4.36it/s]Loading train:  45%|████▌     | 120/266 [00:28<00:32,  4.44it/s]Loading train:  45%|████▌     | 121/266 [00:28<00:31,  4.54it/s]Loading train:  46%|████▌     | 122/266 [00:28<00:31,  4.62it/s]Loading train:  46%|████▌     | 123/266 [00:28<00:30,  4.66it/s]Loading train:  47%|████▋     | 124/266 [00:28<00:30,  4.72it/s]Loading train:  47%|████▋     | 125/266 [00:29<00:29,  4.72it/s]Loading train:  47%|████▋     | 126/266 [00:29<00:29,  4.68it/s]Loading train:  48%|████▊     | 127/266 [00:29<00:29,  4.71it/s]Loading train:  48%|████▊     | 128/266 [00:29<00:29,  4.72it/s]Loading train:  48%|████▊     | 129/266 [00:30<00:28,  4.75it/s]Loading train:  49%|████▉     | 130/266 [00:30<00:28,  4.77it/s]Loading train:  49%|████▉     | 131/266 [00:30<00:28,  4.79it/s]Loading train:  50%|████▉     | 132/266 [00:30<00:28,  4.77it/s]Loading train:  50%|█████     | 133/266 [00:30<00:27,  4.82it/s]Loading train:  50%|█████     | 134/266 [00:31<00:27,  4.82it/s]Loading train:  51%|█████     | 135/266 [00:31<00:27,  4.80it/s]Loading train:  51%|█████     | 136/266 [00:31<00:27,  4.68it/s]Loading train:  52%|█████▏    | 137/266 [00:31<00:27,  4.66it/s]Loading train:  52%|█████▏    | 138/266 [00:31<00:28,  4.56it/s]Loading train:  52%|█████▏    | 139/266 [00:32<00:28,  4.52it/s]Loading train:  53%|█████▎    | 140/266 [00:32<00:27,  4.57it/s]Loading train:  53%|█████▎    | 141/266 [00:32<00:27,  4.56it/s]Loading train:  53%|█████▎    | 142/266 [00:32<00:26,  4.63it/s]Loading train:  54%|█████▍    | 143/266 [00:33<00:26,  4.64it/s]Loading train:  54%|█████▍    | 144/266 [00:33<00:26,  4.65it/s]Loading train:  55%|█████▍    | 145/266 [00:33<00:25,  4.68it/s]Loading train:  55%|█████▍    | 146/266 [00:33<00:25,  4.68it/s]Loading train:  55%|█████▌    | 147/266 [00:33<00:25,  4.60it/s]Loading train:  56%|█████▌    | 148/266 [00:34<00:25,  4.60it/s]Loading train:  56%|█████▌    | 149/266 [00:34<00:25,  4.59it/s]Loading train:  56%|█████▋    | 150/266 [00:34<00:25,  4.56it/s]Loading train:  57%|█████▋    | 151/266 [00:34<00:25,  4.56it/s]Loading train:  57%|█████▋    | 152/266 [00:34<00:25,  4.54it/s]Loading train:  58%|█████▊    | 153/266 [00:35<00:24,  4.59it/s]Loading train:  58%|█████▊    | 154/266 [00:35<00:25,  4.38it/s]Loading train:  58%|█████▊    | 155/266 [00:35<00:26,  4.27it/s]Loading train:  59%|█████▊    | 156/266 [00:35<00:26,  4.12it/s]Loading train:  59%|█████▉    | 157/266 [00:36<00:26,  4.07it/s]Loading train:  59%|█████▉    | 158/266 [00:36<00:26,  4.08it/s]Loading train:  60%|█████▉    | 159/266 [00:36<00:26,  4.11it/s]Loading train:  60%|██████    | 160/266 [00:36<00:25,  4.10it/s]Loading train:  61%|██████    | 161/266 [00:37<00:25,  4.05it/s]Loading train:  61%|██████    | 162/266 [00:37<00:25,  4.03it/s]Loading train:  61%|██████▏   | 163/266 [00:37<00:25,  4.06it/s]Loading train:  62%|██████▏   | 164/266 [00:37<00:25,  4.06it/s]Loading train:  62%|██████▏   | 165/266 [00:38<00:24,  4.09it/s]Loading train:  62%|██████▏   | 166/266 [00:38<00:24,  4.11it/s]Loading train:  63%|██████▎   | 167/266 [00:38<00:24,  4.12it/s]Loading train:  63%|██████▎   | 168/266 [00:38<00:23,  4.14it/s]Loading train:  64%|██████▎   | 169/266 [00:39<00:23,  4.12it/s]Loading train:  64%|██████▍   | 170/266 [00:39<00:23,  4.13it/s]Loading train:  64%|██████▍   | 171/266 [00:39<00:23,  4.11it/s]Loading train:  65%|██████▍   | 172/266 [00:39<00:22,  4.16it/s]Loading train:  65%|██████▌   | 173/266 [00:40<00:23,  4.01it/s]Loading train:  65%|██████▌   | 174/266 [00:40<00:23,  3.99it/s]Loading train:  66%|██████▌   | 175/266 [00:40<00:21,  4.24it/s]Loading train:  66%|██████▌   | 176/266 [00:40<00:20,  4.29it/s]Loading train:  67%|██████▋   | 177/266 [00:41<00:20,  4.38it/s]Loading train:  67%|██████▋   | 178/266 [00:41<00:19,  4.43it/s]Loading train:  67%|██████▋   | 179/266 [00:41<00:19,  4.50it/s]Loading train:  68%|██████▊   | 180/266 [00:41<00:18,  4.54it/s]Loading train:  68%|██████▊   | 181/266 [00:41<00:18,  4.55it/s]Loading train:  68%|██████▊   | 182/266 [00:42<00:18,  4.58it/s]Loading train:  69%|██████▉   | 183/266 [00:42<00:18,  4.59it/s]Loading train:  69%|██████▉   | 184/266 [00:42<00:17,  4.61it/s]Loading train:  70%|██████▉   | 185/266 [00:42<00:17,  4.62it/s]Loading train:  70%|██████▉   | 186/266 [00:42<00:17,  4.63it/s]Loading train:  70%|███████   | 187/266 [00:43<00:17,  4.57it/s]Loading train:  71%|███████   | 188/266 [00:43<00:17,  4.58it/s]Loading train:  71%|███████   | 189/266 [00:43<00:16,  4.60it/s]Loading train:  71%|███████▏  | 190/266 [00:43<00:16,  4.61it/s]Loading train:  72%|███████▏  | 191/266 [00:44<00:16,  4.62it/s]Loading train:  72%|███████▏  | 192/266 [00:44<00:16,  4.59it/s]Loading train:  73%|███████▎  | 193/266 [00:44<00:15,  4.62it/s]Loading train:  73%|███████▎  | 194/266 [00:44<00:15,  4.61it/s]Loading train:  73%|███████▎  | 195/266 [00:44<00:16,  4.39it/s]Loading train:  74%|███████▎  | 196/266 [00:45<00:16,  4.23it/s]Loading train:  74%|███████▍  | 197/266 [00:45<00:16,  4.13it/s]Loading train:  74%|███████▍  | 198/266 [00:45<00:16,  4.08it/s]Loading train:  75%|███████▍  | 199/266 [00:45<00:16,  4.05it/s]Loading train:  75%|███████▌  | 200/266 [00:46<00:16,  4.02it/s]Loading train:  76%|███████▌  | 201/266 [00:46<00:16,  3.99it/s]Loading train:  76%|███████▌  | 202/266 [00:46<00:16,  3.90it/s]Loading train:  76%|███████▋  | 203/266 [00:47<00:15,  3.94it/s]Loading train:  77%|███████▋  | 204/266 [00:47<00:15,  3.93it/s]Loading train:  77%|███████▋  | 205/266 [00:47<00:15,  3.93it/s]Loading train:  77%|███████▋  | 206/266 [00:47<00:15,  3.91it/s]Loading train:  78%|███████▊  | 207/266 [00:48<00:15,  3.93it/s]Loading train:  78%|███████▊  | 208/266 [00:48<00:14,  3.90it/s]Loading train:  79%|███████▊  | 209/266 [00:48<00:14,  3.86it/s]Loading train:  79%|███████▉  | 210/266 [00:48<00:14,  3.87it/s]Loading train:  79%|███████▉  | 211/266 [00:49<00:14,  3.83it/s]Loading train:  80%|███████▉  | 212/266 [00:49<00:13,  3.86it/s]Loading train:  80%|████████  | 213/266 [00:49<00:13,  4.01it/s]Loading train:  80%|████████  | 214/266 [00:49<00:12,  4.11it/s]Loading train:  81%|████████  | 215/266 [00:50<00:12,  4.22it/s]Loading train:  81%|████████  | 216/266 [00:50<00:11,  4.28it/s]Loading train:  82%|████████▏ | 217/266 [00:50<00:11,  4.32it/s]Loading train:  82%|████████▏ | 218/266 [00:50<00:11,  4.35it/s]Loading train:  82%|████████▏ | 219/266 [00:50<00:10,  4.36it/s]Loading train:  83%|████████▎ | 220/266 [00:51<00:10,  4.34it/s]Loading train:  83%|████████▎ | 221/266 [00:51<00:10,  4.35it/s]Loading train:  83%|████████▎ | 222/266 [00:51<00:10,  4.36it/s]Loading train:  84%|████████▍ | 223/266 [00:51<00:09,  4.34it/s]Loading train:  84%|████████▍ | 224/266 [00:52<00:09,  4.37it/s]Loading train:  85%|████████▍ | 225/266 [00:52<00:09,  4.37it/s]Loading train:  85%|████████▍ | 226/266 [00:52<00:09,  4.33it/s]Loading train:  85%|████████▌ | 227/266 [00:52<00:09,  4.28it/s]Loading train:  86%|████████▌ | 228/266 [00:53<00:08,  4.23it/s]Loading train:  86%|████████▌ | 229/266 [00:53<00:08,  4.27it/s]Loading train:  86%|████████▋ | 230/266 [00:53<00:08,  4.29it/s]Loading train:  87%|████████▋ | 231/266 [00:53<00:07,  4.51it/s]Loading train:  87%|████████▋ | 232/266 [00:53<00:07,  4.70it/s]Loading train:  88%|████████▊ | 233/266 [00:54<00:06,  4.83it/s]Loading train:  88%|████████▊ | 234/266 [00:54<00:06,  4.94it/s]Loading train:  88%|████████▊ | 235/266 [00:54<00:06,  5.01it/s]Loading train:  89%|████████▊ | 236/266 [00:54<00:05,  5.04it/s]Loading train:  89%|████████▉ | 237/266 [00:54<00:05,  5.05it/s]Loading train:  89%|████████▉ | 238/266 [00:55<00:05,  5.06it/s]Loading train:  90%|████████▉ | 239/266 [00:55<00:05,  5.07it/s]Loading train:  90%|█████████ | 240/266 [00:55<00:05,  4.94it/s]Loading train:  91%|█████████ | 241/266 [00:55<00:04,  5.01it/s]Loading train:  91%|█████████ | 242/266 [00:55<00:04,  5.07it/s]Loading train:  91%|█████████▏| 243/266 [00:56<00:04,  5.10it/s]Loading train:  92%|█████████▏| 244/266 [00:56<00:04,  5.10it/s]Loading train:  92%|█████████▏| 245/266 [00:56<00:04,  5.15it/s]Loading train:  92%|█████████▏| 246/266 [00:56<00:03,  5.18it/s]Loading train:  93%|█████████▎| 247/266 [00:56<00:03,  5.19it/s]Loading train:  93%|█████████▎| 248/266 [00:56<00:03,  5.21it/s]Loading train:  94%|█████████▎| 249/266 [00:57<00:03,  4.99it/s]Loading train:  94%|█████████▍| 250/266 [00:57<00:03,  4.89it/s]Loading train:  94%|█████████▍| 251/266 [00:57<00:03,  4.79it/s]Loading train:  95%|█████████▍| 252/266 [00:57<00:02,  4.77it/s]Loading train:  95%|█████████▌| 253/266 [00:58<00:02,  4.72it/s]Loading train:  95%|█████████▌| 254/266 [00:58<00:02,  4.70it/s]Loading train:  96%|█████████▌| 255/266 [00:58<00:02,  4.69it/s]Loading train:  96%|█████████▌| 256/266 [00:58<00:02,  4.68it/s]Loading train:  97%|█████████▋| 257/266 [00:58<00:01,  4.67it/s]Loading train:  97%|█████████▋| 258/266 [00:59<00:01,  4.66it/s]Loading train:  97%|█████████▋| 259/266 [00:59<00:01,  4.67it/s]Loading train:  98%|█████████▊| 260/266 [00:59<00:01,  4.66it/s]Loading train:  98%|█████████▊| 261/266 [00:59<00:01,  4.67it/s]Loading train:  98%|█████████▊| 262/266 [00:59<00:00,  4.67it/s]Loading train:  99%|█████████▉| 263/266 [01:00<00:00,  4.67it/s]Loading train:  99%|█████████▉| 264/266 [01:00<00:00,  4.67it/s]Loading train: 100%|█████████▉| 265/266 [01:00<00:00,  4.69it/s]Loading train: 100%|██████████| 266/266 [01:00<00:00,  4.67it/s]Loading train: 100%|██████████| 266/266 [01:00<00:00,  4.37it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 55.38it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 55.40it/s]concatenating: train:   7%|▋         | 18/266 [00:00<00:04, 53.83it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:04, 55.12it/s]concatenating: train:  11%|█▏        | 30/266 [00:00<00:04, 55.73it/s]concatenating: train:  14%|█▎        | 36/266 [00:00<00:04, 56.29it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:03, 56.66it/s]concatenating: train:  18%|█▊        | 48/266 [00:00<00:03, 56.94it/s]concatenating: train:  20%|██        | 54/266 [00:00<00:03, 56.35it/s]concatenating: train:  23%|██▎       | 60/266 [00:01<00:03, 56.88it/s]concatenating: train:  25%|██▍       | 66/266 [00:01<00:03, 57.13it/s]concatenating: train:  27%|██▋       | 72/266 [00:01<00:03, 57.76it/s]concatenating: train:  29%|██▉       | 78/266 [00:01<00:03, 57.56it/s]concatenating: train:  32%|███▏      | 84/266 [00:01<00:03, 56.94it/s]concatenating: train:  34%|███▍      | 90/266 [00:01<00:03, 55.62it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 55.27it/s]concatenating: train:  38%|███▊      | 102/266 [00:01<00:03, 53.60it/s]concatenating: train:  41%|████      | 108/266 [00:01<00:02, 53.22it/s]concatenating: train:  43%|████▎     | 114/266 [00:02<00:02, 53.41it/s]concatenating: train:  45%|████▌     | 120/266 [00:02<00:02, 54.37it/s]concatenating: train:  48%|████▊     | 127/266 [00:02<00:02, 56.77it/s]concatenating: train:  50%|█████     | 134/266 [00:02<00:02, 58.75it/s]concatenating: train:  53%|█████▎    | 141/266 [00:02<00:02, 58.66it/s]concatenating: train:  56%|█████▌    | 148/266 [00:02<00:02, 58.79it/s]concatenating: train:  58%|█████▊    | 154/266 [00:02<00:01, 56.67it/s]concatenating: train:  60%|██████    | 160/266 [00:02<00:01, 54.26it/s]concatenating: train:  62%|██████▏   | 166/266 [00:02<00:01, 51.94it/s]concatenating: train:  65%|██████▍   | 172/266 [00:03<00:01, 51.19it/s]concatenating: train:  67%|██████▋   | 178/266 [00:03<00:01, 51.69it/s]concatenating: train:  69%|██████▉   | 184/266 [00:03<00:01, 51.35it/s]concatenating: train:  71%|███████▏  | 190/266 [00:03<00:01, 51.40it/s]concatenating: train:  74%|███████▎  | 196/266 [00:03<00:01, 51.52it/s]concatenating: train:  76%|███████▌  | 202/266 [00:03<00:01, 49.34it/s]concatenating: train:  78%|███████▊  | 207/266 [00:03<00:01, 48.37it/s]concatenating: train:  80%|███████▉  | 212/266 [00:03<00:01, 47.60it/s]concatenating: train:  82%|████████▏ | 218/266 [00:04<00:00, 48.86it/s]concatenating: train:  84%|████████▍ | 224/266 [00:04<00:00, 49.87it/s]concatenating: train:  86%|████████▋ | 230/266 [00:04<00:00, 50.94it/s]concatenating: train:  89%|████████▊ | 236/266 [00:04<00:00, 52.96it/s]concatenating: train:  91%|█████████▏| 243/266 [00:04<00:00, 55.18it/s]concatenating: train:  94%|█████████▍| 250/266 [00:04<00:00, 56.88it/s]concatenating: train:  96%|█████████▌| 256/266 [00:04<00:00, 56.57it/s]concatenating: train:  98%|█████████▊| 262/266 [00:04<00:00, 56.51it/s]concatenating: train: 100%|██████████| 266/266 [00:04<00:00, 54.51it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:00<00:00,  3.93it/s]Loading test:  50%|█████     | 2/4 [00:00<00:00,  4.09it/s]Loading test:  75%|███████▌  | 3/4 [00:00<00:00,  4.11it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.02it/s]Loading test: 100%|██████████| 4/4 [00:00<00:00,  4.08it/s]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 359.90it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<01:01,  4.32it/s]Loading trainS:   1%|          | 2/266 [00:00<01:01,  4.26it/s]Loading trainS:   1%|          | 3/266 [00:00<01:01,  4.26it/s]Loading trainS:   2%|▏         | 4/266 [00:00<01:02,  4.22it/s]Loading trainS:   2%|▏         | 5/266 [00:01<01:00,  4.30it/s]Loading trainS:   2%|▏         | 6/266 [00:01<01:01,  4.23it/s]Loading trainS:   3%|▎         | 7/266 [00:01<01:01,  4.23it/s]Loading trainS:   3%|▎         | 8/266 [00:01<01:00,  4.26it/s]Loading trainS:   3%|▎         | 9/266 [00:02<01:01,  4.15it/s]Loading trainS:   4%|▍         | 10/266 [00:02<01:01,  4.14it/s]Loading trainS:   4%|▍         | 11/266 [00:02<01:00,  4.22it/s]Loading trainS:   5%|▍         | 12/266 [00:02<01:01,  4.10it/s]Loading trainS:   5%|▍         | 13/266 [00:03<01:01,  4.13it/s]Loading trainS:   5%|▌         | 14/266 [00:03<01:05,  3.84it/s]Loading trainS:   6%|▌         | 15/266 [00:03<01:03,  3.94it/s]Loading trainS:   6%|▌         | 16/266 [00:03<01:02,  4.02it/s]Loading trainS:   6%|▋         | 17/266 [00:04<01:00,  4.12it/s]Loading trainS:   7%|▋         | 18/266 [00:04<00:58,  4.23it/s]Loading trainS:   7%|▋         | 19/266 [00:04<00:57,  4.28it/s]Loading trainS:   8%|▊         | 20/266 [00:04<00:56,  4.32it/s]Loading trainS:   8%|▊         | 21/266 [00:05<00:58,  4.16it/s]Loading trainS:   8%|▊         | 22/266 [00:05<00:58,  4.18it/s]Loading trainS:   9%|▊         | 23/266 [00:05<00:56,  4.28it/s]Loading trainS:   9%|▉         | 24/266 [00:05<00:55,  4.36it/s]Loading trainS:   9%|▉         | 25/266 [00:05<00:54,  4.38it/s]Loading trainS:  10%|▉         | 26/266 [00:06<00:54,  4.42it/s]Loading trainS:  10%|█         | 27/266 [00:06<00:53,  4.44it/s]Loading trainS:  11%|█         | 28/266 [00:06<00:53,  4.47it/s]Loading trainS:  11%|█         | 29/266 [00:06<00:53,  4.45it/s]Loading trainS:  11%|█▏        | 30/266 [00:07<00:54,  4.36it/s]Loading trainS:  12%|█▏        | 31/266 [00:07<00:53,  4.41it/s]Loading trainS:  12%|█▏        | 32/266 [00:07<00:52,  4.44it/s]Loading trainS:  12%|█▏        | 33/266 [00:07<00:51,  4.50it/s]Loading trainS:  13%|█▎        | 34/266 [00:07<00:51,  4.53it/s]Loading trainS:  13%|█▎        | 35/266 [00:08<00:51,  4.51it/s]Loading trainS:  14%|█▎        | 36/266 [00:08<00:50,  4.52it/s]Loading trainS:  14%|█▍        | 37/266 [00:08<00:53,  4.30it/s]Loading trainS:  14%|█▍        | 38/266 [00:08<00:52,  4.35it/s]Loading trainS:  15%|█▍        | 39/266 [00:09<00:52,  4.36it/s]Loading trainS:  15%|█▌        | 40/266 [00:09<00:51,  4.38it/s]Loading trainS:  15%|█▌        | 41/266 [00:09<00:51,  4.38it/s]Loading trainS:  16%|█▌        | 42/266 [00:09<00:51,  4.38it/s]Loading trainS:  16%|█▌        | 43/266 [00:10<00:52,  4.24it/s]Loading trainS:  17%|█▋        | 44/266 [00:10<00:51,  4.33it/s]Loading trainS:  17%|█▋        | 45/266 [00:10<00:51,  4.29it/s]Loading trainS:  17%|█▋        | 46/266 [00:10<00:51,  4.28it/s]Loading trainS:  18%|█▊        | 47/266 [00:10<00:50,  4.30it/s]Loading trainS:  18%|█▊        | 48/266 [00:11<00:54,  4.03it/s]Loading trainS:  18%|█▊        | 49/266 [00:11<00:52,  4.17it/s]Loading trainS:  19%|█▉        | 50/266 [00:11<00:50,  4.26it/s]Loading trainS:  19%|█▉        | 51/266 [00:11<00:49,  4.35it/s]Loading trainS:  20%|█▉        | 52/266 [00:12<00:48,  4.43it/s]Loading trainS:  20%|█▉        | 53/266 [00:12<00:47,  4.48it/s]Loading trainS:  20%|██        | 54/266 [00:12<00:46,  4.52it/s]Loading trainS:  21%|██        | 55/266 [00:12<00:46,  4.50it/s]Loading trainS:  21%|██        | 56/266 [00:13<00:46,  4.52it/s]Loading trainS:  21%|██▏       | 57/266 [00:13<00:45,  4.55it/s]Loading trainS:  22%|██▏       | 58/266 [00:13<00:45,  4.57it/s]Loading trainS:  22%|██▏       | 59/266 [00:13<00:46,  4.49it/s]Loading trainS:  23%|██▎       | 60/266 [00:13<00:46,  4.46it/s]Loading trainS:  23%|██▎       | 61/266 [00:14<00:46,  4.44it/s]Loading trainS:  23%|██▎       | 62/266 [00:14<00:45,  4.44it/s]Loading trainS:  24%|██▎       | 63/266 [00:14<00:45,  4.42it/s]Loading trainS:  24%|██▍       | 64/266 [00:14<00:46,  4.39it/s]Loading trainS:  24%|██▍       | 65/266 [00:15<00:45,  4.41it/s]Loading trainS:  25%|██▍       | 66/266 [00:15<00:45,  4.39it/s]Loading trainS:  25%|██▌       | 67/266 [00:15<00:45,  4.40it/s]Loading trainS:  26%|██▌       | 68/266 [00:15<00:44,  4.41it/s]Loading trainS:  26%|██▌       | 69/266 [00:15<00:44,  4.42it/s]Loading trainS:  26%|██▋       | 70/266 [00:16<00:44,  4.44it/s]Loading trainS:  27%|██▋       | 71/266 [00:16<00:44,  4.42it/s]Loading trainS:  27%|██▋       | 72/266 [00:16<00:44,  4.40it/s]Loading trainS:  27%|██▋       | 73/266 [00:16<00:44,  4.36it/s]Loading trainS:  28%|██▊       | 74/266 [00:17<00:44,  4.36it/s]Loading trainS:  28%|██▊       | 75/266 [00:17<00:43,  4.38it/s]Loading trainS:  29%|██▊       | 76/266 [00:17<00:43,  4.37it/s]Loading trainS:  29%|██▉       | 77/266 [00:17<00:48,  3.90it/s]Loading trainS:  29%|██▉       | 78/266 [00:18<00:49,  3.83it/s]Loading trainS:  30%|██▉       | 79/266 [00:18<00:46,  4.02it/s]Loading trainS:  30%|███       | 80/266 [00:18<00:45,  4.07it/s]Loading trainS:  30%|███       | 81/266 [00:18<00:47,  3.92it/s]Loading trainS:  31%|███       | 82/266 [00:19<00:47,  3.85it/s]Loading trainS:  31%|███       | 83/266 [00:19<00:48,  3.81it/s]Loading trainS:  32%|███▏      | 84/266 [00:19<00:47,  3.82it/s]Loading trainS:  32%|███▏      | 85/266 [00:19<00:47,  3.81it/s]Loading trainS:  32%|███▏      | 86/266 [00:20<00:47,  3.81it/s]Loading trainS:  33%|███▎      | 87/266 [00:20<00:47,  3.80it/s]Loading trainS:  33%|███▎      | 88/266 [00:20<00:46,  3.83it/s]Loading trainS:  33%|███▎      | 89/266 [00:20<00:46,  3.84it/s]Loading trainS:  34%|███▍      | 90/266 [00:21<00:45,  3.86it/s]Loading trainS:  34%|███▍      | 91/266 [00:21<00:45,  3.87it/s]Loading trainS:  35%|███▍      | 92/266 [00:21<00:44,  3.89it/s]Loading trainS:  35%|███▍      | 93/266 [00:22<00:44,  3.86it/s]Loading trainS:  35%|███▌      | 94/266 [00:22<00:44,  3.87it/s]Loading trainS:  36%|███▌      | 95/266 [00:22<00:44,  3.85it/s]Loading trainS:  36%|███▌      | 96/266 [00:22<00:44,  3.86it/s]Loading trainS:  36%|███▋      | 97/266 [00:23<00:43,  3.86it/s]Loading trainS:  37%|███▋      | 98/266 [00:23<00:45,  3.68it/s]Loading trainS:  37%|███▋      | 99/266 [00:23<00:44,  3.71it/s]Loading trainS:  38%|███▊      | 100/266 [00:23<00:43,  3.80it/s]Loading trainS:  38%|███▊      | 101/266 [00:24<00:42,  3.85it/s]Loading trainS:  38%|███▊      | 102/266 [00:24<00:42,  3.90it/s]Loading trainS:  39%|███▊      | 103/266 [00:24<00:41,  3.95it/s]Loading trainS:  39%|███▉      | 104/266 [00:24<00:40,  3.98it/s]Loading trainS:  39%|███▉      | 105/266 [00:25<00:40,  4.01it/s]Loading trainS:  40%|███▉      | 106/266 [00:25<00:39,  4.03it/s]Loading trainS:  40%|████      | 107/266 [00:25<00:39,  4.03it/s]Loading trainS:  41%|████      | 108/266 [00:25<00:38,  4.05it/s]Loading trainS:  41%|████      | 109/266 [00:26<00:38,  4.06it/s]Loading trainS:  41%|████▏     | 110/266 [00:26<00:38,  4.06it/s]Loading trainS:  42%|████▏     | 111/266 [00:26<00:38,  4.05it/s]Loading trainS:  42%|████▏     | 112/266 [00:26<00:38,  4.04it/s]Loading trainS:  42%|████▏     | 113/266 [00:27<00:38,  3.97it/s]Loading trainS:  43%|████▎     | 114/266 [00:27<00:38,  3.95it/s]Loading trainS:  43%|████▎     | 115/266 [00:27<00:38,  3.94it/s]Loading trainS:  44%|████▎     | 116/266 [00:27<00:38,  3.88it/s]Loading trainS:  44%|████▍     | 117/266 [00:28<00:38,  3.91it/s]Loading trainS:  44%|████▍     | 118/266 [00:28<00:35,  4.13it/s]Loading trainS:  45%|████▍     | 119/266 [00:28<00:34,  4.26it/s]Loading trainS:  45%|████▌     | 120/266 [00:28<00:33,  4.40it/s]Loading trainS:  45%|████▌     | 121/266 [00:28<00:32,  4.48it/s]Loading trainS:  46%|████▌     | 122/266 [00:29<00:32,  4.50it/s]Loading trainS:  46%|████▌     | 123/266 [00:29<00:31,  4.54it/s]Loading trainS:  47%|████▋     | 124/266 [00:29<00:32,  4.43it/s]Loading trainS:  47%|████▋     | 125/266 [00:29<00:31,  4.48it/s]Loading trainS:  47%|████▋     | 126/266 [00:30<00:30,  4.56it/s]Loading trainS:  48%|████▊     | 127/266 [00:30<00:30,  4.56it/s]Loading trainS:  48%|████▊     | 128/266 [00:30<00:30,  4.45it/s]Loading trainS:  48%|████▊     | 129/266 [00:30<00:30,  4.47it/s]Loading trainS:  49%|████▉     | 130/266 [00:30<00:29,  4.54it/s]Loading trainS:  49%|████▉     | 131/266 [00:31<00:29,  4.63it/s]Loading trainS:  50%|████▉     | 132/266 [00:31<00:28,  4.69it/s]Loading trainS:  50%|█████     | 133/266 [00:31<00:28,  4.60it/s]Loading trainS:  50%|█████     | 134/266 [00:31<00:28,  4.59it/s]Loading trainS:  51%|█████     | 135/266 [00:32<00:28,  4.55it/s]Loading trainS:  51%|█████     | 136/266 [00:32<00:28,  4.50it/s]Loading trainS:  52%|█████▏    | 137/266 [00:32<00:28,  4.48it/s]Loading trainS:  52%|█████▏    | 138/266 [00:32<00:29,  4.40it/s]Loading trainS:  52%|█████▏    | 139/266 [00:32<00:28,  4.43it/s]Loading trainS:  53%|█████▎    | 140/266 [00:33<00:28,  4.48it/s]Loading trainS:  53%|█████▎    | 141/266 [00:33<00:27,  4.53it/s]Loading trainS:  53%|█████▎    | 142/266 [00:33<00:27,  4.55it/s]Loading trainS:  54%|█████▍    | 143/266 [00:33<00:27,  4.47it/s]Loading trainS:  54%|█████▍    | 144/266 [00:34<00:27,  4.48it/s]Loading trainS:  55%|█████▍    | 145/266 [00:34<00:26,  4.48it/s]Loading trainS:  55%|█████▍    | 146/266 [00:34<00:26,  4.48it/s]Loading trainS:  55%|█████▌    | 147/266 [00:34<00:26,  4.50it/s]Loading trainS:  56%|█████▌    | 148/266 [00:34<00:26,  4.53it/s]Loading trainS:  56%|█████▌    | 149/266 [00:35<00:25,  4.54it/s]Loading trainS:  56%|█████▋    | 150/266 [00:35<00:25,  4.56it/s]Loading trainS:  57%|█████▋    | 151/266 [00:35<00:25,  4.55it/s]Loading trainS:  57%|█████▋    | 152/266 [00:35<00:24,  4.56it/s]Loading trainS:  58%|█████▊    | 153/266 [00:36<00:24,  4.59it/s]Loading trainS:  58%|█████▊    | 154/266 [00:36<00:25,  4.40it/s]Loading trainS:  58%|█████▊    | 155/266 [00:36<00:25,  4.28it/s]Loading trainS:  59%|█████▊    | 156/266 [00:36<00:26,  4.21it/s]Loading trainS:  59%|█████▉    | 157/266 [00:37<00:26,  4.15it/s]Loading trainS:  59%|█████▉    | 158/266 [00:37<00:26,  4.13it/s]Loading trainS:  60%|█████▉    | 159/266 [00:37<00:25,  4.12it/s]Loading trainS:  60%|██████    | 160/266 [00:37<00:25,  4.10it/s]Loading trainS:  61%|██████    | 161/266 [00:38<00:26,  4.01it/s]Loading trainS:  61%|██████    | 162/266 [00:38<00:25,  4.03it/s]Loading trainS:  61%|██████▏   | 163/266 [00:38<00:25,  4.05it/s]Loading trainS:  62%|██████▏   | 164/266 [00:38<00:25,  4.05it/s]Loading trainS:  62%|██████▏   | 165/266 [00:39<00:25,  4.03it/s]Loading trainS:  62%|██████▏   | 166/266 [00:39<00:24,  4.02it/s]Loading trainS:  63%|██████▎   | 167/266 [00:39<00:24,  4.02it/s]Loading trainS:  63%|██████▎   | 168/266 [00:39<00:24,  4.04it/s]Loading trainS:  64%|██████▎   | 169/266 [00:40<00:23,  4.07it/s]Loading trainS:  64%|██████▍   | 170/266 [00:40<00:23,  4.09it/s]Loading trainS:  64%|██████▍   | 171/266 [00:40<00:23,  4.07it/s]Loading trainS:  65%|██████▍   | 172/266 [00:40<00:22,  4.10it/s]Loading trainS:  65%|██████▌   | 173/266 [00:41<00:23,  3.98it/s]Loading trainS:  65%|██████▌   | 174/266 [00:41<00:22,  4.01it/s]Loading trainS:  66%|██████▌   | 175/266 [00:41<00:22,  4.12it/s]Loading trainS:  66%|██████▌   | 176/266 [00:41<00:21,  4.13it/s]Loading trainS:  67%|██████▋   | 177/266 [00:41<00:20,  4.27it/s]Loading trainS:  67%|██████▋   | 178/266 [00:42<00:20,  4.37it/s]Loading trainS:  67%|██████▋   | 179/266 [00:42<00:19,  4.45it/s]Loading trainS:  68%|██████▊   | 180/266 [00:42<00:19,  4.51it/s]Loading trainS:  68%|██████▊   | 181/266 [00:42<00:18,  4.52it/s]Loading trainS:  68%|██████▊   | 182/266 [00:43<00:18,  4.55it/s]Loading trainS:  69%|██████▉   | 183/266 [00:43<00:18,  4.54it/s]Loading trainS:  69%|██████▉   | 184/266 [00:43<00:17,  4.58it/s]Loading trainS:  70%|██████▉   | 185/266 [00:43<00:17,  4.62it/s]Loading trainS:  70%|██████▉   | 186/266 [00:43<00:17,  4.62it/s]Loading trainS:  70%|███████   | 187/266 [00:44<00:17,  4.64it/s]Loading trainS:  71%|███████   | 188/266 [00:44<00:16,  4.61it/s]Loading trainS:  71%|███████   | 189/266 [00:44<00:16,  4.63it/s]Loading trainS:  71%|███████▏  | 190/266 [00:44<00:16,  4.64it/s]Loading trainS:  72%|███████▏  | 191/266 [00:44<00:16,  4.66it/s]Loading trainS:  72%|███████▏  | 192/266 [00:45<00:15,  4.64it/s]Loading trainS:  73%|███████▎  | 193/266 [00:45<00:15,  4.65it/s]Loading trainS:  73%|███████▎  | 194/266 [00:45<00:15,  4.62it/s]Loading trainS:  73%|███████▎  | 195/266 [00:45<00:16,  4.38it/s]Loading trainS:  74%|███████▎  | 196/266 [00:46<00:16,  4.22it/s]Loading trainS:  74%|███████▍  | 197/266 [00:46<00:16,  4.13it/s]Loading trainS:  74%|███████▍  | 198/266 [00:46<00:16,  4.04it/s]Loading trainS:  75%|███████▍  | 199/266 [00:46<00:16,  4.02it/s]Loading trainS:  75%|███████▌  | 200/266 [00:47<00:16,  3.96it/s]Loading trainS:  76%|███████▌  | 201/266 [00:47<00:16,  3.91it/s]Loading trainS:  76%|███████▌  | 202/266 [00:47<00:16,  3.90it/s]Loading trainS:  76%|███████▋  | 203/266 [00:47<00:16,  3.90it/s]Loading trainS:  77%|███████▋  | 204/266 [00:48<00:15,  3.90it/s]Loading trainS:  77%|███████▋  | 205/266 [00:48<00:15,  3.90it/s]Loading trainS:  77%|███████▋  | 206/266 [00:48<00:15,  3.88it/s]Loading trainS:  78%|███████▊  | 207/266 [00:48<00:15,  3.87it/s]Loading trainS:  78%|███████▊  | 208/266 [00:49<00:15,  3.85it/s]Loading trainS:  79%|███████▊  | 209/266 [00:49<00:14,  3.86it/s]Loading trainS:  79%|███████▉  | 210/266 [00:49<00:14,  3.89it/s]Loading trainS:  79%|███████▉  | 211/266 [00:49<00:14,  3.84it/s]Loading trainS:  80%|███████▉  | 212/266 [00:50<00:13,  3.87it/s]Loading trainS:  80%|████████  | 213/266 [00:50<00:13,  4.01it/s]Loading trainS:  80%|████████  | 214/266 [00:50<00:12,  4.13it/s]Loading trainS:  81%|████████  | 215/266 [00:50<00:12,  4.12it/s]Loading trainS:  81%|████████  | 216/266 [00:51<00:11,  4.20it/s]Loading trainS:  82%|████████▏ | 217/266 [00:51<00:11,  4.23it/s]Loading trainS:  82%|████████▏ | 218/266 [00:51<00:11,  4.26it/s]Loading trainS:  82%|████████▏ | 219/266 [00:51<00:10,  4.29it/s]Loading trainS:  83%|████████▎ | 220/266 [00:52<00:10,  4.31it/s]Loading trainS:  83%|████████▎ | 221/266 [00:52<00:10,  4.34it/s]Loading trainS:  83%|████████▎ | 222/266 [00:52<00:10,  4.35it/s]Loading trainS:  84%|████████▍ | 223/266 [00:52<00:09,  4.34it/s]Loading trainS:  84%|████████▍ | 224/266 [00:53<00:09,  4.34it/s]Loading trainS:  85%|████████▍ | 225/266 [00:53<00:09,  4.29it/s]Loading trainS:  85%|████████▍ | 226/266 [00:53<00:09,  4.32it/s]Loading trainS:  85%|████████▌ | 227/266 [00:53<00:09,  4.32it/s]Loading trainS:  86%|████████▌ | 228/266 [00:53<00:08,  4.33it/s]Loading trainS:  86%|████████▌ | 229/266 [00:54<00:08,  4.31it/s]Loading trainS:  86%|████████▋ | 230/266 [00:54<00:08,  4.30it/s]Loading trainS:  87%|████████▋ | 231/266 [00:54<00:07,  4.52it/s]Loading trainS:  87%|████████▋ | 232/266 [00:54<00:07,  4.69it/s]Loading trainS:  88%|████████▊ | 233/266 [00:54<00:06,  4.84it/s]Loading trainS:  88%|████████▊ | 234/266 [00:55<00:06,  4.94it/s]Loading trainS:  88%|████████▊ | 235/266 [00:55<00:06,  4.97it/s]Loading trainS:  89%|████████▊ | 236/266 [00:55<00:06,  5.00it/s]Loading trainS:  89%|████████▉ | 237/266 [00:55<00:05,  5.06it/s]Loading trainS:  89%|████████▉ | 238/266 [00:55<00:05,  5.11it/s]Loading trainS:  90%|████████▉ | 239/266 [00:56<00:05,  5.13it/s]Loading trainS:  90%|█████████ | 240/266 [00:56<00:05,  5.14it/s]Loading trainS:  91%|█████████ | 241/266 [00:56<00:04,  5.16it/s]Loading trainS:  91%|█████████ | 242/266 [00:56<00:04,  5.17it/s]Loading trainS:  91%|█████████▏| 243/266 [00:56<00:04,  5.18it/s]Loading trainS:  92%|█████████▏| 244/266 [00:57<00:04,  5.18it/s]Loading trainS:  92%|█████████▏| 245/266 [00:57<00:04,  5.18it/s]Loading trainS:  92%|█████████▏| 246/266 [00:57<00:03,  5.08it/s]Loading trainS:  93%|█████████▎| 247/266 [00:57<00:03,  5.09it/s]Loading trainS:  93%|█████████▎| 248/266 [00:57<00:03,  5.10it/s]Loading trainS:  94%|█████████▎| 249/266 [00:58<00:03,  4.94it/s]Loading trainS:  94%|█████████▍| 250/266 [00:58<00:03,  4.86it/s]Loading trainS:  94%|█████████▍| 251/266 [00:58<00:03,  4.79it/s]Loading trainS:  95%|█████████▍| 252/266 [00:58<00:02,  4.72it/s]Loading trainS:  95%|█████████▌| 253/266 [00:58<00:02,  4.69it/s]Loading trainS:  95%|█████████▌| 254/266 [00:59<00:02,  4.63it/s]Loading trainS:  96%|█████████▌| 255/266 [00:59<00:02,  4.60it/s]Loading trainS:  96%|█████████▌| 256/266 [00:59<00:02,  4.59it/s]Loading trainS:  97%|█████████▋| 257/266 [00:59<00:01,  4.56it/s]Loading trainS:  97%|█████████▋| 258/266 [01:00<00:01,  4.57it/s]Loading trainS:  97%|█████████▋| 259/266 [01:00<00:01,  4.60it/s]Loading trainS:  98%|█████████▊| 260/266 [01:00<00:01,  4.62it/s]Loading trainS:  98%|█████████▊| 261/266 [01:00<00:01,  4.63it/s]Loading trainS:  98%|█████████▊| 262/266 [01:00<00:00,  4.64it/s]Loading trainS:  99%|█████████▉| 263/266 [01:01<00:00,  4.62it/s]Loading trainS:  99%|█████████▉| 264/266 [01:01<00:00,  4.60it/s]Loading trainS: 100%|█████████▉| 265/266 [01:01<00:00,  4.61it/s]Loading trainS: 100%|██████████| 266/266 [01:01<00:00,  4.63it/s]Loading trainS: 100%|██████████| 266/266 [01:01<00:00,  4.30it/s]
Loading testS:   0%|          | 0/4 [00:00<?, ?it/s]Loading testS:  25%|██▌       | 1/4 [00:00<00:00,  4.25it/s]Loading testS:  50%|█████     | 2/4 [00:00<00:00,  4.34it/s]Loading testS:  75%|███████▌  | 3/4 [00:00<00:00,  4.33it/s]Loading testS: 100%|██████████| 4/4 [00:00<00:00,  4.17it/s]Loading testS: 100%|██████████| 4/4 [00:00<00:00,  4.22it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               2020-01-22 08:42:44.476378: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 08:42:44.476474: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 08:42:44.476489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 08:42:44.476498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 08:42:44.476780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 222,362
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97410792 0.02589208]
Train on 17233 samples, validate on 255 samples
Epoch 1/300
 - 48s - loss: 0.1372 - acc: 0.9839 - mDice: 0.7367 - val_loss: 0.2847 - val_acc: 0.9887 - val_mDice: 0.4367

Epoch 00001: val_mDice improved from -inf to 0.43670, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 2/300
 - 45s - loss: 0.0854 - acc: 0.9915 - mDice: 0.8339 - val_loss: 0.2819 - val_acc: 0.9906 - val_mDice: 0.4411

Epoch 00002: val_mDice improved from 0.43670 to 0.44114, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 3/300
 - 44s - loss: 0.0765 - acc: 0.9924 - mDice: 0.8510 - val_loss: 0.2853 - val_acc: 0.9899 - val_mDice: 0.4346

Epoch 00003: val_mDice did not improve from 0.44114
Epoch 4/300
 - 44s - loss: 0.0698 - acc: 0.9930 - mDice: 0.8640 - val_loss: 0.2636 - val_acc: 0.9927 - val_mDice: 0.4522

Epoch 00004: val_mDice improved from 0.44114 to 0.45217, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 5/300
 - 44s - loss: 0.0679 - acc: 0.9932 - mDice: 0.8677 - val_loss: 0.2825 - val_acc: 0.9925 - val_mDice: 0.4386

Epoch 00005: val_mDice did not improve from 0.45217
Epoch 6/300
 - 44s - loss: 0.0633 - acc: 0.9936 - mDice: 0.8768 - val_loss: 0.2282 - val_acc: 0.9926 - val_mDice: 0.4597

Epoch 00006: val_mDice improved from 0.45217 to 0.45968, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 7/300
 - 45s - loss: 0.0601 - acc: 0.9938 - mDice: 0.8830 - val_loss: 0.0734 - val_acc: 0.9925 - val_mDice: 0.4690

Epoch 00007: val_mDice improved from 0.45968 to 0.46898, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 8/300
 - 45s - loss: 0.0596 - acc: 0.9939 - mDice: 0.8839 - val_loss: 0.2713 - val_acc: 0.9917 - val_mDice: 0.4616

Epoch 00008: val_mDice did not improve from 0.46898
Epoch 9/300
 - 45s - loss: 0.0577 - acc: 0.9941 - mDice: 0.8876 - val_loss: 0.1754 - val_acc: 0.9923 - val_mDice: 0.4721

Epoch 00009: val_mDice improved from 0.46898 to 0.47212, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 10/300
 - 46s - loss: 0.0564 - acc: 0.9942 - mDice: 0.8901 - val_loss: 0.2514 - val_acc: 0.9928 - val_mDice: 0.4802

Epoch 00010: val_mDice improved from 0.47212 to 0.48016, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 11/300
 - 46s - loss: 0.0548 - acc: 0.9944 - mDice: 0.8932 - val_loss: 0.1648 - val_acc: 0.9895 - val_mDice: 0.4409

Epoch 00011: val_mDice did not improve from 0.48016
Epoch 12/300
 - 46s - loss: 0.0521 - acc: 0.9945 - mDice: 0.8986 - val_loss: 0.2067 - val_acc: 0.9881 - val_mDice: 0.4367

Epoch 00012: val_mDice did not improve from 0.48016
Epoch 13/300
 - 45s - loss: 0.0521 - acc: 0.9945 - mDice: 0.8985 - val_loss: 0.1517 - val_acc: 0.9923 - val_mDice: 0.4703

Epoch 00013: val_mDice did not improve from 0.48016
Epoch 14/300
 - 45s - loss: 0.0504 - acc: 0.9947 - mDice: 0.9019 - val_loss: 0.0850 - val_acc: 0.9917 - val_mDice: 0.4432

Epoch 00014: val_mDice did not improve from 0.48016
Epoch 15/300
 - 45s - loss: 0.0508 - acc: 0.9947 - mDice: 0.9010 - val_loss: 0.0883 - val_acc: 0.9922 - val_mDice: 0.4439

Epoch 00015: val_mDice did not improve from 0.48016
Epoch 16/300
 - 45s - loss: 0.0489 - acc: 0.9948 - mDice: 0.9048 - val_loss: 0.1862 - val_acc: 0.9926 - val_mDice: 0.4747

Epoch 00016: val_mDice did not improve from 0.48016
Epoch 17/300
 - 45s - loss: 0.0485 - acc: 0.9948 - mDice: 0.9056 - val_loss: 0.1456 - val_acc: 0.9930 - val_mDice: 0.4772

Epoch 00017: val_mDice did not improve from 0.48016
Epoch 18/300
 - 46s - loss: 0.0492 - acc: 0.9949 - mDice: 0.9042 - val_loss: 0.1363 - val_acc: 0.9926 - val_mDice: 0.4569

Epoch 00018: val_mDice did not improve from 0.48016
Epoch 19/300
 - 45s - loss: 0.0472 - acc: 0.9950 - mDice: 0.9082 - val_loss: 0.0452 - val_acc: 0.9933 - val_mDice: 0.4817

Epoch 00019: val_mDice improved from 0.48016 to 0.48170, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 20/300
 - 46s - loss: 0.0472 - acc: 0.9950 - mDice: 0.9080 - val_loss: 0.0660 - val_acc: 0.9928 - val_mDice: 0.4798

Epoch 00020: val_mDice did not improve from 0.48170
Epoch 21/300
 - 45s - loss: 0.0464 - acc: 0.9950 - mDice: 0.9097 - val_loss: 0.1721 - val_acc: 0.9924 - val_mDice: 0.4637

Epoch 00021: val_mDice did not improve from 0.48170
Epoch 22/300
 - 46s - loss: 0.0463 - acc: 0.9950 - mDice: 0.9100 - val_loss: 0.0864 - val_acc: 0.9932 - val_mDice: 0.4779

Epoch 00022: val_mDice did not improve from 0.48170
Epoch 23/300
 - 46s - loss: 0.0473 - acc: 0.9950 - mDice: 0.9078 - val_loss: 0.1057 - val_acc: 0.9930 - val_mDice: 0.4785

Epoch 00023: val_mDice did not improve from 0.48170
Epoch 24/300
 - 46s - loss: 0.0461 - acc: 0.9951 - mDice: 0.9102 - val_loss: 0.0890 - val_acc: 0.9935 - val_mDice: 0.4821

Epoch 00024: val_mDice improved from 0.48170 to 0.48214, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 25/300
 - 46s - loss: 0.0445 - acc: 0.9952 - mDice: 0.9134 - val_loss: 0.0496 - val_acc: 0.9931 - val_mDice: 0.4729

Epoch 00025: val_mDice did not improve from 0.48214
Epoch 26/300
 - 45s - loss: 0.0442 - acc: 0.9953 - mDice: 0.9140 - val_loss: 0.0478 - val_acc: 0.9931 - val_mDice: 0.4766

Epoch 00026: val_mDice did not improve from 0.48214
Epoch 27/300
 - 45s - loss: 0.0443 - acc: 0.9952 - mDice: 0.9137 - val_loss: 0.1246 - val_acc: 0.9934 - val_mDice: 0.4804

Epoch 00027: val_mDice did not improve from 0.48214
Epoch 28/300
 - 45s - loss: 0.0433 - acc: 0.9953 - mDice: 0.9158 - val_loss: -6.5979e-02 - val_acc: 0.9926 - val_mDice: 0.4691

Epoch 00028: val_mDice did not improve from 0.48214
Epoch 29/300
 - 45s - loss: 0.0432 - acc: 0.9953 - mDice: 0.9159 - val_loss: 0.0677 - val_acc: 0.9930 - val_mDice: 0.4762

Epoch 00029: val_mDice did not improve from 0.48214
Epoch 30/300
 - 46s - loss: 0.0437 - acc: 0.9953 - mDice: 0.9150 - val_loss: 0.1194 - val_acc: 0.9939 - val_mDice: 0.4900

Epoch 00030: val_mDice improved from 0.48214 to 0.48998, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 31/300
 - 45s - loss: 0.0434 - acc: 0.9953 - mDice: 0.9155 - val_loss: 0.0870 - val_acc: 0.9931 - val_mDice: 0.4766

Epoch 00031: val_mDice did not improve from 0.48998
Epoch 32/300
 - 45s - loss: 0.0433 - acc: 0.9953 - mDice: 0.9157 - val_loss: -3.1797e-02 - val_acc: 0.9935 - val_mDice: 0.4787

Epoch 00032: val_mDice did not improve from 0.48998
Epoch 33/300
 - 45s - loss: 0.0431 - acc: 0.9954 - mDice: 0.9160 - val_loss: 0.0801 - val_acc: 0.9934 - val_mDice: 0.4903

Epoch 00033: val_mDice improved from 0.48998 to 0.49034, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 34/300
 - 45s - loss: 0.0419 - acc: 0.9954 - mDice: 0.9185 - val_loss: 0.0446 - val_acc: 0.9932 - val_mDice: 0.4829

Epoch 00034: val_mDice did not improve from 0.49034
Epoch 35/300
 - 45s - loss: 0.0415 - acc: 0.9954 - mDice: 0.9192 - val_loss: 0.0138 - val_acc: 0.9924 - val_mDice: 0.4702

Epoch 00035: val_mDice did not improve from 0.49034
Epoch 36/300
 - 46s - loss: 0.0433 - acc: 0.9954 - mDice: 0.9157 - val_loss: 0.1244 - val_acc: 0.9928 - val_mDice: 0.4806

Epoch 00036: val_mDice did not improve from 0.49034
Epoch 37/300
 - 45s - loss: 0.0422 - acc: 0.9954 - mDice: 0.9179 - val_loss: 0.0815 - val_acc: 0.9933 - val_mDice: 0.4877

Epoch 00037: val_mDice did not improve from 0.49034
Epoch 38/300
 - 46s - loss: 0.0419 - acc: 0.9955 - mDice: 0.9185 - val_loss: 0.0724 - val_acc: 0.9933 - val_mDice: 0.4982

Epoch 00038: val_mDice improved from 0.49034 to 0.49822, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/1-THALAMUS/sd2/best_model_weights.h5
Epoch 39/300
 - 45s - loss: 0.0408 - acc: 0.9955 - mDice: 0.9207 - val_loss: -4.0902e-02 - val_acc: 0.9891 - val_mDice: 0.4206

Epoch 00039: val_mDice did not improve from 0.49822
Epoch 40/300
 - 46s - loss: 0.0411 - acc: 0.9955 - mDice: 0.9200 - val_loss: 0.0752 - val_acc: 0.9924 - val_mDice: 0.4617

Epoch 00040: val_mDice did not improve from 0.49822
Epoch 41/300
 - 45s - loss: 0.0405 - acc: 0.9955 - mDice: 0.9212 - val_loss: 0.0450 - val_acc: 0.9933 - val_mDice: 0.4822

Epoch 00041: val_mDice did not improve from 0.49822
Epoch 42/300
 - 45s - loss: 0.0413 - acc: 0.9955 - mDice: 0.9197 - val_loss: 0.0836 - val_acc: 0.9935 - val_mDice: 0.4833

Epoch 00042: val_mDice did not improve from 0.49822
Epoch 43/300
 - 45s - loss: 0.0412 - acc: 0.9955 - mDice: 0.9198 - val_loss: 0.0049 - val_acc: 0.9939 - val_mDice: 0.4837

Epoch 00043: val_mDice did not improve from 0.49822
Epoch 44/300
 - 45s - loss: 0.0399 - acc: 0.9956 - mDice: 0.9224 - val_loss: 0.0810 - val_acc: 0.9929 - val_mDice: 0.4883

Epoch 00044: val_mDice did not improve from 0.49822
Epoch 45/300
 - 45s - loss: 0.0418 - acc: 0.9956 - mDice: 0.9186 - val_loss: 0.0676 - val_acc: 0.9930 - val_mDice: 0.4762

Epoch 00045: val_mDice did not improve from 0.49822
Epoch 46/300
 - 45s - loss: 0.0399 - acc: 0.9956 - mDice: 0.9224 - val_loss: 0.1035 - val_acc: 0.9928 - val_mDice: 0.4830

Epoch 00046: val_mDice did not improve from 0.49822
Epoch 47/300
 - 45s - loss: 0.0393 - acc: 0.9956 - mDice: 0.9235 - val_loss: -4.0600e-02 - val_acc: 0.9942 - val_mDice: 0.4961

Epoch 00047: val_mDice did not improve from 0.49822
Epoch 48/300
 - 45s - loss: 0.0407 - acc: 0.9956 - mDice: 0.9208 - val_loss: 0.0405 - val_acc: 0.9935 - val_mDice: 0.4912

Epoch 00048: val_mDice did not improve from 0.49822
Epoch 49/300
 - 45s - loss: 0.0400 - acc: 0.9956 - mDice: 0.9221 - val_loss: -3.0453e-02 - val_acc: 0.9933 - val_mDice: 0.4761

Epoch 00049: val_mDice did not improve from 0.49822
Epoch 50/300
 - 46s - loss: 0.0392 - acc: 0.9957 - mDice: 0.9238 - val_loss: 0.1396 - val_acc: 0.9936 - val_mDice: 0.4889

Epoch 00050: val_mDice did not improve from 0.49822
Epoch 51/300
 - 45s - loss: 0.0391 - acc: 0.9956 - mDice: 0.9240 - val_loss: 0.0959 - val_acc: 0.9929 - val_mDice: 0.4744

Epoch 00051: val_mDice did not improve from 0.49822
Epoch 52/300
 - 45s - loss: 0.0400 - acc: 0.9956 - mDice: 0.9221 - val_loss: 0.0723 - val_acc: 0.9926 - val_mDice: 0.4723

Epoch 00052: val_mDice did not improve from 0.49822
Epoch 53/300
 - 45s - loss: 0.0384 - acc: 0.9957 - mDice: 0.9253 - val_loss: -3.5108e-02 - val_acc: 0.9936 - val_mDice: 0.4854

Epoch 00053: val_mDice did not improve from 0.49822

Epoch 00053: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 54/300
 - 45s - loss: 0.0372 - acc: 0.9958 - mDice: 0.9276 - val_loss: 0.2174 - val_acc: 0.9870 - val_mDice: 0.4156

Epoch 00054: val_mDice did not improve from 0.49822
Epoch 55/300
 - 45s - loss: 0.0387 - acc: 0.9958 - mDice: 0.9246 - val_loss: -3.6522e-02 - val_acc: 0.9936 - val_mDice: 0.4882

Epoch 00055: val_mDice did not improve from 0.49822
Epoch 56/300
 - 45s - loss: 0.0367 - acc: 0.9959 - mDice: 0.9286 - val_loss: -3.4766e-02 - val_acc: 0.9936 - val_mDice: 0.4847

Epoch 00056: val_mDice did not improve from 0.49822
Epoch 57/300
 - 45s - loss: 0.0364 - acc: 0.9959 - mDice: 0.9292 - val_loss: 0.0267 - val_acc: 0.9930 - val_mDice: 0.4799

Epoch 00057: val_mDice did not improve from 0.49822
Epoch 58/300
 - 45s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9299 - val_loss: -3.3944e-02 - val_acc: 0.9939 - val_mDice: 0.4828

Epoch 00058: val_mDice did not improve from 0.49822
Epoch 59/300
 - 45s - loss: 0.0363 - acc: 0.9959 - mDice: 0.9295 - val_loss: -3.5294e-02 - val_acc: 0.9934 - val_mDice: 0.4863

Epoch 00059: val_mDice did not improve from 0.49822
Epoch 60/300
 - 45s - loss: 0.0366 - acc: 0.9959 - mDice: 0.9289 - val_loss: 0.0830 - val_acc: 0.9937 - val_mDice: 0.4843

Epoch 00060: val_mDice did not improve from 0.49822
Epoch 61/300
 - 45s - loss: 0.0361 - acc: 0.9959 - mDice: 0.9299 - val_loss: 0.0245 - val_acc: 0.9931 - val_mDice: 0.4841

Epoch 00061: val_mDice did not improve from 0.49822
Epoch 62/300
 - 45s - loss: 0.0355 - acc: 0.9959 - mDice: 0.9310 - val_loss: -3.3417e-02 - val_acc: 0.9937 - val_mDice: 0.4819

Epoch 00062: val_mDice did not improve from 0.49822
Epoch 63/300
 - 45s - loss: 0.0354 - acc: 0.9959 - mDice: 0.9312 - val_loss: 0.1241 - val_acc: 0.9934 - val_mDice: 0.4808

Epoch 00063: val_mDice did not improve from 0.49822
Epoch 64/300
 - 46s - loss: 0.0362 - acc: 0.9960 - mDice: 0.9295 - val_loss: 0.0020 - val_acc: 0.9933 - val_mDice: 0.4898

Epoch 00064: val_mDice did not improve from 0.49822
Epoch 65/300
 - 44s - loss: 0.0363 - acc: 0.9959 - mDice: 0.9294 - val_loss: 0.0062 - val_acc: 0.9936 - val_mDice: 0.4810

Epoch 00065: val_mDice did not improve from 0.49822
Epoch 66/300
 - 45s - loss: 0.0348 - acc: 0.9960 - mDice: 0.9324 - val_loss: 0.1114 - val_acc: 0.9924 - val_mDice: 0.4676

Epoch 00066: val_mDice did not improve from 0.49822
Epoch 67/300
 - 45s - loss: 0.0357 - acc: 0.9960 - mDice: 0.9305 - val_loss: 0.0607 - val_acc: 0.9934 - val_mDice: 0.4900

Epoch 00067: val_mDice did not improve from 0.49822
Epoch 68/300
 - 45s - loss: 0.0357 - acc: 0.9959 - mDice: 0.9307 - val_loss: -3.1872e-02 - val_acc: 0.9935 - val_mDice: 0.4788

Epoch 00068: val_mDice did not improve from 0.49822

Epoch 00068: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 69/300
 - 45s - loss: 0.0354 - acc: 0.9960 - mDice: 0.9312 - val_loss: -1.3017e-02 - val_acc: 0.9933 - val_mDice: 0.4805

Epoch 00069: val_mDice did not improve from 0.49822
Epoch 70/300
 - 45s - loss: 0.0344 - acc: 0.9961 - mDice: 0.9331 - val_loss: -3.3868e-02 - val_acc: 0.9936 - val_mDice: 0.4829

Epoch 00070: val_mDice did not improve from 0.49822
Epoch 71/300
 - 46s - loss: 0.0354 - acc: 0.9961 - mDice: 0.9310 - val_loss: 0.0057 - val_acc: 0.9935 - val_mDice: 0.4821

Epoch 00071: val_mDice did not improve from 0.49822
Epoch 72/300
 - 46s - loss: 0.0347 - acc: 0.9961 - mDice: 0.9325 - val_loss: -3.3631e-02 - val_acc: 0.9936 - val_mDice: 0.4824

Epoch 00072: val_mDice did not improve from 0.49822
Epoch 73/300
 - 46s - loss: 0.0344 - acc: 0.9961 - mDice: 0.9332 - val_loss: 0.0057 - val_acc: 0.9934 - val_mDice: 0.4822

Epoch 00073: val_mDice did not improve from 0.49822
Epoch 74/300
 - 46s - loss: 0.0352 - acc: 0.9961 - mDice: 0.9315 - val_loss: 0.0068 - val_acc: 0.9933 - val_mDice: 0.4801

Epoch 00074: val_mDice did not improve from 0.49822
Epoch 75/300
 - 46s - loss: 0.0336 - acc: 0.9961 - mDice: 0.9346 - val_loss: 0.0044 - val_acc: 0.9932 - val_mDice: 0.4849

Epoch 00075: val_mDice did not improve from 0.49822
Epoch 76/300
 - 46s - loss: 0.0337 - acc: 0.9961 - mDice: 0.9346 - val_loss: 0.0057 - val_acc: 0.9934 - val_mDice: 0.4822

Epoch 00076: val_mDice did not improve from 0.49822
Epoch 77/300
 - 46s - loss: 0.0341 - acc: 0.9961 - mDice: 0.9337 - val_loss: -3.3958e-02 - val_acc: 0.9936 - val_mDice: 0.4830

Epoch 00077: val_mDice did not improve from 0.49822
Epoch 78/300
 - 47s - loss: 0.0333 - acc: 0.9961 - mDice: 0.9352 - val_loss: 0.0036 - val_acc: 0.9933 - val_mDice: 0.4865

Epoch 00078: val_mDice did not improve from 0.49822
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
{'val_loss': [0.2846563879181357, 0.281923490412095, 0.2853436993033278, 0.26363469572628245, 0.2824946568877089, 0.22815159459908804, 0.07335820998631272, 0.27134740907771915, 0.1753664551412358, 0.2514153829976624, 0.16482404867808023, 0.20672254235136742, 0.15168080610387466, 0.08501401748142991, 0.08832006273316402, 0.1862158544507681, 0.14564109929636412, 0.1362647344084347, 0.04519061481251436, 0.06600963952494603, 0.17214917990506864, 0.08636258484101762, 0.1057412045843461, 0.08904942285780813, 0.04964008722819534, 0.047831377562354595, 0.12460291794702119, -0.06597906234217625, 0.0676822656509923, 0.11938670686647004, 0.08697988940220253, -0.03179673061651342, 0.08007344983372033, 0.04464671074175367, 0.013831245840764513, 0.12437926320468679, 0.08147675646286384, 0.07238541514265771, -0.040902248784607534, 0.07516666896202985, 0.04499841525274165, 0.08360564708709717, 0.004881671830719593, 0.08096318502052158, 0.06759783158115312, 0.10354891477846632, -0.040600339571634926, 0.04045781551622877, -0.030452852740007287, 0.13963199567561055, 0.0959230933119269, 0.07228160225877575, -0.03510815635615704, 0.21738055494486117, -0.036521537631165744, -0.034765595606729094, 0.026687575905930763, -0.03394418136746276, -0.03529439749670964, 0.08299578054278504, 0.02447431782881419, -0.03341657157037772, 0.124103195234841, 0.001993288888650782, 0.006245606085833381, 0.11144521394196678, 0.06072993810270347, -0.031872075854563246, -0.013017355811362173, -0.033867782237483005, 0.005733698606491089, -0.0336311845218434, 0.005708755523550744, 0.0068397007736505245, 0.00443286726287767, 0.0057330949633729224, -0.03395756202585557, 0.0036424784099354465], 'val_acc': [0.9887089028077967, 0.9905958093848883, 0.9899115398818371, 0.9926758595541412, 0.992522162549636, 0.9926458036198336, 0.9924742731393552, 0.9917048566481647, 0.9922570340773639, 0.9928483285155951, 0.9894911471535178, 0.9880603154500326, 0.9923277707660899, 0.9916851391979292, 0.9921756421818453, 0.9926141909524506, 0.9929719777668223, 0.9926276487462661, 0.9933404081008014, 0.9927897944169886, 0.9923828676635144, 0.9932305368722654, 0.9929938900704477, 0.9935401163849176, 0.9930937453812244, 0.9931247351216335, 0.9934145983527688, 0.9925569062139473, 0.992952890255872, 0.9939132391237745, 0.9930630618450689, 0.9935207063076543, 0.9933745253319833, 0.9931948535582599, 0.9923982059254366, 0.9928448901456945, 0.9933466654197842, 0.9932593317592845, 0.9891048786686916, 0.992363455248814, 0.9933300766290403, 0.9935473227033428, 0.9938625284269744, 0.9928833877339083, 0.9929654013876822, 0.9927647522851533, 0.9941539577409333, 0.9935379262064018, 0.9933087919272628, 0.993550764579399, 0.9928652433788075, 0.9926307750683204, 0.9935573269339169, 0.9870370345957139, 0.9935620298572615, 0.9936074182098987, 0.9930217476452098, 0.9939357813666848, 0.9934424559275309, 0.9937100877948836, 0.9931003182542091, 0.9936662678625069, 0.9933814090840957, 0.9933460436615289, 0.9935930242725447, 0.9923521899709514, 0.9933538682320538, 0.993491906745761, 0.993336651839462, 0.9935942748013664, 0.9935291654923383, 0.9935898897694606, 0.9934145960153318, 0.9932818716647578, 0.9932380470575071, 0.9934186654932359, 0.9936171209110933, 0.9933341507818184], 'val_mDice': [0.4366960581033378, 0.4411417912741951, 0.43463556333354014, 0.4521717510971671, 0.4386222282168912, 0.459681945104225, 0.4689761975816652, 0.46163058749973385, 0.47212015881257896, 0.480162105943058, 0.4408561546429306, 0.4366730840182772, 0.47025634450655357, 0.4432445577546662, 0.44387248443330035, 0.4747207165597425, 0.47719932537452847, 0.4568568865458171, 0.4817005995587975, 0.4798497207024525, 0.46371710651083864, 0.4779285291830699, 0.4784679115406356, 0.48214280605342374, 0.47288842528474095, 0.47657034889447925, 0.4803711476863599, 0.46906366568131774, 0.47616199886097627, 0.4899844327101521, 0.4765799840291341, 0.47868988443823424, 0.4903433918952942, 0.48285137292216807, 0.4701712458741431, 0.48058533580864177, 0.4876571223870212, 0.49821703691108554, 0.4205977998527826, 0.4617271464244992, 0.4821519308039284, 0.4832778444477156, 0.4836801313886456, 0.48826419547492383, 0.47617226488459197, 0.4830194235432382, 0.49608560636931776, 0.4911629249360047, 0.4760929030530593, 0.48886771996816, 0.474396303442179, 0.47232537943066333, 0.485363348003696, 0.4155542084983751, 0.4881513498577417, 0.4846646715622127, 0.4798686770612703, 0.4827661158724725, 0.48629400367830317, 0.4843431989132774, 0.48410718318294077, 0.4818512015044689, 0.4807639783065693, 0.48980702547466054, 0.48102018385029893, 0.4676274587126339, 0.49002881874056425, 0.47884773236571576, 0.4805147833437385, 0.48289914721367405, 0.48207857348629035, 0.4823909694212541, 0.482215059081129, 0.48005643413099347, 0.4849184793876667, 0.48220301365854185, 0.4829977197097797, 0.4864743705473694], 'loss': [0.13717674420796205, 0.08538391963767208, 0.0765303797301763, 0.06982000730812864, 0.06789556965997144, 0.06325096200732452, 0.060092443091320245, 0.05961805482780374, 0.05769275123912681, 0.05643511760385634, 0.05484950013434085, 0.05210872785943941, 0.05212230694962898, 0.05040160828611948, 0.05082244260813475, 0.04888877725875129, 0.048482492206398664, 0.049217244470651435, 0.047179419714852636, 0.04724901438326635, 0.0463946155949961, 0.04625982577823717, 0.04733130517565131, 0.04613441189350354, 0.0444830993824548, 0.04419512371074605, 0.04434845837670029, 0.043305386222502504, 0.04321375696759945, 0.043672955871278604, 0.04339897423863293, 0.04330095777344608, 0.04314691955530103, 0.04187518749847599, 0.04153116483444305, 0.04332604641055352, 0.0421958526014168, 0.04186999085577879, 0.04076901321633738, 0.04110603500562917, 0.04049183754880008, 0.04127615148850425, 0.04123345750255897, 0.039908321599298184, 0.04180757208179142, 0.03989436056449562, 0.03933244684039561, 0.040684379284016484, 0.04003843712075522, 0.03916904288402722, 0.03907939762280004, 0.040044724943847726, 0.03841364822612929, 0.0372293073603345, 0.03872740781467015, 0.03673604776234218, 0.036411782098558026, 0.03606760968619932, 0.03627274307210329, 0.036586863168787155, 0.03608095286194505, 0.03549094531620911, 0.03538219925317292, 0.03624510818081033, 0.036308968974399405, 0.03479014456303254, 0.035730165603377655, 0.0356567665975203, 0.0353782770458408, 0.03442946017507903, 0.03543773468680884, 0.0347138767995955, 0.0343591746057186, 0.035207182555475926, 0.0336368759845557, 0.03367303675425929, 0.03412467948082865, 0.033337009738749625], 'acc': [0.9838975348399547, 0.9914537581309754, 0.9924080192520484, 0.9929553544895569, 0.9931808659150874, 0.9935628021094746, 0.9937689348070411, 0.99391858137291, 0.9940846435691534, 0.9942078324657277, 0.9943647746186729, 0.9945300497451455, 0.9945477806933141, 0.9946883265157117, 0.9946829807887688, 0.9948054482557365, 0.9948344622424508, 0.9948533039164129, 0.9949811017776832, 0.9950228544007339, 0.9950285337552768, 0.9950451660313969, 0.9950299129319787, 0.9951453635975246, 0.9952091623852314, 0.9952515950781522, 0.9952078335368059, 0.9952812613920998, 0.9952995022084926, 0.9952924581313655, 0.9953155189688592, 0.9953164698830929, 0.9953989864211956, 0.9954386581424385, 0.9954345958539879, 0.9953620657623108, 0.9954394777659676, 0.9954669544522902, 0.995519332052045, 0.9955045608914418, 0.995536251905963, 0.9955488133989415, 0.9955338986379413, 0.995556303596065, 0.9955580448382122, 0.9956018390094094, 0.9955928167000198, 0.9956439386315888, 0.9955843491811038, 0.9956620216770844, 0.9956470374090372, 0.9956403302141941, 0.995687136303242, 0.995800417827341, 0.9957968797401758, 0.9958983453395217, 0.9958643328809409, 0.9958895355737999, 0.9959125224286236, 0.9958535595688106, 0.9958901135966995, 0.9959357006042229, 0.995926654512466, 0.9959594387342101, 0.9959388788118729, 0.9959820282581698, 0.9959863826138763, 0.9959041299369202, 0.9960335630434745, 0.996052493396337, 0.9960841389559609, 0.9960853156193711, 0.9960946481302445, 0.9960563656921722, 0.9960883722450289, 0.9961154922338866, 0.996097728230441, 0.9961076824101847], 'mDice': [0.7367034893767974, 0.8338986337353519, 0.8509616230905015, 0.8640309625316153, 0.8677413788506233, 0.8768136421138423, 0.8830120348407395, 0.8838827612230783, 0.8876398787432487, 0.8900828304180282, 0.8931719449636851, 0.898560409208186, 0.8985226716103033, 0.9018836594849561, 0.9010492114167917, 0.9048461421363513, 0.9056488675843719, 0.9041680911527676, 0.9081748573770237, 0.9080045880329476, 0.9097137090631738, 0.9099823220503321, 0.9078432414917428, 0.9101712269147441, 0.9134398909548421, 0.9139907011823979, 0.9137097165262624, 0.9157572136367736, 0.915926575252573, 0.9150144794855005, 0.9155482654956699, 0.9157433382821347, 0.9160035205212167, 0.9185335511900603, 0.9192171568679068, 0.915670702670902, 0.9178887491217065, 0.9185218534127604, 0.9207002955810363, 0.9200299958645111, 0.9212435420948651, 0.9196641114814667, 0.9197574692235103, 0.9224007671101969, 0.9186038688894822, 0.922405959479608, 0.9235274404856323, 0.9207995290754116, 0.922123889088015, 0.9238252074022714, 0.9240099135979769, 0.9220827408435416, 0.9253163429571929, 0.9276150658667028, 0.9246215168919154, 0.9285502015371826, 0.9292140951534589, 0.9298896206924285, 0.9294704498710935, 0.9288771556651316, 0.9298638529608186, 0.931015353602513, 0.9312364111917596, 0.9294968320689369, 0.9293844020656166, 0.9323918462553629, 0.9305207106591599, 0.9307070547080473, 0.9311982423580717, 0.9330815546526301, 0.9310446583802041, 0.9324905461618367, 0.9332027206713924, 0.9315168241674788, 0.9346369448135908, 0.934558931378212, 0.9336608584762927, 0.9352329496802481], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:00<00:02,  1.42it/s]predicting test subjects:  50%|█████     | 2/4 [00:00<00:01,  1.81it/s]predicting test subjects:  75%|███████▌  | 3/4 [00:01<00:00,  2.36it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  2.86it/s]predicting test subjects: 100%|██████████| 4/4 [00:01<00:00,  3.33it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<00:36,  7.20it/s]predicting train subjects:   1%|          | 2/266 [00:00<00:36,  7.30it/s]predicting train subjects:   1%|          | 3/266 [00:00<00:34,  7.52it/s]predicting train subjects:   2%|▏         | 4/266 [00:00<00:34,  7.55it/s]predicting train subjects:   2%|▏         | 5/266 [00:00<00:34,  7.53it/s]predicting train subjects:   2%|▏         | 6/266 [00:00<00:33,  7.65it/s]predicting train subjects:   3%|▎         | 7/266 [00:00<00:33,  7.78it/s]predicting train subjects:   3%|▎         | 8/266 [00:01<00:33,  7.74it/s]predicting train subjects:   3%|▎         | 9/266 [00:01<00:32,  7.82it/s]predicting train subjects:   4%|▍         | 10/266 [00:01<00:32,  7.93it/s]predicting train subjects:   4%|▍         | 11/266 [00:01<00:32,  7.91it/s]predicting train subjects:   5%|▍         | 12/266 [00:01<00:32,  7.93it/s]predicting train subjects:   5%|▍         | 13/266 [00:01<00:31,  7.94it/s]predicting train subjects:   5%|▌         | 14/266 [00:01<00:34,  7.27it/s]predicting train subjects:   6%|▌         | 15/266 [00:01<00:34,  7.27it/s]predicting train subjects:   6%|▌         | 16/266 [00:02<00:33,  7.46it/s]predicting train subjects:   6%|▋         | 17/266 [00:02<00:32,  7.61it/s]predicting train subjects:   7%|▋         | 18/266 [00:02<00:32,  7.67it/s]predicting train subjects:   7%|▋         | 19/266 [00:02<00:31,  7.74it/s]predicting train subjects:   8%|▊         | 20/266 [00:02<00:31,  7.70it/s]predicting train subjects:   8%|▊         | 21/266 [00:02<00:31,  7.74it/s]predicting train subjects:   8%|▊         | 22/266 [00:02<00:31,  7.75it/s]predicting train subjects:   9%|▊         | 23/266 [00:02<00:30,  7.85it/s]predicting train subjects:   9%|▉         | 24/266 [00:03<00:30,  7.94it/s]predicting train subjects:   9%|▉         | 25/266 [00:03<00:29,  8.08it/s]predicting train subjects:  10%|▉         | 26/266 [00:03<00:29,  8.20it/s]predicting train subjects:  10%|█         | 27/266 [00:03<00:29,  8.20it/s]predicting train subjects:  11%|█         | 28/266 [00:03<00:28,  8.22it/s]predicting train subjects:  11%|█         | 29/266 [00:03<00:28,  8.24it/s]predicting train subjects:  11%|█▏        | 30/266 [00:03<00:28,  8.20it/s]predicting train subjects:  12%|█▏        | 31/266 [00:03<00:28,  8.19it/s]predicting train subjects:  12%|█▏        | 32/266 [00:04<00:28,  8.19it/s]predicting train subjects:  12%|█▏        | 33/266 [00:04<00:28,  8.18it/s]predicting train subjects:  13%|█▎        | 34/266 [00:04<00:28,  8.19it/s]predicting train subjects:  13%|█▎        | 35/266 [00:04<00:28,  8.18it/s]predicting train subjects:  14%|█▎        | 36/266 [00:04<00:28,  8.18it/s]predicting train subjects:  14%|█▍        | 37/266 [00:04<00:27,  8.19it/s]predicting train subjects:  14%|█▍        | 38/266 [00:04<00:27,  8.15it/s]predicting train subjects:  15%|█▍        | 39/266 [00:04<00:27,  8.16it/s]predicting train subjects:  15%|█▌        | 40/266 [00:05<00:30,  7.47it/s]predicting train subjects:  15%|█▌        | 41/266 [00:05<00:29,  7.56it/s]predicting train subjects:  16%|█▌        | 42/266 [00:05<00:28,  7.76it/s]predicting train subjects:  16%|█▌        | 43/266 [00:05<00:28,  7.89it/s]predicting train subjects:  17%|█▋        | 44/266 [00:05<00:27,  7.98it/s]predicting train subjects:  17%|█▋        | 45/266 [00:05<00:27,  8.07it/s]predicting train subjects:  17%|█▋        | 46/266 [00:05<00:27,  8.13it/s]predicting train subjects:  18%|█▊        | 47/266 [00:05<00:26,  8.17it/s]predicting train subjects:  18%|█▊        | 48/266 [00:06<00:26,  8.20it/s]predicting train subjects:  18%|█▊        | 49/266 [00:06<00:26,  8.20it/s]predicting train subjects:  19%|█▉        | 50/266 [00:06<00:26,  8.24it/s]predicting train subjects:  19%|█▉        | 51/266 [00:06<00:25,  8.28it/s]predicting train subjects:  20%|█▉        | 52/266 [00:06<00:25,  8.31it/s]predicting train subjects:  20%|█▉        | 53/266 [00:06<00:25,  8.33it/s]predicting train subjects:  20%|██        | 54/266 [00:06<00:25,  8.24it/s]predicting train subjects:  21%|██        | 55/266 [00:06<00:25,  8.24it/s]predicting train subjects:  21%|██        | 56/266 [00:07<00:25,  8.21it/s]predicting train subjects:  21%|██▏       | 57/266 [00:07<00:25,  8.20it/s]predicting train subjects:  22%|██▏       | 58/266 [00:07<00:25,  8.16it/s]predicting train subjects:  22%|██▏       | 59/266 [00:07<00:26,  7.89it/s]predicting train subjects:  23%|██▎       | 60/266 [00:07<00:26,  7.75it/s]predicting train subjects:  23%|██▎       | 61/266 [00:07<00:26,  7.69it/s]predicting train subjects:  23%|██▎       | 62/266 [00:07<00:26,  7.57it/s]predicting train subjects:  24%|██▎       | 63/266 [00:07<00:26,  7.68it/s]predicting train subjects:  24%|██▍       | 64/266 [00:08<00:26,  7.68it/s]predicting train subjects:  24%|██▍       | 65/266 [00:08<00:26,  7.66it/s]predicting train subjects:  25%|██▍       | 66/266 [00:08<00:28,  7.14it/s]predicting train subjects:  25%|██▌       | 67/266 [00:08<00:26,  7.38it/s]predicting train subjects:  26%|██▌       | 68/266 [00:08<00:26,  7.50it/s]predicting train subjects:  26%|██▌       | 69/266 [00:08<00:26,  7.58it/s]predicting train subjects:  26%|██▋       | 70/266 [00:08<00:25,  7.57it/s]predicting train subjects:  27%|██▋       | 71/266 [00:09<00:25,  7.58it/s]predicting train subjects:  27%|██▋       | 72/266 [00:09<00:25,  7.61it/s]predicting train subjects:  27%|██▋       | 73/266 [00:09<00:25,  7.65it/s]predicting train subjects:  28%|██▊       | 74/266 [00:09<00:25,  7.64it/s]predicting train subjects:  28%|██▊       | 75/266 [00:09<00:24,  7.64it/s]predicting train subjects:  29%|██▊       | 76/266 [00:09<00:24,  7.69it/s]predicting train subjects:  29%|██▉       | 77/266 [00:09<00:27,  6.78it/s]predicting train subjects:  29%|██▉       | 78/266 [00:10<00:29,  6.34it/s]predicting train subjects:  30%|██▉       | 79/266 [00:10<00:31,  5.89it/s]predicting train subjects:  30%|███       | 80/266 [00:10<00:33,  5.58it/s]predicting train subjects:  30%|███       | 81/266 [00:10<00:31,  5.92it/s]predicting train subjects:  31%|███       | 82/266 [00:10<00:29,  6.13it/s]predicting train subjects:  31%|███       | 83/266 [00:10<00:29,  6.27it/s]predicting train subjects:  32%|███▏      | 84/266 [00:11<00:28,  6.35it/s]predicting train subjects:  32%|███▏      | 85/266 [00:11<00:28,  6.42it/s]predicting train subjects:  32%|███▏      | 86/266 [00:11<00:27,  6.54it/s]predicting train subjects:  33%|███▎      | 87/266 [00:11<00:27,  6.59it/s]predicting train subjects:  33%|███▎      | 88/266 [00:11<00:26,  6.65it/s]predicting train subjects:  33%|███▎      | 89/266 [00:11<00:26,  6.64it/s]predicting train subjects:  34%|███▍      | 90/266 [00:11<00:26,  6.72it/s]predicting train subjects:  34%|███▍      | 91/266 [00:12<00:25,  6.75it/s]predicting train subjects:  35%|███▍      | 92/266 [00:12<00:25,  6.84it/s]predicting train subjects:  35%|███▍      | 93/266 [00:12<00:25,  6.78it/s]predicting train subjects:  35%|███▌      | 94/266 [00:12<00:25,  6.79it/s]predicting train subjects:  36%|███▌      | 95/266 [00:12<00:25,  6.75it/s]predicting train subjects:  36%|███▌      | 96/266 [00:12<00:25,  6.72it/s]predicting train subjects:  36%|███▋      | 97/266 [00:12<00:25,  6.67it/s]predicting train subjects:  37%|███▋      | 98/266 [00:13<00:25,  6.64it/s]predicting train subjects:  37%|███▋      | 99/266 [00:13<00:25,  6.60it/s]predicting train subjects:  38%|███▊      | 100/266 [00:13<00:24,  6.70it/s]predicting train subjects:  38%|███▊      | 101/266 [00:13<00:24,  6.83it/s]predicting train subjects:  38%|███▊      | 102/266 [00:13<00:23,  7.01it/s]predicting train subjects:  39%|███▊      | 103/266 [00:13<00:22,  7.09it/s]predicting train subjects:  39%|███▉      | 104/266 [00:13<00:22,  7.05it/s]predicting train subjects:  39%|███▉      | 105/266 [00:14<00:22,  7.08it/s]predicting train subjects:  40%|███▉      | 106/266 [00:14<00:22,  7.04it/s]predicting train subjects:  40%|████      | 107/266 [00:14<00:22,  6.99it/s]predicting train subjects:  41%|████      | 108/266 [00:14<00:22,  6.93it/s]predicting train subjects:  41%|████      | 109/266 [00:14<00:22,  6.92it/s]predicting train subjects:  41%|████▏     | 110/266 [00:14<00:22,  6.95it/s]predicting train subjects:  42%|████▏     | 111/266 [00:14<00:22,  7.01it/s]predicting train subjects:  42%|████▏     | 112/266 [00:15<00:21,  7.01it/s]predicting train subjects:  42%|████▏     | 113/266 [00:15<00:21,  6.97it/s]predicting train subjects:  43%|████▎     | 114/266 [00:15<00:21,  6.93it/s]predicting train subjects:  43%|████▎     | 115/266 [00:15<00:21,  6.88it/s]predicting train subjects:  44%|████▎     | 116/266 [00:15<00:21,  6.87it/s]predicting train subjects:  44%|████▍     | 117/266 [00:15<00:21,  6.88it/s]predicting train subjects:  44%|████▍     | 118/266 [00:15<00:20,  7.19it/s]predicting train subjects:  45%|████▍     | 119/266 [00:16<00:19,  7.47it/s]predicting train subjects:  45%|████▌     | 120/266 [00:16<00:18,  7.75it/s]predicting train subjects:  45%|████▌     | 121/266 [00:16<00:17,  8.07it/s]predicting train subjects:  46%|████▌     | 122/266 [00:16<00:17,  8.20it/s]predicting train subjects:  46%|████▌     | 123/266 [00:16<00:17,  8.23it/s]predicting train subjects:  47%|████▋     | 124/266 [00:16<00:17,  8.26it/s]predicting train subjects:  47%|████▋     | 125/266 [00:16<00:17,  8.27it/s]predicting train subjects:  47%|████▋     | 126/266 [00:16<00:16,  8.30it/s]predicting train subjects:  48%|████▊     | 127/266 [00:17<00:16,  8.30it/s]predicting train subjects:  48%|████▊     | 128/266 [00:17<00:16,  8.24it/s]predicting train subjects:  48%|████▊     | 129/266 [00:17<00:16,  8.25it/s]predicting train subjects:  49%|████▉     | 130/266 [00:17<00:16,  8.26it/s]predicting train subjects:  49%|████▉     | 131/266 [00:17<00:16,  8.21it/s]predicting train subjects:  50%|████▉     | 132/266 [00:17<00:16,  8.20it/s]predicting train subjects:  50%|█████     | 133/266 [00:17<00:16,  8.22it/s]predicting train subjects:  50%|█████     | 134/266 [00:17<00:16,  8.23it/s]predicting train subjects:  51%|█████     | 135/266 [00:18<00:15,  8.26it/s]predicting train subjects:  51%|█████     | 136/266 [00:18<00:15,  8.21it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:18<00:15,  8.19it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:18<00:15,  8.21it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:18<00:15,  8.21it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:18<00:15,  8.21it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:18<00:15,  8.21it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:18<00:15,  8.22it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:18<00:14,  8.21it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:19<00:14,  8.24it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:19<00:14,  8.27it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:19<00:14,  8.30it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:19<00:14,  8.28it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:19<00:14,  8.25it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:19<00:14,  8.25it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:19<00:14,  8.27it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:19<00:14,  8.19it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:20<00:14,  8.14it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:20<00:13,  8.12it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:20<00:14,  7.67it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:20<00:14,  7.41it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:20<00:15,  7.23it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:20<00:15,  7.09it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:20<00:15,  7.03it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:21<00:15,  6.99it/s]predicting train subjects:  60%|██████    | 160/266 [00:21<00:15,  6.91it/s]predicting train subjects:  61%|██████    | 161/266 [00:21<00:15,  6.90it/s]predicting train subjects:  61%|██████    | 162/266 [00:21<00:15,  6.89it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:21<00:14,  6.89it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:21<00:14,  6.92it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:21<00:14,  6.95it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:22<00:14,  6.93it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:22<00:14,  6.93it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:22<00:14,  6.91it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:22<00:14,  6.91it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:22<00:13,  6.93it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:22<00:13,  6.85it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:22<00:13,  7.14it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:23<00:14,  6.54it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:23<00:14,  6.44it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:23<00:14,  6.27it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:23<00:13,  6.73it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:23<00:12,  7.05it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:23<00:11,  7.33it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:23<00:11,  7.57it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:24<00:11,  7.74it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:24<00:10,  7.85it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:24<00:10,  7.93it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:24<00:10,  8.01it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:24<00:10,  8.04it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:24<00:10,  8.05it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:24<00:09,  8.07it/s]predicting train subjects:  70%|███████   | 187/266 [00:24<00:09,  8.06it/s]predicting train subjects:  71%|███████   | 188/266 [00:25<00:09,  8.05it/s]predicting train subjects:  71%|███████   | 189/266 [00:25<00:09,  8.05it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:25<00:09,  8.06it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:25<00:09,  8.03it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:25<00:09,  8.03it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:25<00:09,  8.08it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:25<00:08,  8.13it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:25<00:09,  7.63it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:26<00:09,  7.37it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:26<00:09,  7.19it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:26<00:09,  7.08it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:26<00:09,  7.00it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:26<00:09,  6.92it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:26<00:09,  6.87it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:26<00:09,  6.85it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:27<00:09,  6.83it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:27<00:09,  6.78it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:27<00:08,  6.78it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:27<00:08,  6.82it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:27<00:08,  6.88it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:27<00:08,  6.86it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:28<00:08,  6.81it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:28<00:08,  6.79it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:28<00:08,  6.78it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:28<00:07,  6.78it/s]predicting train subjects:  80%|████████  | 213/266 [00:28<00:07,  6.92it/s]predicting train subjects:  80%|████████  | 214/266 [00:28<00:07,  7.03it/s]predicting train subjects:  81%|████████  | 215/266 [00:28<00:07,  7.10it/s]predicting train subjects:  81%|████████  | 216/266 [00:29<00:06,  7.17it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:29<00:06,  7.20it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:29<00:06,  7.22it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:29<00:06,  7.25it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:29<00:06,  7.25it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:29<00:06,  7.27it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:29<00:06,  7.28it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:29<00:05,  7.31it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:30<00:05,  7.33it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:30<00:05,  7.33it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:30<00:05,  7.34it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:30<00:05,  7.33it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:30<00:05,  7.32it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:30<00:05,  7.31it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:30<00:04,  7.26it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:31<00:04,  7.69it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:31<00:04,  8.09it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:31<00:03,  8.39it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:31<00:03,  8.66it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:31<00:03,  8.85it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:31<00:03,  9.01it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:31<00:03,  9.11it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:31<00:03,  9.15it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:31<00:02,  9.20it/s]predicting train subjects:  90%|█████████ | 240/266 [00:32<00:02,  9.22it/s]predicting train subjects:  91%|█████████ | 241/266 [00:32<00:02,  9.27it/s]predicting train subjects:  91%|█████████ | 242/266 [00:32<00:02,  9.30it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:32<00:02,  9.30it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:32<00:02,  9.32it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:32<00:02,  9.25it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:32<00:02,  9.29it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:32<00:02,  9.26it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:32<00:01,  9.27it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:32<00:01,  8.96it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:33<00:01,  8.77it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:33<00:01,  8.59it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:33<00:01,  8.51it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:33<00:01,  8.46it/s]predicting train subjects:  95%|█████████▌| 254/266 [00:33<00:01,  8.38it/s]predicting train subjects:  96%|█████████▌| 255/266 [00:33<00:01,  8.26it/s]predicting train subjects:  96%|█████████▌| 256/266 [00:33<00:01,  8.13it/s]predicting train subjects:  97%|█████████▋| 257/266 [00:33<00:01,  8.15it/s]predicting train subjects:  97%|█████████▋| 258/266 [00:34<00:00,  8.25it/s]predicting train subjects:  97%|█████████▋| 259/266 [00:34<00:00,  8.19it/s]predicting train subjects:  98%|█████████▊| 260/266 [00:34<00:00,  8.18it/s]predicting train subjects:  98%|█████████▊| 261/266 [00:34<00:00,  8.19it/s]predicting train subjects:  98%|█████████▊| 262/266 [00:34<00:00,  8.23it/s]predicting train subjects:  99%|█████████▉| 263/266 [00:34<00:00,  8.29it/s]predicting train subjects:  99%|█████████▉| 264/266 [00:34<00:00,  8.29it/s]predicting train subjects: 100%|█████████▉| 265/266 [00:34<00:00,  8.25it/s]predicting train subjects: 100%|██████████| 266/266 [00:35<00:00,  8.19it/s]predicting train subjects: 100%|██████████| 266/266 [00:35<00:00,  7.59it/s]
predicting test subjects sagittal:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects sagittal:  25%|██▌       | 1/4 [00:00<00:00,  7.91it/s]predicting test subjects sagittal:  50%|█████     | 2/4 [00:00<00:00,  8.13it/s]predicting test subjects sagittal:  75%|███████▌  | 3/4 [00:00<00:00,  8.24it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  7.86it/s]predicting test subjects sagittal: 100%|██████████| 4/4 [00:00<00:00,  8.00it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<00:33,  7.94it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<00:32,  8.02it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<00:32,  8.13it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:00<00:32,  8.04it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:00<00:32,  8.04it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:00<00:32,  8.06it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:00<00:32,  8.07it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:00<00:31,  8.07it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:01<00:31,  8.10it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:01<00:31,  8.10it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:01<00:31,  8.09it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:01<00:31,  8.09it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:01<00:31,  8.14it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:01<00:30,  8.16it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:01<00:30,  8.14it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:01<00:30,  8.13it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:02<00:30,  8.14it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:02<00:30,  8.14it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:02<00:30,  8.09it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:02<00:30,  8.06it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:02<00:30,  7.98it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:02<00:30,  7.96it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:02<00:29,  8.14it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:02<00:29,  8.23it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:03<00:29,  8.30it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:03<00:28,  8.36it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:03<00:28,  8.39it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:03<00:28,  8.44it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:03<00:28,  8.46it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:03<00:28,  8.41it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:03<00:27,  8.40it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:03<00:27,  8.42it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:04<00:27,  8.44it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:04<00:27,  8.48it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:04<00:27,  8.48it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:04<00:27,  8.47it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:04<00:27,  8.43it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:04<00:27,  8.44it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:04<00:26,  8.42it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:04<00:26,  8.42it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:04<00:26,  8.43it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:05<00:26,  8.42it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:05<00:26,  8.42it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:05<00:26,  8.39it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:05<00:26,  8.39it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:05<00:26,  8.39it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:05<00:26,  8.41it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:05<00:25,  8.43it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:05<00:25,  8.45it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:06<00:25,  8.44it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:06<00:25,  8.42it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:06<00:25,  8.45it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:06<00:25,  8.43it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:06<00:25,  8.44it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:06<00:25,  8.43it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:06<00:24,  8.42it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:06<00:24,  8.46it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:06<00:24,  8.49it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:07<00:25,  8.27it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:07<00:25,  8.14it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:07<00:25,  8.04it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:07<00:25,  7.98it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:07<00:25,  7.92it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:07<00:25,  7.91it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:07<00:25,  7.89it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:08<00:25,  7.86it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:08<00:25,  7.80it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:08<00:25,  7.82it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:08<00:25,  7.74it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:08<00:25,  7.74it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:08<00:25,  7.67it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:08<00:25,  7.70it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:08<00:24,  7.75it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:09<00:24,  7.76it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:09<00:24,  7.70it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:09<00:24,  7.76it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:09<00:25,  7.32it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:09<00:26,  7.16it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:09<00:24,  7.50it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:09<00:23,  7.79it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:09<00:24,  7.55it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:10<00:25,  7.33it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:10<00:25,  7.28it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:10<00:25,  7.16it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:10<00:25,  7.05it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:10<00:25,  6.96it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:10<00:26,  6.87it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:11<00:26,  6.81it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:11<00:26,  6.80it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:11<00:25,  6.80it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:11<00:25,  6.78it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:11<00:25,  6.77it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:11<00:25,  6.77it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:11<00:25,  6.74it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:12<00:25,  6.72it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:12<00:25,  6.71it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:12<00:25,  6.54it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:12<00:25,  6.60it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:12<00:25,  6.65it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:12<00:24,  6.70it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:12<00:24,  6.76it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:13<00:24,  6.81it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:13<00:23,  6.83it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:13<00:24,  6.63it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:13<00:24,  6.68it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:13<00:23,  6.73it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:13<00:23,  6.79it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:13<00:23,  6.78it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:14<00:23,  6.77it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:14<00:22,  6.86it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:14<00:22,  6.96it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:14<00:22,  6.94it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:14<00:22,  6.91it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:14<00:21,  6.95it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:14<00:21,  6.95it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:15<00:21,  6.94it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:15<00:21,  6.91it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:15<00:20,  7.31it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:15<00:19,  7.60it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:15<00:18,  7.81it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:15<00:18,  7.95it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:15<00:17,  8.10it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:15<00:17,  8.19it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:16<00:17,  8.22it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:16<00:17,  8.27it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:16<00:17,  8.22it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:16<00:16,  8.34it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:16<00:16,  8.51it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:16<00:16,  8.55it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:16<00:15,  8.50it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:16<00:15,  8.46it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:17<00:15,  8.42it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:17<00:15,  8.37it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:17<00:15,  8.37it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:17<00:15,  8.35it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:17<00:15,  8.29it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:17<00:15,  8.28it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:17<00:15,  8.27it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:17<00:15,  8.22it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:18<00:15,  8.22it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:18<00:15,  8.23it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:18<00:15,  8.23it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:18<00:14,  8.25it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:18<00:14,  8.22it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:18<00:14,  8.18it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:18<00:14,  8.21it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:18<00:14,  8.20it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:19<00:14,  8.23it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:19<00:14,  8.34it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:19<00:13,  8.34it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:19<00:13,  8.27it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:19<00:13,  8.28it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:19<00:13,  8.31it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:19<00:14,  7.78it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:19<00:14,  7.50it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:20<00:15,  7.29it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:20<00:15,  7.15it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:20<00:15,  7.07it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:20<00:15,  7.03it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:20<00:15,  6.96it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:20<00:15,  6.94it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:20<00:14,  6.94it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:21<00:14,  6.92it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:21<00:14,  6.92it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:21<00:14,  6.86it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:21<00:14,  6.75it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:21<00:14,  6.76it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:21<00:14,  6.77it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:21<00:14,  6.77it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:22<00:14,  6.80it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:22<00:13,  6.84it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:22<00:13,  7.18it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:22<00:13,  7.06it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:22<00:12,  7.18it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:22<00:11,  7.69it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:22<00:11,  7.93it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:22<00:11,  7.99it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:23<00:10,  8.01it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:23<00:10,  8.01it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:23<00:10,  7.96it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:23<00:10,  7.96it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:23<00:10,  7.97it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:23<00:10,  7.98it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:23<00:10,  8.05it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:23<00:09,  8.19it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:24<00:09,  8.28it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:24<00:09,  8.35it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:24<00:09,  8.33it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:24<00:09,  8.35it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:24<00:09,  8.28it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:24<00:09,  8.22it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:24<00:09,  8.11it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:24<00:09,  8.07it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:25<00:08,  8.07it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:25<00:09,  7.53it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:25<00:09,  7.22it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:25<00:09,  7.06it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:25<00:09,  7.04it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:25<00:09,  7.03it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:25<00:09,  7.02it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:26<00:09,  7.02it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:26<00:09,  7.02it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:26<00:08,  7.02it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:26<00:08,  6.98it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:26<00:08,  6.88it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:26<00:08,  6.81it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:26<00:08,  6.77it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:27<00:08,  6.77it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:27<00:08,  6.79it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:27<00:08,  6.74it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:27<00:08,  6.73it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:27<00:08,  6.72it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:27<00:07,  6.88it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:27<00:07,  6.98it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:28<00:07,  7.03it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:28<00:07,  7.10it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:28<00:06,  7.12it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:28<00:06,  7.13it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:28<00:06,  7.15it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:28<00:06,  7.17it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:28<00:06,  7.16it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:29<00:06,  7.18it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:29<00:05,  7.18it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:29<00:05,  7.17it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:29<00:05,  7.17it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:29<00:05,  7.21it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:29<00:05,  7.21it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:29<00:05,  7.23it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:30<00:05,  7.23it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:30<00:04,  7.20it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:30<00:04,  7.72it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:30<00:04,  8.09it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:30<00:03,  8.38it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:30<00:03,  8.59it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:30<00:03,  8.74it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:30<00:03,  8.84it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:30<00:03,  8.90it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:31<00:03,  8.95it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:31<00:03,  8.99it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:31<00:02,  9.01it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:31<00:02,  9.03it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:31<00:02,  9.05it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:31<00:02,  9.07it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:31<00:02,  9.08it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:31<00:02,  9.10it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:31<00:02,  9.09it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:32<00:02,  9.08it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:32<00:01,  9.06it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:32<00:01,  8.77it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:32<00:01,  8.55it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:32<00:01,  8.38it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:32<00:01,  8.30it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:32<00:01,  8.27it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:32<00:01,  8.25it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:33<00:01,  8.22it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:33<00:01,  8.31it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:33<00:01,  8.41it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:33<00:00,  8.49it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [00:33<00:00,  8.52it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [00:33<00:00,  8.39it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [00:33<00:00,  8.30it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [00:33<00:00,  8.25it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [00:34<00:00,  8.18it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [00:34<00:00,  8.12it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [00:34<00:00,  8.15it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:34<00:00,  8.17it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [00:34<00:00,  7.73it/s]
saving BB  test1-THALAMUS:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 4/4 [00:00<00:00, 74.54it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 9/266 [00:00<00:03, 80.99it/s]saving BB  train1-THALAMUS:   7%|▋         | 18/266 [00:00<00:03, 81.84it/s]saving BB  train1-THALAMUS:  10%|█         | 27/266 [00:00<00:02, 82.94it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:02, 83.02it/s]saving BB  train1-THALAMUS:  17%|█▋        | 45/266 [00:00<00:02, 82.78it/s]saving BB  train1-THALAMUS:  21%|██        | 55/266 [00:00<00:02, 84.94it/s]saving BB  train1-THALAMUS:  24%|██▎       | 63/266 [00:00<00:02, 79.40it/s]saving BB  train1-THALAMUS:  27%|██▋       | 71/266 [00:00<00:02, 78.68it/s]saving BB  train1-THALAMUS:  30%|██▉       | 79/266 [00:00<00:02, 75.88it/s]saving BB  train1-THALAMUS:  33%|███▎      | 87/266 [00:01<00:02, 72.74it/s]saving BB  train1-THALAMUS:  36%|███▌      | 95/266 [00:01<00:02, 71.00it/s]saving BB  train1-THALAMUS:  39%|███▊      | 103/266 [00:01<00:02, 65.64it/s]saving BB  train1-THALAMUS:  41%|████▏     | 110/266 [00:01<00:02, 65.72it/s]saving BB  train1-THALAMUS:  44%|████▍     | 117/266 [00:01<00:02, 66.64it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:02, 69.93it/s]saving BB  train1-THALAMUS:  50%|█████     | 133/266 [00:01<00:01, 72.01it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:01<00:01, 75.14it/s]saving BB  train1-THALAMUS:  57%|█████▋    | 152/266 [00:01<00:01, 80.27it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:02<00:01, 79.77it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 170/266 [00:02<00:01, 77.85it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 178/266 [00:02<00:01, 77.34it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:02<00:01, 76.93it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 194/266 [00:02<00:00, 77.66it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 74.45it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 73.30it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:02<00:00, 73.68it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:02<00:00, 74.38it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:03<00:00, 77.35it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 244/266 [00:03<00:00, 80.12it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 253/266 [00:03<00:00, 82.39it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 82.32it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 77.02it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/4 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 4/4 [00:00<00:00, 74.33it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 8/266 [00:00<00:03, 75.88it/s]saving BB  train1-THALAMUS Sagittal:   6%|▌         | 16/266 [00:00<00:03, 76.17it/s]saving BB  train1-THALAMUS Sagittal:   9%|▉         | 24/266 [00:00<00:03, 75.55it/s]saving BB  train1-THALAMUS Sagittal:  12%|█▏        | 33/266 [00:00<00:03, 77.66it/s]saving BB  train1-THALAMUS Sagittal:  16%|█▌        | 42/266 [00:00<00:02, 78.99it/s]saving BB  train1-THALAMUS Sagittal:  19%|█▉        | 51/266 [00:00<00:02, 79.84it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 60/266 [00:00<00:02, 79.76it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▌       | 68/266 [00:00<00:02, 77.82it/s]saving BB  train1-THALAMUS Sagittal:  29%|██▊       | 76/266 [00:00<00:02, 76.05it/s]saving BB  train1-THALAMUS Sagittal:  32%|███▏      | 84/266 [00:01<00:02, 72.42it/s]saving BB  train1-THALAMUS Sagittal:  35%|███▍      | 92/266 [00:01<00:02, 69.69it/s]saving BB  train1-THALAMUS Sagittal:  37%|███▋      | 99/266 [00:01<00:02, 67.14it/s]saving BB  train1-THALAMUS Sagittal:  40%|███▉      | 106/266 [00:01<00:02, 67.60it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 113/266 [00:01<00:02, 67.99it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▌     | 121/266 [00:01<00:02, 68.65it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 129/266 [00:01<00:01, 70.26it/s]saving BB  train1-THALAMUS Sagittal:  52%|█████▏    | 138/266 [00:01<00:01, 73.42it/s]saving BB  train1-THALAMUS Sagittal:  55%|█████▌    | 147/266 [00:01<00:01, 76.98it/s]saving BB  train1-THALAMUS Sagittal:  59%|█████▊    | 156/266 [00:02<00:01, 78.99it/s]saving BB  train1-THALAMUS Sagittal:  62%|██████▏   | 164/266 [00:02<00:01, 77.84it/s]saving BB  train1-THALAMUS Sagittal:  65%|██████▍   | 172/266 [00:02<00:01, 77.12it/s]saving BB  train1-THALAMUS Sagittal:  68%|██████▊   | 180/266 [00:02<00:01, 77.51it/s]saving BB  train1-THALAMUS Sagittal:  71%|███████   | 188/266 [00:02<00:01, 77.49it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 196/266 [00:02<00:00, 75.48it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 204/266 [00:02<00:00, 72.83it/s]saving BB  train1-THALAMUS Sagittal:  80%|███████▉  | 212/266 [00:02<00:00, 71.21it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 220/266 [00:02<00:00, 69.74it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▌ | 228/266 [00:03<00:00, 68.73it/s]saving BB  train1-THALAMUS Sagittal:  89%|████████▊ | 236/266 [00:03<00:00, 71.13it/s]saving BB  train1-THALAMUS Sagittal:  92%|█████████▏| 244/266 [00:03<00:00, 72.39it/s]saving BB  train1-THALAMUS Sagittal:  95%|█████████▍| 252/266 [00:03<00:00, 74.17it/s]saving BB  train1-THALAMUS Sagittal:  98%|█████████▊| 260/266 [00:03<00:00, 75.53it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 74.35it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<04:20,  1.02it/s]Loading train:   1%|          | 2/266 [00:01<04:06,  1.07it/s]Loading train:   1%|          | 3/266 [00:02<03:58,  1.10it/s]Loading train:   2%|▏         | 4/266 [00:03<03:59,  1.10it/s]Loading train:   2%|▏         | 5/266 [00:04<03:32,  1.23it/s]Loading train:   2%|▏         | 6/266 [00:04<03:11,  1.36it/s]Loading train:   3%|▎         | 7/266 [00:05<02:55,  1.48it/s]Loading train:   3%|▎         | 8/266 [00:05<02:45,  1.56it/s]Loading train:   3%|▎         | 9/266 [00:06<02:36,  1.65it/s]Loading train:   4%|▍         | 10/266 [00:06<02:29,  1.72it/s]Loading train:   4%|▍         | 11/266 [00:07<02:25,  1.75it/s]Loading train:   5%|▍         | 12/266 [00:07<02:24,  1.76it/s]Loading train:   5%|▍         | 13/266 [00:08<02:24,  1.75it/s]Loading train:   5%|▌         | 14/266 [00:09<02:26,  1.72it/s]Loading train:   6%|▌         | 15/266 [00:09<02:24,  1.74it/s]Loading train:   6%|▌         | 16/266 [00:10<02:23,  1.74it/s]Loading train:   6%|▋         | 17/266 [00:10<02:24,  1.73it/s]Loading train:   7%|▋         | 18/266 [00:11<02:21,  1.75it/s]Loading train:   7%|▋         | 19/266 [00:11<02:20,  1.76it/s]Loading train:   8%|▊         | 20/266 [00:12<02:19,  1.77it/s]Loading train:   8%|▊         | 21/266 [00:13<02:17,  1.79it/s]Loading train:   8%|▊         | 22/266 [00:13<02:15,  1.80it/s]Loading train:   9%|▊         | 23/266 [00:14<02:16,  1.78it/s]Loading train:   9%|▉         | 24/266 [00:14<02:12,  1.82it/s]Loading train:   9%|▉         | 25/266 [00:15<02:09,  1.86it/s]Loading train:  10%|▉         | 26/266 [00:15<02:08,  1.87it/s]Loading train:  10%|█         | 27/266 [00:16<02:05,  1.91it/s]Loading train:  11%|█         | 28/266 [00:16<02:04,  1.92it/s]Loading train:  11%|█         | 29/266 [00:17<02:03,  1.91it/s]Loading train:  11%|█▏        | 30/266 [00:17<02:03,  1.91it/s]Loading train:  12%|█▏        | 31/266 [00:18<02:04,  1.89it/s]Loading train:  12%|█▏        | 32/266 [00:18<02:06,  1.85it/s]Loading train:  12%|█▏        | 33/266 [00:19<02:10,  1.78it/s]Loading train:  13%|█▎        | 34/266 [00:20<02:08,  1.80it/s]Loading train:  13%|█▎        | 35/266 [00:20<02:05,  1.84it/s]Loading train:  14%|█▎        | 36/266 [00:21<02:02,  1.88it/s]Loading train:  14%|█▍        | 37/266 [00:21<02:00,  1.89it/s]Loading train:  14%|█▍        | 38/266 [00:22<01:59,  1.90it/s]Loading train:  15%|█▍        | 39/266 [00:22<01:58,  1.91it/s]Loading train:  15%|█▌        | 40/266 [00:23<01:56,  1.93it/s]Loading train:  15%|█▌        | 41/266 [00:23<01:55,  1.95it/s]Loading train:  16%|█▌        | 42/266 [00:24<01:54,  1.96it/s]Loading train:  16%|█▌        | 43/266 [00:24<01:51,  1.99it/s]Loading train:  17%|█▋        | 44/266 [00:25<01:52,  1.97it/s]Loading train:  17%|█▋        | 45/266 [00:25<01:52,  1.96it/s]Loading train:  17%|█▋        | 46/266 [00:26<01:53,  1.94it/s]Loading train:  18%|█▊        | 47/266 [00:26<01:52,  1.95it/s]Loading train:  18%|█▊        | 48/266 [00:27<01:51,  1.96it/s]Loading train:  18%|█▊        | 49/266 [00:27<01:52,  1.93it/s]Loading train:  19%|█▉        | 50/266 [00:28<01:49,  1.98it/s]Loading train:  19%|█▉        | 51/266 [00:28<01:47,  2.00it/s]Loading train:  20%|█▉        | 52/266 [00:29<01:47,  1.99it/s]Loading train:  20%|█▉        | 53/266 [00:29<01:47,  1.99it/s]Loading train:  20%|██        | 54/266 [00:30<01:44,  2.04it/s]Loading train:  21%|██        | 55/266 [00:30<01:42,  2.05it/s]Loading train:  21%|██        | 56/266 [00:31<01:44,  2.02it/s]Loading train:  21%|██▏       | 57/266 [00:31<01:43,  2.01it/s]Loading train:  22%|██▏       | 58/266 [00:32<01:43,  2.02it/s]Loading train:  22%|██▏       | 59/266 [00:32<01:50,  1.88it/s]Loading train:  23%|██▎       | 60/266 [00:33<01:54,  1.81it/s]Loading train:  23%|██▎       | 61/266 [00:34<01:55,  1.77it/s]Loading train:  23%|██▎       | 62/266 [00:34<01:55,  1.77it/s]Loading train:  24%|██▎       | 63/266 [00:35<01:54,  1.78it/s]Loading train:  24%|██▍       | 64/266 [00:35<01:56,  1.74it/s]Loading train:  24%|██▍       | 65/266 [00:36<01:53,  1.76it/s]Loading train:  25%|██▍       | 66/266 [00:36<01:51,  1.79it/s]Loading train:  25%|██▌       | 67/266 [00:37<01:51,  1.79it/s]Loading train:  26%|██▌       | 68/266 [00:37<01:50,  1.80it/s]Loading train:  26%|██▌       | 69/266 [00:38<01:49,  1.80it/s]Loading train:  26%|██▋       | 70/266 [00:39<01:49,  1.79it/s]Loading train:  27%|██▋       | 71/266 [00:39<01:52,  1.73it/s]Loading train:  27%|██▋       | 72/266 [00:40<01:52,  1.72it/s]Loading train:  27%|██▋       | 73/266 [00:40<01:51,  1.73it/s]Loading train:  28%|██▊       | 74/266 [00:41<01:51,  1.72it/s]Loading train:  28%|██▊       | 75/266 [00:42<01:52,  1.70it/s]Loading train:  29%|██▊       | 76/266 [00:42<01:50,  1.72it/s]Loading train:  29%|██▉       | 77/266 [00:43<02:15,  1.39it/s]Loading train:  29%|██▉       | 78/266 [00:44<02:29,  1.26it/s]Loading train:  30%|██▉       | 79/266 [00:45<02:30,  1.24it/s]Loading train:  30%|███       | 80/266 [00:46<02:28,  1.25it/s]Loading train:  30%|███       | 81/266 [00:47<02:39,  1.16it/s]Loading train:  31%|███       | 82/266 [00:47<02:27,  1.25it/s]Loading train:  31%|███       | 83/266 [00:48<02:19,  1.31it/s]Loading train:  32%|███▏      | 84/266 [00:49<02:12,  1.37it/s]Loading train:  32%|███▏      | 85/266 [00:49<02:06,  1.43it/s]Loading train:  32%|███▏      | 86/266 [00:50<01:59,  1.51it/s]Loading train:  33%|███▎      | 87/266 [00:51<02:00,  1.48it/s]Loading train:  33%|███▎      | 88/266 [00:51<01:58,  1.51it/s]Loading train:  33%|███▎      | 89/266 [00:52<01:58,  1.49it/s]Loading train:  34%|███▍      | 90/266 [00:53<01:57,  1.50it/s]Loading train:  34%|███▍      | 91/266 [00:53<01:59,  1.47it/s]Loading train:  35%|███▍      | 92/266 [00:54<01:57,  1.48it/s]Loading train:  35%|███▍      | 93/266 [00:55<01:58,  1.46it/s]Loading train:  35%|███▌      | 94/266 [00:55<01:56,  1.47it/s]Loading train:  36%|███▌      | 95/266 [00:56<01:54,  1.50it/s]Loading train:  36%|███▌      | 96/266 [00:57<01:50,  1.53it/s]Loading train:  36%|███▋      | 97/266 [00:57<01:47,  1.57it/s]Loading train:  37%|███▋      | 98/266 [00:58<01:46,  1.58it/s]Loading train:  37%|███▋      | 99/266 [00:58<01:43,  1.61it/s]Loading train:  38%|███▊      | 100/266 [00:59<01:43,  1.61it/s]Loading train:  38%|███▊      | 101/266 [01:00<01:40,  1.64it/s]Loading train:  38%|███▊      | 102/266 [01:00<01:39,  1.65it/s]Loading train:  39%|███▊      | 103/266 [01:01<01:38,  1.65it/s]Loading train:  39%|███▉      | 104/266 [01:01<01:35,  1.69it/s]Loading train:  39%|███▉      | 105/266 [01:02<01:34,  1.70it/s]Loading train:  40%|███▉      | 106/266 [01:03<01:34,  1.69it/s]Loading train:  40%|████      | 107/266 [01:03<01:34,  1.68it/s]Loading train:  41%|████      | 108/266 [01:04<01:32,  1.71it/s]Loading train:  41%|████      | 109/266 [01:04<01:33,  1.68it/s]Loading train:  41%|████▏     | 110/266 [01:05<01:32,  1.69it/s]Loading train:  42%|████▏     | 111/266 [01:06<01:31,  1.70it/s]Loading train:  42%|████▏     | 112/266 [01:06<01:29,  1.72it/s]Loading train:  42%|████▏     | 113/266 [01:07<01:29,  1.71it/s]Loading train:  43%|████▎     | 114/266 [01:07<01:29,  1.70it/s]Loading train:  43%|████▎     | 115/266 [01:08<01:30,  1.67it/s]Loading train:  44%|████▎     | 116/266 [01:09<01:31,  1.65it/s]Loading train:  44%|████▍     | 117/266 [01:09<01:29,  1.67it/s]Loading train:  44%|████▍     | 118/266 [01:10<01:26,  1.72it/s]Loading train:  45%|████▍     | 119/266 [01:10<01:21,  1.81it/s]Loading train:  45%|████▌     | 120/266 [01:11<01:17,  1.88it/s]Loading train:  45%|████▌     | 121/266 [01:11<01:17,  1.88it/s]Loading train:  46%|████▌     | 122/266 [01:12<01:14,  1.94it/s]Loading train:  46%|████▌     | 123/266 [01:12<01:13,  1.95it/s]Loading train:  47%|████▋     | 124/266 [01:13<01:12,  1.95it/s]Loading train:  47%|████▋     | 125/266 [01:13<01:11,  1.96it/s]Loading train:  47%|████▋     | 126/266 [01:14<01:10,  1.98it/s]Loading train:  48%|████▊     | 127/266 [01:14<01:10,  1.98it/s]Loading train:  48%|████▊     | 128/266 [01:15<01:09,  2.00it/s]Loading train:  48%|████▊     | 129/266 [01:15<01:08,  1.99it/s]Loading train:  49%|████▉     | 130/266 [01:16<01:07,  2.01it/s]Loading train:  49%|████▉     | 131/266 [01:16<01:07,  2.01it/s]Loading train:  50%|████▉     | 132/266 [01:17<01:06,  2.02it/s]Loading train:  50%|█████     | 133/266 [01:17<01:05,  2.02it/s]Loading train:  50%|█████     | 134/266 [01:18<01:05,  2.03it/s]Loading train:  51%|█████     | 135/266 [01:18<01:04,  2.04it/s]Loading train:  51%|█████     | 136/266 [01:19<01:04,  2.02it/s]Loading train:  52%|█████▏    | 137/266 [01:19<01:03,  2.03it/s]Loading train:  52%|█████▏    | 138/266 [01:20<01:02,  2.05it/s]Loading train:  52%|█████▏    | 139/266 [01:20<01:02,  2.04it/s]Loading train:  53%|█████▎    | 140/266 [01:21<01:00,  2.07it/s]Loading train:  53%|█████▎    | 141/266 [01:21<01:00,  2.08it/s]Loading train:  53%|█████▎    | 142/266 [01:21<00:59,  2.08it/s]Loading train:  54%|█████▍    | 143/266 [01:22<00:59,  2.08it/s]Loading train:  54%|█████▍    | 144/266 [01:22<00:58,  2.10it/s]Loading train:  55%|█████▍    | 145/266 [01:23<00:57,  2.10it/s]Loading train:  55%|█████▍    | 146/266 [01:23<00:57,  2.10it/s]Loading train:  55%|█████▌    | 147/266 [01:24<00:56,  2.10it/s]Loading train:  56%|█████▌    | 148/266 [01:24<00:55,  2.11it/s]Loading train:  56%|█████▌    | 149/266 [01:25<00:55,  2.10it/s]Loading train:  56%|█████▋    | 150/266 [01:25<00:54,  2.12it/s]Loading train:  57%|█████▋    | 151/266 [01:26<00:54,  2.11it/s]Loading train:  57%|█████▋    | 152/266 [01:26<00:54,  2.09it/s]Loading train:  58%|█████▊    | 153/266 [01:27<00:53,  2.10it/s]Loading train:  58%|█████▊    | 154/266 [01:27<00:59,  1.88it/s]Loading train:  58%|█████▊    | 155/266 [01:28<01:01,  1.80it/s]Loading train:  59%|█████▊    | 156/266 [01:29<01:03,  1.74it/s]Loading train:  59%|█████▉    | 157/266 [01:29<01:03,  1.71it/s]Loading train:  59%|█████▉    | 158/266 [01:30<01:02,  1.72it/s]Loading train:  60%|█████▉    | 159/266 [01:30<01:02,  1.71it/s]Loading train:  60%|██████    | 160/266 [01:31<01:01,  1.72it/s]Loading train:  61%|██████    | 161/266 [01:32<01:01,  1.71it/s]Loading train:  61%|██████    | 162/266 [01:32<01:01,  1.69it/s]Loading train:  61%|██████▏   | 163/266 [01:33<01:00,  1.69it/s]Loading train:  62%|██████▏   | 164/266 [01:33<01:00,  1.70it/s]Loading train:  62%|██████▏   | 165/266 [01:34<00:59,  1.69it/s]Loading train:  62%|██████▏   | 166/266 [01:35<00:59,  1.68it/s]Loading train:  63%|██████▎   | 167/266 [01:35<01:00,  1.63it/s]Loading train:  63%|██████▎   | 168/266 [01:36<00:59,  1.64it/s]Loading train:  64%|██████▎   | 169/266 [01:36<00:57,  1.67it/s]Loading train:  64%|██████▍   | 170/266 [01:37<00:57,  1.68it/s]Loading train:  64%|██████▍   | 171/266 [01:38<00:56,  1.68it/s]Loading train:  65%|██████▍   | 172/266 [01:38<01:02,  1.50it/s]Loading train:  65%|██████▌   | 173/266 [01:39<01:09,  1.34it/s]Loading train:  65%|██████▌   | 174/266 [01:40<01:10,  1.30it/s]Loading train:  66%|██████▌   | 175/266 [01:41<01:07,  1.35it/s]Loading train:  66%|██████▌   | 176/266 [01:42<01:07,  1.32it/s]Loading train:  67%|██████▋   | 177/266 [01:42<01:01,  1.44it/s]Loading train:  67%|██████▋   | 178/266 [01:43<00:57,  1.53it/s]Loading train:  67%|██████▋   | 179/266 [01:43<00:53,  1.62it/s]Loading train:  68%|██████▊   | 180/266 [01:44<00:50,  1.69it/s]Loading train:  68%|██████▊   | 181/266 [01:44<00:49,  1.73it/s]Loading train:  68%|██████▊   | 182/266 [01:45<00:47,  1.77it/s]Loading train:  69%|██████▉   | 183/266 [01:45<00:46,  1.79it/s]Loading train:  69%|██████▉   | 184/266 [01:46<00:45,  1.79it/s]Loading train:  70%|██████▉   | 185/266 [01:47<00:45,  1.79it/s]Loading train:  70%|██████▉   | 186/266 [01:47<00:44,  1.79it/s]Loading train:  70%|███████   | 187/266 [01:48<00:44,  1.79it/s]Loading train:  71%|███████   | 188/266 [01:48<00:43,  1.78it/s]Loading train:  71%|███████   | 189/266 [01:49<00:42,  1.80it/s]Loading train:  71%|███████▏  | 190/266 [01:49<00:43,  1.77it/s]Loading train:  72%|███████▏  | 191/266 [01:50<00:42,  1.78it/s]Loading train:  72%|███████▏  | 192/266 [01:50<00:41,  1.79it/s]Loading train:  73%|███████▎  | 193/266 [01:51<00:40,  1.79it/s]Loading train:  73%|███████▎  | 194/266 [01:52<00:40,  1.77it/s]Loading train:  73%|███████▎  | 195/266 [01:52<00:42,  1.68it/s]Loading train:  74%|███████▎  | 196/266 [01:53<00:41,  1.68it/s]Loading train:  74%|███████▍  | 197/266 [01:53<00:40,  1.68it/s]Loading train:  74%|███████▍  | 198/266 [01:54<00:40,  1.67it/s]Loading train:  75%|███████▍  | 199/266 [01:55<00:40,  1.66it/s]Loading train:  75%|███████▌  | 200/266 [01:55<00:39,  1.65it/s]Loading train:  76%|███████▌  | 201/266 [01:56<00:38,  1.68it/s]Loading train:  76%|███████▌  | 202/266 [01:56<00:37,  1.71it/s]Loading train:  76%|███████▋  | 203/266 [01:57<00:36,  1.71it/s]Loading train:  77%|███████▋  | 204/266 [01:58<00:36,  1.72it/s]Loading train:  77%|███████▋  | 205/266 [01:58<00:36,  1.69it/s]Loading train:  77%|███████▋  | 206/266 [01:59<00:35,  1.69it/s]Loading train:  78%|███████▊  | 207/266 [01:59<00:34,  1.69it/s]Loading train:  78%|███████▊  | 208/266 [02:00<00:33,  1.71it/s]Loading train:  79%|███████▊  | 209/266 [02:00<00:33,  1.71it/s]Loading train:  79%|███████▉  | 210/266 [02:01<00:32,  1.71it/s]Loading train:  79%|███████▉  | 211/266 [02:02<00:32,  1.71it/s]Loading train:  80%|███████▉  | 212/266 [02:02<00:31,  1.70it/s]Loading train:  80%|████████  | 213/266 [02:03<00:31,  1.69it/s]Loading train:  80%|████████  | 214/266 [02:03<00:30,  1.69it/s]Loading train:  81%|████████  | 215/266 [02:04<00:29,  1.74it/s]Loading train:  81%|████████  | 216/266 [02:05<00:28,  1.75it/s]Loading train:  82%|████████▏ | 217/266 [02:05<00:27,  1.78it/s]Loading train:  82%|████████▏ | 218/266 [02:06<00:27,  1.78it/s]Loading train:  82%|████████▏ | 219/266 [02:06<00:26,  1.79it/s]Loading train:  83%|████████▎ | 220/266 [02:07<00:25,  1.81it/s]Loading train:  83%|████████▎ | 221/266 [02:07<00:25,  1.79it/s]Loading train:  83%|████████▎ | 222/266 [02:08<00:24,  1.78it/s]Loading train:  84%|████████▍ | 223/266 [02:08<00:23,  1.80it/s]Loading train:  84%|████████▍ | 224/266 [02:09<00:23,  1.76it/s]Loading train:  85%|████████▍ | 225/266 [02:10<00:24,  1.69it/s]Loading train:  85%|████████▍ | 226/266 [02:10<00:23,  1.71it/s]Loading train:  85%|████████▌ | 227/266 [02:11<00:22,  1.74it/s]Loading train:  86%|████████▌ | 228/266 [02:11<00:21,  1.73it/s]Loading train:  86%|████████▌ | 229/266 [02:12<00:21,  1.72it/s]Loading train:  86%|████████▋ | 230/266 [02:13<00:21,  1.66it/s]Loading train:  87%|████████▋ | 231/266 [02:13<00:19,  1.76it/s]Loading train:  87%|████████▋ | 232/266 [02:14<00:18,  1.87it/s]Loading train:  88%|████████▊ | 233/266 [02:14<00:17,  1.91it/s]Loading train:  88%|████████▊ | 234/266 [02:15<00:16,  1.97it/s]Loading train:  88%|████████▊ | 235/266 [02:15<00:15,  1.99it/s]Loading train:  89%|████████▊ | 236/266 [02:15<00:14,  2.03it/s]Loading train:  89%|████████▉ | 237/266 [02:16<00:15,  1.88it/s]Loading train:  89%|████████▉ | 238/266 [02:17<00:17,  1.58it/s]Loading train:  90%|████████▉ | 239/266 [02:18<00:18,  1.44it/s]Loading train:  90%|█████████ | 240/266 [02:19<00:18,  1.37it/s]Loading train:  91%|█████████ | 241/266 [02:19<00:19,  1.31it/s]Loading train:  91%|█████████ | 242/266 [02:20<00:18,  1.27it/s]Loading train:  91%|█████████▏| 243/266 [02:21<00:18,  1.24it/s]Loading train:  92%|█████████▏| 244/266 [02:22<00:18,  1.17it/s]Loading train:  92%|█████████▏| 245/266 [02:23<00:18,  1.14it/s]Loading train:  92%|█████████▏| 246/266 [02:24<00:17,  1.13it/s]Loading train:  93%|█████████▎| 247/266 [02:25<00:17,  1.10it/s]Loading train:  93%|█████████▎| 248/266 [02:26<00:16,  1.10it/s]Loading train:  94%|█████████▎| 249/266 [02:28<00:23,  1.37s/it]Loading train:  94%|█████████▍| 250/266 [02:31<00:29,  1.87s/it]Loading train:  94%|█████████▍| 251/266 [02:34<00:33,  2.22s/it]Loading train:  95%|█████████▍| 252/266 [02:38<00:35,  2.55s/it]Loading train:  95%|█████████▌| 253/266 [02:41<00:34,  2.68s/it]Loading train:  95%|█████████▌| 254/266 [02:43<00:32,  2.71s/it]Loading train:  96%|█████████▌| 255/266 [02:46<00:30,  2.77s/it]Loading train:  96%|█████████▌| 256/266 [02:49<00:28,  2.80s/it]Loading train:  97%|█████████▋| 257/266 [02:52<00:25,  2.79s/it]Loading train:  97%|█████████▋| 258/266 [02:55<00:22,  2.80s/it]Loading train:  97%|█████████▋| 259/266 [02:58<00:19,  2.78s/it]Loading train:  98%|█████████▊| 260/266 [03:00<00:16,  2.71s/it]Loading train:  98%|█████████▊| 261/266 [03:03<00:13,  2.68s/it]Loading train:  98%|█████████▊| 262/266 [03:05<00:10,  2.62s/it]Loading train:  99%|█████████▉| 263/266 [03:08<00:07,  2.61s/it]Loading train:  99%|█████████▉| 264/266 [03:10<00:05,  2.57s/it]Loading train: 100%|█████████▉| 265/266 [03:13<00:02,  2.63s/it]Loading train: 100%|██████████| 266/266 [03:16<00:00,  2.61s/it]Loading train: 100%|██████████| 266/266 [03:16<00:00,  1.36it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:04, 52.83it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:04, 52.34it/s]concatenating: train:   6%|▋         | 17/266 [00:00<00:04, 51.35it/s]concatenating: train:   8%|▊         | 22/266 [00:00<00:04, 50.68it/s]concatenating: train:  11%|█         | 28/266 [00:00<00:04, 50.42it/s]concatenating: train:  12%|█▏        | 33/266 [00:00<00:04, 50.12it/s]concatenating: train:  14%|█▍        | 38/266 [00:00<00:04, 47.62it/s]concatenating: train:  17%|█▋        | 44/266 [00:00<00:04, 49.41it/s]concatenating: train:  19%|█▉        | 50/266 [00:00<00:04, 50.83it/s]concatenating: train:  21%|██        | 56/266 [00:01<00:04, 52.44it/s]concatenating: train:  23%|██▎       | 62/266 [00:01<00:03, 51.35it/s]concatenating: train:  26%|██▌       | 68/266 [00:01<00:03, 50.70it/s]concatenating: train:  28%|██▊       | 74/266 [00:01<00:03, 51.46it/s]concatenating: train:  30%|███       | 80/266 [00:01<00:03, 50.94it/s]concatenating: train:  32%|███▏      | 86/266 [00:01<00:03, 49.83it/s]concatenating: train:  34%|███▍      | 91/266 [00:01<00:03, 48.93it/s]concatenating: train:  36%|███▌      | 96/266 [00:01<00:03, 48.59it/s]concatenating: train:  38%|███▊      | 101/266 [00:02<00:03, 48.33it/s]concatenating: train:  40%|███▉      | 106/266 [00:02<00:03, 48.80it/s]concatenating: train:  42%|████▏     | 111/266 [00:02<00:03, 49.14it/s]concatenating: train:  44%|████▍     | 117/266 [00:02<00:03, 49.58it/s]concatenating: train:  46%|████▌     | 123/266 [00:02<00:02, 51.13it/s]concatenating: train:  48%|████▊     | 129/266 [00:02<00:02, 51.96it/s]concatenating: train:  51%|█████     | 135/266 [00:02<00:02, 52.26it/s]concatenating: train:  53%|█████▎    | 141/266 [00:02<00:02, 52.87it/s]concatenating: train:  55%|█████▌    | 147/266 [00:02<00:02, 53.86it/s]concatenating: train:  58%|█████▊    | 153/266 [00:02<00:02, 54.17it/s]concatenating: train:  60%|█████▉    | 159/266 [00:03<00:02, 51.67it/s]concatenating: train:  62%|██████▏   | 165/266 [00:03<00:01, 50.66it/s]concatenating: train:  64%|██████▍   | 171/266 [00:03<00:01, 50.53it/s]concatenating: train:  67%|██████▋   | 177/266 [00:03<00:01, 50.64it/s]concatenating: train:  69%|██████▉   | 183/266 [00:03<00:01, 50.35it/s]concatenating: train:  71%|███████   | 189/266 [00:03<00:01, 49.81it/s]concatenating: train:  73%|███████▎  | 194/266 [00:03<00:01, 49.03it/s]concatenating: train:  75%|███████▍  | 199/266 [00:03<00:01, 48.31it/s]concatenating: train:  77%|███████▋  | 204/266 [00:04<00:01, 47.64it/s]concatenating: train:  79%|███████▊  | 209/266 [00:04<00:01, 45.23it/s]concatenating: train:  80%|████████  | 214/266 [00:04<00:01, 44.10it/s]concatenating: train:  82%|████████▏ | 219/266 [00:04<00:01, 43.71it/s]concatenating: train:  84%|████████▍ | 224/266 [00:04<00:00, 43.57it/s]concatenating: train:  86%|████████▌ | 229/266 [00:04<00:00, 43.65it/s]concatenating: train:  88%|████████▊ | 234/266 [00:04<00:00, 43.75it/s]concatenating: train:  90%|████████▉ | 239/266 [00:04<00:00, 43.86it/s]concatenating: train:  92%|█████████▏| 244/266 [00:04<00:00, 43.65it/s]concatenating: train:  94%|█████████▎| 249/266 [00:05<00:00, 43.39it/s]concatenating: train:  95%|█████████▌| 254/266 [00:05<00:00, 43.22it/s]concatenating: train:  97%|█████████▋| 259/266 [00:05<00:00, 42.51it/s]concatenating: train:  99%|█████████▉| 264/266 [00:05<00:00, 42.41it/s]concatenating: train: 100%|██████████| 266/266 [00:05<00:00, 48.29it/s]
Loading test:   0%|          | 0/4 [00:00<?, ?it/s]Loading test:  25%|██▌       | 1/4 [00:07<00:22,  7.54s/it]Loading test:  50%|█████     | 2/4 [00:12<00:13,  6.81s/it]Loading test:  75%|███████▌  | 3/4 [00:16<00:06,  6.06s/it]Loading test: 100%|██████████| 4/4 [00:29<00:00,  8.01s/it]Loading test: 100%|██████████| 4/4 [00:29<00:00,  7.38s/it]
concatenating: validation:   0%|          | 0/4 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 4/4 [00:00<00:00, 53.26it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 4  | SD 2  | Dropout 0.5  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      2020-01-22 09:48:26.071282: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1511] Adding visible gpu devices: 0
2020-01-22 09:48:26.071383: I tensorflow/core/common_runtime/gpu/gpu_device.cc:982] Device interconnect StreamExecutor with strength 1 edge matrix:
2020-01-22 09:48:26.071399: I tensorflow/core/common_runtime/gpu/gpu_device.cc:988]      0 
2020-01-22 09:48:26.071407: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1001] 0:   N 
2020-01-22 09:48:26.071688: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1115] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15117 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:84:00.0, compute capability: 6.0)

__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 223,033
Non-trainable params: 800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.83834942e-02 3.27995793e-02 8.45376338e-02 1.02669015e-02
 2.87989434e-02 7.66888297e-03 8.68295901e-02 1.12945439e-01
 9.17079452e-02 1.37618982e-02 2.77001192e-01 1.85043957e-01
 2.54543577e-04]
Train on 9809 samples, validate on 144 samples
Epoch 1/300
 - 27s - loss: 0.6635 - acc: 0.8769 - mDice: 0.2854 - val_loss: 0.6556 - val_acc: 0.9244 - val_mDice: 0.2928

Epoch 00001: val_mDice improved from -inf to 0.29279, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 2/300
 - 21s - loss: 0.4563 - acc: 0.9257 - mDice: 0.5087 - val_loss: 0.6238 - val_acc: 0.9345 - val_mDice: 0.3206

Epoch 00002: val_mDice improved from 0.29279 to 0.32062, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 3/300
 - 21s - loss: 0.4028 - acc: 0.9325 - mDice: 0.5665 - val_loss: 0.6006 - val_acc: 0.9452 - val_mDice: 0.3277

Epoch 00003: val_mDice improved from 0.32062 to 0.32771, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 4/300
 - 22s - loss: 0.3789 - acc: 0.9360 - mDice: 0.5922 - val_loss: 0.5614 - val_acc: 0.9449 - val_mDice: 0.3408

Epoch 00004: val_mDice improved from 0.32771 to 0.34084, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 5/300
 - 21s - loss: 0.3602 - acc: 0.9384 - mDice: 0.6125 - val_loss: 0.5299 - val_acc: 0.9494 - val_mDice: 0.3355

Epoch 00005: val_mDice did not improve from 0.34084
Epoch 6/300
 - 22s - loss: 0.3516 - acc: 0.9399 - mDice: 0.6217 - val_loss: 0.4877 - val_acc: 0.9475 - val_mDice: 0.3346

Epoch 00006: val_mDice did not improve from 0.34084
Epoch 7/300
 - 20s - loss: 0.3455 - acc: 0.9409 - mDice: 0.6282 - val_loss: 0.5395 - val_acc: 0.9448 - val_mDice: 0.3426

Epoch 00007: val_mDice improved from 0.34084 to 0.34257, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 8/300
 - 21s - loss: 0.3392 - acc: 0.9420 - mDice: 0.6351 - val_loss: 0.3978 - val_acc: 0.9481 - val_mDice: 0.3490

Epoch 00008: val_mDice improved from 0.34257 to 0.34904, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 9/300
 - 21s - loss: 0.3318 - acc: 0.9430 - mDice: 0.6430 - val_loss: 0.4664 - val_acc: 0.9492 - val_mDice: 0.3456

Epoch 00009: val_mDice did not improve from 0.34904
Epoch 10/300
 - 22s - loss: 0.3248 - acc: 0.9436 - mDice: 0.6505 - val_loss: 0.3099 - val_acc: 0.9500 - val_mDice: 0.3505

Epoch 00010: val_mDice improved from 0.34904 to 0.35054, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 11/300
 - 21s - loss: 0.3192 - acc: 0.9444 - mDice: 0.6566 - val_loss: 0.3500 - val_acc: 0.9500 - val_mDice: 0.3494

Epoch 00011: val_mDice did not improve from 0.35054
Epoch 12/300
 - 21s - loss: 0.3182 - acc: 0.9447 - mDice: 0.6576 - val_loss: 0.2784 - val_acc: 0.9512 - val_mDice: 0.3395

Epoch 00012: val_mDice did not improve from 0.35054
Epoch 13/300
 - 21s - loss: 0.3144 - acc: 0.9452 - mDice: 0.6617 - val_loss: 0.2065 - val_acc: 0.9481 - val_mDice: 0.3535

Epoch 00013: val_mDice improved from 0.35054 to 0.35351, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_lr0.001_CSFn2_NoInit_wBiasCorrection_CV_d/MultiClass_24567891011121314/sd2/best_model_weights.h5
Epoch 14/300
 - 21s - loss: 0.3110 - acc: 0.9454 - mDice: 0.6654 - val_loss: 0.2468 - val_acc: 0.9499 - val_mDice: 0.3411

Epoch 00014: val_mDice did not improve from 0.35351
Epoch 15/300
 - 21s - loss: 0.3062 - acc: 0.9461 - mDice: 0.6706 - val_loss: 0.1947 - val_acc: 0.9512 - val_mDice: 0.3511

Epoch 00015: val_mDice did not improve from 0.35351
Epoch 16/300
 - 21s - loss: 0.3044 - acc: 0.9463 - mDice: 0.6725 - val_loss: 0.2095 - val_acc: 0.9467 - val_mDice: 0.3138

Epoch 00016: val_mDice did not improve from 0.35351
Epoch 17/300
 - 21s - loss: 0.2992 - acc: 0.9468 - mDice: 0.6781 - val_loss: 0.2713 - val_acc: 0.9477 - val_mDice: 0.3369

Epoch 00017: val_mDice did not improve from 0.35351
Epoch 18/300
 - 22s - loss: 0.2979 - acc: 0.9472 - mDice: 0.6796 - val_loss: 0.2301 - val_acc: 0.9510 - val_mDice: 0.3332

Epoch 00018: val_mDice did not improve from 0.35351
Epoch 19/300
 - 21s - loss: 0.2980 - acc: 0.9472 - mDice: 0.6794 - val_loss: 0.1756 - val_acc: 0.9486 - val_mDice: 0.3391

Epoch 00019: val_mDice did not improve from 0.35351
Epoch 20/300
 - 21s - loss: 0.2946 - acc: 0.9474 - mDice: 0.6831 - val_loss: 0.1830 - val_acc: 0.9491 - val_mDice: 0.3517

Epoch 00020: val_mDice did not improve from 0.35351
Epoch 21/300
 - 21s - loss: 0.2964 - acc: 0.9476 - mDice: 0.6811 - val_loss: 0.1895 - val_acc: 0.9492 - val_mDice: 0.3381

Epoch 00021: val_mDice did not improve from 0.35351
Epoch 22/300
 - 22s - loss: 0.2933 - acc: 0.9478 - mDice: 0.6845 - val_loss: 0.1633 - val_acc: 0.9507 - val_mDice: 0.3386

Epoch 00022: val_mDice did not improve from 0.35351
Epoch 23/300
 - 21s - loss: 0.2883 - acc: 0.9483 - mDice: 0.6899 - val_loss: 0.1785 - val_acc: 0.9497 - val_mDice: 0.3446

Epoch 00023: val_mDice did not improve from 0.35351
Epoch 24/300
 - 21s - loss: 0.2906 - acc: 0.9481 - mDice: 0.6874 - val_loss: 0.2807 - val_acc: 0.9447 - val_mDice: 0.3358

Epoch 00024: val_mDice did not improve from 0.35351
Epoch 25/300
 - 21s - loss: 0.2874 - acc: 0.9487 - mDice: 0.6909 - val_loss: 0.1125 - val_acc: 0.9497 - val_mDice: 0.3438

Epoch 00025: val_mDice did not improve from 0.35351
Epoch 26/300
 - 21s - loss: 0.2864 - acc: 0.9488 - mDice: 0.6919 - val_loss: 0.1960 - val_acc: 0.9482 - val_mDice: 0.3451

Epoch 00026: val_mDice did not improve from 0.35351
Epoch 27/300
 - 21s - loss: 0.2885 - acc: 0.9486 - mDice: 0.6897 - val_loss: 0.1576 - val_acc: 0.9485 - val_mDice: 0.3343

Epoch 00027: val_mDice did not improve from 0.35351
Epoch 28/300
 - 22s - loss: 0.2834 - acc: 0.9491 - mDice: 0.6951 - val_loss: 0.1366 - val_acc: 0.9498 - val_mDice: 0.3509

Epoch 00028: val_mDice did not improve from 0.35351

Epoch 00028: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 29/300
 - 22s - loss: 0.2754 - acc: 0.9502 - mDice: 0.7038 - val_loss: 0.1763 - val_acc: 0.9492 - val_mDice: 0.3490

Epoch 00029: val_mDice did not improve from 0.35351
Epoch 30/300
 - 21s - loss: 0.2717 - acc: 0.9507 - mDice: 0.7078 - val_loss: 0.0548 - val_acc: 0.9515 - val_mDice: 0.3443

Epoch 00030: val_mDice did not improve from 0.35351
Epoch 31/300
 - 21s - loss: 0.2693 - acc: 0.9507 - mDice: 0.7104 - val_loss: 0.0978 - val_acc: 0.9503 - val_mDice: 0.3383

Epoch 00031: val_mDice did not improve from 0.35351
Epoch 32/300
 - 21s - loss: 0.2690 - acc: 0.9509 - mDice: 0.7107 - val_loss: 0.0935 - val_acc: 0.9509 - val_mDice: 0.3319

Epoch 00032: val_mDice did not improve from 0.35351
Epoch 33/300
 - 21s - loss: 0.2680 - acc: 0.9508 - mDice: 0.7118 - val_loss: 0.0901 - val_acc: 0.9518 - val_mDice: 0.3527

Epoch 00033: val_mDice did not improve from 0.35351
Epoch 34/300
 - 21s - loss: 0.2673 - acc: 0.9512 - mDice: 0.7125 - val_loss: 0.0974 - val_acc: 0.9510 - val_mDice: 0.3466

Epoch 00034: val_mDice did not improve from 0.35351
Epoch 35/300
 - 21s - loss: 0.2659 - acc: 0.9513 - mDice: 0.7141 - val_loss: 0.0438 - val_acc: 0.9493 - val_mDice: 0.3201

Epoch 00035: val_mDice did not improve from 0.35351
Epoch 36/300
 - 20s - loss: 0.2642 - acc: 0.9514 - mDice: 0.7159 - val_loss: 0.0764 - val_acc: 0.9497 - val_mDice: 0.3424

Epoch 00036: val_mDice did not improve from 0.35351
Epoch 37/300
 - 20s - loss: 0.2637 - acc: 0.9514 - mDice: 0.7165 - val_loss: 0.1065 - val_acc: 0.9500 - val_mDice: 0.3372

Epoch 00037: val_mDice did not improve from 0.35351
Epoch 38/300
 - 21s - loss: 0.2609 - acc: 0.9515 - mDice: 0.7195 - val_loss: 0.1324 - val_acc: 0.9485 - val_mDice: 0.3324

Epoch 00038: val_mDice did not improve from 0.35351
Epoch 39/300
 - 21s - loss: 0.2614 - acc: 0.9517 - mDice: 0.7189 - val_loss: 0.0484 - val_acc: 0.9511 - val_mDice: 0.3382

Epoch 00039: val_mDice did not improve from 0.35351
Epoch 40/300
 - 21s - loss: 0.2626 - acc: 0.9518 - mDice: 0.7176 - val_loss: 0.1115 - val_acc: 0.9509 - val_mDice: 0.3421

Epoch 00040: val_mDice did not improve from 0.35351
Epoch 41/300
 - 20s - loss: 0.2619 - acc: 0.9518 - mDice: 0.7184 - val_loss: 0.0630 - val_acc: 0.9511 - val_mDice: 0.3374

Epoch 00041: val_mDice did not improve from 0.35351
Epoch 42/300
 - 21s - loss: 0.2615 - acc: 0.9518 - mDice: 0.7188 - val_loss: 0.1275 - val_acc: 0.9502 - val_mDice: 0.3487

Epoch 00042: val_mDice did not improve from 0.35351
Epoch 43/300
 - 20s - loss: 0.2604 - acc: 0.9520 - mDice: 0.7200 - val_loss: 0.0932 - val_acc: 0.9511 - val_mDice: 0.3345

Epoch 00043: val_mDice did not improve from 0.35351

Epoch 00043: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 44/300
 - 21s - loss: 0.2545 - acc: 0.9525 - mDice: 0.7263 - val_loss: 0.1018 - val_acc: 0.9515 - val_mDice: 0.3469

Epoch 00044: val_mDice did not improve from 0.35351
Epoch 45/300
 - 21s - loss: 0.2542 - acc: 0.9526 - mDice: 0.7267 - val_loss: 0.0907 - val_acc: 0.9509 - val_mDice: 0.3386

Epoch 00045: val_mDice did not improve from 0.35351
Epoch 46/300
 - 21s - loss: 0.2502 - acc: 0.9527 - mDice: 0.7310 - val_loss: 0.1085 - val_acc: 0.9505 - val_mDice: 0.3433

Epoch 00046: val_mDice did not improve from 0.35351
Epoch 47/300
 - 21s - loss: 0.2496 - acc: 0.9528 - mDice: 0.7317 - val_loss: 0.0882 - val_acc: 0.9501 - val_mDice: 0.3339

Epoch 00047: val_mDice did not improve from 0.35351
Epoch 48/300
 - 21s - loss: 0.2524 - acc: 0.9528 - mDice: 0.7286 - val_loss: 0.0911 - val_acc: 0.9504 - val_mDice: 0.3453

Epoch 00048: val_mDice did not improve from 0.35351
Epoch 49/300
 - 21s - loss: 0.2520 - acc: 0.9529 - mDice: 0.7291 - val_loss: 0.0928 - val_acc: 0.9507 - val_mDice: 0.3429

Epoch 00049: val_mDice did not improve from 0.35351
Epoch 50/300
 - 20s - loss: 0.2519 - acc: 0.9529 - mDice: 0.7292 - val_loss: 0.1021 - val_acc: 0.9512 - val_mDice: 0.3473

Epoch 00050: val_mDice did not improve from 0.35351
Epoch 51/300
 - 21s - loss: 0.2502 - acc: 0.9529 - mDice: 0.7310 - val_loss: 0.0770 - val_acc: 0.9517 - val_mDice: 0.3500

Epoch 00051: val_mDice did not improve from 0.35351
Epoch 52/300
 - 21s - loss: 0.2493 - acc: 0.9531 - mDice: 0.7320 - val_loss: 0.0736 - val_acc: 0.9514 - val_mDice: 0.3478

Epoch 00052: val_mDice did not improve from 0.35351
Epoch 53/300
 - 21s - loss: 0.2501 - acc: 0.9531 - mDice: 0.7311 - val_loss: 0.1399 - val_acc: 0.9488 - val_mDice: 0.3389

predicting test subjects:   0%|          | 0/4 [00:00<?, ?it/s]predicting test subjects:  25%|██▌       | 1/4 [00:01<00:04,  1.41s/it]predicting test subjects:  50%|█████     | 2/4 [00:02<00:02,  1.24s/it]predicting test subjects:  75%|███████▌  | 3/4 [00:03<00:01,  1.14s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.12s/it]predicting test subjects: 100%|██████████| 4/4 [00:04<00:00,  1.05s/it]cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_d/sd0/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_d/sd1/vimp*': No such file or directory
cp: cannot stat '/array/ssd/msmajdi/experiments/keras/exp6/results/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyDice_US1_wLRScheduler_CSFn2_NoInit_wBiasCorrection_CV_d/sd2/vimp*': No such file or directory

  0%|          | 0/4 [00:00<?, ?it/s] 25%|██▌       | 1/4 [00:00<00:00,  3.13it/s] 50%|█████     | 2/4 [00:00<00:00,  3.31it/s] 75%|███████▌  | 3/4 [00:00<00:00,  3.43it/s]100%|██████████| 4/4 [00:01<00:00,  3.24it/s]100%|██████████| 4/4 [00:01<00:00,  3.34it/s]

Epoch 00053: val_mDice did not improve from 0.35351
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [0.6555672693583701, 0.6238458040687773, 0.6006148383021355, 0.5614226505988174, 0.529854746742381, 0.4876648423572381, 0.5394800011482503, 0.39775442166460884, 0.46638256518377197, 0.309873769680659, 0.34997028795381385, 0.27840996807855034, 0.20654962073442423, 0.24680607610692581, 0.1946724680148893, 0.20949823166140252, 0.2713461969397031, 0.23012907585750023, 0.17562818165040678, 0.1829855480334825, 0.18945588251679307, 0.16330542953477967, 0.17854878078732225, 0.28066838222245377, 0.11249368720584446, 0.1959641199145052, 0.15762415781824124, 0.1366354242345551, 0.1763486292006241, 0.05479784752242267, 0.09784153926496704, 0.09350092916025056, 0.09014811692759395, 0.09735874769588311, 0.04378703826417526, 0.07644910586532205, 0.10653727222234011, 0.13243287048923472, 0.04842431149962875, 0.11145607970603225, 0.06299083524047294, 0.1274603280212937, 0.09320409399353796, 0.10175486328080297, 0.09068726408036633, 0.10853073916708429, 0.08816552343260911, 0.09111719052695359, 0.09281999027977388, 0.10212604732563098, 0.0769596092027819, 0.0736022022449308, 0.13994651761054733], 'val_acc': [0.92437265564998, 0.9345381218526099, 0.9452489092946053, 0.9448752966192033, 0.9493840941124492, 0.9475462403562334, 0.9448260143399239, 0.948086779150698, 0.9491615237461196, 0.9500311662753423, 0.949950081606706, 0.9511567685339186, 0.9480788384874662, 0.94987852871418, 0.9512187788883845, 0.9466893134845628, 0.9476924969090356, 0.9510105111532741, 0.9486225545406342, 0.9490804390774833, 0.9492457823620902, 0.9506925303075049, 0.9496543622679181, 0.9446686100628641, 0.9497465872102313, 0.9481901162200503, 0.9485001365343729, 0.9497751990954081, 0.9491980829172664, 0.9514524870448642, 0.9502712256378598, 0.9508976191282272, 0.9518467593524191, 0.9510295846396022, 0.9492934635943837, 0.9497227337625291, 0.9500343319442537, 0.948463568256961, 0.951113840772046, 0.9509103414085176, 0.9511424584521188, 0.9502139919333987, 0.9510645609762933, 0.9515303870042165, 0.9508992176916864, 0.9505446818139818, 0.9501138412290149, 0.9503570745388666, 0.9506988988982307, 0.9511583637860086, 0.9517466061645083, 0.9513698054684533, 0.9488038006756041], 'val_mDice': [0.2927914357019795, 0.32061990536749363, 0.32771327036122483, 0.34083872930043274, 0.3354634383900298, 0.33456162166678244, 0.3425716023064322, 0.3490386706673437, 0.34557623022960293, 0.3505376814347174, 0.3494379474884934, 0.33951439563598895, 0.35350696338961524, 0.34107147188236314, 0.35114755885054666, 0.31382512766867876, 0.3369425065401528, 0.3331821932353907, 0.33905179281201625, 0.35166526430596906, 0.3380964549465312, 0.33858362171385026, 0.3446480729099777, 0.3358415989205241, 0.3437621667981148, 0.3450909184498919, 0.33430496603250504, 0.3508625453751948, 0.3489571515884664, 0.34426044372634756, 0.3383035268634558, 0.33187001746975714, 0.35272613178110784, 0.3465746659785509, 0.320059802590145, 0.3424254378510846, 0.3372468650341034, 0.33238135940498775, 0.33816362441413933, 0.3420608549689253, 0.33741255280458265, 0.3486850256514218, 0.3345222452448474, 0.34687329414818024, 0.3386461587829722, 0.34326070381535423, 0.33385838340553975, 0.3452598768182927, 0.34290331540008384, 0.3472725184013446, 0.3499647814573513, 0.34775915183126926, 0.3388536073681381], 'loss': [0.6634506173169823, 0.4563197825149192, 0.4027955701001401, 0.3789142216822097, 0.36015913178461606, 0.35156787525247585, 0.34552440580783095, 0.3391666901696165, 0.33181624452216335, 0.324845942542244, 0.31918357446210954, 0.31823443746345587, 0.3144204079320956, 0.3110098511889047, 0.3061668637246334, 0.30443067224775083, 0.2992354570385245, 0.29785308712471126, 0.29800703969676506, 0.29461514083285956, 0.2964148893033295, 0.2932912255447931, 0.2883050493665859, 0.2906086130424892, 0.2873769323782571, 0.2864390196712973, 0.2885086793505291, 0.283431755535123, 0.27536929202731175, 0.2716628226793096, 0.26926710536592, 0.2689710921140874, 0.26795419284523003, 0.26732523477287734, 0.2658956417287328, 0.26420694453044946, 0.2636656436318347, 0.26089995879197975, 0.261354001986165, 0.26259730615003574, 0.2618772639209481, 0.2615067411427931, 0.26038824627493995, 0.25453041952822303, 0.2542284799711045, 0.25021164107242483, 0.24961771460918247, 0.2523988525167932, 0.25199491982218664, 0.25187265096831024, 0.2502007243228331, 0.24928542589093702, 0.2501129377373182], 'acc': [0.8769388406191206, 0.9256863559418976, 0.932499406309543, 0.9360417215597351, 0.9384237568195424, 0.9398611471100993, 0.9408658684387716, 0.9419725361020087, 0.943032012308807, 0.9436316055519426, 0.94439992040338, 0.944726021893346, 0.9451738602768234, 0.9454481938111574, 0.946053294653508, 0.9462855704966543, 0.9467675556817153, 0.9471565333391283, 0.9472081126490066, 0.9473837670935733, 0.9475695718949888, 0.9477590429805959, 0.9482526978302566, 0.948142722502726, 0.9487182063202766, 0.9488196393706794, 0.9486409056100389, 0.9491259943200538, 0.9501888080588271, 0.9507297946111497, 0.9507233767361679, 0.95091914924621, 0.9508199325965588, 0.9511903085734382, 0.9512998408189133, 0.9513650509678925, 0.9513868734564107, 0.9515231537920994, 0.9516624674020235, 0.9518354362286441, 0.9518224605302075, 0.9517526983400528, 0.9520023146868116, 0.9525407117032193, 0.9525634913661329, 0.9526827100074574, 0.9527847497564583, 0.9528398318737457, 0.9529436688951085, 0.9529476132411356, 0.9528615841844637, 0.9530541591231569, 0.9531494772437881], 'mDice': [0.28535103201368633, 0.508694802181037, 0.5664599629787267, 0.5922210661080868, 0.6124568247979831, 0.6217027108948072, 0.628210443266185, 0.6350609186999914, 0.6429868530140629, 0.6504947897587995, 0.6565973296273871, 0.6576110373482523, 0.6617176681498721, 0.6654159069875534, 0.6706394347068743, 0.672497549356215, 0.6781042271560213, 0.6795729625624902, 0.6794159502681212, 0.6830829797030249, 0.6811244042353086, 0.6845026202237816, 0.6898851603746584, 0.6873984808695282, 0.6908746245184711, 0.6918860211723842, 0.6896686307308882, 0.6951355746682235, 0.7038429691492812, 0.7078378374988071, 0.710431770691875, 0.7107302471577592, 0.7118454942074691, 0.7125083608405648, 0.7140590907212657, 0.7158919236919836, 0.7164843936119134, 0.7194689505325568, 0.7189499813064861, 0.717602620675107, 0.7183999340217502, 0.7187914660198388, 0.7199967263707182, 0.7263296812921626, 0.7266738013288323, 0.731016512656749, 0.7316591660659701, 0.7286435621559395, 0.7290743869286038, 0.7292063288616227, 0.7310166155809485, 0.7320015480460249, 0.7311010147796297], 'lr': [0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.0005, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025, 0.00025]}
CrossVal ['d']
