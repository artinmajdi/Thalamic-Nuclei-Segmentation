2019-08-17 16:59:42.746982: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-08-17 16:59:43.092867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:04:00.0
totalMemory: 15.89GiB freeMemory: 14.95GiB
2019-08-17 16:59:43.092923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 16:59:43.643114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 16:59:43.643180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 16:59:43.643195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 16:59:43.643798: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14485 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<06:12,  1.41s/it]Loading train:   1%|          | 2/266 [00:02<05:44,  1.31s/it]Loading train:   1%|          | 3/266 [00:03<05:06,  1.16s/it]Loading train:   2%|▏         | 4/266 [00:04<04:40,  1.07s/it]Loading train:   2%|▏         | 5/266 [00:05<04:54,  1.13s/it]Loading train:   2%|▏         | 6/266 [00:06<04:55,  1.14s/it]Loading train:   3%|▎         | 7/266 [00:07<04:59,  1.16s/it]Loading train:   3%|▎         | 8/266 [00:08<05:00,  1.16s/it]Loading train:   3%|▎         | 9/266 [00:09<04:36,  1.07s/it]Loading train:   4%|▍         | 10/266 [00:10<04:14,  1.01it/s]Loading train:   4%|▍         | 11/266 [00:12<04:42,  1.11s/it]Loading train:   5%|▍         | 12/266 [00:13<04:47,  1.13s/it]Loading train:   5%|▍         | 13/266 [00:14<05:17,  1.26s/it]Loading train:   5%|▌         | 14/266 [00:16<05:39,  1.35s/it]Loading train:   6%|▌         | 15/266 [00:17<05:27,  1.31s/it]Loading train:   6%|▌         | 16/266 [00:18<05:15,  1.26s/it]Loading train:   6%|▋         | 17/266 [00:19<05:07,  1.23s/it]Loading train:   7%|▋         | 18/266 [00:21<05:51,  1.42s/it]Loading train:   7%|▋         | 19/266 [00:23<05:48,  1.41s/it]Loading train:   8%|▊         | 20/266 [00:24<05:40,  1.39s/it]Loading train:   8%|▊         | 21/266 [00:26<05:59,  1.47s/it]Loading train:   8%|▊         | 22/266 [00:27<05:56,  1.46s/it]Loading train:   9%|▊         | 23/266 [00:29<06:08,  1.52s/it]Loading train:   9%|▉         | 24/266 [00:30<06:00,  1.49s/it]Loading train:   9%|▉         | 25/266 [00:32<06:08,  1.53s/it]Loading train:  10%|▉         | 26/266 [00:33<05:57,  1.49s/it]Loading train:  10%|█         | 27/266 [00:35<05:50,  1.47s/it]Loading train:  11%|█         | 28/266 [00:36<05:40,  1.43s/it]Loading train:  11%|█         | 29/266 [00:37<05:50,  1.48s/it]Loading train:  11%|█▏        | 30/266 [00:39<05:48,  1.47s/it]Loading train:  12%|█▏        | 31/266 [00:40<05:50,  1.49s/it]Loading train:  12%|█▏        | 32/266 [00:42<05:49,  1.49s/it]Loading train:  12%|█▏        | 33/266 [00:43<05:14,  1.35s/it]Loading train:  13%|█▎        | 34/266 [00:44<04:47,  1.24s/it]Loading train:  13%|█▎        | 35/266 [00:45<05:02,  1.31s/it]Loading train:  14%|█▎        | 36/266 [00:47<05:12,  1.36s/it]Loading train:  14%|█▍        | 37/266 [00:48<05:20,  1.40s/it]Loading train:  14%|█▍        | 38/266 [00:50<05:34,  1.47s/it]Loading train:  15%|█▍        | 39/266 [00:52<05:48,  1.54s/it]Loading train:  15%|█▌        | 40/266 [00:53<05:50,  1.55s/it]Loading train:  15%|█▌        | 41/266 [00:55<05:49,  1.56s/it]Loading train:  16%|█▌        | 42/266 [00:57<05:56,  1.59s/it]Loading train:  16%|█▌        | 43/266 [00:58<05:14,  1.41s/it]Loading train:  17%|█▋        | 44/266 [00:59<05:18,  1.43s/it]Loading train:  17%|█▋        | 45/266 [01:01<05:21,  1.45s/it]Loading train:  17%|█▋        | 46/266 [01:02<05:28,  1.49s/it]Loading train:  18%|█▊        | 47/266 [01:03<05:00,  1.37s/it]Loading train:  18%|█▊        | 48/266 [01:04<04:43,  1.30s/it]Loading train:  18%|█▊        | 49/266 [01:06<04:45,  1.32s/it]Loading train:  19%|█▉        | 50/266 [01:07<04:50,  1.34s/it]Loading train:  19%|█▉        | 51/266 [01:08<04:06,  1.15s/it]Loading train:  20%|█▉        | 52/266 [01:09<04:28,  1.26s/it]Loading train:  20%|█▉        | 53/266 [01:10<04:16,  1.20s/it]Loading train:  20%|██        | 54/266 [01:12<04:49,  1.36s/it]Loading train:  21%|██        | 55/266 [01:14<05:00,  1.42s/it]Loading train:  21%|██        | 56/266 [01:15<04:35,  1.31s/it]Loading train:  21%|██▏       | 57/266 [01:16<04:18,  1.24s/it]Loading train:  22%|██▏       | 58/266 [01:17<04:16,  1.23s/it]Loading train:  22%|██▏       | 59/266 [01:19<04:33,  1.32s/it]Loading train:  23%|██▎       | 60/266 [01:20<04:59,  1.46s/it]Loading train:  23%|██▎       | 61/266 [01:22<05:12,  1.53s/it]Loading train:  23%|██▎       | 62/266 [01:24<05:15,  1.55s/it]Loading train:  24%|██▎       | 63/266 [01:25<05:31,  1.63s/it]Loading train:  24%|██▍       | 64/266 [01:27<05:29,  1.63s/it]Loading train:  24%|██▍       | 65/266 [01:28<05:13,  1.56s/it]Loading train:  25%|██▍       | 66/266 [01:30<05:05,  1.53s/it]Loading train:  25%|██▌       | 67/266 [01:31<04:59,  1.50s/it]Loading train:  26%|██▌       | 68/266 [01:33<05:03,  1.54s/it]Loading train:  26%|██▌       | 69/266 [01:34<04:52,  1.48s/it]Loading train:  26%|██▋       | 70/266 [01:35<04:24,  1.35s/it]Loading train:  27%|██▋       | 71/266 [01:37<04:33,  1.40s/it]Loading train:  27%|██▋       | 72/266 [01:38<04:30,  1.40s/it]Loading train:  27%|██▋       | 73/266 [01:39<04:18,  1.34s/it]Loading train:  28%|██▊       | 74/266 [01:41<04:26,  1.39s/it]Loading train:  28%|██▊       | 75/266 [01:42<04:25,  1.39s/it]Loading train:  29%|██▊       | 76/266 [01:44<04:14,  1.34s/it]Loading train:  29%|██▉       | 77/266 [01:45<04:14,  1.35s/it]Loading train:  29%|██▉       | 78/266 [01:46<04:19,  1.38s/it]Loading train:  30%|██▉       | 79/266 [01:48<04:11,  1.34s/it]Loading train:  30%|███       | 80/266 [01:49<04:06,  1.33s/it]Loading train:  30%|███       | 81/266 [01:50<04:08,  1.34s/it]Loading train:  31%|███       | 82/266 [01:52<04:19,  1.41s/it]Loading train:  31%|███       | 83/266 [01:53<04:12,  1.38s/it]Loading train:  32%|███▏      | 84/266 [01:55<04:17,  1.42s/it]Loading train:  32%|███▏      | 85/266 [01:56<04:09,  1.38s/it]Loading train:  32%|███▏      | 86/266 [01:57<04:02,  1.35s/it]Loading train:  33%|███▎      | 87/266 [01:59<04:03,  1.36s/it]Loading train:  33%|███▎      | 88/266 [02:00<04:10,  1.41s/it]Loading train:  33%|███▎      | 89/266 [02:02<04:12,  1.43s/it]Loading train:  34%|███▍      | 90/266 [02:03<04:04,  1.39s/it]Loading train:  34%|███▍      | 91/266 [02:04<03:47,  1.30s/it]Loading train:  35%|███▍      | 92/266 [02:05<03:53,  1.34s/it]Loading train:  35%|███▍      | 93/266 [02:07<03:56,  1.37s/it]Loading train:  35%|███▌      | 94/266 [02:08<03:49,  1.33s/it]Loading train:  36%|███▌      | 95/266 [02:10<03:56,  1.38s/it]Loading train:  36%|███▌      | 96/266 [02:11<04:03,  1.43s/it]Loading train:  36%|███▋      | 97/266 [02:13<04:18,  1.53s/it]Loading train:  37%|███▋      | 98/266 [02:14<04:06,  1.47s/it]Loading train:  37%|███▋      | 99/266 [02:16<03:53,  1.40s/it]Loading train:  38%|███▊      | 100/266 [02:17<04:03,  1.47s/it]Loading train:  38%|███▊      | 101/266 [02:18<03:54,  1.42s/it]Loading train:  38%|███▊      | 102/266 [02:20<03:53,  1.43s/it]Loading train:  39%|███▊      | 103/266 [02:21<03:50,  1.42s/it]Loading train:  39%|███▉      | 104/266 [02:23<03:53,  1.44s/it]Loading train:  39%|███▉      | 105/266 [02:24<03:30,  1.31s/it]Loading train:  40%|███▉      | 106/266 [02:25<03:14,  1.22s/it]Loading train:  40%|████      | 107/266 [02:26<03:15,  1.23s/it]Loading train:  41%|████      | 108/266 [02:27<03:22,  1.28s/it]Loading train:  41%|████      | 109/266 [02:29<03:31,  1.35s/it]Loading train:  41%|████▏     | 110/266 [02:30<03:30,  1.35s/it]Loading train:  42%|████▏     | 111/266 [02:32<03:22,  1.30s/it]Loading train:  42%|████▏     | 112/266 [02:33<03:32,  1.38s/it]Loading train:  42%|████▏     | 113/266 [02:35<03:44,  1.47s/it]Loading train:  43%|████▎     | 114/266 [02:36<03:46,  1.49s/it]Loading train:  43%|████▎     | 115/266 [02:38<03:40,  1.46s/it]Loading train:  44%|████▎     | 116/266 [02:39<03:32,  1.41s/it]Loading train:  44%|████▍     | 117/266 [02:40<03:14,  1.30s/it]Loading train:  44%|████▍     | 118/266 [02:41<03:03,  1.24s/it]Loading train:  45%|████▍     | 119/266 [02:43<03:13,  1.32s/it]Loading train:  45%|████▌     | 120/266 [02:44<03:06,  1.28s/it]Loading train:  45%|████▌     | 121/266 [02:45<03:14,  1.34s/it]Loading train:  46%|████▌     | 122/266 [02:47<03:13,  1.34s/it]Loading train:  46%|████▌     | 123/266 [02:48<03:20,  1.40s/it]Loading train:  47%|████▋     | 124/266 [02:50<03:18,  1.39s/it]Loading train:  47%|████▋     | 125/266 [02:51<03:27,  1.47s/it]Loading train:  47%|████▋     | 126/266 [02:53<03:41,  1.58s/it]Loading train:  48%|████▊     | 127/266 [02:55<03:39,  1.58s/it]Loading train:  48%|████▊     | 128/266 [02:56<03:25,  1.49s/it]Loading train:  48%|████▊     | 129/266 [02:58<03:30,  1.53s/it]Loading train:  49%|████▉     | 130/266 [02:59<03:21,  1.48s/it]Loading train:  49%|████▉     | 131/266 [03:00<03:19,  1.48s/it]Loading train:  50%|████▉     | 132/266 [03:02<03:31,  1.58s/it]Loading train:  50%|█████     | 133/266 [03:04<03:36,  1.63s/it]Loading train:  50%|█████     | 134/266 [03:06<03:32,  1.61s/it]Loading train:  51%|█████     | 135/266 [03:07<03:20,  1.53s/it]Loading train:  51%|█████     | 136/266 [03:09<03:23,  1.57s/it]Loading train:  52%|█████▏    | 137/266 [03:10<03:16,  1.52s/it]Loading train:  52%|█████▏    | 138/266 [03:11<03:07,  1.46s/it]Loading train:  52%|█████▏    | 139/266 [03:13<02:58,  1.40s/it]Loading train:  53%|█████▎    | 140/266 [03:14<03:01,  1.44s/it]Loading train:  53%|█████▎    | 141/266 [03:16<03:01,  1.45s/it]Loading train:  53%|█████▎    | 142/266 [03:17<03:02,  1.47s/it]Loading train:  54%|█████▍    | 143/266 [03:19<03:08,  1.53s/it]Loading train:  54%|█████▍    | 144/266 [03:19<02:35,  1.27s/it]Loading train:  55%|█████▍    | 145/266 [03:21<02:30,  1.24s/it]Loading train:  55%|█████▍    | 146/266 [03:22<02:20,  1.17s/it]Loading train:  55%|█████▌    | 147/266 [03:23<02:31,  1.27s/it]Loading train:  56%|█████▌    | 148/266 [03:25<02:42,  1.38s/it]Loading train:  56%|█████▌    | 149/266 [03:26<02:42,  1.39s/it]Loading train:  56%|█████▋    | 150/266 [03:27<02:41,  1.39s/it]Loading train:  57%|█████▋    | 151/266 [03:29<02:41,  1.40s/it]Loading train:  57%|█████▋    | 152/266 [03:30<02:40,  1.41s/it]Loading train:  58%|█████▊    | 153/266 [03:31<02:29,  1.32s/it]Loading train:  58%|█████▊    | 154/266 [03:32<02:15,  1.21s/it]Loading train:  58%|█████▊    | 155/266 [03:34<02:26,  1.32s/it]Loading train:  59%|█████▊    | 156/266 [03:35<02:26,  1.33s/it]Loading train:  59%|█████▉    | 157/266 [03:37<02:22,  1.30s/it]Loading train:  59%|█████▉    | 158/266 [03:38<02:25,  1.35s/it]Loading train:  60%|█████▉    | 159/266 [03:39<02:20,  1.31s/it]Loading train:  60%|██████    | 160/266 [03:40<02:16,  1.28s/it]Loading train:  61%|██████    | 161/266 [03:42<02:11,  1.25s/it]Loading train:  61%|██████    | 162/266 [03:43<02:12,  1.27s/it]Loading train:  61%|██████▏   | 163/266 [03:44<02:02,  1.19s/it]Loading train:  62%|██████▏   | 164/266 [03:45<01:59,  1.17s/it]Loading train:  62%|██████▏   | 165/266 [03:46<02:01,  1.21s/it]Loading train:  62%|██████▏   | 166/266 [03:48<02:10,  1.31s/it]Loading train:  63%|██████▎   | 167/266 [03:49<02:07,  1.29s/it]Loading train:  63%|██████▎   | 168/266 [03:50<02:07,  1.30s/it]Loading train:  64%|██████▎   | 169/266 [03:52<02:08,  1.32s/it]Loading train:  64%|██████▍   | 170/266 [03:53<02:06,  1.32s/it]Loading train:  64%|██████▍   | 171/266 [03:55<02:14,  1.42s/it]Loading train:  65%|██████▍   | 172/266 [03:56<02:18,  1.47s/it]Loading train:  65%|██████▌   | 173/266 [03:58<02:16,  1.47s/it]Loading train:  65%|██████▌   | 174/266 [03:59<02:03,  1.34s/it]Loading train:  66%|██████▌   | 175/266 [04:00<02:04,  1.37s/it]Loading train:  66%|██████▌   | 176/266 [04:02<02:06,  1.41s/it]Loading train:  67%|██████▋   | 177/266 [04:03<02:06,  1.42s/it]Loading train:  67%|██████▋   | 178/266 [04:05<02:07,  1.45s/it]Loading train:  67%|██████▋   | 179/266 [04:06<02:09,  1.48s/it]Loading train:  68%|██████▊   | 180/266 [04:08<02:15,  1.58s/it]Loading train:  68%|██████▊   | 181/266 [04:10<02:13,  1.57s/it]Loading train:  68%|██████▊   | 182/266 [04:11<01:57,  1.40s/it]Loading train:  69%|██████▉   | 183/266 [04:13<02:10,  1.57s/it]Loading train:  69%|██████▉   | 184/266 [04:14<02:05,  1.53s/it]Loading train:  70%|██████▉   | 185/266 [04:15<01:56,  1.44s/it]Loading train:  70%|██████▉   | 186/266 [04:17<01:51,  1.39s/it]Loading train:  70%|███████   | 187/266 [04:18<01:48,  1.37s/it]Loading train:  71%|███████   | 188/266 [04:19<01:43,  1.32s/it]Loading train:  71%|███████   | 189/266 [04:20<01:34,  1.23s/it]Loading train:  71%|███████▏  | 190/266 [04:22<01:36,  1.27s/it]Loading train:  72%|███████▏  | 191/266 [04:23<01:39,  1.33s/it]Loading train:  72%|███████▏  | 192/266 [04:24<01:30,  1.22s/it]Loading train:  73%|███████▎  | 193/266 [04:25<01:27,  1.20s/it]Loading train:  73%|███████▎  | 194/266 [04:27<01:37,  1.35s/it]Loading train:  73%|███████▎  | 195/266 [04:28<01:31,  1.28s/it]Loading train:  74%|███████▎  | 196/266 [04:29<01:30,  1.29s/it]Loading train:  74%|███████▍  | 197/266 [04:31<01:32,  1.34s/it]Loading train:  74%|███████▍  | 198/266 [04:32<01:32,  1.36s/it]Loading train:  75%|███████▍  | 199/266 [04:34<01:35,  1.42s/it]Loading train:  75%|███████▌  | 200/266 [04:35<01:30,  1.37s/it]Loading train:  76%|███████▌  | 201/266 [04:36<01:27,  1.35s/it]Loading train:  76%|███████▌  | 202/266 [04:38<01:26,  1.35s/it]Loading train:  76%|███████▋  | 203/266 [04:39<01:25,  1.36s/it]Loading train:  77%|███████▋  | 204/266 [04:40<01:25,  1.37s/it]Loading train:  77%|███████▋  | 205/266 [04:42<01:23,  1.37s/it]Loading train:  77%|███████▋  | 206/266 [04:43<01:21,  1.36s/it]Loading train:  78%|███████▊  | 207/266 [04:44<01:05,  1.12s/it]Loading train:  78%|███████▊  | 208/266 [04:45<01:08,  1.18s/it]Loading train:  79%|███████▊  | 209/266 [04:46<01:12,  1.28s/it]Loading train:  79%|███████▉  | 210/266 [04:48<01:16,  1.36s/it]Loading train:  79%|███████▉  | 211/266 [04:49<01:11,  1.30s/it]Loading train:  80%|███████▉  | 212/266 [04:51<01:12,  1.34s/it]Loading train:  80%|████████  | 213/266 [04:52<01:09,  1.32s/it]Loading train:  80%|████████  | 214/266 [04:53<00:58,  1.13s/it]Loading train:  81%|████████  | 215/266 [04:54<01:03,  1.24s/it]Loading train:  81%|████████  | 216/266 [04:56<01:06,  1.33s/it]Loading train:  82%|████████▏ | 217/266 [04:57<01:02,  1.28s/it]Loading train:  82%|████████▏ | 218/266 [04:58<01:03,  1.33s/it]Loading train:  82%|████████▏ | 219/266 [04:59<00:59,  1.28s/it]Loading train:  83%|████████▎ | 220/266 [05:00<00:56,  1.22s/it]Loading train:  83%|████████▎ | 221/266 [05:02<00:54,  1.20s/it]Loading train:  83%|████████▎ | 222/266 [05:03<00:52,  1.20s/it]Loading train:  84%|████████▍ | 223/266 [05:04<00:52,  1.22s/it]Loading train:  84%|████████▍ | 224/266 [05:05<00:49,  1.18s/it]Loading train:  85%|████████▍ | 225/266 [05:06<00:46,  1.14s/it]Loading train:  85%|████████▍ | 226/266 [05:08<00:48,  1.21s/it]Loading train:  85%|████████▌ | 227/266 [05:09<00:48,  1.24s/it]Loading train:  86%|████████▌ | 228/266 [05:10<00:43,  1.14s/it]Loading train:  86%|████████▌ | 229/266 [05:11<00:42,  1.16s/it]Loading train:  86%|████████▋ | 230/266 [05:12<00:43,  1.20s/it]Loading train:  87%|████████▋ | 231/266 [05:13<00:42,  1.20s/it]Loading train:  87%|████████▋ | 232/266 [05:14<00:37,  1.11s/it]Loading train:  88%|████████▊ | 233/266 [05:15<00:35,  1.06s/it]Loading train:  88%|████████▊ | 234/266 [05:16<00:34,  1.08s/it]Loading train:  88%|████████▊ | 235/266 [05:18<00:36,  1.18s/it]Loading train:  89%|████████▊ | 236/266 [05:19<00:36,  1.21s/it]Loading train:  89%|████████▉ | 237/266 [05:20<00:33,  1.16s/it]Loading train:  89%|████████▉ | 238/266 [05:22<00:33,  1.20s/it]Loading train:  90%|████████▉ | 239/266 [05:23<00:32,  1.21s/it]Loading train:  90%|█████████ | 240/266 [05:24<00:35,  1.36s/it]Loading train:  91%|█████████ | 241/266 [05:26<00:36,  1.44s/it]Loading train:  91%|█████████ | 242/266 [05:28<00:37,  1.55s/it]Loading train:  91%|█████████▏| 243/266 [05:30<00:37,  1.65s/it]Loading train:  92%|█████████▏| 244/266 [05:32<00:37,  1.72s/it]Loading train:  92%|█████████▏| 245/266 [05:33<00:35,  1.69s/it]Loading train:  92%|█████████▏| 246/266 [05:35<00:32,  1.63s/it]Loading train:  93%|█████████▎| 247/266 [05:36<00:31,  1.63s/it]Loading train:  93%|█████████▎| 248/266 [05:38<00:29,  1.64s/it]Loading train:  94%|█████████▎| 249/266 [05:40<00:29,  1.71s/it]Loading train:  94%|█████████▍| 250/266 [05:42<00:27,  1.72s/it]Loading train:  94%|█████████▍| 251/266 [05:44<00:28,  1.88s/it]Loading train:  95%|█████████▍| 252/266 [05:47<00:31,  2.23s/it]Loading train:  95%|█████████▌| 253/266 [05:50<00:30,  2.32s/it]Loading train:  95%|█████████▌| 254/266 [05:52<00:27,  2.28s/it]Loading train:  96%|█████████▌| 255/266 [05:54<00:25,  2.36s/it]Loading train:  96%|█████████▌| 256/266 [05:56<00:23,  2.31s/it]Loading train:  97%|█████████▋| 257/266 [05:58<00:19,  2.19s/it]Loading train:  97%|█████████▋| 258/266 [06:01<00:17,  2.21s/it]Loading train:  97%|█████████▋| 259/266 [06:02<00:14,  2.12s/it]Loading train:  98%|█████████▊| 260/266 [06:04<00:11,  1.91s/it]Loading train:  98%|█████████▊| 261/266 [06:05<00:08,  1.77s/it]Loading train:  98%|█████████▊| 262/266 [06:06<00:05,  1.50s/it]Loading train:  99%|█████████▉| 263/266 [06:07<00:04,  1.39s/it]Loading train:  99%|█████████▉| 264/266 [06:09<00:02,  1.34s/it]Loading train: 100%|█████████▉| 265/266 [06:09<00:01,  1.13s/it]Loading train: 100%|██████████| 266/266 [06:10<00:00,  1.01it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   0%|          | 1/266 [00:00<00:42,  6.27it/s]concatenating: train:   1%|          | 2/266 [00:00<00:40,  6.46it/s]concatenating: train:   1%|          | 3/266 [00:00<00:37,  6.93it/s]concatenating: train:   2%|▏         | 5/266 [00:00<00:32,  7.96it/s]concatenating: train:   2%|▏         | 6/266 [00:00<00:34,  7.55it/s]concatenating: train:   3%|▎         | 7/266 [00:00<00:32,  8.07it/s]concatenating: train:   3%|▎         | 9/266 [00:00<00:28,  9.03it/s]concatenating: train:   4%|▍         | 10/266 [00:01<00:28,  8.91it/s]concatenating: train:   5%|▍         | 12/266 [00:01<00:24, 10.22it/s]concatenating: train:   5%|▌         | 14/266 [00:01<00:21, 11.67it/s]concatenating: train:   6%|▌         | 16/266 [00:01<00:19, 12.76it/s]concatenating: train:   7%|▋         | 19/266 [00:01<00:16, 14.71it/s]concatenating: train:   8%|▊         | 21/266 [00:01<00:18, 13.31it/s]concatenating: train:   9%|▊         | 23/266 [00:02<00:20, 11.77it/s]concatenating: train:   9%|▉         | 25/266 [00:02<00:19, 12.06it/s]concatenating: train:  10%|█         | 27/266 [00:02<00:19, 12.28it/s]concatenating: train:  11%|█         | 29/266 [00:02<00:17, 13.23it/s]concatenating: train:  12%|█▏        | 31/266 [00:02<00:17, 13.75it/s]concatenating: train:  12%|█▏        | 33/266 [00:02<00:16, 13.94it/s]concatenating: train:  14%|█▎        | 36/266 [00:02<00:14, 16.33it/s]concatenating: train:  15%|█▌        | 40/266 [00:02<00:12, 18.46it/s]concatenating: train:  16%|█▌        | 43/266 [00:03<00:12, 17.26it/s]concatenating: train:  17%|█▋        | 45/266 [00:03<00:13, 16.74it/s]concatenating: train:  18%|█▊        | 47/266 [00:03<00:15, 14.16it/s]concatenating: train:  18%|█▊        | 49/266 [00:03<00:17, 12.58it/s]concatenating: train:  19%|█▉        | 51/266 [00:03<00:15, 13.56it/s]concatenating: train:  20%|█▉        | 53/266 [00:03<00:16, 12.84it/s]concatenating: train:  21%|██        | 55/266 [00:04<00:15, 13.91it/s]concatenating: train:  21%|██▏       | 57/266 [00:04<00:14, 14.14it/s]concatenating: train:  22%|██▏       | 59/266 [00:04<00:13, 14.94it/s]concatenating: train:  23%|██▎       | 61/266 [00:04<00:12, 15.97it/s]concatenating: train:  24%|██▍       | 65/266 [00:04<00:10, 19.42it/s]concatenating: train:  26%|██▋       | 70/266 [00:04<00:08, 22.94it/s]concatenating: train:  28%|██▊       | 74/266 [00:04<00:07, 24.38it/s]concatenating: train:  29%|██▉       | 77/266 [00:05<00:09, 19.77it/s]concatenating: train:  30%|███       | 80/266 [00:05<00:10, 16.94it/s]concatenating: train:  31%|███       | 83/266 [00:05<00:10, 16.86it/s]concatenating: train:  32%|███▏      | 85/266 [00:05<00:12, 14.34it/s]concatenating: train:  33%|███▎      | 87/266 [00:05<00:12, 13.97it/s]concatenating: train:  33%|███▎      | 89/266 [00:06<00:15, 11.61it/s]concatenating: train:  34%|███▍      | 91/266 [00:06<00:13, 12.74it/s]concatenating: train:  35%|███▍      | 93/266 [00:06<00:13, 12.90it/s]concatenating: train:  36%|███▌      | 95/266 [00:06<00:13, 12.68it/s]concatenating: train:  36%|███▋      | 97/266 [00:06<00:13, 12.16it/s]concatenating: train:  38%|███▊      | 100/266 [00:06<00:11, 14.21it/s]concatenating: train:  38%|███▊      | 102/266 [00:06<00:11, 13.89it/s]concatenating: train:  39%|███▉      | 104/266 [00:07<00:13, 11.65it/s]concatenating: train:  40%|███▉      | 106/266 [00:07<00:13, 11.98it/s]concatenating: train:  41%|████      | 108/266 [00:07<00:12, 12.50it/s]concatenating: train:  41%|████▏     | 110/266 [00:07<00:11, 13.29it/s]concatenating: train:  42%|████▏     | 112/266 [00:07<00:10, 14.03it/s]concatenating: train:  43%|████▎     | 114/266 [00:07<00:10, 14.86it/s]concatenating: train:  44%|████▎     | 116/266 [00:07<00:10, 14.56it/s]concatenating: train:  44%|████▍     | 118/266 [00:08<00:10, 13.99it/s]concatenating: train:  45%|████▌     | 120/266 [00:08<00:10, 14.06it/s]concatenating: train:  46%|████▌     | 123/266 [00:08<00:09, 15.21it/s]concatenating: train:  47%|████▋     | 126/266 [00:08<00:08, 17.10it/s]concatenating: train:  48%|████▊     | 128/266 [00:08<00:09, 14.49it/s]concatenating: train:  49%|████▉     | 130/266 [00:08<00:10, 12.58it/s]concatenating: train:  50%|████▉     | 132/266 [00:09<00:09, 13.47it/s]concatenating: train:  50%|█████     | 134/266 [00:09<00:09, 14.28it/s]concatenating: train:  51%|█████     | 136/266 [00:09<00:09, 13.67it/s]concatenating: train:  52%|█████▏    | 138/266 [00:09<00:09, 14.10it/s]concatenating: train:  53%|█████▎    | 140/266 [00:09<00:08, 14.80it/s]concatenating: train:  53%|█████▎    | 142/266 [00:09<00:08, 15.46it/s]concatenating: train:  54%|█████▍    | 144/266 [00:09<00:08, 14.19it/s]concatenating: train:  55%|█████▍    | 146/266 [00:10<00:08, 13.42it/s]concatenating: train:  56%|█████▌    | 148/266 [00:10<00:08, 13.55it/s]concatenating: train:  56%|█████▋    | 150/266 [00:10<00:08, 14.48it/s]concatenating: train:  58%|█████▊    | 153/266 [00:10<00:06, 16.23it/s]concatenating: train:  59%|█████▊    | 156/266 [00:10<00:07, 15.55it/s]concatenating: train:  59%|█████▉    | 158/266 [00:10<00:07, 14.23it/s]concatenating: train:  60%|██████    | 160/266 [00:11<00:07, 13.37it/s]concatenating: train:  61%|██████    | 162/266 [00:11<00:07, 13.30it/s]concatenating: train:  62%|██████▏   | 164/266 [00:11<00:07, 14.28it/s]concatenating: train:  62%|██████▏   | 166/266 [00:11<00:06, 14.79it/s]concatenating: train:  63%|██████▎   | 168/266 [00:11<00:06, 15.45it/s]concatenating: train:  64%|██████▍   | 170/266 [00:11<00:06, 15.50it/s]concatenating: train:  65%|██████▌   | 174/266 [00:11<00:05, 18.16it/s]concatenating: train:  67%|██████▋   | 177/266 [00:11<00:04, 19.61it/s]concatenating: train:  68%|██████▊   | 180/266 [00:12<00:04, 20.97it/s]concatenating: train:  69%|██████▉   | 184/266 [00:12<00:03, 22.94it/s]concatenating: train:  70%|███████   | 187/266 [00:12<00:03, 23.72it/s]concatenating: train:  71%|███████▏  | 190/266 [00:12<00:03, 19.61it/s]concatenating: train:  73%|███████▎  | 193/266 [00:12<00:04, 16.98it/s]concatenating: train:  73%|███████▎  | 195/266 [00:12<00:04, 16.23it/s]concatenating: train:  74%|███████▍  | 197/266 [00:12<00:04, 16.41it/s]concatenating: train:  75%|███████▌  | 200/266 [00:13<00:03, 17.99it/s]concatenating: train:  76%|███████▋  | 203/266 [00:13<00:03, 20.10it/s]concatenating: train:  77%|███████▋  | 206/266 [00:13<00:02, 22.27it/s]concatenating: train:  79%|███████▊  | 209/266 [00:13<00:02, 20.27it/s]concatenating: train:  80%|███████▉  | 212/266 [00:13<00:02, 18.30it/s]concatenating: train:  80%|████████  | 214/266 [00:13<00:02, 18.42it/s]concatenating: train:  81%|████████  | 216/266 [00:13<00:02, 17.85it/s]concatenating: train:  82%|████████▏ | 218/266 [00:14<00:02, 17.49it/s]concatenating: train:  83%|████████▎ | 220/266 [00:14<00:02, 16.88it/s]concatenating: train:  83%|████████▎ | 222/266 [00:14<00:02, 17.16it/s]concatenating: train:  84%|████████▍ | 224/266 [00:14<00:02, 16.66it/s]concatenating: train:  85%|████████▍ | 226/266 [00:14<00:02, 16.82it/s]concatenating: train:  86%|████████▋ | 230/266 [00:14<00:01, 19.28it/s]concatenating: train:  88%|████████▊ | 235/266 [00:14<00:01, 23.12it/s]concatenating: train:  89%|████████▉ | 238/266 [00:14<00:01, 19.93it/s]concatenating: train:  91%|█████████ | 241/266 [00:15<00:01, 13.68it/s]concatenating: train:  91%|█████████▏| 243/266 [00:15<00:01, 12.69it/s]concatenating: train:  92%|█████████▏| 245/266 [00:15<00:01, 13.13it/s]concatenating: train:  93%|█████████▎| 247/266 [00:15<00:01, 13.08it/s]concatenating: train:  94%|█████████▎| 249/266 [00:15<00:01, 14.17it/s]concatenating: train:  95%|█████████▍| 252/266 [00:16<00:00, 16.08it/s]concatenating: train: 100%|██████████| 266/266 [00:16<00:00, 16.47it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.29s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.18s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.11s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.15s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.13s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation:  20%|██        | 1/5 [00:00<00:00,  7.48it/s]concatenating: validation:  40%|████      | 2/5 [00:00<00:00,  7.62it/s]concatenating: validation:  80%|████████  | 4/5 [00:00<00:00,  7.90it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00,  8.43it/s]
Loading trainS:   0%|          | 0/266 [00:00<?, ?it/s]Loading trainS:   0%|          | 1/266 [00:00<04:07,  1.07it/s]Loading trainS:   1%|          | 2/266 [00:02<04:41,  1.07s/it]Loading trainS:   1%|          | 3/266 [00:03<04:39,  1.06s/it]Loading trainS:   2%|▏         | 4/266 [00:04<04:42,  1.08s/it]Loading trainS:   2%|▏         | 5/266 [00:05<05:02,  1.16s/it]Loading trainS:   2%|▏         | 6/266 [00:07<05:10,  1.19s/it]Loading trainS:   3%|▎         | 7/266 [00:08<05:07,  1.19s/it]Loading trainS:   3%|▎         | 8/266 [00:09<04:37,  1.08s/it]Loading trainS:   3%|▎         | 9/266 [00:10<04:37,  1.08s/it]Loading trainS:   4%|▍         | 10/266 [00:11<04:41,  1.10s/it]Loading trainS:   4%|▍         | 11/266 [00:12<04:54,  1.15s/it]Loading trainS:   5%|▍         | 12/266 [00:13<04:51,  1.15s/it]Loading trainS:   5%|▍         | 13/266 [00:14<04:58,  1.18s/it]Loading trainS:   5%|▌         | 14/266 [00:15<04:35,  1.09s/it]Loading trainS:   6%|▌         | 15/266 [00:17<04:37,  1.11s/it]Loading trainS:   6%|▌         | 16/266 [00:17<04:01,  1.04it/s]Loading trainS:   6%|▋         | 17/266 [00:18<03:41,  1.13it/s]Loading trainS:   7%|▋         | 18/266 [00:19<03:26,  1.20it/s]Loading trainS:   7%|▋         | 19/266 [00:19<03:24,  1.21it/s]Loading trainS:   8%|▊         | 20/266 [00:20<03:44,  1.10it/s]Loading trainS:   8%|▊         | 21/266 [00:22<04:02,  1.01it/s]Loading trainS:   8%|▊         | 22/266 [00:23<04:04,  1.00s/it]Loading trainS:   9%|▊         | 23/266 [00:24<04:25,  1.09s/it]Loading trainS:   9%|▉         | 24/266 [00:25<04:36,  1.14s/it]Loading trainS:   9%|▉         | 25/266 [00:27<04:42,  1.17s/it]Loading trainS:  10%|▉         | 26/266 [00:27<04:19,  1.08s/it]Loading trainS:  10%|█         | 27/266 [00:29<04:23,  1.10s/it]Loading trainS:  11%|█         | 28/266 [00:29<03:52,  1.02it/s]Loading trainS:  11%|█         | 29/266 [00:30<04:09,  1.05s/it]Loading trainS:  11%|█▏        | 30/266 [00:32<04:35,  1.17s/it]Loading trainS:  12%|█▏        | 31/266 [00:33<04:30,  1.15s/it]Loading trainS:  12%|█▏        | 32/266 [00:34<04:20,  1.11s/it]Loading trainS:  12%|█▏        | 33/266 [00:35<04:19,  1.11s/it]Loading trainS:  13%|█▎        | 34/266 [00:36<04:07,  1.07s/it]Loading trainS:  13%|█▎        | 35/266 [00:37<03:35,  1.07it/s]Loading trainS:  14%|█▎        | 36/266 [00:38<03:47,  1.01it/s]Loading trainS:  14%|█▍        | 37/266 [00:39<03:52,  1.01s/it]Loading trainS:  14%|█▍        | 38/266 [00:40<03:52,  1.02s/it]Loading trainS:  15%|█▍        | 39/266 [00:41<03:49,  1.01s/it]Loading trainS:  15%|█▌        | 40/266 [00:42<04:03,  1.08s/it]Loading trainS:  15%|█▌        | 41/266 [00:43<04:15,  1.14s/it]Loading trainS:  16%|█▌        | 42/266 [00:44<03:55,  1.05s/it]Loading trainS:  16%|█▌        | 43/266 [00:45<03:49,  1.03s/it]Loading trainS:  17%|█▋        | 44/266 [00:46<03:57,  1.07s/it]Loading trainS:  17%|█▋        | 45/266 [00:48<04:06,  1.12s/it]Loading trainS:  17%|█▋        | 46/266 [00:49<03:59,  1.09s/it]Loading trainS:  18%|█▊        | 47/266 [00:50<03:48,  1.04s/it]Loading trainS:  18%|█▊        | 48/266 [00:50<03:35,  1.01it/s]Loading trainS:  18%|█▊        | 49/266 [00:51<03:29,  1.04it/s]Loading trainS:  19%|█▉        | 50/266 [00:52<03:21,  1.07it/s]Loading trainS:  19%|█▉        | 51/266 [00:53<03:29,  1.03it/s]Loading trainS:  20%|█▉        | 52/266 [00:54<03:25,  1.04it/s]Loading trainS:  20%|█▉        | 53/266 [00:55<03:28,  1.02it/s]Loading trainS:  20%|██        | 54/266 [00:56<03:30,  1.01it/s]Loading trainS:  21%|██        | 55/266 [00:57<03:09,  1.11it/s]Loading trainS:  21%|██        | 56/266 [00:58<03:23,  1.03it/s]Loading trainS:  21%|██▏       | 57/266 [00:59<03:39,  1.05s/it]Loading trainS:  22%|██▏       | 58/266 [01:00<03:27,  1.00it/s]Loading trainS:  22%|██▏       | 59/266 [01:01<03:26,  1.00it/s]Loading trainS:  23%|██▎       | 60/266 [01:02<03:27,  1.01s/it]Loading trainS:  23%|██▎       | 61/266 [01:03<03:19,  1.03it/s]Loading trainS:  23%|██▎       | 62/266 [01:04<03:07,  1.09it/s]Loading trainS:  24%|██▎       | 63/266 [01:05<03:19,  1.02it/s]Loading trainS:  24%|██▍       | 64/266 [01:06<03:28,  1.03s/it]Loading trainS:  24%|██▍       | 65/266 [01:08<03:49,  1.14s/it]Loading trainS:  25%|██▍       | 66/266 [01:09<03:38,  1.09s/it]Loading trainS:  25%|██▌       | 67/266 [01:10<03:43,  1.12s/it]Loading trainS:  26%|██▌       | 68/266 [01:11<03:43,  1.13s/it]Loading trainS:  26%|██▌       | 69/266 [01:12<03:45,  1.14s/it]Loading trainS:  26%|██▋       | 70/266 [01:13<03:35,  1.10s/it]Loading trainS:  27%|██▋       | 71/266 [01:14<03:37,  1.11s/it]Loading trainS:  27%|██▋       | 72/266 [01:15<03:39,  1.13s/it]Loading trainS:  27%|██▋       | 73/266 [01:17<03:38,  1.13s/it]Loading trainS:  28%|██▊       | 74/266 [01:17<03:20,  1.05s/it]Loading trainS:  28%|██▊       | 75/266 [01:18<03:18,  1.04s/it]Loading trainS:  29%|██▊       | 76/266 [01:20<03:23,  1.07s/it]Loading trainS:  29%|██▉       | 77/266 [01:21<03:16,  1.04s/it]Loading trainS:  29%|██▉       | 78/266 [01:21<03:00,  1.04it/s]Loading trainS:  30%|██▉       | 79/266 [01:23<03:16,  1.05s/it]Loading trainS:  30%|███       | 80/266 [01:24<03:17,  1.06s/it]Loading trainS:  30%|███       | 81/266 [01:25<03:20,  1.08s/it]Loading trainS:  31%|███       | 82/266 [01:26<03:17,  1.07s/it]Loading trainS:  31%|███       | 83/266 [01:27<03:09,  1.04s/it]Loading trainS:  32%|███▏      | 84/266 [01:28<03:05,  1.02s/it]Loading trainS:  32%|███▏      | 85/266 [01:29<02:55,  1.03it/s]Loading trainS:  32%|███▏      | 86/266 [01:30<03:09,  1.05s/it]Loading trainS:  33%|███▎      | 87/266 [01:31<03:11,  1.07s/it]Loading trainS:  33%|███▎      | 88/266 [01:32<03:05,  1.04s/it]Loading trainS:  33%|███▎      | 89/266 [01:33<03:15,  1.10s/it]Loading trainS:  34%|███▍      | 90/266 [01:34<03:15,  1.11s/it]Loading trainS:  34%|███▍      | 91/266 [01:35<03:05,  1.06s/it]Loading trainS:  35%|███▍      | 92/266 [01:36<02:59,  1.03s/it]Loading trainS:  35%|███▍      | 93/266 [01:37<03:09,  1.09s/it]Loading trainS:  35%|███▌      | 94/266 [01:39<03:13,  1.13s/it]Loading trainS:  36%|███▌      | 95/266 [01:40<03:02,  1.07s/it]Loading trainS:  36%|███▌      | 96/266 [01:41<02:58,  1.05s/it]Loading trainS:  36%|███▋      | 97/266 [01:42<02:54,  1.03s/it]Loading trainS:  37%|███▋      | 98/266 [01:43<02:49,  1.01s/it]Loading trainS:  37%|███▋      | 99/266 [01:44<02:51,  1.02s/it]Loading trainS:  38%|███▊      | 100/266 [01:45<02:49,  1.02s/it]Loading trainS:  38%|███▊      | 101/266 [01:46<02:58,  1.08s/it]Loading trainS:  38%|███▊      | 102/266 [01:47<02:58,  1.09s/it]Loading trainS:  39%|███▊      | 103/266 [01:48<02:47,  1.02s/it]Loading trainS:  39%|███▉      | 104/266 [01:49<02:53,  1.07s/it]Loading trainS:  39%|███▉      | 105/266 [01:50<02:56,  1.09s/it]Loading trainS:  40%|███▉      | 106/266 [01:51<02:58,  1.11s/it]Loading trainS:  40%|████      | 107/266 [01:52<02:37,  1.01it/s]Loading trainS:  41%|████      | 108/266 [01:53<02:43,  1.04s/it]Loading trainS:  41%|████      | 109/266 [01:54<02:37,  1.01s/it]Loading trainS:  41%|████▏     | 110/266 [01:55<02:31,  1.03it/s]Loading trainS:  42%|████▏     | 111/266 [01:56<02:47,  1.08s/it]Loading trainS:  42%|████▏     | 112/266 [01:57<02:36,  1.02s/it]Loading trainS:  42%|████▏     | 113/266 [01:58<02:41,  1.05s/it]Loading trainS:  43%|████▎     | 114/266 [01:59<02:41,  1.06s/it]Loading trainS:  43%|████▎     | 115/266 [02:00<02:29,  1.01it/s]Loading trainS:  44%|████▎     | 116/266 [02:01<02:37,  1.05s/it]Loading trainS:  44%|████▍     | 117/266 [02:02<02:34,  1.04s/it]Loading trainS:  44%|████▍     | 118/266 [02:04<02:40,  1.08s/it]Loading trainS:  45%|████▍     | 119/266 [02:05<02:37,  1.07s/it]Loading trainS:  45%|████▌     | 120/266 [02:06<02:36,  1.07s/it]Loading trainS:  45%|████▌     | 121/266 [02:07<02:39,  1.10s/it]Loading trainS:  46%|████▌     | 122/266 [02:08<02:37,  1.09s/it]Loading trainS:  46%|████▌     | 123/266 [02:09<02:31,  1.06s/it]Loading trainS:  47%|████▋     | 124/266 [02:10<02:36,  1.10s/it]Loading trainS:  47%|████▋     | 125/266 [02:11<02:44,  1.16s/it]Loading trainS:  47%|████▋     | 126/266 [02:13<02:58,  1.28s/it]Loading trainS:  48%|████▊     | 127/266 [02:14<03:06,  1.34s/it]Loading trainS:  48%|████▊     | 128/266 [02:16<03:17,  1.43s/it]Loading trainS:  48%|████▊     | 129/266 [02:17<03:10,  1.39s/it]Loading trainS:  49%|████▉     | 130/266 [02:19<03:10,  1.40s/it]Loading trainS:  49%|████▉     | 131/266 [02:20<03:15,  1.45s/it]Loading trainS:  50%|████▉     | 132/266 [02:22<03:19,  1.49s/it]Loading trainS:  50%|█████     | 133/266 [02:24<03:21,  1.51s/it]Loading trainS:  50%|█████     | 134/266 [02:25<03:19,  1.51s/it]Loading trainS:  51%|█████     | 135/266 [02:27<03:18,  1.52s/it]Loading trainS:  51%|█████     | 136/266 [02:27<02:48,  1.30s/it]Loading trainS:  52%|█████▏    | 137/266 [02:28<02:34,  1.20s/it]Loading trainS:  52%|█████▏    | 138/266 [02:30<02:38,  1.24s/it]Loading trainS:  52%|█████▏    | 139/266 [02:31<02:52,  1.35s/it]Loading trainS:  53%|█████▎    | 140/266 [02:33<02:48,  1.34s/it]Loading trainS:  53%|█████▎    | 141/266 [02:33<02:20,  1.13s/it]Loading trainS:  53%|█████▎    | 142/266 [02:34<02:22,  1.15s/it]Loading trainS:  54%|█████▍    | 143/266 [02:36<02:30,  1.22s/it]Loading trainS:  54%|█████▍    | 144/266 [02:37<02:30,  1.24s/it]Loading trainS:  55%|█████▍    | 145/266 [02:38<02:16,  1.12s/it]Loading trainS:  55%|█████▍    | 146/266 [02:39<02:12,  1.11s/it]Loading trainS:  55%|█████▌    | 147/266 [02:40<02:18,  1.17s/it]Loading trainS:  56%|█████▌    | 148/266 [02:42<02:20,  1.19s/it]Loading trainS:  56%|█████▌    | 149/266 [02:43<02:13,  1.14s/it]Loading trainS:  56%|█████▋    | 150/266 [02:44<02:20,  1.21s/it]Loading trainS:  57%|█████▋    | 151/266 [02:45<02:12,  1.15s/it]Loading trainS:  57%|█████▋    | 152/266 [02:46<02:17,  1.20s/it]Loading trainS:  58%|█████▊    | 153/266 [02:48<02:19,  1.24s/it]Loading trainS:  58%|█████▊    | 154/266 [02:49<02:23,  1.28s/it]Loading trainS:  58%|█████▊    | 155/266 [02:50<02:27,  1.33s/it]Loading trainS:  59%|█████▊    | 156/266 [02:52<02:29,  1.36s/it]Loading trainS:  59%|█████▉    | 157/266 [02:53<02:28,  1.37s/it]Loading trainS:  59%|█████▉    | 158/266 [02:55<02:29,  1.38s/it]Loading trainS:  60%|█████▉    | 159/266 [02:55<02:06,  1.18s/it]Loading trainS:  60%|██████    | 160/266 [02:57<02:08,  1.21s/it]Loading trainS:  61%|██████    | 161/266 [02:57<01:50,  1.05s/it]Loading trainS:  61%|██████    | 162/266 [02:58<01:49,  1.05s/it]Loading trainS:  61%|██████▏   | 163/266 [03:00<02:03,  1.19s/it]Loading trainS:  62%|██████▏   | 164/266 [03:01<01:57,  1.15s/it]Loading trainS:  62%|██████▏   | 165/266 [03:02<01:44,  1.04s/it]Loading trainS:  62%|██████▏   | 166/266 [03:03<01:49,  1.10s/it]Loading trainS:  63%|██████▎   | 167/266 [03:04<01:44,  1.05s/it]Loading trainS:  63%|██████▎   | 168/266 [03:05<01:55,  1.18s/it]Loading trainS:  64%|██████▎   | 169/266 [03:07<01:55,  1.19s/it]Loading trainS:  64%|██████▍   | 170/266 [03:08<01:51,  1.17s/it]Loading trainS:  64%|██████▍   | 171/266 [03:09<01:52,  1.18s/it]Loading trainS:  65%|██████▍   | 172/266 [03:10<01:52,  1.19s/it]Loading trainS:  65%|██████▌   | 173/266 [03:11<01:37,  1.05s/it]Loading trainS:  65%|██████▌   | 174/266 [03:12<01:38,  1.07s/it]Loading trainS:  66%|██████▌   | 175/266 [03:13<01:45,  1.16s/it]Loading trainS:  66%|██████▌   | 176/266 [03:15<01:54,  1.27s/it]Loading trainS:  67%|██████▋   | 177/266 [03:16<01:52,  1.26s/it]Loading trainS:  67%|██████▋   | 178/266 [03:17<01:50,  1.26s/it]Loading trainS:  67%|██████▋   | 179/266 [03:19<01:50,  1.27s/it]Loading trainS:  68%|██████▊   | 180/266 [03:20<01:44,  1.22s/it]Loading trainS:  68%|██████▊   | 181/266 [03:21<01:51,  1.31s/it]Loading trainS:  68%|██████▊   | 182/266 [03:23<01:47,  1.28s/it]Loading trainS:  69%|██████▉   | 183/266 [03:24<01:45,  1.27s/it]Loading trainS:  69%|██████▉   | 184/266 [03:25<01:39,  1.22s/it]Loading trainS:  70%|██████▉   | 185/266 [03:26<01:35,  1.18s/it]Loading trainS:  70%|██████▉   | 186/266 [03:27<01:31,  1.15s/it]Loading trainS:  70%|███████   | 187/266 [03:29<01:41,  1.29s/it]Loading trainS:  71%|███████   | 188/266 [03:30<01:41,  1.30s/it]Loading trainS:  71%|███████   | 189/266 [03:32<01:48,  1.41s/it]Loading trainS:  71%|███████▏  | 190/266 [03:33<01:48,  1.43s/it]Loading trainS:  72%|███████▏  | 191/266 [03:34<01:39,  1.32s/it]Loading trainS:  72%|███████▏  | 192/266 [03:36<01:37,  1.32s/it]Loading trainS:  73%|███████▎  | 193/266 [03:36<01:28,  1.21s/it]Loading trainS:  73%|███████▎  | 194/266 [03:38<01:25,  1.19s/it]Loading trainS:  73%|███████▎  | 195/266 [03:39<01:26,  1.22s/it]Loading trainS:  74%|███████▎  | 196/266 [03:40<01:24,  1.20s/it]Loading trainS:  74%|███████▍  | 197/266 [03:41<01:27,  1.27s/it]Loading trainS:  74%|███████▍  | 198/266 [03:42<01:20,  1.19s/it]Loading trainS:  75%|███████▍  | 199/266 [03:44<01:24,  1.26s/it]Loading trainS:  75%|███████▌  | 200/266 [03:45<01:20,  1.22s/it]Loading trainS:  76%|███████▌  | 201/266 [03:47<01:25,  1.32s/it]Loading trainS:  76%|███████▌  | 202/266 [03:48<01:25,  1.33s/it]Loading trainS:  76%|███████▋  | 203/266 [03:49<01:25,  1.36s/it]Loading trainS:  77%|███████▋  | 204/266 [03:51<01:23,  1.34s/it]Loading trainS:  77%|███████▋  | 205/266 [03:52<01:22,  1.35s/it]Loading trainS:  77%|███████▋  | 206/266 [03:54<01:24,  1.41s/it]Loading trainS:  78%|███████▊  | 207/266 [03:55<01:26,  1.47s/it]Loading trainS:  78%|███████▊  | 208/266 [03:57<01:23,  1.44s/it]Loading trainS:  79%|███████▊  | 209/266 [03:58<01:17,  1.35s/it]Loading trainS:  79%|███████▉  | 210/266 [03:59<01:17,  1.39s/it]Loading trainS:  79%|███████▉  | 211/266 [04:01<01:17,  1.40s/it]Loading trainS:  80%|███████▉  | 212/266 [04:02<01:12,  1.33s/it]Loading trainS:  80%|████████  | 213/266 [04:03<01:05,  1.24s/it]Loading trainS:  80%|████████  | 214/266 [04:04<01:04,  1.24s/it]Loading trainS:  81%|████████  | 215/266 [04:05<01:01,  1.21s/it]Loading trainS:  81%|████████  | 216/266 [04:06<01:00,  1.20s/it]Loading trainS:  82%|████████▏ | 217/266 [04:08<00:58,  1.19s/it]Loading trainS:  82%|████████▏ | 218/266 [04:09<01:05,  1.36s/it]Loading trainS:  82%|████████▏ | 219/266 [04:11<01:02,  1.33s/it]Loading trainS:  83%|████████▎ | 220/266 [04:12<01:02,  1.35s/it]Loading trainS:  83%|████████▎ | 221/266 [04:13<00:59,  1.33s/it]Loading trainS:  83%|████████▎ | 222/266 [04:14<00:53,  1.22s/it]Loading trainS:  84%|████████▍ | 223/266 [04:15<00:53,  1.25s/it]Loading trainS:  84%|████████▍ | 224/266 [04:17<00:54,  1.29s/it]Loading trainS:  85%|████████▍ | 225/266 [04:18<00:56,  1.38s/it]Loading trainS:  85%|████████▍ | 226/266 [04:20<00:55,  1.38s/it]Loading trainS:  85%|████████▌ | 227/266 [04:21<00:55,  1.41s/it]Loading trainS:  86%|████████▌ | 228/266 [04:23<00:51,  1.35s/it]Loading trainS:  86%|████████▌ | 229/266 [04:24<00:47,  1.29s/it]Loading trainS:  86%|████████▋ | 230/266 [04:25<00:44,  1.23s/it]Loading trainS:  87%|████████▋ | 231/266 [04:26<00:39,  1.12s/it]Loading trainS:  87%|████████▋ | 232/266 [04:27<00:39,  1.17s/it]Loading trainS:  88%|████████▊ | 233/266 [04:28<00:41,  1.25s/it]Loading trainS:  88%|████████▊ | 234/266 [04:30<00:42,  1.32s/it]Loading trainS:  88%|████████▊ | 235/266 [04:31<00:42,  1.38s/it]Loading trainS:  89%|████████▊ | 236/266 [04:33<00:41,  1.37s/it]Loading trainS:  89%|████████▉ | 237/266 [04:34<00:38,  1.34s/it]Loading trainS:  89%|████████▉ | 238/266 [04:35<00:36,  1.30s/it]Loading trainS:  90%|████████▉ | 239/266 [04:36<00:32,  1.19s/it]Loading trainS:  90%|█████████ | 240/266 [04:37<00:27,  1.06s/it]Loading trainS:  91%|█████████ | 241/266 [04:38<00:28,  1.14s/it]Loading trainS:  91%|█████████ | 242/266 [04:39<00:28,  1.17s/it]Loading trainS:  91%|█████████▏| 243/266 [04:41<00:28,  1.24s/it]Loading trainS:  92%|█████████▏| 244/266 [04:42<00:28,  1.29s/it]Loading trainS:  92%|█████████▏| 245/266 [04:44<00:27,  1.29s/it]Loading trainS:  92%|█████████▏| 246/266 [04:45<00:24,  1.24s/it]Loading trainS:  93%|█████████▎| 247/266 [04:46<00:23,  1.23s/it]Loading trainS:  93%|█████████▎| 248/266 [04:47<00:21,  1.22s/it]Loading trainS:  94%|█████████▎| 249/266 [04:49<00:22,  1.33s/it]Loading trainS:  94%|█████████▍| 250/266 [04:50<00:19,  1.22s/it]Loading trainS:  94%|█████████▍| 251/266 [04:51<00:18,  1.24s/it]Loading trainS:  95%|█████████▍| 252/266 [04:53<00:18,  1.34s/it]Loading trainS:  95%|█████████▌| 253/266 [04:54<00:18,  1.41s/it]Loading trainS:  95%|█████████▌| 254/266 [04:56<00:17,  1.43s/it]Loading trainS:  96%|█████████▌| 255/266 [04:57<00:14,  1.36s/it]Loading trainS:  96%|█████████▌| 256/266 [04:58<00:13,  1.31s/it]Loading trainS:  97%|█████████▋| 257/266 [04:59<00:10,  1.14s/it]Loading trainS:  97%|█████████▋| 258/266 [05:00<00:09,  1.15s/it]Loading trainS:  97%|█████████▋| 259/266 [05:01<00:08,  1.25s/it]Loading trainS:  98%|█████████▊| 260/266 [05:03<00:07,  1.25s/it]Loading trainS:  98%|█████████▊| 261/266 [05:04<00:06,  1.36s/it]Loading trainS:  98%|█████████▊| 262/266 [05:06<00:06,  1.57s/it]Loading trainS:  99%|█████████▉| 263/266 [05:07<00:04,  1.40s/it]Loading trainS:  99%|█████████▉| 264/266 [05:09<00:02,  1.40s/it]Loading trainS: 100%|█████████▉| 265/266 [05:10<00:01,  1.37s/it]Loading trainS: 100%|██████████| 266/266 [05:12<00:00,  1.43s/it]
Loading testS:   0%|          | 0/5 [00:00<?, ?it/s]Loading testS:  20%|██        | 1/5 [00:01<00:06,  1.53s/it]Loading testS:  40%|████      | 2/5 [00:02<00:04,  1.48s/it]Loading testS:  60%|██████    | 3/5 [00:04<00:02,  1.50s/it]Loading testS:  80%|████████  | 4/5 [00:05<00:01,  1.50s/it]Loading testS: 100%|██████████| 5/5 [00:06<00:00,  1.37s/it]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:14,  2.89it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:11,  3.44it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:13,  2.96it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:09,  3.93it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.56it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:08,  3.70it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:09,  3.33it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:06,  4.37it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:07,  3.63it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:07,  3.38it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:04<00:07,  2.98it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:04,  3.91it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:05<00:04,  4.03it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:05<00:04,  3.82it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  3.92it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:06<00:03,  3.48it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:02,  4.43it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:07<00:01,  4.21it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:07<00:01,  3.51it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:00,  4.02it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:08<00:00,  3.25it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:08<00:00,  5.32it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 108, 116, 1)  0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 108, 116, 20) 200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 108, 116, 20) 80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 108, 116, 20) 0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 108, 116, 20) 3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 108, 116, 20) 80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 108, 116, 20) 0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 54, 58, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 54, 58, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 54, 58, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 54, 58, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 54, 58, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 54, 58, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 54, 58, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 54, 58, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 54, 58, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 27, 29, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 27, 29, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 27, 29, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 27, 29, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 27, 29, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 27, 29, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 27, 29, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 27, 29, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 27, 29, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 27, 29, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 54, 58, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 54, 58, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 54, 58, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 54, 58, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 54, 58, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 54, 58, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 54, 58, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 54, 58, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 54, 58, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 54, 58, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 108, 116, 20) 11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 108, 116, 40) 0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 108, 116, 20) 7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 108, 116, 20) 80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 108, 116, 20) 0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 108, 116, 20) 3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 108, 116, 20) 80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 108, 116, 20) 0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 108, 116, 60) 0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 108, 116, 60) 0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 108, 116, 2)  122         dropout_5[0][0]                  
==================================================================================================
Total params: 223,162
Trainable params: 196,482
Non-trainable params: 26,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97286605 0.02713395]
Train on 17214 samples, validate on 320 samples
Epoch 1/300
 - 36s - loss: 0.4292 - acc: 0.9456 - mDice: 0.5394 - val_loss: 0.8556 - val_acc: 0.9899 - val_mDice: 0.7086

Epoch 00001: val_mDice improved from -inf to 0.70858, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 31s - loss: 0.1156 - acc: 0.9884 - mDice: 0.8048 - val_loss: 0.7595 - val_acc: 0.9906 - val_mDice: 0.7475

Epoch 00002: val_mDice improved from 0.70858 to 0.74752, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 31s - loss: 0.0880 - acc: 0.9909 - mDice: 0.8448 - val_loss: 0.7310 - val_acc: 0.9913 - val_mDice: 0.7635

Epoch 00003: val_mDice improved from 0.74752 to 0.76353, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 31s - loss: 0.0753 - acc: 0.9919 - mDice: 0.8652 - val_loss: 0.7203 - val_acc: 0.9919 - val_mDice: 0.7828

Epoch 00004: val_mDice improved from 0.76353 to 0.78275, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 31s - loss: 0.0686 - acc: 0.9925 - mDice: 0.8762 - val_loss: 0.6883 - val_acc: 0.9926 - val_mDice: 0.7966

Epoch 00005: val_mDice improved from 0.78275 to 0.79660, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 31s - loss: 0.0633 - acc: 0.9929 - mDice: 0.8851 - val_loss: 0.7238 - val_acc: 0.9920 - val_mDice: 0.7879

Epoch 00006: val_mDice did not improve from 0.79660
Epoch 7/300
 - 31s - loss: 0.0603 - acc: 0.9932 - mDice: 0.8902 - val_loss: 0.6994 - val_acc: 0.9930 - val_mDice: 0.8052

Epoch 00007: val_mDice improved from 0.79660 to 0.80521, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 31s - loss: 0.0568 - acc: 0.9935 - mDice: 0.8960 - val_loss: 0.7109 - val_acc: 0.9929 - val_mDice: 0.8023

Epoch 00008: val_mDice did not improve from 0.80521
Epoch 9/300
 - 31s - loss: 0.0541 - acc: 0.9937 - mDice: 0.9008 - val_loss: 0.6657 - val_acc: 0.9931 - val_mDice: 0.8053

Epoch 00009: val_mDice improved from 0.80521 to 0.80533, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 31s - loss: 0.0516 - acc: 0.9939 - mDice: 0.9051 - val_loss: 0.7061 - val_acc: 0.9930 - val_mDice: 0.8037

Epoch 00010: val_mDice did not improve from 0.80533
Epoch 11/300
 - 31s - loss: 0.0497 - acc: 0.9941 - mDice: 0.9084 - val_loss: 0.4785 - val_acc: 0.9935 - val_mDice: 0.8124

Epoch 00011: val_mDice improved from 0.80533 to 0.81235, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 31s - loss: 0.0489 - acc: 0.9942 - mDice: 0.9098 - val_loss: 0.6883 - val_acc: 0.9931 - val_mDice: 0.8091

Epoch 00012: val_mDice did not improve from 0.81235
Epoch 13/300
 - 31s - loss: 0.0465 - acc: 0.9944 - mDice: 0.9141 - val_loss: 0.5995 - val_acc: 0.9931 - val_mDice: 0.8081

Epoch 00013: val_mDice did not improve from 0.81235
Epoch 14/300
 - 31s - loss: 0.0455 - acc: 0.9945 - mDice: 0.9159 - val_loss: 0.6669 - val_acc: 0.9931 - val_mDice: 0.8071

Epoch 00014: val_mDice did not improve from 0.81235
Epoch 15/300
 - 31s - loss: 0.0440 - acc: 0.9947 - mDice: 0.9185 - val_loss: 0.4363 - val_acc: 0.9933 - val_mDice: 0.8131

Epoch 00015: val_mDice improved from 0.81235 to 0.81309, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 31s - loss: 0.0434 - acc: 0.9947 - mDice: 0.9195 - val_loss: 0.6315 - val_acc: 0.9932 - val_mDice: 0.8119

Epoch 00016: val_mDice did not improve from 0.81309
Epoch 17/300
 - 31s - loss: 0.0423 - acc: 0.9948 - mDice: 0.9215 - val_loss: 0.6603 - val_acc: 0.9932 - val_mDice: 0.8098

Epoch 00017: val_mDice did not improve from 0.81309
Epoch 18/300
 - 31s - loss: 0.0421 - acc: 0.9949 - mDice: 0.9217 - val_loss: 0.6545 - val_acc: 0.9935 - val_mDice: 0.8151

Epoch 00018: val_mDice improved from 0.81309 to 0.81507, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 31s - loss: 0.0406 - acc: 0.9950 - mDice: 0.9245 - val_loss: 0.6139 - val_acc: 0.9932 - val_mDice: 0.8099

Epoch 00019: val_mDice did not improve from 0.81507
Epoch 20/300
 - 31s - loss: 0.0403 - acc: 0.9950 - mDice: 0.9250 - val_loss: 0.6932 - val_acc: 0.9926 - val_mDice: 0.8027

Epoch 00020: val_mDice did not improve from 0.81507
Epoch 21/300
 - 31s - loss: 0.0393 - acc: 0.9951 - mDice: 0.9267 - val_loss: 0.5883 - val_acc: 0.9932 - val_mDice: 0.8133

Epoch 00021: val_mDice did not improve from 0.81507
Epoch 22/300
 - 31s - loss: 0.0387 - acc: 0.9952 - mDice: 0.9279 - val_loss: 0.5939 - val_acc: 0.9934 - val_mDice: 0.8156

Epoch 00022: val_mDice improved from 0.81507 to 0.81563, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 31s - loss: 0.0387 - acc: 0.9952 - mDice: 0.9279 - val_loss: 0.5620 - val_acc: 0.9932 - val_mDice: 0.8096

Epoch 00023: val_mDice did not improve from 0.81563
Epoch 24/300
 - 31s - loss: 0.0379 - acc: 0.9953 - mDice: 0.9293 - val_loss: 0.3507 - val_acc: 0.9935 - val_mDice: 0.8153

Epoch 00024: val_mDice did not improve from 0.81563
Epoch 25/300
 - 31s - loss: 0.0375 - acc: 0.9953 - mDice: 0.9301 - val_loss: 0.6267 - val_acc: 0.9929 - val_mDice: 0.8114

Epoch 00025: val_mDice did not improve from 0.81563
Epoch 26/300
 - 31s - loss: 0.0371 - acc: 0.9954 - mDice: 0.9308 - val_loss: 0.6456 - val_acc: 0.9932 - val_mDice: 0.8150

Epoch 00026: val_mDice did not improve from 0.81563
Epoch 27/300
 - 31s - loss: 0.0369 - acc: 0.9954 - mDice: 0.9311 - val_loss: 0.3191 - val_acc: 0.9932 - val_mDice: 0.8108

Epoch 00027: val_mDice did not improve from 0.81563
Epoch 28/300
 - 31s - loss: 0.0363 - acc: 0.9954 - mDice: 0.9322 - val_loss: 0.6136 - val_acc: 0.9930 - val_mDice: 0.8063

Epoch 00028: val_mDice did not improve from 0.81563
Epoch 29/300
 - 31s - loss: 0.0358 - acc: 0.9955 - mDice: 0.9331 - val_loss: 0.6035 - val_acc: 0.9932 - val_mDice: 0.8102

Epoch 00029: val_mDice did not improve from 0.81563
Epoch 30/300
 - 31s - loss: 0.0354 - acc: 0.9955 - mDice: 0.9338 - val_loss: 0.6839 - val_acc: 0.9931 - val_mDice: 0.8124

Epoch 00030: val_mDice did not improve from 0.81563
Epoch 31/300
 - 31s - loss: 0.0355 - acc: 0.9955 - mDice: 0.9337 - val_loss: 0.4626 - val_acc: 0.9931 - val_mDice: 0.8103

Epoch 00031: val_mDice did not improve from 0.81563
Epoch 32/300
 - 31s - loss: 0.0348 - acc: 0.9956 - mDice: 0.9349 - val_loss: 0.6272 - val_acc: 0.9933 - val_mDice: 0.8154

Epoch 00032: val_mDice did not improve from 0.81563
Epoch 33/300
 - 31s - loss: 0.0344 - acc: 0.9956 - mDice: 0.9357 - val_loss: 0.6715 - val_acc: 0.9931 - val_mDice: 0.8100

Epoch 00033: val_mDice did not improve from 0.81563
Epoch 34/300
 - 31s - loss: 0.0341 - acc: 0.9956 - mDice: 0.9362 - val_loss: 0.6544 - val_acc: 0.9933 - val_mDice: 0.8135

Epoch 00034: val_mDice did not improve from 0.81563
Epoch 35/300
 - 31s - loss: 0.0342 - acc: 0.9956 - mDice: 0.9361 - val_loss: 0.6636 - val_acc: 0.9934 - val_mDice: 0.8184

Epoch 00035: val_mDice improved from 0.81563 to 0.81845, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 31s - loss: 0.0340 - acc: 0.9956 - mDice: 0.9363 - val_loss: 0.6639 - val_acc: 0.9933 - val_mDice: 0.8126

Epoch 00036: val_mDice did not improve from 0.81845
Epoch 37/300
 - 31s - loss: 0.0338 - acc: 0.9956 - mDice: 0.9367 - val_loss: 0.6279 - val_acc: 0.9933 - val_mDice: 0.8136

Epoch 00037: val_mDice did not improve from 0.81845
Epoch 38/300
 - 31s - loss: 0.0332 - acc: 0.9957 - mDice: 0.9377 - val_loss: 0.6994 - val_acc: 0.9932 - val_mDice: 0.8135

Epoch 00038: val_mDice did not improve from 0.81845
Epoch 39/300
 - 31s - loss: 0.0332 - acc: 0.9957 - mDice: 0.9377 - val_loss: 0.5963 - val_acc: 0.9936 - val_mDice: 0.8196

Epoch 00039: val_mDice improved from 0.81845 to 0.81958, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 31s - loss: 0.0330 - acc: 0.9957 - mDice: 0.9381 - val_loss: 0.6556 - val_acc: 0.9934 - val_mDice: 0.8180

Epoch 00040: val_mDice did not improve from 0.81958
Epoch 41/300
 - 31s - loss: 0.0324 - acc: 0.9958 - mDice: 0.9392 - val_loss: 0.6261 - val_acc: 0.9934 - val_mDice: 0.8158

Epoch 00041: val_mDice did not improve from 0.81958
Epoch 42/300
 - 31s - loss: 0.0326 - acc: 0.9958 - mDice: 0.9389 - val_loss: 0.6466 - val_acc: 0.9934 - val_mDice: 0.8153

Epoch 00042: val_mDice did not improve from 0.81958
Epoch 43/300
 - 31s - loss: 0.0323 - acc: 0.9958 - mDice: 0.9395 - val_loss: 0.6596 - val_acc: 0.9933 - val_mDice: 0.8139

Epoch 00043: val_mDice did not improve from 0.81958
Epoch 44/300
 - 31s - loss: 0.0321 - acc: 0.9958 - mDice: 0.9399 - val_loss: 0.6721 - val_acc: 0.9931 - val_mDice: 0.8123

Epoch 00044: val_mDice did not improve from 0.81958
Epoch 45/300
 - 30s - loss: 0.0320 - acc: 0.9958 - mDice: 0.9401 - val_loss: 0.6269 - val_acc: 0.9932 - val_mDice: 0.8136

Epoch 00045: val_mDice did not improve from 0.81958
Epoch 46/300
 - 31s - loss: 0.0321 - acc: 0.9958 - mDice: 0.9399 - val_loss: 0.6646 - val_acc: 0.9932 - val_mDice: 0.8144

Epoch 00046: val_mDice did not improve from 0.81958
Epoch 47/300
 - 30s - loss: 0.0316 - acc: 0.9958 - mDice: 0.9408 - val_loss: 0.6506 - val_acc: 0.9933 - val_mDice: 0.8144

Epoch 00047: val_mDice did not improve from 0.81958
Epoch 48/300
 - 30s - loss: 0.0313 - acc: 0.9959 - mDice: 0.9413 - val_loss: 0.6680 - val_acc: 0.9933 - val_mDice: 0.8138

Epoch 00048: val_mDice did not improve from 0.81958
Epoch 49/300
 - 30s - loss: 0.0314 - acc: 0.9958 - mDice: 0.9410 - val_loss: 0.6579 - val_acc: 0.9930 - val_mDice: 0.8121

Epoch 00049: val_mDice did not improve from 0.81958
Epoch 50/300
 - 30s - loss: 0.0312 - acc: 0.9959 - mDice: 0.9415 - val_loss: 0.6791 - val_acc: 0.9934 - val_mDice: 0.8175

Epoch 00050: val_mDice did not improve from 0.81958
Epoch 51/300
 - 30s - loss: 0.0309 - acc: 0.9959 - mDice: 0.9421 - val_loss: 0.3513 - val_acc: 0.9934 - val_mDice: 0.8169

Epoch 00051: val_mDice did not improve from 0.81958
Epoch 52/300
 - 30s - loss: 0.0310 - acc: 0.9959 - mDice: 0.9418 - val_loss: 0.6155 - val_acc: 0.9935 - val_mDice: 0.8169

Epoch 00052: val_mDice did not improve from 0.81958
Epoch 53/300
 - 30s - loss: 0.0308 - acc: 0.9959 - mDice: 0.9422 - val_loss: 0.6611 - val_acc: 0.9934 - val_mDice: 0.8171

Epoch 00053: val_mDice did not improve from 0.81958
Epoch 54/300
 - 30s - loss: 0.0305 - acc: 0.9959 - mDice: 0.9427 - val_loss: 0.4772 - val_acc: 0.9939 - val_mDice: 0.8183

Epoch 00054: val_mDice did not improve from 0.81958
Epoch 55/300
 - 31s - loss: 0.0304 - acc: 0.9959 - mDice: 0.9429 - val_loss: 0.7000 - val_acc: 0.9931 - val_mDice: 0.8147

Epoch 00055: val_mDice did not improve from 0.81958
Epoch 56/300
 - 30s - loss: 0.0303 - acc: 0.9959 - mDice: 0.9431 - val_loss: 0.0814 - val_acc: 0.9934 - val_mDice: 0.8131

Epoch 00056: val_mDice did not improve from 0.81958
Epoch 57/300
 - 30s - loss: 0.0303 - acc: 0.9959 - mDice: 0.9432 - val_loss: 0.3296 - val_acc: 0.9935 - val_mDice: 0.8167

Epoch 00057: val_mDice did not improve from 0.81958
Epoch 58/300
 - 30s - loss: 0.0303 - acc: 0.9959 - mDice: 0.9432 - val_loss: 0.6280 - val_acc: 0.9934 - val_mDice: 0.8150

Epoch 00058: val_mDice did not improve from 0.81958
Epoch 59/300
 - 30s - loss: 0.0300 - acc: 0.9960 - mDice: 0.9436 - val_loss: 0.6585 - val_acc: 0.9935 - val_mDice: 0.8153

Epoch 00059: val_mDice did not improve from 0.81958
Epoch 60/300
 - 30s - loss: 0.0299 - acc: 0.9960 - mDice: 0.9438 - val_loss: 0.6921 - val_acc: 0.9933 - val_mDice: 0.8158

Epoch 00060: val_mDice did not improve from 0.81958
Epoch 61/300
 - 30s - loss: 0.0295 - acc: 0.9960 - mDice: 0.9446 - val_loss: 0.6836 - val_acc: 0.9933 - val_mDice: 0.8140

Epoch 00061: val_mDice did not improve from 0.81958
Epoch 62/300
 - 30s - loss: 0.0297 - acc: 0.9960 - mDice: 0.9442 - val_loss: 0.6309 - val_acc: 0.9934 - val_mDice: 0.8151

Epoch 00062: val_mDice did not improve from 0.81958
Epoch 63/300
 - 30s - loss: 0.0297 - acc: 0.9960 - mDice: 0.9442 - val_loss: 0.0492 - val_acc: 0.9934 - val_mDice: 0.8123

Epoch 00063: val_mDice did not improve from 0.81958
Epoch 64/300
 - 30s - loss: 0.0295 - acc: 0.9960 - mDice: 0.9446 - val_loss: 0.6959 - val_acc: 0.9931 - val_mDice: 0.8144

Epoch 00064: val_mDice did not improve from 0.81958
Epoch 65/300
 - 31s - loss: 0.0293 - acc: 0.9960 - mDice: 0.9449 - val_loss: 0.4644 - val_acc: 0.9935 - val_mDice: 0.8177

Epoch 00065: val_mDice did not improve from 0.81958
Epoch 66/300
 - 30s - loss: 0.0295 - acc: 0.9960 - mDice: 0.9447 - val_loss: 0.6362 - val_acc: 0.9932 - val_mDice: 0.8112

Epoch 00066: val_mDice did not improve from 0.81958
Epoch 67/300
 - 30s - loss: 0.0291 - acc: 0.9960 - mDice: 0.9453 - val_loss: 0.5693 - val_acc: 0.9934 - val_mDice: 0.8166

Epoch 00067: val_mDice did not improve from 0.81958
Epoch 68/300
 - 30s - loss: 0.0291 - acc: 0.9960 - mDice: 0.9454 - val_loss: 0.0487 - val_acc: 0.9934 - val_mDice: 0.8128

Epoch 00068: val_mDice did not improve from 0.81958
Epoch 69/300
 - 30s - loss: 0.0293 - acc: 0.9960 - mDice: 0.9450 - val_loss: 0.6243 - val_acc: 0.9936 - val_mDice: 0.8184

Epoch 00069: val_mDice did not improve from 0.81958
Epoch 70/300
 - 30s - loss: 0.0290 - acc: 0.9960 - mDice: 0.9456 - val_loss: 0.6387 - val_acc: 0.9934 - val_mDice: 0.8168

Epoch 00070: val_mDice did not improve from 0.81958
Epoch 71/300
 - 30s - loss: 0.0288 - acc: 0.9961 - mDice: 0.9459 - val_loss: 0.5512 - val_acc: 0.9935 - val_mDice: 0.8158

Epoch 00071: val_mDice did not improve from 0.81958
Epoch 72/300
 - 30s - loss: 0.0290 - acc: 0.9960 - mDice: 0.9456 - val_loss: 0.6426 - val_acc: 0.9936 - val_mDice: 0.8186

Epoch 00072: val_mDice did not improve from 0.81958
Epoch 73/300
 - 30s - loss: 0.0290 - acc: 0.9960 - mDice: 0.9455 - val_loss: 0.7039 - val_acc: 0.9935 - val_mDice: 0.8198

Epoch 00073: val_mDice improved from 0.81958 to 0.81981, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 31s - loss: 0.0286 - acc: 0.9961 - mDice: 0.9463 - val_loss: 0.6450 - val_acc: 0.9938 - val_mDice: 0.8218

Epoch 00074: val_mDice improved from 0.81981 to 0.82178, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd2/best_model_weights_TF_CSFn2.h5
Epoch 75/300
 - 31s - loss: 0.0283 - acc: 0.9961 - mDice: 0.9468 - val_loss: 0.5998 - val_acc: 0.9934 - val_mDice: 0.8174

Epoch 00075: val_mDice did not improve from 0.82178
Epoch 76/300
 - 31s - loss: 0.0282 - acc: 0.9961 - mDice: 0.9469 - val_loss: 0.6295 - val_acc: 0.9936 - val_mDice: 0.8182

Epoch 00076: val_mDice did not improve from 0.82178
Epoch 77/300
 - 31s - loss: 0.0284 - acc: 0.9961 - mDice: 0.9467 - val_loss: 0.5230 - val_acc: 0.9934 - val_mDice: 0.8101

Epoch 00077: val_mDice did not improve from 0.82178
Epoch 78/300
 - 31s - loss: 0.0284 - acc: 0.9961 - mDice: 0.9467 - val_loss: 0.5581 - val_acc: 0.9938 - val_mDice: 0.8210

Epoch 00078: val_mDice did not improve from 0.82178
Epoch 79/300
 - 30s - loss: 0.0285 - acc: 0.9961 - mDice: 0.9465 - val_loss: 0.6128 - val_acc: 0.9936 - val_mDice: 0.8178

Epoch 00079: val_mDice did not improve from 0.82178
Epoch 80/300
 - 31s - loss: 0.0281 - acc: 0.9961 - mDice: 0.9472 - val_loss: 0.5485 - val_acc: 0.9936 - val_mDice: 0.8168

Epoch 00080: val_mDice did not improve from 0.82178
Epoch 81/300
 - 30s - loss: 0.0281 - acc: 0.9961 - mDice: 0.9471 - val_loss: 0.6436 - val_acc: 0.9937 - val_mDice: 0.8177

Epoch 00081: val_mDice did not improve from 0.82178
Epoch 82/300
 - 30s - loss: 0.0278 - acc: 0.9961 - mDice: 0.9476 - val_loss: 0.6103 - val_acc: 0.9937 - val_mDice: 0.8193

Epoch 00082: val_mDice did not improve from 0.82178
Epoch 83/300
 - 30s - loss: 0.0279 - acc: 0.9961 - mDice: 0.9475 - val_loss: 0.6244 - val_acc: 0.9938 - val_mDice: 0.8207

Epoch 00083: val_mDice did not improve from 0.82178
Epoch 84/300
 - 30s - loss: 0.0281 - acc: 0.9961 - mDice: 0.9471 - val_loss: 0.5721 - val_acc: 0.9934 - val_mDice: 0.8107

Epoch 00084: val_mDice did not improve from 0.82178
Epoch 85/300
 - 30s - loss: 0.0278 - acc: 0.9961 - mDice: 0.9477 - val_loss: 0.5679 - val_acc: 0.9938 - val_mDice: 0.8206

Epoch 00085: val_mDice did not improve from 0.82178
Epoch 86/300
 - 30s - loss: 0.0278 - acc: 0.9961 - mDice: 0.9477 - val_loss: 0.2481 - val_acc: 0.9934 - val_mDice: 0.8116

Epoch 00086: val_mDice did not improve from 0.82178
Epoch 87/300
 - 30s - loss: 0.0278 - acc: 0.9961 - mDice: 0.9478 - val_loss: 0.5517 - val_acc: 0.9933 - val_mDice: 0.8136

Epoch 00087: val_mDice did not improve from 0.82178
Epoch 88/300
 - 30s - loss: 0.0277 - acc: 0.9961 - mDice: 0.9479 - val_loss: 0.5982 - val_acc: 0.9935 - val_mDice: 0.8146

Epoch 00088: val_mDice did not improve from 0.82178
Epoch 89/300
 - 30s - loss: 0.0275 - acc: 0.9961 - mDice: 0.9482 - val_loss: 0.6139 - val_acc: 0.9935 - val_mDice: 0.8159

Epoch 00089: val_mDice did not improve from 0.82178
Epoch 90/300
 - 31s - loss: 0.0274 - acc: 0.9961 - mDice: 0.9484 - val_loss: 0.6763 - val_acc: 0.9935 - val_mDice: 0.8167

Epoch 00090: val_mDice did not improve from 0.82178
Epoch 91/300
 - 31s - loss: 0.0275 - acc: 0.9962 - mDice: 0.9483 - val_loss: 0.6138 - val_acc: 0.9935 - val_mDice: 0.8129

Epoch 00091: val_mDice did not improve from 0.82178
Epoch 92/300
 - 30s - loss: 0.0276 - acc: 0.9961 - mDice: 0.9480 - val_loss: 0.6487 - val_acc: 0.9934 - val_mDice: 0.8153

Epoch 00092: val_mDice did not improve from 0.82178
Epoch 93/300
 - 31s - loss: 0.0274 - acc: 0.9961 - mDice: 0.9484 - val_loss: 0.6298 - val_acc: 0.9938 - val_mDice: 0.8189

Epoch 00093: val_mDice did not improve from 0.82178
Epoch 94/300
 - 31s - loss: 0.0274 - acc: 0.9961 - mDice: 0.9485 - val_loss: 0.6724 - val_acc: 0.9935 - val_mDice: 0.8155

Epoch 00094: val_mDice did not improve from 0.82178
Epoch 95/300
 - 30s - loss: 0.0273 - acc: 0.9961 - mDice: 0.9488 - val_loss: 0.5696 - val_acc: 0.9937 - val_mDice: 0.8176

Epoch 00095: val_mDice did not improve from 0.82178
Epoch 96/300
 - 30s - loss: 0.0272 - acc: 0.9961 - mDice: 0.9488 - val_loss: 0.5928 - val_acc: 0.9936 - val_mDice: 0.8163

Epoch 00096: val_mDice did not improve from 0.82178
Epoch 97/300
 - 30s - loss: 0.0269 - acc: 0.9962 - mDice: 0.9494 - val_loss: 0.6096 - val_acc: 0.9934 - val_mDice: 0.8166

Epoch 00097: val_mDice did not improve from 0.82178
Epoch 98/300
 - 30s - loss: 0.0271 - acc: 0.9962 - mDice: 0.9489 - val_loss: 0.6635 - val_acc: 0.9933 - val_mDice: 0.8106

Epoch 00098: val_mDice did not improve from 0.82178
Epoch 99/300
 - 30s - loss: 0.0271 - acc: 0.9962 - mDice: 0.9490 - val_loss: 0.5607 - val_acc: 0.9936 - val_mDice: 0.8176

Epoch 00099: val_mDice did not improve from 0.82178
Epoch 100/300
 - 30s - loss: 0.0270 - acc: 0.9962 - mDice: 0.9492 - val_loss: 0.6327 - val_acc: 0.9935 - val_mDice: 0.8132

Epoch 00100: val_mDice did not improve from 0.82178
Epoch 101/300
 - 30s - loss: 0.0271 - acc: 0.9962 - mDice: 0.9489 - val_loss: 0.6255 - val_acc: 0.9936 - val_mDice: 0.8182

Epoch 00101: val_mDice did not improve from 0.82178
Epoch 102/300
 - 30s - loss: 0.0270 - acc: 0.9962 - mDice: 0.9492 - val_loss: 0.6031 - val_acc: 0.9936 - val_mDice: 0.8188

Epoch 00102: val_mDice did not improve from 0.82178
Epoch 103/300
 - 30s - loss: 0.0268 - acc: 0.9962 - mDice: 0.9496 - val_loss: 0.5676 - val_acc: 0.9937 - val_mDice: 0.8160

Epoch 00103: val_mDice did not improve from 0.82178
Epoch 104/300
 - 30s - loss: 0.0267 - acc: 0.9962 - mDice: 0.9497 - val_loss: 0.4538 - val_acc: 0.9937 - val_mDice: 0.8208

Epoch 00104: val_mDice did not improve from 0.82178
Epoch 105/300
 - 30s - loss: 0.0268 - acc: 0.9962 - mDice: 0.9496 - val_loss: 0.6417 - val_acc: 0.9934 - val_mDice: 0.8132

Epoch 00105: val_mDice did not improve from 0.82178
Epoch 106/300
 - 30s - loss: 0.0267 - acc: 0.9962 - mDice: 0.9499 - val_loss: 0.6399 - val_acc: 0.9934 - val_mDice: 0.8140

Epoch 00106: val_mDice did not improve from 0.82178
Epoch 107/300
 - 30s - loss: 0.0267 - acc: 0.9962 - mDice: 0.9498 - val_loss: 0.6368 - val_acc: 0.9936 - val_mDice: 0.8156

Epoch 00107: val_mDice did not improve from 0.82178
Epoch 108/300
 - 30s - loss: 0.0268 - acc: 0.9962 - mDice: 0.9496 - val_loss: 0.6602 - val_acc: 0.9935 - val_mDice: 0.8164

Epoch 00108: val_mDice did not improve from 0.82178
Epoch 109/300
 - 30s - loss: 0.0265 - acc: 0.9962 - mDice: 0.9501 - val_loss: 0.6614 - val_acc: 0.9936 - val_mDice: 0.8195

Epoch 00109: val_mDice did not improve from 0.82178
Epoch 110/300
 - 30s - loss: 0.0264 - acc: 0.9962 - mDice: 0.9504 - val_loss: 0.7176 - val_acc: 0.9927 - val_mDice: 0.8054

Epoch 00110: val_mDice did not improve from 0.82178
Epoch 111/300
 - 30s - loss: 0.0263 - acc: 0.9962 - mDice: 0.9505 - val_loss: 0.7129 - val_acc: 0.9934 - val_mDice: 0.8179

Epoch 00111: val_mDice did not improve from 0.82178
Epoch 112/300
 - 30s - loss: 0.0263 - acc: 0.9962 - mDice: 0.9505 - val_loss: 0.6507 - val_acc: 0.9935 - val_mDice: 0.8121

Epoch 00112: val_mDice did not improve from 0.82178
Epoch 113/300
 - 30s - loss: 0.0264 - acc: 0.9962 - mDice: 0.9503 - val_loss: 0.6697 - val_acc: 0.9933 - val_mDice: 0.8113

Epoch 00113: val_mDice did not improve from 0.82178
Epoch 114/300
 - 30s - loss: 0.0263 - acc: 0.9962 - mDice: 0.9505 - val_loss: 0.7133 - val_acc: 0.9934 - val_mDice: 0.8183

Epoch 00114: val_mDice did not improve from 0.82178
Restoring model weights from the end of the best epoch
Epoch 00114: early stopping
{'val_loss': [0.8555952531751245, 0.7594992232043296, 0.7310441411100328, 0.7202882594428957, 0.6883239550516009, 0.723836716148071, 0.6993722190381959, 0.7108810018980876, 0.665686841821298, 0.7061408975860104, 0.4784910660237074, 0.6882993474137038, 0.5994861533399671, 0.666926352889277, 0.43632936652284116, 0.631473787361756, 0.6603481814963743, 0.6544946351787075, 0.6138989272294566, 0.6932091887574643, 0.5882712440798059, 0.5938979336060584, 0.5620239715790376, 0.3506862906506285, 0.6267364200903103, 0.6456194459460676, 0.3191433008760214, 0.6136252523865551, 0.6034908867441118, 0.6839488472323865, 0.46261831221636385, 0.6271642143838108, 0.6714927082648501, 0.6544205927057192, 0.6636453568935394, 0.6639384316513315, 0.6278587731067091, 0.6993501565884799, 0.5962948693195358, 0.6555971624329686, 0.6260784348705783, 0.646570636308752, 0.6596335573121905, 0.67210344504565, 0.6269181809620932, 0.6646348262438551, 0.6505680737318471, 0.6679756350349635, 0.6578679531812668, 0.6790800739545375, 0.3513271603733301, 0.6154606462223455, 0.6611128854565322, 0.47718976822216064, 0.7000465056626126, 0.08136566157918423, 0.3295529311290011, 0.6280451860511675, 0.6585264258319512, 0.692119269631803, 0.6835889989743009, 0.6308542352635413, 0.04916462616529316, 0.695931741851382, 0.4644260343629867, 0.636200656183064, 0.5693255121586844, 0.048709524096921086, 0.624331547296606, 0.6386573932832107, 0.5512458940502256, 0.6425993761513382, 0.7038664186839014, 0.6449966938234866, 0.5998143503675237, 0.6294598028762266, 0.5230241807876155, 0.5581491930643097, 0.6128324227174744, 0.5485172277549282, 0.6436117613920942, 0.6102859900565818, 0.6244201329536736, 0.5720542911440134, 0.5679476443910971, 0.24811933760065585, 0.5517215032596141, 0.598218951257877, 0.6138519115047529, 0.6763417724287137, 0.6138154388172552, 0.6486739008687437, 0.6298285825178027, 0.6724301881622523, 0.5696405461058021, 0.5927880017552525, 0.6096278215991333, 0.6635061393026263, 0.5607183577958494, 0.6326747235143557, 0.6255331342108548, 0.603135506506078, 0.5675610988400877, 0.45380754477810115, 0.6416709235636517, 0.6399224578635767, 0.6368451121961698, 0.6602431166684255, 0.6613976118387654, 0.7176405946956947, 0.7128542545251548, 0.650699644931592, 0.6697016601683572, 0.7132972198305652], 'val_acc': [0.9898841641843319, 0.9906032904982567, 0.9913002476096153, 0.991867957636714, 0.9926312528550625, 0.9920021668076515, 0.9930116571485996, 0.9928622413426638, 0.9931181613355875, 0.993015643209219, 0.9934681318700314, 0.993112176656723, 0.9931151680648327, 0.9931406080722809, 0.9933436512947083, 0.9931917544454336, 0.9931553304195404, 0.9934753607958555, 0.9931742865592241, 0.992592841386795, 0.9931974913924932, 0.9934396892786026, 0.9932398926466703, 0.993492579087615, 0.9929495509713888, 0.9932388961315155, 0.993165573105216, 0.9930251222103834, 0.9932149313390255, 0.9931446220725775, 0.993106696754694, 0.9932892750948668, 0.9930947180837393, 0.9932999946177006, 0.9934149943292141, 0.9933217111974955, 0.9932925272732973, 0.9932251684367657, 0.9936242774128914, 0.9934192448854446, 0.9933573845773935, 0.9934032782912254, 0.9933252036571503, 0.9930959604680538, 0.9931600634008646, 0.9931752849370241, 0.9932815469801426, 0.9933282025158405, 0.9930126592516899, 0.9934209734201431, 0.9934052713215351, 0.993475865572691, 0.9933653604239225, 0.9938570074737072, 0.9931376185268164, 0.9934374541044235, 0.9935137704014778, 0.9933905452489853, 0.9934935849159956, 0.9932653363794088, 0.9933406617492437, 0.9933531433343887, 0.9933838192373514, 0.9931059386581182, 0.993520000949502, 0.9932481236755848, 0.9934134967625141, 0.993393300101161, 0.9936090670526028, 0.9934379495680332, 0.9935090411454439, 0.9936110619455576, 0.9934980496764183, 0.9938068743795156, 0.9934429321438074, 0.9936068095266819, 0.9933835808187723, 0.9938213489949703, 0.9936190340667963, 0.9936462417244911, 0.9936938732862473, 0.9937240649014711, 0.9937632121145725, 0.9933628719300032, 0.9938018694519997, 0.9933977909386158, 0.993268322199583, 0.9934586435556412, 0.9934963248670101, 0.9934865925461054, 0.9934653770178556, 0.9933830611407757, 0.9937659613788128, 0.9934778679162264, 0.9937108475714922, 0.9935509450733662, 0.9934075139462948, 0.9932852853089571, 0.9936489667743444, 0.9935245104134083, 0.9935813806951046, 0.9935913551598787, 0.9937258046120405, 0.9937345292419195, 0.9934135023504496, 0.9934097602963448, 0.9935736525803804, 0.9935025572776794, 0.9936290327459574, 0.9927120730280876, 0.9934135042130947, 0.9934893306344748, 0.9933494050055742, 0.9934194926172495], 'val_mDice': [0.7085821963846684, 0.7475248631089926, 0.7635288033634424, 0.7827518228441477, 0.7965968921780586, 0.7878678292036057, 0.8052137400954962, 0.8023187424987555, 0.8053345512598753, 0.8037151489406824, 0.8123507909476757, 0.8091089874505997, 0.8081313315778971, 0.8071420434862375, 0.813089469447732, 0.8119005616754293, 0.8098167274147272, 0.8150659035891294, 0.8099398761987686, 0.8026631735265255, 0.8132916782051325, 0.8156324457377195, 0.8095796499401331, 0.8152928855270147, 0.8113507553935051, 0.8149686828255653, 0.810844823718071, 0.8063418790698051, 0.8102231379598379, 0.8124268427491188, 0.8103469759225845, 0.8154262509196997, 0.8099805098026991, 0.8135146461427212, 0.8184461947530508, 0.8125892840325832, 0.8135654125362635, 0.813478110358119, 0.819575022906065, 0.8179510850459337, 0.8158457092940807, 0.8153459057211876, 0.8138570003211498, 0.8122753258794546, 0.8136154152452946, 0.8143922034651041, 0.8143702335655689, 0.8137544151395559, 0.8120628632605076, 0.8175027277320623, 0.8168943971395493, 0.8168620988726616, 0.8171181194484234, 0.8183460216969252, 0.8146810717880726, 0.813091155141592, 0.816653398796916, 0.8149900007992983, 0.8152777701616287, 0.815783366560936, 0.813978798687458, 0.8151003811508417, 0.8122543152421713, 0.8144085388630629, 0.8177062124013901, 0.8112094085663557, 0.8166069071739912, 0.8128345850855112, 0.8184155635535717, 0.816821176558733, 0.8157761581242085, 0.818600608035922, 0.8198108337819576, 0.8217824622988701, 0.8174049761146307, 0.818203529343009, 0.8101075142621994, 0.8210039976984262, 0.8177762571722269, 0.8168341964483261, 0.8177426178008318, 0.819313507527113, 0.8206931967288256, 0.8106868620961905, 0.820607990026474, 0.8116253931075335, 0.813632421195507, 0.8146372158080339, 0.8158882614225149, 0.8167015109211206, 0.8128693886101246, 0.815333891659975, 0.8189042937010527, 0.8154911920428276, 0.8176135085523129, 0.8163044508546591, 0.816598990932107, 0.8106355927884579, 0.8175589237362146, 0.8132483717054129, 0.8182481583207846, 0.8187573030591011, 0.8160499297082424, 0.8207674976438284, 0.8131731022149324, 0.8140173647552729, 0.8156292513012886, 0.8163660671561956, 0.8195321727544069, 0.8053501788526773, 0.8178746327757835, 0.812072679400444, 0.8113089855760336, 0.8183330483734608], 'loss': [0.42924425642246206, 0.11558182215277182, 0.08801401479024082, 0.07527334748334387, 0.06858093784287775, 0.06325229894241292, 0.060266549709720785, 0.05681695859735126, 0.054099704664271095, 0.05161354416901051, 0.04972805451518209, 0.04894190899568096, 0.046468456874027946, 0.045458644592167814, 0.04396214590525743, 0.04341433689528861, 0.04229801391767849, 0.04214855741206965, 0.04058487012967653, 0.04030174475461435, 0.039348667544634466, 0.038660726705731605, 0.03869835163177832, 0.0378906728090175, 0.037452377214035784, 0.03705236986946032, 0.036875901507665794, 0.036319805940662274, 0.03581100927092991, 0.03540884670092175, 0.035478630476803594, 0.03477872777598216, 0.03436732097167794, 0.034064852463890204, 0.034154952364480635, 0.03404614703143925, 0.03380023776048794, 0.03324227609096109, 0.033249967975321856, 0.03301847915963573, 0.032436000115921015, 0.03257831554343521, 0.03226828173454754, 0.03205186813447351, 0.03196992938752698, 0.03207426347021125, 0.03157825835752054, 0.03131330400217115, 0.03143399059374296, 0.031180866348303, 0.030873988162407176, 0.03101169195970142, 0.03082172707306656, 0.03052080671295508, 0.03042576853517, 0.030318795154642683, 0.030260274193655522, 0.030267747216453825, 0.030033808443931193, 0.02990795658392553, 0.029498718963963888, 0.029709674128198908, 0.029719713520666817, 0.029484046780657615, 0.029325373318430242, 0.029454397918632448, 0.029118259997777205, 0.029079609263034333, 0.029274900409334472, 0.028959266686678087, 0.02880360519913198, 0.028950246116093425, 0.02901235532564812, 0.028575230045524348, 0.028331388405043654, 0.0282277920250591, 0.02837344378222568, 0.028356343590651943, 0.02845623492943544, 0.028105592111886703, 0.028124246405022296, 0.027846186316960696, 0.027912608376074725, 0.028132208340900956, 0.027835582066260245, 0.02783100781251367, 0.027760839099056894, 0.027705666253437795, 0.027548420193515423, 0.027445863448260856, 0.027509976215413866, 0.027640454360958355, 0.027430854563764595, 0.027366824519524137, 0.027250662594696044, 0.02724603906038387, 0.02691251663329904, 0.027147036213291443, 0.027132939178969674, 0.027012380919904745, 0.027148485226132276, 0.027018388353900184, 0.026807392321841234, 0.026716725783474744, 0.02676589241154181, 0.02665613618181276, 0.0266592481768812, 0.026781757890769548, 0.02650671657267882, 0.026371253686822346, 0.02630394347621455, 0.026303025197782652, 0.026417326720123493, 0.026285353700025608], 'acc': [0.9456297855032603, 0.9883679668288676, 0.9909179161217372, 0.9919316302930851, 0.9924936493722573, 0.9929175455423132, 0.9931970200112601, 0.9934924219673181, 0.9937067288713642, 0.9939368571071131, 0.994103585931362, 0.9942021909817678, 0.9944375630689302, 0.9945465403108962, 0.9946872669187616, 0.9947392568849196, 0.994833396316835, 0.9948671134670285, 0.9950110268493112, 0.9950462076962305, 0.9951374501498912, 0.9952102643875373, 0.9952078581936644, 0.9952785089634514, 0.9953146759081735, 0.995367597699844, 0.9953866279525486, 0.9954288793770821, 0.9954891790561979, 0.9955100603908061, 0.9955148157639081, 0.995558702171479, 0.99558869777441, 0.9956225898327611, 0.9956115413809039, 0.9956212134342984, 0.9956470373215071, 0.9956826060937647, 0.9956931979506359, 0.9957161817426561, 0.9957532698412563, 0.9957595501292855, 0.9957617302451716, 0.9958111019074688, 0.9957744826890457, 0.9958004535207131, 0.9958352697938525, 0.9958501409830581, 0.9958362671450011, 0.9958682254491762, 0.9958758220947397, 0.9958659220381704, 0.9959066753896033, 0.9959089851786592, 0.9959149735375842, 0.9959367086444982, 0.9959358275733067, 0.9959402447781719, 0.9959604090634325, 0.9959942552289079, 0.9959952792279796, 0.9959815718217138, 0.9959735982340776, 0.9959979220468214, 0.9960003005955518, 0.9960040574610074, 0.9960311716603142, 0.9960375768639449, 0.9960061315322872, 0.9960290643899328, 0.9960523750206672, 0.9960343742794424, 0.9960057579419803, 0.9960704587319454, 0.9960544428316243, 0.9960864698262224, 0.9960725506977766, 0.9960732834671825, 0.9960695798144712, 0.9960930087611528, 0.9960904814397277, 0.996108328830743, 0.9961044637877392, 0.9960998385240908, 0.9961122435408214, 0.9961062849599808, 0.9961200378089884, 0.9961203866419344, 0.9961140967625919, 0.9961477579230615, 0.9961528761940606, 0.9961155302795754, 0.9961195682362978, 0.9961151190442298, 0.9961310826874754, 0.9961351255956699, 0.9961805456369143, 0.996165434727204, 0.9961580713132927, 0.9961564752218185, 0.9961576956523701, 0.9961641568665002, 0.9961884575700655, 0.9961709189570102, 0.996183782320786, 0.996155988336288, 0.9961777491770071, 0.9961675254742111, 0.9961773742639992, 0.9962024080278262, 0.9962124983317292, 0.9961964175982856, 0.9961882075241831, 0.9962049137913033], 'mDice': [0.5393507697945087, 0.8048055080554759, 0.8447845852290544, 0.8651701893570449, 0.8762012164573629, 0.8851183201705203, 0.8901899084336281, 0.8960474849827574, 0.9007885390227163, 0.9050897219406266, 0.9084171675369828, 0.9098045929004275, 0.9141476743517956, 0.9159040496617199, 0.9185382837449769, 0.9194949256275483, 0.9214586145207208, 0.9217248631158024, 0.9245055130969305, 0.9250167737553396, 0.9267150567732193, 0.9279326013160303, 0.9278630603131232, 0.9293314560484329, 0.9301072289071959, 0.9308313909302166, 0.931144164728207, 0.9321558736987516, 0.9330641486038934, 0.9337992804646285, 0.933667765257042, 0.9349446752919848, 0.935695433555697, 0.936244137856109, 0.9360766270178127, 0.9362762133266586, 0.9367239379198609, 0.9377419736114712, 0.9377261586508935, 0.9381408980530674, 0.9392118780707405, 0.938947725575796, 0.939520031473453, 0.9399111592161596, 0.9400789053151731, 0.939864541237205, 0.940779666147457, 0.9412664008345548, 0.9410457383039259, 0.9415105047701847, 0.9420714282097544, 0.9418247261847355, 0.9421611529714045, 0.9427204168437041, 0.9428925454318766, 0.9430843277427395, 0.9431952197432338, 0.9431821435215554, 0.9436050719384935, 0.9438372176948624, 0.9446022078607837, 0.9442068857433101, 0.9441901676065071, 0.9446191119790368, 0.9449133924162594, 0.9446748104455012, 0.9452910829299527, 0.945361803879067, 0.9450090367494594, 0.9455880601466762, 0.9458725019255845, 0.9456085576487014, 0.9454952047388354, 0.9462911006713752, 0.9467516396745678, 0.9469417903680093, 0.9466687476675145, 0.9467073798636686, 0.9465154600473069, 0.9471660289903461, 0.9471316944435109, 0.9476404022475188, 0.9475240030119169, 0.9471152572040706, 0.9476615487940568, 0.9476692466781823, 0.947798674670581, 0.9479044766754061, 0.9481964529744836, 0.9483778894508538, 0.9482556430182972, 0.948027964674029, 0.9484197396122371, 0.9485336816780406, 0.9487521198688657, 0.9487577265281496, 0.9493695935666167, 0.9489417158450706, 0.9489598606775983, 0.9491906416351072, 0.9489383421681602, 0.949181099074829, 0.9495676130011368, 0.9497374075553524, 0.9496420795346603, 0.9498592737217709, 0.9498473104871606, 0.9496201226225682, 0.950131330989276, 0.9503728937393588, 0.9504979386262615, 0.9505068652788022, 0.9502992504452169, 0.950542861103416]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:00<00:03,  1.19it/s]predicting test subjects:  40%|████      | 2/5 [00:01<00:01,  1.54it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.95it/s]predicting test subjects:  80%|████████  | 4/5 [00:01<00:00,  2.41it/s]predicting test subjects: 100%|██████████| 5/5 [00:01<00:00,  2.78it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:12,  3.66it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:13,  3.58it/s]predicting train subjects:   1%|          | 3/266 [00:00<01:14,  3.52it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:15,  3.49it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:14,  3.52it/s]predicting train subjects:   2%|▏         | 6/266 [00:01<01:15,  3.45it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:16,  3.40it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:16,  3.37it/s]predicting train subjects:   3%|▎         | 9/266 [00:02<01:16,  3.35it/s]predicting train subjects:   4%|▍         | 10/266 [00:02<01:14,  3.44it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:17,  3.31it/s]predicting train subjects:   5%|▍         | 12/266 [00:03<01:17,  3.29it/s]predicting train subjects:   5%|▍         | 13/266 [00:03<01:17,  3.26it/s]predicting train subjects:   5%|▌         | 14/266 [00:04<01:15,  3.35it/s]predicting train subjects:   6%|▌         | 15/266 [00:04<01:13,  3.42it/s]predicting train subjects:   6%|▌         | 16/266 [00:04<01:10,  3.55it/s]predicting train subjects:   6%|▋         | 17/266 [00:05<01:15,  3.31it/s]predicting train subjects:   7%|▋         | 18/266 [00:05<01:16,  3.24it/s]predicting train subjects:   7%|▋         | 19/266 [00:05<01:16,  3.22it/s]predicting train subjects:   8%|▊         | 20/266 [00:05<01:13,  3.34it/s]predicting train subjects:   8%|▊         | 21/266 [00:06<01:10,  3.47it/s]predicting train subjects:   8%|▊         | 22/266 [00:06<01:07,  3.62it/s]predicting train subjects:   9%|▊         | 23/266 [00:06<01:06,  3.67it/s]predicting train subjects:   9%|▉         | 24/266 [00:07<01:09,  3.48it/s]predicting train subjects:   9%|▉         | 25/266 [00:07<01:10,  3.42it/s]predicting train subjects:  10%|▉         | 26/266 [00:07<01:07,  3.54it/s]predicting train subjects:  10%|█         | 27/266 [00:07<01:06,  3.59it/s]predicting train subjects:  11%|█         | 28/266 [00:08<01:03,  3.72it/s]predicting train subjects:  11%|█         | 29/266 [00:08<01:01,  3.84it/s]predicting train subjects:  11%|█▏        | 30/266 [00:08<01:01,  3.81it/s]predicting train subjects:  12%|█▏        | 31/266 [00:08<01:04,  3.64it/s]predicting train subjects:  12%|█▏        | 32/266 [00:09<01:04,  3.64it/s]predicting train subjects:  12%|█▏        | 33/266 [00:09<01:01,  3.78it/s]predicting train subjects:  13%|█▎        | 34/266 [00:09<00:59,  3.87it/s]predicting train subjects:  13%|█▎        | 35/266 [00:09<00:59,  3.86it/s]predicting train subjects:  14%|█▎        | 36/266 [00:10<01:00,  3.80it/s]predicting train subjects:  14%|█▍        | 37/266 [00:10<01:00,  3.77it/s]predicting train subjects:  14%|█▍        | 38/266 [00:10<00:58,  3.87it/s]predicting train subjects:  15%|█▍        | 39/266 [00:10<00:57,  3.95it/s]predicting train subjects:  15%|█▌        | 40/266 [00:11<00:56,  4.01it/s]predicting train subjects:  15%|█▌        | 41/266 [00:11<00:55,  4.05it/s]predicting train subjects:  16%|█▌        | 42/266 [00:11<00:56,  3.95it/s]predicting train subjects:  16%|█▌        | 43/266 [00:11<00:54,  4.11it/s]predicting train subjects:  17%|█▋        | 44/266 [00:12<00:52,  4.22it/s]predicting train subjects:  17%|█▋        | 45/266 [00:12<00:49,  4.44it/s]predicting train subjects:  17%|█▋        | 46/266 [00:12<00:47,  4.58it/s]predicting train subjects:  18%|█▊        | 47/266 [00:12<00:48,  4.53it/s]predicting train subjects:  18%|█▊        | 48/266 [00:12<00:46,  4.67it/s]predicting train subjects:  18%|█▊        | 49/266 [00:13<00:46,  4.64it/s]predicting train subjects:  19%|█▉        | 50/266 [00:13<00:45,  4.77it/s]predicting train subjects:  19%|█▉        | 51/266 [00:13<00:48,  4.44it/s]predicting train subjects:  20%|█▉        | 52/266 [00:13<00:48,  4.45it/s]predicting train subjects:  20%|█▉        | 53/266 [00:14<00:49,  4.31it/s]predicting train subjects:  20%|██        | 54/266 [00:14<00:48,  4.40it/s]predicting train subjects:  21%|██        | 55/266 [00:14<00:46,  4.53it/s]predicting train subjects:  21%|██        | 56/266 [00:14<00:44,  4.70it/s]predicting train subjects:  21%|██▏       | 57/266 [00:14<00:43,  4.80it/s]predicting train subjects:  22%|██▏       | 58/266 [00:15<00:43,  4.79it/s]predicting train subjects:  22%|██▏       | 59/266 [00:15<00:42,  4.89it/s]predicting train subjects:  23%|██▎       | 60/266 [00:15<00:41,  4.91it/s]predicting train subjects:  23%|██▎       | 61/266 [00:15<00:41,  4.89it/s]predicting train subjects:  23%|██▎       | 62/266 [00:15<00:40,  5.00it/s]predicting train subjects:  24%|██▎       | 63/266 [00:16<00:39,  5.09it/s]predicting train subjects:  24%|██▍       | 64/266 [00:16<00:39,  5.10it/s]predicting train subjects:  24%|██▍       | 65/266 [00:16<00:39,  5.12it/s]predicting train subjects:  25%|██▍       | 66/266 [00:16<00:41,  4.87it/s]predicting train subjects:  25%|██▌       | 67/266 [00:16<00:39,  4.98it/s]predicting train subjects:  26%|██▌       | 68/266 [00:17<00:39,  5.06it/s]predicting train subjects:  26%|██▌       | 69/266 [00:17<00:38,  5.09it/s]predicting train subjects:  26%|██▋       | 70/266 [00:17<00:38,  5.04it/s]predicting train subjects:  27%|██▋       | 71/266 [00:17<00:39,  4.92it/s]predicting train subjects:  27%|██▋       | 72/266 [00:17<00:40,  4.83it/s]predicting train subjects:  27%|██▋       | 73/266 [00:18<00:39,  4.84it/s]predicting train subjects:  28%|██▊       | 74/266 [00:18<00:40,  4.73it/s]predicting train subjects:  28%|██▊       | 75/266 [00:18<00:39,  4.86it/s]predicting train subjects:  29%|██▊       | 76/266 [00:18<00:38,  4.97it/s]predicting train subjects:  29%|██▉       | 77/266 [00:18<00:37,  5.01it/s]predicting train subjects:  29%|██▉       | 78/266 [00:19<00:41,  4.57it/s]predicting train subjects:  30%|██▉       | 79/266 [00:19<00:42,  4.43it/s]predicting train subjects:  30%|███       | 80/266 [00:19<00:44,  4.19it/s]predicting train subjects:  30%|███       | 81/266 [00:19<00:44,  4.17it/s]predicting train subjects:  31%|███       | 82/266 [00:20<00:45,  4.04it/s]predicting train subjects:  31%|███       | 83/266 [00:20<00:48,  3.77it/s]predicting train subjects:  32%|███▏      | 84/266 [00:20<00:46,  3.88it/s]predicting train subjects:  32%|███▏      | 85/266 [00:21<00:46,  3.88it/s]predicting train subjects:  32%|███▏      | 86/266 [00:21<00:46,  3.91it/s]predicting train subjects:  33%|███▎      | 87/266 [00:21<00:48,  3.72it/s]predicting train subjects:  33%|███▎      | 88/266 [00:21<00:47,  3.79it/s]predicting train subjects:  33%|███▎      | 89/266 [00:22<00:45,  3.90it/s]predicting train subjects:  34%|███▍      | 90/266 [00:22<00:44,  3.95it/s]predicting train subjects:  34%|███▍      | 91/266 [00:22<00:43,  4.00it/s]predicting train subjects:  35%|███▍      | 92/266 [00:22<00:43,  4.01it/s]predicting train subjects:  35%|███▍      | 93/266 [00:23<00:43,  3.99it/s]predicting train subjects:  35%|███▌      | 94/266 [00:23<00:42,  4.03it/s]predicting train subjects:  36%|███▌      | 95/266 [00:23<00:42,  4.02it/s]predicting train subjects:  36%|███▌      | 96/266 [00:23<00:45,  3.73it/s]predicting train subjects:  36%|███▋      | 97/266 [00:24<00:47,  3.58it/s]predicting train subjects:  37%|███▋      | 98/266 [00:24<00:45,  3.67it/s]predicting train subjects:  37%|███▋      | 99/266 [00:24<00:44,  3.78it/s]predicting train subjects:  38%|███▊      | 100/266 [00:24<00:40,  4.08it/s]predicting train subjects:  38%|███▊      | 101/266 [00:25<00:39,  4.20it/s]predicting train subjects:  38%|███▊      | 102/266 [00:25<00:37,  4.34it/s]predicting train subjects:  39%|███▊      | 103/266 [00:25<00:36,  4.46it/s]predicting train subjects:  39%|███▉      | 104/266 [00:25<00:35,  4.53it/s]predicting train subjects:  39%|███▉      | 105/266 [00:25<00:35,  4.58it/s]predicting train subjects:  40%|███▉      | 106/266 [00:26<00:34,  4.68it/s]predicting train subjects:  40%|████      | 107/266 [00:26<00:34,  4.65it/s]predicting train subjects:  41%|████      | 108/266 [00:26<00:34,  4.62it/s]predicting train subjects:  41%|████      | 109/266 [00:26<00:34,  4.55it/s]predicting train subjects:  41%|████▏     | 110/266 [00:27<00:34,  4.54it/s]predicting train subjects:  42%|████▏     | 111/266 [00:27<00:33,  4.58it/s]predicting train subjects:  42%|████▏     | 112/266 [00:27<00:33,  4.55it/s]predicting train subjects:  42%|████▏     | 113/266 [00:27<00:33,  4.54it/s]predicting train subjects:  43%|████▎     | 114/266 [00:27<00:33,  4.58it/s]predicting train subjects:  43%|████▎     | 115/266 [00:28<00:32,  4.61it/s]predicting train subjects:  44%|████▎     | 116/266 [00:28<00:32,  4.57it/s]predicting train subjects:  44%|████▍     | 117/266 [00:28<00:31,  4.67it/s]predicting train subjects:  44%|████▍     | 118/266 [00:28<00:31,  4.72it/s]predicting train subjects:  45%|████▍     | 119/266 [00:29<00:33,  4.37it/s]predicting train subjects:  45%|████▌     | 120/266 [00:29<00:38,  3.83it/s]predicting train subjects:  45%|████▌     | 121/266 [00:29<00:38,  3.74it/s]predicting train subjects:  46%|████▌     | 122/266 [00:29<00:38,  3.74it/s]predicting train subjects:  46%|████▌     | 123/266 [00:30<00:38,  3.71it/s]predicting train subjects:  47%|████▋     | 124/266 [00:30<00:37,  3.83it/s]predicting train subjects:  47%|████▋     | 125/266 [00:30<00:36,  3.89it/s]predicting train subjects:  47%|████▋     | 126/266 [00:30<00:35,  3.90it/s]predicting train subjects:  48%|████▊     | 127/266 [00:31<00:35,  3.87it/s]predicting train subjects:  48%|████▊     | 128/266 [00:31<00:36,  3.79it/s]predicting train subjects:  48%|████▊     | 129/266 [00:31<00:35,  3.86it/s]predicting train subjects:  49%|████▉     | 130/266 [00:31<00:34,  3.95it/s]predicting train subjects:  49%|████▉     | 131/266 [00:32<00:34,  3.92it/s]predicting train subjects:  50%|████▉     | 132/266 [00:32<00:33,  4.00it/s]predicting train subjects:  50%|█████     | 133/266 [00:32<00:35,  3.77it/s]predicting train subjects:  50%|█████     | 134/266 [00:33<00:37,  3.52it/s]predicting train subjects:  51%|█████     | 135/266 [00:33<00:36,  3.63it/s]predicting train subjects:  51%|█████     | 136/266 [00:33<00:38,  3.39it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:34<00:38,  3.32it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:34<00:35,  3.57it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:34<00:33,  3.77it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:34<00:32,  3.92it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:34<00:30,  4.05it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:35<00:30,  4.08it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:35<00:29,  4.13it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:35<00:30,  4.01it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:35<00:30,  3.97it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:36<00:31,  3.80it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:36<00:31,  3.81it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:36<00:30,  3.89it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:36<00:29,  4.03it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:37<00:28,  4.04it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:37<00:30,  3.82it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:37<00:28,  3.96it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:38<00:29,  3.84it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:38<00:28,  3.91it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:38<00:25,  4.31it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:38<00:24,  4.58it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:38<00:22,  4.85it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:39<00:22,  4.80it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:39<00:23,  4.63it/s]predicting train subjects:  60%|██████    | 160/266 [00:39<00:23,  4.47it/s]predicting train subjects:  61%|██████    | 161/266 [00:39<00:22,  4.75it/s]predicting train subjects:  61%|██████    | 162/266 [00:39<00:22,  4.58it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:40<00:22,  4.48it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:40<00:23,  4.43it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:40<00:23,  4.33it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:40<00:21,  4.65it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:40<00:20,  4.91it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:41<00:20,  4.82it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:41<00:20,  4.75it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:41<00:19,  4.88it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:41<00:20,  4.68it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:42<00:20,  4.64it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:42<00:21,  4.32it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:42<00:20,  4.45it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:42<00:19,  4.60it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:42<00:19,  4.65it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:43<00:18,  4.81it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:43<00:18,  4.83it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:43<00:17,  4.85it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:43<00:17,  4.86it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:43<00:17,  4.89it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:44<00:17,  4.91it/s]predicting train subjects:  69%|██████▉   | 183/266 [00:44<00:16,  4.95it/s]predicting train subjects:  69%|██████▉   | 184/266 [00:44<00:18,  4.55it/s]predicting train subjects:  70%|██████▉   | 185/266 [00:44<00:18,  4.46it/s]predicting train subjects:  70%|██████▉   | 186/266 [00:45<00:18,  4.24it/s]predicting train subjects:  70%|███████   | 187/266 [00:45<00:18,  4.24it/s]predicting train subjects:  71%|███████   | 188/266 [00:45<00:17,  4.44it/s]predicting train subjects:  71%|███████   | 189/266 [00:45<00:16,  4.55it/s]predicting train subjects:  71%|███████▏  | 190/266 [00:46<00:17,  4.36it/s]predicting train subjects:  72%|███████▏  | 191/266 [00:46<00:16,  4.46it/s]predicting train subjects:  72%|███████▏  | 192/266 [00:46<00:18,  4.02it/s]predicting train subjects:  73%|███████▎  | 193/266 [00:46<00:17,  4.11it/s]predicting train subjects:  73%|███████▎  | 194/266 [00:47<00:18,  3.88it/s]predicting train subjects:  73%|███████▎  | 195/266 [00:47<00:17,  4.05it/s]predicting train subjects:  74%|███████▎  | 196/266 [00:47<00:16,  4.19it/s]predicting train subjects:  74%|███████▍  | 197/266 [00:47<00:15,  4.32it/s]predicting train subjects:  74%|███████▍  | 198/266 [00:47<00:15,  4.46it/s]predicting train subjects:  75%|███████▍  | 199/266 [00:48<00:15,  4.36it/s]predicting train subjects:  75%|███████▌  | 200/266 [00:48<00:14,  4.46it/s]predicting train subjects:  76%|███████▌  | 201/266 [00:48<00:14,  4.39it/s]predicting train subjects:  76%|███████▌  | 202/266 [00:48<00:14,  4.45it/s]predicting train subjects:  76%|███████▋  | 203/266 [00:49<00:15,  4.19it/s]predicting train subjects:  77%|███████▋  | 204/266 [00:49<00:14,  4.15it/s]predicting train subjects:  77%|███████▋  | 205/266 [00:49<00:14,  4.33it/s]predicting train subjects:  77%|███████▋  | 206/266 [00:49<00:13,  4.47it/s]predicting train subjects:  78%|███████▊  | 207/266 [00:49<00:13,  4.44it/s]predicting train subjects:  78%|███████▊  | 208/266 [00:50<00:12,  4.53it/s]predicting train subjects:  79%|███████▊  | 209/266 [00:50<00:13,  4.26it/s]predicting train subjects:  79%|███████▉  | 210/266 [00:50<00:12,  4.35it/s]predicting train subjects:  79%|███████▉  | 211/266 [00:50<00:12,  4.49it/s]predicting train subjects:  80%|███████▉  | 212/266 [00:51<00:11,  4.63it/s]predicting train subjects:  80%|████████  | 213/266 [00:51<00:11,  4.66it/s]predicting train subjects:  80%|████████  | 214/266 [00:51<00:10,  4.87it/s]predicting train subjects:  81%|████████  | 215/266 [00:51<00:10,  4.88it/s]predicting train subjects:  81%|████████  | 216/266 [00:51<00:10,  4.89it/s]predicting train subjects:  82%|████████▏ | 217/266 [00:52<00:09,  4.97it/s]predicting train subjects:  82%|████████▏ | 218/266 [00:52<00:09,  5.10it/s]predicting train subjects:  82%|████████▏ | 219/266 [00:52<00:09,  5.12it/s]predicting train subjects:  83%|████████▎ | 220/266 [00:52<00:08,  5.15it/s]predicting train subjects:  83%|████████▎ | 221/266 [00:52<00:09,  4.88it/s]predicting train subjects:  83%|████████▎ | 222/266 [00:53<00:08,  5.00it/s]predicting train subjects:  84%|████████▍ | 223/266 [00:53<00:08,  5.00it/s]predicting train subjects:  84%|████████▍ | 224/266 [00:53<00:08,  4.93it/s]predicting train subjects:  85%|████████▍ | 225/266 [00:53<00:08,  4.93it/s]predicting train subjects:  85%|████████▍ | 226/266 [00:53<00:08,  4.96it/s]predicting train subjects:  85%|████████▌ | 227/266 [00:54<00:07,  4.98it/s]predicting train subjects:  86%|████████▌ | 228/266 [00:54<00:07,  5.01it/s]predicting train subjects:  86%|████████▌ | 229/266 [00:54<00:07,  4.95it/s]predicting train subjects:  86%|████████▋ | 230/266 [00:54<00:07,  4.86it/s]predicting train subjects:  87%|████████▋ | 231/266 [00:54<00:07,  4.97it/s]predicting train subjects:  87%|████████▋ | 232/266 [00:55<00:06,  5.07it/s]predicting train subjects:  88%|████████▊ | 233/266 [00:55<00:06,  5.11it/s]predicting train subjects:  88%|████████▊ | 234/266 [00:55<00:06,  5.05it/s]predicting train subjects:  88%|████████▊ | 235/266 [00:55<00:06,  4.73it/s]predicting train subjects:  89%|████████▊ | 236/266 [00:55<00:06,  4.85it/s]predicting train subjects:  89%|████████▉ | 237/266 [00:56<00:05,  4.95it/s]predicting train subjects:  89%|████████▉ | 238/266 [00:56<00:05,  4.94it/s]predicting train subjects:  90%|████████▉ | 239/266 [00:56<00:05,  5.01it/s]predicting train subjects:  90%|█████████ | 240/266 [00:56<00:05,  5.01it/s]predicting train subjects:  91%|█████████ | 241/266 [00:56<00:05,  5.00it/s]predicting train subjects:  91%|█████████ | 242/266 [00:57<00:04,  4.97it/s]predicting train subjects:  91%|█████████▏| 243/266 [00:57<00:04,  5.03it/s]predicting train subjects:  92%|█████████▏| 244/266 [00:57<00:04,  4.64it/s]predicting train subjects:  92%|█████████▏| 245/266 [00:57<00:04,  4.40it/s]predicting train subjects:  92%|█████████▏| 246/266 [00:58<00:04,  4.21it/s]predicting train subjects:  93%|█████████▎| 247/266 [00:58<00:04,  4.10it/s]predicting train subjects:  93%|█████████▎| 248/266 [00:58<00:04,  4.08it/s]predicting train subjects:  94%|█████████▎| 249/266 [00:58<00:04,  3.77it/s]predicting train subjects:  94%|█████████▍| 250/266 [00:59<00:04,  3.85it/s]predicting train subjects:  94%|█████████▍| 251/266 [00:59<00:04,  3.75it/s]predicting train subjects:  95%|█████████▍| 252/266 [00:59<00:03,  3.76it/s]predicting train subjects:  95%|█████████▌| 253/266 [00:59<00:03,  3.77it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:00<00:03,  3.89it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:00<00:02,  3.95it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:00<00:02,  3.96it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:00<00:02,  4.05it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:01<00:01,  4.09it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:01<00:01,  3.87it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:01<00:01,  3.73it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:01<00:01,  3.74it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:02<00:01,  3.79it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:02<00:00,  3.92it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:02<00:00,  4.03it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:02<00:00,  4.08it/s]predicting train subjects: 100%|██████████| 266/266 [01:03<00:00,  4.13it/s]
predicting test subjects sagittal:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects sagittal:  20%|██        | 1/5 [00:00<00:00,  4.83it/s]predicting test subjects sagittal:  40%|████      | 2/5 [00:00<00:00,  4.81it/s]predicting test subjects sagittal:  60%|██████    | 3/5 [00:00<00:00,  4.94it/s]predicting test subjects sagittal:  80%|████████  | 4/5 [00:00<00:00,  5.00it/s]predicting test subjects sagittal: 100%|██████████| 5/5 [00:01<00:00,  4.66it/s]
predicting train subjects sagittal:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects sagittal:   0%|          | 1/266 [00:00<01:21,  3.24it/s]predicting train subjects sagittal:   1%|          | 2/266 [00:00<01:17,  3.39it/s]predicting train subjects sagittal:   1%|          | 3/266 [00:00<01:10,  3.74it/s]predicting train subjects sagittal:   2%|▏         | 4/266 [00:01<01:09,  3.76it/s]predicting train subjects sagittal:   2%|▏         | 5/266 [00:01<01:08,  3.82it/s]predicting train subjects sagittal:   2%|▏         | 6/266 [00:01<01:08,  3.80it/s]predicting train subjects sagittal:   3%|▎         | 7/266 [00:01<01:11,  3.62it/s]predicting train subjects sagittal:   3%|▎         | 8/266 [00:02<01:13,  3.50it/s]predicting train subjects sagittal:   3%|▎         | 9/266 [00:02<01:10,  3.64it/s]predicting train subjects sagittal:   4%|▍         | 10/266 [00:02<01:09,  3.70it/s]predicting train subjects sagittal:   4%|▍         | 11/266 [00:02<01:08,  3.73it/s]predicting train subjects sagittal:   5%|▍         | 12/266 [00:03<01:06,  3.79it/s]predicting train subjects sagittal:   5%|▍         | 13/266 [00:03<01:06,  3.79it/s]predicting train subjects sagittal:   5%|▌         | 14/266 [00:03<01:09,  3.62it/s]predicting train subjects sagittal:   6%|▌         | 15/266 [00:04<01:07,  3.74it/s]predicting train subjects sagittal:   6%|▌         | 16/266 [00:04<01:05,  3.83it/s]predicting train subjects sagittal:   6%|▋         | 17/266 [00:04<01:03,  3.91it/s]predicting train subjects sagittal:   7%|▋         | 18/266 [00:04<01:06,  3.73it/s]predicting train subjects sagittal:   7%|▋         | 19/266 [00:05<01:08,  3.62it/s]predicting train subjects sagittal:   8%|▊         | 20/266 [00:05<01:06,  3.70it/s]predicting train subjects sagittal:   8%|▊         | 21/266 [00:05<01:08,  3.57it/s]predicting train subjects sagittal:   8%|▊         | 22/266 [00:05<01:06,  3.67it/s]predicting train subjects sagittal:   9%|▊         | 23/266 [00:06<01:04,  3.76it/s]predicting train subjects sagittal:   9%|▉         | 24/266 [00:06<01:02,  3.86it/s]predicting train subjects sagittal:   9%|▉         | 25/266 [00:06<01:01,  3.94it/s]predicting train subjects sagittal:  10%|▉         | 26/266 [00:06<01:01,  3.93it/s]predicting train subjects sagittal:  10%|█         | 27/266 [00:07<00:59,  4.00it/s]predicting train subjects sagittal:  11%|█         | 28/266 [00:07<00:58,  4.07it/s]predicting train subjects sagittal:  11%|█         | 29/266 [00:07<00:58,  4.08it/s]predicting train subjects sagittal:  11%|█▏        | 30/266 [00:07<00:58,  4.03it/s]predicting train subjects sagittal:  12%|█▏        | 31/266 [00:08<01:02,  3.74it/s]predicting train subjects sagittal:  12%|█▏        | 32/266 [00:08<01:02,  3.77it/s]predicting train subjects sagittal:  12%|█▏        | 33/266 [00:08<01:00,  3.87it/s]predicting train subjects sagittal:  13%|█▎        | 34/266 [00:08<00:59,  3.89it/s]predicting train subjects sagittal:  13%|█▎        | 35/266 [00:09<00:59,  3.89it/s]predicting train subjects sagittal:  14%|█▎        | 36/266 [00:09<00:58,  3.91it/s]predicting train subjects sagittal:  14%|█▍        | 37/266 [00:09<01:02,  3.66it/s]predicting train subjects sagittal:  14%|█▍        | 38/266 [00:10<01:01,  3.71it/s]predicting train subjects sagittal:  15%|█▍        | 39/266 [00:10<01:03,  3.58it/s]predicting train subjects sagittal:  15%|█▌        | 40/266 [00:10<01:04,  3.50it/s]predicting train subjects sagittal:  15%|█▌        | 41/266 [00:10<01:05,  3.46it/s]predicting train subjects sagittal:  16%|█▌        | 42/266 [00:11<00:58,  3.80it/s]predicting train subjects sagittal:  16%|█▌        | 43/266 [00:11<00:54,  4.12it/s]predicting train subjects sagittal:  17%|█▋        | 44/266 [00:11<00:50,  4.39it/s]predicting train subjects sagittal:  17%|█▋        | 45/266 [00:11<00:48,  4.59it/s]predicting train subjects sagittal:  17%|█▋        | 46/266 [00:11<00:46,  4.72it/s]predicting train subjects sagittal:  18%|█▊        | 47/266 [00:12<00:45,  4.84it/s]predicting train subjects sagittal:  18%|█▊        | 48/266 [00:12<00:44,  4.93it/s]predicting train subjects sagittal:  18%|█▊        | 49/266 [00:12<00:43,  4.96it/s]predicting train subjects sagittal:  19%|█▉        | 50/266 [00:12<00:43,  4.98it/s]predicting train subjects sagittal:  19%|█▉        | 51/266 [00:12<00:42,  5.03it/s]predicting train subjects sagittal:  20%|█▉        | 52/266 [00:13<00:42,  5.02it/s]predicting train subjects sagittal:  20%|█▉        | 53/266 [00:13<00:42,  5.04it/s]predicting train subjects sagittal:  20%|██        | 54/266 [00:13<00:43,  4.92it/s]predicting train subjects sagittal:  21%|██        | 55/266 [00:13<00:42,  4.97it/s]predicting train subjects sagittal:  21%|██        | 56/266 [00:13<00:41,  5.04it/s]predicting train subjects sagittal:  21%|██▏       | 57/266 [00:14<00:42,  4.97it/s]predicting train subjects sagittal:  22%|██▏       | 58/266 [00:14<00:41,  4.98it/s]predicting train subjects sagittal:  22%|██▏       | 59/266 [00:14<00:45,  4.59it/s]predicting train subjects sagittal:  23%|██▎       | 60/266 [00:14<00:44,  4.59it/s]predicting train subjects sagittal:  23%|██▎       | 61/266 [00:15<00:46,  4.40it/s]predicting train subjects sagittal:  23%|██▎       | 62/266 [00:15<00:45,  4.50it/s]predicting train subjects sagittal:  24%|██▎       | 63/266 [00:15<00:46,  4.32it/s]predicting train subjects sagittal:  24%|██▍       | 64/266 [00:15<00:44,  4.52it/s]predicting train subjects sagittal:  24%|██▍       | 65/266 [00:15<00:42,  4.69it/s]predicting train subjects sagittal:  25%|██▍       | 66/266 [00:16<00:41,  4.79it/s]predicting train subjects sagittal:  25%|██▌       | 67/266 [00:16<00:41,  4.84it/s]predicting train subjects sagittal:  26%|██▌       | 68/266 [00:16<00:39,  4.96it/s]predicting train subjects sagittal:  26%|██▌       | 69/266 [00:16<00:39,  4.95it/s]predicting train subjects sagittal:  26%|██▋       | 70/266 [00:16<00:39,  5.00it/s]predicting train subjects sagittal:  27%|██▋       | 71/266 [00:17<00:39,  4.99it/s]predicting train subjects sagittal:  27%|██▋       | 72/266 [00:17<00:41,  4.63it/s]predicting train subjects sagittal:  27%|██▋       | 73/266 [00:17<00:43,  4.41it/s]predicting train subjects sagittal:  28%|██▊       | 74/266 [00:17<00:42,  4.56it/s]predicting train subjects sagittal:  28%|██▊       | 75/266 [00:17<00:40,  4.73it/s]predicting train subjects sagittal:  29%|██▊       | 76/266 [00:18<00:38,  4.89it/s]predicting train subjects sagittal:  29%|██▉       | 77/266 [00:18<00:37,  4.97it/s]predicting train subjects sagittal:  29%|██▉       | 78/266 [00:18<00:43,  4.35it/s]predicting train subjects sagittal:  30%|██▉       | 79/266 [00:18<00:44,  4.20it/s]predicting train subjects sagittal:  30%|███       | 80/266 [00:19<00:44,  4.19it/s]predicting train subjects sagittal:  30%|███       | 81/266 [00:19<00:45,  4.06it/s]predicting train subjects sagittal:  31%|███       | 82/266 [00:19<00:48,  3.81it/s]predicting train subjects sagittal:  31%|███       | 83/266 [00:19<00:49,  3.73it/s]predicting train subjects sagittal:  32%|███▏      | 84/266 [00:20<00:47,  3.82it/s]predicting train subjects sagittal:  32%|███▏      | 85/266 [00:20<00:46,  3.88it/s]predicting train subjects sagittal:  32%|███▏      | 86/266 [00:20<00:48,  3.71it/s]predicting train subjects sagittal:  33%|███▎      | 87/266 [00:21<00:47,  3.78it/s]predicting train subjects sagittal:  33%|███▎      | 88/266 [00:21<00:48,  3.64it/s]predicting train subjects sagittal:  33%|███▎      | 89/266 [00:21<00:50,  3.53it/s]predicting train subjects sagittal:  34%|███▍      | 90/266 [00:21<00:48,  3.63it/s]predicting train subjects sagittal:  34%|███▍      | 91/266 [00:22<00:49,  3.54it/s]predicting train subjects sagittal:  35%|███▍      | 92/266 [00:22<00:48,  3.62it/s]predicting train subjects sagittal:  35%|███▍      | 93/266 [00:22<00:46,  3.71it/s]predicting train subjects sagittal:  35%|███▌      | 94/266 [00:22<00:44,  3.83it/s]predicting train subjects sagittal:  36%|███▌      | 95/266 [00:23<00:46,  3.67it/s]predicting train subjects sagittal:  36%|███▌      | 96/266 [00:23<00:42,  3.96it/s]predicting train subjects sagittal:  36%|███▋      | 97/266 [00:23<00:42,  3.98it/s]predicting train subjects sagittal:  37%|███▋      | 98/266 [00:24<00:44,  3.75it/s]predicting train subjects sagittal:  37%|███▋      | 99/266 [00:24<00:42,  3.88it/s]predicting train subjects sagittal:  38%|███▊      | 100/266 [00:24<00:40,  4.14it/s]predicting train subjects sagittal:  38%|███▊      | 101/266 [00:24<00:39,  4.23it/s]predicting train subjects sagittal:  38%|███▊      | 102/266 [00:24<00:37,  4.39it/s]predicting train subjects sagittal:  39%|███▊      | 103/266 [00:25<00:36,  4.49it/s]predicting train subjects sagittal:  39%|███▉      | 104/266 [00:25<00:36,  4.48it/s]predicting train subjects sagittal:  39%|███▉      | 105/266 [00:25<00:35,  4.58it/s]predicting train subjects sagittal:  40%|███▉      | 106/266 [00:25<00:34,  4.60it/s]predicting train subjects sagittal:  40%|████      | 107/266 [00:25<00:34,  4.65it/s]predicting train subjects sagittal:  41%|████      | 108/266 [00:26<00:34,  4.58it/s]predicting train subjects sagittal:  41%|████      | 109/266 [00:26<00:34,  4.49it/s]predicting train subjects sagittal:  41%|████▏     | 110/266 [00:26<00:34,  4.58it/s]predicting train subjects sagittal:  42%|████▏     | 111/266 [00:26<00:34,  4.49it/s]predicting train subjects sagittal:  42%|████▏     | 112/266 [00:27<00:33,  4.60it/s]predicting train subjects sagittal:  42%|████▏     | 113/266 [00:27<00:34,  4.38it/s]predicting train subjects sagittal:  43%|████▎     | 114/266 [00:27<00:34,  4.42it/s]predicting train subjects sagittal:  43%|████▎     | 115/266 [00:27<00:35,  4.20it/s]predicting train subjects sagittal:  44%|████▎     | 116/266 [00:28<00:36,  4.11it/s]predicting train subjects sagittal:  44%|████▍     | 117/266 [00:28<00:34,  4.30it/s]predicting train subjects sagittal:  44%|████▍     | 118/266 [00:28<00:33,  4.43it/s]predicting train subjects sagittal:  45%|████▍     | 119/266 [00:28<00:34,  4.20it/s]predicting train subjects sagittal:  45%|████▌     | 120/266 [00:28<00:35,  4.11it/s]predicting train subjects sagittal:  45%|████▌     | 121/266 [00:29<00:36,  4.00it/s]predicting train subjects sagittal:  46%|████▌     | 122/266 [00:29<00:36,  3.97it/s]predicting train subjects sagittal:  46%|████▌     | 123/266 [00:29<00:38,  3.74it/s]predicting train subjects sagittal:  47%|████▋     | 124/266 [00:30<00:39,  3.56it/s]predicting train subjects sagittal:  47%|████▋     | 125/266 [00:30<00:37,  3.72it/s]predicting train subjects sagittal:  47%|████▋     | 126/266 [00:30<00:37,  3.71it/s]predicting train subjects sagittal:  48%|████▊     | 127/266 [00:30<00:38,  3.57it/s]predicting train subjects sagittal:  48%|████▊     | 128/266 [00:31<00:37,  3.72it/s]predicting train subjects sagittal:  48%|████▊     | 129/266 [00:31<00:38,  3.58it/s]predicting train subjects sagittal:  49%|████▉     | 130/266 [00:31<00:36,  3.70it/s]predicting train subjects sagittal:  49%|████▉     | 131/266 [00:31<00:35,  3.76it/s]predicting train subjects sagittal:  50%|████▉     | 132/266 [00:32<00:34,  3.87it/s]predicting train subjects sagittal:  50%|█████     | 133/266 [00:32<00:34,  3.81it/s]predicting train subjects sagittal:  50%|█████     | 134/266 [00:32<00:33,  3.89it/s]predicting train subjects sagittal:  51%|█████     | 135/266 [00:33<00:35,  3.70it/s]predicting train subjects sagittal:  51%|█████     | 136/266 [00:33<00:34,  3.76it/s]predicting train subjects sagittal:  52%|█████▏    | 137/266 [00:33<00:32,  3.92it/s]predicting train subjects sagittal:  52%|█████▏    | 138/266 [00:33<00:31,  4.04it/s]predicting train subjects sagittal:  52%|█████▏    | 139/266 [00:33<00:30,  4.13it/s]predicting train subjects sagittal:  53%|█████▎    | 140/266 [00:34<00:31,  4.05it/s]predicting train subjects sagittal:  53%|█████▎    | 141/266 [00:34<00:30,  4.16it/s]predicting train subjects sagittal:  53%|█████▎    | 142/266 [00:34<00:29,  4.21it/s]predicting train subjects sagittal:  54%|█████▍    | 143/266 [00:34<00:29,  4.24it/s]predicting train subjects sagittal:  54%|█████▍    | 144/266 [00:35<00:28,  4.25it/s]predicting train subjects sagittal:  55%|█████▍    | 145/266 [00:35<00:28,  4.28it/s]predicting train subjects sagittal:  55%|█████▍    | 146/266 [00:35<00:27,  4.32it/s]predicting train subjects sagittal:  55%|█████▌    | 147/266 [00:35<00:27,  4.33it/s]predicting train subjects sagittal:  56%|█████▌    | 148/266 [00:36<00:28,  4.16it/s]predicting train subjects sagittal:  56%|█████▌    | 149/266 [00:36<00:28,  4.06it/s]predicting train subjects sagittal:  56%|█████▋    | 150/266 [00:36<00:27,  4.16it/s]predicting train subjects sagittal:  57%|█████▋    | 151/266 [00:36<00:27,  4.21it/s]predicting train subjects sagittal:  57%|█████▋    | 152/266 [00:37<00:26,  4.28it/s]predicting train subjects sagittal:  58%|█████▊    | 153/266 [00:37<00:26,  4.29it/s]predicting train subjects sagittal:  58%|█████▊    | 154/266 [00:37<00:25,  4.32it/s]predicting train subjects sagittal:  58%|█████▊    | 155/266 [00:37<00:23,  4.65it/s]predicting train subjects sagittal:  59%|█████▊    | 156/266 [00:37<00:22,  4.94it/s]predicting train subjects sagittal:  59%|█████▉    | 157/266 [00:38<00:21,  5.16it/s]predicting train subjects sagittal:  59%|█████▉    | 158/266 [00:38<00:20,  5.31it/s]predicting train subjects sagittal:  60%|█████▉    | 159/266 [00:38<00:19,  5.44it/s]predicting train subjects sagittal:  60%|██████    | 160/266 [00:38<00:19,  5.51it/s]predicting train subjects sagittal:  61%|██████    | 161/266 [00:38<00:19,  5.51it/s]predicting train subjects sagittal:  61%|██████    | 162/266 [00:38<00:19,  5.45it/s]predicting train subjects sagittal:  61%|██████▏   | 163/266 [00:39<00:18,  5.54it/s]predicting train subjects sagittal:  62%|██████▏   | 164/266 [00:39<00:18,  5.42it/s]predicting train subjects sagittal:  62%|██████▏   | 165/266 [00:39<00:19,  5.16it/s]predicting train subjects sagittal:  62%|██████▏   | 166/266 [00:39<00:19,  5.08it/s]predicting train subjects sagittal:  63%|██████▎   | 167/266 [00:39<00:19,  5.04it/s]predicting train subjects sagittal:  63%|██████▎   | 168/266 [00:40<00:18,  5.16it/s]predicting train subjects sagittal:  64%|██████▎   | 169/266 [00:40<00:18,  5.36it/s]predicting train subjects sagittal:  64%|██████▍   | 170/266 [00:40<00:17,  5.46it/s]predicting train subjects sagittal:  64%|██████▍   | 171/266 [00:40<00:18,  5.08it/s]predicting train subjects sagittal:  65%|██████▍   | 172/266 [00:40<00:19,  4.84it/s]predicting train subjects sagittal:  65%|██████▌   | 173/266 [00:41<00:20,  4.51it/s]predicting train subjects sagittal:  65%|██████▌   | 174/266 [00:41<00:21,  4.25it/s]predicting train subjects sagittal:  66%|██████▌   | 175/266 [00:41<00:21,  4.16it/s]predicting train subjects sagittal:  66%|██████▌   | 176/266 [00:41<00:21,  4.14it/s]predicting train subjects sagittal:  67%|██████▋   | 177/266 [00:42<00:21,  4.17it/s]predicting train subjects sagittal:  67%|██████▋   | 178/266 [00:42<00:20,  4.38it/s]predicting train subjects sagittal:  67%|██████▋   | 179/266 [00:42<00:19,  4.53it/s]predicting train subjects sagittal:  68%|██████▊   | 180/266 [00:42<00:18,  4.56it/s]predicting train subjects sagittal:  68%|██████▊   | 181/266 [00:43<00:18,  4.58it/s]predicting train subjects sagittal:  68%|██████▊   | 182/266 [00:43<00:17,  4.67it/s]predicting train subjects sagittal:  69%|██████▉   | 183/266 [00:43<00:17,  4.66it/s]predicting train subjects sagittal:  69%|██████▉   | 184/266 [00:43<00:17,  4.78it/s]predicting train subjects sagittal:  70%|██████▉   | 185/266 [00:43<00:16,  4.83it/s]predicting train subjects sagittal:  70%|██████▉   | 186/266 [00:44<00:18,  4.42it/s]predicting train subjects sagittal:  70%|███████   | 187/266 [00:44<00:19,  4.15it/s]predicting train subjects sagittal:  71%|███████   | 188/266 [00:44<00:18,  4.33it/s]predicting train subjects sagittal:  71%|███████   | 189/266 [00:44<00:16,  4.54it/s]predicting train subjects sagittal:  71%|███████▏  | 190/266 [00:44<00:16,  4.69it/s]predicting train subjects sagittal:  72%|███████▏  | 191/266 [00:45<00:15,  4.76it/s]predicting train subjects sagittal:  72%|███████▏  | 192/266 [00:45<00:15,  4.92it/s]predicting train subjects sagittal:  73%|███████▎  | 193/266 [00:45<00:15,  4.70it/s]predicting train subjects sagittal:  73%|███████▎  | 194/266 [00:45<00:16,  4.48it/s]predicting train subjects sagittal:  73%|███████▎  | 195/266 [00:46<00:16,  4.40it/s]predicting train subjects sagittal:  74%|███████▎  | 196/266 [00:46<00:16,  4.20it/s]predicting train subjects sagittal:  74%|███████▍  | 197/266 [00:46<00:17,  4.03it/s]predicting train subjects sagittal:  74%|███████▍  | 198/266 [00:46<00:16,  4.19it/s]predicting train subjects sagittal:  75%|███████▍  | 199/266 [00:47<00:15,  4.34it/s]predicting train subjects sagittal:  75%|███████▌  | 200/266 [00:47<00:14,  4.52it/s]predicting train subjects sagittal:  76%|███████▌  | 201/266 [00:47<00:14,  4.59it/s]predicting train subjects sagittal:  76%|███████▌  | 202/266 [00:47<00:13,  4.57it/s]predicting train subjects sagittal:  76%|███████▋  | 203/266 [00:47<00:13,  4.58it/s]predicting train subjects sagittal:  77%|███████▋  | 204/266 [00:48<00:14,  4.26it/s]predicting train subjects sagittal:  77%|███████▋  | 205/266 [00:48<00:14,  4.10it/s]predicting train subjects sagittal:  77%|███████▋  | 206/266 [00:48<00:14,  4.14it/s]predicting train subjects sagittal:  78%|███████▊  | 207/266 [00:48<00:13,  4.33it/s]predicting train subjects sagittal:  78%|███████▊  | 208/266 [00:49<00:12,  4.48it/s]predicting train subjects sagittal:  79%|███████▊  | 209/266 [00:49<00:12,  4.59it/s]predicting train subjects sagittal:  79%|███████▉  | 210/266 [00:49<00:12,  4.65it/s]predicting train subjects sagittal:  79%|███████▉  | 211/266 [00:49<00:11,  4.71it/s]predicting train subjects sagittal:  80%|███████▉  | 212/266 [00:49<00:11,  4.78it/s]predicting train subjects sagittal:  80%|████████  | 213/266 [00:50<00:10,  4.92it/s]predicting train subjects sagittal:  80%|████████  | 214/266 [00:50<00:10,  4.88it/s]predicting train subjects sagittal:  81%|████████  | 215/266 [00:50<00:10,  4.88it/s]predicting train subjects sagittal:  81%|████████  | 216/266 [00:50<00:09,  5.03it/s]predicting train subjects sagittal:  82%|████████▏ | 217/266 [00:50<00:09,  5.17it/s]predicting train subjects sagittal:  82%|████████▏ | 218/266 [00:51<00:09,  5.22it/s]predicting train subjects sagittal:  82%|████████▏ | 219/266 [00:51<00:08,  5.30it/s]predicting train subjects sagittal:  83%|████████▎ | 220/266 [00:51<00:08,  5.30it/s]predicting train subjects sagittal:  83%|████████▎ | 221/266 [00:51<00:08,  5.01it/s]predicting train subjects sagittal:  83%|████████▎ | 222/266 [00:51<00:09,  4.84it/s]predicting train subjects sagittal:  84%|████████▍ | 223/266 [00:52<00:08,  4.94it/s]predicting train subjects sagittal:  84%|████████▍ | 224/266 [00:52<00:08,  4.85it/s]predicting train subjects sagittal:  85%|████████▍ | 225/266 [00:52<00:08,  4.59it/s]predicting train subjects sagittal:  85%|████████▍ | 226/266 [00:52<00:09,  4.42it/s]predicting train subjects sagittal:  85%|████████▌ | 227/266 [00:53<00:08,  4.42it/s]predicting train subjects sagittal:  86%|████████▌ | 228/266 [00:53<00:08,  4.63it/s]predicting train subjects sagittal:  86%|████████▌ | 229/266 [00:53<00:07,  4.81it/s]predicting train subjects sagittal:  86%|████████▋ | 230/266 [00:53<00:07,  4.97it/s]predicting train subjects sagittal:  87%|████████▋ | 231/266 [00:53<00:06,  5.03it/s]predicting train subjects sagittal:  87%|████████▋ | 232/266 [00:53<00:06,  5.09it/s]predicting train subjects sagittal:  88%|████████▊ | 233/266 [00:54<00:06,  5.08it/s]predicting train subjects sagittal:  88%|████████▊ | 234/266 [00:54<00:06,  5.13it/s]predicting train subjects sagittal:  88%|████████▊ | 235/266 [00:54<00:05,  5.19it/s]predicting train subjects sagittal:  89%|████████▊ | 236/266 [00:54<00:05,  5.06it/s]predicting train subjects sagittal:  89%|████████▉ | 237/266 [00:55<00:06,  4.54it/s]predicting train subjects sagittal:  89%|████████▉ | 238/266 [00:55<00:05,  4.67it/s]predicting train subjects sagittal:  90%|████████▉ | 239/266 [00:55<00:05,  4.82it/s]predicting train subjects sagittal:  90%|█████████ | 240/266 [00:55<00:05,  4.93it/s]predicting train subjects sagittal:  91%|█████████ | 241/266 [00:55<00:05,  4.92it/s]predicting train subjects sagittal:  91%|█████████ | 242/266 [00:56<00:04,  4.88it/s]predicting train subjects sagittal:  91%|█████████▏| 243/266 [00:56<00:04,  4.95it/s]predicting train subjects sagittal:  92%|█████████▏| 244/266 [00:56<00:04,  4.90it/s]predicting train subjects sagittal:  92%|█████████▏| 245/266 [00:56<00:04,  4.83it/s]predicting train subjects sagittal:  92%|█████████▏| 246/266 [00:56<00:04,  4.92it/s]predicting train subjects sagittal:  93%|█████████▎| 247/266 [00:57<00:03,  5.01it/s]predicting train subjects sagittal:  93%|█████████▎| 248/266 [00:57<00:03,  5.06it/s]predicting train subjects sagittal:  94%|█████████▎| 249/266 [00:57<00:03,  4.77it/s]predicting train subjects sagittal:  94%|█████████▍| 250/266 [00:57<00:03,  4.50it/s]predicting train subjects sagittal:  94%|█████████▍| 251/266 [00:57<00:03,  4.07it/s]predicting train subjects sagittal:  95%|█████████▍| 252/266 [00:58<00:03,  3.81it/s]predicting train subjects sagittal:  95%|█████████▌| 253/266 [00:58<00:03,  3.93it/s]predicting train subjects sagittal:  95%|█████████▌| 254/266 [00:58<00:03,  3.92it/s]predicting train subjects sagittal:  96%|█████████▌| 255/266 [00:59<00:02,  3.92it/s]predicting train subjects sagittal:  96%|█████████▌| 256/266 [00:59<00:02,  3.99it/s]predicting train subjects sagittal:  97%|█████████▋| 257/266 [00:59<00:02,  3.77it/s]predicting train subjects sagittal:  97%|█████████▋| 258/266 [00:59<00:02,  3.66it/s]predicting train subjects sagittal:  97%|█████████▋| 259/266 [01:00<00:01,  3.74it/s]predicting train subjects sagittal:  98%|█████████▊| 260/266 [01:00<00:01,  3.86it/s]predicting train subjects sagittal:  98%|█████████▊| 261/266 [01:00<00:01,  3.94it/s]predicting train subjects sagittal:  98%|█████████▊| 262/266 [01:00<00:00,  4.01it/s]predicting train subjects sagittal:  99%|█████████▉| 263/266 [01:01<00:00,  4.05it/s]predicting train subjects sagittal:  99%|█████████▉| 264/266 [01:01<00:00,  4.10it/s]predicting train subjects sagittal: 100%|█████████▉| 265/266 [01:01<00:00,  4.06it/s]predicting train subjects sagittal: 100%|██████████| 266/266 [01:01<00:00,  3.82it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 73.08it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   3%|▎         | 7/266 [00:00<00:03, 67.61it/s]saving BB  train1-THALAMUS:   5%|▌         | 14/266 [00:00<00:03, 67.11it/s]saving BB  train1-THALAMUS:   8%|▊         | 21/266 [00:00<00:03, 66.75it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 66.68it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 67.78it/s]saving BB  train1-THALAMUS:  17%|█▋        | 44/266 [00:00<00:03, 69.01it/s]saving BB  train1-THALAMUS:  20%|█▉        | 52/266 [00:00<00:03, 70.75it/s]saving BB  train1-THALAMUS:  23%|██▎       | 60/266 [00:00<00:02, 72.22it/s]saving BB  train1-THALAMUS:  26%|██▌       | 69/266 [00:00<00:02, 74.80it/s]saving BB  train1-THALAMUS:  29%|██▉       | 78/266 [00:01<00:02, 76.51it/s]saving BB  train1-THALAMUS:  32%|███▏      | 86/266 [00:01<00:02, 73.67it/s]saving BB  train1-THALAMUS:  35%|███▌      | 94/266 [00:01<00:02, 72.66it/s]saving BB  train1-THALAMUS:  38%|███▊      | 102/266 [00:01<00:02, 71.78it/s]saving BB  train1-THALAMUS:  41%|████▏     | 110/266 [00:01<00:02, 71.82it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:01<00:02, 69.13it/s]saving BB  train1-THALAMUS:  47%|████▋     | 125/266 [00:01<00:02, 68.30it/s]saving BB  train1-THALAMUS:  50%|████▉     | 132/266 [00:01<00:01, 67.93it/s]saving BB  train1-THALAMUS:  52%|█████▏    | 139/266 [00:01<00:01, 67.82it/s]saving BB  train1-THALAMUS:  55%|█████▍    | 146/266 [00:02<00:01, 67.78it/s]saving BB  train1-THALAMUS:  58%|█████▊    | 153/266 [00:02<00:01, 68.08it/s]saving BB  train1-THALAMUS:  61%|██████    | 161/266 [00:02<00:01, 70.95it/s]saving BB  train1-THALAMUS:  64%|██████▍   | 170/266 [00:02<00:01, 74.08it/s]saving BB  train1-THALAMUS:  67%|██████▋   | 178/266 [00:02<00:01, 73.43it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 186/266 [00:02<00:01, 74.80it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 194/266 [00:02<00:00, 75.11it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 74.12it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 73.95it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 218/266 [00:03<00:00, 74.76it/s]saving BB  train1-THALAMUS:  85%|████████▍ | 226/266 [00:03<00:00, 75.14it/s]saving BB  train1-THALAMUS:  88%|████████▊ | 235/266 [00:03<00:00, 76.68it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 244/266 [00:03<00:00, 78.16it/s]saving BB  train1-THALAMUS:  95%|█████████▍| 252/266 [00:03<00:00, 76.40it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 260/266 [00:03<00:00, 74.18it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 72.31it/s]
saving BB  test1-THALAMUS Sagittal:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS Sagittal: 100%|██████████| 5/5 [00:00<00:00, 62.59it/s]
saving BB  train1-THALAMUS Sagittal:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS Sagittal:   3%|▎         | 7/266 [00:00<00:03, 67.59it/s]saving BB  train1-THALAMUS Sagittal:   5%|▌         | 14/266 [00:00<00:03, 66.96it/s]saving BB  train1-THALAMUS Sagittal:   8%|▊         | 21/266 [00:00<00:03, 66.52it/s]saving BB  train1-THALAMUS Sagittal:  11%|█         | 28/266 [00:00<00:03, 67.10it/s]saving BB  train1-THALAMUS Sagittal:  13%|█▎        | 35/266 [00:00<00:03, 65.77it/s]saving BB  train1-THALAMUS Sagittal:  16%|█▌        | 43/266 [00:00<00:03, 68.26it/s]saving BB  train1-THALAMUS Sagittal:  20%|█▉        | 52/266 [00:00<00:02, 71.48it/s]saving BB  train1-THALAMUS Sagittal:  23%|██▎       | 61/266 [00:00<00:02, 74.46it/s]saving BB  train1-THALAMUS Sagittal:  26%|██▋       | 70/266 [00:00<00:02, 77.82it/s]saving BB  train1-THALAMUS Sagittal:  30%|██▉       | 79/266 [00:01<00:02, 79.09it/s]saving BB  train1-THALAMUS Sagittal:  33%|███▎      | 87/266 [00:01<00:02, 78.09it/s]saving BB  train1-THALAMUS Sagittal:  36%|███▌      | 95/266 [00:01<00:02, 76.81it/s]saving BB  train1-THALAMUS Sagittal:  39%|███▊      | 103/266 [00:01<00:02, 76.23it/s]saving BB  train1-THALAMUS Sagittal:  42%|████▏     | 111/266 [00:01<00:02, 76.46it/s]saving BB  train1-THALAMUS Sagittal:  45%|████▍     | 119/266 [00:01<00:01, 76.58it/s]saving BB  train1-THALAMUS Sagittal:  48%|████▊     | 127/266 [00:01<00:01, 76.24it/s]saving BB  train1-THALAMUS Sagittal:  51%|█████     | 135/266 [00:01<00:01, 72.01it/s]saving BB  train1-THALAMUS Sagittal:  54%|█████▍    | 143/266 [00:01<00:01, 72.09it/s]saving BB  train1-THALAMUS Sagittal:  57%|█████▋    | 151/266 [00:02<00:01, 72.07it/s]saving BB  train1-THALAMUS Sagittal:  60%|██████    | 160/266 [00:02<00:01, 74.86it/s]saving BB  train1-THALAMUS Sagittal:  64%|██████▎   | 169/266 [00:02<00:01, 76.87it/s]saving BB  train1-THALAMUS Sagittal:  67%|██████▋   | 178/266 [00:02<00:01, 79.21it/s]saving BB  train1-THALAMUS Sagittal:  70%|███████   | 187/266 [00:02<00:00, 81.64it/s]saving BB  train1-THALAMUS Sagittal:  74%|███████▎  | 196/266 [00:02<00:00, 80.59it/s]saving BB  train1-THALAMUS Sagittal:  77%|███████▋  | 205/266 [00:02<00:00, 79.20it/s]saving BB  train1-THALAMUS Sagittal:  80%|████████  | 213/266 [00:02<00:00, 78.24it/s]saving BB  train1-THALAMUS Sagittal:  83%|████████▎ | 221/266 [00:02<00:00, 78.58it/s]saving BB  train1-THALAMUS Sagittal:  86%|████████▋ | 230/266 [00:03<00:00, 79.19it/s]saving BB  train1-THALAMUS Sagittal:  90%|████████▉ | 239/266 [00:03<00:00, 80.23it/s]saving BB  train1-THALAMUS Sagittal:  93%|█████████▎| 248/266 [00:03<00:00, 78.69it/s]saving BB  train1-THALAMUS Sagittal:  96%|█████████▌| 256/266 [00:03<00:00, 76.29it/s]saving BB  train1-THALAMUS Sagittal:  99%|█████████▉| 264/266 [00:03<00:00, 74.52it/s]saving BB  train1-THALAMUS Sagittal: 100%|██████████| 266/266 [00:03<00:00, 75.74it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<07:12,  1.63s/it]Loading train:   1%|          | 2/266 [00:03<07:04,  1.61s/it]Loading train:   1%|          | 3/266 [00:04<06:26,  1.47s/it]Loading train:   2%|▏         | 4/266 [00:05<05:55,  1.36s/it]Loading train:   2%|▏         | 5/266 [00:06<06:05,  1.40s/it]Loading train:   2%|▏         | 6/266 [00:07<05:28,  1.26s/it]Loading train:   3%|▎         | 7/266 [00:08<05:15,  1.22s/it]Loading train:   3%|▎         | 8/266 [00:09<04:58,  1.16s/it]Loading train:   3%|▎         | 9/266 [00:10<04:43,  1.10s/it]Loading train:   4%|▍         | 10/266 [00:11<04:28,  1.05s/it]Loading train:   4%|▍         | 11/266 [00:12<04:21,  1.02s/it]Loading train:   5%|▍         | 12/266 [00:13<04:13,  1.00it/s]Loading train:   5%|▍         | 13/266 [00:14<04:08,  1.02it/s]Loading train:   5%|▌         | 14/266 [00:15<04:03,  1.03it/s]Loading train:   6%|▌         | 15/266 [00:16<03:55,  1.07it/s]Loading train:   6%|▌         | 16/266 [00:17<03:52,  1.07it/s]Loading train:   6%|▋         | 17/266 [00:18<03:47,  1.10it/s]Loading train:   7%|▋         | 18/266 [00:19<03:45,  1.10it/s]Loading train:   7%|▋         | 19/266 [00:20<03:51,  1.07it/s]Loading train:   8%|▊         | 20/266 [00:21<03:48,  1.07it/s]Loading train:   8%|▊         | 21/266 [00:22<03:50,  1.06it/s]Loading train:   8%|▊         | 22/266 [00:23<03:53,  1.05it/s]Loading train:   9%|▊         | 23/266 [00:24<03:51,  1.05it/s]Loading train:   9%|▉         | 24/266 [00:24<03:46,  1.07it/s]Loading train:   9%|▉         | 25/266 [00:25<03:37,  1.11it/s]Loading train:  10%|▉         | 26/266 [00:26<03:31,  1.14it/s]Loading train:  10%|█         | 27/266 [00:27<03:29,  1.14it/s]Loading train:  11%|█         | 28/266 [00:28<03:26,  1.15it/s]Loading train:  11%|█         | 29/266 [00:29<03:23,  1.16it/s]Loading train:  11%|█▏        | 30/266 [00:30<03:23,  1.16it/s]Loading train:  12%|█▏        | 31/266 [00:30<03:20,  1.17it/s]Loading train:  12%|█▏        | 32/266 [00:31<03:23,  1.15it/s]Loading train:  12%|█▏        | 33/266 [00:32<03:24,  1.14it/s]Loading train:  13%|█▎        | 34/266 [00:33<03:28,  1.11it/s]Loading train:  13%|█▎        | 35/266 [00:34<03:25,  1.12it/s]Loading train:  14%|█▎        | 36/266 [00:35<03:24,  1.13it/s]Loading train:  14%|█▍        | 37/266 [00:36<03:21,  1.14it/s]Loading train:  14%|█▍        | 38/266 [00:37<03:14,  1.17it/s]Loading train:  15%|█▍        | 39/266 [00:37<03:13,  1.18it/s]Loading train:  15%|█▌        | 40/266 [00:38<03:14,  1.16it/s]Loading train:  15%|█▌        | 41/266 [00:39<03:14,  1.16it/s]Loading train:  16%|█▌        | 42/266 [00:40<03:03,  1.22it/s]Loading train:  16%|█▌        | 43/266 [00:41<02:54,  1.28it/s]Loading train:  17%|█▋        | 44/266 [00:41<02:52,  1.29it/s]Loading train:  17%|█▋        | 45/266 [00:42<02:48,  1.31it/s]Loading train:  17%|█▋        | 46/266 [00:43<02:51,  1.29it/s]Loading train:  18%|█▊        | 47/266 [00:44<02:50,  1.28it/s]Loading train:  18%|█▊        | 48/266 [00:44<02:48,  1.29it/s]Loading train:  18%|█▊        | 49/266 [00:45<02:49,  1.28it/s]Loading train:  19%|█▉        | 50/266 [00:46<02:43,  1.33it/s]Loading train:  19%|█▉        | 51/266 [00:47<02:40,  1.34it/s]Loading train:  20%|█▉        | 52/266 [00:47<02:42,  1.32it/s]Loading train:  20%|█▉        | 53/266 [00:48<02:44,  1.30it/s]Loading train:  20%|██        | 54/266 [00:49<02:39,  1.33it/s]Loading train:  21%|██        | 55/266 [00:50<02:39,  1.33it/s]Loading train:  21%|██        | 56/266 [00:50<02:34,  1.36it/s]Loading train:  21%|██▏       | 57/266 [00:51<02:32,  1.37it/s]Loading train:  22%|██▏       | 58/266 [00:52<02:30,  1.38it/s]Loading train:  22%|██▏       | 59/266 [00:52<02:25,  1.43it/s]Loading train:  23%|██▎       | 60/266 [00:53<02:24,  1.42it/s]Loading train:  23%|██▎       | 61/266 [00:54<02:29,  1.37it/s]Loading train:  23%|██▎       | 62/266 [00:55<02:26,  1.40it/s]Loading train:  24%|██▎       | 63/266 [00:55<02:22,  1.43it/s]Loading train:  24%|██▍       | 64/266 [00:56<02:19,  1.45it/s]Loading train:  24%|██▍       | 65/266 [00:57<02:19,  1.44it/s]Loading train:  25%|██▍       | 66/266 [00:57<02:18,  1.45it/s]Loading train:  25%|██▌       | 67/266 [00:58<02:13,  1.49it/s]Loading train:  26%|██▌       | 68/266 [00:59<02:10,  1.52it/s]Loading train:  26%|██▌       | 69/266 [00:59<02:10,  1.51it/s]Loading train:  26%|██▋       | 70/266 [01:00<02:09,  1.52it/s]Loading train:  27%|██▋       | 71/266 [01:01<02:10,  1.49it/s]Loading train:  27%|██▋       | 72/266 [01:01<02:11,  1.48it/s]Loading train:  27%|██▋       | 73/266 [01:02<02:12,  1.46it/s]Loading train:  28%|██▊       | 74/266 [01:03<02:16,  1.41it/s]Loading train:  28%|██▊       | 75/266 [01:03<02:12,  1.44it/s]Loading train:  29%|██▊       | 76/266 [01:04<02:10,  1.46it/s]Loading train:  29%|██▉       | 77/266 [01:05<02:06,  1.49it/s]Loading train:  29%|██▉       | 78/266 [01:06<02:21,  1.33it/s]Loading train:  30%|██▉       | 79/266 [01:07<02:28,  1.26it/s]Loading train:  30%|███       | 80/266 [01:07<02:32,  1.22it/s]Loading train:  30%|███       | 81/266 [01:08<02:37,  1.17it/s]Loading train:  31%|███       | 82/266 [01:09<02:41,  1.14it/s]Loading train:  31%|███       | 83/266 [01:10<02:42,  1.12it/s]Loading train:  32%|███▏      | 84/266 [01:11<02:41,  1.13it/s]Loading train:  32%|███▏      | 85/266 [01:12<02:39,  1.13it/s]Loading train:  32%|███▏      | 86/266 [01:13<02:41,  1.11it/s]Loading train:  33%|███▎      | 87/266 [01:14<02:41,  1.11it/s]Loading train:  33%|███▎      | 88/266 [01:15<02:39,  1.12it/s]Loading train:  33%|███▎      | 89/266 [01:16<02:34,  1.14it/s]Loading train:  34%|███▍      | 90/266 [01:16<02:32,  1.16it/s]Loading train:  34%|███▍      | 91/266 [01:17<02:29,  1.17it/s]Loading train:  35%|███▍      | 92/266 [01:18<02:32,  1.14it/s]Loading train:  35%|███▍      | 93/266 [01:19<02:32,  1.13it/s]Loading train:  35%|███▌      | 94/266 [01:20<02:35,  1.10it/s]Loading train:  36%|███▌      | 95/266 [01:21<02:35,  1.10it/s]Loading train:  36%|███▌      | 96/266 [01:22<02:49,  1.00it/s]Loading train:  36%|███▋      | 97/266 [01:24<03:12,  1.14s/it]Loading train:  37%|███▋      | 98/266 [01:25<03:12,  1.15s/it]Loading train:  37%|███▋      | 99/266 [01:26<03:00,  1.08s/it]Loading train:  38%|███▊      | 100/266 [01:27<03:01,  1.09s/it]Loading train:  38%|███▊      | 101/266 [01:28<02:43,  1.01it/s]Loading train:  38%|███▊      | 102/266 [01:28<02:29,  1.10it/s]Loading train:  39%|███▊      | 103/266 [01:29<02:18,  1.18it/s]Loading train:  39%|███▉      | 104/266 [01:30<02:14,  1.21it/s]Loading train:  39%|███▉      | 105/266 [01:30<02:07,  1.26it/s]Loading train:  40%|███▉      | 106/266 [01:31<02:08,  1.25it/s]Loading train:  40%|████      | 107/266 [01:32<02:05,  1.27it/s]Loading train:  41%|████      | 108/266 [01:33<02:02,  1.29it/s]Loading train:  41%|████      | 109/266 [01:34<02:00,  1.30it/s]Loading train:  41%|████▏     | 110/266 [01:34<01:58,  1.32it/s]Loading train:  42%|████▏     | 111/266 [01:35<01:56,  1.33it/s]Loading train:  42%|████▏     | 112/266 [01:36<01:54,  1.35it/s]Loading train:  42%|████▏     | 113/266 [01:36<01:51,  1.37it/s]Loading train:  43%|████▎     | 114/266 [01:37<01:50,  1.37it/s]Loading train:  43%|████▎     | 115/266 [01:38<01:54,  1.32it/s]Loading train:  44%|████▎     | 116/266 [01:39<01:52,  1.34it/s]Loading train:  44%|████▍     | 117/266 [01:39<01:53,  1.32it/s]Loading train:  44%|████▍     | 118/266 [01:40<01:53,  1.30it/s]Loading train:  45%|████▍     | 119/266 [01:41<02:00,  1.22it/s]Loading train:  45%|████▌     | 120/266 [01:42<01:59,  1.22it/s]Loading train:  45%|████▌     | 121/266 [01:43<02:00,  1.20it/s]Loading train:  46%|████▌     | 122/266 [01:44<02:03,  1.16it/s]Loading train:  46%|████▌     | 123/266 [01:45<02:01,  1.18it/s]Loading train:  47%|████▋     | 124/266 [01:46<02:02,  1.16it/s]Loading train:  47%|████▋     | 125/266 [01:46<02:05,  1.12it/s]Loading train:  47%|████▋     | 126/266 [01:48<02:10,  1.07it/s]Loading train:  48%|████▊     | 127/266 [01:48<02:09,  1.07it/s]Loading train:  48%|████▊     | 128/266 [01:49<02:05,  1.10it/s]Loading train:  48%|████▊     | 129/266 [01:50<02:04,  1.10it/s]Loading train:  49%|████▉     | 130/266 [01:51<02:04,  1.09it/s]Loading train:  49%|████▉     | 131/266 [01:52<02:03,  1.09it/s]Loading train:  50%|████▉     | 132/266 [01:53<02:00,  1.11it/s]Loading train:  50%|█████     | 133/266 [01:54<02:02,  1.09it/s]Loading train:  50%|█████     | 134/266 [01:55<02:02,  1.08it/s]Loading train:  51%|█████     | 135/266 [01:56<02:01,  1.08it/s]Loading train:  51%|█████     | 136/266 [01:57<01:59,  1.09it/s]Loading train:  52%|█████▏    | 137/266 [01:58<01:59,  1.08it/s]Loading train:  52%|█████▏    | 138/266 [01:58<01:55,  1.11it/s]Loading train:  52%|█████▏    | 139/266 [01:59<01:50,  1.15it/s]Loading train:  53%|█████▎    | 140/266 [02:00<01:49,  1.15it/s]Loading train:  53%|█████▎    | 141/266 [02:01<01:46,  1.18it/s]Loading train:  53%|█████▎    | 142/266 [02:02<01:44,  1.19it/s]Loading train:  54%|█████▍    | 143/266 [02:03<01:43,  1.19it/s]Loading train:  54%|█████▍    | 144/266 [02:04<01:48,  1.13it/s]Loading train:  55%|█████▍    | 145/266 [02:04<01:46,  1.14it/s]Loading train:  55%|█████▍    | 146/266 [02:05<01:41,  1.18it/s]Loading train:  55%|█████▌    | 147/266 [02:06<01:41,  1.17it/s]Loading train:  56%|█████▌    | 148/266 [02:07<01:42,  1.15it/s]Loading train:  56%|█████▌    | 149/266 [02:08<01:38,  1.18it/s]Loading train:  56%|█████▋    | 150/266 [02:09<01:35,  1.21it/s]Loading train:  57%|█████▋    | 151/266 [02:09<01:34,  1.21it/s]Loading train:  57%|█████▋    | 152/266 [02:10<01:34,  1.21it/s]Loading train:  58%|█████▊    | 153/266 [02:11<01:34,  1.20it/s]Loading train:  58%|█████▊    | 154/266 [02:12<01:33,  1.20it/s]Loading train:  58%|█████▊    | 155/266 [02:13<01:32,  1.20it/s]Loading train:  59%|█████▊    | 156/266 [02:13<01:27,  1.26it/s]Loading train:  59%|█████▉    | 157/266 [02:14<01:23,  1.30it/s]Loading train:  59%|█████▉    | 158/266 [02:15<01:18,  1.37it/s]Loading train:  60%|█████▉    | 159/266 [02:15<01:14,  1.44it/s]Loading train:  60%|██████    | 160/266 [02:16<01:13,  1.45it/s]Loading train:  61%|██████    | 161/266 [02:17<01:11,  1.48it/s]Loading train:  61%|██████    | 162/266 [02:17<01:10,  1.48it/s]Loading train:  61%|██████▏   | 163/266 [02:18<01:09,  1.48it/s]Loading train:  62%|██████▏   | 164/266 [02:19<01:09,  1.48it/s]Loading train:  62%|██████▏   | 165/266 [02:19<01:08,  1.48it/s]Loading train:  62%|██████▏   | 166/266 [02:20<01:07,  1.47it/s]Loading train:  63%|██████▎   | 167/266 [02:21<01:06,  1.49it/s]Loading train:  63%|██████▎   | 168/266 [02:21<01:06,  1.48it/s]Loading train:  64%|██████▎   | 169/266 [02:22<01:05,  1.48it/s]Loading train:  64%|██████▍   | 170/266 [02:23<01:04,  1.48it/s]Loading train:  64%|██████▍   | 171/266 [02:23<01:04,  1.47it/s]Loading train:  65%|██████▍   | 172/266 [02:24<01:03,  1.49it/s]Loading train:  65%|██████▌   | 173/266 [02:25<01:03,  1.47it/s]Loading train:  65%|██████▌   | 174/266 [02:26<01:03,  1.45it/s]Loading train:  66%|██████▌   | 175/266 [02:26<01:03,  1.44it/s]Loading train:  66%|██████▌   | 176/266 [02:27<01:04,  1.39it/s]Loading train:  67%|██████▋   | 177/266 [02:28<01:02,  1.42it/s]Loading train:  67%|██████▋   | 178/266 [02:28<01:00,  1.45it/s]Loading train:  67%|██████▋   | 179/266 [02:29<01:01,  1.41it/s]Loading train:  68%|██████▊   | 180/266 [02:30<01:00,  1.42it/s]Loading train:  68%|██████▊   | 181/266 [02:30<00:59,  1.42it/s]Loading train:  68%|██████▊   | 182/266 [02:32<01:21,  1.03it/s]Loading train:  69%|██████▉   | 183/266 [02:33<01:13,  1.13it/s]Loading train:  69%|██████▉   | 184/266 [02:33<01:07,  1.21it/s]Loading train:  70%|██████▉   | 185/266 [02:34<01:03,  1.27it/s]Loading train:  70%|██████▉   | 186/266 [02:35<00:59,  1.34it/s]Loading train:  70%|███████   | 187/266 [02:36<00:57,  1.37it/s]Loading train:  71%|███████   | 188/266 [02:36<00:56,  1.37it/s]Loading train:  71%|███████   | 189/266 [02:37<00:54,  1.42it/s]Loading train:  71%|███████▏  | 190/266 [02:38<00:53,  1.43it/s]Loading train:  72%|███████▏  | 191/266 [02:39<01:02,  1.20it/s]Loading train:  72%|███████▏  | 192/266 [02:40<01:09,  1.07it/s]Loading train:  73%|███████▎  | 193/266 [02:41<01:13,  1.00s/it]Loading train:  73%|███████▎  | 194/266 [02:43<01:23,  1.15s/it]Loading train:  73%|███████▎  | 195/266 [02:43<01:14,  1.04s/it]Loading train:  74%|███████▎  | 196/266 [02:44<01:07,  1.04it/s]Loading train:  74%|███████▍  | 197/266 [02:45<01:03,  1.08it/s]Loading train:  74%|███████▍  | 198/266 [02:46<00:59,  1.15it/s]Loading train:  75%|███████▍  | 199/266 [02:46<00:56,  1.19it/s]Loading train:  75%|███████▌  | 200/266 [02:47<00:54,  1.20it/s]Loading train:  76%|███████▌  | 201/266 [02:48<00:53,  1.22it/s]Loading train:  76%|███████▌  | 202/266 [02:49<00:50,  1.27it/s]Loading train:  76%|███████▋  | 203/266 [02:50<00:50,  1.24it/s]Loading train:  77%|███████▋  | 204/266 [02:50<00:49,  1.25it/s]Loading train:  77%|███████▋  | 205/266 [02:51<00:48,  1.26it/s]Loading train:  77%|███████▋  | 206/266 [02:52<00:46,  1.29it/s]Loading train:  78%|███████▊  | 207/266 [02:53<00:46,  1.27it/s]Loading train:  78%|███████▊  | 208/266 [02:53<00:44,  1.30it/s]Loading train:  79%|███████▊  | 209/266 [02:54<00:44,  1.29it/s]Loading train:  79%|███████▉  | 210/266 [02:55<00:42,  1.31it/s]Loading train:  79%|███████▉  | 211/266 [02:56<00:41,  1.32it/s]Loading train:  80%|███████▉  | 212/266 [02:56<00:40,  1.32it/s]Loading train:  80%|████████  | 213/266 [02:57<00:39,  1.34it/s]Loading train:  80%|████████  | 214/266 [02:58<00:37,  1.37it/s]Loading train:  81%|████████  | 215/266 [02:59<00:36,  1.41it/s]Loading train:  81%|████████  | 216/266 [02:59<00:35,  1.41it/s]Loading train:  82%|████████▏ | 217/266 [03:00<00:33,  1.47it/s]Loading train:  82%|████████▏ | 218/266 [03:01<00:32,  1.48it/s]Loading train:  82%|████████▏ | 219/266 [03:01<00:32,  1.47it/s]Loading train:  83%|████████▎ | 220/266 [03:02<00:31,  1.44it/s]Loading train:  83%|████████▎ | 221/266 [03:03<00:30,  1.46it/s]Loading train:  83%|████████▎ | 222/266 [03:03<00:29,  1.48it/s]Loading train:  84%|████████▍ | 223/266 [03:04<00:28,  1.51it/s]Loading train:  84%|████████▍ | 224/266 [03:05<00:27,  1.51it/s]Loading train:  85%|████████▍ | 225/266 [03:05<00:27,  1.49it/s]Loading train:  85%|████████▍ | 226/266 [03:06<00:26,  1.51it/s]Loading train:  85%|████████▌ | 227/266 [03:07<00:26,  1.50it/s]Loading train:  86%|████████▌ | 228/266 [03:07<00:25,  1.48it/s]Loading train:  86%|████████▌ | 229/266 [03:08<00:26,  1.41it/s]Loading train:  86%|████████▋ | 230/266 [03:09<00:25,  1.40it/s]Loading train:  87%|████████▋ | 231/266 [03:10<00:25,  1.39it/s]Loading train:  87%|████████▋ | 232/266 [03:10<00:23,  1.45it/s]Loading train:  88%|████████▊ | 233/266 [03:11<00:22,  1.50it/s]Loading train:  88%|████████▊ | 234/266 [03:11<00:20,  1.54it/s]Loading train:  88%|████████▊ | 235/266 [03:12<00:20,  1.54it/s]Loading train:  89%|████████▊ | 236/266 [03:13<00:19,  1.57it/s]Loading train:  89%|████████▉ | 237/266 [03:13<00:18,  1.57it/s]Loading train:  89%|████████▉ | 238/266 [03:14<00:18,  1.55it/s]Loading train:  90%|████████▉ | 239/266 [03:15<00:17,  1.51it/s]Loading train:  90%|█████████ | 240/266 [03:15<00:17,  1.50it/s]Loading train:  91%|█████████ | 241/266 [03:16<00:16,  1.52it/s]Loading train:  91%|█████████ | 242/266 [03:17<00:15,  1.56it/s]Loading train:  91%|█████████▏| 243/266 [03:17<00:14,  1.58it/s]Loading train:  92%|█████████▏| 244/266 [03:18<00:13,  1.58it/s]Loading train:  92%|█████████▏| 245/266 [03:18<00:13,  1.59it/s]Loading train:  92%|█████████▏| 246/266 [03:19<00:12,  1.59it/s]Loading train:  93%|█████████▎| 247/266 [03:20<00:11,  1.59it/s]Loading train:  93%|█████████▎| 248/266 [03:20<00:11,  1.60it/s]Loading train:  94%|█████████▎| 249/266 [03:21<00:12,  1.41it/s]Loading train:  94%|█████████▍| 250/266 [03:22<00:12,  1.31it/s]Loading train:  94%|█████████▍| 251/266 [03:23<00:11,  1.28it/s]Loading train:  95%|█████████▍| 252/266 [03:24<00:11,  1.24it/s]Loading train:  95%|█████████▌| 253/266 [03:25<00:10,  1.23it/s]Loading train:  95%|█████████▌| 254/266 [03:25<00:09,  1.22it/s]Loading train:  96%|█████████▌| 255/266 [03:26<00:09,  1.22it/s]Loading train:  96%|█████████▌| 256/266 [03:27<00:08,  1.18it/s]Loading train:  97%|█████████▋| 257/266 [03:28<00:07,  1.18it/s]Loading train:  97%|█████████▋| 258/266 [03:29<00:06,  1.16it/s]Loading train:  97%|█████████▋| 259/266 [03:30<00:05,  1.19it/s]Loading train:  98%|█████████▊| 260/266 [03:31<00:05,  1.19it/s]Loading train:  98%|█████████▊| 261/266 [03:31<00:04,  1.18it/s]Loading train:  98%|█████████▊| 262/266 [03:32<00:03,  1.19it/s]Loading train:  99%|█████████▉| 263/266 [03:33<00:02,  1.19it/s]Loading train:  99%|█████████▉| 264/266 [03:34<00:01,  1.19it/s]Loading train: 100%|█████████▉| 265/266 [03:35<00:00,  1.15it/s]Loading train: 100%|██████████| 266/266 [03:36<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 25/266 [00:00<00:00, 245.49it/s]concatenating: train:  15%|█▍        | 39/266 [00:00<00:01, 199.48it/s]concatenating: train:  23%|██▎       | 62/266 [00:00<00:00, 207.67it/s]concatenating: train:  32%|███▏      | 84/266 [00:00<00:00, 211.19it/s]concatenating: train:  39%|███▉      | 104/266 [00:00<00:00, 206.33it/s]concatenating: train:  48%|████▊     | 127/266 [00:00<00:00, 212.62it/s]concatenating: train:  57%|█████▋    | 151/266 [00:00<00:00, 218.93it/s]concatenating: train:  67%|██████▋   | 178/266 [00:00<00:00, 231.67it/s]concatenating: train:  77%|███████▋  | 204/266 [00:00<00:00, 238.54it/s]concatenating: train:  86%|████████▌ | 228/266 [00:01<00:00, 237.64it/s]concatenating: train:  95%|█████████▍| 252/266 [00:01<00:00, 236.49it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 232.46it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.10s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.14s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.11s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.09s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.16s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 200.94it/s]2019-08-17 18:16:23.125831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 18:16:23.125928: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 18:16:23.125943: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 18:16:23.125951: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 18:16:23.126377: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14485 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.71it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.77it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.31it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.08it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  8.79it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.04it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.08it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:02,  7.70it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01,  9.55it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.04it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 10.16it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.00it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.93it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.16it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.09it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.95it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.28it/s]
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 84, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 84, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 84, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 84, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 84, 20)   3620        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 84, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 84, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 42, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 26, 42, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 26, 42, 40)   7240        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 26, 42, 40)   160         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 26, 42, 40)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 26, 42, 40)   14440       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 26, 42, 40)   160         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 26, 42, 40)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 26, 42, 60)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 21, 60)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 13, 21, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 13, 21, 80)   43280       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 13, 21, 80)   320         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 13, 21, 80)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 13, 21, 80)   57680       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 13, 21, 80)   320         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 13, 21, 80)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 13, 21, 140)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 13, 21, 140)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 42, 40)   22440       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 26, 42, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 26, 42, 40)   36040       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 26, 42, 40)   160         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 26, 42, 40)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 26, 42, 40)   14440       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 26, 42, 40)   160         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 26, 42, 40)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 42, 140)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 26, 42, 140)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 84, 20)   11220       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 52, 84, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 52, 84, 20)   7220        concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 52, 84, 20)   80          conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 52, 84, 20)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 52, 84, 20)   3620        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 52, 84, 20)   80          conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 52, 84, 20)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 84, 60)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 52, 84, 60)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 84, 13)   793         dropout_5[0][0]                  
==================================================================================================
Total params: 223,833
Trainable params: 197,153
Non-trainable params: 26,680
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33979967e-02 3.28583014e-02 7.68346187e-02 9.54708772e-03
 2.76314458e-02 7.22898893e-03 8.43219751e-02 1.14202011e-01
 8.96711200e-02 1.36241636e-02 2.90731408e-01 1.89696237e-01
 2.54645508e-04]
Train on 9877 samples, validate on 179 samples
Epoch 1/300
 - 14s - loss: 2.6330 - acc: 0.7039 - mDice: 0.1274 - val_loss: 1.0517 - val_acc: 0.9074 - val_mDice: 0.3383

Epoch 00001: val_mDice improved from -inf to 0.33832, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.0422 - acc: 0.8913 - mDice: 0.3512 - val_loss: 0.8107 - val_acc: 0.9216 - val_mDice: 0.4632

Epoch 00002: val_mDice improved from 0.33832 to 0.46318, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 0.7627 - acc: 0.9049 - mDice: 0.4560 - val_loss: 0.6566 - val_acc: 0.9270 - val_mDice: 0.5167

Epoch 00003: val_mDice improved from 0.46318 to 0.51665, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6442 - acc: 0.9125 - mDice: 0.5117 - val_loss: 0.6055 - val_acc: 0.9293 - val_mDice: 0.5478

Epoch 00004: val_mDice improved from 0.51665 to 0.54785, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.5757 - acc: 0.9176 - mDice: 0.5480 - val_loss: 0.5604 - val_acc: 0.9327 - val_mDice: 0.5651

Epoch 00005: val_mDice improved from 0.54785 to 0.56512, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.5233 - acc: 0.9228 - mDice: 0.5775 - val_loss: 0.5351 - val_acc: 0.9372 - val_mDice: 0.5817

Epoch 00006: val_mDice improved from 0.56512 to 0.58170, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.4783 - acc: 0.9278 - mDice: 0.6046 - val_loss: 0.5239 - val_acc: 0.9400 - val_mDice: 0.5853

Epoch 00007: val_mDice improved from 0.58170 to 0.58533, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.4428 - acc: 0.9315 - mDice: 0.6274 - val_loss: 0.4939 - val_acc: 0.9453 - val_mDice: 0.6013

Epoch 00008: val_mDice improved from 0.58533 to 0.60125, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.4162 - acc: 0.9344 - mDice: 0.6448 - val_loss: 0.4973 - val_acc: 0.9434 - val_mDice: 0.6007

Epoch 00009: val_mDice did not improve from 0.60125
Epoch 10/300
 - 9s - loss: 0.3977 - acc: 0.9366 - mDice: 0.6574 - val_loss: 0.4880 - val_acc: 0.9445 - val_mDice: 0.6057

Epoch 00010: val_mDice improved from 0.60125 to 0.60574, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.3818 - acc: 0.9385 - mDice: 0.6684 - val_loss: 0.5056 - val_acc: 0.9457 - val_mDice: 0.6006

Epoch 00011: val_mDice did not improve from 0.60574
Epoch 12/300
 - 9s - loss: 0.3691 - acc: 0.9396 - mDice: 0.6771 - val_loss: 0.4661 - val_acc: 0.9448 - val_mDice: 0.6162

Epoch 00012: val_mDice improved from 0.60574 to 0.61623, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 9s - loss: 0.3591 - acc: 0.9409 - mDice: 0.6843 - val_loss: 0.4867 - val_acc: 0.9458 - val_mDice: 0.6076

Epoch 00013: val_mDice did not improve from 0.61623
Epoch 14/300
 - 9s - loss: 0.3481 - acc: 0.9419 - mDice: 0.6919 - val_loss: 0.4997 - val_acc: 0.9429 - val_mDice: 0.5991

Epoch 00014: val_mDice did not improve from 0.61623
Epoch 15/300
 - 9s - loss: 0.3388 - acc: 0.9428 - mDice: 0.6988 - val_loss: 0.4739 - val_acc: 0.9450 - val_mDice: 0.6122

Epoch 00015: val_mDice did not improve from 0.61623
Epoch 16/300
 - 9s - loss: 0.3297 - acc: 0.9435 - mDice: 0.7053 - val_loss: 0.4852 - val_acc: 0.9431 - val_mDice: 0.6054

Epoch 00016: val_mDice did not improve from 0.61623
Epoch 17/300
 - 9s - loss: 0.3223 - acc: 0.9443 - mDice: 0.7109 - val_loss: 0.4578 - val_acc: 0.9479 - val_mDice: 0.6230

Epoch 00017: val_mDice improved from 0.61623 to 0.62299, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.3171 - acc: 0.9449 - mDice: 0.7148 - val_loss: 0.4652 - val_acc: 0.9457 - val_mDice: 0.6186

Epoch 00018: val_mDice did not improve from 0.62299
Epoch 19/300
 - 9s - loss: 0.3103 - acc: 0.9454 - mDice: 0.7197 - val_loss: 0.4779 - val_acc: 0.9461 - val_mDice: 0.6130

Epoch 00019: val_mDice did not improve from 0.62299
Epoch 20/300
 - 9s - loss: 0.3057 - acc: 0.9461 - mDice: 0.7234 - val_loss: 0.4647 - val_acc: 0.9480 - val_mDice: 0.6194

Epoch 00020: val_mDice did not improve from 0.62299
Epoch 21/300
 - 9s - loss: 0.2992 - acc: 0.9467 - mDice: 0.7282 - val_loss: 0.4619 - val_acc: 0.9480 - val_mDice: 0.6197

Epoch 00021: val_mDice did not improve from 0.62299
Epoch 22/300
 - 9s - loss: 0.2942 - acc: 0.9472 - mDice: 0.7320 - val_loss: 0.4651 - val_acc: 0.9475 - val_mDice: 0.6194

Epoch 00022: val_mDice did not improve from 0.62299
Epoch 23/300
 - 9s - loss: 0.2907 - acc: 0.9474 - mDice: 0.7348 - val_loss: 0.4669 - val_acc: 0.9477 - val_mDice: 0.6193

Epoch 00023: val_mDice did not improve from 0.62299
Epoch 24/300
 - 9s - loss: 0.2876 - acc: 0.9479 - mDice: 0.7371 - val_loss: 0.4687 - val_acc: 0.9480 - val_mDice: 0.6166

Epoch 00024: val_mDice did not improve from 0.62299
Epoch 25/300
 - 9s - loss: 0.2842 - acc: 0.9481 - mDice: 0.7397 - val_loss: 0.4624 - val_acc: 0.9479 - val_mDice: 0.6219

Epoch 00025: val_mDice did not improve from 0.62299
Epoch 26/300
 - 9s - loss: 0.2807 - acc: 0.9485 - mDice: 0.7424 - val_loss: 0.4611 - val_acc: 0.9485 - val_mDice: 0.6222

Epoch 00026: val_mDice did not improve from 0.62299
Epoch 27/300
 - 9s - loss: 0.2775 - acc: 0.9489 - mDice: 0.7449 - val_loss: 0.4649 - val_acc: 0.9477 - val_mDice: 0.6201

Epoch 00027: val_mDice did not improve from 0.62299
Epoch 28/300
 - 9s - loss: 0.2755 - acc: 0.9493 - mDice: 0.7465 - val_loss: 0.4888 - val_acc: 0.9479 - val_mDice: 0.6100

Epoch 00028: val_mDice did not improve from 0.62299
Epoch 29/300
 - 9s - loss: 0.2715 - acc: 0.9496 - mDice: 0.7496 - val_loss: 0.4724 - val_acc: 0.9487 - val_mDice: 0.6162

Epoch 00029: val_mDice did not improve from 0.62299
Epoch 30/300
 - 9s - loss: 0.2677 - acc: 0.9501 - mDice: 0.7525 - val_loss: 0.4801 - val_acc: 0.9481 - val_mDice: 0.6113

Epoch 00030: val_mDice did not improve from 0.62299
Epoch 31/300
 - 9s - loss: 0.2658 - acc: 0.9502 - mDice: 0.7541 - val_loss: 0.4635 - val_acc: 0.9490 - val_mDice: 0.6207

Epoch 00031: val_mDice did not improve from 0.62299
Epoch 32/300
 - 9s - loss: 0.2662 - acc: 0.9505 - mDice: 0.7538 - val_loss: 0.4692 - val_acc: 0.9482 - val_mDice: 0.6173

Epoch 00032: val_mDice did not improve from 0.62299
Epoch 33/300
 - 9s - loss: 0.2607 - acc: 0.9509 - mDice: 0.7581 - val_loss: 0.4758 - val_acc: 0.9482 - val_mDice: 0.6131

Epoch 00033: val_mDice did not improve from 0.62299
Epoch 34/300
 - 9s - loss: 0.2588 - acc: 0.9511 - mDice: 0.7596 - val_loss: 0.4715 - val_acc: 0.9473 - val_mDice: 0.6151

Epoch 00034: val_mDice did not improve from 0.62299
Epoch 35/300
 - 9s - loss: 0.2617 - acc: 0.9511 - mDice: 0.7577 - val_loss: 0.5811 - val_acc: 0.9459 - val_mDice: 0.5675

Epoch 00035: val_mDice did not improve from 0.62299
Epoch 36/300
 - 9s - loss: 0.2645 - acc: 0.9508 - mDice: 0.7550 - val_loss: 0.4773 - val_acc: 0.9482 - val_mDice: 0.6120

Epoch 00036: val_mDice did not improve from 0.62299
Epoch 37/300
 - 9s - loss: 0.2553 - acc: 0.9516 - mDice: 0.7623 - val_loss: 0.4748 - val_acc: 0.9484 - val_mDice: 0.6136

Epoch 00037: val_mDice did not improve from 0.62299
Epoch 38/300
 - 9s - loss: 0.2518 - acc: 0.9519 - mDice: 0.7651 - val_loss: 0.4585 - val_acc: 0.9484 - val_mDice: 0.6233

Epoch 00038: val_mDice improved from 0.62299 to 0.62332, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 9s - loss: 0.2506 - acc: 0.9520 - mDice: 0.7661 - val_loss: 0.4608 - val_acc: 0.9488 - val_mDice: 0.6223

Epoch 00039: val_mDice did not improve from 0.62332
Epoch 40/300
 - 9s - loss: 0.2488 - acc: 0.9523 - mDice: 0.7677 - val_loss: 0.4738 - val_acc: 0.9486 - val_mDice: 0.6146

Epoch 00040: val_mDice did not improve from 0.62332
Epoch 41/300
 - 9s - loss: 0.2506 - acc: 0.9522 - mDice: 0.7667 - val_loss: 0.4772 - val_acc: 0.9495 - val_mDice: 0.6155

Epoch 00041: val_mDice did not improve from 0.62332
Epoch 42/300
 - 9s - loss: 0.2459 - acc: 0.9524 - mDice: 0.7698 - val_loss: 0.4815 - val_acc: 0.9493 - val_mDice: 0.6102

Epoch 00042: val_mDice did not improve from 0.62332
Epoch 43/300
 - 10s - loss: 0.2451 - acc: 0.9527 - mDice: 0.7705 - val_loss: 0.4643 - val_acc: 0.9501 - val_mDice: 0.6201

Epoch 00043: val_mDice did not improve from 0.62332
Epoch 44/300
 - 11s - loss: 0.2417 - acc: 0.9528 - mDice: 0.7732 - val_loss: 0.4675 - val_acc: 0.9492 - val_mDice: 0.6184

Epoch 00044: val_mDice did not improve from 0.62332
Epoch 45/300
 - 11s - loss: 0.2411 - acc: 0.9530 - mDice: 0.7738 - val_loss: 0.4931 - val_acc: 0.9477 - val_mDice: 0.6057

Epoch 00045: val_mDice did not improve from 0.62332
Epoch 46/300
 - 11s - loss: 0.2417 - acc: 0.9530 - mDice: 0.7734 - val_loss: 0.4817 - val_acc: 0.9479 - val_mDice: 0.6104

Epoch 00046: val_mDice did not improve from 0.62332
Epoch 47/300
 - 10s - loss: 0.2391 - acc: 0.9532 - mDice: 0.7754 - val_loss: 0.4645 - val_acc: 0.9477 - val_mDice: 0.6195

Epoch 00047: val_mDice did not improve from 0.62332
Epoch 48/300
 - 10s - loss: 0.2372 - acc: 0.9534 - mDice: 0.7769 - val_loss: 0.4797 - val_acc: 0.9473 - val_mDice: 0.6122

Epoch 00048: val_mDice did not improve from 0.62332
Epoch 49/300
 - 9s - loss: 0.2362 - acc: 0.9536 - mDice: 0.7777 - val_loss: 0.4841 - val_acc: 0.9481 - val_mDice: 0.6102

Epoch 00049: val_mDice did not improve from 0.62332
Epoch 50/300
 - 10s - loss: 0.2357 - acc: 0.9535 - mDice: 0.7782 - val_loss: 0.4810 - val_acc: 0.9482 - val_mDice: 0.6110

Epoch 00050: val_mDice did not improve from 0.62332
Epoch 51/300
 - 9s - loss: 0.2347 - acc: 0.9537 - mDice: 0.7790 - val_loss: 0.4589 - val_acc: 0.9492 - val_mDice: 0.6239

Epoch 00051: val_mDice improved from 0.62332 to 0.62389, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 52/300
 - 9s - loss: 0.2335 - acc: 0.9538 - mDice: 0.7800 - val_loss: 0.4661 - val_acc: 0.9477 - val_mDice: 0.6208

Epoch 00052: val_mDice did not improve from 0.62389
Epoch 53/300
 - 9s - loss: 0.2327 - acc: 0.9539 - mDice: 0.7806 - val_loss: 0.4815 - val_acc: 0.9482 - val_mDice: 0.6124

Epoch 00053: val_mDice did not improve from 0.62389
Epoch 54/300
 - 9s - loss: 0.2325 - acc: 0.9540 - mDice: 0.7809 - val_loss: 0.4821 - val_acc: 0.9488 - val_mDice: 0.6132

Epoch 00054: val_mDice did not improve from 0.62389
Epoch 55/300
 - 10s - loss: 0.2318 - acc: 0.9540 - mDice: 0.7813 - val_loss: 0.4812 - val_acc: 0.9491 - val_mDice: 0.6127

Epoch 00055: val_mDice did not improve from 0.62389
Epoch 56/300
 - 9s - loss: 0.2344 - acc: 0.9542 - mDice: 0.7822 - val_loss: 0.4699 - val_acc: 0.9497 - val_mDice: 0.6211

Epoch 00056: val_mDice did not improve from 0.62389
Epoch 57/300
 - 9s - loss: 0.2308 - acc: 0.9541 - mDice: 0.7822 - val_loss: 0.4681 - val_acc: 0.9490 - val_mDice: 0.6204

Epoch 00057: val_mDice did not improve from 0.62389
Epoch 58/300
 - 10s - loss: 0.2270 - acc: 0.9546 - mDice: 0.7853 - val_loss: 0.4787 - val_acc: 0.9488 - val_mDice: 0.6135

Epoch 00058: val_mDice did not improve from 0.62389
Epoch 59/300
 - 9s - loss: 0.2278 - acc: 0.9545 - mDice: 0.7847 - val_loss: 0.4811 - val_acc: 0.9493 - val_mDice: 0.6115

Epoch 00059: val_mDice did not improve from 0.62389
Epoch 60/300
 - 9s - loss: 0.2263 - acc: 0.9546 - mDice: 0.7858 - val_loss: 0.4896 - val_acc: 0.9488 - val_mDice: 0.6098

Epoch 00060: val_mDice did not improve from 0.62389
Epoch 61/300
 - 10s - loss: 0.2264 - acc: 0.9547 - mDice: 0.7859 - val_loss: 0.4971 - val_acc: 0.9484 - val_mDice: 0.6056

Epoch 00061: val_mDice did not improve from 0.62389
Epoch 62/300
 - 9s - loss: 0.2265 - acc: 0.9547 - mDice: 0.7857 - val_loss: 0.4931 - val_acc: 0.9492 - val_mDice: 0.6074

Epoch 00062: val_mDice did not improve from 0.62389
Epoch 63/300
 - 9s - loss: 0.2244 - acc: 0.9549 - mDice: 0.7875 - val_loss: 0.4674 - val_acc: 0.9486 - val_mDice: 0.6204

Epoch 00063: val_mDice did not improve from 0.62389
Epoch 64/300
 - 9s - loss: 0.2269 - acc: 0.9545 - mDice: 0.7853 - val_loss: 0.4910 - val_acc: 0.9485 - val_mDice: 0.6068

Epoch 00064: val_mDice did not improve from 0.62389
Epoch 65/300
 - 9s - loss: 0.2228 - acc: 0.9549 - mDice: 0.7887 - val_loss: 0.5096 - val_acc: 0.9483 - val_mDice: 0.5990

Epoch 00065: val_mDice did not improve from 0.62389
Epoch 66/300
 - 10s - loss: 0.2215 - acc: 0.9550 - mDice: 0.7898 - val_loss: 0.4991 - val_acc: 0.9491 - val_mDice: 0.6066

Epoch 00066: val_mDice did not improve from 0.62389
Epoch 67/300
 - 9s - loss: 0.2206 - acc: 0.9551 - mDice: 0.7906 - val_loss: 0.5016 - val_acc: 0.9477 - val_mDice: 0.6011

Epoch 00067: val_mDice did not improve from 0.62389
Epoch 68/300
 - 9s - loss: 0.2191 - acc: 0.9553 - mDice: 0.7918 - val_loss: 0.4956 - val_acc: 0.9498 - val_mDice: 0.6075

Epoch 00068: val_mDice did not improve from 0.62389
Epoch 69/300
 - 9s - loss: 0.2201 - acc: 0.9552 - mDice: 0.7910 - val_loss: 0.4875 - val_acc: 0.9504 - val_mDice: 0.6115

Epoch 00069: val_mDice did not improve from 0.62389
Epoch 70/300
 - 9s - loss: 0.2175 - acc: 0.9554 - mDice: 0.7931 - val_loss: 0.4783 - val_acc: 0.9488 - val_mDice: 0.6137

Epoch 00070: val_mDice did not improve from 0.62389
Epoch 71/300
 - 9s - loss: 0.2192 - acc: 0.9553 - mDice: 0.7918 - val_loss: 0.4934 - val_acc: 0.9498 - val_mDice: 0.6092

Epoch 00071: val_mDice did not improve from 0.62389
Epoch 72/300
 - 9s - loss: 0.2170 - acc: 0.9555 - mDice: 0.7936 - val_loss: 0.4758 - val_acc: 0.9494 - val_mDice: 0.6169

Epoch 00072: val_mDice did not improve from 0.62389
Epoch 73/300
 - 9s - loss: 0.2159 - acc: 0.9557 - mDice: 0.7944 - val_loss: 0.4895 - val_acc: 0.9486 - val_mDice: 0.6080

Epoch 00073: val_mDice did not improve from 0.62389
Epoch 74/300
 - 9s - loss: 0.2164 - acc: 0.9556 - mDice: 0.7940 - val_loss: 0.4911 - val_acc: 0.9476 - val_mDice: 0.6075

Epoch 00074: val_mDice did not improve from 0.62389
Epoch 75/300
 - 9s - loss: 0.2154 - acc: 0.9556 - mDice: 0.7948 - val_loss: 0.4747 - val_acc: 0.9493 - val_mDice: 0.6146

Epoch 00075: val_mDice did not improve from 0.62389
Epoch 76/300
 - 9s - loss: 0.2158 - acc: 0.9556 - mDice: 0.7945 - val_loss: 0.4811 - val_acc: 0.9502 - val_mDice: 0.6149

Epoch 00076: val_mDice did not improve from 0.62389
Epoch 77/300
 - 9s - loss: 0.2137 - acc: 0.9558 - mDice: 0.7962 - val_loss: 0.4745 - val_acc: 0.9495 - val_mDice: 0.6175

Epoch 00077: val_mDice did not improve from 0.62389
Epoch 78/300
 - 9s - loss: 0.2138 - acc: 0.9559 - mDice: 0.7962 - val_loss: 0.4938 - val_acc: 0.9488 - val_mDice: 0.6074

Epoch 00078: val_mDice did not improve from 0.62389
Epoch 79/300
 - 9s - loss: 0.2142 - acc: 0.9559 - mDice: 0.7959 - val_loss: 0.4786 - val_acc: 0.9497 - val_mDice: 0.6158

Epoch 00079: val_mDice did not improve from 0.62389
Epoch 80/300
 - 9s - loss: 0.2137 - acc: 0.9559 - mDice: 0.7963 - val_loss: 0.4788 - val_acc: 0.9495 - val_mDice: 0.6137

Epoch 00080: val_mDice did not improve from 0.62389
Epoch 81/300
 - 9s - loss: 0.2125 - acc: 0.9560 - mDice: 0.7973 - val_loss: 0.5007 - val_acc: 0.9490 - val_mDice: 0.6014

Epoch 00081: val_mDice did not improve from 0.62389
Epoch 82/300
 - 9s - loss: 0.2125 - acc: 0.9559 - mDice: 0.7973 - val_loss: 0.4902 - val_acc: 0.9480 - val_mDice: 0.6064

Epoch 00082: val_mDice did not improve from 0.62389
Epoch 83/300
 - 9s - loss: 0.2120 - acc: 0.9561 - mDice: 0.7977 - val_loss: 0.4959 - val_acc: 0.9492 - val_mDice: 0.6051

Epoch 00083: val_mDice did not improve from 0.62389
Epoch 84/300
 - 9s - loss: 0.2117 - acc: 0.9563 - mDice: 0.7984 - val_loss: 0.4757 - val_acc: 0.9487 - val_mDice: 0.6163

Epoch 00084: val_mDice did not improve from 0.62389
Epoch 85/300
 - 9s - loss: 0.2126 - acc: 0.9561 - mDice: 0.7972 - val_loss: 0.4847 - val_acc: 0.9493 - val_mDice: 0.6112

Epoch 00085: val_mDice did not improve from 0.62389
Epoch 86/300
 - 9s - loss: 0.2150 - acc: 0.9558 - mDice: 0.7955 - val_loss: 0.4835 - val_acc: 0.9497 - val_mDice: 0.6127

Epoch 00086: val_mDice did not improve from 0.62389
Epoch 87/300
 - 10s - loss: 0.2098 - acc: 0.9563 - mDice: 0.7996 - val_loss: 0.4820 - val_acc: 0.9500 - val_mDice: 0.6127

Epoch 00087: val_mDice did not improve from 0.62389
Epoch 88/300
 - 9s - loss: 0.2095 - acc: 0.9563 - mDice: 0.7998 - val_loss: 0.5032 - val_acc: 0.9493 - val_mDice: 0.6035

Epoch 00088: val_mDice did not improve from 0.62389
Epoch 89/300
 - 10s - loss: 0.2086 - acc: 0.9565 - mDice: 0.8005 - val_loss: 0.4838 - val_acc: 0.9497 - val_mDice: 0.6130

Epoch 00089: val_mDice did not improve from 0.62389
Epoch 90/300
 - 9s - loss: 0.2097 - acc: 0.9564 - mDice: 0.7997 - val_loss: 0.4891 - val_acc: 0.9491 - val_mDice: 0.6104

Epoch 00090: val_mDice did not improve from 0.62389
Epoch 91/300
 - 11s - loss: 0.2102 - acc: 0.9564 - mDice: 0.8016 - val_loss: 0.5163 - val_acc: 0.9472 - val_mDice: 0.5965

Epoch 00091: val_mDice did not improve from 0.62389
Restoring model weights from the end of the best epoch
Epoch 00091: early stopping
{'val_loss': [1.05172058124116, 0.8107424055397844, 0.656555925334632, 0.6055294911288682, 0.5603974897768245, 0.5350999962018189, 0.52394924982966, 0.4939129264328067, 0.49730342892961127, 0.48800628378404587, 0.5056299447347332, 0.46613783010557375, 0.4867366287628366, 0.49969621710271145, 0.4739468678748807, 0.4851810958798371, 0.45778510290817176, 0.4651728380658773, 0.4779466507155136, 0.464720919478539, 0.461879325645596, 0.4650597389183897, 0.466934330803056, 0.4687259626788134, 0.46236188168632253, 0.461118326839788, 0.4648890107370622, 0.48877181620571203, 0.47239708384322054, 0.48008506807535056, 0.46349235520016546, 0.46915199436954946, 0.4758082564982622, 0.47154097883394974, 0.5810504074536222, 0.4773319941326227, 0.4748493512915499, 0.45852569811170996, 0.4608224845132348, 0.4738073370643168, 0.47720084177049177, 0.4815271420185792, 0.46430963377712825, 0.4674845531000105, 0.4931311843781498, 0.4817404051066777, 0.4645294557070599, 0.4797116135085761, 0.48411511875397667, 0.4809701812333901, 0.45890509616063296, 0.4661419141891948, 0.4815329742831225, 0.4820780720790671, 0.4812019833639347, 0.46993429234573963, 0.4681219583450083, 0.47865647527092664, 0.4810650733263133, 0.4895625592277037, 0.4971267832391089, 0.4930976850693452, 0.46737068558538425, 0.49100423491866896, 0.5095934919471847, 0.4991101945578719, 0.5015507703386871, 0.49555756692779795, 0.4875029816640822, 0.47826004128216365, 0.4934456256847808, 0.47584463164793045, 0.4894798016747949, 0.49109114148763305, 0.47474267096492834, 0.4810640182575034, 0.4744839160468991, 0.4937697529126812, 0.47864937132963253, 0.4787908960654083, 0.5007106954824991, 0.4902333936877757, 0.495919406414032, 0.4757277492704338, 0.48470617039909575, 0.48348165124488274, 0.4819865268368961, 0.5032383125254561, 0.4838295334211275, 0.4890801445398917, 0.5163055215467954], 'val_acc': [0.9074400923105591, 0.9216278485079717, 0.9270276970037535, 0.9292710276955333, 0.9326654459511101, 0.937166171366942, 0.9399953048322454, 0.9453248265069291, 0.9434472598843069, 0.9445484606913348, 0.9457366446543006, 0.9448323912460711, 0.9457775597465771, 0.9429126535048032, 0.9449730785199384, 0.9430635554830455, 0.94787765748008, 0.9457366526459848, 0.946052543277847, 0.9480017120611735, 0.9479850883590443, 0.9475348951430295, 0.9477075468228516, 0.9479786850220664, 0.9478648724502692, 0.9484698239651472, 0.9476653510631796, 0.9478559104423949, 0.9487115594261851, 0.948116820617761, 0.9489673585865085, 0.9482204301397228, 0.948219141480643, 0.9473340847638733, 0.9458734769394944, 0.9481667113703722, 0.9483969151640738, 0.9484250668706841, 0.9488228106631913, 0.948616910913137, 0.9494635922282768, 0.9492551174909709, 0.9501120491400777, 0.9491950213576162, 0.9476883721085234, 0.9479352232464199, 0.9477331242081839, 0.9473404774452721, 0.9481488070008475, 0.9482191321570114, 0.9492014110421335, 0.9477356902047909, 0.9481654227112924, 0.9487512038406714, 0.9490850194872424, 0.9496784729664552, 0.9489763096058169, 0.948812585969211, 0.9492717498507579, 0.9487652778625488, 0.9484480885820016, 0.9491540832892477, 0.9485759788385316, 0.9484557675915724, 0.948348322061187, 0.9491336222467476, 0.9476538447028432, 0.9497500924424752, 0.9504125914094168, 0.9487806082437824, 0.9498344962823324, 0.9494482511914643, 0.9486309885978699, 0.9476461710210619, 0.9493050052467005, 0.9501644722576248, 0.9494520838700193, 0.948802354282507, 0.9496720623037669, 0.9494687092370827, 0.9489545735566975, 0.9479876430340985, 0.9492218574332125, 0.9487115431098299, 0.949302438251133, 0.9497449694399062, 0.9500353019996728, 0.9493113999260204, 0.9496963829967563, 0.9490709451323781, 0.9471895688072929], 'val_mDice': [0.33831802326873694, 0.4631844099673479, 0.5166501632615841, 0.5478454495275487, 0.5651153066304809, 0.581703135754143, 0.5853326393905298, 0.6012525998014312, 0.6007464378239722, 0.6057359013477517, 0.6005531229786367, 0.6162303409762888, 0.6075759296976654, 0.59908289549737, 0.6121667949847003, 0.6054260857278408, 0.6229902475905817, 0.6186189997795574, 0.6129969181961188, 0.6193898443403191, 0.6197193088478217, 0.6194246394674205, 0.6193436643930786, 0.6165636281727412, 0.6219431338363519, 0.622161715390296, 0.620085250731953, 0.6100423056320106, 0.6161640552835091, 0.6112876064950528, 0.62069250018903, 0.617285343854787, 0.6131204832865539, 0.615106697855049, 0.5674776135210219, 0.6119708628627841, 0.6135906973364633, 0.6233232820500209, 0.6223153132300138, 0.614550298485676, 0.6155182269698415, 0.6101653978811296, 0.6201157929511044, 0.6184437617909309, 0.6056919870429864, 0.6103912904941836, 0.6195110921753185, 0.6122204221826691, 0.610206526417972, 0.6109878387531089, 0.6238902867173349, 0.6208444284327204, 0.6123852743116837, 0.6132424293949618, 0.6127206393460322, 0.6211114998636299, 0.6203966840019439, 0.6134617628331956, 0.6115147581313576, 0.6098308353450711, 0.6055928195655013, 0.6073919135099016, 0.6204462950456076, 0.6067739898266074, 0.5989905539171656, 0.6065991321089548, 0.6011325673684061, 0.6074514032742164, 0.6114973142826358, 0.6137253032716293, 0.6092143824646593, 0.616903775897106, 0.6079900324677622, 0.6075237063722237, 0.6145962050507189, 0.6149349905259116, 0.617522828072809, 0.6073718120931914, 0.6158088056068847, 0.6137362958332679, 0.6013985868938808, 0.6064162427486655, 0.6051134976594807, 0.6162614542678748, 0.6111746819991639, 0.6126554238729637, 0.6127385686895701, 0.6035163309321058, 0.6130198599905942, 0.6103987200966094, 0.596549298843192], 'loss': [2.632970130526852, 1.042221606489834, 0.7626855279603467, 0.6442290068071019, 0.5756630134978395, 0.5232620752387603, 0.4783282235070159, 0.44282813365852663, 0.416158172386528, 0.3977309026656103, 0.381765746561588, 0.36906982978683883, 0.35911569816689387, 0.34813735281587116, 0.33877614553886903, 0.3297197570790643, 0.3223468317240371, 0.31714865822981303, 0.31029028414629894, 0.3056781004167248, 0.29915795816430873, 0.29422893725849303, 0.29071821531714054, 0.2876005633991112, 0.2841670168179955, 0.28073008313067493, 0.27745044537071906, 0.2755384991993797, 0.2714572203380202, 0.2677380681502574, 0.26579309180129984, 0.2661971237219646, 0.26066276655875925, 0.25878265229412767, 0.2616654930779045, 0.2644558752854609, 0.2552538760986311, 0.2517839113043498, 0.2505587326668047, 0.24875954576376008, 0.2505666579452618, 0.24591821867516617, 0.24512628696189787, 0.24171208144380843, 0.24108037474462712, 0.24169023517076818, 0.23905380096158677, 0.23721241658909717, 0.2361570415261956, 0.23570525256972136, 0.23469096645177273, 0.23350888786980217, 0.23269575635883818, 0.23248740963557116, 0.231829564864908, 0.23438539783928308, 0.2307882714732596, 0.22702998347890466, 0.22783972793194138, 0.22632589957076094, 0.22640001741246896, 0.2264683249826022, 0.2243537986804759, 0.22688652071873644, 0.2228193445987543, 0.22149123186263475, 0.22059337652211153, 0.21909322370651993, 0.22012487902952205, 0.2175257253531588, 0.21917083166962853, 0.21697630257491607, 0.21592178801069908, 0.21644510120723706, 0.21543812626097575, 0.21579817642901994, 0.2137187604987695, 0.21382991998702805, 0.21422814420538777, 0.2137256732028156, 0.21249959216169034, 0.21246338028517694, 0.21202024970446157, 0.2117114977576755, 0.2126407102104912, 0.21498024040018243, 0.20978080680209324, 0.20947713075475172, 0.20862123114601422, 0.209746760033977, 0.21022819346643912], 'acc': [0.7039270294888476, 0.8913320435485075, 0.9049458755611154, 0.9125263857083534, 0.9175953271177311, 0.9228076524817534, 0.9278302645591562, 0.9314813273535019, 0.9344468334853994, 0.9365901805266589, 0.9384957633726242, 0.9396330361980845, 0.9409440335648569, 0.9418850016157021, 0.9427818382294467, 0.9435332509517138, 0.944302465566392, 0.9448972129925574, 0.9454154447769605, 0.9461499846414889, 0.9467260279587385, 0.9472054105014034, 0.9473679871275271, 0.9479499618039388, 0.9480934381738443, 0.9485428112654162, 0.9488633494091333, 0.9492569958631406, 0.9495524111831551, 0.9501261818719149, 0.9502493768336018, 0.9504937306582065, 0.9508636880225108, 0.9510969098695463, 0.9510964019356245, 0.9508121604497971, 0.9516479443704791, 0.951909517721692, 0.9520446029621374, 0.9523220545212194, 0.9521551636641984, 0.9524105052191489, 0.9526955141668271, 0.952761434707321, 0.9530421788482226, 0.9530441235576285, 0.9531668326120163, 0.9533764386727427, 0.9535589277038234, 0.953549492602963, 0.9537396532714132, 0.9538049690574, 0.9539024121753839, 0.9540482100789166, 0.9540322845228604, 0.9542298142734033, 0.9541450730337598, 0.954609043258784, 0.9544931999570363, 0.9546382963941009, 0.9546952002309432, 0.954665206337284, 0.9548541609304594, 0.9545334343112672, 0.9548737461103219, 0.9549849373832989, 0.9551160606136324, 0.9553461985826082, 0.9551954469036764, 0.9554092961971584, 0.9553404556144355, 0.955488055850905, 0.9556560115653927, 0.9555880278967479, 0.9556373046865537, 0.955645231537048, 0.9558420208249484, 0.9559116997892128, 0.955870623758499, 0.9558954494822854, 0.9560267797990815, 0.9559482976868168, 0.9560577944185107, 0.956346694028147, 0.9560961558701261, 0.9558234078398694, 0.956270922874166, 0.9562671934651908, 0.9564647682526339, 0.9563516551537999, 0.9564197536746875], 'mDice': [0.12742473579580343, 0.35116534592398774, 0.45601534078849454, 0.5116862270095105, 0.54799689196063, 0.5774970208873171, 0.6045555709356285, 0.6274347431543591, 0.6448194134799022, 0.6574183793834096, 0.6684354597394665, 0.6771376289927405, 0.6842589637003798, 0.6919214202045272, 0.6987875526378883, 0.705305988970611, 0.7109177594871865, 0.7148294805925216, 0.7197356681368956, 0.7234105393629972, 0.7282306157505873, 0.7320195409442245, 0.7347861726817252, 0.7371015144623133, 0.7397086989171135, 0.7424050615518648, 0.7449077918025735, 0.7464737414324031, 0.749643469473557, 0.7524877972504841, 0.7540576816679339, 0.753833072514045, 0.7580967348959446, 0.7595852773187373, 0.7576649244393826, 0.7550204333185341, 0.7623476280282115, 0.7651218380403746, 0.7660526279026262, 0.7676948520762362, 0.7666504574386869, 0.7698280602087071, 0.7705298932600181, 0.7732400830559394, 0.7737762520546685, 0.7733539263101632, 0.7753788214216496, 0.776903566584433, 0.7777478437113764, 0.778169533133905, 0.7790000332660661, 0.78001277246033, 0.7805752178019112, 0.7808505398512393, 0.7813074651717464, 0.7821631523427589, 0.7821812457711008, 0.7852950107777326, 0.7846558858137256, 0.785846389539693, 0.7859405245244582, 0.785746811287623, 0.7874990563541334, 0.7853157556019561, 0.7886841927955928, 0.7898252643746645, 0.7905635853594368, 0.7917752290551716, 0.7909540136635056, 0.7930628582933261, 0.7917854100861047, 0.793588627129416, 0.7944034951846223, 0.7939708425808716, 0.7947901690357475, 0.7944904972428649, 0.7962132815022308, 0.7961713480927677, 0.7958703229962494, 0.7963485277965144, 0.7973334902607624, 0.7973402936207303, 0.7977249487952398, 0.79840730479025, 0.7971597326734813, 0.7954694885551972, 0.7995701510015257, 0.7998435516232866, 0.800546466380922, 0.7996603667380007, 0.8015703836517608]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:04<00:18,  4.68s/it]predicting test subjects:  40%|████      | 2/5 [00:08<00:13,  4.41s/it]predicting test subjects:  60%|██████    | 3/5 [00:11<00:08,  4.14s/it]predicting test subjects:  80%|████████  | 4/5 [00:15<00:03,  3.90s/it]predicting test subjects: 100%|██████████| 5/5 [00:19<00:00,  3.87s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:04<18:54,  4.28s/it]predicting train subjects:   1%|          | 2/266 [00:08<18:53,  4.29s/it]predicting train subjects:   1%|          | 3/266 [00:12<18:02,  4.11s/it]predicting train subjects:   2%|▏         | 4/266 [00:15<17:09,  3.93s/it]predicting train subjects:   2%|▏         | 5/266 [00:19<17:10,  3.95s/it]predicting train subjects:   2%|▏         | 6/266 [00:23<17:26,  4.02s/it]predicting train subjects:   3%|▎         | 7/266 [00:28<17:50,  4.13s/it]predicting train subjects:   3%|▎         | 8/266 [00:32<17:53,  4.16s/it]predicting train subjects:   3%|▎         | 9/266 [00:36<17:58,  4.20s/it]predicting train subjects:   4%|▍         | 10/266 [00:40<17:38,  4.14s/it]predicting train subjects:   4%|▍         | 11/266 [00:44<17:15,  4.06s/it]predicting train subjects:   5%|▍         | 12/266 [00:48<17:04,  4.03s/it]predicting train subjects:   5%|▍         | 13/266 [00:52<17:08,  4.06s/it]predicting train subjects:   5%|▌         | 14/266 [00:57<17:27,  4.16s/it]predicting train subjects:   6%|▌         | 15/266 [01:01<17:05,  4.09s/it]predicting train subjects:   6%|▌         | 16/266 [01:04<16:32,  3.97s/it]predicting train subjects:   6%|▋         | 17/266 [01:09<16:48,  4.05s/it]predicting train subjects:   7%|▋         | 18/266 [01:12<16:21,  3.96s/it]predicting train subjects:   7%|▋         | 19/266 [01:16<16:21,  3.98s/it]predicting train subjects:   8%|▊         | 20/266 [01:20<16:19,  3.98s/it]predicting train subjects:   8%|▊         | 21/266 [01:24<16:25,  4.02s/it]predicting train subjects:   8%|▊         | 22/266 [01:29<16:30,  4.06s/it]predicting train subjects:   9%|▊         | 23/266 [01:33<16:14,  4.01s/it]predicting train subjects:   9%|▉         | 24/266 [01:36<15:39,  3.88s/it]predicting train subjects:   9%|▉         | 25/266 [01:40<15:26,  3.84s/it]predicting train subjects:  10%|▉         | 26/266 [01:44<15:25,  3.86s/it]predicting train subjects:  10%|█         | 27/266 [01:48<15:16,  3.83s/it]predicting train subjects:  11%|█         | 28/266 [01:52<15:32,  3.92s/it]predicting train subjects:  11%|█         | 29/266 [01:55<15:23,  3.90s/it]predicting train subjects:  11%|█▏        | 30/266 [01:59<14:58,  3.81s/it]predicting train subjects:  12%|█▏        | 31/266 [02:02<14:21,  3.66s/it]predicting train subjects:  12%|█▏        | 32/266 [02:06<13:54,  3.57s/it]predicting train subjects:  12%|█▏        | 33/266 [02:09<13:34,  3.50s/it]predicting train subjects:  13%|█▎        | 34/266 [02:12<13:23,  3.46s/it]predicting train subjects:  13%|█▎        | 35/266 [02:16<13:23,  3.48s/it]predicting train subjects:  14%|█▎        | 36/266 [02:20<13:22,  3.49s/it]predicting train subjects:  14%|█▍        | 37/266 [02:23<13:43,  3.60s/it]predicting train subjects:  14%|█▍        | 38/266 [02:27<13:36,  3.58s/it]predicting train subjects:  15%|█▍        | 39/266 [02:31<13:52,  3.67s/it]predicting train subjects:  15%|█▌        | 40/266 [02:35<14:03,  3.73s/it]predicting train subjects:  15%|█▌        | 41/266 [02:38<14:00,  3.73s/it]predicting train subjects:  16%|█▌        | 42/266 [02:42<13:28,  3.61s/it]predicting train subjects:  16%|█▌        | 43/266 [02:45<13:06,  3.53s/it]predicting train subjects:  17%|█▋        | 44/266 [02:48<12:45,  3.45s/it]predicting train subjects:  17%|█▋        | 45/266 [02:51<12:22,  3.36s/it]predicting train subjects:  17%|█▋        | 46/266 [02:55<12:17,  3.35s/it]predicting train subjects:  18%|█▊        | 47/266 [02:58<12:31,  3.43s/it]predicting train subjects:  18%|█▊        | 48/266 [03:02<12:13,  3.37s/it]predicting train subjects:  18%|█▊        | 49/266 [03:05<12:10,  3.37s/it]predicting train subjects:  19%|█▉        | 50/266 [03:08<12:04,  3.35s/it]predicting train subjects:  19%|█▉        | 51/266 [03:12<11:53,  3.32s/it]predicting train subjects:  20%|█▉        | 52/266 [03:15<11:43,  3.29s/it]predicting train subjects:  20%|█▉        | 53/266 [03:18<11:41,  3.29s/it]predicting train subjects:  20%|██        | 54/266 [03:21<11:10,  3.16s/it]predicting train subjects:  21%|██        | 55/266 [03:24<10:51,  3.09s/it]predicting train subjects:  21%|██        | 56/266 [03:27<10:34,  3.02s/it]predicting train subjects:  21%|██▏       | 57/266 [03:30<10:22,  2.98s/it]predicting train subjects:  22%|██▏       | 58/266 [03:32<10:12,  2.95s/it]predicting train subjects:  22%|██▏       | 59/266 [03:36<10:16,  2.98s/it]predicting train subjects:  23%|██▎       | 60/266 [03:38<10:10,  2.96s/it]predicting train subjects:  23%|██▎       | 61/266 [03:42<10:29,  3.07s/it]predicting train subjects:  23%|██▎       | 62/266 [03:45<10:33,  3.10s/it]predicting train subjects:  24%|██▎       | 63/266 [03:48<10:15,  3.03s/it]predicting train subjects:  24%|██▍       | 64/266 [03:51<10:33,  3.13s/it]predicting train subjects:  24%|██▍       | 65/266 [03:54<10:34,  3.16s/it]predicting train subjects:  25%|██▍       | 66/266 [03:57<10:19,  3.10s/it]predicting train subjects:  25%|██▌       | 67/266 [04:01<10:31,  3.17s/it]predicting train subjects:  26%|██▌       | 68/266 [04:04<10:44,  3.26s/it]predicting train subjects:  26%|██▌       | 69/266 [04:07<10:30,  3.20s/it]predicting train subjects:  26%|██▋       | 70/266 [04:10<10:02,  3.08s/it]predicting train subjects:  27%|██▋       | 71/266 [04:13<10:00,  3.08s/it]predicting train subjects:  27%|██▋       | 72/266 [04:17<10:18,  3.19s/it]predicting train subjects:  27%|██▋       | 73/266 [04:20<10:29,  3.26s/it]predicting train subjects:  28%|██▊       | 74/266 [04:23<10:21,  3.24s/it]predicting train subjects:  28%|██▊       | 75/266 [04:27<10:29,  3.30s/it]predicting train subjects:  29%|██▊       | 76/266 [04:30<10:30,  3.32s/it]predicting train subjects:  29%|██▉       | 77/266 [04:33<10:23,  3.30s/it]predicting train subjects:  29%|██▉       | 78/266 [04:37<10:46,  3.44s/it]predicting train subjects:  30%|██▉       | 79/266 [04:41<11:09,  3.58s/it]predicting train subjects:  30%|███       | 80/266 [04:45<11:36,  3.75s/it]predicting train subjects:  30%|███       | 81/266 [04:49<11:49,  3.84s/it]predicting train subjects:  31%|███       | 82/266 [04:53<12:01,  3.92s/it]predicting train subjects:  31%|███       | 83/266 [04:57<11:56,  3.92s/it]predicting train subjects:  32%|███▏      | 84/266 [05:01<11:41,  3.85s/it]predicting train subjects:  32%|███▏      | 85/266 [05:05<11:43,  3.89s/it]predicting train subjects:  32%|███▏      | 86/266 [05:09<11:43,  3.91s/it]predicting train subjects:  33%|███▎      | 87/266 [05:13<11:51,  3.97s/it]predicting train subjects:  33%|███▎      | 88/266 [05:17<12:00,  4.05s/it]predicting train subjects:  33%|███▎      | 89/266 [05:21<12:02,  4.08s/it]predicting train subjects:  34%|███▍      | 90/266 [05:25<11:43,  4.00s/it]predicting train subjects:  34%|███▍      | 91/266 [05:29<11:50,  4.06s/it]predicting train subjects:  35%|███▍      | 92/266 [05:33<11:44,  4.05s/it]predicting train subjects:  35%|███▍      | 93/266 [05:37<11:28,  3.98s/it]predicting train subjects:  35%|███▌      | 94/266 [05:41<11:36,  4.05s/it]predicting train subjects:  36%|███▌      | 95/266 [05:45<11:29,  4.03s/it]predicting train subjects:  36%|███▌      | 96/266 [05:49<11:18,  3.99s/it]predicting train subjects:  36%|███▋      | 97/266 [05:53<11:06,  3.94s/it]predicting train subjects:  37%|███▋      | 98/266 [05:57<10:46,  3.85s/it]predicting train subjects:  37%|███▋      | 99/266 [06:00<10:00,  3.60s/it]predicting train subjects:  38%|███▊      | 100/266 [06:03<09:53,  3.57s/it]predicting train subjects:  38%|███▊      | 101/266 [06:07<09:57,  3.62s/it]predicting train subjects:  38%|███▊      | 102/266 [06:10<09:44,  3.57s/it]predicting train subjects:  39%|███▊      | 103/266 [06:14<09:28,  3.49s/it]predicting train subjects:  39%|███▉      | 104/266 [06:17<09:21,  3.47s/it]predicting train subjects:  39%|███▉      | 105/266 [06:20<09:07,  3.40s/it]predicting train subjects:  40%|███▉      | 106/266 [06:24<09:15,  3.47s/it]predicting train subjects:  40%|████      | 107/266 [06:28<09:22,  3.54s/it]predicting train subjects:  41%|████      | 108/266 [06:31<09:16,  3.52s/it]predicting train subjects:  41%|████      | 109/266 [06:35<09:09,  3.50s/it]predicting train subjects:  41%|████▏     | 110/266 [06:38<09:07,  3.51s/it]predicting train subjects:  42%|████▏     | 111/266 [06:42<09:04,  3.51s/it]predicting train subjects:  42%|████▏     | 112/266 [06:45<09:07,  3.55s/it]predicting train subjects:  42%|████▏     | 113/266 [06:49<09:05,  3.57s/it]predicting train subjects:  43%|████▎     | 114/266 [06:53<09:10,  3.62s/it]predicting train subjects:  43%|████▎     | 115/266 [06:56<09:16,  3.68s/it]predicting train subjects:  44%|████▎     | 116/266 [07:00<09:12,  3.68s/it]predicting train subjects:  44%|████▍     | 117/266 [07:04<09:08,  3.68s/it]predicting train subjects:  44%|████▍     | 118/266 [07:08<09:08,  3.71s/it]predicting train subjects:  45%|████▍     | 119/266 [07:11<09:08,  3.73s/it]predicting train subjects:  45%|████▌     | 120/266 [07:15<09:17,  3.82s/it]predicting train subjects:  45%|████▌     | 121/266 [07:19<09:23,  3.88s/it]predicting train subjects:  46%|████▌     | 122/266 [07:23<09:21,  3.90s/it]predicting train subjects:  46%|████▌     | 123/266 [07:27<09:12,  3.86s/it]predicting train subjects:  47%|████▋     | 124/266 [07:31<09:04,  3.84s/it]predicting train subjects:  47%|████▋     | 125/266 [07:35<09:16,  3.95s/it]predicting train subjects:  47%|████▋     | 126/266 [07:39<09:11,  3.94s/it]predicting train subjects:  48%|████▊     | 127/266 [07:43<09:09,  3.96s/it]predicting train subjects:  48%|████▊     | 128/266 [07:47<09:01,  3.93s/it]predicting train subjects:  48%|████▊     | 129/266 [07:51<08:48,  3.86s/it]predicting train subjects:  49%|████▉     | 130/266 [07:55<08:52,  3.92s/it]predicting train subjects:  49%|████▉     | 131/266 [07:58<08:42,  3.87s/it]predicting train subjects:  50%|████▉     | 132/266 [08:02<08:44,  3.91s/it]predicting train subjects:  50%|█████     | 133/266 [08:06<08:43,  3.93s/it]predicting train subjects:  50%|█████     | 134/266 [08:10<08:43,  3.96s/it]predicting train subjects:  51%|█████     | 135/266 [08:15<08:47,  4.02s/it]predicting train subjects:  51%|█████     | 136/266 [08:19<08:47,  4.05s/it]predicting train subjects:  52%|█████▏    | 137/266 [08:23<08:33,  3.98s/it]predicting train subjects:  52%|█████▏    | 138/266 [08:26<08:25,  3.95s/it]predicting train subjects:  52%|█████▏    | 139/266 [08:31<08:27,  4.00s/it]predicting train subjects:  53%|█████▎    | 140/266 [08:34<08:21,  3.98s/it]predicting train subjects:  53%|█████▎    | 141/266 [08:38<08:06,  3.89s/it]predicting train subjects:  53%|█████▎    | 142/266 [08:42<07:50,  3.79s/it]predicting train subjects:  54%|█████▍    | 143/266 [08:45<07:26,  3.63s/it]predicting train subjects:  54%|█████▍    | 144/266 [08:48<07:07,  3.51s/it]predicting train subjects:  55%|█████▍    | 145/266 [08:52<07:01,  3.48s/it]predicting train subjects:  55%|█████▍    | 146/266 [08:55<06:50,  3.42s/it]predicting train subjects:  55%|█████▌    | 147/266 [08:59<06:55,  3.50s/it]predicting train subjects:  56%|█████▌    | 148/266 [09:02<07:06,  3.62s/it]predicting train subjects:  56%|█████▌    | 149/266 [09:06<07:04,  3.63s/it]predicting train subjects:  56%|█████▋    | 150/266 [09:10<07:00,  3.62s/it]predicting train subjects:  57%|█████▋    | 151/266 [09:14<07:14,  3.78s/it]predicting train subjects:  57%|█████▋    | 152/266 [09:18<07:06,  3.75s/it]predicting train subjects:  58%|█████▊    | 153/266 [09:22<07:11,  3.81s/it]predicting train subjects:  58%|█████▊    | 154/266 [09:25<07:08,  3.83s/it]predicting train subjects:  58%|█████▊    | 155/266 [09:28<06:31,  3.53s/it]predicting train subjects:  59%|█████▊    | 156/266 [09:32<06:21,  3.47s/it]predicting train subjects:  59%|█████▉    | 157/266 [09:34<05:56,  3.27s/it]predicting train subjects:  59%|█████▉    | 158/266 [09:37<05:38,  3.13s/it]predicting train subjects:  60%|█████▉    | 159/266 [09:41<05:45,  3.23s/it]predicting train subjects:  60%|██████    | 160/266 [09:43<05:31,  3.12s/it]predicting train subjects:  61%|██████    | 161/266 [09:47<05:31,  3.16s/it]predicting train subjects:  61%|██████    | 162/266 [09:50<05:23,  3.11s/it]predicting train subjects:  61%|██████▏   | 163/266 [09:53<05:16,  3.07s/it]predicting train subjects:  62%|██████▏   | 164/266 [09:56<05:12,  3.06s/it]predicting train subjects:  62%|██████▏   | 165/266 [09:59<05:21,  3.19s/it]predicting train subjects:  62%|██████▏   | 166/266 [10:02<05:17,  3.17s/it]predicting train subjects:  63%|██████▎   | 167/266 [10:05<05:09,  3.13s/it]predicting train subjects:  63%|██████▎   | 168/266 [10:09<05:09,  3.16s/it]predicting train subjects:  64%|██████▎   | 169/266 [10:12<05:09,  3.19s/it]predicting train subjects:  64%|██████▍   | 170/266 [10:15<05:10,  3.23s/it]predicting train subjects:  64%|██████▍   | 171/266 [10:19<05:14,  3.31s/it]predicting train subjects:  65%|██████▍   | 172/266 [10:21<04:57,  3.16s/it]predicting train subjects:  65%|██████▌   | 173/266 [10:25<04:50,  3.13s/it]predicting train subjects:  65%|██████▌   | 174/266 [10:28<04:50,  3.15s/it]predicting train subjects:  66%|██████▌   | 175/266 [10:31<04:57,  3.27s/it]predicting train subjects:  66%|██████▌   | 176/266 [10:34<04:46,  3.19s/it]predicting train subjects:  67%|██████▋   | 177/266 [10:37<04:37,  3.12s/it]predicting train subjects:  67%|██████▋   | 178/266 [10:40<04:28,  3.05s/it]predicting train subjects:  67%|██████▋   | 179/266 [10:43<04:19,  2.98s/it]predicting train subjects:  68%|██████▊   | 180/266 [10:46<04:13,  2.94s/it]predicting train subjects:  68%|██████▊   | 181/266 [10:49<04:08,  2.92s/it]predicting train subjects:  68%|██████▊   | 182/266 [10:52<04:03,  2.90s/it]predicting train subjects:  69%|██████▉   | 183/266 [10:54<03:59,  2.88s/it]predicting train subjects:  69%|██████▉   | 184/266 [10:57<03:59,  2.92s/it]predicting train subjects:  70%|██████▉   | 185/266 [11:00<03:53,  2.88s/it]predicting train subjects:  70%|██████▉   | 186/266 [11:03<03:48,  2.85s/it]predicting train subjects:  70%|███████   | 187/266 [11:06<03:45,  2.85s/it]predicting train subjects:  71%|███████   | 188/266 [11:09<03:42,  2.86s/it]predicting train subjects:  71%|███████   | 189/266 [11:11<03:37,  2.82s/it]predicting train subjects:  71%|███████▏  | 190/266 [11:14<03:31,  2.78s/it]predicting train subjects:  72%|███████▏  | 191/266 [11:17<03:35,  2.87s/it]predicting train subjects:  72%|███████▏  | 192/266 [11:20<03:25,  2.77s/it]predicting train subjects:  73%|███████▎  | 193/266 [11:22<03:05,  2.54s/it]predicting train subjects:  73%|███████▎  | 194/266 [11:24<03:02,  2.54s/it]predicting train subjects:  73%|███████▎  | 195/266 [11:26<02:51,  2.41s/it]predicting train subjects:  74%|███████▎  | 196/266 [11:29<02:43,  2.33s/it]predicting train subjects:  74%|███████▍  | 197/266 [11:31<02:39,  2.31s/it]predicting train subjects:  74%|███████▍  | 198/266 [11:33<02:35,  2.29s/it]predicting train subjects:  75%|███████▍  | 199/266 [11:35<02:31,  2.26s/it]predicting train subjects:  75%|███████▌  | 200/266 [11:37<02:28,  2.24s/it]predicting train subjects:  76%|███████▌  | 201/266 [11:40<02:26,  2.25s/it]predicting train subjects:  76%|███████▌  | 202/266 [11:42<02:22,  2.23s/it]predicting train subjects:  76%|███████▋  | 203/266 [11:44<02:22,  2.26s/it]predicting train subjects:  77%|███████▋  | 204/266 [11:46<02:18,  2.23s/it]predicting train subjects:  77%|███████▋  | 205/266 [11:49<02:19,  2.29s/it]predicting train subjects:  77%|███████▋  | 206/266 [11:51<02:16,  2.28s/it]predicting train subjects:  78%|███████▊  | 207/266 [11:53<02:17,  2.32s/it]predicting train subjects:  78%|███████▊  | 208/266 [11:56<02:13,  2.31s/it]predicting train subjects:  79%|███████▊  | 209/266 [11:58<02:08,  2.25s/it]predicting train subjects:  79%|███████▉  | 210/266 [12:00<02:06,  2.26s/it]predicting train subjects:  79%|███████▉  | 211/266 [12:02<02:03,  2.25s/it]predicting train subjects:  80%|███████▉  | 212/266 [12:05<01:59,  2.22s/it]predicting train subjects:  80%|████████  | 213/266 [12:07<01:57,  2.22s/it]predicting train subjects:  80%|████████  | 214/266 [12:09<01:51,  2.14s/it]predicting train subjects:  81%|████████  | 215/266 [12:11<01:44,  2.04s/it]predicting train subjects:  81%|████████  | 216/266 [12:13<01:44,  2.09s/it]predicting train subjects:  82%|████████▏ | 217/266 [12:15<01:45,  2.15s/it]predicting train subjects:  82%|████████▏ | 218/266 [12:17<01:39,  2.07s/it]predicting train subjects:  82%|████████▏ | 219/266 [12:19<01:35,  2.03s/it]predicting train subjects:  83%|████████▎ | 220/266 [12:21<01:36,  2.10s/it]predicting train subjects:  83%|████████▎ | 221/266 [12:23<01:32,  2.06s/it]predicting train subjects:  83%|████████▎ | 222/266 [12:25<01:30,  2.05s/it]predicting train subjects:  84%|████████▍ | 223/266 [12:27<01:29,  2.09s/it]predicting train subjects:  84%|████████▍ | 224/266 [12:29<01:25,  2.03s/it]predicting train subjects:  85%|████████▍ | 225/266 [12:31<01:22,  2.01s/it]predicting train subjects:  85%|████████▍ | 226/266 [12:33<01:18,  1.97s/it]predicting train subjects:  85%|████████▌ | 227/266 [12:35<01:18,  2.02s/it]predicting train subjects:  86%|████████▌ | 228/266 [12:37<01:16,  2.00s/it]predicting train subjects:  86%|████████▌ | 229/266 [12:39<01:12,  1.96s/it]predicting train subjects:  86%|████████▋ | 230/266 [12:41<01:13,  2.04s/it]predicting train subjects:  87%|████████▋ | 231/266 [12:43<01:10,  2.02s/it]predicting train subjects:  87%|████████▋ | 232/266 [12:45<01:09,  2.04s/it]predicting train subjects:  88%|████████▊ | 233/266 [12:47<01:08,  2.07s/it]predicting train subjects:  88%|████████▊ | 234/266 [12:49<01:05,  2.06s/it]predicting train subjects:  88%|████████▊ | 235/266 [12:52<01:05,  2.10s/it]predicting train subjects:  89%|████████▊ | 236/266 [12:54<01:02,  2.08s/it]predicting train subjects:  89%|████████▉ | 237/266 [12:56<01:04,  2.21s/it]predicting train subjects:  89%|████████▉ | 238/266 [12:58<01:00,  2.17s/it]predicting train subjects:  90%|████████▉ | 239/266 [13:00<00:58,  2.18s/it]predicting train subjects:  90%|█████████ | 240/266 [13:02<00:55,  2.13s/it]predicting train subjects:  91%|█████████ | 241/266 [13:05<00:53,  2.15s/it]predicting train subjects:  91%|█████████ | 242/266 [13:07<00:50,  2.09s/it]predicting train subjects:  91%|█████████▏| 243/266 [13:09<00:49,  2.13s/it]predicting train subjects:  92%|█████████▏| 244/266 [13:11<00:48,  2.18s/it]predicting train subjects:  92%|█████████▏| 245/266 [13:13<00:44,  2.14s/it]predicting train subjects:  92%|█████████▏| 246/266 [13:15<00:42,  2.10s/it]predicting train subjects:  93%|█████████▎| 247/266 [13:18<00:41,  2.17s/it]predicting train subjects:  93%|█████████▎| 248/266 [13:19<00:37,  2.10s/it]predicting train subjects:  94%|█████████▎| 249/266 [13:22<00:37,  2.23s/it]predicting train subjects:  94%|█████████▍| 250/266 [13:25<00:37,  2.33s/it]predicting train subjects:  94%|█████████▍| 251/266 [13:27<00:35,  2.38s/it]predicting train subjects:  95%|█████████▍| 252/266 [13:30<00:34,  2.48s/it]predicting train subjects:  95%|█████████▌| 253/266 [13:32<00:33,  2.54s/it]predicting train subjects:  95%|█████████▌| 254/266 [13:35<00:30,  2.57s/it]predicting train subjects:  96%|█████████▌| 255/266 [13:38<00:28,  2.57s/it]predicting train subjects:  96%|█████████▌| 256/266 [13:40<00:25,  2.58s/it]predicting train subjects:  97%|█████████▋| 257/266 [13:43<00:23,  2.59s/it]predicting train subjects:  97%|█████████▋| 258/266 [13:46<00:20,  2.60s/it]predicting train subjects:  97%|█████████▋| 259/266 [13:48<00:18,  2.61s/it]predicting train subjects:  98%|█████████▊| 260/266 [13:51<00:15,  2.63s/it]predicting train subjects:  98%|█████████▊| 261/266 [13:53<00:13,  2.63s/it]predicting train subjects:  98%|█████████▊| 262/266 [13:56<00:10,  2.64s/it]predicting train subjects:  99%|█████████▉| 263/266 [13:59<00:08,  2.69s/it]predicting train subjects:  99%|█████████▉| 264/266 [14:01<00:05,  2.64s/it]predicting train subjects: 100%|█████████▉| 265/266 [14:04<00:02,  2.64s/it]predicting train subjects: 100%|██████████| 266/266 [14:07<00:00,  2.61s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:00<02:11,  2.01it/s]Loading train:   1%|          | 2/266 [00:01<02:14,  1.97it/s]Loading train:   1%|          | 3/266 [00:01<02:13,  1.97it/s]Loading train:   2%|▏         | 4/266 [00:01<02:08,  2.05it/s]Loading train:   2%|▏         | 5/266 [00:02<02:04,  2.09it/s]Loading train:   2%|▏         | 6/266 [00:02<02:04,  2.09it/s]Loading train:   3%|▎         | 7/266 [00:03<02:00,  2.16it/s]Loading train:   3%|▎         | 8/266 [00:03<01:56,  2.21it/s]Loading train:   3%|▎         | 9/266 [00:04<01:58,  2.16it/s]Loading train:   4%|▍         | 10/266 [00:04<01:59,  2.15it/s]Loading train:   4%|▍         | 11/266 [00:05<01:55,  2.22it/s]Loading train:   5%|▍         | 12/266 [00:05<01:53,  2.24it/s]Loading train:   5%|▍         | 13/266 [00:06<01:53,  2.23it/s]Loading train:   5%|▌         | 14/266 [00:06<01:55,  2.19it/s]Loading train:   6%|▌         | 15/266 [00:06<01:50,  2.26it/s]Loading train:   6%|▌         | 16/266 [00:07<01:50,  2.26it/s]Loading train:   6%|▋         | 17/266 [00:07<01:51,  2.23it/s]Loading train:   7%|▋         | 18/266 [00:08<01:55,  2.14it/s]Loading train:   7%|▋         | 19/266 [00:08<01:53,  2.18it/s]Loading train:   8%|▊         | 20/266 [00:09<01:56,  2.11it/s]Loading train:   8%|▊         | 21/266 [00:09<01:56,  2.11it/s]Loading train:   8%|▊         | 22/266 [00:10<01:56,  2.09it/s]Loading train:   9%|▊         | 23/266 [00:10<01:56,  2.08it/s]Loading train:   9%|▉         | 24/266 [00:11<01:53,  2.14it/s]Loading train:   9%|▉         | 25/266 [00:11<01:51,  2.17it/s]Loading train:  10%|▉         | 26/266 [00:12<01:45,  2.27it/s]Loading train:  10%|█         | 27/266 [00:12<01:52,  2.13it/s]Loading train:  11%|█         | 28/266 [00:13<01:55,  2.05it/s]Loading train:  11%|█         | 29/266 [00:13<01:53,  2.09it/s]Loading train:  11%|█▏        | 30/266 [00:14<01:54,  2.07it/s]Loading train:  12%|█▏        | 31/266 [00:14<01:55,  2.03it/s]Loading train:  12%|█▏        | 32/266 [00:14<01:50,  2.12it/s]Loading train:  12%|█▏        | 33/266 [00:15<01:46,  2.18it/s]Loading train:  13%|█▎        | 34/266 [00:15<01:44,  2.23it/s]Loading train:  13%|█▎        | 35/266 [00:16<01:42,  2.26it/s]Loading train:  14%|█▎        | 36/266 [00:16<01:41,  2.26it/s]Loading train:  14%|█▍        | 37/266 [00:17<01:42,  2.23it/s]Loading train:  14%|█▍        | 38/266 [00:17<01:46,  2.15it/s]Loading train:  15%|█▍        | 39/266 [00:18<01:44,  2.16it/s]Loading train:  15%|█▌        | 40/266 [00:18<01:44,  2.16it/s]Loading train:  15%|█▌        | 41/266 [00:19<01:42,  2.20it/s]Loading train:  16%|█▌        | 42/266 [00:19<01:38,  2.28it/s]Loading train:  16%|█▌        | 43/266 [00:19<01:36,  2.31it/s]Loading train:  17%|█▋        | 44/266 [00:20<01:35,  2.32it/s]Loading train:  17%|█▋        | 45/266 [00:20<01:35,  2.32it/s]Loading train:  17%|█▋        | 46/266 [00:21<01:29,  2.45it/s]Loading train:  18%|█▊        | 47/266 [00:21<01:25,  2.57it/s]Loading train:  18%|█▊        | 48/266 [00:21<01:25,  2.56it/s]Loading train:  18%|█▊        | 49/266 [00:22<01:29,  2.43it/s]Loading train:  19%|█▉        | 50/266 [00:22<01:27,  2.47it/s]Loading train:  19%|█▉        | 51/266 [00:23<01:25,  2.51it/s]Loading train:  20%|█▉        | 52/266 [00:23<01:25,  2.51it/s]Loading train:  20%|█▉        | 53/266 [00:23<01:29,  2.38it/s]Loading train:  20%|██        | 54/266 [00:24<01:32,  2.29it/s]Loading train:  21%|██        | 55/266 [00:24<01:32,  2.27it/s]Loading train:  21%|██        | 56/266 [00:25<01:33,  2.24it/s]Loading train:  21%|██▏       | 57/266 [00:25<01:32,  2.26it/s]Loading train:  22%|██▏       | 58/266 [00:26<01:27,  2.37it/s]Loading train:  22%|██▏       | 59/266 [00:26<01:25,  2.42it/s]Loading train:  23%|██▎       | 60/266 [00:26<01:29,  2.30it/s]Loading train:  23%|██▎       | 61/266 [00:27<01:26,  2.36it/s]Loading train:  23%|██▎       | 62/266 [00:27<01:26,  2.35it/s]Loading train:  24%|██▎       | 63/266 [00:28<01:25,  2.38it/s]Loading train:  24%|██▍       | 64/266 [00:28<01:24,  2.39it/s]Loading train:  24%|██▍       | 65/266 [00:29<01:24,  2.39it/s]Loading train:  25%|██▍       | 66/266 [00:29<01:21,  2.45it/s]Loading train:  25%|██▌       | 67/266 [00:29<01:20,  2.47it/s]Loading train:  26%|██▌       | 68/266 [00:30<01:21,  2.42it/s]Loading train:  26%|██▌       | 69/266 [00:30<01:15,  2.60it/s]Loading train:  26%|██▋       | 70/266 [00:30<01:11,  2.75it/s]Loading train:  27%|██▋       | 71/266 [00:31<01:08,  2.86it/s]Loading train:  27%|██▋       | 72/266 [00:31<01:05,  2.94it/s]Loading train:  27%|██▋       | 73/266 [00:31<01:05,  2.97it/s]Loading train:  28%|██▊       | 74/266 [00:32<01:07,  2.83it/s]Loading train:  28%|██▊       | 75/266 [00:32<01:09,  2.76it/s]Loading train:  29%|██▊       | 76/266 [00:32<01:10,  2.70it/s]Loading train:  29%|██▉       | 77/266 [00:33<01:08,  2.77it/s]Loading train:  29%|██▉       | 78/266 [00:33<01:12,  2.61it/s]Loading train:  30%|██▉       | 79/266 [00:34<01:15,  2.47it/s]Loading train:  30%|███       | 80/266 [00:34<01:18,  2.36it/s]Loading train:  30%|███       | 81/266 [00:35<01:20,  2.30it/s]Loading train:  31%|███       | 82/266 [00:35<01:20,  2.27it/s]Loading train:  31%|███       | 83/266 [00:36<01:20,  2.27it/s]Loading train:  32%|███▏      | 84/266 [00:36<01:21,  2.23it/s]Loading train:  32%|███▏      | 85/266 [00:37<01:23,  2.16it/s]Loading train:  32%|███▏      | 86/266 [00:37<01:22,  2.18it/s]Loading train:  33%|███▎      | 87/266 [00:37<01:20,  2.22it/s]Loading train:  33%|███▎      | 88/266 [00:38<01:19,  2.24it/s]Loading train:  33%|███▎      | 89/266 [00:38<01:19,  2.23it/s]Loading train:  34%|███▍      | 90/266 [00:39<01:19,  2.22it/s]Loading train:  34%|███▍      | 91/266 [00:39<01:18,  2.24it/s]Loading train:  35%|███▍      | 92/266 [00:40<01:19,  2.18it/s]Loading train:  35%|███▍      | 93/266 [00:40<01:20,  2.15it/s]Loading train:  35%|███▌      | 94/266 [00:41<01:15,  2.27it/s]Loading train:  36%|███▌      | 95/266 [00:41<01:16,  2.23it/s]Loading train:  36%|███▌      | 96/266 [00:41<01:17,  2.20it/s]Loading train:  36%|███▋      | 97/266 [00:42<01:19,  2.13it/s]Loading train:  37%|███▋      | 98/266 [00:42<01:14,  2.25it/s]Loading train:  37%|███▋      | 99/266 [00:43<01:10,  2.36it/s]Loading train:  38%|███▊      | 100/266 [00:43<01:06,  2.48it/s]Loading train:  38%|███▊      | 101/266 [00:43<01:06,  2.49it/s]Loading train:  38%|███▊      | 102/266 [00:44<01:11,  2.28it/s]Loading train:  39%|███▊      | 103/266 [00:44<01:11,  2.29it/s]Loading train:  39%|███▉      | 104/266 [00:45<01:14,  2.18it/s]Loading train:  39%|███▉      | 105/266 [00:45<01:12,  2.21it/s]Loading train:  40%|███▉      | 106/266 [00:46<01:10,  2.26it/s]Loading train:  40%|████      | 107/266 [00:46<01:09,  2.29it/s]Loading train:  41%|████      | 108/266 [00:47<01:09,  2.26it/s]Loading train:  41%|████      | 109/266 [00:47<01:08,  2.28it/s]Loading train:  41%|████▏     | 110/266 [00:48<01:08,  2.29it/s]Loading train:  42%|████▏     | 111/266 [00:48<01:08,  2.28it/s]Loading train:  42%|████▏     | 112/266 [00:48<01:07,  2.29it/s]Loading train:  42%|████▏     | 113/266 [00:49<01:05,  2.34it/s]Loading train:  43%|████▎     | 114/266 [00:49<01:06,  2.27it/s]Loading train:  43%|████▎     | 115/266 [00:50<01:07,  2.24it/s]Loading train:  44%|████▎     | 116/266 [00:50<01:08,  2.18it/s]Loading train:  44%|████▍     | 117/266 [00:51<01:10,  2.13it/s]Loading train:  44%|████▍     | 118/266 [00:51<01:11,  2.08it/s]Loading train:  45%|████▍     | 119/266 [00:52<01:10,  2.07it/s]Loading train:  45%|████▌     | 120/266 [00:52<01:08,  2.13it/s]Loading train:  45%|████▌     | 121/266 [00:53<01:06,  2.17it/s]Loading train:  46%|████▌     | 122/266 [00:53<01:05,  2.20it/s]Loading train:  46%|████▌     | 123/266 [00:54<01:04,  2.20it/s]Loading train:  47%|████▋     | 124/266 [00:54<01:04,  2.18it/s]Loading train:  47%|████▋     | 125/266 [00:54<01:02,  2.24it/s]Loading train:  47%|████▋     | 126/266 [00:55<01:03,  2.21it/s]Loading train:  48%|████▊     | 127/266 [00:55<01:02,  2.21it/s]Loading train:  48%|████▊     | 128/266 [00:56<01:01,  2.25it/s]Loading train:  48%|████▊     | 129/266 [00:56<01:00,  2.25it/s]Loading train:  49%|████▉     | 130/266 [00:57<00:59,  2.30it/s]Loading train:  49%|████▉     | 131/266 [00:57<00:58,  2.32it/s]Loading train:  50%|████▉     | 132/266 [00:57<00:55,  2.40it/s]Loading train:  50%|█████     | 133/266 [00:58<00:54,  2.45it/s]Loading train:  50%|█████     | 134/266 [00:58<00:54,  2.43it/s]Loading train:  51%|█████     | 135/266 [00:59<00:55,  2.34it/s]Loading train:  51%|█████     | 136/266 [00:59<00:53,  2.43it/s]Loading train:  52%|█████▏    | 137/266 [00:59<00:52,  2.48it/s]Loading train:  52%|█████▏    | 138/266 [01:00<00:50,  2.55it/s]Loading train:  52%|█████▏    | 139/266 [01:00<00:48,  2.62it/s]Loading train:  53%|█████▎    | 140/266 [01:01<00:47,  2.65it/s]Loading train:  53%|█████▎    | 141/266 [01:01<00:46,  2.67it/s]Loading train:  53%|█████▎    | 142/266 [01:01<00:45,  2.71it/s]Loading train:  54%|█████▍    | 143/266 [01:02<00:46,  2.64it/s]Loading train:  54%|█████▍    | 144/266 [01:02<00:46,  2.62it/s]Loading train:  55%|█████▍    | 145/266 [01:02<00:47,  2.57it/s]Loading train:  55%|█████▍    | 146/266 [01:03<00:48,  2.49it/s]Loading train:  55%|█████▌    | 147/266 [01:03<00:48,  2.47it/s]Loading train:  56%|█████▌    | 148/266 [01:04<00:49,  2.40it/s]Loading train:  56%|█████▌    | 149/266 [01:04<00:47,  2.45it/s]Loading train:  56%|█████▋    | 150/266 [01:05<00:46,  2.48it/s]Loading train:  57%|█████▋    | 151/266 [01:05<00:49,  2.31it/s]Loading train:  57%|█████▋    | 152/266 [01:05<00:48,  2.37it/s]Loading train:  58%|█████▊    | 153/266 [01:06<00:46,  2.43it/s]Loading train:  58%|█████▊    | 154/266 [01:06<00:46,  2.42it/s]Loading train:  58%|█████▊    | 155/266 [01:07<00:44,  2.51it/s]Loading train:  59%|█████▊    | 156/266 [01:07<00:41,  2.64it/s]Loading train:  59%|█████▉    | 157/266 [01:07<00:40,  2.71it/s]Loading train:  59%|█████▉    | 158/266 [01:08<00:38,  2.79it/s]Loading train:  60%|█████▉    | 159/266 [01:08<00:39,  2.72it/s]Loading train:  60%|██████    | 160/266 [01:08<00:40,  2.62it/s]Loading train:  61%|██████    | 161/266 [01:09<00:38,  2.72it/s]Loading train:  61%|██████    | 162/266 [01:09<00:38,  2.67it/s]Loading train:  61%|██████▏   | 163/266 [01:09<00:38,  2.70it/s]Loading train:  62%|██████▏   | 164/266 [01:10<00:37,  2.75it/s]Loading train:  62%|██████▏   | 165/266 [01:10<00:37,  2.70it/s]Loading train:  62%|██████▏   | 166/266 [01:11<00:40,  2.45it/s]Loading train:  63%|██████▎   | 167/266 [01:11<00:38,  2.55it/s]Loading train:  63%|██████▎   | 168/266 [01:11<00:36,  2.67it/s]Loading train:  64%|██████▎   | 169/266 [01:12<00:35,  2.74it/s]Loading train:  64%|██████▍   | 170/266 [01:12<00:34,  2.76it/s]Loading train:  64%|██████▍   | 171/266 [01:12<00:33,  2.80it/s]Loading train:  65%|██████▍   | 172/266 [01:13<00:33,  2.84it/s]Loading train:  65%|██████▌   | 173/266 [01:13<00:33,  2.76it/s]Loading train:  65%|██████▌   | 174/266 [01:14<00:33,  2.78it/s]Loading train:  66%|██████▌   | 175/266 [01:14<00:32,  2.82it/s]Loading train:  66%|██████▌   | 176/266 [01:14<00:31,  2.84it/s]Loading train:  67%|██████▋   | 177/266 [01:15<00:31,  2.86it/s]Loading train:  67%|██████▋   | 178/266 [01:15<00:31,  2.77it/s]Loading train:  67%|██████▋   | 179/266 [01:15<00:30,  2.81it/s]Loading train:  68%|██████▊   | 180/266 [01:16<00:30,  2.84it/s]Loading train:  68%|██████▊   | 181/266 [01:16<00:30,  2.78it/s]Loading train:  68%|██████▊   | 182/266 [01:16<00:29,  2.85it/s]Loading train:  69%|██████▉   | 183/266 [01:17<00:29,  2.82it/s]Loading train:  69%|██████▉   | 184/266 [01:17<00:29,  2.77it/s]Loading train:  70%|██████▉   | 185/266 [01:17<00:29,  2.76it/s]Loading train:  70%|██████▉   | 186/266 [01:18<00:28,  2.78it/s]Loading train:  70%|███████   | 187/266 [01:18<00:28,  2.77it/s]Loading train:  71%|███████   | 188/266 [01:19<00:28,  2.71it/s]Loading train:  71%|███████   | 189/266 [01:19<00:28,  2.68it/s]Loading train:  71%|███████▏  | 190/266 [01:19<00:28,  2.68it/s]Loading train:  72%|███████▏  | 191/266 [01:20<00:29,  2.58it/s]Loading train:  72%|███████▏  | 192/266 [01:20<00:28,  2.57it/s]Loading train:  73%|███████▎  | 193/266 [01:21<00:28,  2.54it/s]Loading train:  73%|███████▎  | 194/266 [01:21<00:30,  2.37it/s]Loading train:  73%|███████▎  | 195/266 [01:21<00:29,  2.44it/s]Loading train:  74%|███████▎  | 196/266 [01:22<00:27,  2.53it/s]Loading train:  74%|███████▍  | 197/266 [01:22<00:26,  2.58it/s]Loading train:  74%|███████▍  | 198/266 [01:23<00:26,  2.56it/s]Loading train:  75%|███████▍  | 199/266 [01:23<00:26,  2.57it/s]Loading train:  75%|███████▌  | 200/266 [01:23<00:25,  2.60it/s]Loading train:  76%|███████▌  | 201/266 [01:24<00:24,  2.62it/s]Loading train:  76%|███████▌  | 202/266 [01:24<00:23,  2.69it/s]Loading train:  76%|███████▋  | 203/266 [01:24<00:23,  2.70it/s]Loading train:  77%|███████▋  | 204/266 [01:25<00:22,  2.74it/s]Loading train:  77%|███████▋  | 205/266 [01:25<00:21,  2.84it/s]Loading train:  77%|███████▋  | 206/266 [01:25<00:21,  2.85it/s]Loading train:  78%|███████▊  | 207/266 [01:26<00:21,  2.79it/s]Loading train:  78%|███████▊  | 208/266 [01:26<00:20,  2.77it/s]Loading train:  79%|███████▊  | 209/266 [01:26<00:20,  2.80it/s]Loading train:  79%|███████▉  | 210/266 [01:27<00:19,  2.83it/s]Loading train:  79%|███████▉  | 211/266 [01:27<00:19,  2.82it/s]Loading train:  80%|███████▉  | 212/266 [01:28<00:18,  2.87it/s]Loading train:  80%|████████  | 213/266 [01:28<00:18,  2.90it/s]Loading train:  80%|████████  | 214/266 [01:28<00:17,  2.89it/s]Loading train:  81%|████████  | 215/266 [01:29<00:17,  2.94it/s]Loading train:  81%|████████  | 216/266 [01:29<00:16,  2.96it/s]Loading train:  82%|████████▏ | 217/266 [01:29<00:16,  2.95it/s]Loading train:  82%|████████▏ | 218/266 [01:30<00:16,  2.95it/s]Loading train:  82%|████████▏ | 219/266 [01:30<00:15,  2.99it/s]Loading train:  83%|████████▎ | 220/266 [01:30<00:15,  3.03it/s]Loading train:  83%|████████▎ | 221/266 [01:30<00:14,  3.09it/s]Loading train:  83%|████████▎ | 222/266 [01:31<00:14,  3.12it/s]Loading train:  84%|████████▍ | 223/266 [01:31<00:13,  3.16it/s]Loading train:  84%|████████▍ | 224/266 [01:31<00:13,  3.15it/s]Loading train:  85%|████████▍ | 225/266 [01:32<00:12,  3.19it/s]Loading train:  85%|████████▍ | 226/266 [01:32<00:12,  3.14it/s]Loading train:  85%|████████▌ | 227/266 [01:32<00:12,  3.18it/s]Loading train:  86%|████████▌ | 228/266 [01:33<00:12,  3.10it/s]Loading train:  86%|████████▌ | 229/266 [01:33<00:12,  3.08it/s]Loading train:  86%|████████▋ | 230/266 [01:33<00:12,  2.96it/s]Loading train:  87%|████████▋ | 231/266 [01:34<00:12,  2.90it/s]Loading train:  87%|████████▋ | 232/266 [01:34<00:11,  2.88it/s]Loading train:  88%|████████▊ | 233/266 [01:35<00:11,  2.79it/s]Loading train:  88%|████████▊ | 234/266 [01:35<00:11,  2.69it/s]Loading train:  88%|████████▊ | 235/266 [01:35<00:11,  2.73it/s]Loading train:  89%|████████▊ | 236/266 [01:36<00:11,  2.70it/s]Loading train:  89%|████████▉ | 237/266 [01:36<00:10,  2.72it/s]Loading train:  89%|████████▉ | 238/266 [01:36<00:10,  2.72it/s]Loading train:  90%|████████▉ | 239/266 [01:37<00:09,  2.81it/s]Loading train:  90%|█████████ | 240/266 [01:37<00:09,  2.86it/s]Loading train:  91%|█████████ | 241/266 [01:37<00:08,  2.85it/s]Loading train:  91%|█████████ | 242/266 [01:38<00:08,  2.82it/s]Loading train:  91%|█████████▏| 243/266 [01:38<00:08,  2.75it/s]Loading train:  92%|█████████▏| 244/266 [01:38<00:07,  2.81it/s]Loading train:  92%|█████████▏| 245/266 [01:39<00:07,  2.81it/s]Loading train:  92%|█████████▏| 246/266 [01:39<00:07,  2.83it/s]Loading train:  93%|█████████▎| 247/266 [01:40<00:06,  2.81it/s]Loading train:  93%|█████████▎| 248/266 [01:40<00:06,  2.89it/s]Loading train:  94%|█████████▎| 249/266 [01:40<00:06,  2.72it/s]Loading train:  94%|█████████▍| 250/266 [01:41<00:06,  2.60it/s]Loading train:  94%|█████████▍| 251/266 [01:41<00:05,  2.59it/s]Loading train:  95%|█████████▍| 252/266 [01:41<00:05,  2.59it/s]Loading train:  95%|█████████▌| 253/266 [01:42<00:05,  2.56it/s]Loading train:  95%|█████████▌| 254/266 [01:42<00:04,  2.60it/s]Loading train:  96%|█████████▌| 255/266 [01:43<00:04,  2.60it/s]Loading train:  96%|█████████▌| 256/266 [01:43<00:03,  2.57it/s]Loading train:  97%|█████████▋| 257/266 [01:43<00:03,  2.48it/s]Loading train:  97%|█████████▋| 258/266 [01:44<00:03,  2.53it/s]Loading train:  97%|█████████▋| 259/266 [01:44<00:02,  2.56it/s]Loading train:  98%|█████████▊| 260/266 [01:45<00:02,  2.55it/s]Loading train:  98%|█████████▊| 261/266 [01:45<00:01,  2.54it/s]Loading train:  98%|█████████▊| 262/266 [01:45<00:01,  2.52it/s]Loading train:  99%|█████████▉| 263/266 [01:46<00:01,  2.52it/s]Loading train:  99%|█████████▉| 264/266 [01:46<00:00,  2.57it/s]Loading train: 100%|█████████▉| 265/266 [01:47<00:00,  2.60it/s]Loading train: 100%|██████████| 266/266 [01:47<00:00,  2.59it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/266 [00:00<00:01, 129.41it/s]concatenating: train:  10%|█         | 27/266 [00:00<00:01, 131.39it/s]concatenating: train:  16%|█▌        | 42/266 [00:00<00:01, 133.22it/s]concatenating: train:  23%|██▎       | 61/266 [00:00<00:01, 145.37it/s]concatenating: train:  29%|██▉       | 78/266 [00:00<00:01, 151.51it/s]concatenating: train:  35%|███▍      | 92/266 [00:00<00:01, 138.37it/s]concatenating: train:  44%|████▍     | 118/266 [00:00<00:00, 159.63it/s]concatenating: train:  51%|█████     | 136/266 [00:00<00:00, 165.00it/s]concatenating: train:  61%|██████▏   | 163/266 [00:00<00:00, 186.49it/s]concatenating: train:  72%|███████▏  | 192/266 [00:01<00:00, 208.29it/s]concatenating: train:  83%|████████▎ | 221/266 [00:01<00:00, 227.33it/s]concatenating: train:  95%|█████████▍| 252/266 [00:01<00:00, 246.69it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 209.42it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:00<00:01,  2.05it/s]Loading test:  40%|████      | 2/5 [00:00<00:01,  2.17it/s]Loading test:  60%|██████    | 3/5 [00:01<00:00,  2.29it/s]Loading test:  80%|████████  | 4/5 [00:01<00:00,  2.48it/s]Loading test: 100%|██████████| 5/5 [00:01<00:00,  2.50it/s]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 357.38it/s]2019-08-17 18:47:05.409766: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 18:47:05.409872: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 18:47:05.409886: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 18:47:05.409895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 18:47:05.410347: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14485 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:07,  5.96it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:05,  7.09it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  6.40it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  8.25it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:03,  9.08it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.83it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02, 10.06it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02, 10.36it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:01<00:02,  8.42it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:01, 10.41it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01, 10.97it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01, 11.16it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:02<00:01,  8.64it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:02<00:00, 10.69it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00, 10.86it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00, 10.98it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  8.83it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 12.30it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 2.0      1-THALAMUS
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/1-THALAMUS/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 76, 108, 1)   0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 76, 108, 30)  300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 76, 108, 30)  120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 76, 108, 30)  0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 76, 108, 30)  8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 76, 108, 30)  120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 76, 108, 30)  0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 38, 54, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 38, 54, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 38, 54, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 38, 54, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 38, 54, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 38, 54, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 38, 54, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 38, 54, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 38, 54, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 19, 27, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 19, 27, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 19, 27, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 19, 27, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 19, 27, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 19, 27, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 19, 27, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 19, 27, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 19, 27, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 19, 27, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 38, 54, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 38, 54, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 38, 54, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 38, 54, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 38, 54, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 38, 54, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 38, 54, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 38, 54, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 38, 54, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 38, 54, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 76, 108, 30)  25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 76, 108, 60)  0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 76, 108, 30)  16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 76, 108, 30)  120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 76, 108, 30)  0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 76, 108, 30)  8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 76, 108, 30)  120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 76, 108, 30)  0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 76, 108, 90)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 76, 108, 90)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 76, 108, 2)   182         dropout_5[0][0]                  
==================================================================================================
Total params: 500,342
Trainable params: 441,122
Non-trainable params: 59,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [0.97453182 0.02546818]
Train on 27987 samples, validate on 500 samples
Epoch 1/300
 - 50s - loss: 0.2470 - acc: 0.9603 - mDice: 0.7219 - val_loss: 0.0720 - val_acc: 0.9883 - val_mDice: 0.8769

Epoch 00001: val_mDice improved from -inf to 0.87690, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 46s - loss: 0.0643 - acc: 0.9836 - mDice: 0.8923 - val_loss: 0.0657 - val_acc: 0.9922 - val_mDice: 0.8884

Epoch 00002: val_mDice improved from 0.87690 to 0.88836, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 46s - loss: 0.0543 - acc: 0.9856 - mDice: 0.9103 - val_loss: 0.0641 - val_acc: 0.9936 - val_mDice: 0.8910

Epoch 00003: val_mDice improved from 0.88836 to 0.89104, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 45s - loss: 0.0490 - acc: 0.9867 - mDice: 0.9201 - val_loss: 0.0620 - val_acc: 0.9923 - val_mDice: 0.8951

Epoch 00004: val_mDice improved from 0.89104 to 0.89506, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 46s - loss: 0.0455 - acc: 0.9871 - mDice: 0.9264 - val_loss: 0.0620 - val_acc: 0.9935 - val_mDice: 0.8950

Epoch 00005: val_mDice did not improve from 0.89506
Epoch 6/300
 - 45s - loss: 0.0430 - acc: 0.9872 - mDice: 0.9310 - val_loss: 0.0606 - val_acc: 0.9914 - val_mDice: 0.8976

Epoch 00006: val_mDice improved from 0.89506 to 0.89761, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 46s - loss: 0.0410 - acc: 0.9872 - mDice: 0.9347 - val_loss: 0.0629 - val_acc: 0.9927 - val_mDice: 0.8935

Epoch 00007: val_mDice did not improve from 0.89761
Epoch 8/300
 - 45s - loss: 0.0395 - acc: 0.9872 - mDice: 0.9375 - val_loss: 0.0598 - val_acc: 0.9919 - val_mDice: 0.8989

Epoch 00008: val_mDice improved from 0.89761 to 0.89887, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/1-THALAMUS/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 46s - loss: 0.0382 - acc: 0.9871 - mDice: 0.9400 - val_loss: 0.0601 - val_acc: 0.9928 - val_mDice: 0.8985

Epoch 00009: val_mDice did not improve from 0.89887
Epoch 10/300
 - 46s - loss: 0.0372 - acc: 0.9872 - mDice: 0.9419 - val_loss: 0.0610 - val_acc: 0.9926 - val_mDice: 0.8971

Epoch 00010: val_mDice did not improve from 0.89887
Epoch 11/300
 - 46s - loss: 0.0362 - acc: 0.9872 - mDice: 0.9437 - val_loss: 0.0620 - val_acc: 0.9920 - val_mDice: 0.8955

Epoch 00011: val_mDice did not improve from 0.89887
Epoch 12/300
 - 46s - loss: 0.0356 - acc: 0.9877 - mDice: 0.9450 - val_loss: 0.0600 - val_acc: 0.9928 - val_mDice: 0.8987

Epoch 00012: val_mDice did not improve from 0.89887
Epoch 13/300
 - 46s - loss: 0.0349 - acc: 0.9880 - mDice: 0.9463 - val_loss: 0.0602 - val_acc: 0.9926 - val_mDice: 0.8985

Epoch 00013: val_mDice did not improve from 0.89887
Epoch 14/300
 - 50s - loss: 0.0342 - acc: 0.9883 - mDice: 0.9475 - val_loss: 0.0616 - val_acc: 0.9922 - val_mDice: 0.8960

Epoch 00014: val_mDice did not improve from 0.89887
Epoch 15/300
 - 49s - loss: 0.0338 - acc: 0.9888 - mDice: 0.9484 - val_loss: 0.0621 - val_acc: 0.9924 - val_mDice: 0.8953

Epoch 00015: val_mDice did not improve from 0.89887
Epoch 16/300
 - 49s - loss: 0.0333 - acc: 0.9893 - mDice: 0.9492 - val_loss: 0.0616 - val_acc: 0.9935 - val_mDice: 0.8957

Epoch 00016: val_mDice did not improve from 0.89887
Epoch 17/300
 - 49s - loss: 0.0329 - acc: 0.9899 - mDice: 0.9500 - val_loss: 0.0610 - val_acc: 0.9939 - val_mDice: 0.8970

Epoch 00017: val_mDice did not improve from 0.89887
Epoch 18/300
 - 50s - loss: 0.0325 - acc: 0.9912 - mDice: 0.9508 - val_loss: 0.0617 - val_acc: 0.9947 - val_mDice: 0.8961

Epoch 00018: val_mDice did not improve from 0.89887
Epoch 19/300
 - 49s - loss: 0.0273 - acc: 0.9957 - mDice: 0.9514 - val_loss: 0.0589 - val_acc: 0.9950 - val_mDice: 0.8924

Epoch 00019: val_mDice did not improve from 0.89887
Epoch 20/300
 - 49s - loss: 0.0256 - acc: 0.9966 - mDice: 0.9516 - val_loss: 0.0577 - val_acc: 0.9950 - val_mDice: 0.8943

Epoch 00020: val_mDice did not improve from 0.89887
Epoch 21/300
 - 49s - loss: 0.0252 - acc: 0.9966 - mDice: 0.9523 - val_loss: 0.0576 - val_acc: 0.9951 - val_mDice: 0.8945

Epoch 00021: val_mDice did not improve from 0.89887
Epoch 22/300
 - 50s - loss: 0.0250 - acc: 0.9966 - mDice: 0.9528 - val_loss: 0.0574 - val_acc: 0.9950 - val_mDice: 0.8948

Epoch 00022: val_mDice did not improve from 0.89887
Epoch 23/300
 - 51s - loss: 0.0247 - acc: 0.9966 - mDice: 0.9533 - val_loss: 0.0561 - val_acc: 0.9952 - val_mDice: 0.8970

Epoch 00023: val_mDice did not improve from 0.89887
Epoch 24/300
 - 50s - loss: 0.0246 - acc: 0.9966 - mDice: 0.9535 - val_loss: 0.0575 - val_acc: 0.9950 - val_mDice: 0.8947

Epoch 00024: val_mDice did not improve from 0.89887
Epoch 25/300
 - 51s - loss: 0.0245 - acc: 0.9967 - mDice: 0.9537 - val_loss: 0.0552 - val_acc: 0.9953 - val_mDice: 0.8985

Epoch 00025: val_mDice did not improve from 0.89887
Epoch 26/300
 - 51s - loss: 0.0241 - acc: 0.9967 - mDice: 0.9544 - val_loss: 0.0554 - val_acc: 0.9952 - val_mDice: 0.8983

Epoch 00026: val_mDice did not improve from 0.89887
Epoch 27/300
 - 50s - loss: 0.0240 - acc: 0.9967 - mDice: 0.9546 - val_loss: 0.0568 - val_acc: 0.9950 - val_mDice: 0.8959

Epoch 00027: val_mDice did not improve from 0.89887
Epoch 28/300
 - 50s - loss: 0.0238 - acc: 0.9967 - mDice: 0.9550 - val_loss: 0.0558 - val_acc: 0.9951 - val_mDice: 0.8976

Epoch 00028: val_mDice did not improve from 0.89887
Epoch 29/300
 - 50s - loss: 0.0237 - acc: 0.9967 - mDice: 0.9553 - val_loss: 0.0566 - val_acc: 0.9951 - val_mDice: 0.8962

Epoch 00029: val_mDice did not improve from 0.89887
Epoch 30/300
 - 50s - loss: 0.0236 - acc: 0.9967 - mDice: 0.9554 - val_loss: 0.0574 - val_acc: 0.9949 - val_mDice: 0.8950

Epoch 00030: val_mDice did not improve from 0.89887
Epoch 31/300
 - 49s - loss: 0.0235 - acc: 0.9967 - mDice: 0.9555 - val_loss: 0.0575 - val_acc: 0.9950 - val_mDice: 0.8948

Epoch 00031: val_mDice did not improve from 0.89887
Epoch 32/300
 - 50s - loss: 0.0234 - acc: 0.9967 - mDice: 0.9557 - val_loss: 0.0561 - val_acc: 0.9951 - val_mDice: 0.8970

Epoch 00032: val_mDice did not improve from 0.89887
Epoch 33/300
 - 49s - loss: 0.0232 - acc: 0.9967 - mDice: 0.9561 - val_loss: 0.0556 - val_acc: 0.9950 - val_mDice: 0.8981

Epoch 00033: val_mDice did not improve from 0.89887
Epoch 34/300
 - 50s - loss: 0.0231 - acc: 0.9968 - mDice: 0.9563 - val_loss: 0.0587 - val_acc: 0.9949 - val_mDice: 0.8926

Epoch 00034: val_mDice did not improve from 0.89887
Epoch 35/300
 - 50s - loss: 0.0230 - acc: 0.9968 - mDice: 0.9565 - val_loss: 0.0560 - val_acc: 0.9950 - val_mDice: 0.8973

Epoch 00035: val_mDice did not improve from 0.89887
Epoch 36/300
 - 48s - loss: 0.0229 - acc: 0.9968 - mDice: 0.9568 - val_loss: 0.0551 - val_acc: 0.9951 - val_mDice: 0.8988

Epoch 00036: val_mDice did not improve from 0.89887
Epoch 37/300
 - 47s - loss: 0.0227 - acc: 0.9968 - mDice: 0.9570 - val_loss: 0.0562 - val_acc: 0.9950 - val_mDice: 0.8969

Epoch 00037: val_mDice did not improve from 0.89887
Epoch 38/300
 - 48s - loss: 0.0227 - acc: 0.9968 - mDice: 0.9570 - val_loss: 0.0576 - val_acc: 0.9949 - val_mDice: 0.8944

Epoch 00038: val_mDice did not improve from 0.89887
Epoch 39/300
 - 47s - loss: 0.0226 - acc: 0.9968 - mDice: 0.9573 - val_loss: 0.0560 - val_acc: 0.9951 - val_mDice: 0.8974

Epoch 00039: val_mDice did not improve from 0.89887
Epoch 40/300
 - 47s - loss: 0.0226 - acc: 0.9968 - mDice: 0.9573 - val_loss: 0.0579 - val_acc: 0.9951 - val_mDice: 0.8940

Epoch 00040: val_mDice did not improve from 0.89887
Epoch 41/300
 - 46s - loss: 0.0224 - acc: 0.9968 - mDice: 0.9576 - val_loss: 0.0564 - val_acc: 0.9950 - val_mDice: 0.8965

Epoch 00041: val_mDice did not improve from 0.89887
Epoch 42/300
 - 46s - loss: 0.0223 - acc: 0.9968 - mDice: 0.9578 - val_loss: 0.0563 - val_acc: 0.9950 - val_mDice: 0.8968

Epoch 00042: val_mDice did not improve from 0.89887
Epoch 43/300
 - 45s - loss: 0.0223 - acc: 0.9968 - mDice: 0.9578 - val_loss: 0.0552 - val_acc: 0.9951 - val_mDice: 0.8988

Epoch 00043: val_mDice did not improve from 0.89887
Epoch 44/300
 - 46s - loss: 0.0222 - acc: 0.9968 - mDice: 0.9580 - val_loss: 0.0561 - val_acc: 0.9951 - val_mDice: 0.8971

Epoch 00044: val_mDice did not improve from 0.89887
Epoch 45/300
 - 45s - loss: 0.0221 - acc: 0.9968 - mDice: 0.9582 - val_loss: 0.0562 - val_acc: 0.9951 - val_mDice: 0.8969

Epoch 00045: val_mDice did not improve from 0.89887
Epoch 46/300
 - 45s - loss: 0.0221 - acc: 0.9968 - mDice: 0.9582 - val_loss: 0.0581 - val_acc: 0.9949 - val_mDice: 0.8936

Epoch 00046: val_mDice did not improve from 0.89887
Epoch 47/300
 - 46s - loss: 0.0220 - acc: 0.9968 - mDice: 0.9583 - val_loss: 0.0570 - val_acc: 0.9950 - val_mDice: 0.8955

Epoch 00047: val_mDice did not improve from 0.89887
Epoch 48/300
 - 45s - loss: 0.0219 - acc: 0.9968 - mDice: 0.9585 - val_loss: 0.0570 - val_acc: 0.9951 - val_mDice: 0.8953

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:01<00:04,  1.07s/it]predicting test subjects:  40%|████      | 2/5 [00:01<00:02,  1.18it/s]predicting test subjects:  60%|██████    | 3/5 [00:01<00:01,  1.45it/s]predicting test subjects:  80%|████████  | 4/5 [00:02<00:00,  1.67it/s]predicting test subjects: 100%|██████████| 5/5 [00:02<00:00,  1.85it/s]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:00<01:53,  2.34it/s]predicting train subjects:   1%|          | 2/266 [00:00<01:53,  2.33it/s]predicting train subjects:   1%|          | 3/266 [00:01<01:42,  2.58it/s]predicting train subjects:   2%|▏         | 4/266 [00:01<01:34,  2.77it/s]predicting train subjects:   2%|▏         | 5/266 [00:01<01:36,  2.70it/s]predicting train subjects:   2%|▏         | 6/266 [00:02<01:34,  2.76it/s]predicting train subjects:   3%|▎         | 7/266 [00:02<01:34,  2.73it/s]predicting train subjects:   3%|▎         | 8/266 [00:02<01:32,  2.79it/s]predicting train subjects:   3%|▎         | 9/266 [00:03<01:32,  2.78it/s]predicting train subjects:   4%|▍         | 10/266 [00:03<01:33,  2.74it/s]predicting train subjects:   4%|▍         | 11/266 [00:03<01:31,  2.78it/s]predicting train subjects:   5%|▍         | 12/266 [00:04<01:31,  2.78it/s]predicting train subjects:   5%|▍         | 13/266 [00:04<01:31,  2.76it/s]predicting train subjects:   5%|▌         | 14/266 [00:05<01:31,  2.75it/s]predicting train subjects:   6%|▌         | 15/266 [00:05<01:32,  2.72it/s]predicting train subjects:   6%|▌         | 16/266 [00:05<01:33,  2.67it/s]predicting train subjects:   6%|▋         | 17/266 [00:06<01:31,  2.73it/s]predicting train subjects:   7%|▋         | 18/266 [00:06<01:29,  2.77it/s]predicting train subjects:   7%|▋         | 19/266 [00:06<01:31,  2.69it/s]predicting train subjects:   8%|▊         | 20/266 [00:07<01:32,  2.66it/s]predicting train subjects:   8%|▊         | 21/266 [00:07<01:29,  2.73it/s]predicting train subjects:   8%|▊         | 22/266 [00:08<01:29,  2.73it/s]predicting train subjects:   9%|▊         | 23/266 [00:08<01:28,  2.74it/s]predicting train subjects:   9%|▉         | 24/266 [00:08<01:25,  2.84it/s]predicting train subjects:   9%|▉         | 25/266 [00:09<01:24,  2.85it/s]predicting train subjects:  10%|▉         | 26/266 [00:09<01:22,  2.91it/s]predicting train subjects:  10%|█         | 27/266 [00:09<01:21,  2.93it/s]predicting train subjects:  11%|█         | 28/266 [00:10<01:20,  2.96it/s]predicting train subjects:  11%|█         | 29/266 [00:10<01:19,  3.00it/s]predicting train subjects:  11%|█▏        | 30/266 [00:10<01:18,  3.01it/s]predicting train subjects:  12%|█▏        | 31/266 [00:11<01:18,  3.01it/s]predicting train subjects:  12%|█▏        | 32/266 [00:11<01:17,  3.00it/s]predicting train subjects:  12%|█▏        | 33/266 [00:11<01:19,  2.94it/s]predicting train subjects:  13%|█▎        | 34/266 [00:12<01:18,  2.96it/s]predicting train subjects:  13%|█▎        | 35/266 [00:12<01:17,  3.00it/s]predicting train subjects:  14%|█▎        | 36/266 [00:12<01:15,  3.03it/s]predicting train subjects:  14%|█▍        | 37/266 [00:13<01:15,  3.02it/s]predicting train subjects:  14%|█▍        | 38/266 [00:13<01:16,  3.00it/s]predicting train subjects:  15%|█▍        | 39/266 [00:13<01:16,  2.97it/s]predicting train subjects:  15%|█▌        | 40/266 [00:14<01:17,  2.92it/s]predicting train subjects:  15%|█▌        | 41/266 [00:14<01:17,  2.90it/s]predicting train subjects:  16%|█▌        | 42/266 [00:14<01:14,  3.00it/s]predicting train subjects:  16%|█▌        | 43/266 [00:15<01:10,  3.16it/s]predicting train subjects:  17%|█▋        | 44/266 [00:15<01:10,  3.15it/s]predicting train subjects:  17%|█▋        | 45/266 [00:15<01:07,  3.28it/s]predicting train subjects:  17%|█▋        | 46/266 [00:15<01:07,  3.25it/s]predicting train subjects:  18%|█▊        | 47/266 [00:16<01:05,  3.35it/s]predicting train subjects:  18%|█▊        | 48/266 [00:16<01:04,  3.37it/s]predicting train subjects:  18%|█▊        | 49/266 [00:16<01:05,  3.33it/s]predicting train subjects:  19%|█▉        | 50/266 [00:17<01:05,  3.28it/s]predicting train subjects:  19%|█▉        | 51/266 [00:17<01:06,  3.25it/s]predicting train subjects:  20%|█▉        | 52/266 [00:17<01:06,  3.22it/s]predicting train subjects:  20%|█▉        | 53/266 [00:18<01:06,  3.19it/s]predicting train subjects:  20%|██        | 54/266 [00:18<01:05,  3.21it/s]predicting train subjects:  21%|██        | 55/266 [00:18<01:04,  3.27it/s]predicting train subjects:  21%|██        | 56/266 [00:18<01:02,  3.39it/s]predicting train subjects:  21%|██▏       | 57/266 [00:19<01:00,  3.45it/s]predicting train subjects:  22%|██▏       | 58/266 [00:19<00:59,  3.49it/s]predicting train subjects:  22%|██▏       | 59/266 [00:19<01:02,  3.30it/s]predicting train subjects:  23%|██▎       | 60/266 [00:20<01:03,  3.25it/s]predicting train subjects:  23%|██▎       | 61/266 [00:20<01:00,  3.38it/s]predicting train subjects:  23%|██▎       | 62/266 [00:20<01:01,  3.33it/s]predicting train subjects:  24%|██▎       | 63/266 [00:21<01:00,  3.34it/s]predicting train subjects:  24%|██▍       | 64/266 [00:21<01:00,  3.36it/s]predicting train subjects:  24%|██▍       | 65/266 [00:21<00:59,  3.39it/s]predicting train subjects:  25%|██▍       | 66/266 [00:21<00:56,  3.52it/s]predicting train subjects:  25%|██▌       | 67/266 [00:22<00:58,  3.42it/s]predicting train subjects:  26%|██▌       | 68/266 [00:22<00:59,  3.32it/s]predicting train subjects:  26%|██▌       | 69/266 [00:22<00:57,  3.45it/s]predicting train subjects:  26%|██▋       | 70/266 [00:23<00:57,  3.39it/s]predicting train subjects:  27%|██▋       | 71/266 [00:23<00:56,  3.46it/s]predicting train subjects:  27%|██▋       | 72/266 [00:23<00:55,  3.52it/s]predicting train subjects:  27%|██▋       | 73/266 [00:23<00:54,  3.53it/s]predicting train subjects:  28%|██▊       | 74/266 [00:24<00:55,  3.45it/s]predicting train subjects:  28%|██▊       | 75/266 [00:24<00:54,  3.53it/s]predicting train subjects:  29%|██▊       | 76/266 [00:24<00:54,  3.49it/s]predicting train subjects:  29%|██▉       | 77/266 [00:25<00:53,  3.54it/s]predicting train subjects:  29%|██▉       | 78/266 [00:25<01:01,  3.07it/s]predicting train subjects:  30%|██▉       | 79/266 [00:25<01:03,  2.92it/s]predicting train subjects:  30%|███       | 80/266 [00:26<01:04,  2.87it/s]predicting train subjects:  30%|███       | 81/266 [00:26<01:08,  2.69it/s]predicting train subjects:  31%|███       | 82/266 [00:27<01:09,  2.65it/s]predicting train subjects:  31%|███       | 83/266 [00:27<01:07,  2.73it/s]predicting train subjects:  32%|███▏      | 84/266 [00:27<01:06,  2.74it/s]predicting train subjects:  32%|███▏      | 85/266 [00:28<01:05,  2.75it/s]predicting train subjects:  32%|███▏      | 86/266 [00:28<01:06,  2.70it/s]predicting train subjects:  33%|███▎      | 87/266 [00:28<01:04,  2.78it/s]predicting train subjects:  33%|███▎      | 88/266 [00:29<01:04,  2.77it/s]predicting train subjects:  33%|███▎      | 89/266 [00:29<01:02,  2.83it/s]predicting train subjects:  34%|███▍      | 90/266 [00:29<01:02,  2.81it/s]predicting train subjects:  34%|███▍      | 91/266 [00:30<01:01,  2.84it/s]predicting train subjects:  35%|███▍      | 92/266 [00:30<01:03,  2.75it/s]predicting train subjects:  35%|███▍      | 93/266 [00:30<01:01,  2.81it/s]predicting train subjects:  35%|███▌      | 94/266 [00:31<01:01,  2.81it/s]predicting train subjects:  36%|███▌      | 95/266 [00:31<01:00,  2.81it/s]predicting train subjects:  36%|███▌      | 96/266 [00:32<01:00,  2.82it/s]predicting train subjects:  36%|███▋      | 97/266 [00:32<01:03,  2.68it/s]predicting train subjects:  37%|███▋      | 98/266 [00:32<01:05,  2.58it/s]predicting train subjects:  37%|███▋      | 99/266 [00:33<00:59,  2.80it/s]predicting train subjects:  38%|███▊      | 100/266 [00:33<00:59,  2.80it/s]predicting train subjects:  38%|███▊      | 101/266 [00:33<00:59,  2.77it/s]predicting train subjects:  38%|███▊      | 102/266 [00:34<00:58,  2.81it/s]predicting train subjects:  39%|███▊      | 103/266 [00:34<00:55,  2.92it/s]predicting train subjects:  39%|███▉      | 104/266 [00:34<00:53,  3.00it/s]predicting train subjects:  39%|███▉      | 105/266 [00:35<00:52,  3.05it/s]predicting train subjects:  40%|███▉      | 106/266 [00:35<00:54,  2.96it/s]predicting train subjects:  40%|████      | 107/266 [00:35<00:53,  3.00it/s]predicting train subjects:  41%|████      | 108/266 [00:36<00:53,  2.97it/s]predicting train subjects:  41%|████      | 109/266 [00:36<00:53,  2.93it/s]predicting train subjects:  41%|████▏     | 110/266 [00:36<00:53,  2.94it/s]predicting train subjects:  42%|████▏     | 111/266 [00:37<00:51,  3.00it/s]predicting train subjects:  42%|████▏     | 112/266 [00:37<00:50,  3.05it/s]predicting train subjects:  42%|████▏     | 113/266 [00:37<00:50,  3.04it/s]predicting train subjects:  43%|████▎     | 114/266 [00:38<00:50,  3.03it/s]predicting train subjects:  43%|████▎     | 115/266 [00:38<00:49,  3.02it/s]predicting train subjects:  44%|████▎     | 116/266 [00:38<00:48,  3.11it/s]predicting train subjects:  44%|████▍     | 117/266 [00:39<00:49,  3.03it/s]predicting train subjects:  44%|████▍     | 118/266 [00:39<00:48,  3.04it/s]predicting train subjects:  45%|████▍     | 119/266 [00:39<00:49,  2.96it/s]predicting train subjects:  45%|████▌     | 120/266 [00:40<00:50,  2.89it/s]predicting train subjects:  45%|████▌     | 121/266 [00:40<00:50,  2.87it/s]predicting train subjects:  46%|████▌     | 122/266 [00:40<00:50,  2.84it/s]predicting train subjects:  46%|████▌     | 123/266 [00:41<00:49,  2.89it/s]predicting train subjects:  47%|████▋     | 124/266 [00:41<00:50,  2.79it/s]predicting train subjects:  47%|████▋     | 125/266 [00:41<00:50,  2.79it/s]predicting train subjects:  47%|████▋     | 126/266 [00:42<00:49,  2.83it/s]predicting train subjects:  48%|████▊     | 127/266 [00:42<00:48,  2.84it/s]predicting train subjects:  48%|████▊     | 128/266 [00:43<00:48,  2.87it/s]predicting train subjects:  48%|████▊     | 129/266 [00:43<00:48,  2.82it/s]predicting train subjects:  49%|████▉     | 130/266 [00:43<00:49,  2.74it/s]predicting train subjects:  49%|████▉     | 131/266 [00:44<00:49,  2.72it/s]predicting train subjects:  50%|████▉     | 132/266 [00:44<00:49,  2.72it/s]predicting train subjects:  50%|█████     | 133/266 [00:44<00:48,  2.76it/s]predicting train subjects:  50%|█████     | 134/266 [00:45<00:47,  2.76it/s]predicting train subjects:  51%|█████     | 135/266 [00:45<00:48,  2.70it/s]predicting train subjects:  51%|█████     | 136/266 [00:45<00:47,  2.74it/s]predicting train subjects:  52%|█████▏    | 137/266 [00:46<00:47,  2.73it/s]predicting train subjects:  52%|█████▏    | 138/266 [00:46<00:46,  2.75it/s]predicting train subjects:  52%|█████▏    | 139/266 [00:47<00:45,  2.80it/s]predicting train subjects:  53%|█████▎    | 140/266 [00:47<00:45,  2.78it/s]predicting train subjects:  53%|█████▎    | 141/266 [00:47<00:44,  2.78it/s]predicting train subjects:  53%|█████▎    | 142/266 [00:48<00:42,  2.88it/s]predicting train subjects:  54%|█████▍    | 143/266 [00:48<00:41,  2.97it/s]predicting train subjects:  54%|█████▍    | 144/266 [00:48<00:41,  2.94it/s]predicting train subjects:  55%|█████▍    | 145/266 [00:49<00:41,  2.93it/s]predicting train subjects:  55%|█████▍    | 146/266 [00:49<00:41,  2.93it/s]predicting train subjects:  55%|█████▌    | 147/266 [00:49<00:40,  2.93it/s]predicting train subjects:  56%|█████▌    | 148/266 [00:50<00:40,  2.89it/s]predicting train subjects:  56%|█████▌    | 149/266 [00:50<00:40,  2.91it/s]predicting train subjects:  56%|█████▋    | 150/266 [00:50<00:39,  2.95it/s]predicting train subjects:  57%|█████▋    | 151/266 [00:51<00:39,  2.92it/s]predicting train subjects:  57%|█████▋    | 152/266 [00:51<00:38,  3.00it/s]predicting train subjects:  58%|█████▊    | 153/266 [00:51<00:37,  3.02it/s]predicting train subjects:  58%|█████▊    | 154/266 [00:52<00:36,  3.04it/s]predicting train subjects:  58%|█████▊    | 155/266 [00:52<00:34,  3.20it/s]predicting train subjects:  59%|█████▊    | 156/266 [00:52<00:32,  3.43it/s]predicting train subjects:  59%|█████▉    | 157/266 [00:52<00:31,  3.44it/s]predicting train subjects:  59%|█████▉    | 158/266 [00:53<00:30,  3.54it/s]predicting train subjects:  60%|█████▉    | 159/266 [00:53<00:29,  3.63it/s]predicting train subjects:  60%|██████    | 160/266 [00:53<00:28,  3.75it/s]predicting train subjects:  61%|██████    | 161/266 [00:53<00:27,  3.81it/s]predicting train subjects:  61%|██████    | 162/266 [00:54<00:27,  3.78it/s]predicting train subjects:  61%|██████▏   | 163/266 [00:54<00:28,  3.65it/s]predicting train subjects:  62%|██████▏   | 164/266 [00:54<00:29,  3.50it/s]predicting train subjects:  62%|██████▏   | 165/266 [00:55<00:29,  3.41it/s]predicting train subjects:  62%|██████▏   | 166/266 [00:55<00:29,  3.35it/s]predicting train subjects:  63%|██████▎   | 167/266 [00:55<00:28,  3.50it/s]predicting train subjects:  63%|██████▎   | 168/266 [00:55<00:28,  3.45it/s]predicting train subjects:  64%|██████▎   | 169/266 [00:56<00:27,  3.59it/s]predicting train subjects:  64%|██████▍   | 170/266 [00:56<00:26,  3.67it/s]predicting train subjects:  64%|██████▍   | 171/266 [00:56<00:25,  3.72it/s]predicting train subjects:  65%|██████▍   | 172/266 [00:57<00:25,  3.68it/s]predicting train subjects:  65%|██████▌   | 173/266 [00:57<00:26,  3.49it/s]predicting train subjects:  65%|██████▌   | 174/266 [00:57<00:26,  3.51it/s]predicting train subjects:  66%|██████▌   | 175/266 [00:57<00:26,  3.46it/s]predicting train subjects:  66%|██████▌   | 176/266 [00:58<00:25,  3.50it/s]predicting train subjects:  67%|██████▋   | 177/266 [00:58<00:25,  3.45it/s]predicting train subjects:  67%|██████▋   | 178/266 [00:58<00:25,  3.45it/s]predicting train subjects:  67%|██████▋   | 179/266 [00:59<00:25,  3.43it/s]predicting train subjects:  68%|██████▊   | 180/266 [00:59<00:24,  3.45it/s]predicting train subjects:  68%|██████▊   | 181/266 [00:59<00:24,  3.48it/s]predicting train subjects:  68%|██████▊   | 182/266 [00:59<00:24,  3.48it/s]predicting train subjects:  69%|██████▉   | 183/266 [01:00<00:24,  3.43it/s]predicting train subjects:  69%|██████▉   | 184/266 [01:00<00:24,  3.39it/s]predicting train subjects:  70%|██████▉   | 185/266 [01:00<00:24,  3.34it/s]predicting train subjects:  70%|██████▉   | 186/266 [01:01<00:23,  3.40it/s]predicting train subjects:  70%|███████   | 187/266 [01:01<00:22,  3.45it/s]predicting train subjects:  71%|███████   | 188/266 [01:01<00:22,  3.50it/s]predicting train subjects:  71%|███████   | 189/266 [01:01<00:21,  3.52it/s]predicting train subjects:  71%|███████▏  | 190/266 [01:02<00:21,  3.49it/s]predicting train subjects:  72%|███████▏  | 191/266 [01:02<00:22,  3.33it/s]predicting train subjects:  72%|███████▏  | 192/266 [01:02<00:22,  3.23it/s]predicting train subjects:  73%|███████▎  | 193/266 [01:03<00:22,  3.28it/s]predicting train subjects:  73%|███████▎  | 194/266 [01:03<00:25,  2.83it/s]predicting train subjects:  73%|███████▎  | 195/266 [01:04<00:24,  2.84it/s]predicting train subjects:  74%|███████▎  | 196/266 [01:04<00:23,  3.00it/s]predicting train subjects:  74%|███████▍  | 197/266 [01:04<00:21,  3.16it/s]predicting train subjects:  74%|███████▍  | 198/266 [01:04<00:21,  3.16it/s]predicting train subjects:  75%|███████▍  | 199/266 [01:05<00:20,  3.27it/s]predicting train subjects:  75%|███████▌  | 200/266 [01:05<00:19,  3.30it/s]predicting train subjects:  76%|███████▌  | 201/266 [01:05<00:19,  3.36it/s]predicting train subjects:  76%|███████▌  | 202/266 [01:06<00:18,  3.41it/s]predicting train subjects:  76%|███████▋  | 203/266 [01:06<00:18,  3.43it/s]predicting train subjects:  77%|███████▋  | 204/266 [01:06<00:17,  3.45it/s]predicting train subjects:  77%|███████▋  | 205/266 [01:06<00:17,  3.47it/s]predicting train subjects:  77%|███████▋  | 206/266 [01:07<00:17,  3.52it/s]predicting train subjects:  78%|███████▊  | 207/266 [01:07<00:17,  3.39it/s]predicting train subjects:  78%|███████▊  | 208/266 [01:07<00:17,  3.25it/s]predicting train subjects:  79%|███████▊  | 209/266 [01:08<00:18,  3.12it/s]predicting train subjects:  79%|███████▉  | 210/266 [01:08<00:18,  3.10it/s]predicting train subjects:  79%|███████▉  | 211/266 [01:08<00:17,  3.17it/s]predicting train subjects:  80%|███████▉  | 212/266 [01:09<00:16,  3.26it/s]predicting train subjects:  80%|████████  | 213/266 [01:09<00:15,  3.35it/s]predicting train subjects:  80%|████████  | 214/266 [01:09<00:14,  3.49it/s]predicting train subjects:  81%|████████  | 215/266 [01:09<00:14,  3.48it/s]predicting train subjects:  81%|████████  | 216/266 [01:10<00:13,  3.60it/s]predicting train subjects:  82%|████████▏ | 217/266 [01:10<00:13,  3.70it/s]predicting train subjects:  82%|████████▏ | 218/266 [01:10<00:12,  3.78it/s]predicting train subjects:  82%|████████▏ | 219/266 [01:10<00:12,  3.82it/s]predicting train subjects:  83%|████████▎ | 220/266 [01:11<00:12,  3.82it/s]predicting train subjects:  83%|████████▎ | 221/266 [01:11<00:11,  3.84it/s]predicting train subjects:  83%|████████▎ | 222/266 [01:11<00:11,  3.72it/s]predicting train subjects:  84%|████████▍ | 223/266 [01:12<00:11,  3.80it/s]predicting train subjects:  84%|████████▍ | 224/266 [01:12<00:11,  3.69it/s]predicting train subjects:  85%|████████▍ | 225/266 [01:12<00:10,  3.75it/s]predicting train subjects:  85%|████████▍ | 226/266 [01:12<00:10,  3.75it/s]predicting train subjects:  85%|████████▌ | 227/266 [01:13<00:10,  3.63it/s]predicting train subjects:  86%|████████▌ | 228/266 [01:13<00:10,  3.68it/s]predicting train subjects:  86%|████████▌ | 229/266 [01:13<00:10,  3.66it/s]predicting train subjects:  86%|████████▋ | 230/266 [01:13<00:10,  3.60it/s]predicting train subjects:  87%|████████▋ | 231/266 [01:14<00:09,  3.57it/s]predicting train subjects:  87%|████████▋ | 232/266 [01:14<00:09,  3.62it/s]predicting train subjects:  88%|████████▊ | 233/266 [01:14<00:09,  3.65it/s]predicting train subjects:  88%|████████▊ | 234/266 [01:15<00:09,  3.54it/s]predicting train subjects:  88%|████████▊ | 235/266 [01:15<00:09,  3.41it/s]predicting train subjects:  89%|████████▊ | 236/266 [01:15<00:08,  3.53it/s]predicting train subjects:  89%|████████▉ | 237/266 [01:15<00:08,  3.62it/s]predicting train subjects:  89%|████████▉ | 238/266 [01:16<00:07,  3.67it/s]predicting train subjects:  90%|████████▉ | 239/266 [01:16<00:07,  3.70it/s]predicting train subjects:  90%|█████████ | 240/266 [01:16<00:06,  3.73it/s]predicting train subjects:  91%|█████████ | 241/266 [01:17<00:06,  3.59it/s]predicting train subjects:  91%|█████████ | 242/266 [01:17<00:06,  3.58it/s]predicting train subjects:  91%|█████████▏| 243/266 [01:17<00:06,  3.39it/s]predicting train subjects:  92%|█████████▏| 244/266 [01:17<00:06,  3.48it/s]predicting train subjects:  92%|█████████▏| 245/266 [01:18<00:05,  3.57it/s]predicting train subjects:  92%|█████████▏| 246/266 [01:18<00:05,  3.65it/s]predicting train subjects:  93%|█████████▎| 247/266 [01:18<00:05,  3.68it/s]predicting train subjects:  93%|█████████▎| 248/266 [01:18<00:04,  3.68it/s]predicting train subjects:  94%|█████████▎| 249/266 [01:19<00:05,  3.21it/s]predicting train subjects:  94%|█████████▍| 250/266 [01:19<00:05,  3.10it/s]predicting train subjects:  94%|█████████▍| 251/266 [01:20<00:04,  3.08it/s]predicting train subjects:  95%|█████████▍| 252/266 [01:20<00:04,  3.07it/s]predicting train subjects:  95%|█████████▌| 253/266 [01:20<00:04,  2.93it/s]predicting train subjects:  95%|█████████▌| 254/266 [01:21<00:04,  2.89it/s]predicting train subjects:  96%|█████████▌| 255/266 [01:21<00:03,  2.85it/s]predicting train subjects:  96%|█████████▌| 256/266 [01:21<00:03,  2.80it/s]predicting train subjects:  97%|█████████▋| 257/266 [01:22<00:03,  2.84it/s]predicting train subjects:  97%|█████████▋| 258/266 [01:22<00:02,  2.81it/s]predicting train subjects:  97%|█████████▋| 259/266 [01:22<00:02,  2.79it/s]predicting train subjects:  98%|█████████▊| 260/266 [01:23<00:02,  2.82it/s]predicting train subjects:  98%|█████████▊| 261/266 [01:23<00:01,  2.84it/s]predicting train subjects:  98%|█████████▊| 262/266 [01:23<00:01,  2.87it/s]predicting train subjects:  99%|█████████▉| 263/266 [01:24<00:01,  2.90it/s]predicting train subjects:  99%|█████████▉| 264/266 [01:24<00:00,  2.86it/s]predicting train subjects: 100%|█████████▉| 265/266 [01:25<00:00,  2.84it/s]predicting train subjects: 100%|██████████| 266/266 [01:25<00:00,  2.86it/s]
saving BB  test1-THALAMUS:   0%|          | 0/5 [00:00<?, ?it/s]saving BB  test1-THALAMUS: 100%|██████████| 5/5 [00:00<00:00, 61.09it/s]
saving BB  train1-THALAMUS:   0%|          | 0/266 [00:00<?, ?it/s]saving BB  train1-THALAMUS:   2%|▏         | 6/266 [00:00<00:04, 53.37it/s]saving BB  train1-THALAMUS:   5%|▍         | 13/266 [00:00<00:04, 56.54it/s]saving BB  train1-THALAMUS:   8%|▊         | 20/266 [00:00<00:04, 59.02it/s]saving BB  train1-THALAMUS:  11%|█         | 28/266 [00:00<00:03, 62.24it/s]saving BB  train1-THALAMUS:  14%|█▎        | 36/266 [00:00<00:03, 65.06it/s]saving BB  train1-THALAMUS:  16%|█▌        | 43/266 [00:00<00:03, 64.89it/s]saving BB  train1-THALAMUS:  19%|█▉        | 51/266 [00:00<00:03, 68.58it/s]saving BB  train1-THALAMUS:  23%|██▎       | 60/266 [00:00<00:02, 72.16it/s]saving BB  train1-THALAMUS:  26%|██▌       | 69/266 [00:00<00:02, 76.03it/s]saving BB  train1-THALAMUS:  29%|██▉       | 78/266 [00:01<00:02, 78.88it/s]saving BB  train1-THALAMUS:  32%|███▏      | 86/266 [00:01<00:02, 77.72it/s]saving BB  train1-THALAMUS:  35%|███▌      | 94/266 [00:01<00:02, 76.98it/s]saving BB  train1-THALAMUS:  38%|███▊      | 102/266 [00:01<00:02, 68.93it/s]saving BB  train1-THALAMUS:  41%|████▏     | 110/266 [00:01<00:02, 71.61it/s]saving BB  train1-THALAMUS:  44%|████▍     | 118/266 [00:01<00:02, 73.31it/s]saving BB  train1-THALAMUS:  47%|████▋     | 126/266 [00:01<00:01, 72.99it/s]saving BB  train1-THALAMUS:  50%|█████     | 134/266 [00:01<00:01, 72.61it/s]saving BB  train1-THALAMUS:  53%|█████▎    | 142/266 [00:01<00:01, 70.58it/s]saving BB  train1-THALAMUS:  56%|█████▋    | 150/266 [00:02<00:01, 70.45it/s]saving BB  train1-THALAMUS:  59%|█████▉    | 158/266 [00:02<00:01, 72.49it/s]saving BB  train1-THALAMUS:  63%|██████▎   | 167/266 [00:02<00:01, 76.60it/s]saving BB  train1-THALAMUS:  66%|██████▌   | 176/266 [00:02<00:01, 78.87it/s]saving BB  train1-THALAMUS:  70%|██████▉   | 185/266 [00:02<00:01, 80.87it/s]saving BB  train1-THALAMUS:  73%|███████▎  | 194/266 [00:02<00:00, 79.40it/s]saving BB  train1-THALAMUS:  76%|███████▌  | 202/266 [00:02<00:00, 78.42it/s]saving BB  train1-THALAMUS:  79%|███████▉  | 210/266 [00:02<00:00, 78.03it/s]saving BB  train1-THALAMUS:  82%|████████▏ | 219/266 [00:02<00:00, 78.29it/s]saving BB  train1-THALAMUS:  85%|████████▌ | 227/266 [00:03<00:00, 78.65it/s]saving BB  train1-THALAMUS:  89%|████████▊ | 236/266 [00:03<00:00, 79.99it/s]saving BB  train1-THALAMUS:  92%|█████████▏| 245/266 [00:03<00:00, 81.06it/s]saving BB  train1-THALAMUS:  95%|█████████▌| 254/266 [00:03<00:00, 79.54it/s]saving BB  train1-THALAMUS:  98%|█████████▊| 262/266 [00:03<00:00, 77.74it/s]saving BB  train1-THALAMUS: 100%|██████████| 266/266 [00:03<00:00, 75.02it/s]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:01<08:15,  1.87s/it]Loading train:   1%|          | 2/266 [00:03<08:12,  1.86s/it]Loading train:   1%|          | 3/266 [00:05<07:33,  1.73s/it]Loading train:   2%|▏         | 4/266 [00:06<06:57,  1.59s/it]Loading train:   2%|▏         | 5/266 [00:07<06:47,  1.56s/it]Loading train:   2%|▏         | 6/266 [00:09<06:35,  1.52s/it]Loading train:   3%|▎         | 7/266 [00:10<05:59,  1.39s/it]Loading train:   3%|▎         | 8/266 [00:11<05:34,  1.30s/it]Loading train:   3%|▎         | 9/266 [00:12<05:13,  1.22s/it]Loading train:   4%|▍         | 10/266 [00:13<04:57,  1.16s/it]Loading train:   4%|▍         | 11/266 [00:14<04:52,  1.15s/it]Loading train:   5%|▍         | 12/266 [00:15<04:42,  1.11s/it]Loading train:   5%|▍         | 13/266 [00:16<04:32,  1.08s/it]Loading train:   5%|▌         | 14/266 [00:17<04:27,  1.06s/it]Loading train:   6%|▌         | 15/266 [00:18<04:32,  1.09s/it]Loading train:   6%|▌         | 16/266 [00:19<04:30,  1.08s/it]Loading train:   6%|▋         | 17/266 [00:20<04:23,  1.06s/it]Loading train:   7%|▋         | 18/266 [00:22<04:26,  1.08s/it]Loading train:   7%|▋         | 19/266 [00:23<04:27,  1.08s/it]Loading train:   8%|▊         | 20/266 [00:24<04:26,  1.08s/it]Loading train:   8%|▊         | 21/266 [00:25<04:25,  1.08s/it]Loading train:   8%|▊         | 22/266 [00:26<04:18,  1.06s/it]Loading train:   9%|▊         | 23/266 [00:27<04:16,  1.06s/it]Loading train:   9%|▉         | 24/266 [00:28<04:07,  1.02s/it]Loading train:   9%|▉         | 25/266 [00:29<03:55,  1.02it/s]Loading train:  10%|▉         | 26/266 [00:30<03:48,  1.05it/s]Loading train:  10%|█         | 27/266 [00:31<03:47,  1.05it/s]Loading train:  11%|█         | 28/266 [00:31<03:42,  1.07it/s]Loading train:  11%|█         | 29/266 [00:32<03:42,  1.07it/s]Loading train:  11%|█▏        | 30/266 [00:33<03:40,  1.07it/s]Loading train:  12%|█▏        | 31/266 [00:34<03:42,  1.06it/s]Loading train:  12%|█▏        | 32/266 [00:35<03:39,  1.07it/s]Loading train:  12%|█▏        | 33/266 [00:36<03:34,  1.09it/s]Loading train:  13%|█▎        | 34/266 [00:37<03:33,  1.09it/s]Loading train:  13%|█▎        | 35/266 [00:38<03:34,  1.08it/s]Loading train:  14%|█▎        | 36/266 [00:39<03:36,  1.06it/s]Loading train:  14%|█▍        | 37/266 [00:40<03:36,  1.06it/s]Loading train:  14%|█▍        | 38/266 [00:41<03:37,  1.05it/s]Loading train:  15%|█▍        | 39/266 [00:42<03:35,  1.06it/s]Loading train:  15%|█▌        | 40/266 [00:43<03:34,  1.05it/s]Loading train:  15%|█▌        | 41/266 [00:44<03:29,  1.08it/s]Loading train:  16%|█▌        | 42/266 [00:45<03:35,  1.04it/s]Loading train:  16%|█▌        | 43/266 [00:45<03:25,  1.09it/s]Loading train:  17%|█▋        | 44/266 [00:46<03:20,  1.10it/s]Loading train:  17%|█▋        | 45/266 [00:47<03:15,  1.13it/s]Loading train:  17%|█▋        | 46/266 [00:48<03:08,  1.16it/s]Loading train:  18%|█▊        | 47/266 [00:49<03:06,  1.18it/s]Loading train:  18%|█▊        | 48/266 [00:50<03:01,  1.20it/s]Loading train:  18%|█▊        | 49/266 [00:50<02:57,  1.22it/s]Loading train:  19%|█▉        | 50/266 [00:51<02:58,  1.21it/s]Loading train:  19%|█▉        | 51/266 [00:52<02:58,  1.20it/s]Loading train:  20%|█▉        | 52/266 [00:53<03:00,  1.18it/s]Loading train:  20%|█▉        | 53/266 [00:54<02:57,  1.20it/s]Loading train:  20%|██        | 54/266 [00:55<02:56,  1.20it/s]Loading train:  21%|██        | 55/266 [00:55<02:52,  1.22it/s]Loading train:  21%|██        | 56/266 [00:56<02:50,  1.23it/s]Loading train:  21%|██▏       | 57/266 [00:57<02:49,  1.23it/s]Loading train:  22%|██▏       | 58/266 [00:58<02:48,  1.24it/s]Loading train:  22%|██▏       | 59/266 [00:59<02:49,  1.22it/s]Loading train:  23%|██▎       | 60/266 [01:00<03:00,  1.14it/s]Loading train:  23%|██▎       | 61/266 [01:00<02:53,  1.18it/s]Loading train:  23%|██▎       | 62/266 [01:01<02:46,  1.22it/s]Loading train:  24%|██▎       | 63/266 [01:02<02:41,  1.26it/s]Loading train:  24%|██▍       | 64/266 [01:03<02:41,  1.25it/s]Loading train:  24%|██▍       | 65/266 [01:03<02:39,  1.26it/s]Loading train:  25%|██▍       | 66/266 [01:04<02:33,  1.30it/s]Loading train:  25%|██▌       | 67/266 [01:05<02:32,  1.31it/s]Loading train:  26%|██▌       | 68/266 [01:06<02:33,  1.29it/s]Loading train:  26%|██▌       | 69/266 [01:07<02:34,  1.28it/s]Loading train:  26%|██▋       | 70/266 [01:07<02:32,  1.28it/s]Loading train:  27%|██▋       | 71/266 [01:08<02:30,  1.30it/s]Loading train:  27%|██▋       | 72/266 [01:09<02:30,  1.29it/s]Loading train:  27%|██▋       | 73/266 [01:10<02:29,  1.29it/s]Loading train:  28%|██▊       | 74/266 [01:10<02:25,  1.32it/s]Loading train:  28%|██▊       | 75/266 [01:11<02:26,  1.30it/s]Loading train:  29%|██▊       | 76/266 [01:12<02:28,  1.28it/s]Loading train:  29%|██▉       | 77/266 [01:13<02:23,  1.32it/s]Loading train:  29%|██▉       | 78/266 [01:14<02:46,  1.13it/s]Loading train:  30%|██▉       | 79/266 [01:15<02:47,  1.12it/s]Loading train:  30%|███       | 80/266 [01:16<02:50,  1.09it/s]Loading train:  30%|███       | 81/266 [01:17<02:54,  1.06it/s]Loading train:  31%|███       | 82/266 [01:18<02:51,  1.07it/s]Loading train:  31%|███       | 83/266 [01:19<02:53,  1.06it/s]Loading train:  32%|███▏      | 84/266 [01:20<02:51,  1.06it/s]Loading train:  32%|███▏      | 85/266 [01:21<02:51,  1.06it/s]Loading train:  32%|███▏      | 86/266 [01:21<02:51,  1.05it/s]Loading train:  33%|███▎      | 87/266 [01:22<02:50,  1.05it/s]Loading train:  33%|███▎      | 88/266 [01:23<02:48,  1.06it/s]Loading train:  33%|███▎      | 89/266 [01:24<02:46,  1.06it/s]Loading train:  34%|███▍      | 90/266 [01:25<02:44,  1.07it/s]Loading train:  34%|███▍      | 91/266 [01:26<02:50,  1.03it/s]Loading train:  35%|███▍      | 92/266 [01:27<02:51,  1.02it/s]Loading train:  35%|███▍      | 93/266 [01:28<02:48,  1.02it/s]Loading train:  35%|███▌      | 94/266 [01:29<02:45,  1.04it/s]Loading train:  36%|███▌      | 95/266 [01:30<02:45,  1.03it/s]Loading train:  36%|███▌      | 96/266 [01:32<03:13,  1.14s/it]Loading train:  36%|███▋      | 97/266 [01:33<03:33,  1.26s/it]Loading train:  37%|███▋      | 98/266 [01:35<03:42,  1.32s/it]Loading train:  37%|███▋      | 99/266 [01:36<03:34,  1.28s/it]Loading train:  38%|███▊      | 100/266 [01:37<03:31,  1.27s/it]Loading train:  38%|███▊      | 101/266 [01:38<03:12,  1.17s/it]Loading train:  38%|███▊      | 102/266 [01:39<02:57,  1.08s/it]Loading train:  39%|███▊      | 103/266 [01:40<02:49,  1.04s/it]Loading train:  39%|███▉      | 104/266 [01:41<02:40,  1.01it/s]Loading train:  39%|███▉      | 105/266 [01:42<02:34,  1.04it/s]Loading train:  40%|███▉      | 106/266 [01:43<02:35,  1.03it/s]Loading train:  40%|████      | 107/266 [01:44<02:29,  1.07it/s]Loading train:  41%|████      | 108/266 [01:44<02:24,  1.09it/s]Loading train:  41%|████      | 109/266 [01:45<02:26,  1.07it/s]Loading train:  41%|████▏     | 110/266 [01:46<02:22,  1.09it/s]Loading train:  42%|████▏     | 111/266 [01:47<02:18,  1.12it/s]Loading train:  42%|████▏     | 112/266 [01:48<02:17,  1.12it/s]Loading train:  42%|████▏     | 113/266 [01:49<02:14,  1.14it/s]Loading train:  43%|████▎     | 114/266 [01:50<02:11,  1.16it/s]Loading train:  43%|████▎     | 115/266 [01:50<02:09,  1.17it/s]Loading train:  44%|████▎     | 116/266 [01:51<02:06,  1.18it/s]Loading train:  44%|████▍     | 117/266 [01:52<02:05,  1.18it/s]Loading train:  44%|████▍     | 118/266 [01:53<02:03,  1.20it/s]Loading train:  45%|████▍     | 119/266 [01:54<02:17,  1.07it/s]Loading train:  45%|████▌     | 120/266 [01:55<02:18,  1.05it/s]Loading train:  45%|████▌     | 121/266 [01:56<02:16,  1.06it/s]Loading train:  46%|████▌     | 122/266 [01:57<02:14,  1.07it/s]Loading train:  46%|████▌     | 123/266 [01:58<02:14,  1.07it/s]Loading train:  47%|████▋     | 124/266 [01:59<02:13,  1.06it/s]Loading train:  47%|████▋     | 125/266 [02:00<02:18,  1.02it/s]Loading train:  47%|████▋     | 126/266 [02:01<02:19,  1.00it/s]Loading train:  48%|████▊     | 127/266 [02:02<02:14,  1.03it/s]Loading train:  48%|████▊     | 128/266 [02:03<02:11,  1.05it/s]Loading train:  48%|████▊     | 129/266 [02:04<02:07,  1.07it/s]Loading train:  49%|████▉     | 130/266 [02:05<02:06,  1.08it/s]Loading train:  49%|████▉     | 131/266 [02:06<02:06,  1.07it/s]Loading train:  50%|████▉     | 132/266 [02:07<02:07,  1.05it/s]Loading train:  50%|█████     | 133/266 [02:08<02:08,  1.03it/s]Loading train:  50%|█████     | 134/266 [02:08<02:07,  1.03it/s]Loading train:  51%|█████     | 135/266 [02:10<02:08,  1.02it/s]Loading train:  51%|█████     | 136/266 [02:10<02:07,  1.02it/s]Loading train:  52%|█████▏    | 137/266 [02:12<02:18,  1.07s/it]Loading train:  52%|█████▏    | 138/266 [02:13<02:11,  1.03s/it]Loading train:  52%|█████▏    | 139/266 [02:14<02:06,  1.00it/s]Loading train:  53%|█████▎    | 140/266 [02:15<02:04,  1.01it/s]Loading train:  53%|█████▎    | 141/266 [02:16<02:03,  1.01it/s]Loading train:  53%|█████▎    | 142/266 [02:17<02:01,  1.02it/s]Loading train:  54%|█████▍    | 143/266 [02:17<01:58,  1.03it/s]Loading train:  54%|█████▍    | 144/266 [02:18<01:56,  1.05it/s]Loading train:  55%|█████▍    | 145/266 [02:19<01:54,  1.05it/s]Loading train:  55%|█████▍    | 146/266 [02:20<01:55,  1.04it/s]Loading train:  55%|█████▌    | 147/266 [02:21<01:53,  1.05it/s]Loading train:  56%|█████▌    | 148/266 [02:22<01:51,  1.06it/s]Loading train:  56%|█████▌    | 149/266 [02:23<01:53,  1.03it/s]Loading train:  56%|█████▋    | 150/266 [02:24<01:49,  1.06it/s]Loading train:  57%|█████▋    | 151/266 [02:25<01:48,  1.06it/s]Loading train:  57%|█████▋    | 152/266 [02:26<01:45,  1.08it/s]Loading train:  58%|█████▊    | 153/266 [02:27<01:43,  1.09it/s]Loading train:  58%|█████▊    | 154/266 [02:28<01:41,  1.10it/s]Loading train:  58%|█████▊    | 155/266 [02:29<01:38,  1.13it/s]Loading train:  59%|█████▊    | 156/266 [02:29<01:33,  1.17it/s]Loading train:  59%|█████▉    | 157/266 [02:30<01:30,  1.20it/s]Loading train:  59%|█████▉    | 158/266 [02:31<01:28,  1.23it/s]Loading train:  60%|█████▉    | 159/266 [02:32<01:24,  1.27it/s]Loading train:  60%|██████    | 160/266 [02:32<01:22,  1.28it/s]Loading train:  61%|██████    | 161/266 [02:33<01:20,  1.31it/s]Loading train:  61%|██████    | 162/266 [02:34<01:18,  1.32it/s]Loading train:  61%|██████▏   | 163/266 [02:35<01:17,  1.33it/s]Loading train:  62%|██████▏   | 164/266 [02:35<01:16,  1.34it/s]Loading train:  62%|██████▏   | 165/266 [02:36<01:15,  1.35it/s]Loading train:  62%|██████▏   | 166/266 [02:37<01:14,  1.34it/s]Loading train:  63%|██████▎   | 167/266 [02:38<01:14,  1.33it/s]Loading train:  63%|██████▎   | 168/266 [02:38<01:14,  1.32it/s]Loading train:  64%|██████▎   | 169/266 [02:39<01:13,  1.33it/s]Loading train:  64%|██████▍   | 170/266 [02:40<01:15,  1.27it/s]Loading train:  64%|██████▍   | 171/266 [02:41<01:13,  1.29it/s]Loading train:  65%|██████▍   | 172/266 [02:42<01:16,  1.23it/s]Loading train:  65%|██████▌   | 173/266 [02:43<01:19,  1.17it/s]Loading train:  65%|██████▌   | 174/266 [02:43<01:17,  1.19it/s]Loading train:  66%|██████▌   | 175/266 [02:44<01:14,  1.22it/s]Loading train:  66%|██████▌   | 176/266 [02:45<01:13,  1.23it/s]Loading train:  67%|██████▋   | 177/266 [02:46<01:10,  1.25it/s]Loading train:  67%|██████▋   | 178/266 [02:46<01:08,  1.28it/s]Loading train:  67%|██████▋   | 179/266 [02:47<01:07,  1.30it/s]Loading train:  68%|██████▊   | 180/266 [02:48<01:05,  1.32it/s]Loading train:  68%|██████▊   | 181/266 [02:49<01:03,  1.33it/s]Loading train:  68%|██████▊   | 182/266 [02:49<01:03,  1.32it/s]Loading train:  69%|██████▉   | 183/266 [02:50<01:02,  1.33it/s]Loading train:  69%|██████▉   | 184/266 [02:51<01:03,  1.30it/s]Loading train:  70%|██████▉   | 185/266 [02:52<01:02,  1.30it/s]Loading train:  70%|██████▉   | 186/266 [02:53<01:01,  1.29it/s]Loading train:  70%|███████   | 187/266 [02:53<01:02,  1.26it/s]Loading train:  71%|███████   | 188/266 [02:54<01:01,  1.27it/s]Loading train:  71%|███████   | 189/266 [02:55<00:59,  1.29it/s]Loading train:  71%|███████▏  | 190/266 [02:56<00:58,  1.30it/s]Loading train:  72%|███████▏  | 191/266 [02:57<01:12,  1.04it/s]Loading train:  72%|███████▏  | 192/266 [02:58<01:17,  1.05s/it]Loading train:  73%|███████▎  | 193/266 [03:00<01:22,  1.13s/it]Loading train:  73%|███████▎  | 194/266 [03:01<01:31,  1.27s/it]Loading train:  73%|███████▎  | 195/266 [03:02<01:23,  1.18s/it]Loading train:  74%|███████▎  | 196/266 [03:03<01:15,  1.08s/it]Loading train:  74%|███████▍  | 197/266 [03:04<01:10,  1.02s/it]Loading train:  74%|███████▍  | 198/266 [03:05<01:04,  1.06it/s]Loading train:  75%|███████▍  | 199/266 [03:05<00:59,  1.12it/s]Loading train:  75%|███████▌  | 200/266 [03:06<00:59,  1.12it/s]Loading train:  76%|███████▌  | 201/266 [03:07<00:56,  1.14it/s]Loading train:  76%|███████▌  | 202/266 [03:08<00:54,  1.17it/s]Loading train:  76%|███████▋  | 203/266 [03:09<00:54,  1.17it/s]Loading train:  77%|███████▋  | 204/266 [03:10<00:51,  1.19it/s]Loading train:  77%|███████▋  | 205/266 [03:10<00:51,  1.19it/s]Loading train:  77%|███████▋  | 206/266 [03:11<00:50,  1.18it/s]Loading train:  78%|███████▊  | 207/266 [03:12<00:49,  1.20it/s]Loading train:  78%|███████▊  | 208/266 [03:13<00:47,  1.23it/s]Loading train:  79%|███████▊  | 209/266 [03:14<00:45,  1.24it/s]Loading train:  79%|███████▉  | 210/266 [03:14<00:44,  1.25it/s]Loading train:  79%|███████▉  | 211/266 [03:15<00:44,  1.24it/s]Loading train:  80%|███████▉  | 212/266 [03:16<00:43,  1.24it/s]Loading train:  80%|████████  | 213/266 [03:17<00:42,  1.24it/s]Loading train:  80%|████████  | 214/266 [03:18<00:41,  1.25it/s]Loading train:  81%|████████  | 215/266 [03:19<00:41,  1.23it/s]Loading train:  81%|████████  | 216/266 [03:19<00:41,  1.21it/s]Loading train:  82%|████████▏ | 217/266 [03:20<00:40,  1.21it/s]Loading train:  82%|████████▏ | 218/266 [03:21<00:39,  1.22it/s]Loading train:  82%|████████▏ | 219/266 [03:22<00:37,  1.24it/s]Loading train:  83%|████████▎ | 220/266 [03:23<00:38,  1.20it/s]Loading train:  83%|████████▎ | 221/266 [03:23<00:36,  1.24it/s]Loading train:  83%|████████▎ | 222/266 [03:24<00:35,  1.24it/s]Loading train:  84%|████████▍ | 223/266 [03:25<00:36,  1.18it/s]Loading train:  84%|████████▍ | 224/266 [03:26<00:34,  1.21it/s]Loading train:  85%|████████▍ | 225/266 [03:27<00:33,  1.23it/s]Loading train:  85%|████████▍ | 226/266 [03:28<00:32,  1.22it/s]Loading train:  85%|████████▌ | 227/266 [03:28<00:32,  1.20it/s]Loading train:  86%|████████▌ | 228/266 [03:29<00:30,  1.23it/s]Loading train:  86%|████████▌ | 229/266 [03:30<00:29,  1.24it/s]Loading train:  86%|████████▋ | 230/266 [03:31<00:28,  1.26it/s]Loading train:  87%|████████▋ | 231/266 [03:32<00:29,  1.20it/s]Loading train:  87%|████████▋ | 232/266 [03:33<00:28,  1.20it/s]Loading train:  88%|████████▊ | 233/266 [03:33<00:27,  1.20it/s]Loading train:  88%|████████▊ | 234/266 [03:34<00:27,  1.18it/s]Loading train:  88%|████████▊ | 235/266 [03:35<00:25,  1.19it/s]Loading train:  89%|████████▊ | 236/266 [03:36<00:25,  1.19it/s]Loading train:  89%|████████▉ | 237/266 [03:37<00:23,  1.21it/s]Loading train:  89%|████████▉ | 238/266 [03:37<00:22,  1.23it/s]Loading train:  90%|████████▉ | 239/266 [03:38<00:22,  1.21it/s]Loading train:  90%|█████████ | 240/266 [03:39<00:20,  1.25it/s]Loading train:  91%|█████████ | 241/266 [03:40<00:19,  1.26it/s]Loading train:  91%|█████████ | 242/266 [03:41<00:18,  1.29it/s]Loading train:  91%|█████████▏| 243/266 [03:41<00:17,  1.28it/s]Loading train:  92%|█████████▏| 244/266 [03:42<00:17,  1.27it/s]Loading train:  92%|█████████▏| 245/266 [03:43<00:16,  1.30it/s]Loading train:  92%|█████████▏| 246/266 [03:44<00:15,  1.29it/s]Loading train:  93%|█████████▎| 247/266 [03:44<00:14,  1.31it/s]Loading train:  93%|█████████▎| 248/266 [03:45<00:13,  1.33it/s]Loading train:  94%|█████████▎| 249/266 [03:46<00:14,  1.15it/s]Loading train:  94%|█████████▍| 250/266 [03:47<00:14,  1.12it/s]Loading train:  94%|█████████▍| 251/266 [03:48<00:14,  1.07it/s]Loading train:  95%|█████████▍| 252/266 [03:49<00:12,  1.08it/s]Loading train:  95%|█████████▌| 253/266 [03:50<00:11,  1.09it/s]Loading train:  95%|█████████▌| 254/266 [03:51<00:11,  1.07it/s]Loading train:  96%|█████████▌| 255/266 [03:52<00:10,  1.08it/s]Loading train:  96%|█████████▌| 256/266 [03:53<00:09,  1.07it/s]Loading train:  97%|█████████▋| 257/266 [03:54<00:08,  1.07it/s]Loading train:  97%|█████████▋| 258/266 [03:55<00:07,  1.06it/s]Loading train:  97%|█████████▋| 259/266 [03:56<00:06,  1.06it/s]Loading train:  98%|█████████▊| 260/266 [03:57<00:05,  1.06it/s]Loading train:  98%|█████████▊| 261/266 [03:58<00:04,  1.02it/s]Loading train:  98%|█████████▊| 262/266 [03:59<00:03,  1.00it/s]Loading train:  99%|█████████▉| 263/266 [04:00<00:02,  1.02it/s]Loading train:  99%|█████████▉| 264/266 [04:01<00:01,  1.04it/s]Loading train: 100%|█████████▉| 265/266 [04:02<00:00,  1.06it/s]Loading train: 100%|██████████| 266/266 [04:02<00:00,  1.07it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 12/266 [00:00<00:02, 109.21it/s]concatenating: train:   9%|▉         | 24/266 [00:00<00:02, 110.21it/s]concatenating: train:  15%|█▍        | 39/266 [00:00<00:01, 118.95it/s]concatenating: train:  20%|█▉        | 53/266 [00:00<00:01, 123.18it/s]concatenating: train:  26%|██▌       | 68/266 [00:00<00:01, 127.79it/s]concatenating: train:  31%|███       | 82/266 [00:00<00:01, 130.28it/s]concatenating: train:  36%|███▋      | 97/266 [00:00<00:01, 134.58it/s]concatenating: train:  42%|████▏     | 111/266 [00:00<00:01, 135.12it/s]concatenating: train:  48%|████▊     | 128/266 [00:00<00:00, 142.05it/s]concatenating: train:  55%|█████▍    | 146/266 [00:01<00:00, 149.68it/s]concatenating: train:  62%|██████▏   | 165/266 [00:01<00:00, 158.76it/s]concatenating: train:  69%|██████▉   | 183/266 [00:01<00:00, 163.59it/s]concatenating: train:  77%|███████▋  | 205/266 [00:01<00:00, 175.92it/s]concatenating: train:  85%|████████▍ | 226/266 [00:01<00:00, 182.99it/s]concatenating: train:  92%|█████████▏| 246/266 [00:01<00:00, 187.26it/s]concatenating: train: 100%|██████████| 266/266 [00:01<00:00, 161.72it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:05,  1.39s/it]Loading test:  40%|████      | 2/5 [00:02<00:04,  1.35s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.28s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.22s/it]Loading test: 100%|██████████| 5/5 [00:06<00:00,  1.27s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 308.73it/s]2019-08-17 19:31:31.174817: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 19:31:31.174902: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 19:31:31.174916: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 19:31:31.174924: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 19:31:31.175326: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14485 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.27it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.29it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.86it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.50it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.72it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.57it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.71it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.67it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.00it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.54it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.35it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.94it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.98it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.79it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.61it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.99it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.43it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.51it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.97it/s]
Epoch 00048: val_mDice did not improve from 0.89887
Restoring model weights from the end of the best epoch
Epoch 00048: early stopping
{'val_loss': [0.07200275510549545, 0.06568777710199356, 0.06410265602171421, 0.06200672574341297, 0.06201118528842926, 0.0605912160128355, 0.06294171661138534, 0.05983210988342762, 0.06008318215608597, 0.06096384339034557, 0.061959435045719144, 0.059985310211777686, 0.060243692621588706, 0.06160192117094994, 0.06207787059247494, 0.06163716278970242, 0.06098515726625919, 0.061700521409511565, 0.05886651538312435, 0.05770789384841919, 0.05763548202812672, 0.05742436610162258, 0.056132680550217626, 0.057460454478859904, 0.05523981787264347, 0.055440934374928474, 0.056819275766611096, 0.05583710335195065, 0.0565758466720581, 0.05737512409687042, 0.05747770145535469, 0.05613120645284653, 0.05555586218833923, 0.05868312902748585, 0.0560199785977602, 0.05509676523506642, 0.05621301382780075, 0.05759926848113537, 0.05595334693789482, 0.05793949365615845, 0.05642898678779602, 0.05628434792160988, 0.055153286457061766, 0.0560754582285881, 0.05617853514850139, 0.05808413773775101, 0.05704870633780956, 0.05702216513454914], 'val_acc': [0.9882748544216156, 0.9922119796276092, 0.9935857713222503, 0.9923116564750671, 0.9935004889965058, 0.991426157951355, 0.9927090585231781, 0.9919103264808655, 0.9927653491497039, 0.9925631046295166, 0.9920358180999755, 0.9928079903125763, 0.9925930798053741, 0.992232209444046, 0.9923525929450989, 0.9934600412845611, 0.9938669562339782, 0.9947312295436859, 0.9949853718280792, 0.9950046360492706, 0.995068222284317, 0.9949663698673248, 0.9952019929885865, 0.995034122467041, 0.9952621817588806, 0.9951878666877747, 0.9950204730033875, 0.9950560331344604, 0.9951096475124359, 0.994938850402832, 0.9950277805328369, 0.99506676197052, 0.9950004935264587, 0.9949415266513825, 0.9950209558010101, 0.9950716316699981, 0.9950017035007477, 0.9949437141418457, 0.9951025784015656, 0.9950911343097687, 0.99502192735672, 0.9950497090816498, 0.9951303541660309, 0.9950589597225189, 0.9950999021530151, 0.9949159324169159, 0.9949734330177307, 0.9950828552246094], 'val_mDice': [0.8768961071968079, 0.8883575975894928, 0.8910432040691376, 0.8950606286525726, 0.8950017213821411, 0.897610068321228, 0.8934695303440094, 0.8988706886768341, 0.8984757602214813, 0.8970697402954102, 0.8954612731933593, 0.8986816585063935, 0.898479825258255, 0.8960140466690063, 0.8952823281288147, 0.8956953287124634, 0.897007554769516, 0.8960835337638855, 0.892373675107956, 0.8943165898323059, 0.8944505512714386, 0.8947974860668182, 0.8969949662685395, 0.894689428806305, 0.8984859645366668, 0.8982655167579651, 0.8958746671676636, 0.8976348638534546, 0.8961842656135559, 0.8950154483318329, 0.8948422372341156, 0.8969740450382233, 0.8981145799160004, 0.892581307888031, 0.8972982108592987, 0.8988034546375274, 0.8969109535217286, 0.8944260239601135, 0.8973718047142029, 0.894030749797821, 0.8965235829353333, 0.8968044698238373, 0.8987620830535888, 0.8970892190933227, 0.8969416677951813, 0.8935949981212616, 0.8954606413841247, 0.8953084528446198], 'loss': [0.247016151342531, 0.06433157674393483, 0.05429938398191122, 0.04895274596327468, 0.045497973631120646, 0.043016345216648905, 0.04102384790207926, 0.0395261995157869, 0.03822368807276333, 0.037193648211649215, 0.03623676705189289, 0.03556729882037639, 0.03488453933954831, 0.03422024018212492, 0.03376513830903459, 0.03331965093274662, 0.03291738492956127, 0.032467743334072145, 0.027307775658455, 0.02561067727352107, 0.025231064997705808, 0.025000991345936856, 0.024706191720630863, 0.024622321912384764, 0.024520932681751786, 0.02411490815409162, 0.024008544995370782, 0.023818605150928276, 0.023651239589215025, 0.02355727918422637, 0.023545173676900465, 0.023408932293750837, 0.023219452160007766, 0.02311931124637419, 0.023014576481631615, 0.022853887205575487, 0.022730114968439605, 0.022716183423893213, 0.02255145815445789, 0.02257336504651184, 0.022387588500891904, 0.022273419689243727, 0.022273326302550547, 0.02219492106603248, 0.022077027471359978, 0.022089328875486144, 0.022027876553675982, 0.021946431909480736], 'acc': [0.9603319903144492, 0.9836044996145195, 0.9856200125046464, 0.9867023253899174, 0.9871081050008713, 0.9871756283826382, 0.9871972366050964, 0.9872144846797445, 0.9870788807947672, 0.9871584899910147, 0.9871889886209665, 0.9876546080495723, 0.9879502744461199, 0.9882941071970199, 0.9887605409519625, 0.9892859609431084, 0.9898555484786483, 0.991212668464716, 0.9957322234376841, 0.9965627060747694, 0.9965936907486853, 0.9966153615531453, 0.996628047160262, 0.996643665148931, 0.9966583935190559, 0.9966801232423891, 0.9966933572326829, 0.996707778715664, 0.9967145087545434, 0.9967235685008198, 0.9967304624838857, 0.9967390791704601, 0.996749457455731, 0.9967565841880451, 0.9967731116059705, 0.9967868948185538, 0.996791625545097, 0.9967941240758832, 0.9967886311288824, 0.9968001282040055, 0.9968037593955502, 0.9968179973110481, 0.9968155675405994, 0.9968170403825103, 0.9968258080666662, 0.9968239044599622, 0.9968390067972145, 0.9968434556438578], 'mDice': [0.721895072821227, 0.8923368724795465, 0.9103118386491641, 0.9200598701776643, 0.9264230933582795, 0.9310200123702248, 0.9347289787567402, 0.9375288191087701, 0.9399692644774605, 0.9419020669451011, 0.943702435471746, 0.9449644648479735, 0.9462524879169126, 0.9475086420177071, 0.9483693524751606, 0.9492146153433315, 0.9499774865983669, 0.9508309546857673, 0.9513980863468054, 0.951643515113219, 0.9523404368988105, 0.9527647857259323, 0.9533147351826213, 0.9534655498867101, 0.9536514577555683, 0.9544103643912681, 0.9546032889644003, 0.9549556990573145, 0.955271375301963, 0.9554435985326111, 0.9554624207346847, 0.9557173336954001, 0.9560719947022343, 0.9562596272509867, 0.9564515475049153, 0.9567545018114495, 0.9569837288248768, 0.9570091334545128, 0.9573195273160517, 0.9572787141201048, 0.9576295122382308, 0.9578407712593021, 0.957844355754472, 0.957990387621879, 0.958209541880544, 0.9581850805917933, 0.9582987460445377, 0.9584513304637091]}
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM30_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 48, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 48, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 48, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 48, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 48, 52, 30)   8130        activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 48, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 48, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 24, 26, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 24, 26, 30)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 24, 26, 60)   16260       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 24, 26, 60)   240         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 24, 26, 60)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 24, 26, 60)   32460       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 24, 26, 60)   240         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 24, 26, 60)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 24, 26, 90)   0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 12, 13, 90)   0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 12, 13, 90)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 12, 13, 120)  97320       dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 12, 13, 120)  480         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 12, 13, 120)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 12, 13, 120)  129720      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 12, 13, 120)  480         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 12, 13, 120)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 12, 13, 210)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 12, 13, 210)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 24, 26, 60)   50460       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 24, 26, 150)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 24, 26, 60)   81060       concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 24, 26, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 24, 26, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 24, 26, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 24, 26, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 24, 26, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 24, 26, 210)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 24, 26, 210)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 48, 52, 30)   25230       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 48, 52, 60)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 48, 52, 30)   16230       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 48, 52, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 48, 52, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 48, 52, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 48, 52, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 48, 52, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 48, 52, 90)   0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 48, 52, 90)   0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 48, 52, 13)   1183        dropout_5[0][0]                  
==================================================================================================
Total params: 501,343
Trainable params: 442,123
Non-trainable params: 59,220
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.34783344e-02 3.28999393e-02 7.69319832e-02 9.55918576e-03
 2.76664603e-02 7.23814948e-03 8.42813897e-02 1.14346728e-01
 8.97847510e-02 1.36414281e-02 2.91099822e-01 1.88810888e-01
 2.60941369e-04]
Train on 16938 samples, validate on 313 samples
Epoch 1/300
 - 17s - loss: 1.2473 - acc: 0.8189 - mDice: 0.3851 - val_loss: 1.1512 - val_acc: 0.9449 - val_mDice: 0.5581

Epoch 00001: val_mDice improved from -inf to 0.55805, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.4889 - acc: 0.9232 - mDice: 0.6049 - val_loss: 0.9938 - val_acc: 0.9512 - val_mDice: 0.5795

Epoch 00002: val_mDice improved from 0.55805 to 0.57946, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.3910 - acc: 0.9368 - mDice: 0.6684 - val_loss: 0.9266 - val_acc: 0.9531 - val_mDice: 0.5850

Epoch 00003: val_mDice improved from 0.57946 to 0.58496, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.3990 - acc: 0.9395 - mDice: 0.6731 - val_loss: 1.0012 - val_acc: 0.9470 - val_mDice: 0.5891

Epoch 00004: val_mDice improved from 0.58496 to 0.58911, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.3390 - acc: 0.9444 - mDice: 0.7026 - val_loss: 0.9986 - val_acc: 0.9483 - val_mDice: 0.5887

Epoch 00005: val_mDice did not improve from 0.58911
Epoch 6/300
 - 12s - loss: 0.3110 - acc: 0.9472 - mDice: 0.7247 - val_loss: 0.9562 - val_acc: 0.9481 - val_mDice: 0.5878

Epoch 00006: val_mDice did not improve from 0.58911
Epoch 7/300
 - 12s - loss: 0.3010 - acc: 0.9487 - mDice: 0.7359 - val_loss: 0.8833 - val_acc: 0.9505 - val_mDice: 0.5920

Epoch 00007: val_mDice improved from 0.58911 to 0.59205, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.3019 - acc: 0.9485 - mDice: 0.7358 - val_loss: 0.9164 - val_acc: 0.9511 - val_mDice: 0.6001

Epoch 00008: val_mDice improved from 0.59205 to 0.60015, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.2930 - acc: 0.9496 - mDice: 0.7425 - val_loss: 0.9494 - val_acc: 0.9498 - val_mDice: 0.6024

Epoch 00009: val_mDice improved from 0.60015 to 0.60236, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.3097 - acc: 0.9475 - mDice: 0.7274 - val_loss: 0.8687 - val_acc: 0.9502 - val_mDice: 0.5981

Epoch 00010: val_mDice did not improve from 0.60236
Epoch 11/300
 - 12s - loss: 0.2682 - acc: 0.9512 - mDice: 0.7554 - val_loss: 0.8517 - val_acc: 0.9481 - val_mDice: 0.5946

Epoch 00011: val_mDice did not improve from 0.60236
Epoch 12/300
 - 12s - loss: 0.2506 - acc: 0.9525 - mDice: 0.7670 - val_loss: 0.8597 - val_acc: 0.9486 - val_mDice: 0.5894

Epoch 00012: val_mDice did not improve from 0.60236
Epoch 13/300
 - 12s - loss: 0.3030 - acc: 0.9482 - mDice: 0.7370 - val_loss: 1.2168 - val_acc: 0.9467 - val_mDice: 0.5624

Epoch 00013: val_mDice did not improve from 0.60236
Epoch 14/300
 - 12s - loss: 0.3061 - acc: 0.9484 - mDice: 0.7315 - val_loss: 0.9485 - val_acc: 0.9506 - val_mDice: 0.5947

Epoch 00014: val_mDice did not improve from 0.60236
Epoch 15/300
 - 12s - loss: 0.2719 - acc: 0.9516 - mDice: 0.7581 - val_loss: 0.8202 - val_acc: 0.9505 - val_mDice: 0.5972

Epoch 00015: val_mDice did not improve from 0.60236
Epoch 16/300
 - 12s - loss: 0.2628 - acc: 0.9517 - mDice: 0.7596 - val_loss: 0.7917 - val_acc: 0.9516 - val_mDice: 0.5925

Epoch 00016: val_mDice did not improve from 0.60236
Epoch 17/300
 - 12s - loss: 0.2519 - acc: 0.9530 - mDice: 0.7713 - val_loss: 0.8885 - val_acc: 0.9492 - val_mDice: 0.5990

Epoch 00017: val_mDice did not improve from 0.60236
Epoch 18/300
 - 12s - loss: 0.2411 - acc: 0.9540 - mDice: 0.7776 - val_loss: 0.8780 - val_acc: 0.9482 - val_mDice: 0.5875

Epoch 00018: val_mDice did not improve from 0.60236
Epoch 19/300
 - 12s - loss: 0.2353 - acc: 0.9545 - mDice: 0.7818 - val_loss: 0.7425 - val_acc: 0.9528 - val_mDice: 0.6093

Epoch 00019: val_mDice improved from 0.60236 to 0.60932, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 12s - loss: 0.2318 - acc: 0.9549 - mDice: 0.7850 - val_loss: 0.7263 - val_acc: 0.9508 - val_mDice: 0.6009

Epoch 00020: val_mDice did not improve from 0.60932
Epoch 21/300
 - 12s - loss: 0.2644 - acc: 0.9532 - mDice: 0.7673 - val_loss: 0.7178 - val_acc: 0.9504 - val_mDice: 0.5920

Epoch 00021: val_mDice did not improve from 0.60932
Epoch 22/300
 - 12s - loss: 0.2283 - acc: 0.9549 - mDice: 0.7849 - val_loss: 0.6926 - val_acc: 0.9497 - val_mDice: 0.5950

Epoch 00022: val_mDice did not improve from 0.60932
Epoch 23/300
 - 12s - loss: 0.2419 - acc: 0.9540 - mDice: 0.7806 - val_loss: 0.6400 - val_acc: 0.9521 - val_mDice: 0.5982

Epoch 00023: val_mDice did not improve from 0.60932
Epoch 24/300
 - 12s - loss: 0.2289 - acc: 0.9553 - mDice: 0.7868 - val_loss: 0.6753 - val_acc: 0.9507 - val_mDice: 0.5993

Epoch 00024: val_mDice did not improve from 0.60932
Epoch 25/300
 - 12s - loss: 0.2712 - acc: 0.9525 - mDice: 0.7633 - val_loss: 0.7990 - val_acc: 0.9505 - val_mDice: 0.5859

Epoch 00025: val_mDice did not improve from 0.60932
Epoch 26/300
 - 12s - loss: 0.2430 - acc: 0.9543 - mDice: 0.7787 - val_loss: 0.7809 - val_acc: 0.9506 - val_mDice: 0.5939

Epoch 00026: val_mDice did not improve from 0.60932
Epoch 27/300
 - 12s - loss: 0.2287 - acc: 0.9552 - mDice: 0.7855 - val_loss: 0.5749 - val_acc: 0.9515 - val_mDice: 0.5994

Epoch 00027: val_mDice did not improve from 0.60932
Epoch 28/300
 - 12s - loss: 0.2231 - acc: 0.9555 - mDice: 0.7905 - val_loss: 0.6070 - val_acc: 0.9518 - val_mDice: 0.6071

Epoch 00028: val_mDice did not improve from 0.60932
Epoch 29/300
 - 12s - loss: 0.2357 - acc: 0.9547 - mDice: 0.7819 - val_loss: 0.7017 - val_acc: 0.9506 - val_mDice: 0.5975

Epoch 00029: val_mDice did not improve from 0.60932
Epoch 30/300
 - 12s - loss: 0.2521 - acc: 0.9538 - mDice: 0.7742 - val_loss: 0.6371 - val_acc: 0.9529 - val_mDice: 0.5992

Epoch 00030: val_mDice did not improve from 0.60932
Epoch 31/300
 - 12s - loss: 0.2500 - acc: 0.9530 - mDice: 0.7717 - val_loss: 0.6561 - val_acc: 0.9495 - val_mDice: 0.6022

Epoch 00031: val_mDice did not improve from 0.60932
Epoch 32/300
 - 12s - loss: 0.2246 - acc: 0.9555 - mDice: 0.7908 - val_loss: 0.6309 - val_acc: 0.9506 - val_mDice: 0.5954

Epoch 00032: val_mDice did not improve from 0.60932
Epoch 33/300
 - 12s - loss: 0.2291 - acc: 0.9557 - mDice: 0.7910 - val_loss: 0.6073 - val_acc: 0.9501 - val_mDice: 0.5935

Epoch 00033: val_mDice did not improve from 0.60932
Epoch 34/300
 - 12s - loss: 0.2117 - acc: 0.9566 - mDice: 0.7989 - val_loss: 0.5913 - val_acc: 0.9505 - val_mDice: 0.5939

Epoch 00034: val_mDice did not improve from 0.60932
Epoch 35/300
 - 12s - loss: 0.2174 - acc: 0.9567 - mDice: 0.7979 - val_loss: 0.5799 - val_acc: 0.9503 - val_mDice: 0.5963

Epoch 00035: val_mDice did not improve from 0.60932
Epoch 36/300
 - 12s - loss: 0.2141 - acc: 0.9571 - mDice: 0.8013 - val_loss: 0.5513 - val_acc: 0.9508 - val_mDice: 0.6006

Epoch 00036: val_mDice did not improve from 0.60932
Epoch 37/300
 - 12s - loss: 0.2452 - acc: 0.9541 - mDice: 0.7805 - val_loss: 0.5352 - val_acc: 0.9513 - val_mDice: 0.5951

Epoch 00037: val_mDice did not improve from 0.60932
Epoch 38/300
 - 12s - loss: 0.2215 - acc: 0.9560 - mDice: 0.7941 - val_loss: 0.8664 - val_acc: 0.9327 - val_mDice: 0.5186

Epoch 00038: val_mDice did not improve from 0.60932
Epoch 39/300
 - 12s - loss: 0.2417 - acc: 0.9541 - mDice: 0.7779 - val_loss: 0.5407 - val_acc: 0.9524 - val_mDice: 0.5994

Epoch 00039: val_mDice did not improve from 0.60932
Epoch 40/300
 - 12s - loss: 0.2124 - acc: 0.9568 - mDice: 0.8009 - val_loss: 0.5213 - val_acc: 0.9523 - val_mDice: 0.6036

Epoch 00040: val_mDice did not improve from 0.60932
Epoch 41/300
 - 12s - loss: 0.2238 - acc: 0.9559 - mDice: 0.7912 - val_loss: 0.5385 - val_acc: 0.9519 - val_mDice: 0.5985

Epoch 00041: val_mDice did not improve from 0.60932
Epoch 42/300
 - 12s - loss: 0.2527 - acc: 0.9551 - mDice: 0.7809 - val_loss: 0.6870 - val_acc: 0.9469 - val_mDice: 0.5746

Epoch 00042: val_mDice did not improve from 0.60932
Epoch 43/300
 - 12s - loss: 0.2172 - acc: 0.9563 - mDice: 0.7946 - val_loss: 0.5553 - val_acc: 0.9522 - val_mDice: 0.5950

Epoch 00043: val_mDice did not improve from 0.60932
Epoch 44/300
 - 12s - loss: 0.2080 - acc: 0.9574 - mDice: 0.8044 - val_loss: 0.5358 - val_acc: 0.9520 - val_mDice: 0.5959

Epoch 00044: val_mDice did not improve from 0.60932
Epoch 45/300
 - 12s - loss: 0.2215 - acc: 0.9562 - mDice: 0.7953 - val_loss: 0.5322 - val_acc: 0.9530 - val_mDice: 0.5809

Epoch 00045: val_mDice did not improve from 0.60932
Epoch 46/300
 - 12s - loss: 0.2160 - acc: 0.9565 - mDice: 0.7965 - val_loss: 0.8113 - val_acc: 0.9495 - val_mDice: 0.5896

Epoch 00046: val_mDice did not improve from 0.60932
Epoch 47/300
 - 12s - loss: 0.2094 - acc: 0.9569 - mDice: 0.8007 - val_loss: 0.5583 - val_acc: 0.9519 - val_mDice: 0.5939

Epoch 00047: val_mDice did not improve from 0.60932
Epoch 48/300
 - 12s - loss: 0.2028 - acc: 0.9577 - mDice: 0.8090 - val_loss: 0.5696 - val_acc: 0.9514 - val_mDice: 0.5932

Epoch 00048: val_mDice did not improve from 0.60932
Epoch 49/300
 - 12s - loss: 0.2356 - acc: 0.9567 - mDice: 0.7990 - val_loss: 0.6232 - val_acc: 0.9478 - val_mDice: 0.5867

Epoch 00049: val_mDice did not improve from 0.60932
Epoch 50/300
 - 12s - loss: 0.2115 - acc: 0.9569 - mDice: 0.7998 - val_loss: 0.4927 - val_acc: 0.9512 - val_mDice: 0.5951

Epoch 00050: val_mDice did not improve from 0.60932
Epoch 51/300
 - 12s - loss: 0.2016 - acc: 0.9580 - mDice: 0.8092 - val_loss: 0.5310 - val_acc: 0.9521 - val_mDice: 0.5918

Epoch 00051: val_mDice did not improve from 0.60932
Epoch 52/300
 - 12s - loss: 0.1969 - acc: 0.9583 - mDice: 0.8116 - val_loss: 0.4677 - val_acc: 0.9520 - val_mDice: 0.5965

Epoch 00052: val_mDice did not improve from 0.60932
Epoch 53/300
 - 12s - loss: 0.2207 - acc: 0.9572 - mDice: 0.8032 - val_loss: 0.5272 - val_acc: 0.9505 - val_mDice: 0.5956

Epoch 00053: val_mDice did not improve from 0.60932
Epoch 54/300
 - 12s - loss: 0.2229 - acc: 0.9566 - mDice: 0.7969 - val_loss: 0.4710 - val_acc: 0.9505 - val_mDice: 0.6035

Epoch 00054: val_mDice did not improve from 0.60932
Epoch 55/300
 - 12s - loss: 0.2018 - acc: 0.9581 - mDice: 0.8103 - val_loss: 0.7123 - val_acc: 0.9487 - val_mDice: 0.5960

Epoch 00055: val_mDice did not improve from 0.60932
Epoch 56/300
 - 12s - loss: 0.2088 - acc: 0.9574 - mDice: 0.8053 - val_loss: 0.4638 - val_acc: 0.9504 - val_mDice: 0.5961

Epoch 00056: val_mDice did not improve from 0.60932
Epoch 57/300
 - 12s - loss: 0.2020 - acc: 0.9581 - mDice: 0.8100 - val_loss: 0.5142 - val_acc: 0.9503 - val_mDice: 0.5946

Epoch 00057: val_mDice did not improve from 0.60932
Epoch 58/300
 - 12s - loss: 0.2031 - acc: 0.9580 - mDice: 0.8096 - val_loss: 0.4778 - val_acc: 0.9540 - val_mDice: 0.5788

Epoch 00058: val_mDice did not improve from 0.60932
Epoch 59/300
 - 12s - loss: 0.2141 - acc: 0.9571 - mDice: 0.8015 - val_loss: 0.5782 - val_acc: 0.9529 - val_mDice: 0.5775

predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:02<00:11,  2.96s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.76s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.52s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.36s/it]predicting test subjects: 100%|██████████| 5/5 [00:11<00:00,  2.35s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:02<12:27,  2.82s/it]predicting train subjects:   1%|          | 2/266 [00:05<12:08,  2.76s/it]predicting train subjects:   1%|          | 3/266 [00:07<11:16,  2.57s/it]predicting train subjects:   2%|▏         | 4/266 [00:09<10:32,  2.41s/it]predicting train subjects:   2%|▏         | 5/266 [00:12<10:47,  2.48s/it]predicting train subjects:   2%|▏         | 6/266 [00:15<11:09,  2.58s/it]predicting train subjects:   3%|▎         | 7/266 [00:17<11:21,  2.63s/it]predicting train subjects:   3%|▎         | 8/266 [00:20<11:31,  2.68s/it]predicting train subjects:   3%|▎         | 9/266 [00:23<11:40,  2.73s/it]predicting train subjects:   4%|▍         | 10/266 [00:26<11:46,  2.76s/it]predicting train subjects:   4%|▍         | 11/266 [00:29<11:58,  2.82s/it]predicting train subjects:   5%|▍         | 12/266 [00:32<12:06,  2.86s/it]predicting train subjects:   5%|▍         | 13/266 [00:35<12:01,  2.85s/it]predicting train subjects:   5%|▌         | 14/266 [00:37<11:59,  2.86s/it]predicting train subjects:   6%|▌         | 15/266 [00:40<11:57,  2.86s/it]predicting train subjects:   6%|▌         | 16/266 [00:43<11:51,  2.85s/it]predicting train subjects:   6%|▋         | 17/266 [00:46<11:48,  2.84s/it]predicting train subjects:   7%|▋         | 18/266 [00:49<11:38,  2.82s/it]predicting train subjects:   7%|▋         | 19/266 [00:51<11:34,  2.81s/it]predicting train subjects:   8%|▊         | 20/266 [00:54<11:34,  2.82s/it]predicting train subjects:   8%|▊         | 21/266 [00:57<11:31,  2.82s/it]predicting train subjects:   8%|▊         | 22/266 [01:00<11:28,  2.82s/it]predicting train subjects:   9%|▊         | 23/266 [01:03<11:29,  2.84s/it]predicting train subjects:   9%|▉         | 24/266 [01:05<11:06,  2.76s/it]predicting train subjects:   9%|▉         | 25/266 [01:08<10:52,  2.71s/it]predicting train subjects:  10%|▉         | 26/266 [01:11<10:39,  2.66s/it]predicting train subjects:  10%|█         | 27/266 [01:13<10:30,  2.64s/it]predicting train subjects:  11%|█         | 28/266 [01:16<10:23,  2.62s/it]predicting train subjects:  11%|█         | 29/266 [01:18<10:18,  2.61s/it]predicting train subjects:  11%|█▏        | 30/266 [01:21<10:09,  2.58s/it]predicting train subjects:  12%|█▏        | 31/266 [01:23<10:05,  2.58s/it]predicting train subjects:  12%|█▏        | 32/266 [01:26<10:03,  2.58s/it]predicting train subjects:  12%|█▏        | 33/266 [01:29<10:01,  2.58s/it]predicting train subjects:  13%|█▎        | 34/266 [01:31<09:53,  2.56s/it]predicting train subjects:  13%|█▎        | 35/266 [01:34<09:54,  2.57s/it]predicting train subjects:  14%|█▎        | 36/266 [01:36<09:48,  2.56s/it]predicting train subjects:  14%|█▍        | 37/266 [01:39<09:50,  2.58s/it]predicting train subjects:  14%|█▍        | 38/266 [01:41<09:46,  2.57s/it]predicting train subjects:  15%|█▍        | 39/266 [01:44<09:48,  2.59s/it]predicting train subjects:  15%|█▌        | 40/266 [01:47<09:42,  2.58s/it]predicting train subjects:  15%|█▌        | 41/266 [01:49<09:41,  2.58s/it]predicting train subjects:  16%|█▌        | 42/266 [01:51<09:09,  2.45s/it]predicting train subjects:  16%|█▌        | 43/266 [01:54<08:53,  2.39s/it]predicting train subjects:  17%|█▋        | 44/266 [01:56<08:38,  2.34s/it]predicting train subjects:  17%|█▋        | 45/266 [01:58<08:22,  2.28s/it]predicting train subjects:  17%|█▋        | 46/266 [02:00<08:15,  2.25s/it]predicting train subjects:  18%|█▊        | 47/266 [02:02<08:08,  2.23s/it]predicting train subjects:  18%|█▊        | 48/266 [02:04<08:04,  2.22s/it]predicting train subjects:  18%|█▊        | 49/266 [02:07<08:00,  2.22s/it]predicting train subjects:  19%|█▉        | 50/266 [02:09<07:55,  2.20s/it]predicting train subjects:  19%|█▉        | 51/266 [02:11<07:46,  2.17s/it]predicting train subjects:  20%|█▉        | 52/266 [02:13<07:43,  2.17s/it]predicting train subjects:  20%|█▉        | 53/266 [02:15<07:41,  2.17s/it]predicting train subjects:  20%|██        | 54/266 [02:17<07:40,  2.17s/it]predicting train subjects:  21%|██        | 55/266 [02:20<07:37,  2.17s/it]predicting train subjects:  21%|██        | 56/266 [02:22<07:30,  2.15s/it]predicting train subjects:  21%|██▏       | 57/266 [02:24<07:29,  2.15s/it]predicting train subjects:  22%|██▏       | 58/266 [02:26<07:29,  2.16s/it]predicting train subjects:  22%|██▏       | 59/266 [02:28<07:26,  2.16s/it]predicting train subjects:  23%|██▎       | 60/266 [02:30<07:14,  2.11s/it]predicting train subjects:  23%|██▎       | 61/266 [02:32<07:10,  2.10s/it]predicting train subjects:  23%|██▎       | 62/266 [02:34<07:02,  2.07s/it]predicting train subjects:  24%|██▎       | 63/266 [02:36<06:59,  2.07s/it]predicting train subjects:  24%|██▍       | 64/266 [02:38<06:53,  2.05s/it]predicting train subjects:  24%|██▍       | 65/266 [02:40<06:51,  2.05s/it]predicting train subjects:  25%|██▍       | 66/266 [02:42<06:51,  2.06s/it]predicting train subjects:  25%|██▌       | 67/266 [02:44<06:47,  2.05s/it]predicting train subjects:  26%|██▌       | 68/266 [02:47<06:46,  2.05s/it]predicting train subjects:  26%|██▌       | 69/266 [02:49<06:44,  2.05s/it]predicting train subjects:  26%|██▋       | 70/266 [02:51<06:41,  2.05s/it]predicting train subjects:  27%|██▋       | 71/266 [02:53<06:36,  2.03s/it]predicting train subjects:  27%|██▋       | 72/266 [02:55<06:33,  2.03s/it]predicting train subjects:  27%|██▋       | 73/266 [02:57<06:33,  2.04s/it]predicting train subjects:  28%|██▊       | 74/266 [02:59<06:30,  2.04s/it]predicting train subjects:  28%|██▊       | 75/266 [03:01<06:24,  2.01s/it]predicting train subjects:  29%|██▊       | 76/266 [03:03<06:20,  2.00s/it]predicting train subjects:  29%|██▉       | 77/266 [03:05<06:17,  2.00s/it]predicting train subjects:  29%|██▉       | 78/266 [03:07<06:46,  2.16s/it]predicting train subjects:  30%|██▉       | 79/266 [03:10<07:02,  2.26s/it]predicting train subjects:  30%|███       | 80/266 [03:12<07:22,  2.38s/it]predicting train subjects:  30%|███       | 81/266 [03:15<07:36,  2.47s/it]predicting train subjects:  31%|███       | 82/266 [03:18<07:40,  2.50s/it]predicting train subjects:  31%|███       | 83/266 [03:20<07:43,  2.53s/it]predicting train subjects:  32%|███▏      | 84/266 [03:23<07:46,  2.57s/it]predicting train subjects:  32%|███▏      | 85/266 [03:26<07:48,  2.59s/it]predicting train subjects:  32%|███▏      | 86/266 [03:28<07:46,  2.59s/it]predicting train subjects:  33%|███▎      | 87/266 [03:31<07:49,  2.62s/it]predicting train subjects:  33%|███▎      | 88/266 [03:34<07:52,  2.65s/it]predicting train subjects:  33%|███▎      | 89/266 [03:36<07:53,  2.68s/it]predicting train subjects:  34%|███▍      | 90/266 [03:39<07:51,  2.68s/it]predicting train subjects:  34%|███▍      | 91/266 [03:41<07:42,  2.64s/it]predicting train subjects:  35%|███▍      | 92/266 [03:44<07:35,  2.62s/it]predicting train subjects:  35%|███▍      | 93/266 [03:47<07:33,  2.62s/it]predicting train subjects:  35%|███▌      | 94/266 [03:49<07:29,  2.61s/it]predicting train subjects:  36%|███▌      | 95/266 [03:52<07:21,  2.58s/it]predicting train subjects:  36%|███▌      | 96/266 [03:54<07:01,  2.48s/it]predicting train subjects:  36%|███▋      | 97/266 [03:57<07:13,  2.56s/it]predicting train subjects:  37%|███▋      | 98/266 [03:59<07:10,  2.56s/it]predicting train subjects:  37%|███▋      | 99/266 [04:01<06:34,  2.36s/it]predicting train subjects:  38%|███▊      | 100/266 [04:03<06:19,  2.29s/it]predicting train subjects:  38%|███▊      | 101/266 [04:06<06:20,  2.31s/it]predicting train subjects:  38%|███▊      | 102/266 [04:08<06:25,  2.35s/it]predicting train subjects:  39%|███▊      | 103/266 [04:10<06:18,  2.32s/it]predicting train subjects:  39%|███▉      | 104/266 [04:13<06:17,  2.33s/it]predicting train subjects:  39%|███▉      | 105/266 [04:15<06:15,  2.33s/it]predicting train subjects:  40%|███▉      | 106/266 [04:17<06:08,  2.30s/it]predicting train subjects:  40%|████      | 107/266 [04:20<06:05,  2.30s/it]predicting train subjects:  41%|████      | 108/266 [04:22<06:09,  2.34s/it]predicting train subjects:  41%|████      | 109/266 [04:24<06:04,  2.32s/it]predicting train subjects:  41%|████▏     | 110/266 [04:27<06:05,  2.34s/it]predicting train subjects:  42%|████▏     | 111/266 [04:29<06:03,  2.35s/it]predicting train subjects:  42%|████▏     | 112/266 [04:31<06:01,  2.34s/it]predicting train subjects:  42%|████▏     | 113/266 [04:34<06:02,  2.37s/it]predicting train subjects:  43%|████▎     | 114/266 [04:36<05:59,  2.37s/it]predicting train subjects:  43%|████▎     | 115/266 [04:39<06:01,  2.39s/it]predicting train subjects:  44%|████▎     | 116/266 [04:41<05:57,  2.39s/it]predicting train subjects:  44%|████▍     | 117/266 [04:43<05:56,  2.39s/it]predicting train subjects:  44%|████▍     | 118/266 [04:46<05:58,  2.42s/it]predicting train subjects:  45%|████▍     | 119/266 [04:49<06:16,  2.56s/it]predicting train subjects:  45%|████▌     | 120/266 [04:52<06:21,  2.61s/it]predicting train subjects:  45%|████▌     | 121/266 [04:54<06:26,  2.67s/it]predicting train subjects:  46%|████▌     | 122/266 [04:57<06:31,  2.72s/it]predicting train subjects:  46%|████▌     | 123/266 [05:00<06:28,  2.71s/it]predicting train subjects:  47%|████▋     | 124/266 [05:03<06:31,  2.75s/it]predicting train subjects:  47%|████▋     | 125/266 [05:05<06:26,  2.74s/it]predicting train subjects:  47%|████▋     | 126/266 [05:08<06:23,  2.74s/it]predicting train subjects:  48%|████▊     | 127/266 [05:11<06:20,  2.74s/it]predicting train subjects:  48%|████▊     | 128/266 [05:14<06:12,  2.70s/it]predicting train subjects:  48%|████▊     | 129/266 [05:16<06:16,  2.75s/it]predicting train subjects:  49%|████▉     | 130/266 [05:19<06:10,  2.73s/it]predicting train subjects:  49%|████▉     | 131/266 [05:22<06:10,  2.75s/it]predicting train subjects:  50%|████▉     | 132/266 [05:25<06:03,  2.71s/it]predicting train subjects:  50%|█████     | 133/266 [05:27<06:03,  2.73s/it]predicting train subjects:  50%|█████     | 134/266 [05:30<05:59,  2.72s/it]predicting train subjects:  51%|█████     | 135/266 [05:33<05:53,  2.70s/it]predicting train subjects:  51%|█████     | 136/266 [05:35<05:52,  2.71s/it]predicting train subjects:  52%|█████▏    | 137/266 [05:38<05:43,  2.67s/it]predicting train subjects:  52%|█████▏    | 138/266 [05:41<05:42,  2.67s/it]predicting train subjects:  52%|█████▏    | 139/266 [05:43<05:46,  2.73s/it]predicting train subjects:  53%|█████▎    | 140/266 [05:46<05:40,  2.70s/it]predicting train subjects:  53%|█████▎    | 141/266 [05:49<05:36,  2.69s/it]predicting train subjects:  53%|█████▎    | 142/266 [05:51<05:32,  2.68s/it]predicting train subjects:  54%|█████▍    | 143/266 [05:54<05:27,  2.66s/it]predicting train subjects:  54%|█████▍    | 144/266 [05:57<05:21,  2.63s/it]predicting train subjects:  55%|█████▍    | 145/266 [05:59<05:17,  2.63s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:02<05:13,  2.62s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:04<05:08,  2.59s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:07<05:09,  2.62s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:10<05:09,  2.64s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:12<05:06,  2.64s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:15<05:02,  2.63s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:18<04:58,  2.62s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:20<04:56,  2.63s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:23<04:55,  2.64s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:25<04:31,  2.44s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:27<04:13,  2.30s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:29<04:00,  2.21s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:31<03:50,  2.13s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:33<03:53,  2.18s/it]predicting train subjects:  60%|██████    | 160/266 [06:36<04:00,  2.26s/it]predicting train subjects:  61%|██████    | 161/266 [06:38<04:01,  2.30s/it]predicting train subjects:  61%|██████    | 162/266 [06:40<03:59,  2.31s/it]predicting train subjects:  61%|██████▏   | 163/266 [06:43<04:00,  2.34s/it]predicting train subjects:  62%|██████▏   | 164/266 [06:45<03:59,  2.35s/it]predicting train subjects:  62%|██████▏   | 165/266 [06:47<03:55,  2.34s/it]predicting train subjects:  62%|██████▏   | 166/266 [06:50<03:59,  2.40s/it]predicting train subjects:  63%|██████▎   | 167/266 [06:52<03:58,  2.41s/it]predicting train subjects:  63%|██████▎   | 168/266 [06:55<04:01,  2.47s/it]predicting train subjects:  64%|██████▎   | 169/266 [06:58<04:07,  2.55s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:00<04:01,  2.51s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:02<03:55,  2.47s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:05<03:51,  2.47s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:08<04:03,  2.62s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:11<04:08,  2.70s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:13<03:59,  2.63s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:16<03:58,  2.65s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:19<03:56,  2.66s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:21<03:55,  2.68s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:24<03:57,  2.73s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:27<03:55,  2.73s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:30<03:52,  2.73s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:33<03:52,  2.77s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:35<03:48,  2.75s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:38<03:44,  2.74s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:41<03:40,  2.73s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:43<03:39,  2.75s/it]predicting train subjects:  70%|███████   | 187/266 [07:46<03:36,  2.74s/it]predicting train subjects:  71%|███████   | 188/266 [07:49<03:34,  2.75s/it]predicting train subjects:  71%|███████   | 189/266 [07:52<03:36,  2.81s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:55<03:38,  2.88s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:58<03:40,  2.94s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:01<03:32,  2.87s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:03<03:24,  2.81s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:07<03:37,  3.03s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:10<03:31,  2.98s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:13<03:29,  3.00s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:16<03:28,  3.03s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:19<03:27,  3.05s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:22<03:23,  3.04s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:25<03:20,  3.04s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:28<03:16,  3.02s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:31<03:12,  3.00s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:34<03:09,  3.01s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:37<03:07,  3.02s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:40<02:53,  2.85s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:42<02:42,  2.71s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:44<02:33,  2.60s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:48<02:42,  2.81s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:50<02:42,  2.85s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:53<02:38,  2.83s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:56<02:36,  2.85s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:59<02:36,  2.90s/it]predicting train subjects:  80%|████████  | 213/266 [09:02<02:30,  2.83s/it]predicting train subjects:  80%|████████  | 214/266 [09:04<02:22,  2.74s/it]predicting train subjects:  81%|████████  | 215/266 [09:07<02:15,  2.66s/it]predicting train subjects:  81%|████████  | 216/266 [09:09<02:11,  2.63s/it]predicting train subjects:  82%|████████▏ | 217/266 [09:12<02:08,  2.63s/it]predicting train subjects:  82%|████████▏ | 218/266 [09:15<02:09,  2.70s/it]predicting train subjects:  82%|████████▏ | 219/266 [09:18<02:07,  2.70s/it]predicting train subjects:  83%|████████▎ | 220/266 [09:20<02:02,  2.67s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:23<01:59,  2.66s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:26<01:57,  2.67s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:28<01:55,  2.69s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:31<01:52,  2.69s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:34<01:52,  2.73s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:36<01:48,  2.70s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:39<01:45,  2.71s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:42<01:43,  2.73s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:45<01:39,  2.68s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:47<01:36,  2.67s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:50<01:33,  2.67s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:53<01:32,  2.71s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:55<01:30,  2.74s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:58<01:27,  2.73s/it]predicting train subjects:  88%|████████▊ | 235/266 [10:01<01:23,  2.70s/it]predicting train subjects:  89%|████████▊ | 236/266 [10:04<01:22,  2.74s/it]predicting train subjects:  89%|████████▉ | 237/266 [10:06<01:17,  2.69s/it]predicting train subjects:  89%|████████▉ | 238/266 [10:09<01:15,  2.71s/it]predicting train subjects:  90%|████████▉ | 239/266 [10:12<01:12,  2.68s/it]predicting train subjects:  90%|█████████ | 240/266 [10:14<01:09,  2.69s/it]predicting train subjects:  91%|█████████ | 241/266 [10:17<01:07,  2.69s/it]predicting train subjects:  91%|█████████ | 242/266 [10:20<01:05,  2.72s/it]predicting train subjects:  91%|█████████▏| 243/266 [10:22<01:01,  2.68s/it]predicting train subjects:  92%|█████████▏| 244/266 [10:25<01:00,  2.74s/it]predicting train subjects:  92%|█████████▏| 245/266 [10:28<00:57,  2.75s/it]predicting train subjects:  92%|█████████▏| 246/266 [10:31<00:54,  2.75s/it]predicting train subjects:  93%|█████████▎| 247/266 [10:33<00:51,  2.73s/it]predicting train subjects:  93%|█████████▎| 248/266 [10:36<00:49,  2.73s/it]predicting train subjects:  94%|█████████▎| 249/266 [10:40<00:51,  3.04s/it]predicting train subjects:  94%|█████████▍| 250/266 [10:43<00:50,  3.15s/it]predicting train subjects:  94%|█████████▍| 251/266 [10:47<00:49,  3.33s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:51<00:47,  3.39s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:54<00:44,  3.46s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:58<00:41,  3.43s/it]predicting train subjects:  96%|█████████▌| 255/266 [11:01<00:38,  3.46s/it]predicting train subjects:  96%|█████████▌| 256/266 [11:05<00:34,  3.46s/it]predicting train subjects:  97%|█████████▋| 257/266 [11:08<00:31,  3.45s/it]predicting train subjects:  97%|█████████▋| 258/266 [11:11<00:27,  3.43s/it]predicting train subjects:  97%|█████████▋| 259/266 [11:15<00:23,  3.39s/it]predicting train subjects:  98%|█████████▊| 260/266 [11:18<00:20,  3.35s/it]predicting train subjects:  98%|█████████▊| 261/266 [11:21<00:16,  3.26s/it]predicting train subjects:  98%|█████████▊| 262/266 [11:24<00:13,  3.32s/it]predicting train subjects:  99%|█████████▉| 263/266 [11:28<00:09,  3.29s/it]predicting train subjects:  99%|█████████▉| 264/266 [11:30<00:06,  3.08s/it]predicting train subjects: 100%|█████████▉| 265/266 [11:33<00:03,  3.01s/it]predicting train subjects: 100%|██████████| 266/266 [11:36<00:00,  3.01s/it]
Loading train:   0%|          | 0/266 [00:00<?, ?it/s]Loading train:   0%|          | 1/266 [00:02<09:22,  2.12s/it]Loading train:   1%|          | 2/266 [00:04<09:16,  2.11s/it]Loading train:   1%|          | 3/266 [00:05<08:44,  1.99s/it]Loading train:   2%|▏         | 4/266 [00:07<08:16,  1.90s/it]Loading train:   2%|▏         | 5/266 [00:09<08:09,  1.87s/it]Loading train:   2%|▏         | 6/266 [00:10<07:32,  1.74s/it]Loading train:   3%|▎         | 7/266 [00:12<06:54,  1.60s/it]Loading train:   3%|▎         | 8/266 [00:13<06:24,  1.49s/it]Loading train:   3%|▎         | 9/266 [00:14<05:56,  1.39s/it]Loading train:   4%|▍         | 10/266 [00:15<05:43,  1.34s/it]Loading train:   4%|▍         | 11/266 [00:16<05:25,  1.28s/it]Loading train:   5%|▍         | 12/266 [00:17<05:12,  1.23s/it]Loading train:   5%|▍         | 13/266 [00:19<05:03,  1.20s/it]Loading train:   5%|▌         | 14/266 [00:20<04:59,  1.19s/it]Loading train:   6%|▌         | 15/266 [00:21<04:53,  1.17s/it]Loading train:   6%|▌         | 16/266 [00:22<05:06,  1.22s/it]Loading train:   6%|▋         | 17/266 [00:23<04:56,  1.19s/it]Loading train:   7%|▋         | 18/266 [00:24<04:48,  1.16s/it]Loading train:   7%|▋         | 19/266 [00:26<04:39,  1.13s/it]Loading train:   8%|▊         | 20/266 [00:26<04:26,  1.08s/it]Loading train:   8%|▊         | 21/266 [00:28<04:43,  1.16s/it]Loading train:   8%|▊         | 22/266 [00:29<04:35,  1.13s/it]Loading train:   9%|▊         | 23/266 [00:30<04:36,  1.14s/it]Loading train:   9%|▉         | 24/266 [00:31<04:34,  1.14s/it]Loading train:   9%|▉         | 25/266 [00:33<04:50,  1.20s/it]Loading train:  10%|▉         | 26/266 [00:34<04:33,  1.14s/it]Loading train:  10%|█         | 27/266 [00:35<04:36,  1.16s/it]Loading train:  11%|█         | 28/266 [00:36<04:51,  1.22s/it]Loading train:  11%|█         | 29/266 [00:37<04:34,  1.16s/it]Loading train:  11%|█▏        | 30/266 [00:38<04:37,  1.18s/it]Loading train:  12%|█▏        | 31/266 [00:39<04:24,  1.13s/it]Loading train:  12%|█▏        | 32/266 [00:41<04:28,  1.15s/it]Loading train:  12%|█▏        | 33/266 [00:42<04:23,  1.13s/it]Loading train:  13%|█▎        | 34/266 [00:43<04:24,  1.14s/it]Loading train:  13%|█▎        | 35/266 [00:44<04:14,  1.10s/it]Loading train:  14%|█▎        | 36/266 [00:45<04:23,  1.15s/it]Loading train:  14%|█▍        | 37/266 [00:46<04:25,  1.16s/it]Loading train:  14%|█▍        | 38/266 [00:47<04:29,  1.18s/it]Loading train:  15%|█▍        | 39/266 [00:49<04:41,  1.24s/it]Loading train:  15%|█▌        | 40/266 [00:50<04:28,  1.19s/it]Loading train:  15%|█▌        | 41/266 [00:51<04:21,  1.16s/it]Loading train:  16%|█▌        | 42/266 [00:53<04:57,  1.33s/it]Loading train:  16%|█▌        | 43/266 [00:54<05:07,  1.38s/it]Loading train:  17%|█▋        | 44/266 [00:55<04:41,  1.27s/it]Loading train:  17%|█▋        | 45/266 [00:56<04:16,  1.16s/it]Loading train:  17%|█▋        | 46/266 [00:57<04:18,  1.17s/it]Loading train:  18%|█▊        | 47/266 [00:58<04:12,  1.15s/it]Loading train:  18%|█▊        | 48/266 [00:59<03:55,  1.08s/it]Loading train:  18%|█▊        | 49/266 [01:00<03:52,  1.07s/it]Loading train:  19%|█▉        | 50/266 [01:01<03:50,  1.07s/it]Loading train:  19%|█▉        | 51/266 [01:03<03:55,  1.09s/it]Loading train:  20%|█▉        | 52/266 [01:04<03:53,  1.09s/it]Loading train:  20%|█▉        | 53/266 [01:05<04:07,  1.16s/it]Loading train:  20%|██        | 54/266 [01:06<03:58,  1.12s/it]Loading train:  21%|██        | 55/266 [01:07<03:49,  1.09s/it]Loading train:  21%|██        | 56/266 [01:08<03:50,  1.10s/it]Loading train:  21%|██▏       | 57/266 [01:09<03:57,  1.14s/it]Loading train:  22%|██▏       | 58/266 [01:11<04:05,  1.18s/it]Loading train:  22%|██▏       | 59/266 [01:12<03:45,  1.09s/it]Loading train:  23%|██▎       | 60/266 [01:12<03:29,  1.02s/it]Loading train:  23%|██▎       | 61/266 [01:13<03:26,  1.01s/it]Loading train:  23%|██▎       | 62/266 [01:14<03:26,  1.01s/it]Loading train:  24%|██▎       | 63/266 [01:16<03:29,  1.03s/it]Loading train:  24%|██▍       | 64/266 [01:17<03:32,  1.05s/it]Loading train:  24%|██▍       | 65/266 [01:18<03:25,  1.02s/it]Loading train:  25%|██▍       | 66/266 [01:18<03:12,  1.04it/s]Loading train:  25%|██▌       | 67/266 [01:19<03:08,  1.06it/s]Loading train:  26%|██▌       | 68/266 [01:21<03:27,  1.05s/it]Loading train:  26%|██▌       | 69/266 [01:22<03:41,  1.12s/it]Loading train:  26%|██▋       | 70/266 [01:23<03:34,  1.09s/it]Loading train:  27%|██▋       | 71/266 [01:24<03:32,  1.09s/it]Loading train:  27%|██▋       | 72/266 [01:25<03:18,  1.02s/it]Loading train:  27%|██▋       | 73/266 [01:26<03:05,  1.04it/s]Loading train:  28%|██▊       | 74/266 [01:27<03:04,  1.04it/s]Loading train:  28%|██▊       | 75/266 [01:28<03:05,  1.03it/s]Loading train:  29%|██▊       | 76/266 [01:29<03:04,  1.03it/s]Loading train:  29%|██▉       | 77/266 [01:30<03:08,  1.01it/s]Loading train:  29%|██▉       | 78/266 [01:31<03:17,  1.05s/it]Loading train:  30%|██▉       | 79/266 [01:32<03:21,  1.08s/it]Loading train:  30%|███       | 80/266 [01:33<03:21,  1.08s/it]Loading train:  30%|███       | 81/266 [01:34<03:24,  1.11s/it]Loading train:  31%|███       | 82/266 [01:35<03:19,  1.08s/it]Loading train:  31%|███       | 83/266 [01:36<03:16,  1.08s/it]Loading train:  32%|███▏      | 84/266 [01:37<03:13,  1.06s/it]Loading train:  32%|███▏      | 85/266 [01:38<03:06,  1.03s/it]Loading train:  32%|███▏      | 86/266 [01:40<03:16,  1.09s/it]Loading train:  33%|███▎      | 87/266 [01:41<03:14,  1.08s/it]Loading train:  33%|███▎      | 88/266 [01:42<03:13,  1.09s/it]Loading train:  33%|███▎      | 89/266 [01:43<03:19,  1.13s/it]Loading train:  34%|███▍      | 90/266 [01:44<03:16,  1.12s/it]Loading train:  34%|███▍      | 91/266 [01:45<03:14,  1.11s/it]Loading train:  35%|███▍      | 92/266 [01:46<03:10,  1.10s/it]Loading train:  35%|███▍      | 93/266 [01:47<03:10,  1.10s/it]Loading train:  35%|███▌      | 94/266 [01:48<03:11,  1.11s/it]Loading train:  36%|███▌      | 95/266 [01:50<03:13,  1.13s/it]Loading train:  36%|███▌      | 96/266 [01:51<03:31,  1.24s/it]Loading train:  36%|███▋      | 97/266 [01:53<03:51,  1.37s/it]
Epoch 00059: val_mDice did not improve from 0.60932
Restoring model weights from the end of the best epoch
Epoch 00059: early stopping
{'val_loss': [1.151163095673814, 0.9938099999397326, 0.926583936800972, 1.0012370443191771, 0.9985749632024917, 0.9561684992366706, 0.8833446597900635, 0.9163802062360623, 0.9494067518094096, 0.868732528374218, 0.8517082735372428, 0.8597443911214225, 1.2168366175870926, 0.9485249881165477, 0.8202231118854243, 0.7916822945728851, 0.8884740869838971, 0.8780074675623982, 0.7425036001890993, 0.7262702496668783, 0.7177847806638041, 0.6925666292254536, 0.6400157929228517, 0.6753026201321294, 0.7990188025437985, 0.7809287372488565, 0.5748741634356709, 0.6069993479564167, 0.701650259403375, 0.6370830705371527, 0.6561367900226824, 0.6309016305036819, 0.607288828292213, 0.5912563918878476, 0.5799487351228635, 0.5512729205262547, 0.5352063565589369, 0.8663532745343047, 0.5406747087122152, 0.5212871796026016, 0.5385011701157298, 0.6870498518212534, 0.5552500697751396, 0.5357949105314553, 0.5322375361340496, 0.8112865448378908, 0.5582511426922613, 0.5695862341612673, 0.6232480010666406, 0.4927243990258287, 0.5309651330256233, 0.46771378662829965, 0.5271847301397842, 0.47104406204467386, 0.7122877727682217, 0.46377062273863406, 0.5141835229846236, 0.4778205719999612, 0.5781720353010744], 'val_acc': [0.9449009788683809, 0.9511768242802483, 0.9531262802620666, 0.9470334630042981, 0.9483083412289238, 0.9481125053125449, 0.9504907428266142, 0.9510629114251548, 0.9498136395844408, 0.9501541165498119, 0.9480549028506294, 0.9485592316514768, 0.9466853000866339, 0.9506097828237393, 0.9504677095352271, 0.9515736375373012, 0.9491851411688442, 0.9481790631343001, 0.9527896377986993, 0.9508197141912418, 0.9503717133031485, 0.9497329996416743, 0.9521240428232918, 0.9507160257226743, 0.9504933113488145, 0.9506200300618863, 0.9514878759749781, 0.9517541192591, 0.9506353958727072, 0.9528536402379362, 0.9495000382200979, 0.9506021180091956, 0.9500952319215281, 0.9505355571405575, 0.9502590757589371, 0.9508030719269579, 0.951343230546092, 0.9327025636316488, 0.9523685241278749, 0.9523032378083982, 0.9518577884942198, 0.9468888187179931, 0.9521637166650913, 0.9519704422249962, 0.9530046755513444, 0.9495435564662702, 0.9518795495216077, 0.9514341095385079, 0.9478449901452841, 0.9511691604178554, 0.9520626020507691, 0.9519755436589543, 0.9505201909488763, 0.950461321935867, 0.9486577893598392, 0.950408825668664, 0.9503077043892857, 0.9540094900816775, 0.9529061245080381], 'val_mDice': [0.5580515370201379, 0.5794588484988806, 0.5849566544873265, 0.5891113470728024, 0.5886536541457374, 0.5877638178797194, 0.5920480725388176, 0.6001473601443318, 0.6023550724354796, 0.5980765299675183, 0.5946156545378529, 0.5893875549014765, 0.5624304355714268, 0.5946977359418291, 0.5972434638407284, 0.5924662160702026, 0.5989687010026968, 0.5874896584132228, 0.6093200048604331, 0.6008747086738245, 0.5919618868408874, 0.5949678673340489, 0.5981781307500772, 0.599308248859244, 0.5859240323971635, 0.593941999033998, 0.5993569281916268, 0.6070887110294244, 0.5974856807401006, 0.5992413602126673, 0.6022173725187588, 0.5953508373647453, 0.5934584917732701, 0.5938832584185342, 0.5962959042372414, 0.6006361808830176, 0.5950968175079114, 0.5186412059270535, 0.5993957194847802, 0.6035592974946141, 0.598469318958898, 0.5746171180242167, 0.5950113012196537, 0.5959080741428339, 0.5809224745907342, 0.5895577706753636, 0.5938828267133274, 0.5932434301216382, 0.5866783936374104, 0.5950802709347904, 0.5917562019710724, 0.5964702423959495, 0.595552500158834, 0.6034564514891408, 0.5959768552368823, 0.5960915646613977, 0.5946434182100022, 0.5788225422080714, 0.5774546285597281], 'loss': [1.2473444631029602, 0.4889012655558447, 0.3909710313518237, 0.39898605769099194, 0.33900249979476016, 0.31099112049820204, 0.30101142300070494, 0.30188815524078677, 0.29295961163460343, 0.30973924906001293, 0.2682215037695955, 0.25059851291983676, 0.3030042509280153, 0.3060633498875756, 0.27186365012281377, 0.2627865245451625, 0.2519427471901847, 0.24112785106560236, 0.2352565296362896, 0.23182684989849078, 0.2644412160898018, 0.22831878262422545, 0.24194082427030472, 0.22891982377441142, 0.27117913452388687, 0.24301879532870105, 0.22871548933619126, 0.22305419522033332, 0.23569227325225162, 0.2521014598275543, 0.24999385405134347, 0.22455656600612187, 0.22908735759657464, 0.2117328784505625, 0.2173917087335797, 0.21406275027440674, 0.2452213566071563, 0.22152016070393268, 0.24168613195517843, 0.21237600574436824, 0.22380189984871457, 0.2527434636663555, 0.2172043939920648, 0.20802218406030654, 0.22152078255689023, 0.21602083345500592, 0.20943058741980874, 0.20279571272178556, 0.23557148882251575, 0.21154420500959242, 0.20161731570012484, 0.19685655693642462, 0.22066730106189408, 0.2228565069868033, 0.20182164789674864, 0.20879650905803998, 0.20197199087439102, 0.2030642927924609, 0.21411353054618396], 'acc': [0.8189421880615054, 0.92324945100126, 0.9368013751057782, 0.9394846838682429, 0.9443715200371832, 0.9472150615965099, 0.9486776443535047, 0.9485447100194431, 0.949633192609257, 0.9474682211664777, 0.9512050788762058, 0.9525221680677096, 0.9481752200452647, 0.9484249774491101, 0.9515766489743651, 0.9517324075379047, 0.9530499710328943, 0.9540034636497948, 0.9544683234133368, 0.9549239582724914, 0.9531721434664706, 0.9549058634453054, 0.9539897677002894, 0.9552898272275503, 0.9524679304590922, 0.9543358632631153, 0.955183671137028, 0.9555009096625113, 0.9546690927104723, 0.9537735280946683, 0.9529529688053985, 0.9554670405142957, 0.955742719379222, 0.9565595662330622, 0.9566502524725675, 0.9571224225357075, 0.9541201447916926, 0.9560131499386971, 0.9540514779043023, 0.9568270392085152, 0.9559376696893352, 0.9550704670594257, 0.9563121046461425, 0.9573633796505191, 0.956190503323454, 0.95648824975769, 0.9569159757923469, 0.957741597345129, 0.9566717314486493, 0.9569365304847129, 0.9579999852749149, 0.9583330737233993, 0.9571865236960472, 0.9565978831729129, 0.9580903881372309, 0.9574438255952823, 0.9581189167543178, 0.9580485934363246, 0.9571226823004771], 'mDice': [0.38508120998924944, 0.6049063909200193, 0.6683556936766606, 0.6730895919703526, 0.7026452976101362, 0.7246548213493108, 0.735925696171756, 0.7357530855473753, 0.7425301486914605, 0.7274035914530649, 0.7554426597850722, 0.7669704726784242, 0.7369717138057645, 0.7314786128387469, 0.7580888904398004, 0.7596046571002996, 0.7713291376551147, 0.7775631163052423, 0.7817708499063665, 0.7850440881274529, 0.7673344927282285, 0.784931149958776, 0.7805551626857105, 0.7868374216681825, 0.7633070411486754, 0.77873001531187, 0.785505973056886, 0.7905343932643214, 0.7818578793315908, 0.7742117837182267, 0.7717205239645719, 0.7907930948346068, 0.7909960156489831, 0.7989012246810921, 0.7979351058452776, 0.8012596569160937, 0.7805483903903468, 0.7941487700095465, 0.7779220788843981, 0.8008825445924012, 0.7911830188983418, 0.7809392269562205, 0.7946009755782076, 0.8044103474104076, 0.7953278393148039, 0.7964741134463382, 0.8006894187587171, 0.8089695765412196, 0.7990153011302765, 0.7998152883504102, 0.8092274052050364, 0.8115599051897353, 0.8031510652301022, 0.7969159381225492, 0.8103404835892309, 0.8052993590624277, 0.8099782879947419, 0.8096023417656503, 0.8015439134869276]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 0  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp6
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 7.0      2-AVLoading train:  37%|███▋      | 98/266 [01:55<04:10,  1.49s/it]Loading train:  37%|███▋      | 99/266 [01:56<03:56,  1.42s/it]Loading train:  38%|███▊      | 100/266 [01:57<03:48,  1.38s/it]Loading train:  38%|███▊      | 101/266 [01:58<03:29,  1.27s/it]Loading train:  38%|███▊      | 102/266 [01:59<03:09,  1.15s/it]Loading train:  39%|███▊      | 103/266 [02:00<03:00,  1.10s/it]Loading train:  39%|███▉      | 104/266 [02:01<03:03,  1.13s/it]Loading train:  39%|███▉      | 105/266 [02:02<02:53,  1.08s/it]Loading train:  40%|███▉      | 106/266 [02:03<02:45,  1.04s/it]Loading train:  40%|████      | 107/266 [02:04<02:50,  1.07s/it]Loading train:  41%|████      | 108/266 [02:05<02:57,  1.12s/it]Loading train:  41%|████      | 109/266 [02:06<02:42,  1.03s/it]Loading train:  41%|████▏     | 110/266 [02:08<02:51,  1.10s/it]Loading train:  42%|████▏     | 111/266 [02:09<02:59,  1.16s/it]Loading train:  42%|████▏     | 112/266 [02:10<02:49,  1.10s/it]Loading train:  42%|████▏     | 113/266 [02:11<02:42,  1.06s/it]Loading train:  43%|████▎     | 114/266 [02:12<02:41,  1.06s/it]Loading train:  43%|████▎     | 115/266 [02:13<02:42,  1.08s/it]Loading train:  44%|████▎     | 116/266 [02:14<02:53,  1.15s/it]Loading train:  44%|████▍     | 117/266 [02:15<02:39,  1.07s/it]Loading train:  44%|████▍     | 118/266 [02:16<02:32,  1.03s/it]Loading train:  45%|████▍     | 119/266 [02:17<02:43,  1.11s/it]Loading train:  45%|████▌     | 120/266 [02:19<02:47,  1.15s/it]Loading train:  45%|████▌     | 121/266 [02:20<02:44,  1.14s/it]Loading train:  46%|████▌     | 122/266 [02:21<02:51,  1.19s/it]Loading train:  46%|████▌     | 123/266 [02:22<02:51,  1.20s/it]Loading train:  47%|████▋     | 124/266 [02:23<02:44,  1.16s/it]Loading train:  47%|████▋     | 125/266 [02:24<02:37,  1.11s/it]Loading train:  47%|████▋     | 126/266 [02:25<02:34,  1.10s/it]Loading train:  48%|████▊     | 127/266 [02:27<02:34,  1.11s/it]Loading train:  48%|████▊     | 128/266 [02:28<02:34,  1.12s/it]Loading train:  48%|████▊     | 129/266 [02:29<02:51,  1.25s/it]Loading train:  49%|████▉     | 130/266 [02:30<02:40,  1.18s/it]Loading train:  49%|████▉     | 131/266 [02:31<02:26,  1.09s/it]Loading train:  50%|████▉     | 132/266 [02:32<02:15,  1.01s/it]Loading train:  50%|█████     | 133/266 [02:33<02:23,  1.08s/it]Loading train:  50%|█████     | 134/266 [02:34<02:18,  1.05s/it]Loading train:  51%|█████     | 135/266 [02:35<02:23,  1.10s/it]Loading train:  51%|█████     | 136/266 [02:37<02:28,  1.14s/it]Loading train:  52%|█████▏    | 137/266 [02:38<02:33,  1.19s/it]Loading train:  52%|█████▏    | 138/266 [02:39<02:32,  1.19s/it]Loading train:  52%|█████▏    | 139/266 [02:40<02:30,  1.19s/it]Loading train:  53%|█████▎    | 140/266 [02:41<02:22,  1.13s/it]Loading train:  53%|█████▎    | 141/266 [02:42<02:10,  1.05s/it]Loading train:  53%|█████▎    | 142/266 [02:43<02:01,  1.02it/s]Loading train:  54%|█████▍    | 143/266 [02:44<01:52,  1.10it/s]Loading train:  54%|█████▍    | 144/266 [02:44<01:45,  1.15it/s]Loading train:  55%|█████▍    | 145/266 [02:45<01:42,  1.18it/s]Loading train:  55%|█████▍    | 146/266 [02:46<01:39,  1.20it/s]Loading train:  55%|█████▌    | 147/266 [02:47<01:38,  1.21it/s]Loading train:  56%|█████▌    | 148/266 [02:48<01:34,  1.24it/s]Loading train:  56%|█████▌    | 149/266 [02:48<01:33,  1.25it/s]Loading train:  56%|█████▋    | 150/266 [02:49<01:32,  1.26it/s]Loading train:  57%|█████▋    | 151/266 [02:50<01:33,  1.23it/s]Loading train:  57%|█████▋    | 152/266 [02:51<01:31,  1.24it/s]Loading train:  58%|█████▊    | 153/266 [02:52<01:31,  1.23it/s]Loading train:  58%|█████▊    | 154/266 [02:52<01:30,  1.24it/s]Loading train:  58%|█████▊    | 155/266 [02:53<01:26,  1.28it/s]Loading train:  59%|█████▊    | 156/266 [02:54<01:22,  1.33it/s]Loading train:  59%|█████▉    | 157/266 [02:55<01:18,  1.39it/s]Loading train:  59%|█████▉    | 158/266 [02:55<01:15,  1.44it/s]Loading train:  60%|█████▉    | 159/266 [02:56<01:11,  1.50it/s]Loading train:  60%|██████    | 160/266 [02:56<01:07,  1.57it/s]Loading train:  61%|██████    | 161/266 [02:57<01:05,  1.59it/s]Loading train:  61%|██████    | 162/266 [02:58<01:06,  1.55it/s]Loading train:  61%|██████▏   | 163/266 [02:58<01:08,  1.50it/s]Loading train:  62%|██████▏   | 164/266 [02:59<01:08,  1.50it/s]Loading train:  62%|██████▏   | 165/266 [03:00<01:07,  1.49it/s]Loading train:  62%|██████▏   | 166/266 [03:00<01:07,  1.48it/s]Loading train:  63%|██████▎   | 167/266 [03:01<01:08,  1.45it/s]Loading train:  63%|██████▎   | 168/266 [03:02<01:08,  1.43it/s]Loading train:  64%|██████▎   | 169/266 [03:02<01:06,  1.45it/s]Loading train:  64%|██████▍   | 170/266 [03:03<01:06,  1.45it/s]Loading train:  64%|██████▍   | 171/266 [03:04<01:06,  1.44it/s]Loading train:  65%|██████▍   | 172/266 [03:05<01:06,  1.41it/s]Loading train:  65%|██████▌   | 173/266 [03:05<01:09,  1.33it/s]Loading train:  65%|██████▌   | 174/266 [03:06<01:08,  1.34it/s]Loading train:  66%|██████▌   | 175/266 [03:07<01:05,  1.39it/s]Loading train:  66%|██████▌   | 176/266 [03:08<01:03,  1.41it/s]Loading train:  67%|██████▋   | 177/266 [03:08<01:01,  1.45it/s]Loading train:  67%|██████▋   | 178/266 [03:09<01:01,  1.44it/s]Loading train:  67%|██████▋   | 179/266 [03:10<01:01,  1.42it/s]Loading train:  68%|██████▊   | 180/266 [03:10<00:58,  1.46it/s]Loading train:  68%|██████▊   | 181/266 [03:11<01:00,  1.40it/s]Loading train:  68%|██████▊   | 182/266 [03:12<00:59,  1.41it/s]Loading train:  69%|██████▉   | 183/266 [03:12<00:58,  1.42it/s]Loading train:  69%|██████▉   | 184/266 [03:13<00:59,  1.39it/s]Loading train:  70%|██████▉   | 185/266 [03:14<00:56,  1.43it/s]Loading train:  70%|██████▉   | 186/266 [03:15<00:54,  1.46it/s]Loading train:  70%|███████   | 187/266 [03:15<00:54,  1.45it/s]Loading train:  71%|███████   | 188/266 [03:16<00:53,  1.46it/s]Loading train:  71%|███████   | 189/266 [03:17<00:52,  1.48it/s]Loading train:  71%|███████▏  | 190/266 [03:17<00:50,  1.50it/s]Loading train:  72%|███████▏  | 191/266 [03:18<01:03,  1.17it/s]Loading train:  72%|███████▏  | 192/266 [03:20<01:09,  1.06it/s]Loading train:  73%|███████▎  | 193/266 [03:21<01:14,  1.03s/it]Loading train:  73%|███████▎  | 194/266 [03:22<01:26,  1.20s/it]Loading train:  73%|███████▎  | 195/266 [03:23<01:16,  1.08s/it]Loading train:  74%|███████▎  | 196/266 [03:24<01:11,  1.02s/it]Loading train:  74%|███████▍  | 197/266 [03:25<01:06,  1.04it/s]Loading train:  74%|███████▍  | 198/266 [03:26<01:00,  1.12it/s]Loading train:  75%|███████▍  | 199/266 [03:27<00:58,  1.14it/s]Loading train:  75%|███████▌  | 200/266 [03:27<00:56,  1.16it/s]Loading train:  76%|███████▌  | 201/266 [03:28<00:53,  1.21it/s]Loading train:  76%|███████▌  | 202/266 [03:29<00:52,  1.22it/s]Loading train:  76%|███████▋  | 203/266 [03:30<00:50,  1.24it/s]Loading train:  77%|███████▋  | 204/266 [03:30<00:49,  1.24it/s]Loading train:  77%|███████▋  | 205/266 [03:31<00:49,  1.24it/s]Loading train:  77%|███████▋  | 206/266 [03:32<00:48,  1.23it/s]Loading train:  78%|███████▊  | 207/266 [03:33<00:47,  1.23it/s]Loading train:  78%|███████▊  | 208/266 [03:34<00:47,  1.21it/s]Loading train:  79%|███████▊  | 209/266 [03:35<00:46,  1.23it/s]Loading train:  79%|███████▉  | 210/266 [03:35<00:44,  1.26it/s]Loading train:  79%|███████▉  | 211/266 [03:36<00:42,  1.28it/s]Loading train:  80%|███████▉  | 212/266 [03:37<00:42,  1.27it/s]Loading train:  80%|████████  | 213/266 [03:38<00:41,  1.28it/s]Loading train:  80%|████████  | 214/266 [03:38<00:39,  1.32it/s]Loading train:  81%|████████  | 215/266 [03:39<00:38,  1.34it/s]Loading train:  81%|████████  | 216/266 [03:40<00:37,  1.33it/s]Loading train:  82%|████████▏ | 217/266 [03:41<00:36,  1.35it/s]Loading train:  82%|████████▏ | 218/266 [03:41<00:35,  1.37it/s]Loading train:  82%|████████▏ | 219/266 [03:42<00:33,  1.38it/s]Loading train:  83%|████████▎ | 220/266 [03:43<00:33,  1.37it/s]Loading train:  83%|████████▎ | 221/266 [03:43<00:32,  1.38it/s]Loading train:  83%|████████▎ | 222/266 [03:44<00:32,  1.36it/s]Loading train:  84%|████████▍ | 223/266 [03:45<00:31,  1.37it/s]Loading train:  84%|████████▍ | 224/266 [03:46<00:31,  1.35it/s]Loading train:  85%|████████▍ | 225/266 [03:46<00:30,  1.35it/s]Loading train:  85%|████████▍ | 226/266 [03:47<00:29,  1.34it/s]Loading train:  85%|████████▌ | 227/266 [03:48<00:28,  1.35it/s]Loading train:  86%|████████▌ | 228/266 [03:49<00:29,  1.31it/s]Loading train:  86%|████████▌ | 229/266 [03:49<00:27,  1.36it/s]Loading train:  86%|████████▋ | 230/266 [03:50<00:26,  1.33it/s]Loading train:  87%|████████▋ | 231/266 [03:51<00:26,  1.33it/s]Loading train:  87%|████████▋ | 232/266 [03:52<00:25,  1.35it/s]Loading train:  88%|████████▊ | 233/266 [03:52<00:24,  1.37it/s]Loading train:  88%|████████▊ | 234/266 [03:53<00:23,  1.36it/s]Loading train:  88%|████████▊ | 235/266 [03:54<00:22,  1.35it/s]Loading train:  89%|████████▊ | 236/266 [03:55<00:22,  1.34it/s]Loading train:  89%|████████▉ | 237/266 [03:55<00:21,  1.33it/s]Loading train:  89%|████████▉ | 238/266 [03:56<00:21,  1.31it/s]Loading train:  90%|████████▉ | 239/266 [03:57<00:20,  1.31it/s]Loading train:  90%|█████████ | 240/266 [03:58<00:20,  1.29it/s]Loading train:  91%|█████████ | 241/266 [03:58<00:19,  1.32it/s]Loading train:  91%|█████████ | 242/266 [03:59<00:18,  1.30it/s]Loading train:  91%|█████████▏| 243/266 [04:00<00:17,  1.29it/s]Loading train:  92%|█████████▏| 244/266 [04:01<00:16,  1.33it/s]Loading train:  92%|█████████▏| 245/266 [04:01<00:15,  1.38it/s]Loading train:  92%|█████████▏| 246/266 [04:02<00:14,  1.36it/s]Loading train:  93%|█████████▎| 247/266 [04:03<00:14,  1.34it/s]Loading train:  93%|█████████▎| 248/266 [04:04<00:13,  1.36it/s]Loading train:  94%|█████████▎| 249/266 [04:05<00:13,  1.25it/s]Loading train:  94%|█████████▍| 250/266 [04:05<00:13,  1.19it/s]Loading train:  94%|█████████▍| 251/266 [04:06<00:12,  1.17it/s]Loading train:  95%|█████████▍| 252/266 [04:07<00:12,  1.15it/s]Loading train:  95%|█████████▌| 253/266 [04:08<00:11,  1.12it/s]Loading train:  95%|█████████▌| 254/266 [04:09<00:10,  1.10it/s]Loading train:  96%|█████████▌| 255/266 [04:10<00:10,  1.08it/s]Loading train:  96%|█████████▌| 256/266 [04:11<00:09,  1.08it/s]Loading train:  97%|█████████▋| 257/266 [04:12<00:08,  1.08it/s]Loading train:  97%|█████████▋| 258/266 [04:13<00:07,  1.08it/s]Loading train:  97%|█████████▋| 259/266 [04:14<00:06,  1.07it/s]Loading train:  98%|█████████▊| 260/266 [04:15<00:05,  1.08it/s]Loading train:  98%|█████████▊| 261/266 [04:16<00:04,  1.09it/s]Loading train:  98%|█████████▊| 262/266 [04:17<00:03,  1.08it/s]Loading train:  99%|█████████▉| 263/266 [04:18<00:02,  1.10it/s]Loading train:  99%|█████████▉| 264/266 [04:18<00:01,  1.15it/s]Loading train: 100%|█████████▉| 265/266 [04:19<00:00,  1.16it/s]Loading train: 100%|██████████| 266/266 [04:20<00:00,  1.20it/s]
concatenating: train:   0%|          | 0/266 [00:00<?, ?it/s]concatenating: train:  11%|█         | 29/266 [00:00<00:00, 283.31it/s]concatenating: train:  22%|██▏       | 58/266 [00:00<00:00, 283.79it/s]concatenating: train:  33%|███▎      | 88/266 [00:00<00:00, 287.13it/s]concatenating: train:  45%|████▌     | 121/266 [00:00<00:00, 297.88it/s]concatenating: train:  57%|█████▋    | 151/266 [00:00<00:00, 298.44it/s]concatenating: train:  69%|██████▉   | 184/266 [00:00<00:00, 306.94it/s]concatenating: train:  82%|████████▏ | 217/266 [00:00<00:00, 310.44it/s]concatenating: train:  93%|█████████▎| 247/266 [00:00<00:00, 305.77it/s]concatenating: train: 100%|██████████| 266/266 [00:00<00:00, 307.85it/s]
Loading test:   0%|          | 0/5 [00:00<?, ?it/s]Loading test:  20%|██        | 1/5 [00:01<00:04,  1.21s/it]Loading test:  40%|████      | 2/5 [00:02<00:03,  1.18s/it]Loading test:  60%|██████    | 3/5 [00:03<00:02,  1.12s/it]Loading test:  80%|████████  | 4/5 [00:04<00:01,  1.06s/it]Loading test: 100%|██████████| 5/5 [00:05<00:00,  1.14s/it]
concatenating: validation:   0%|          | 0/5 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 5/5 [00:00<00:00, 652.42it/s]2019-08-17 20:00:03.593908: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-08-17 20:00:03.594005: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-08-17 20:00:03.594020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-08-17 20:00:03.594028: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-08-17 20:00:03.594446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14485 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:04:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.29it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.25it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.90it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.57it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.98it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.90it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.73it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.71it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.07it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.47it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.32it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.77it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.84it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.61it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.55it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.70it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.93it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:03<00:00,  7.78it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:03<00:00, 11.12it/s]
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM40_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Ps_ET_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 84, 48, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 84, 48, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 84, 48, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 84, 48, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 84, 48, 40)   14440       activation_1[0][0]               
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 84, 48, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 84, 48, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 42, 24, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 42, 24, 40)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 42, 24, 80)   28880       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 42, 24, 80)   320         conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 42, 24, 80)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 42, 24, 80)   57680       activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 42, 24, 80)   320         conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 42, 24, 80)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 42, 24, 120)  0           dropout_1[0][0]                  
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 21, 12, 120)  0           concatenate_1[0][0]              
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 21, 12, 120)  0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 21, 12, 160)  172960      dropout_2[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 21, 12, 160)  640         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 21, 12, 160)  0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 21, 12, 160)  230560      activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 21, 12, 160)  640         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 21, 12, 160)  0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 21, 12, 280)  0           dropout_2[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 21, 12, 280)  0           concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 42, 24, 80)   89680       dropout_3[0][0]                  
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 42, 24, 200)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_1[0][0]              
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 42, 24, 80)   144080      concatenate_3[0][0]              
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 42, 24, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 42, 24, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 42, 24, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 42, 24, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 42, 24, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 42, 24, 280)  0           concatenate_3[0][0]              
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 42, 24, 280)  0           concatenate_4[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 84, 48, 40)   44840       dropout_4[0][0]                  
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 84, 48, 80)   0           conv2d_transpose_2[0][0]         
                                                                 activation_2[0][0]               
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 84, 48, 40)   28840       concatenate_5[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 84, 48, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 84, 48, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 84, 48, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 84, 48, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 84, 48, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 84, 48, 120)  0           concatenate_5[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 84, 48, 120)  0           concatenate_6[0][0]              
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 84, 48, 13)   1573        dropout_5[0][0]                  
==================================================================================================
Total params: 889,253
Trainable params: 784,693
Non-trainable params: 104,560
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.33875399e-02 3.28528818e-02 7.68219457e-02 9.54551304e-03
 2.76268883e-02 7.22782911e-03 8.44920862e-02 1.14183175e-01
 8.96563298e-02 1.36219164e-02 2.90683456e-01 1.89631366e-01
 2.69073402e-04]
Train on 10195 samples, validate on 187 samples
Epoch 1/300
 - 18s - loss: 1.8510 - acc: 0.7187 - mDice: 0.2576 - val_loss: 0.6878 - val_acc: 0.9210 - val_mDice: 0.4944

Epoch 00001: val_mDice improved from -inf to 0.49444, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.5581 - acc: 0.9115 - mDice: 0.5641 - val_loss: 0.5329 - val_acc: 0.9412 - val_mDice: 0.5747

Epoch 00002: val_mDice improved from 0.49444 to 0.57465, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.4128 - acc: 0.9336 - mDice: 0.6484 - val_loss: 0.5042 - val_acc: 0.9413 - val_mDice: 0.5902

Epoch 00003: val_mDice improved from 0.57465 to 0.59015, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.3571 - acc: 0.9402 - mDice: 0.6865 - val_loss: 0.4693 - val_acc: 0.9439 - val_mDice: 0.6116

Epoch 00004: val_mDice improved from 0.59015 to 0.61162, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.3236 - acc: 0.9437 - mDice: 0.7104 - val_loss: 0.4994 - val_acc: 0.9413 - val_mDice: 0.5988

Epoch 00005: val_mDice did not improve from 0.61162
Epoch 6/300
 - 14s - loss: 0.2974 - acc: 0.9462 - mDice: 0.7297 - val_loss: 0.4719 - val_acc: 0.9420 - val_mDice: 0.6120

Epoch 00006: val_mDice improved from 0.61162 to 0.61202, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.2815 - acc: 0.9479 - mDice: 0.7418 - val_loss: 0.4658 - val_acc: 0.9440 - val_mDice: 0.6175

Epoch 00007: val_mDice improved from 0.61202 to 0.61749, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.2658 - acc: 0.9493 - mDice: 0.7539 - val_loss: 0.4829 - val_acc: 0.9447 - val_mDice: 0.6102

Epoch 00008: val_mDice did not improve from 0.61749
Epoch 9/300
 - 14s - loss: 0.2559 - acc: 0.9504 - mDice: 0.7618 - val_loss: 0.4675 - val_acc: 0.9425 - val_mDice: 0.6163

Epoch 00009: val_mDice did not improve from 0.61749
Epoch 10/300
 - 14s - loss: 0.2449 - acc: 0.9516 - mDice: 0.7706 - val_loss: 0.4788 - val_acc: 0.9440 - val_mDice: 0.6128

Epoch 00010: val_mDice did not improve from 0.61749
Epoch 11/300
 - 14s - loss: 0.2361 - acc: 0.9525 - mDice: 0.7776 - val_loss: 0.4763 - val_acc: 0.9429 - val_mDice: 0.6121

Epoch 00011: val_mDice did not improve from 0.61749
Epoch 12/300
 - 14s - loss: 0.2452 - acc: 0.9520 - mDice: 0.7729 - val_loss: 0.5034 - val_acc: 0.9423 - val_mDice: 0.6030

Epoch 00012: val_mDice did not improve from 0.61749
Epoch 13/300
 - 14s - loss: 0.2287 - acc: 0.9533 - mDice: 0.7837 - val_loss: 0.4983 - val_acc: 0.9425 - val_mDice: 0.6050

Epoch 00013: val_mDice did not improve from 0.61749
Epoch 14/300
 - 14s - loss: 0.2198 - acc: 0.9540 - mDice: 0.7909 - val_loss: 0.4963 - val_acc: 0.9431 - val_mDice: 0.6043

Epoch 00014: val_mDice did not improve from 0.61749
Epoch 15/300
 - 14s - loss: 0.2169 - acc: 0.9546 - mDice: 0.7936 - val_loss: 0.4869 - val_acc: 0.9456 - val_mDice: 0.6131

Epoch 00015: val_mDice did not improve from 0.61749
Epoch 16/300
 - 14s - loss: 0.2108 - acc: 0.9551 - mDice: 0.7985 - val_loss: 0.4990 - val_acc: 0.9439 - val_mDice: 0.6059

Epoch 00016: val_mDice did not improve from 0.61749
Epoch 17/300
 - 14s - loss: 0.2067 - acc: 0.9555 - mDice: 0.8020 - val_loss: 0.5039 - val_acc: 0.9423 - val_mDice: 0.6023

Epoch 00017: val_mDice did not improve from 0.61749
Epoch 18/300
 - 14s - loss: 0.2031 - acc: 0.9559 - mDice: 0.8051 - val_loss: 0.4915 - val_acc: 0.9448 - val_mDice: 0.6121

Epoch 00018: val_mDice did not improve from 0.61749
Epoch 19/300
 - 14s - loss: 0.2009 - acc: 0.9562 - mDice: 0.8070 - val_loss: 0.4864 - val_acc: 0.9450 - val_mDice: 0.6160

Epoch 00019: val_mDice did not improve from 0.61749
Epoch 20/300
 - 14s - loss: 0.1988 - acc: 0.9566 - mDice: 0.8088 - val_loss: 0.4884 - val_acc: 0.9446 - val_mDice: 0.6152

Epoch 00020: val_mDice did not improve from 0.61749
Epoch 21/300
 - 14s - loss: 0.1963 - acc: 0.9567 - mDice: 0.8110 - val_loss: 0.4980 - val_acc: 0.9456 - val_mDice: 0.6121

Epoch 00021: val_mDice did not improve from 0.61749
Epoch 22/300
 - 14s - loss: 0.1932 - acc: 0.9570 - mDice: 0.8136 - val_loss: 0.4930 - val_acc: 0.9438 - val_mDice: 0.6106

Epoch 00022: val_mDice did not improve from 0.61749
Epoch 23/300
 - 14s - loss: 0.2571 - acc: 0.9503 - mDice: 0.7662 - val_loss: 0.4887 - val_acc: 0.9458 - val_mDice: 0.6068

Epoch 00023: val_mDice did not improve from 0.61749
Epoch 24/300
 - 14s - loss: 0.2147 - acc: 0.9541 - mDice: 0.7952 - val_loss: 0.4793 - val_acc: 0.9436 - val_mDice: 0.6140

Epoch 00024: val_mDice did not improve from 0.61749
Epoch 25/300
 - 14s - loss: 0.2093 - acc: 0.9551 - mDice: 0.8033 - val_loss: 5.8715 - val_acc: 0.9045 - val_mDice: 0.0848

Epoch 00025: val_mDice did not improve from 0.61749
Epoch 26/300
 - 14s - loss: 0.2186 - acc: 0.9537 - mDice: 0.7920 - val_loss: 0.4907 - val_acc: 0.9430 - val_mDice: 0.6121

Epoch 00026: val_mDice did not improve from 0.61749
Epoch 27/300
 - 14s - loss: 0.1985 - acc: 0.9561 - mDice: 0.8088 - val_loss: 0.4862 - val_acc: 0.9433 - val_mDice: 0.6090

Epoch 00027: val_mDice did not improve from 0.61749
Epoch 28/300
 - 14s - loss: 0.1952 - acc: 0.9566 - mDice: 0.8118 - val_loss: 0.4714 - val_acc: 0.9448 - val_mDice: 0.6185

Epoch 00028: val_mDice improved from 0.61749 to 0.61852, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 14s - loss: 0.1905 - acc: 0.9571 - mDice: 0.8158 - val_loss: 0.4878 - val_acc: 0.9447 - val_mDice: 0.6150

Epoch 00029: val_mDice did not improve from 0.61852
Epoch 30/300
 - 14s - loss: 0.1864 - acc: 0.9576 - mDice: 0.8193 - val_loss: 0.4904 - val_acc: 0.9436 - val_mDice: 0.6090

Epoch 00030: val_mDice did not improve from 0.61852
Epoch 31/300
 - 14s - loss: 0.1831 - acc: 0.9579 - mDice: 0.8222 - val_loss: 0.4901 - val_acc: 0.9452 - val_mDice: 0.6131

Epoch 00031: val_mDice did not improve from 0.61852
Epoch 32/300
 - 14s - loss: 0.1823 - acc: 0.9580 - mDice: 0.8229 - val_loss: 0.4778 - val_acc: 0.9445 - val_mDice: 0.6169

Epoch 00032: val_mDice did not improve from 0.61852
Epoch 33/300
 - 14s - loss: 0.1812 - acc: 0.9582 - mDice: 0.8239 - val_loss: 0.4687 - val_acc: 0.9453 - val_mDice: 0.6202

Epoch 00033: val_mDice improved from 0.61852 to 0.62025, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 14s - loss: 0.1795 - acc: 0.9584 - mDice: 0.8254 - val_loss: 0.4885 - val_acc: 0.9449 - val_mDice: 0.6142

Epoch 00034: val_mDice did not improve from 0.62025
Epoch 35/300
 - 14s - loss: 0.1776 - acc: 0.9585 - mDice: 0.8270 - val_loss: 0.4939 - val_acc: 0.9451 - val_mDice: 0.6119

Epoch 00035: val_mDice did not improve from 0.62025
Epoch 36/300
 - 14s - loss: 0.1761 - acc: 0.9588 - mDice: 0.8284 - val_loss: 0.4850 - val_acc: 0.9459 - val_mDice: 0.6192

Epoch 00036: val_mDice did not improve from 0.62025
Epoch 37/300
 - 14s - loss: 0.1749 - acc: 0.9590 - mDice: 0.8294 - val_loss: 0.4824 - val_acc: 0.9458 - val_mDice: 0.6125

Epoch 00037: val_mDice did not improve from 0.62025
Epoch 38/300
 - 14s - loss: 0.1743 - acc: 0.9590 - mDice: 0.8300 - val_loss: 0.4691 - val_acc: 0.9460 - val_mDice: 0.6234

Epoch 00038: val_mDice improved from 0.62025 to 0.62340, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 14s - loss: 0.1732 - acc: 0.9591 - mDice: 0.8309 - val_loss: 0.5318 - val_acc: 0.9448 - val_mDice: 0.5997

Epoch 00039: val_mDice did not improve from 0.62340
Epoch 40/300
 - 14s - loss: 0.1740 - acc: 0.9591 - mDice: 0.8302 - val_loss: 0.4966 - val_acc: 0.9467 - val_mDice: 0.6148

Epoch 00040: val_mDice did not improve from 0.62340
Epoch 41/300
 - 14s - loss: 0.1708 - acc: 0.9595 - mDice: 0.8331 - val_loss: 0.5024 - val_acc: 0.9454 - val_mDice: 0.6183

Epoch 00041: val_mDice did not improve from 0.62340
Epoch 42/300
 - 14s - loss: 0.1703 - acc: 0.9596 - mDice: 0.8335 - val_loss: 0.4944 - val_acc: 0.9453 - val_mDice: 0.6138

Epoch 00042: val_mDice did not improve from 0.62340
Epoch 43/300
 - 14s - loss: 0.1702 - acc: 0.9596 - mDice: 0.8336 - val_loss: 0.4848 - val_acc: 0.9466 - val_mDice: 0.6198

Epoch 00043: val_mDice did not improve from 0.62340
Epoch 44/300
 - 14s - loss: 0.1686 - acc: 0.9597 - mDice: 0.8350 - val_loss: 0.5052 - val_acc: 0.9461 - val_mDice: 0.6087

Epoch 00044: val_mDice did not improve from 0.62340
Epoch 45/300
 - 14s - loss: 0.1680 - acc: 0.9597 - mDice: 0.8356 - val_loss: 0.5049 - val_acc: 0.9445 - val_mDice: 0.6149

Epoch 00045: val_mDice did not improve from 0.62340
Epoch 46/300
 - 14s - loss: 0.1728 - acc: 0.9598 - mDice: 0.8363 - val_loss: 0.4891 - val_acc: 0.9465 - val_mDice: 0.6142

Epoch 00046: val_mDice did not improve from 0.62340
Epoch 47/300
 - 14s - loss: 0.1665 - acc: 0.9599 - mDice: 0.8369 - val_loss: 0.5135 - val_acc: 0.9459 - val_mDice: 0.6117

Epoch 00047: val_mDice did not improve from 0.62340
Epoch 48/300
 - 14s - loss: 0.1716 - acc: 0.9599 - mDice: 0.8361 - val_loss: 0.4920 - val_acc: 0.9453 - val_mDice: 0.6109

Epoch 00048: val_mDice did not improve from 0.62340
Epoch 49/300
 - 14s - loss: 0.1658 - acc: 0.9600 - mDice: 0.8375 - val_loss: 0.4802 - val_acc: 0.9471 - val_mDice: 0.6233

Epoch 00049: val_mDice did not improve from 0.62340
Epoch 50/300
 - 14s - loss: 0.1645 - acc: 0.9601 - mDice: 0.8386 - val_loss: 0.4917 - val_acc: 0.9454 - val_mDice: 0.6114

Epoch 00050: val_mDice did not improve from 0.62340
Epoch 51/300
 - 14s - loss: 0.1630 - acc: 0.9603 - mDice: 0.8401 - val_loss: 0.4976 - val_acc: 0.9461 - val_mDice: 0.6160

Epoch 00051: val_mDice did not improve from 0.62340
Epoch 52/300
 - 14s - loss: 0.1636 - acc: 0.9603 - mDice: 0.8395 - val_loss: 0.5014 - val_acc: 0.9454 - val_mDice: 0.6128

Epoch 00052: val_mDice did not improve from 0.62340
Epoch 53/300
 - 14s - loss: 0.1621 - acc: 0.9605 - mDice: 0.8408 - val_loss: 0.4742 - val_acc: 0.9465 - val_mDice: 0.6207

Epoch 00053: val_mDice did not improve from 0.62340
Epoch 54/300
 - 14s - loss: 0.1620 - acc: 0.9604 - mDice: 0.8409 - val_loss: 0.5072 - val_acc: 0.9461 - val_mDice: 0.6118

Epoch 00054: val_mDice did not improve from 0.62340
Epoch 55/300
 - 14s - loss: 0.1598 - acc: 0.9606 - mDice: 0.8429 - val_loss: 0.4909 - val_acc: 0.9448 - val_mDice: 0.6137

Epoch 00055: val_mDice did not improve from 0.62340
Epoch 56/300
 - 14s - loss: 0.1594 - acc: 0.9607 - mDice: 0.8432 - val_loss: 0.4950 - val_acc: 0.9462 - val_mDice: 0.6153

Epoch 00056: val_mDice did not improve from 0.62340
Epoch 57/300
 - 14s - loss: 0.1594 - acc: 0.9608 - mDice: 0.8434 - val_loss: 0.5158 - val_acc: 0.9452 - val_mDice: 0.6146

Epoch 00057: val_mDice did not improve from 0.62340
Epoch 58/300
 - 14s - loss: 0.1586 - acc: 0.9608 - mDice: 0.8439 - val_loss: 0.4926 - val_acc: 0.9465 - val_mDice: 0.6129

Epoch 00058: val_mDice did not improve from 0.62340
Epoch 59/300
 - 14s - loss: 0.1582 - acc: 0.9609 - mDice: 0.8444 - val_loss: 0.4822 - val_acc: 0.9468 - val_mDice: 0.6171

Epoch 00059: val_mDice did not improve from 0.62340
Epoch 60/300
 - 14s - loss: 0.1569 - acc: 0.9610 - mDice: 0.8455 - val_loss: 0.4952 - val_acc: 0.9460 - val_mDice: 0.6161

Epoch 00060: val_mDice did not improve from 0.62340
Epoch 61/300
 - 14s - loss: 0.1566 - acc: 0.9611 - mDice: 0.8458 - val_loss: 0.5110 - val_acc: 0.9453 - val_mDice: 0.6117

Epoch 00061: val_mDice did not improve from 0.62340
Epoch 62/300
 - 14s - loss: 0.1571 - acc: 0.9610 - mDice: 0.8452 - val_loss: 0.5162 - val_acc: 0.9458 - val_mDice: 0.6092

Epoch 00062: val_mDice did not improve from 0.62340
Epoch 63/300
 - 14s - loss: 0.1554 - acc: 0.9612 - mDice: 0.8468 - val_loss: 0.4826 - val_acc: 0.9458 - val_mDice: 0.6160

Epoch 00063: val_mDice did not improve from 0.62340
Epoch 64/300
 - 14s - loss: 0.1559 - acc: 0.9612 - mDice: 0.8465 - val_loss: 0.4923 - val_acc: 0.9441 - val_mDice: 0.6157

Epoch 00064: val_mDice did not improve from 0.62340
Epoch 65/300
 - 14s - loss: 0.1559 - acc: 0.9612 - mDice: 0.8463 - val_loss: 0.4796 - val_acc: 0.9463 - val_mDice: 0.6207

Epoch 00065: val_mDice did not improve from 0.62340
Epoch 66/300
 - 14s - loss: 0.1546 - acc: 0.9614 - mDice: 0.8475 - val_loss: 0.4838 - val_acc: 0.9458 - val_mDice: 0.6143

Epoch 00066: val_mDice did not improve from 0.62340
Epoch 67/300
 - 14s - loss: 0.1530 - acc: 0.9614 - mDice: 0.8490 - val_loss: 0.4945 - val_acc: 0.9466 - val_mDice: 0.6116

Epoch 00067: val_mDice did not improve from 0.62340
Epoch 68/300
 - 14s - loss: 0.1644 - acc: 0.9610 - mDice: 0.8441 - val_loss: 0.4772 - val_acc: 0.9461 - val_mDice: 0.6229

Epoch 00068: val_mDice did not improve from 0.62340
Epoch 69/300
 - 15s - loss: 0.1561 - acc: 0.9612 - mDice: 0.8462 - val_loss: 0.4689 - val_acc: 0.9468 - val_mDice: 0.6208

Epoch 00069: val_mDice did not improve from 0.62340
Epoch 70/300
 - 15s - loss: 0.1523 - acc: 0.9615 - mDice: 0.8496 - val_loss: 0.4791 - val_acc: 0.9469 - val_mDice: 0.6184

Epoch 00070: val_mDice did not improve from 0.62340
Epoch 71/300
 - 14s - loss: 0.1526 - acc: 0.9615 - mDice: 0.8494 - val_loss: 0.4720 - val_acc: 0.9467 - val_mDice: 0.6191

Epoch 00071: val_mDice did not improve from 0.62340
Epoch 72/300
 - 14s - loss: 0.1507 - acc: 0.9616 - mDice: 0.8511 - val_loss: 0.4647 - val_acc: 0.9470 - val_mDice: 0.6246

Epoch 00072: val_mDice improved from 0.62340 to 0.62465, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 73/300
 - 15s - loss: 0.1504 - acc: 0.9617 - mDice: 0.8513 - val_loss: 0.4952 - val_acc: 0.9466 - val_mDice: 0.6121

Epoch 00073: val_mDice did not improve from 0.62465
Epoch 74/300
 - 14s - loss: 0.1502 - acc: 0.9617 - mDice: 0.8516 - val_loss: 0.4797 - val_acc: 0.9470 - val_mDice: 0.6178

Epoch 00074: val_mDice did not improve from 0.62465
Epoch 75/300
 - 14s - loss: 0.1501 - acc: 0.9618 - mDice: 0.8517 - val_loss: 0.4724 - val_acc: 0.9466 - val_mDice: 0.6174

Epoch 00075: val_mDice did not improve from 0.62465
Epoch 76/300
 - 15s - loss: 0.1493 - acc: 0.9618 - mDice: 0.8524 - val_loss: 0.5037 - val_acc: 0.9470 - val_mDice: 0.6144

Epoch 00076: val_mDice did not improve from 0.62465
Epoch 77/300
 - 14s - loss: 0.1496 - acc: 0.9619 - mDice: 0.8521 - val_loss: 0.4812 - val_acc: 0.9455 - val_mDice: 0.6132

Epoch 00077: val_mDice did not improve from 0.62465
Epoch 78/300
 - 14s - loss: 0.1490 - acc: 0.9619 - mDice: 0.8526 - val_loss: 0.4650 - val_acc: 0.9481 - val_mDice: 0.6266

Epoch 00078: val_mDice improved from 0.62465 to 0.62657, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 79/300
 - 15s - loss: 0.1480 - acc: 0.9620 - mDice: 0.8535 - val_loss: 0.4801 - val_acc: 0.9478 - val_mDice: 0.6237

Epoch 00079: val_mDice did not improve from 0.62657
Epoch 80/300
 - 15s - loss: 0.1477 - acc: 0.9620 - mDice: 0.8538 - val_loss: 0.4572 - val_acc: 0.9471 - val_mDice: 0.6239

Epoch 00080: val_mDice did not improve from 0.62657
Epoch 81/300
 - 15s - loss: 0.1474 - acc: 0.9620 - mDice: 0.8540 - val_loss: 0.4785 - val_acc: 0.9490 - val_mDice: 0.6201

Epoch 00081: val_mDice did not improve from 0.62657
Epoch 82/300
 - 15s - loss: 0.1705 - acc: 0.9608 - mDice: 0.8396 - val_loss: 0.4796 - val_acc: 0.9453 - val_mDice: 0.6196

Epoch 00082: val_mDice did not improve from 0.62657
Epoch 83/300
 - 15s - loss: 0.1542 - acc: 0.9614 - mDice: 0.8479 - val_loss: 0.4729 - val_acc: 0.9473 - val_mDice: 0.6178

Epoch 00083: val_mDice did not improve from 0.62657
Epoch 84/300
 - 14s - loss: 0.1493 - acc: 0.9619 - mDice: 0.8523 - val_loss: 0.4647 - val_acc: 0.9457 - val_mDice: 0.6232

Epoch 00084: val_mDice did not improve from 0.62657
Epoch 85/300
 - 14s - loss: 0.1477 - acc: 0.9620 - mDice: 0.8538 - val_loss: 0.4645 - val_acc: 0.9475 - val_mDice: 0.6237

Epoch 00085: val_mDice did not improve from 0.62657
Epoch 86/300
 - 15s - loss: 0.1467 - acc: 0.9621 - mDice: 0.8547 - val_loss: 0.4622 - val_acc: 0.9462 - val_mDice: 0.6235

Epoch 00086: val_mDice did not improve from 0.62657
Epoch 87/300
 - 15s - loss: 0.1462 - acc: 0.9623 - mDice: 0.8551 - val_loss: 0.5040 - val_acc: 0.9481 - val_mDice: 0.6161

Epoch 00087: val_mDice did not improve from 0.62657
Epoch 88/300
 - 15s - loss: 0.1448 - acc: 0.9623 - mDice: 0.8564 - val_loss: 0.4618 - val_acc: 0.9471 - val_mDice: 0.6243

Epoch 00088: val_mDice did not improve from 0.62657
Epoch 89/300
 - 15s - loss: 0.1446 - acc: 0.9623 - mDice: 0.8567 - val_loss: 0.4538 - val_acc: 0.9475 - val_mDice: 0.6286

Epoch 00089: val_mDice improved from 0.62657 to 0.62859, saving model to /array/ssd/msmajdi/experiments/keras/exp6/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA0_FCNB0_FM0_permute7_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 90/300
 - 15s - loss: 0.1452 - acc: 0.9623 - mDice: 0.8561 - val_loss: 0.4803 - val_acc: 0.9466 - val_mDice: 0.6211

Epoch 00090: val_mDice did not improve from 0.62859
Epoch 91/300
 - 15s - loss: 0.1501 - acc: 0.9624 - mDice: 0.8573 - val_loss: 0.4827 - val_acc: 0.9479 - val_mDice: 0.6191

Epoch 00091: val_mDice did not improve from 0.62859
Epoch 92/300
 - 15s - loss: 0.1440 - acc: 0.9624 - mDice: 0.8572 - val_loss: 0.4757 - val_acc: 0.9465 - val_mDice: 0.6198

Epoch 00092: val_mDice did not improve from 0.62859
Epoch 93/300
 - 15s - loss: 0.1430 - acc: 0.9625 - mDice: 0.8581 - val_loss: 0.4877 - val_acc: 0.9468 - val_mDice: 0.6177

Epoch 00093: val_mDice did not improve from 0.62859
Epoch 94/300
 - 14s - loss: 0.1447 - acc: 0.9624 - mDice: 0.8566 - val_loss: 0.4919 - val_acc: 0.9470 - val_mDice: 0.6169

Epoch 00094: val_mDice did not improve from 0.62859
Epoch 95/300
 - 14s - loss: 0.1435 - acc: 0.9625 - mDice: 0.8576 - val_loss: 0.4834 - val_acc: 0.9471 - val_mDice: 0.6224

Epoch 00095: val_mDice did not improve from 0.62859
Epoch 96/300
 - 15s - loss: 0.1430 - acc: 0.9625 - mDice: 0.8581 - val_loss: 0.4730 - val_acc: 0.9476 - val_mDice: 0.6211

Epoch 00096: val_mDice did not improve from 0.62859
Epoch 97/300
 - 14s - loss: 0.1429 - acc: 0.9626 - mDice: 0.8582 - val_loss: 0.5026 - val_acc: 0.9481 - val_mDice: 0.6168

Epoch 00097: val_mDice did not improve from 0.62859
Epoch 98/300
 - 14s - loss: 0.1423 - acc: 0.9626 - mDice: 0.8588 - val_loss: 0.4823 - val_acc: 0.9469 - val_mDice: 0.6173

Epoch 00098: val_mDice did not improve from 0.62859
Epoch 99/300
 - 14s - loss: 0.1419 - acc: 0.9627 - mDice: 0.8591 - val_loss: 0.4774 - val_acc: 0.9459 - val_mDice: 0.6207

Epoch 00099: val_mDice did not improve from 0.62859
Epoch 100/300
 - 14s - loss: 0.1413 - acc: 0.9627 - mDice: 0.8596 - val_loss: 0.4789 - val_acc: 0.9475 - val_mDice: 0.6193

Epoch 00100: val_mDice did not improve from 0.62859
Epoch 101/300
 - 14s - loss: 0.1421 - acc: 0.9627 - mDice: 0.8589 - val_loss: 0.4673 - val_acc: 0.9479 - val_mDice: 0.6234

Epoch 00101: val_mDice did not improve from 0.62859
Epoch 102/300
 - 14s - loss: 0.1414 - acc: 0.9627 - mDice: 0.8595 - val_loss: 0.5070 - val_acc: 0.9477 - val_mDice: 0.6120

Epoch 00102: val_mDice did not improve from 0.62859
Epoch 103/300
 - 14s - loss: 0.1414 - acc: 0.9627 - mDice: 0.8596 - val_loss: 0.4941 - val_acc: 0.9468 - val_mDice: 0.6181

Epoch 00103: val_mDice did not improve from 0.62859
Epoch 104/300
 - 14s - loss: 0.1405 - acc: 0.9628 - mDice: 0.8603 - val_loss: 0.4944 - val_acc: 0.9470 - val_mDice: 0.6164

Epoch 00104: val_mDice did not improve from 0.62859
Epoch 105/300
 - 14s - loss: 0.1405 - acc: 0.9628 - mDice: 0.8604 - val_loss: 0.4853 - val_acc: 0.9473 - val_mDice: 0.6175

Epoch 00105: val_mDice did not improve from 0.62859
Epoch 106/300
 - 14s - loss: 0.1400 - acc: 0.9628 - mDice: 0.8609 - val_loss: 0.4885 - val_acc: 0.9479 - val_mDice: 0.6175

Epoch 00106: val_mDice did not improve from 0.62859
Epoch 107/300
 - 14s - loss: 0.1408 - acc: 0.9627 - mDice: 0.8601 - val_loss: 0.4700 - val_acc: 0.9466 - val_mDice: 0.6204

Epoch 00107: val_mDice did not improve from 0.62859
Epoch 108/300
 - 14s - loss: 0.1451 - acc: 0.9623 - mDice: 0.8566 - val_loss: 0.5131 - val_acc: 0.9477 - val_mDice: 0.6196

Epoch 00108: val_mDice did not improve from 0.62859
Epoch 109/300
 - 14s - loss: 0.1408 - acc: 0.9627 - mDice: 0.8600 - val_loss: 0.4691 - val_acc: 0.9467 - val_mDice: 0.6207

Epoch 00109: val_mDice did not improve from 0.62859
Epoch 110/300
 - 14s - loss: 0.1395 - acc: 0.9628 - mDice: 0.8613 - val_loss: 0.4798 - val_acc: 0.9470 - val_mDice: 0.6186

Epoch 00110: val_mDice did not improve from 0.62859
Epoch 111/300
 - 14s - loss: 0.1393 - acc: 0.9628 - mDice: 0.8615 - val_loss: 0.4818 - val_acc: 0.9465 - val_mDice: 0.6217

Epoch 00111: val_mDice did not improve from 0.62859
Epoch 112/300
 - 14s - loss: 0.1391 - acc: 0.9630 - mDice: 0.8617 - val_loss: 0.5086 - val_acc: 0.9468 - val_mDice: 0.6135

Epoch 00112: val_mDice did not improve from 0.62859
Epoch 113/300
 - 15s - loss: 0.1393 - acc: 0.9629 - mDice: 0.8616 - val_loss: 0.5188 - val_acc: 0.9467 - val_mDice: 0.6106

Epoch 00113: val_mDice did not improve from 0.62859
Epoch 114/300
 - 14s - loss: 0.1383 - acc: 0.9630 - mDice: 0.8624 - val_loss: 0.4980 - val_acc: 0.9477 - val_mDice: 0.6144

Epoch 00114: val_mDice did not improve from 0.62859
Epoch 115/300
 - 14s - loss: 0.1378 - acc: 0.9630 - mDice: 0.8629 - val_loss: 0.4983 - val_acc: 0.9474 - val_mDice: 0.6166

Epoch 00115: val_mDice did not improve from 0.62859
Epoch 116/300
 - 14s - loss: 0.1403 - acc: 0.9629 - mDice: 0.8608 - val_loss: 0.5022 - val_acc: 0.9474 - val_mDice: 0.6129

Epoch 00116: val_mDice did not improve from 0.62859
Epoch 117/300
 - 14s - loss: 0.1383 - acc: 0.9630 - mDice: 0.8625 - val_loss: 0.4656 - val_acc: 0.9478 - val_mDice: 0.6238

Epoch 00117: val_mDice did not improve from 0.62859
Epoch 118/300
 - 14s - loss: 0.1377 - acc: 0.9631 - mDice: 0.8630 - val_loss: 0.4661 - val_acc: 0.9465 - val_mDice: 0.6255

Epoch 00118: val_mDice did not improve from 0.62859
Epoch 119/300
 - 14s - loss: 0.1374 - acc: 0.9631 - mDice: 0.8633 - val_loss: 0.4858 - val_acc: 0.9477 - val_mDice: 0.6168

Epoch 00119: val_mDice did not improve from 0.62859
Epoch 120/300
 - 14s - loss: 0.1372 - acc: 0.9630 - mDice: 0.8634 - val_loss: 0.4739 - val_acc: 0.9476 - val_mDice: 0.6192

Epoch 00120: val_mDice did not improve from 0.62859
Epoch 121/300
 - 14s - loss: 0.1376 - acc: 0.9631 - mDice: 0.8631 - val_loss: 0.4706 - val_acc: 0.9471 - val_mDice: 0.6214

Epoch 00121: val_mDice did not improve from 0.62859
Epoch 122/300
 - 14s - loss: 0.1364 - acc: 0.9632 - mDice: 0.8642 - val_loss: 0.4867 - val_acc: 0.9471 - val_mDice: 0.6158

Epoch 00122: val_mDice did not improve from 0.62859
Epoch 123/300
 - 14s - loss: 0.1383 - acc: 0.9630 - mDice: 0.8625 - val_loss: 0.4743 - val_acc: 0.9483 - val_mDice: 0.6216

Epoch 00123: val_mDice did not improve from 0.62859
Epoch 124/300
 - 14s - loss: 0.1374 - acc: 0.9631 - mDice: 0.8632 - val_loss: 0.4698 - val_acc: 0.9480 - val_mDice: 0.6237

Epoch 00124: val_mDice did not improve from 0.62859
Epoch 125/300
 - 14s - loss: 0.1365 - acc: 0.9632 - mDice: 0.8641 - val_loss: 0.4867 - val_acc: 0.9483 - val_mDice: 0.6201

Epoch 00125: val_mDice did not improve from 0.62859
Epoch 126/300
 - 14s - loss: 0.1356 - acc: 0.9632 - mDice: 0.8649 - val_loss: 0.4796 - val_acc: 0.9487 - val_mDice: 0.6216

Epoch 00126: val_mDice did not improve from 0.62859
Epoch 127/300
 - 14s - loss: 0.1364 - acc: 0.9632 - mDice: 0.8641 - val_loss: 0.4664 - val_acc: 0.9477 - val_mDice: 0.6256

Epoch 00127: val_mDice did not improve from 0.62859
Epoch 128/300
 - 14s - loss: 0.1361 - acc: 0.9633 - mDice: 0.8645 - val_loss: 0.5118 - val_acc: 0.9472 - val_mDice: 0.6130

Epoch 00128: val_mDice did not improve from 0.62859
Epoch 129/300
 - 14s - loss: 0.1369 - acc: 0.9632 - mDice: 0.8638 - val_loss: 0.4796 - val_acc: 0.9478 - val_mDice: 0.6223

Epoch 00129: val_mDice did not improve from 0.62859
Restoring model weights from the end of the best epoch
Epoch 00129: early stopping
{'val_loss': [0.6877550377565271, 0.5329380363704049, 0.5041628417803005, 0.4693473689058885, 0.49938282832742376, 0.4718807929339893, 0.4657710486236103, 0.4828943589473153, 0.4675063659800565, 0.47876073220834375, 0.4762632217317979, 0.5034444434120056, 0.4983300848759432, 0.49632120371502353, 0.4868782180197099, 0.49904687630938976, 0.5038813419520536, 0.491493876286369, 0.4863542711989765, 0.48839817136366737, 0.4979999328360838, 0.49296246190122106, 0.488659952732331, 0.47925468848988334, 5.871457005567092, 0.4907232290283244, 0.4862486739209629, 0.47141243238500097, 0.4878221342270387, 0.4903642332808857, 0.49010749790757735, 0.47778714500009056, 0.46874800802552125, 0.4884737511688375, 0.4939012825489044, 0.4850292304620386, 0.48236530588909904, 0.4691418603779798, 0.5318296883195479, 0.49660651361878544, 0.5023843123313577, 0.4943541623054341, 0.48478026775752797, 0.5051858044244388, 0.504870426049207, 0.48905284025452356, 0.5135279503416887, 0.4919554337779468, 0.48022452395230053, 0.4917355299314713, 0.49758771779065464, 0.5013590831170107, 0.47422109536308654, 0.5072283704969335, 0.490882786359379, 0.49504250096764796, 0.5157684172219771, 0.4926324271582027, 0.4821812285777719, 0.4952341485469737, 0.5110206092423933, 0.5161624732502004, 0.4825644485134492, 0.49231451797612846, 0.4796431631965433, 0.48375361201597405, 0.4944942416673038, 0.47720487089080604, 0.4689021689050338, 0.4791173327734126, 0.47202278761302724, 0.46469656652945246, 0.4951910437109636, 0.4797258329263983, 0.4724178581951774, 0.5036736583327227, 0.48119608651507983, 0.4649720023022616, 0.4800917670369786, 0.4572010864229763, 0.47854494793529817, 0.47964517062998074, 0.4729429735219415, 0.4646690640857513, 0.4644696561091724, 0.46216684611723385, 0.503995579512999, 0.4617993160683841, 0.45383616867549914, 0.48025755910949913, 0.48267621901583546, 0.47567198796068283, 0.4877392649650574, 0.4919292458238449, 0.4833819088451365, 0.472971420396458, 0.5025666883603774, 0.4823314405698827, 0.47735847381347, 0.47888299902492665, 0.46730288751622573, 0.506963047433027, 0.4941339542202771, 0.4943628317532055, 0.48534338279841416, 0.4885309129794014, 0.4699658126754557, 0.5131391855803403, 0.4691183699324807, 0.4798353053031758, 0.4818185147117166, 0.5085701370303006, 0.5188323353382356, 0.4980381853121487, 0.4982901963001904, 0.5021856946741196, 0.4656215847176027, 0.46607964067535607, 0.48575106661587475, 0.4738948523679519, 0.47063895757185586, 0.48669209279478554, 0.4743085132244437, 0.4698448866446388, 0.4867274377116545, 0.4796056156171197, 0.46643466936713235, 0.5117510302181549, 0.47956409126042043], 'val_acc': [0.9210168939223264, 0.9412029914677462, 0.9412719658351837, 0.9438781231482398, 0.9413276620727172, 0.9420199821339571, 0.9439762674550959, 0.9446513576303573, 0.9425332680105526, 0.9440027765411744, 0.9428728028414721, 0.9423449189267694, 0.9424868356735311, 0.9430677501913061, 0.9456049340931489, 0.9438794379565805, 0.9422839299880247, 0.9448224344355537, 0.9449656701342944, 0.9446394121583133, 0.945587702294722, 0.9437919137949612, 0.9458344091068615, 0.9436314156986175, 0.9045099182562395, 0.9429523626113321, 0.9433064734872012, 0.9447945627299222, 0.944736228907172, 0.9435584972248995, 0.9451805295791218, 0.9444550409674007, 0.9452773491966533, 0.944932518158367, 0.945099638745109, 0.9459153012158399, 0.9457946075475152, 0.9460359904217848, 0.9448197888818016, 0.9466500817773177, 0.945370197614884, 0.9452508203486071, 0.9466221922221668, 0.946147383853076, 0.9445133993332399, 0.9464882427358372, 0.9458529509325079, 0.9453171415124985, 0.9471421174824557, 0.9454285559807232, 0.9460598603289395, 0.9454205864891011, 0.9465426295836341, 0.9460532260451088, 0.9448476344506371, 0.9461566936523519, 0.9451858308863512, 0.9464749751243999, 0.9468410486843497, 0.9459696877448954, 0.9453463168705211, 0.9457680786994689, 0.9457906220048506, 0.9440545156040293, 0.9462561358742535, 0.9457680809306589, 0.946643422312915, 0.9460863961892969, 0.9468251211757965, 0.9468609524920663, 0.9466540325771678, 0.9469816286296131, 0.9466222097529448, 0.9469988840149048, 0.9465996689974943, 0.9470201013559963, 0.9454895573503831, 0.9480585914882109, 0.9477959778857104, 0.9470983635295521, 0.9490320774960646, 0.9453118497675116, 0.9473211612293427, 0.9456845493240152, 0.9475094940573137, 0.9462083954224612, 0.9481222549861765, 0.9471102886021456, 0.9475227537002155, 0.9465824190308066, 0.9478742282658337, 0.946494884669462, 0.9468171666650211, 0.9470492636456209, 0.9470598927156173, 0.947606321962122, 0.9480572511805571, 0.9469087018686182, 0.9459073575422725, 0.9474949119562771, 0.94791003854517, 0.9477203701906664, 0.9468463394731124, 0.9469617292842764, 0.947305250932826, 0.9479246129964125, 0.9466062911691513, 0.9476686448336923, 0.9466871899716994, 0.9470174408213977, 0.9464736676471118, 0.9467986009337686, 0.9466925014786541, 0.9477097714011045, 0.9474206318192303, 0.9474073744075183, 0.9477681294482022, 0.9464511170106775, 0.9477402606112434, 0.9475851087646688, 0.947063868377298, 0.9471315021183402, 0.9482787398093524, 0.9479816632474808, 0.9482575450989015, 0.9486660284792038, 0.9477230256254022, 0.9471500786868009, 0.947790681997085], 'val_mDice': [0.49444115767504443, 0.574650298465382, 0.5901512653432428, 0.6116216329329791, 0.5988194461174827, 0.6120174472982233, 0.6174883880717231, 0.6102347906260567, 0.6163132920622189, 0.6128130070665941, 0.6120878333713919, 0.6030442561695283, 0.6050160039554943, 0.6043187510521016, 0.6131020083146936, 0.6059010749194711, 0.6023283106757995, 0.612103027455947, 0.616043276646558, 0.61524991236906, 0.6120833142555971, 0.6106110817608349, 0.606809028967179, 0.6139618550392396, 0.08483821758253371, 0.6121383251990864, 0.609016724767532, 0.6185168480490618, 0.6149743744396271, 0.6090115930307358, 0.6131476151114479, 0.6168707854607526, 0.620245019382334, 0.6141762268097005, 0.6118520823392001, 0.6191670687440882, 0.6125408857263983, 0.6233965834194326, 0.5997258545880649, 0.6147813274261148, 0.6183172120129998, 0.6137636476022037, 0.6197922443323595, 0.6087168834426187, 0.6149197364235944, 0.6142036863826813, 0.6116910761690395, 0.6108506994451431, 0.6232812630938974, 0.6114211302390073, 0.6159751131572825, 0.6128041269307468, 0.6207186984505882, 0.6118134696853352, 0.6136713624000549, 0.6153417997819217, 0.6146176352220423, 0.6129468685802929, 0.617136177850917, 0.6161171044895356, 0.6116904568544683, 0.6092489036646757, 0.6159718827130323, 0.6156861944632097, 0.6206916181798925, 0.6143478862742052, 0.6115675112780403, 0.6229342458082393, 0.620750900258355, 0.618438362756515, 0.6190591432194021, 0.6246483657449324, 0.6121138487270171, 0.6177967649730132, 0.6173902903011138, 0.614421305809429, 0.613198082077312, 0.6265681127813411, 0.6237071867295128, 0.6239206185315382, 0.6200561663683724, 0.619559855703364, 0.6177581886556697, 0.6232496611574755, 0.6236504807191736, 0.6234590506808643, 0.6161270830083021, 0.624327953486519, 0.6285858747155909, 0.6211348619053071, 0.6191176775305028, 0.6197908804378408, 0.6176882166276003, 0.6168923470425733, 0.622358720889066, 0.6211464373185673, 0.6168045086019179, 0.6173410708891517, 0.6206652410527601, 0.6192862085480103, 0.6233938428807386, 0.6119929609451702, 0.6180769077596817, 0.6163580191326651, 0.617492671956353, 0.6174752026955712, 0.6204406679632829, 0.6195984332956732, 0.6206979534842751, 0.618599170032032, 0.6216693071120563, 0.6135009743950584, 0.6106223438512832, 0.614389150537909, 0.6165702116680655, 0.6128859781326457, 0.6237770134114964, 0.6255050572482023, 0.6167760673053762, 0.6192177476729939, 0.6214112298373871, 0.6157766969446192, 0.6216195063157515, 0.6237208702984978, 0.6200582356376444, 0.6216065905948374, 0.6256050158311977, 0.6130061516149796, 0.6223028818553782], 'loss': [1.850965114391686, 0.5581094154310671, 0.41282983480159297, 0.35710665092508015, 0.32364223921573765, 0.29736347057294354, 0.28145226684196606, 0.2658032888785012, 0.25594965507728085, 0.24490819332089828, 0.23606497020099373, 0.24520557471324908, 0.22869187948632438, 0.2198471586352882, 0.21693308044146414, 0.21082358699531284, 0.2066732212981504, 0.2031267018383072, 0.2009015125845974, 0.19879993703536042, 0.1962872180373368, 0.19316557342805016, 0.2571017953141055, 0.21466471571995968, 0.20925466581090166, 0.21856644743064152, 0.19851382230209802, 0.19523930836828857, 0.1904515556958214, 0.18635877261651737, 0.18312468710426258, 0.18230459900858825, 0.181236085937326, 0.17946632042739133, 0.17759147977028014, 0.1760543057034564, 0.1749032710173248, 0.17426180050997478, 0.17324196828265234, 0.17403286923492228, 0.17078284594052676, 0.17034192912393833, 0.17015325151979485, 0.16864966140359333, 0.16798622157861345, 0.17279375471309916, 0.1664853333155275, 0.17163128303130976, 0.16583510026766893, 0.16453334091339936, 0.1629713223794911, 0.1635831845060992, 0.16212484220069318, 0.1619667921831001, 0.15975667957203712, 0.1593951811285917, 0.15939900598407902, 0.15862143926172645, 0.15815662093873467, 0.15691235388184716, 0.15655950167823388, 0.15713990206020378, 0.15543166234131944, 0.15587510905206176, 0.15592326454054556, 0.15462258566296996, 0.1530291714640211, 0.16440070664958664, 0.15610538786272607, 0.15229470934307768, 0.15258707061534188, 0.15065154798654085, 0.1504293023414504, 0.15019897323662654, 0.15006035829420591, 0.14925734806931915, 0.14958360197790818, 0.1490009880244235, 0.14801378399060602, 0.1476505466057659, 0.14744987891637093, 0.17049747626532405, 0.15424241907547478, 0.14930490153335133, 0.14766155889275145, 0.1466886955932287, 0.14623187449470695, 0.14483007618380037, 0.144553957330707, 0.14522068864607005, 0.15012107657971133, 0.14400006938120966, 0.14299340469396365, 0.14466963164680083, 0.1434877048072539, 0.1429775673174402, 0.14287645120197445, 0.14227306238426304, 0.14190125369657308, 0.14132357864124978, 0.1421112104585324, 0.14141290668853068, 0.14139552320143123, 0.14054762546106433, 0.14047337599306964, 0.13998556313940333, 0.14083611756899359, 0.14507000154873623, 0.1408466877321685, 0.13950969979656624, 0.13934191985420294, 0.13909870901342816, 0.13925119898318075, 0.13834346451555882, 0.13781421424390755, 0.14028369434736943, 0.13829333873400798, 0.13767170135065174, 0.13735196367088867, 0.13719811624116088, 0.13758238359313785, 0.13639140752467996, 0.13826769533374836, 0.137436770987955, 0.13652916547859223, 0.13555063631763759, 0.13641036016471014, 0.13610529665738827, 0.13685738585081797], 'acc': [0.7186578976071717, 0.9114619079847556, 0.9335908850306913, 0.9402448397573739, 0.9436899367765564, 0.9461606083224953, 0.947865190957328, 0.9493249181499079, 0.9504064078305269, 0.9515696904307315, 0.9524505537418012, 0.9519591187951376, 0.953315653539043, 0.9540159357944618, 0.954579183492899, 0.955146104258144, 0.9555155632249159, 0.9558747033385332, 0.9562375694001756, 0.956607804162763, 0.9566979116818202, 0.9569618134536013, 0.9503123626631811, 0.9541440657858407, 0.955067162510225, 0.9537227411022252, 0.9561052761749055, 0.9565668619982807, 0.9570666140291608, 0.9575645185499112, 0.9579359995143679, 0.9580473907441704, 0.9581760356916172, 0.9584190623031754, 0.9585351527701879, 0.9587772076418728, 0.958968249619621, 0.9589916029182236, 0.9591150895353039, 0.959079740473077, 0.9594684636376546, 0.9595536391719877, 0.9595766720554302, 0.9596788952489762, 0.9597410749956461, 0.9598350754960487, 0.9598829013100437, 0.959896575621146, 0.9600361884078774, 0.9600597869946479, 0.9602841332942145, 0.960327363265619, 0.9604634721235881, 0.960444911313209, 0.9605819698699027, 0.9607110735304862, 0.9607715765420802, 0.9608212516786071, 0.9609260796155925, 0.9610200530176598, 0.9611129102430956, 0.9610244311089022, 0.9612081998876054, 0.9612054759641089, 0.9611657016004869, 0.9613517314093319, 0.9614326444369078, 0.9610009573440215, 0.9612230652100084, 0.9614641982121115, 0.9615342333773996, 0.9616488399255387, 0.9616694190503337, 0.9617476838952832, 0.9617807662270711, 0.9618441850136986, 0.9618616048584621, 0.9618698784157949, 0.9619930229565862, 0.9620179335471167, 0.9620393627469829, 0.9607555922952102, 0.9613797317070374, 0.9618699021524164, 0.9619928505152917, 0.9620866573809875, 0.9622512291961584, 0.9622861392478138, 0.96230411848173, 0.9622997614377383, 0.9623682456545061, 0.9623831320241598, 0.9625304542142074, 0.9624159029151015, 0.9624939193732601, 0.9625069079532408, 0.9625614022086099, 0.96258096150641, 0.9626857391638519, 0.9626765915025035, 0.9626535049193393, 0.9627419103004583, 0.962683939360824, 0.9627921220249496, 0.9627658968874495, 0.9628255950755614, 0.9627237610515278, 0.9622516688498403, 0.9626856424926601, 0.9628492392939408, 0.9628312391589353, 0.9629542129831374, 0.9629390073091508, 0.962957352092887, 0.9630298461032416, 0.9628513591905737, 0.96299734628335, 0.9631051153105342, 0.9630597693011596, 0.9630250308138298, 0.9630765065426566, 0.9631815284651363, 0.9630409640795814, 0.9631343557882566, 0.9631742282846852, 0.9632381616181285, 0.9631645205033766, 0.9632923603057861, 0.9631581233669111], 'mDice': [0.2575505710599278, 0.5641122378222553, 0.6484151375299578, 0.6864750772612301, 0.71036642360126, 0.7297348842835999, 0.7418326100863447, 0.7539218286780413, 0.7617546928577882, 0.7706063582126623, 0.7776016426647686, 0.7729315667716004, 0.7836742155279466, 0.7909365307764424, 0.7935781556055088, 0.7985114571567609, 0.8020193757760636, 0.8050553519799465, 0.807004341487501, 0.8088247196062808, 0.8109655845042477, 0.8135632589612889, 0.7662483588803802, 0.7951779400033656, 0.8032777253876369, 0.7920226170304594, 0.8088270643284766, 0.8118207585642068, 0.8157693141812843, 0.819329830669433, 0.8222040799156365, 0.8228908892412171, 0.8238795620661965, 0.8254043417505449, 0.827037955511429, 0.8283945561741544, 0.829404748614481, 0.8299754353467597, 0.8308752305721641, 0.830232187484397, 0.8330694810615678, 0.8334701052479091, 0.8336479653325252, 0.8349894510875326, 0.835568409973994, 0.8362817046337119, 0.8368938325257088, 0.8360982137956474, 0.8375002843249715, 0.838643562478023, 0.8400551800110458, 0.839461286346254, 0.8407974245210323, 0.8409370818870099, 0.8428830539203848, 0.8432217477699774, 0.8433764089901931, 0.8439050196958208, 0.8443513030570883, 0.8454784657687402, 0.8457947347081134, 0.8452484860263542, 0.8467829196168957, 0.8464704328684786, 0.8463420760929731, 0.8475471642626565, 0.8489522639883097, 0.8440991353614474, 0.8462408648921673, 0.8496041175721615, 0.8493629118693465, 0.8510894257394399, 0.8512941207471812, 0.8515626370994527, 0.8516785684843283, 0.8523982569480305, 0.8521240329906132, 0.8526175590401014, 0.8535172661886079, 0.8538231813422367, 0.854006743477863, 0.8395779504093135, 0.847875800800417, 0.8523285094869669, 0.8538214287493614, 0.8546972274195628, 0.8551144592898801, 0.8563901602257228, 0.8566708062839835, 0.8560584135766471, 0.8572799601117556, 0.857166454568688, 0.8580701972351991, 0.8566287507784022, 0.8576261879709084, 0.858106089725747, 0.858198147652604, 0.8587767780850248, 0.8590981537597678, 0.859617626976885, 0.858909171986311, 0.8595411423493273, 0.8595585603816887, 0.8603103117009715, 0.8604192978146615, 0.8608716280218315, 0.8600971265246086, 0.8565563197051737, 0.8600424772503915, 0.8612856075072651, 0.8615120516623159, 0.8616752236891517, 0.8615608144589882, 0.8623609735779811, 0.8628615727899354, 0.8607616266706166, 0.8624516596333427, 0.8629880125116869, 0.8632998527294868, 0.86343150643989, 0.8631159023890137, 0.8641589788492547, 0.8624598951009982, 0.8632348923486726, 0.8641233758753336, 0.864927735411694, 0.8641439152442105, 0.8644660357285388, 0.8637735534088468]}
predicting test subjects:   0%|          | 0/5 [00:00<?, ?it/s]predicting test subjects:  20%|██        | 1/5 [00:03<00:12,  3.11s/it]predicting test subjects:  40%|████      | 2/5 [00:05<00:08,  2.90s/it]predicting test subjects:  60%|██████    | 3/5 [00:07<00:05,  2.67s/it]predicting test subjects:  80%|████████  | 4/5 [00:09<00:02,  2.48s/it]predicting test subjects: 100%|██████████| 5/5 [00:12<00:00,  2.49s/it]
predicting train subjects:   0%|          | 0/266 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/266 [00:03<13:40,  3.10s/it]predicting train subjects:   1%|          | 2/266 [00:06<14:29,  3.29s/it]predicting train subjects:   1%|          | 3/266 [00:10<14:18,  3.26s/it]predicting train subjects:   2%|▏         | 4/266 [00:12<13:44,  3.15s/it]predicting train subjects:   2%|▏         | 5/266 [00:16<14:05,  3.24s/it]predicting train subjects:   2%|▏         | 6/266 [00:19<14:29,  3.35s/it]predicting train subjects:   3%|▎         | 7/266 [00:23<14:56,  3.46s/it]predicting train subjects:   3%|▎         | 8/266 [00:27<15:11,  3.53s/it]predicting train subjects:   3%|▎         | 9/266 [00:30<15:10,  3.54s/it]predicting train subjects:   4%|▍         | 10/266 [00:34<15:19,  3.59s/it]predicting train subjects:   4%|▍         | 11/266 [00:38<15:22,  3.62s/it]predicting train subjects:   5%|▍         | 12/266 [00:42<15:29,  3.66s/it]predicting train subjects:   5%|▍         | 13/266 [00:45<15:24,  3.66s/it]predicting train subjects:   5%|▌         | 14/266 [00:49<14:55,  3.55s/it]predicting train subjects:   6%|▌         | 15/266 [00:52<14:53,  3.56s/it]predicting train subjects:   6%|▌         | 16/266 [00:56<14:50,  3.56s/it]predicting train subjects:   6%|▋         | 17/266 [00:59<14:36,  3.52s/it]predicting train subjects:   7%|▋         | 18/266 [01:03<14:40,  3.55s/it]predicting train subjects:   7%|▋         | 19/266 [01:06<14:37,  3.55s/it]predicting train subjects:   8%|▊         | 20/266 [01:10<14:36,  3.56s/it]predicting train subjects:   8%|▊         | 21/266 [01:14<14:59,  3.67s/it]predicting train subjects:   8%|▊         | 22/266 [01:17<14:50,  3.65s/it]predicting train subjects:   9%|▊         | 23/266 [01:21<14:39,  3.62s/it]predicting train subjects:   9%|▉         | 24/266 [01:24<14:22,  3.56s/it]predicting train subjects:   9%|▉         | 25/266 [01:28<14:13,  3.54s/it]predicting train subjects:  10%|▉         | 26/266 [01:31<13:56,  3.48s/it]predicting train subjects:  10%|█         | 27/266 [01:35<13:55,  3.49s/it]predicting train subjects:  11%|█         | 28/266 [01:38<13:34,  3.42s/it]predicting train subjects:  11%|█         | 29/266 [01:42<13:38,  3.45s/it]predicting train subjects:  11%|█▏        | 30/266 [01:45<13:16,  3.38s/it]predicting train subjects:  12%|█▏        | 31/266 [01:48<13:26,  3.43s/it]predicting train subjects:  12%|█▏        | 32/266 [01:52<13:25,  3.44s/it]predicting train subjects:  12%|█▏        | 33/266 [01:55<13:15,  3.42s/it]predicting train subjects:  13%|█▎        | 34/266 [01:59<13:30,  3.49s/it]predicting train subjects:  13%|█▎        | 35/266 [02:02<13:13,  3.43s/it]predicting train subjects:  14%|█▎        | 36/266 [02:05<13:04,  3.41s/it]predicting train subjects:  14%|█▍        | 37/266 [02:09<12:48,  3.36s/it]predicting train subjects:  14%|█▍        | 38/266 [02:12<12:55,  3.40s/it]predicting train subjects:  15%|█▍        | 39/266 [02:15<12:38,  3.34s/it]predicting train subjects:  15%|█▌        | 40/266 [02:19<12:45,  3.39s/it]predicting train subjects:  15%|█▌        | 41/266 [02:22<12:34,  3.35s/it]predicting train subjects:  16%|█▌        | 42/266 [02:25<12:05,  3.24s/it]predicting train subjects:  16%|█▌        | 43/266 [02:28<11:36,  3.12s/it]predicting train subjects:  17%|█▋        | 44/266 [02:31<11:18,  3.06s/it]predicting train subjects:  17%|█▋        | 45/266 [02:34<10:58,  2.98s/it]predicting train subjects:  17%|█▋        | 46/266 [02:36<10:43,  2.93s/it]predicting train subjects:  18%|█▊        | 47/266 [02:39<10:34,  2.90s/it]predicting train subjects:  18%|█▊        | 48/266 [02:42<10:17,  2.83s/it]predicting train subjects:  18%|█▊        | 49/266 [02:45<10:26,  2.89s/it]predicting train subjects:  19%|█▉        | 50/266 [02:48<10:28,  2.91s/it]predicting train subjects:  19%|█▉        | 51/266 [02:51<10:18,  2.88s/it]predicting train subjects:  20%|█▉        | 52/266 [02:54<10:22,  2.91s/it]predicting train subjects:  20%|█▉        | 53/266 [02:57<10:11,  2.87s/it]predicting train subjects:  20%|██        | 54/266 [02:59<10:09,  2.87s/it]predicting train subjects:  21%|██        | 55/266 [03:02<09:53,  2.81s/it]predicting train subjects:  21%|██        | 56/266 [03:05<09:44,  2.78s/it]predicting train subjects:  21%|██▏       | 57/266 [03:07<09:30,  2.73s/it]predicting train subjects:  22%|██▏       | 58/266 [03:10<08:51,  2.55s/it]predicting train subjects:  22%|██▏       | 59/266 [03:12<08:22,  2.43s/it]predicting train subjects:  23%|██▎       | 60/266 [03:14<07:51,  2.29s/it]predicting train subjects:  23%|██▎       | 61/266 [03:16<07:30,  2.20s/it]predicting train subjects:  23%|██▎       | 62/266 [03:18<07:13,  2.12s/it]predicting train subjects:  24%|██▎       | 63/266 [03:20<07:02,  2.08s/it]predicting train subjects:  24%|██▍       | 64/266 [03:22<07:01,  2.08s/it]predicting train subjects:  24%|██▍       | 65/266 [03:24<06:52,  2.05s/it]predicting train subjects:  25%|██▍       | 66/266 [03:26<06:43,  2.02s/it]predicting train subjects:  25%|██▌       | 67/266 [03:27<06:34,  1.98s/it]predicting train subjects:  26%|██▌       | 68/266 [03:30<06:38,  2.01s/it]predicting train subjects:  26%|██▌       | 69/266 [03:31<06:31,  1.99s/it]predicting train subjects:  26%|██▋       | 70/266 [03:33<06:26,  1.97s/it]predicting train subjects:  27%|██▋       | 71/266 [03:35<06:26,  1.98s/it]predicting train subjects:  27%|██▋       | 72/266 [03:37<06:24,  1.98s/it]predicting train subjects:  27%|██▋       | 73/266 [03:39<06:20,  1.97s/it]predicting train subjects:  28%|██▊       | 74/266 [03:41<06:19,  1.98s/it]predicting train subjects:  28%|██▊       | 75/266 [03:43<06:17,  1.98s/it]predicting train subjects:  29%|██▊       | 76/266 [03:45<06:16,  1.98s/it]predicting train subjects:  29%|██▉       | 77/266 [03:47<06:11,  1.97s/it]predicting train subjects:  29%|██▉       | 78/266 [03:50<06:38,  2.12s/it]predicting train subjects:  30%|██▉       | 79/266 [03:52<07:00,  2.25s/it]predicting train subjects:  30%|███       | 80/266 [03:55<07:17,  2.35s/it]predicting train subjects:  30%|███       | 81/266 [03:57<07:26,  2.41s/it]predicting train subjects:  31%|███       | 82/266 [04:00<07:28,  2.44s/it]predicting train subjects:  31%|███       | 83/266 [04:02<07:32,  2.47s/it]predicting train subjects:  32%|███▏      | 84/266 [04:05<07:33,  2.49s/it]predicting train subjects:  32%|███▏      | 85/266 [04:08<07:32,  2.50s/it]predicting train subjects:  32%|███▏      | 86/266 [04:10<07:28,  2.49s/it]predicting train subjects:  33%|███▎      | 87/266 [04:12<07:27,  2.50s/it]predicting train subjects:  33%|███▎      | 88/266 [04:15<07:25,  2.50s/it]predicting train subjects:  33%|███▎      | 89/266 [04:18<07:27,  2.53s/it]predicting train subjects:  34%|███▍      | 90/266 [04:20<07:26,  2.53s/it]predicting train subjects:  34%|███▍      | 91/266 [04:23<07:25,  2.55s/it]predicting train subjects:  35%|███▍      | 92/266 [04:25<07:25,  2.56s/it]predicting train subjects:  35%|███▍      | 93/266 [04:28<07:20,  2.55s/it]predicting train subjects:  35%|███▌      | 94/266 [04:30<07:15,  2.53s/it]predicting train subjects:  36%|███▌      | 95/266 [04:33<07:13,  2.54s/it]predicting train subjects:  36%|███▌      | 96/266 [04:35<06:55,  2.44s/it]predicting train subjects:  36%|███▋      | 97/266 [04:38<06:58,  2.48s/it]predicting train subjects:  37%|███▋      | 98/266 [04:40<06:55,  2.47s/it]predicting train subjects:  37%|███▋      | 99/266 [04:42<06:18,  2.26s/it]predicting train subjects:  38%|███▊      | 100/266 [04:44<06:01,  2.18s/it]predicting train subjects:  38%|███▊      | 101/266 [04:46<05:55,  2.16s/it]predicting train subjects:  38%|███▊      | 102/266 [04:48<05:50,  2.14s/it]predicting train subjects:  39%|███▊      | 103/266 [04:50<05:49,  2.14s/it]predicting train subjects:  39%|███▉      | 104/266 [04:52<05:49,  2.16s/it]predicting train subjects:  39%|███▉      | 105/266 [04:55<05:47,  2.16s/it]predicting train subjects:  40%|███▉      | 106/266 [04:57<05:44,  2.15s/it]predicting train subjects:  40%|████      | 107/266 [04:59<05:41,  2.15s/it]predicting train subjects:  41%|████      | 108/266 [05:01<05:40,  2.15s/it]predicting train subjects:  41%|████      | 109/266 [05:03<05:36,  2.14s/it]predicting train subjects:  41%|████▏     | 110/266 [05:05<05:37,  2.16s/it]predicting train subjects:  42%|████▏     | 111/266 [05:08<05:35,  2.16s/it]predicting train subjects:  42%|████▏     | 112/266 [05:10<05:34,  2.17s/it]predicting train subjects:  42%|████▏     | 113/266 [05:12<05:29,  2.15s/it]predicting train subjects:  43%|████▎     | 114/266 [05:14<05:27,  2.16s/it]predicting train subjects:  43%|████▎     | 115/266 [05:16<05:23,  2.14s/it]predicting train subjects:  44%|████▎     | 116/266 [05:18<05:19,  2.13s/it]predicting train subjects:  44%|████▍     | 117/266 [05:20<05:14,  2.11s/it]predicting train subjects:  44%|████▍     | 118/266 [05:22<05:14,  2.13s/it]predicting train subjects:  45%|████▍     | 119/266 [05:25<05:29,  2.24s/it]predicting train subjects:  45%|████▌     | 120/266 [05:28<05:41,  2.34s/it]predicting train subjects:  45%|████▌     | 121/266 [05:30<05:45,  2.38s/it]predicting train subjects:  46%|████▌     | 122/266 [05:33<05:48,  2.42s/it]predicting train subjects:  46%|████▌     | 123/266 [05:35<05:48,  2.44s/it]predicting train subjects:  47%|████▋     | 124/266 [05:37<05:47,  2.45s/it]predicting train subjects:  47%|████▋     | 125/266 [05:40<05:47,  2.46s/it]predicting train subjects:  47%|████▋     | 126/266 [05:42<05:43,  2.45s/it]predicting train subjects:  48%|████▊     | 127/266 [05:45<05:41,  2.46s/it]predicting train subjects:  48%|████▊     | 128/266 [05:47<05:42,  2.48s/it]predicting train subjects:  48%|████▊     | 129/266 [05:50<05:40,  2.48s/it]predicting train subjects:  49%|████▉     | 130/266 [05:52<05:39,  2.50s/it]predicting train subjects:  49%|████▉     | 131/266 [05:55<05:36,  2.49s/it]predicting train subjects:  50%|████▉     | 132/266 [05:57<05:32,  2.48s/it]predicting train subjects:  50%|█████     | 133/266 [06:00<05:27,  2.46s/it]predicting train subjects:  50%|█████     | 134/266 [06:02<05:23,  2.45s/it]predicting train subjects:  51%|█████     | 135/266 [06:05<05:21,  2.45s/it]predicting train subjects:  51%|█████     | 136/266 [06:07<05:19,  2.46s/it]predicting train subjects:  52%|█████▏    | 137/266 [06:10<05:15,  2.44s/it]predicting train subjects:  52%|█████▏    | 138/266 [06:12<05:09,  2.42s/it]predicting train subjects:  52%|█████▏    | 139/266 [06:14<05:03,  2.39s/it]predicting train subjects:  53%|█████▎    | 140/266 [06:17<05:02,  2.40s/it]predicting train subjects:  53%|█████▎    | 141/266 [06:19<05:00,  2.40s/it]predicting train subjects:  53%|█████▎    | 142/266 [06:21<04:58,  2.41s/it]predicting train subjects:  54%|█████▍    | 143/266 [06:24<04:53,  2.39s/it]predicting train subjects:  54%|█████▍    | 144/266 [06:26<04:51,  2.39s/it]predicting train subjects:  55%|█████▍    | 145/266 [06:29<04:51,  2.41s/it]predicting train subjects:  55%|█████▍    | 146/266 [06:31<04:50,  2.42s/it]predicting train subjects:  55%|█████▌    | 147/266 [06:34<04:48,  2.42s/it]predicting train subjects:  56%|█████▌    | 148/266 [06:36<04:45,  2.42s/it]predicting train subjects:  56%|█████▌    | 149/266 [06:38<04:42,  2.42s/it]predicting train subjects:  56%|█████▋    | 150/266 [06:41<04:40,  2.42s/it]predicting train subjects:  57%|█████▋    | 151/266 [06:43<04:36,  2.41s/it]predicting train subjects:  57%|█████▋    | 152/266 [06:46<04:34,  2.41s/it]predicting train subjects:  58%|█████▊    | 153/266 [06:48<04:29,  2.39s/it]predicting train subjects:  58%|█████▊    | 154/266 [06:50<04:26,  2.38s/it]predicting train subjects:  58%|█████▊    | 155/266 [06:52<04:01,  2.18s/it]predicting train subjects:  59%|█████▊    | 156/266 [06:54<03:43,  2.03s/it]predicting train subjects:  59%|█████▉    | 157/266 [06:55<03:31,  1.94s/it]predicting train subjects:  59%|█████▉    | 158/266 [06:57<03:22,  1.87s/it]predicting train subjects:  60%|█████▉    | 159/266 [06:59<03:17,  1.84s/it]predicting train subjects:  60%|██████    | 160/266 [07:01<03:10,  1.79s/it]predicting train subjects:  61%|██████    | 161/266 [07:02<03:07,  1.78s/it]predicting train subjects:  61%|██████    | 162/266 [07:04<03:04,  1.77s/it]predicting train subjects:  61%|██████▏   | 163/266 [07:06<03:01,  1.76s/it]predicting train subjects:  62%|██████▏   | 164/266 [07:07<02:57,  1.74s/it]predicting train subjects:  62%|██████▏   | 165/266 [07:09<02:56,  1.75s/it]predicting train subjects:  62%|██████▏   | 166/266 [07:11<02:53,  1.74s/it]predicting train subjects:  63%|██████▎   | 167/266 [07:13<02:51,  1.74s/it]predicting train subjects:  63%|██████▎   | 168/266 [07:14<02:51,  1.75s/it]predicting train subjects:  64%|██████▎   | 169/266 [07:16<02:48,  1.74s/it]predicting train subjects:  64%|██████▍   | 170/266 [07:18<02:48,  1.75s/it]predicting train subjects:  64%|██████▍   | 171/266 [07:20<02:46,  1.76s/it]predicting train subjects:  65%|██████▍   | 172/266 [07:22<02:46,  1.77s/it]predicting train subjects:  65%|██████▌   | 173/266 [07:23<02:49,  1.83s/it]predicting train subjects:  65%|██████▌   | 174/266 [07:25<02:51,  1.87s/it]predicting train subjects:  66%|██████▌   | 175/266 [07:27<02:53,  1.91s/it]predicting train subjects:  66%|██████▌   | 176/266 [07:29<02:54,  1.94s/it]predicting train subjects:  67%|██████▋   | 177/266 [07:31<02:55,  1.97s/it]predicting train subjects:  67%|██████▋   | 178/266 [07:33<02:53,  1.97s/it]predicting train subjects:  67%|██████▋   | 179/266 [07:35<02:50,  1.96s/it]predicting train subjects:  68%|██████▊   | 180/266 [07:37<02:48,  1.96s/it]predicting train subjects:  68%|██████▊   | 181/266 [07:39<02:46,  1.95s/it]predicting train subjects:  68%|██████▊   | 182/266 [07:41<02:43,  1.94s/it]predicting train subjects:  69%|██████▉   | 183/266 [07:43<02:40,  1.93s/it]predicting train subjects:  69%|██████▉   | 184/266 [07:45<02:40,  1.96s/it]predicting train subjects:  70%|██████▉   | 185/266 [07:47<02:38,  1.95s/it]predicting train subjects:  70%|██████▉   | 186/266 [07:49<02:35,  1.94s/it]predicting train subjects:  70%|███████   | 187/266 [07:51<02:32,  1.93s/it]predicting train subjects:  71%|███████   | 188/266 [07:53<02:30,  1.93s/it]predicting train subjects:  71%|███████   | 189/266 [07:55<02:27,  1.92s/it]predicting train subjects:  71%|███████▏  | 190/266 [07:57<02:26,  1.93s/it]predicting train subjects:  72%|███████▏  | 191/266 [07:59<02:29,  2.00s/it]predicting train subjects:  72%|███████▏  | 192/266 [08:01<02:24,  1.96s/it]predicting train subjects:  73%|███████▎  | 193/266 [08:03<02:21,  1.94s/it]predicting train subjects:  73%|███████▎  | 194/266 [08:05<02:30,  2.09s/it]predicting train subjects:  73%|███████▎  | 195/266 [08:07<02:29,  2.11s/it]predicting train subjects:  74%|███████▎  | 196/266 [08:09<02:27,  2.11s/it]predicting train subjects:  74%|███████▍  | 197/266 [08:11<02:24,  2.10s/it]predicting train subjects:  74%|███████▍  | 198/266 [08:13<02:22,  2.10s/it]predicting train subjects:  75%|███████▍  | 199/266 [08:16<02:21,  2.11s/it]predicting train subjects:  75%|███████▌  | 200/266 [08:18<02:20,  2.12s/it]predicting train subjects:  76%|███████▌  | 201/266 [08:20<02:18,  2.13s/it]predicting train subjects:  76%|███████▌  | 202/266 [08:22<02:17,  2.15s/it]predicting train subjects:  76%|███████▋  | 203/266 [08:24<02:14,  2.13s/it]predicting train subjects:  77%|███████▋  | 204/266 [08:26<02:13,  2.15s/it]predicting train subjects:  77%|███████▋  | 205/266 [08:28<02:10,  2.13s/it]predicting train subjects:  77%|███████▋  | 206/266 [08:31<02:06,  2.11s/it]predicting train subjects:  78%|███████▊  | 207/266 [08:33<02:05,  2.12s/it]predicting train subjects:  78%|███████▊  | 208/266 [08:35<02:04,  2.15s/it]predicting train subjects:  79%|███████▊  | 209/266 [08:37<02:02,  2.14s/it]predicting train subjects:  79%|███████▉  | 210/266 [08:39<02:00,  2.15s/it]predicting train subjects:  79%|███████▉  | 211/266 [08:41<01:57,  2.13s/it]predicting train subjects:  80%|███████▉  | 212/266 [08:43<01:55,  2.13s/it]predicting train subjects:  80%|████████  | 213/266 [08:45<01:47,  2.02s/it]predicting train subjects:  80%|████████  | 214/266 [08:47<01:43,  1.99s/it]predicting train subjects:  81%|████████  | 215/266 [08:49<01:39,  1.95s/it]predicting train subjects:  81%|████████  | 216/266 [08:51<01:37,  1.96s/it]predicting train subjects:  82%|████████▏ | 217/266 [08:53<01:35,  1.94s/it]predicting train subjects:  82%|████████▏ | 218/266 [08:55<01:32,  1.94s/it]predicting train subjects:  82%|████████▏ | 219/266 [08:57<01:30,  1.92s/it]predicting train subjects:  83%|████████▎ | 220/266 [08:59<01:27,  1.91s/it]predicting train subjects:  83%|████████▎ | 221/266 [09:00<01:25,  1.91s/it]predicting train subjects:  83%|████████▎ | 222/266 [09:02<01:23,  1.90s/it]predicting train subjects:  84%|████████▍ | 223/266 [09:04<01:21,  1.90s/it]predicting train subjects:  84%|████████▍ | 224/266 [09:06<01:18,  1.88s/it]predicting train subjects:  85%|████████▍ | 225/266 [09:08<01:17,  1.88s/it]predicting train subjects:  85%|████████▍ | 226/266 [09:10<01:15,  1.88s/it]predicting train subjects:  85%|████████▌ | 227/266 [09:12<01:13,  1.88s/it]predicting train subjects:  86%|████████▌ | 228/266 [09:14<01:11,  1.88s/it]predicting train subjects:  86%|████████▌ | 229/266 [09:15<01:09,  1.88s/it]predicting train subjects:  86%|████████▋ | 230/266 [09:17<01:07,  1.88s/it]predicting train subjects:  87%|████████▋ | 231/266 [09:19<01:06,  1.90s/it]predicting train subjects:  87%|████████▋ | 232/266 [09:21<01:04,  1.91s/it]predicting train subjects:  88%|████████▊ | 233/266 [09:23<01:02,  1.90s/it]predicting train subjects:  88%|████████▊ | 234/266 [09:25<01:00,  1.91s/it]predicting train subjects:  88%|████████▊ | 235/266 [09:27<00:59,  1.92s/it]predicting train subjects:  89%|████████▊ | 236/266 [09:29<00:57,  1.93s/it]predicting train subjects:  89%|████████▉ | 237/266 [09:31<00:56,  1.93s/it]predicting train subjects:  89%|████████▉ | 238/266 [09:33<00:53,  1.93s/it]predicting train subjects:  90%|████████▉ | 239/266 [09:35<00:51,  1.91s/it]predicting train subjects:  90%|█████████ | 240/266 [09:37<00:49,  1.91s/it]predicting train subjects:  91%|█████████ | 241/266 [09:39<00:48,  1.92s/it]predicting train subjects:  91%|█████████ | 242/266 [09:40<00:46,  1.92s/it]predicting train subjects:  91%|█████████▏| 243/266 [09:42<00:43,  1.91s/it]predicting train subjects:  92%|█████████▏| 244/266 [09:44<00:42,  1.91s/it]predicting train subjects:  92%|█████████▏| 245/266 [09:46<00:40,  1.92s/it]predicting train subjects:  92%|█████████▏| 246/266 [09:48<00:38,  1.92s/it]predicting train subjects:  93%|█████████▎| 247/266 [09:50<00:36,  1.91s/it]predicting train subjects:  93%|█████████▎| 248/266 [09:52<00:34,  1.91s/it]predicting train subjects:  94%|█████████▎| 249/266 [09:54<00:35,  2.09s/it]predicting train subjects:  94%|█████████▍| 250/266 [09:57<00:35,  2.23s/it]predicting train subjects:  94%|█████████▍| 251/266 [09:59<00:34,  2.27s/it]predicting train subjects:  95%|█████████▍| 252/266 [10:02<00:32,  2.34s/it]predicting train subjects:  95%|█████████▌| 253/266 [10:04<00:30,  2.38s/it]predicting train subjects:  95%|█████████▌| 254/266 [10:07<00:28,  2.40s/it]predicting train subjects:  96%|█████████▌| 255/266 [10:09<00:26,  2.41s/it]predicting train subjects:  96%|█████████▌| 256/266 [10:12<00:24,  2.43s/it]predicting train subjects:  97%|█████████▋| 257/266 [10:14<00:22,  2.46s/it]predicting train subjects:  97%|█████████▋| 258/266 [10:17<00:19,  2.46s/it]predicting train subjects:  97%|█████████▋| 259/266 [10:19<00:17,  2.48s/it]predicting train subjects:  98%|█████████▊| 260/266 [10:22<00:14,  2.47s/it]predicting train subjects:  98%|█████████▊| 261/266 [10:24<00:12,  2.53s/it]predicting train subjects:  98%|█████████▊| 262/266 [10:27<00:10,  2.54s/it]predicting train subjects:  99%|█████████▉| 263/266 [10:29<00:07,  2.53s/it]predicting train subjects:  99%|█████████▉| 264/266 [10:32<00:05,  2.58s/it]predicting train subjects: 100%|█████████▉| 265/266 [10:35<00:02,  2.59s/it]predicting train subjects: 100%|██████████| 266/266 [10:37<00:00,  2.59s/it]

