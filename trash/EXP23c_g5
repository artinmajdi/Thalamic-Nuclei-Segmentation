2019-07-10 20:17:59.482277: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
2019-07-10 20:18:02.564101: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1392] Found device 0 with properties: 
name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285
pciBusID: 0000:85:00.0
totalMemory: 15.89GiB freeMemory: 15.60GiB
2019-07-10 20:18:02.564173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:18:02.970893: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:18:02.970974: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:18:02.970992: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:18:02.971596: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)
mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a’: File exists
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88
  return f(*args, **kwds)
Using TensorFlow backend.
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<13:34,  2.87s/it]Loading train:   1%|          | 2/285 [00:04<12:28,  2.64s/it]Loading train:   1%|          | 3/285 [00:07<11:45,  2.50s/it]Loading train:   1%|▏         | 4/285 [00:09<11:15,  2.40s/it]Loading train:   2%|▏         | 5/285 [00:11<10:37,  2.28s/it]Loading train:   2%|▏         | 6/285 [00:12<09:10,  1.97s/it]Loading train:   2%|▏         | 7/285 [00:15<10:15,  2.21s/it]Loading train:   3%|▎         | 8/285 [00:18<11:04,  2.40s/it]Loading train:   3%|▎         | 9/285 [00:20<11:03,  2.40s/it]Loading train:   4%|▎         | 10/285 [00:23<11:09,  2.43s/it]Loading train:   4%|▍         | 11/285 [00:24<09:53,  2.17s/it]Loading train:   4%|▍         | 12/285 [00:26<09:14,  2.03s/it]Loading train:   5%|▍         | 13/285 [00:27<08:28,  1.87s/it]Loading train:   5%|▍         | 14/285 [00:29<08:45,  1.94s/it]Loading train:   5%|▌         | 15/285 [00:32<08:57,  1.99s/it]Loading train:   6%|▌         | 16/285 [00:34<08:56,  2.00s/it]Loading train:   6%|▌         | 17/285 [00:35<07:51,  1.76s/it]Loading train:   6%|▋         | 18/285 [00:37<07:51,  1.77s/it]Loading train:   7%|▋         | 19/285 [00:38<07:25,  1.67s/it]Loading train:   7%|▋         | 20/285 [00:40<07:19,  1.66s/it]Loading train:   7%|▋         | 21/285 [00:41<07:16,  1.65s/it]Loading train:   8%|▊         | 22/285 [00:43<07:25,  1.69s/it]Loading train:   8%|▊         | 23/285 [00:45<07:33,  1.73s/it]Loading train:   8%|▊         | 24/285 [00:46<07:02,  1.62s/it]Loading train:   9%|▉         | 25/285 [00:48<07:37,  1.76s/it]Loading train:   9%|▉         | 26/285 [00:50<07:50,  1.82s/it]Loading train:   9%|▉         | 27/285 [00:52<07:24,  1.72s/it]Loading train:  10%|▉         | 28/285 [00:55<09:00,  2.10s/it]Loading train:  10%|█         | 29/285 [00:57<08:53,  2.09s/it]Loading train:  11%|█         | 30/285 [00:59<08:39,  2.04s/it]Loading train:  11%|█         | 31/285 [01:01<09:12,  2.18s/it]Loading train:  11%|█         | 32/285 [01:03<09:13,  2.19s/it]Loading train:  12%|█▏        | 33/285 [01:06<09:10,  2.18s/it]Loading train:  12%|█▏        | 34/285 [01:08<09:14,  2.21s/it]Loading train:  12%|█▏        | 35/285 [01:10<09:13,  2.21s/it]Loading train:  13%|█▎        | 36/285 [01:12<08:33,  2.06s/it]Loading train:  13%|█▎        | 37/285 [01:14<08:03,  1.95s/it]Loading train:  13%|█▎        | 38/285 [01:16<08:18,  2.02s/it]Loading train:  14%|█▎        | 39/285 [01:18<08:17,  2.02s/it]Loading train:  14%|█▍        | 40/285 [01:19<07:52,  1.93s/it]Loading train:  14%|█▍        | 41/285 [01:21<07:36,  1.87s/it]Loading train:  15%|█▍        | 42/285 [01:22<06:54,  1.71s/it]Loading train:  15%|█▌        | 43/285 [01:24<07:05,  1.76s/it]Loading train:  15%|█▌        | 44/285 [01:26<06:51,  1.71s/it]Loading train:  16%|█▌        | 45/285 [01:28<07:18,  1.83s/it]Loading train:  16%|█▌        | 46/285 [01:30<07:44,  1.95s/it]Loading train:  16%|█▋        | 47/285 [01:32<07:55,  2.00s/it]Loading train:  17%|█▋        | 48/285 [01:34<07:38,  1.94s/it]Loading train:  17%|█▋        | 49/285 [01:36<07:45,  1.97s/it]Loading train:  18%|█▊        | 50/285 [01:38<07:42,  1.97s/it]Loading train:  18%|█▊        | 51/285 [01:40<07:59,  2.05s/it]Loading train:  18%|█▊        | 52/285 [01:43<08:20,  2.15s/it]Loading train:  19%|█▊        | 53/285 [01:45<07:58,  2.06s/it]Loading train:  19%|█▉        | 54/285 [01:46<07:18,  1.90s/it]Loading train:  19%|█▉        | 55/285 [01:47<06:20,  1.65s/it]Loading train:  20%|█▉        | 56/285 [01:49<06:42,  1.76s/it]Loading train:  20%|██        | 57/285 [01:51<06:41,  1.76s/it]Loading train:  20%|██        | 58/285 [01:54<07:48,  2.06s/it]Loading train:  21%|██        | 59/285 [01:56<07:54,  2.10s/it]Loading train:  21%|██        | 60/285 [01:58<07:52,  2.10s/it]Loading train:  21%|██▏       | 61/285 [02:00<07:54,  2.12s/it]Loading train:  22%|██▏       | 62/285 [02:03<08:14,  2.22s/it]Loading train:  22%|██▏       | 63/285 [02:05<07:59,  2.16s/it]Loading train:  22%|██▏       | 64/285 [02:06<07:21,  2.00s/it]Loading train:  23%|██▎       | 65/285 [02:09<07:56,  2.17s/it]Loading train:  23%|██▎       | 66/285 [02:12<08:30,  2.33s/it]Loading train:  24%|██▎       | 67/285 [02:14<08:03,  2.22s/it]Loading train:  24%|██▍       | 68/285 [02:16<07:42,  2.13s/it]Loading train:  24%|██▍       | 69/285 [02:17<07:06,  1.97s/it]Loading train:  25%|██▍       | 70/285 [02:19<07:15,  2.03s/it]Loading train:  25%|██▍       | 71/285 [02:21<06:55,  1.94s/it]Loading train:  25%|██▌       | 72/285 [02:23<06:38,  1.87s/it]Loading train:  26%|██▌       | 73/285 [02:25<06:38,  1.88s/it]Loading train:  26%|██▌       | 74/285 [02:26<06:22,  1.81s/it]Loading train:  26%|██▋       | 75/285 [02:28<05:54,  1.69s/it]Loading train:  27%|██▋       | 76/285 [02:29<05:50,  1.68s/it]Loading train:  27%|██▋       | 77/285 [02:31<05:31,  1.59s/it]Loading train:  27%|██▋       | 78/285 [02:32<05:30,  1.60s/it]Loading train:  28%|██▊       | 79/285 [02:34<05:46,  1.68s/it]Loading train:  28%|██▊       | 80/285 [02:36<05:42,  1.67s/it]Loading train:  28%|██▊       | 81/285 [02:37<05:23,  1.58s/it]Loading train:  29%|██▉       | 82/285 [02:39<05:03,  1.50s/it]Loading train:  29%|██▉       | 83/285 [02:41<05:30,  1.64s/it]Loading train:  29%|██▉       | 84/285 [02:42<05:27,  1.63s/it]Loading train:  30%|██▉       | 85/285 [02:44<05:54,  1.77s/it]Loading train:  30%|███       | 86/285 [02:47<06:27,  1.95s/it]Loading train:  31%|███       | 87/285 [02:49<07:07,  2.16s/it]Loading train:  31%|███       | 88/285 [02:51<06:55,  2.11s/it]Loading train:  31%|███       | 89/285 [02:53<06:37,  2.03s/it]Loading train:  32%|███▏      | 90/285 [02:55<06:36,  2.03s/it]Loading train:  32%|███▏      | 91/285 [02:57<06:28,  2.00s/it]Loading train:  32%|███▏      | 92/285 [02:59<06:30,  2.03s/it]Loading train:  33%|███▎      | 93/285 [03:01<06:30,  2.03s/it]Loading train:  33%|███▎      | 94/285 [03:03<06:20,  1.99s/it]Loading train:  33%|███▎      | 95/285 [03:05<06:16,  1.98s/it]Loading train:  34%|███▎      | 96/285 [03:07<05:48,  1.84s/it]Loading train:  34%|███▍      | 97/285 [03:08<05:49,  1.86s/it]Loading train:  34%|███▍      | 98/285 [03:11<06:06,  1.96s/it]Loading train:  35%|███▍      | 99/285 [03:12<05:28,  1.77s/it]Loading train:  35%|███▌      | 100/285 [03:14<05:53,  1.91s/it]Loading train:  35%|███▌      | 101/285 [03:16<05:29,  1.79s/it]Loading train:  36%|███▌      | 102/285 [03:18<05:38,  1.85s/it]Loading train:  36%|███▌      | 103/285 [03:20<05:42,  1.88s/it]Loading train:  36%|███▋      | 104/285 [03:22<05:56,  1.97s/it]Loading train:  37%|███▋      | 105/285 [03:24<06:05,  2.03s/it]Loading train:  37%|███▋      | 106/285 [03:25<05:32,  1.86s/it]Loading train:  38%|███▊      | 107/285 [03:27<05:02,  1.70s/it]Loading train:  38%|███▊      | 108/285 [03:29<05:12,  1.77s/it]Loading train:  38%|███▊      | 109/285 [03:31<05:21,  1.83s/it]Loading train:  39%|███▊      | 110/285 [03:32<05:09,  1.77s/it]Loading train:  39%|███▉      | 111/285 [03:34<04:59,  1.72s/it]Loading train:  39%|███▉      | 112/285 [03:36<05:15,  1.82s/it]Loading train:  40%|███▉      | 113/285 [03:38<05:36,  1.96s/it]Loading train:  40%|████      | 114/285 [03:40<05:46,  2.03s/it]Loading train:  40%|████      | 115/285 [03:43<06:16,  2.22s/it]Loading train:  41%|████      | 116/285 [03:45<05:57,  2.11s/it]Loading train:  41%|████      | 117/285 [03:47<05:30,  1.97s/it]Loading train:  41%|████▏     | 118/285 [03:48<05:14,  1.88s/it]Loading train:  42%|████▏     | 119/285 [03:50<05:11,  1.88s/it]Loading train:  42%|████▏     | 120/285 [03:52<04:56,  1.80s/it]Loading train:  42%|████▏     | 121/285 [03:54<05:20,  1.96s/it]Loading train:  43%|████▎     | 122/285 [03:56<05:21,  1.97s/it]Loading train:  43%|████▎     | 123/285 [03:58<05:29,  2.03s/it]Loading train:  44%|████▎     | 124/285 [04:00<05:10,  1.93s/it]Loading train:  44%|████▍     | 125/285 [04:01<04:48,  1.80s/it]Loading train:  44%|████▍     | 126/285 [04:03<04:40,  1.76s/it]Loading train:  45%|████▍     | 127/285 [04:05<04:35,  1.74s/it]Loading train:  45%|████▍     | 128/285 [04:07<04:42,  1.80s/it]Loading train:  45%|████▌     | 129/285 [04:08<04:19,  1.66s/it]Loading train:  46%|████▌     | 130/285 [04:10<04:39,  1.80s/it]Loading train:  46%|████▌     | 131/285 [04:12<04:21,  1.70s/it]Loading train:  46%|████▋     | 132/285 [04:13<04:02,  1.58s/it]Loading train:  47%|████▋     | 133/285 [04:15<04:21,  1.72s/it]Loading train:  47%|████▋     | 134/285 [04:16<04:00,  1.59s/it]Loading train:  47%|████▋     | 135/285 [04:18<04:22,  1.75s/it]Loading train:  48%|████▊     | 136/285 [04:20<04:30,  1.81s/it]Loading train:  48%|████▊     | 137/285 [04:22<04:26,  1.80s/it]Loading train:  48%|████▊     | 138/285 [04:23<04:00,  1.64s/it]Loading train:  49%|████▉     | 139/285 [04:25<03:45,  1.54s/it]Loading train:  49%|████▉     | 140/285 [04:26<03:48,  1.57s/it]Loading train:  49%|████▉     | 141/285 [04:28<03:31,  1.47s/it]Loading train:  50%|████▉     | 142/285 [04:29<03:37,  1.52s/it]Loading train:  50%|█████     | 143/285 [04:31<03:28,  1.47s/it]Loading train:  51%|█████     | 144/285 [04:32<03:23,  1.45s/it]Loading train:  51%|█████     | 145/285 [04:33<03:13,  1.39s/it]Loading train:  51%|█████     | 146/285 [04:35<03:29,  1.51s/it]Loading train:  52%|█████▏    | 147/285 [04:37<03:26,  1.50s/it]Loading train:  52%|█████▏    | 148/285 [04:37<03:02,  1.33s/it]Loading train:  52%|█████▏    | 149/285 [04:38<02:43,  1.20s/it]Loading train:  53%|█████▎    | 150/285 [04:40<03:07,  1.39s/it]Loading train:  53%|█████▎    | 151/285 [04:42<03:21,  1.50s/it]Loading train:  53%|█████▎    | 152/285 [04:43<03:12,  1.45s/it]Loading train:  54%|█████▎    | 153/285 [04:45<03:03,  1.39s/it]Loading train:  54%|█████▍    | 154/285 [04:46<02:58,  1.36s/it]Loading train:  54%|█████▍    | 155/285 [04:47<02:42,  1.25s/it]Loading train:  55%|█████▍    | 156/285 [04:48<02:35,  1.20s/it]Loading train:  55%|█████▌    | 157/285 [04:49<02:20,  1.10s/it]Loading train:  55%|█████▌    | 158/285 [04:50<02:13,  1.05s/it]Loading train:  56%|█████▌    | 159/285 [04:51<02:13,  1.06s/it]Loading train:  56%|█████▌    | 160/285 [04:52<02:07,  1.02s/it]Loading train:  56%|█████▋    | 161/285 [04:53<02:17,  1.11s/it]Loading train:  57%|█████▋    | 162/285 [04:54<02:11,  1.07s/it]Loading train:  57%|█████▋    | 163/285 [04:55<02:19,  1.14s/it]Loading train:  58%|█████▊    | 164/285 [04:57<02:30,  1.24s/it]Loading train:  58%|█████▊    | 165/285 [04:58<02:15,  1.13s/it]Loading train:  58%|█████▊    | 166/285 [04:59<02:09,  1.08s/it]Loading train:  59%|█████▊    | 167/285 [05:00<02:06,  1.07s/it]Loading train:  59%|█████▉    | 168/285 [05:01<02:04,  1.06s/it]Loading train:  59%|█████▉    | 169/285 [05:02<02:03,  1.07s/it]Loading train:  60%|█████▉    | 170/285 [05:03<02:02,  1.07s/it]Loading train:  60%|██████    | 171/285 [05:04<01:56,  1.02s/it]Loading train:  60%|██████    | 172/285 [05:05<02:00,  1.07s/it]Loading train:  61%|██████    | 173/285 [05:06<02:03,  1.10s/it]Loading train:  61%|██████    | 174/285 [05:07<02:05,  1.13s/it]Loading train:  61%|██████▏   | 175/285 [05:09<02:16,  1.24s/it]Loading train:  62%|██████▏   | 176/285 [05:10<02:18,  1.27s/it]Loading train:  62%|██████▏   | 177/285 [05:11<02:00,  1.12s/it]Loading train:  62%|██████▏   | 178/285 [05:12<01:47,  1.01s/it]Loading train:  63%|██████▎   | 179/285 [05:12<01:37,  1.08it/s]Loading train:  63%|██████▎   | 180/285 [05:14<01:50,  1.05s/it]Loading train:  64%|██████▎   | 181/285 [05:15<01:46,  1.03s/it]Loading train:  64%|██████▍   | 182/285 [05:16<01:46,  1.04s/it]Loading train:  64%|██████▍   | 183/285 [05:17<01:54,  1.12s/it]Loading train:  65%|██████▍   | 184/285 [05:18<01:42,  1.01s/it]Loading train:  65%|██████▍   | 185/285 [05:19<01:33,  1.07it/s]Loading train:  65%|██████▌   | 186/285 [05:20<01:30,  1.09it/s]Loading train:  66%|██████▌   | 187/285 [05:20<01:29,  1.09it/s]Loading train:  66%|██████▌   | 188/285 [05:21<01:28,  1.09it/s]Loading train:  66%|██████▋   | 189/285 [05:22<01:22,  1.16it/s]Loading train:  67%|██████▋   | 190/285 [05:23<01:19,  1.19it/s]Loading train:  67%|██████▋   | 191/285 [05:24<01:20,  1.17it/s]Loading train:  67%|██████▋   | 192/285 [05:24<01:14,  1.24it/s]Loading train:  68%|██████▊   | 193/285 [05:25<01:12,  1.27it/s]Loading train:  68%|██████▊   | 194/285 [05:26<01:10,  1.28it/s]Loading train:  68%|██████▊   | 195/285 [05:27<01:08,  1.31it/s]Loading train:  69%|██████▉   | 196/285 [05:28<01:13,  1.20it/s]Loading train:  69%|██████▉   | 197/285 [05:29<01:15,  1.17it/s]Loading train:  69%|██████▉   | 198/285 [05:30<01:16,  1.13it/s]Loading train:  70%|██████▉   | 199/285 [05:30<01:09,  1.24it/s]Loading train:  70%|███████   | 200/285 [05:31<01:03,  1.34it/s]Loading train:  71%|███████   | 201/285 [05:32<01:04,  1.30it/s]Loading train:  71%|███████   | 202/285 [05:32<01:02,  1.33it/s]Loading train:  71%|███████   | 203/285 [05:33<01:00,  1.36it/s]Loading train:  72%|███████▏  | 204/285 [05:34<00:57,  1.41it/s]Loading train:  72%|███████▏  | 205/285 [05:34<00:58,  1.37it/s]Loading train:  72%|███████▏  | 206/285 [05:35<00:58,  1.35it/s]Loading train:  73%|███████▎  | 207/285 [05:36<01:02,  1.24it/s]Loading train:  73%|███████▎  | 208/285 [05:37<01:04,  1.20it/s]Loading train:  73%|███████▎  | 209/285 [05:38<01:06,  1.14it/s]Loading train:  74%|███████▎  | 210/285 [05:39<01:07,  1.11it/s]Loading train:  74%|███████▍  | 211/285 [05:40<01:02,  1.19it/s]Loading train:  74%|███████▍  | 212/285 [05:41<01:01,  1.19it/s]Loading train:  75%|███████▍  | 213/285 [05:41<01:00,  1.19it/s]Loading train:  75%|███████▌  | 214/285 [05:42<00:56,  1.25it/s]Loading train:  75%|███████▌  | 215/285 [05:43<00:59,  1.19it/s]Loading train:  76%|███████▌  | 216/285 [05:44<00:53,  1.29it/s]Loading train:  76%|███████▌  | 217/285 [05:45<00:55,  1.21it/s]Loading train:  76%|███████▋  | 218/285 [05:45<00:55,  1.20it/s]Loading train:  77%|███████▋  | 219/285 [05:46<00:57,  1.15it/s]Loading train:  77%|███████▋  | 220/285 [05:47<00:52,  1.25it/s]Loading train:  78%|███████▊  | 221/285 [05:48<00:48,  1.31it/s]Loading train:  78%|███████▊  | 222/285 [05:49<00:49,  1.26it/s]Loading train:  78%|███████▊  | 223/285 [05:49<00:48,  1.27it/s]Loading train:  79%|███████▊  | 224/285 [05:50<00:47,  1.30it/s]Loading train:  79%|███████▉  | 225/285 [05:51<00:44,  1.34it/s]Loading train:  79%|███████▉  | 226/285 [05:52<00:46,  1.26it/s]Loading train:  80%|███████▉  | 227/285 [05:53<00:47,  1.22it/s]Loading train:  80%|████████  | 228/285 [05:53<00:48,  1.18it/s]Loading train:  80%|████████  | 229/285 [05:54<00:45,  1.22it/s]Loading train:  81%|████████  | 230/285 [05:55<00:42,  1.28it/s]Loading train:  81%|████████  | 231/285 [05:56<00:40,  1.34it/s]Loading train:  81%|████████▏ | 232/285 [05:56<00:40,  1.31it/s]Loading train:  82%|████████▏ | 233/285 [05:57<00:38,  1.36it/s]Loading train:  82%|████████▏ | 234/285 [05:58<00:38,  1.32it/s]Loading train:  82%|████████▏ | 235/285 [05:59<00:37,  1.33it/s]Loading train:  83%|████████▎ | 236/285 [06:00<00:40,  1.22it/s]Loading train:  83%|████████▎ | 237/285 [06:00<00:39,  1.22it/s]Loading train:  84%|████████▎ | 238/285 [06:01<00:40,  1.17it/s]Loading train:  84%|████████▍ | 239/285 [06:02<00:38,  1.19it/s]Loading train:  84%|████████▍ | 240/285 [06:03<00:36,  1.23it/s]Loading train:  85%|████████▍ | 241/285 [06:04<00:34,  1.27it/s]Loading train:  85%|████████▍ | 242/285 [06:04<00:31,  1.35it/s]Loading train:  85%|████████▌ | 243/285 [06:05<00:29,  1.42it/s]Loading train:  86%|████████▌ | 244/285 [06:06<00:30,  1.33it/s]Loading train:  86%|████████▌ | 245/285 [06:06<00:27,  1.44it/s]Loading train:  86%|████████▋ | 246/285 [06:07<00:28,  1.35it/s]Loading train:  87%|████████▋ | 247/285 [06:08<00:29,  1.28it/s]Loading train:  87%|████████▋ | 248/285 [06:09<00:27,  1.35it/s]Loading train:  87%|████████▋ | 249/285 [06:09<00:24,  1.46it/s]Loading train:  88%|████████▊ | 250/285 [06:10<00:24,  1.46it/s]Loading train:  88%|████████▊ | 251/285 [06:11<00:23,  1.42it/s]Loading train:  88%|████████▊ | 252/285 [06:11<00:22,  1.44it/s]Loading train:  89%|████████▉ | 253/285 [06:12<00:23,  1.34it/s]Loading train:  89%|████████▉ | 254/285 [06:13<00:24,  1.26it/s]Loading train:  89%|████████▉ | 255/285 [06:14<00:25,  1.18it/s]Loading train:  90%|████████▉ | 256/285 [06:15<00:22,  1.27it/s]Loading train:  90%|█████████ | 257/285 [06:15<00:20,  1.33it/s]Loading train:  91%|█████████ | 258/285 [06:16<00:21,  1.28it/s]Loading train:  91%|█████████ | 259/285 [06:17<00:20,  1.30it/s]Loading train:  91%|█████████ | 260/285 [06:18<00:18,  1.35it/s]Loading train:  92%|█████████▏| 261/285 [06:18<00:17,  1.38it/s]Loading train:  92%|█████████▏| 262/285 [06:19<00:16,  1.38it/s]Loading train:  92%|█████████▏| 263/285 [06:20<00:16,  1.35it/s]Loading train:  93%|█████████▎| 264/285 [06:21<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [06:22<00:16,  1.19it/s]Loading train:  93%|█████████▎| 266/285 [06:22<00:15,  1.26it/s]Loading train:  94%|█████████▎| 267/285 [06:23<00:13,  1.30it/s]Loading train:  94%|█████████▍| 268/285 [06:24<00:13,  1.22it/s]Loading train:  94%|█████████▍| 269/285 [06:25<00:12,  1.24it/s]Loading train:  95%|█████████▍| 270/285 [06:25<00:11,  1.28it/s]Loading train:  95%|█████████▌| 271/285 [06:26<00:10,  1.36it/s]Loading train:  95%|█████████▌| 272/285 [06:27<00:09,  1.32it/s]Loading train:  96%|█████████▌| 273/285 [06:28<00:08,  1.41it/s]Loading train:  96%|█████████▌| 274/285 [06:28<00:07,  1.49it/s]Loading train:  96%|█████████▋| 275/285 [06:29<00:07,  1.36it/s]Loading train:  97%|█████████▋| 276/285 [06:30<00:06,  1.32it/s]Loading train:  97%|█████████▋| 277/285 [06:30<00:05,  1.41it/s]Loading train:  98%|█████████▊| 278/285 [06:31<00:04,  1.47it/s]Loading train:  98%|█████████▊| 279/285 [06:32<00:04,  1.46it/s]Loading train:  98%|█████████▊| 280/285 [06:32<00:03,  1.53it/s]Loading train:  99%|█████████▊| 281/285 [06:33<00:02,  1.47it/s]Loading train:  99%|█████████▉| 282/285 [06:34<00:02,  1.49it/s]Loading train:  99%|█████████▉| 283/285 [06:35<00:01,  1.34it/s]Loading train: 100%|█████████▉| 284/285 [06:36<00:00,  1.25it/s]Loading train: 100%|██████████| 285/285 [06:36<00:00,  1.20it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:00, 264.71it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:00, 287.00it/s]concatenating: train:  35%|███▍      | 99/285 [00:00<00:00, 304.05it/s]concatenating: train:  47%|████▋     | 133/285 [00:00<00:00, 313.17it/s]concatenating: train:  57%|█████▋    | 163/285 [00:00<00:00, 307.49it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 260.84it/s]concatenating: train:  75%|███████▌  | 215/285 [00:00<00:00, 244.32it/s]concatenating: train:  84%|████████▍ | 239/285 [00:00<00:00, 237.43it/s]concatenating: train:  93%|█████████▎| 264/285 [00:00<00:00, 240.35it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 278.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.29s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.24s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 190.36it/s]
/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.34it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.32it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:17,  2.35it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:11,  3.11it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:02<00:11,  2.92it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:08,  3.77it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:07,  4.12it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.53it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:03,  6.18it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  7.90it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:01,  8.70it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  9.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:05<00:03,  3.40it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:02,  4.23it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.22it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:05<00:00,  6.18it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  5.90it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.94it/s]---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   598         dropout_7[0][0]                  
==================================================================================================
Total params: 128,918
Trainable params: 30,418
Non-trainable params: 98,500
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 3.0659 - acc: 0.6592 - mDice: 0.0776 - val_loss: 2.6281 - val_acc: 0.8814 - val_mDice: 0.1632

Epoch 00001: val_mDice improved from -inf to 0.16321, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 8s - loss: 1.2626 - acc: 0.8768 - mDice: 0.2985 - val_loss: 1.6251 - val_acc: 0.9066 - val_mDice: 0.3586

Epoch 00002: val_mDice improved from 0.16321 to 0.35860, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 8s - loss: 0.7384 - acc: 0.8892 - mDice: 0.4613 - val_loss: 1.3396 - val_acc: 0.9200 - val_mDice: 0.4664

Epoch 00003: val_mDice improved from 0.35860 to 0.46638, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 8s - loss: 0.6056 - acc: 0.9002 - mDice: 0.5283 - val_loss: 1.1545 - val_acc: 0.9249 - val_mDice: 0.5416

Epoch 00004: val_mDice improved from 0.46638 to 0.54156, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 8s - loss: 0.5483 - acc: 0.9069 - mDice: 0.5610 - val_loss: 1.1151 - val_acc: 0.9258 - val_mDice: 0.5505

Epoch 00005: val_mDice improved from 0.54156 to 0.55046, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 8s - loss: 0.5121 - acc: 0.9115 - mDice: 0.5827 - val_loss: 1.0884 - val_acc: 0.9323 - val_mDice: 0.5518

Epoch 00006: val_mDice improved from 0.55046 to 0.55177, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 8s - loss: 0.4870 - acc: 0.9155 - mDice: 0.5982 - val_loss: 1.0159 - val_acc: 0.9367 - val_mDice: 0.5579

Epoch 00007: val_mDice improved from 0.55177 to 0.55792, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 8s - loss: 0.4703 - acc: 0.9193 - mDice: 0.6089 - val_loss: 0.9274 - val_acc: 0.9406 - val_mDice: 0.5708

Epoch 00008: val_mDice improved from 0.55792 to 0.57081, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 8s - loss: 0.4555 - acc: 0.9229 - mDice: 0.6184 - val_loss: 0.9186 - val_acc: 0.9376 - val_mDice: 0.5770

Epoch 00009: val_mDice improved from 0.57081 to 0.57699, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 8s - loss: 0.4452 - acc: 0.9252 - mDice: 0.6251 - val_loss: 0.8837 - val_acc: 0.9431 - val_mDice: 0.5692

Epoch 00010: val_mDice did not improve from 0.57699
Epoch 11/300
 - 8s - loss: 0.4375 - acc: 0.9266 - mDice: 0.6301 - val_loss: 0.9248 - val_acc: 0.9419 - val_mDice: 0.5547

Epoch 00011: val_mDice did not improve from 0.57699
Epoch 12/300
 - 8s - loss: 0.4289 - acc: 0.9278 - mDice: 0.6358 - val_loss: 0.8716 - val_acc: 0.9422 - val_mDice: 0.5673

Epoch 00012: val_mDice did not improve from 0.57699
Epoch 13/300
 - 8s - loss: 0.4202 - acc: 0.9287 - mDice: 0.6415 - val_loss: 0.8440 - val_acc: 0.9411 - val_mDice: 0.5867

Epoch 00013: val_mDice improved from 0.57699 to 0.58667, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.4153 - acc: 0.9292 - mDice: 0.6449 - val_loss: 0.8558 - val_acc: 0.9443 - val_mDice: 0.5579

Epoch 00014: val_mDice did not improve from 0.58667
Epoch 15/300
 - 8s - loss: 0.4080 - acc: 0.9300 - mDice: 0.6496 - val_loss: 0.8732 - val_acc: 0.9447 - val_mDice: 0.5645

Epoch 00015: val_mDice did not improve from 0.58667
Epoch 16/300
 - 8s - loss: 0.4051 - acc: 0.9303 - mDice: 0.6518 - val_loss: 0.8444 - val_acc: 0.9440 - val_mDice: 0.5824

Epoch 00016: val_mDice did not improve from 0.58667
Epoch 17/300
 - 8s - loss: 0.4000 - acc: 0.9310 - mDice: 0.6553 - val_loss: 0.8146 - val_acc: 0.9442 - val_mDice: 0.5613

Epoch 00017: val_mDice did not improve from 0.58667
Epoch 18/300
 - 8s - loss: 0.3944 - acc: 0.9312 - mDice: 0.6589 - val_loss: 0.8130 - val_acc: 0.9443 - val_mDice: 0.5839

Epoch 00018: val_mDice did not improve from 0.58667
Epoch 19/300
 - 8s - loss: 0.3879 - acc: 0.9321 - mDice: 0.6633 - val_loss: 0.7930 - val_acc: 0.9455 - val_mDice: 0.5649

Epoch 00019: val_mDice did not improve from 0.58667
Epoch 20/300
 - 8s - loss: 0.3874 - acc: 0.9322 - mDice: 0.6637 - val_loss: 0.8123 - val_acc: 0.9416 - val_mDice: 0.5830

Epoch 00020: val_mDice did not improve from 0.58667
Epoch 21/300
 - 8s - loss: 0.3814 - acc: 0.9329 - mDice: 0.6678 - val_loss: 0.7871 - val_acc: 0.9448 - val_mDice: 0.5632

Epoch 00021: val_mDice did not improve from 0.58667
Epoch 22/300
 - 8s - loss: 0.3774 - acc: 0.9333 - mDice: 0.6705 - val_loss: 0.7226 - val_acc: 0.9422 - val_mDice: 0.5868

Epoch 00022: val_mDice improved from 0.58667 to 0.58683, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 8s - loss: 0.3764 - acc: 0.9334 - mDice: 0.6713 - val_loss: 0.7029 - val_acc: 0.9439 - val_mDice: 0.5878

Epoch 00023: val_mDice improved from 0.58683 to 0.58778, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 8s - loss: 0.3730 - acc: 0.9339 - mDice: 0.6737 - val_loss: 0.7368 - val_acc: 0.9446 - val_mDice: 0.5772

Epoch 00024: val_mDice did not improve from 0.58778
Epoch 25/300
 - 8s - loss: 0.3704 - acc: 0.9340 - mDice: 0.6755 - val_loss: 0.7443 - val_acc: 0.9395 - val_mDice: 0.5781

Epoch 00025: val_mDice did not improve from 0.58778
Epoch 26/300
 - 8s - loss: 0.3681 - acc: 0.9342 - mDice: 0.6771 - val_loss: 0.7610 - val_acc: 0.9445 - val_mDice: 0.5647

Epoch 00026: val_mDice did not improve from 0.58778
Epoch 27/300
 - 8s - loss: 0.3647 - acc: 0.9345 - mDice: 0.6794 - val_loss: 0.7354 - val_acc: 0.9448 - val_mDice: 0.5838

Epoch 00027: val_mDice did not improve from 0.58778
Epoch 28/300
 - 8s - loss: 0.3616 - acc: 0.9347 - mDice: 0.6817 - val_loss: 0.6898 - val_acc: 0.9444 - val_mDice: 0.5869

Epoch 00028: val_mDice did not improve from 0.58778
Epoch 29/300
 - 8s - loss: 0.3613 - acc: 0.9351 - mDice: 0.6819 - val_loss: 0.7508 - val_acc: 0.9400 - val_mDice: 0.5816

Epoch 00029: val_mDice did not improve from 0.58778
Epoch 30/300
 - 8s - loss: 0.3582 - acc: 0.9353 - mDice: 0.6841 - val_loss: 0.6921 - val_acc: 0.9419 - val_mDice: 0.5759

Epoch 00030: val_mDice did not improve from 0.58778
Epoch 31/300
 - 8s - loss: 0.3547 - acc: 0.9357 - mDice: 0.6866 - val_loss: 0.7442 - val_acc: 0.9399 - val_mDice: 0.5757

Epoch 00031: val_mDice did not improve from 0.58778
Epoch 32/300
 - 8s - loss: 0.3541 - acc: 0.9358 - mDice: 0.6870 - val_loss: 0.6815 - val_acc: 0.9430 - val_mDice: 0.5792

Epoch 00032: val_mDice did not improve from 0.58778
Epoch 33/300
 - 8s - loss: 0.3520 - acc: 0.9360 - mDice: 0.6886 - val_loss: 0.7353 - val_acc: 0.9442 - val_mDice: 0.5674

Epoch 00033: val_mDice did not improve from 0.58778
Epoch 34/300
 - 8s - loss: 0.3503 - acc: 0.9361 - mDice: 0.6897 - val_loss: 0.6700 - val_acc: 0.9424 - val_mDice: 0.5795

Epoch 00034: val_mDice did not improve from 0.58778
Epoch 35/300
 - 8s - loss: 0.3496 - acc: 0.9362 - mDice: 0.6903 - val_loss: 0.7040 - val_acc: 0.9449 - val_mDice: 0.5630

Epoch 00035: val_mDice did not improve from 0.58778
Epoch 36/300
 - 8s - loss: 0.3486 - acc: 0.9363 - mDice: 0.6910 - val_loss: 0.6799 - val_acc: 0.9449 - val_mDice: 0.5648

Epoch 00036: val_mDice did not improve from 0.58778
Epoch 37/300
 - 8s - loss: 0.3445 - acc: 0.9367 - mDice: 0.6938 - val_loss: 0.7138 - val_acc: 0.9434 - val_mDice: 0.5842

Epoch 00037: val_mDice did not improve from 0.58778
Epoch 38/300
 - 8s - loss: 0.3428 - acc: 0.9368 - mDice: 0.6951 - val_loss: 0.6469 - val_acc: 0.9448 - val_mDice: 0.5812

Epoch 00038: val_mDice did not improve from 0.58778
Epoch 39/300
 - 8s - loss: 0.3423 - acc: 0.9370 - mDice: 0.6956 - val_loss: 0.6458 - val_acc: 0.9455 - val_mDice: 0.5763

Epoch 00039: val_mDice did not improve from 0.58778
Epoch 40/300
 - 8s - loss: 0.3401 - acc: 0.9372 - mDice: 0.6972 - val_loss: 0.7085 - val_acc: 0.9436 - val_mDice: 0.5794

Epoch 00040: val_mDice did not improve from 0.58778
Epoch 41/300
 - 8s - loss: 0.3382 - acc: 0.9374 - mDice: 0.6984 - val_loss: 0.7081 - val_acc: 0.9448 - val_mDice: 0.5847

Epoch 00041: val_mDice did not improve from 0.58778
Epoch 42/300
 - 8s - loss: 0.3373 - acc: 0.9375 - mDice: 0.6991 - val_loss: 0.6386 - val_acc: 0.9442 - val_mDice: 0.5669

Epoch 00042: val_mDice did not improve from 0.58778
Epoch 43/300
 - 8s - loss: 0.3371 - acc: 0.9376 - mDice: 0.6993 - val_loss: 0.6305 - val_acc: 0.9445 - val_mDice: 0.5716

Epoch 00043: val_mDice did not improve from 0.58778
Epoch 44/300
 - 8s - loss: 0.3366 - acc: 0.9376 - mDice: 0.6996 - val_loss: 0.6942 - val_acc: 0.9425 - val_mDice: 0.5680

Epoch 00044: val_mDice did not improve from 0.58778
Epoch 45/300
 - 8s - loss: 0.3330 - acc: 0.9380 - mDice: 0.7022 - val_loss: 0.6342 - val_acc: 0.9441 - val_mDice: 0.5714

Epoch 00045: val_mDice did not improve from 0.58778
Epoch 46/300
 - 9s - loss: 0.3310 - acc: 0.9382 - mDice: 0.7037 - val_loss: 0.6945 - val_acc: 0.9417 - val_mDice: 0.5715

Epoch 00046: val_mDice did not improve from 0.58778
Epoch 47/300
 - 8s - loss: 0.3318 - acc: 0.9380 - mDice: 0.7031 - val_loss: 0.6011 - val_acc: 0.9450 - val_mDice: 0.5742

Epoch 00047: val_mDice did not improve from 0.58778
Epoch 48/300
 - 9s - loss: 0.3326 - acc: 0.9379 - mDice: 0.7025 - val_loss: 0.6518 - val_acc: 0.9443 - val_mDice: 0.5748

Epoch 00048: val_mDice did not improve from 0.58778
Epoch 49/300
 - 8s - loss: 0.3280 - acc: 0.9383 - mDice: 0.7060 - val_loss: 0.6787 - val_acc: 0.9389 - val_mDice: 0.5754

Epoch 00049: val_mDice did not improve from 0.58778
Epoch 50/300
 - 9s - loss: 0.3298 - acc: 0.9384 - mDice: 0.7047 - val_loss: 0.6379 - val_acc: 0.9323 - val_mDice: 0.5662

Epoch 00050: val_mDice did not improve from 0.58778
Epoch 51/300
 - 8s - loss: 0.3276 - acc: 0.9385 - mDice: 0.7062 - val_loss: 0.6855 - val_acc: 0.9446 - val_mDice: 0.5622

Epoch 00051: val_mDice did not improve from 0.58778
Epoch 52/300
 - 8s - loss: 0.3261 - acc: 0.9387 - mDice: 0.7073 - val_loss: 0.7075 - val_acc: 0.9419 - val_mDice: 0.5504

Epoch 00052: val_mDice did not improve from 0.58778
Epoch 53/300
 - 8s - loss: 0.3245 - acc: 0.9388 - mDice: 0.7085 - val_loss: 0.5731 - val_acc: 0.9451 - val_mDice: 0.5568

Epoch 00053: val_mDice did not improve from 0.58778
Epoch 54/300
 - 9s - loss: 0.3244 - acc: 0.9389 - mDice: 0.7086 - val_loss: 0.5995 - val_acc: 0.9403 - val_mDice: 0.5747

Epoch 00054: val_mDice did not improve from 0.58778
Epoch 55/300
 - 8s - loss: 0.3256 - acc: 0.9387 - mDice: 0.7077 - val_loss: 0.5832 - val_acc: 0.9426 - val_mDice: 0.5782

Epoch 00055: val_mDice did not improve from 0.58778
Epoch 56/300
 - 9s - loss: 0.3241 - acc: 0.9388 - mDice: 0.7088 - val_loss: 0.6044 - val_acc: 0.9441 - val_mDice: 0.5585

Epoch 00056: val_mDice did not improve from 0.58778
Epoch 57/300
 - 8s - loss: 0.3249 - acc: 0.9389 - mDice: 0.7082 - val_loss: 0.6427 - val_acc: 0.9410 - val_mDice: 0.5592

Epoch 00057: val_mDice did not improve from 0.58778
Epoch 58/300
 - 9s - loss: 0.3241 - acc: 0.9390 - mDice: 0.7088 - val_loss: 0.5916 - val_acc: 0.9399 - val_mDice: 0.5753

Epoch 00058: val_mDice did not improve from 0.58778
Epoch 59/300
 - 8s - loss: 0.3209 - acc: 0.9392 - mDice: 0.7112 - val_loss: 0.5398 - val_acc: 0.9447 - val_mDice: 0.5656

Epoch 00059: val_mDice did not improve from 0.58778
Epoch 60/300
 - 8s - loss: 0.3212 - acc: 0.9394 - mDice: 0.7110 - val_loss: 0.5990 - val_acc: 0.9448 - val_mDice: 0.5789

Epoch 00060: val_mDice did not improve from 0.58778
Epoch 61/300
 - 9s - loss: 0.3188 - acc: 0.9396 - mDice: 0.7127 - val_loss: 0.5769 - val_acc: 0.9431 - val_mDice: 0.5757

Epoch 00061: val_mDice did not improve from 0.58778
Epoch 62/300
 - 8s - loss: 0.3173 - acc: 0.9396 - mDice: 0.7138 - val_loss: 0.5918 - val_acc: 0.9379 - val_mDice: 0.5691

Epoch 00062: val_mDice did not improve from 0.58778
Epoch 63/300
 - 9s - loss: 0.3171 - acc: 0.9395 - mDice: 0.7140 - val_loss: 0.5731 - val_acc: 0.9426 - val_mDice: 0.5746

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.24s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:34,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:50,  1.66s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:44,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:18,  1.56s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:18,  1.57s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:35,  1.64s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:49,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:06,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:40,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<08:03,  1.77s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:47,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<08:03,  1.78s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:19,  1.85s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:21,  1.86s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:57,  1.78s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:57,  1.79s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:35,  1.71s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:42,  1.74s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:56,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:34,  1.73s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:37,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:21,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:35,  1.75s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:46,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:23,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:34,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:38,  1.79s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:40,  1.81s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:47,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:22,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:28,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:24,  1.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:33,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:18,  1.76s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:26,  1.80s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:33,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:11,  1.76s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:13,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:56,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:44,  1.67s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:47,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:04,  1.76s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:52,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:11,  1.81s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:52,  1.73s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<07:00,  1.77s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:14,  1.84s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:15,  1.85s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:26,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:00,  1.80s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:57,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:04,  1.84s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:50,  1.78s/it]predicting train subjects:  20%|█▉        | 56/285 [01:38<06:51,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:39,  1.75s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:43,  1.78s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:55,  1.84s/it]predicting train subjects:  21%|██        | 60/285 [01:45<07:02,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:47<06:43,  1.80s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:33,  1.77s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:23,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:22,  1.75s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:23,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:09,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:13,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:17,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:06,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:06,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:09<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:11<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<06:12,  1.78s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:02,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:55,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:58,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<06:00,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:52,  1.73s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:50,  1.73s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:38,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:31,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:30<05:38,  1.70s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:40,  1.72s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:33,  1.69s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:29,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:31,  1.70s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:26,  1.68s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:36,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:30,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:31,  1.74s/it]predicting train subjects:  33%|███▎      | 95/285 [02:45<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:31,  1.75s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:33,  1.77s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:28,  1.76s/it]predicting train subjects:  35%|███▍      | 99/285 [02:52<05:28,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [02:54<05:30,  1.79s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:17,  1.73s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:24,  1.77s/it]predicting train subjects:  36%|███▌      | 103/285 [02:59<05:16,  1.74s/it]predicting train subjects:  36%|███▋      | 104/285 [03:01<05:20,  1.77s/it]predicting train subjects:  37%|███▋      | 105/285 [03:03<05:21,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:12,  1.75s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:12,  1.75s/it]predicting train subjects:  38%|███▊      | 108/285 [03:08<05:03,  1.71s/it]predicting train subjects:  38%|███▊      | 109/285 [03:10<05:02,  1.72s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:01,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:13<04:54,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:15<04:53,  1.70s/it]predicting train subjects:  40%|███▉      | 113/285 [03:17<04:59,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:19<04:59,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:20<04:59,  1.76s/it]predicting train subjects:  41%|████      | 116/285 [03:22<05:04,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:24<04:57,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [03:26<04:51,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:27<04:50,  1.75s/it]predicting train subjects:  42%|████▏     | 120/285 [03:29<04:36,  1.68s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:32,  1.66s/it]predicting train subjects:  43%|████▎     | 122/285 [03:32<04:20,  1.60s/it]predicting train subjects:  43%|████▎     | 123/285 [03:33<04:08,  1.53s/it]predicting train subjects:  44%|████▎     | 124/285 [03:35<04:09,  1.55s/it]predicting train subjects:  44%|████▍     | 125/285 [03:36<04:04,  1.53s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<03:58,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:39<03:52,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:57,  1.51s/it]predicting train subjects:  45%|████▌     | 129/285 [03:42<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 131/285 [03:45<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:48,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:48<03:46,  1.49s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:41,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [03:51<03:35,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:52<03:29,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:54<03:33,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [03:55<03:31,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [03:57<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:58<03:37,  1.50s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [04:01<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:23,  1.43s/it]predicting train subjects:  51%|█████     | 144/285 [04:04<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:25,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [04:07<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:10<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:19,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:13<03:14,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:16<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:17<03:13,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:19<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:20<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:22<03:18,  1.54s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:10,  1.50s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:26<03:03,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<03:05,  1.48s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:10,  1.53s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<03:03,  1.49s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:04,  1.52s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<03:01,  1.50s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:59,  1.50s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<03:03,  1.54s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:58,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:55,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:49,  1.48s/it]predicting train subjects:  60%|██████    | 171/285 [04:45<02:48,  1.48s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:43,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:48<02:51,  1.53s/it]predicting train subjects:  61%|██████    | 174/285 [04:49<02:56,  1.59s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:51<02:59,  1.63s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:53<03:05,  1.70s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<03:02,  1.69s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:57,  1.66s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:57,  1.68s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<03:17,  1.88s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:02<03:17,  1.90s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:04<03:19,  1.94s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:06<03:16,  1.93s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:08<03:07,  1.85s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:10<03:00,  1.80s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:12<03:05,  1.88s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:14<03:17,  2.01s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:16<03:20,  2.07s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:18<03:05,  1.93s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:19<02:57,  1.87s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:22<03:04,  1.96s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:24<03:06,  2.01s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:26<03:02,  1.98s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:27<02:53,  1.90s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:29<02:42,  1.81s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:31<02:50,  1.92s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:33<02:57,  2.02s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:36<03:01,  2.08s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:38<02:54,  2.02s/it]predicting train subjects:  70%|███████   | 200/285 [05:40<02:50,  2.00s/it]predicting train subjects:  71%|███████   | 201/285 [05:42<02:51,  2.04s/it]predicting train subjects:  71%|███████   | 202/285 [05:44<03:01,  2.19s/it]predicting train subjects:  71%|███████   | 203/285 [05:46<02:56,  2.15s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:48<02:40,  1.98s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:50<02:43,  2.04s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:52<02:32,  1.93s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:54<02:37,  2.02s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:37,  2.05s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:39,  2.10s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:00<02:24,  1.92s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:02<02:19,  1.88s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:04<02:22,  1.95s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:05<02:17,  1.91s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<02:09,  1.82s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<02:14,  1.91s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:11<02:04,  1.81s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:13<02:13,  1.96s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:15<02:14,  2.01s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<02:26,  2.22s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:20<02:12,  2.04s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:21<02:03,  1.92s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:23<02:06,  2.01s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:25<01:56,  1.88s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:27<01:49,  1.79s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:28<01:44,  1.74s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:30<01:50,  1.87s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:54,  1.97s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:57,  2.06s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:56,  2.08s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:52,  2.04s/it]predicting train subjects:  81%|████████  | 231/285 [06:41<01:43,  1.91s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:41,  1.91s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:44<01:38,  1.89s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:41,  2.00s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:48<01:35,  1.90s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:50<01:38,  2.01s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:53<01:39,  2.08s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:55<01:41,  2.16s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:57<01:37,  2.13s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:59<01:28,  1.97s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:00<01:24,  1.91s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:02<01:17,  1.81s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:04<01:16,  1.83s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:06<01:18,  1.91s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:08<01:12,  1.82s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:10<01:16,  1.97s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:12<01:17,  2.05s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:14<01:15,  2.05s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:16<01:13,  2.04s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:18<01:08,  1.94s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:20<01:02,  1.85s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:21<00:58,  1.78s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:24<01:01,  1.94s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:26<01:02,  2.02s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:28<00:58,  1.97s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:29<00:54,  1.89s/it]predicting train subjects:  90%|█████████ | 257/285 [07:31<00:52,  1.86s/it]predicting train subjects:  91%|█████████ | 258/285 [07:33<00:51,  1.91s/it]predicting train subjects:  91%|█████████ | 259/285 [07:35<00:50,  1.96s/it]predicting train subjects:  91%|█████████ | 260/285 [07:37<00:47,  1.90s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:39<00:45,  1.91s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:41<00:42,  1.86s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:42<00:38,  1.76s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:45<00:41,  1.98s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:47<00:41,  2.07s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:49<00:37,  1.95s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:50<00:33,  1.87s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:52<00:33,  1.97s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:55<00:31,  1.99s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:56<00:28,  1.89s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:58<00:25,  1.83s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:00<00:24,  1.87s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:02<00:22,  1.84s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:03<00:19,  1.76s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:06<00:19,  1.93s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:08<00:18,  2.01s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:09<00:14,  1.87s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:11<00:13,  1.89s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:13<00:11,  1.91s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:15<00:09,  1.89s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:17<00:07,  1.86s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:18<00:05,  1.81s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:21<00:03,  2.00s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:23<00:02,  2.14s/it]predicting train subjects: 100%|██████████| 285/285 [08:26<00:00,  2.19s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:45,  2.06s/it]Loading train:   1%|          | 2/285 [00:04<09:47,  2.07s/it]Loading train:   1%|          | 3/285 [00:06<10:15,  2.18s/it]
Epoch 00063: val_mDice did not improve from 0.58778
Restoring model weights from the end of the best epoch
Epoch 00063: early stopping
{'val_loss': [2.6280680838085355, 1.6250967865898496, 1.3396203744979132, 1.1545270738147555, 1.1151269504002161, 1.088448206583659, 1.0159077644348145, 0.9273507651828584, 0.9185715743473598, 0.8837069159462339, 0.9248152119772775, 0.8715730167570568, 0.8440283991041637, 0.8557656833103725, 0.8731936046055385, 0.844384715670631, 0.8145997864859444, 0.8130303450993129, 0.7929612681979225, 0.8123457147961571, 0.7871289480300176, 0.7226452316556659, 0.7029391811007545, 0.7368186031069074, 0.7442752349944342, 0.7610009511311849, 0.7354092768260411, 0.6897848390397572, 0.7507637852714175, 0.6920940138044811, 0.7442495766140166, 0.681487900870187, 0.7352731171108428, 0.6700323763347807, 0.7039822169712612, 0.6798730577741351, 0.7138497488839286, 0.6469059728440785, 0.645781954129537, 0.7084804886863345, 0.7080790372121901, 0.6385751451764788, 0.6305433398201352, 0.694218879654294, 0.6341509591965449, 0.6945250999359858, 0.6011159760611398, 0.6518378541583106, 0.6786949293954032, 0.6379304499853224, 0.6855129741487049, 0.7074948492504302, 0.5731218315306164, 0.5995232093901861, 0.5832377388363793, 0.6044498965853736, 0.6426876726604643, 0.5915586721329462, 0.5397543793632871, 0.599026498340425, 0.5768633115859259, 0.591808211235773, 0.573110682623727], 'val_acc': [0.8814377245448884, 0.9065796874818348, 0.9199724992116293, 0.9249450280552819, 0.925773819287618, 0.9322802083832877, 0.9366849944705055, 0.9405861071177891, 0.9375732739766439, 0.9430540033749172, 0.9419138914062863, 0.9421886262439546, 0.9411264005161467, 0.9443154618853614, 0.9446932219323658, 0.9440293312072754, 0.9442261939957028, 0.944290300210317, 0.9454578643753415, 0.9415842635290963, 0.9447687779154096, 0.94219780535925, 0.9439033638863337, 0.9446222668602353, 0.9394665871347699, 0.9444551467895508, 0.9448282747041612, 0.9443658192952474, 0.9399725141979399, 0.9419001567931402, 0.9399427544502985, 0.9429624790237063, 0.9442467944962638, 0.9423672301428658, 0.9448534704390026, 0.9449313084284464, 0.9433768192927042, 0.9447756523177737, 0.9454967918850127, 0.9436103332610357, 0.9447825068519229, 0.9442147357123238, 0.9444665568215507, 0.9425457914670309, 0.9440613587697347, 0.9417010205132621, 0.9450343307994661, 0.9442696713265919, 0.9389217297236124, 0.9323031192734128, 0.9446107972235906, 0.9418841600418091, 0.9450801014900208, 0.940325106893267, 0.942589282989502, 0.94410487867537, 0.9409844165756589, 0.9398740984144665, 0.9447275456928071, 0.9447756523177737, 0.9430998393467495, 0.9378731790043059, 0.9426144673710778], 'val_mDice': [0.1632114246132828, 0.3585986377937453, 0.4663842128855841, 0.5415619489337716, 0.5504582607675166, 0.5517674241037596, 0.5579243493931634, 0.5708122663199902, 0.576993642108781, 0.5691968763158435, 0.5547074672012102, 0.5672701673493499, 0.5866663638679754, 0.5578505556498256, 0.5645026202712741, 0.5823770534424555, 0.5613413018484911, 0.5838631260253134, 0.5648534785778749, 0.5829931210194316, 0.5631883967490423, 0.5868275910615921, 0.5877792239189148, 0.5772478630145391, 0.5781344672044119, 0.5647275268676735, 0.5837541321913401, 0.5868634005032834, 0.5816398305552346, 0.5758673009418306, 0.5756762020644688, 0.5791704317643529, 0.5673678737311136, 0.5794862831632296, 0.5629779737265337, 0.5648297970848424, 0.5842200766007105, 0.581237892842009, 0.5762839320869673, 0.5793693484294982, 0.584746893672716, 0.5668782739057427, 0.5716425162695703, 0.5680202863046101, 0.5714393199554512, 0.5714690284360022, 0.5742353839533669, 0.574831176726591, 0.57540735868471, 0.5661957444889205, 0.5621818626920382, 0.5504252878682954, 0.5568258219531604, 0.5746992315564837, 0.5781895291237604, 0.5584767558390186, 0.5591817189540181, 0.5752726466882796, 0.5655805473881108, 0.5788977419336637, 0.5756741652176494, 0.569090598041103, 0.5746022090315819], 'loss': [3.0659385796615517, 1.2626046147193895, 0.7383632639457846, 0.6056272811988013, 0.5482830150821018, 0.5120736174450597, 0.48697762145043705, 0.47032129002118445, 0.45551808212611034, 0.44522546490010484, 0.43748335580800984, 0.4288596717728019, 0.42020445932812467, 0.41525420004148944, 0.40798956318376883, 0.40505725979023594, 0.3999764466012216, 0.3943648127570004, 0.3878675102440636, 0.3874212670457232, 0.38137410390645937, 0.3773815807164095, 0.3764039543820917, 0.3729519598086905, 0.3703693551825999, 0.36806182407886967, 0.36470303150277755, 0.36159256286811386, 0.3613386966542332, 0.35819160407945927, 0.35465037501545477, 0.3541280974858249, 0.351983661674134, 0.3502541616895145, 0.34956402166261596, 0.34856781851286966, 0.34454334348135657, 0.34283569873424996, 0.34228806062909434, 0.34006508613152153, 0.338163237552641, 0.33730345984541293, 0.33707741551002096, 0.3365804873233083, 0.33304581061617494, 0.33095452069937437, 0.33178278247078696, 0.332572771740116, 0.32796804153875553, 0.3297778016194365, 0.3275822335087497, 0.3260719874402979, 0.3245195606287123, 0.3243673006555628, 0.325627869491704, 0.3240870469586799, 0.3248796174527134, 0.3240672509656928, 0.32090098290331265, 0.32120972625295025, 0.31882724330240025, 0.3173110038185708, 0.31706296320891875], 'acc': [0.6592415069164006, 0.8768410228202861, 0.8892463905654571, 0.9002388799629484, 0.9069175600017314, 0.9115491693870672, 0.9155232778789681, 0.9192539849606741, 0.9228972031106282, 0.925209102061573, 0.9266380848097668, 0.9277916741504453, 0.9286898144389568, 0.9292231354268502, 0.9299545309459495, 0.9302748585795309, 0.9309897573324718, 0.9312284281999821, 0.9320729723642253, 0.9322481490477721, 0.9329202735449322, 0.9332535485093342, 0.9333799081154819, 0.9339213421378312, 0.933959530490153, 0.9341888799703211, 0.9345255463321429, 0.9347459585974159, 0.9350565994707449, 0.9352530051293528, 0.9356965093408588, 0.9357657296270999, 0.93603250312511, 0.9361349227388447, 0.9361885418109589, 0.936326627088278, 0.9367475412313433, 0.9367591051184788, 0.9369636634560433, 0.9372013864637639, 0.9374048071650382, 0.9375092008680606, 0.9376003821047373, 0.9376135160864629, 0.937965662419187, 0.9381749485300666, 0.9380162897564116, 0.9379448274644969, 0.938342899181766, 0.938368133331554, 0.9384554919535562, 0.9386572012074862, 0.9388074263203505, 0.9388748313825852, 0.9387054448530396, 0.938804712671523, 0.9388613240875581, 0.9389807749902304, 0.9391531721806052, 0.9394197163495435, 0.9395570799935317, 0.9395987675418416, 0.939546373105587], 'mDice': [0.07760237590094707, 0.29848877683709946, 0.4613017241389898, 0.5283196342917612, 0.5609508030143849, 0.58266515573923, 0.5982055176147864, 0.6088701450390371, 0.6183564546298079, 0.6250606036861899, 0.6300853497379428, 0.6357515556908353, 0.6414555198589639, 0.6448501729887071, 0.6496139042911121, 0.6517576305122074, 0.6552894507641275, 0.6588962022017624, 0.6633197504453215, 0.6637191980450926, 0.6678246155119779, 0.6705281980147545, 0.6712719582743744, 0.6736802395446834, 0.6755352556096443, 0.6771201640855882, 0.6793744116935377, 0.6816997550713756, 0.6819153384066556, 0.6840717703339588, 0.6865763825351663, 0.6869643222557136, 0.6886206931959394, 0.6897460271886072, 0.6902657211320994, 0.6910435839358474, 0.6938459405739091, 0.6951254954543995, 0.6955771417729951, 0.6971890248152846, 0.6984424084304315, 0.699089367563885, 0.6993167006902803, 0.6996233282186678, 0.7021589066703264, 0.7037073535819905, 0.7030905390121308, 0.7025273291389447, 0.7059537650349744, 0.7046880204598982, 0.7062266159774666, 0.7073409919773702, 0.7084806149052314, 0.7085776339842217, 0.7077232212121256, 0.7088212246308327, 0.7082181646112811, 0.7087692491162919, 0.7112019444582939, 0.7110097669603647, 0.7127115770941734, 0.7137623699340652, 0.7139705948708305]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0Loading train:   1%|▏         | 4/285 [00:08<10:12,  2.18s/it]Loading train:   2%|▏         | 5/285 [00:10<10:14,  2.19s/it]Loading train:   2%|▏         | 6/285 [00:13<10:31,  2.26s/it]Loading train:   2%|▏         | 7/285 [00:15<10:15,  2.21s/it]Loading train:   3%|▎         | 8/285 [00:17<09:41,  2.10s/it]Loading train:   3%|▎         | 9/285 [00:19<10:20,  2.25s/it]Loading train:   4%|▎         | 10/285 [00:22<10:17,  2.25s/it]Loading train:   4%|▍         | 11/285 [00:23<09:33,  2.09s/it]Loading train:   4%|▍         | 12/285 [00:26<09:36,  2.11s/it]Loading train:   5%|▍         | 13/285 [00:27<09:09,  2.02s/it]Loading train:   5%|▍         | 14/285 [00:29<08:34,  1.90s/it]Loading train:   5%|▌         | 15/285 [00:31<08:19,  1.85s/it]Loading train:   6%|▌         | 16/285 [00:33<08:43,  1.95s/it]Loading train:   6%|▌         | 17/285 [00:35<09:11,  2.06s/it]Loading train:   6%|▋         | 18/285 [00:37<09:08,  2.05s/it]Loading train:   7%|▋         | 19/285 [00:39<09:00,  2.03s/it]Loading train:   7%|▋         | 20/285 [00:41<08:40,  1.96s/it]Loading train:   7%|▋         | 21/285 [00:43<08:34,  1.95s/it]Loading train:   8%|▊         | 22/285 [00:45<08:39,  1.98s/it]Loading train:   8%|▊         | 23/285 [00:47<08:02,  1.84s/it]Loading train:   8%|▊         | 24/285 [00:48<07:20,  1.69s/it]Loading train:   9%|▉         | 25/285 [00:50<07:43,  1.78s/it]Loading train:   9%|▉         | 26/285 [00:52<07:58,  1.85s/it]Loading train:   9%|▉         | 27/285 [00:53<07:24,  1.72s/it]Loading train:  10%|▉         | 28/285 [00:55<07:51,  1.83s/it]Loading train:  10%|█         | 29/285 [00:57<07:48,  1.83s/it]Loading train:  11%|█         | 30/285 [01:00<08:37,  2.03s/it]Loading train:  11%|█         | 31/285 [01:02<08:39,  2.05s/it]Loading train:  11%|█         | 32/285 [01:04<08:40,  2.06s/it]Loading train:  12%|█▏        | 33/285 [01:06<08:51,  2.11s/it]Loading train:  12%|█▏        | 34/285 [01:08<08:03,  1.93s/it]Loading train:  12%|█▏        | 35/285 [01:10<08:10,  1.96s/it]Loading train:  13%|█▎        | 36/285 [01:12<08:02,  1.94s/it]Loading train:  13%|█▎        | 37/285 [01:13<07:19,  1.77s/it]Loading train:  13%|█▎        | 38/285 [01:14<06:58,  1.69s/it]Loading train:  14%|█▎        | 39/285 [01:16<06:36,  1.61s/it]Loading train:  14%|█▍        | 40/285 [01:17<06:22,  1.56s/it]Loading train:  14%|█▍        | 41/285 [01:18<05:52,  1.44s/it]Loading train:  15%|█▍        | 42/285 [01:20<06:07,  1.51s/it]Loading train:  15%|█▌        | 43/285 [01:22<06:41,  1.66s/it]Loading train:  15%|█▌        | 44/285 [01:24<06:38,  1.65s/it]Loading train:  16%|█▌        | 45/285 [01:26<07:20,  1.84s/it]Loading train:  16%|█▌        | 46/285 [01:28<07:51,  1.97s/it]Loading train:  16%|█▋        | 47/285 [01:30<07:14,  1.82s/it]Loading train:  17%|█▋        | 48/285 [01:31<06:48,  1.72s/it]Loading train:  17%|█▋        | 49/285 [01:33<06:57,  1.77s/it]Loading train:  18%|█▊        | 50/285 [01:35<06:26,  1.64s/it]Loading train:  18%|█▊        | 51/285 [01:37<06:48,  1.75s/it]Loading train:  18%|█▊        | 52/285 [01:38<06:39,  1.71s/it]Loading train:  19%|█▊        | 53/285 [01:40<06:40,  1.73s/it]Loading train:  19%|█▉        | 54/285 [01:42<06:56,  1.80s/it]Loading train:  19%|█▉        | 55/285 [01:43<06:33,  1.71s/it]Loading train:  20%|█▉        | 56/285 [01:45<05:57,  1.56s/it]Loading train:  20%|██        | 57/285 [01:46<05:51,  1.54s/it]Loading train:  20%|██        | 58/285 [01:48<06:05,  1.61s/it]Loading train:  21%|██        | 59/285 [01:50<06:12,  1.65s/it]Loading train:  21%|██        | 60/285 [01:51<06:13,  1.66s/it]Loading train:  21%|██▏       | 61/285 [01:52<05:34,  1.50s/it]Loading train:  22%|██▏       | 62/285 [01:54<05:29,  1.48s/it]Loading train:  22%|██▏       | 63/285 [01:55<05:26,  1.47s/it]Loading train:  22%|██▏       | 64/285 [01:57<06:10,  1.68s/it]Loading train:  23%|██▎       | 65/285 [02:00<06:35,  1.80s/it]Loading train:  23%|██▎       | 66/285 [02:02<07:34,  2.07s/it]Loading train:  24%|██▎       | 67/285 [02:04<06:57,  1.92s/it]Loading train:  24%|██▍       | 68/285 [02:05<06:20,  1.75s/it]Loading train:  24%|██▍       | 69/285 [02:06<05:48,  1.62s/it]Loading train:  25%|██▍       | 70/285 [02:08<05:40,  1.58s/it]Loading train:  25%|██▍       | 71/285 [02:09<05:29,  1.54s/it]Loading train:  25%|██▌       | 72/285 [02:11<05:38,  1.59s/it]Loading train:  26%|██▌       | 73/285 [02:12<05:23,  1.53s/it]Loading train:  26%|██▌       | 74/285 [02:14<05:29,  1.56s/it]Loading train:  26%|██▋       | 75/285 [02:16<05:17,  1.51s/it]Loading train:  27%|██▋       | 76/285 [02:17<05:23,  1.55s/it]Loading train:  27%|██▋       | 77/285 [02:19<05:52,  1.70s/it]Loading train:  27%|██▋       | 78/285 [02:21<05:35,  1.62s/it]Loading train:  28%|██▊       | 79/285 [02:22<05:40,  1.65s/it]Loading train:  28%|██▊       | 80/285 [02:24<05:15,  1.54s/it]Loading train:  28%|██▊       | 81/285 [02:25<04:48,  1.41s/it]Loading train:  29%|██▉       | 82/285 [02:26<04:35,  1.36s/it]Loading train:  29%|██▉       | 83/285 [02:27<04:16,  1.27s/it]Loading train:  29%|██▉       | 84/285 [02:29<04:27,  1.33s/it]Loading train:  30%|██▉       | 85/285 [02:30<04:51,  1.46s/it]Loading train:  30%|███       | 86/285 [02:32<04:47,  1.44s/it]Loading train:  31%|███       | 87/285 [02:33<04:34,  1.39s/it]Loading train:  31%|███       | 88/285 [02:34<04:33,  1.39s/it]Loading train:  31%|███       | 89/285 [02:35<04:12,  1.29s/it]Loading train:  32%|███▏      | 90/285 [02:37<04:12,  1.30s/it]Loading train:  32%|███▏      | 91/285 [02:38<04:02,  1.25s/it]Loading train:  32%|███▏      | 92/285 [02:39<04:06,  1.28s/it]Loading train:  33%|███▎      | 93/285 [02:40<03:51,  1.20s/it]Loading train:  33%|███▎      | 94/285 [02:42<04:02,  1.27s/it]Loading train:  33%|███▎      | 95/285 [02:43<04:20,  1.37s/it]Loading train:  34%|███▎      | 96/285 [02:45<04:20,  1.38s/it]Loading train:  34%|███▍      | 97/285 [02:47<04:55,  1.57s/it]Loading train:  34%|███▍      | 98/285 [02:48<04:44,  1.52s/it]Loading train:  35%|███▍      | 99/285 [02:50<05:03,  1.63s/it]Loading train:  35%|███▌      | 100/285 [02:52<05:05,  1.65s/it]Loading train:  35%|███▌      | 101/285 [02:53<04:56,  1.61s/it]Loading train:  36%|███▌      | 102/285 [02:55<05:24,  1.78s/it]Loading train:  36%|███▌      | 103/285 [02:57<05:37,  1.85s/it]Loading train:  36%|███▋      | 104/285 [02:59<05:47,  1.92s/it]Loading train:  37%|███▋      | 105/285 [03:01<05:02,  1.68s/it]Loading train:  37%|███▋      | 106/285 [03:02<04:24,  1.48s/it]Loading train:  38%|███▊      | 107/285 [03:03<04:24,  1.49s/it]Loading train:  38%|███▊      | 108/285 [03:05<04:27,  1.51s/it]Loading train:  38%|███▊      | 109/285 [03:06<04:27,  1.52s/it]Loading train:  39%|███▊      | 110/285 [03:07<04:00,  1.38s/it]Loading train:  39%|███▉      | 111/285 [03:08<03:34,  1.23s/it]Loading train:  39%|███▉      | 112/285 [03:09<03:19,  1.15s/it]Loading train:  40%|███▉      | 113/285 [03:10<03:10,  1.11s/it]Loading train:  40%|████      | 114/285 [03:11<02:57,  1.04s/it]Loading train:  40%|████      | 115/285 [03:12<02:53,  1.02s/it]Loading train:  41%|████      | 116/285 [03:13<02:52,  1.02s/it]Loading train:  41%|████      | 117/285 [03:14<02:50,  1.01s/it]Loading train:  41%|████▏     | 118/285 [03:15<02:47,  1.00s/it]Loading train:  42%|████▏     | 119/285 [03:16<02:53,  1.05s/it]Loading train:  42%|████▏     | 120/285 [03:17<02:56,  1.07s/it]Loading train:  42%|████▏     | 121/285 [03:19<03:13,  1.18s/it]Loading train:  43%|████▎     | 122/285 [03:20<03:12,  1.18s/it]Loading train:  43%|████▎     | 123/285 [03:21<03:13,  1.19s/it]Loading train:  44%|████▎     | 124/285 [03:22<02:56,  1.10s/it]Loading train:  44%|████▍     | 125/285 [03:23<02:49,  1.06s/it]Loading train:  44%|████▍     | 126/285 [03:24<02:40,  1.01s/it]Loading train:  45%|████▍     | 127/285 [03:25<02:35,  1.02it/s]Loading train:  45%|████▍     | 128/285 [03:26<02:30,  1.04it/s]Loading train:  45%|████▌     | 129/285 [03:26<02:24,  1.08it/s]Loading train:  46%|████▌     | 130/285 [03:27<02:24,  1.07it/s]Loading train:  46%|████▌     | 131/285 [03:28<02:20,  1.09it/s]Loading train:  46%|████▋     | 132/285 [03:29<02:16,  1.12it/s]Loading train:  47%|████▋     | 133/285 [03:30<02:10,  1.16it/s]Loading train:  47%|████▋     | 134/285 [03:31<02:06,  1.19it/s]Loading train:  47%|████▋     | 135/285 [03:31<02:02,  1.23it/s]Loading train:  48%|████▊     | 136/285 [03:32<01:55,  1.29it/s]Loading train:  48%|████▊     | 137/285 [03:33<01:53,  1.30it/s]Loading train:  48%|████▊     | 138/285 [03:34<01:55,  1.27it/s]Loading train:  49%|████▉     | 139/285 [03:35<01:59,  1.22it/s]Loading train:  49%|████▉     | 140/285 [03:36<02:00,  1.20it/s]Loading train:  49%|████▉     | 141/285 [03:36<02:01,  1.18it/s]Loading train:  50%|████▉     | 142/285 [03:37<02:03,  1.16it/s]Loading train:  50%|█████     | 143/285 [03:38<02:00,  1.18it/s]Loading train:  51%|█████     | 144/285 [03:39<02:01,  1.16it/s]Loading train:  51%|█████     | 145/285 [03:40<02:00,  1.16it/s]Loading train:  51%|█████     | 146/285 [03:41<01:57,  1.18it/s]Loading train:  52%|█████▏    | 147/285 [03:42<01:59,  1.16it/s]Loading train:  52%|█████▏    | 148/285 [03:43<02:03,  1.11it/s]Loading train:  52%|█████▏    | 149/285 [03:43<01:57,  1.16it/s]Loading train:  53%|█████▎    | 150/285 [03:44<01:55,  1.17it/s]Loading train:  53%|█████▎    | 151/285 [03:45<01:51,  1.21it/s]Loading train:  53%|█████▎    | 152/285 [03:46<01:45,  1.26it/s]Loading train:  54%|█████▎    | 153/285 [03:46<01:42,  1.29it/s]Loading train:  54%|█████▍    | 154/285 [03:47<01:39,  1.31it/s]Loading train:  54%|█████▍    | 155/285 [03:48<01:38,  1.33it/s]Loading train:  55%|█████▍    | 156/285 [03:49<01:38,  1.30it/s]Loading train:  55%|█████▌    | 157/285 [03:49<01:38,  1.30it/s]Loading train:  55%|█████▌    | 158/285 [03:50<01:42,  1.24it/s]Loading train:  56%|█████▌    | 159/285 [03:51<01:45,  1.20it/s]Loading train:  56%|█████▌    | 160/285 [03:52<01:47,  1.16it/s]Loading train:  56%|█████▋    | 161/285 [03:53<01:49,  1.13it/s]Loading train:  57%|█████▋    | 162/285 [03:54<01:45,  1.16it/s]Loading train:  57%|█████▋    | 163/285 [03:55<01:44,  1.17it/s]Loading train:  58%|█████▊    | 164/285 [03:56<01:40,  1.20it/s]Loading train:  58%|█████▊    | 165/285 [03:56<01:37,  1.24it/s]Loading train:  58%|█████▊    | 166/285 [03:57<01:39,  1.19it/s]Loading train:  59%|█████▊    | 167/285 [03:58<01:41,  1.16it/s]Loading train:  59%|█████▉    | 168/285 [03:59<01:38,  1.19it/s]Loading train:  59%|█████▉    | 169/285 [04:00<01:37,  1.19it/s]Loading train:  60%|█████▉    | 170/285 [04:00<01:34,  1.21it/s]Loading train:  60%|██████    | 171/285 [04:01<01:34,  1.20it/s]Loading train:  60%|██████    | 172/285 [04:02<01:38,  1.15it/s]Loading train:  61%|██████    | 173/285 [04:03<01:36,  1.16it/s]Loading train:  61%|██████    | 174/285 [04:04<01:34,  1.17it/s]Loading train:  61%|██████▏   | 175/285 [04:05<01:34,  1.17it/s]Loading train:  62%|██████▏   | 176/285 [04:06<01:32,  1.17it/s]Loading train:  62%|██████▏   | 177/285 [04:06<01:29,  1.21it/s]Loading train:  62%|██████▏   | 178/285 [04:07<01:27,  1.22it/s]Loading train:  63%|██████▎   | 179/285 [04:08<01:31,  1.16it/s]Loading train:  63%|██████▎   | 180/285 [04:09<01:38,  1.06it/s]Loading train:  64%|██████▎   | 181/285 [04:10<01:42,  1.01it/s]Loading train:  64%|██████▍   | 182/285 [04:11<01:42,  1.00it/s]Loading train:  64%|██████▍   | 183/285 [04:12<01:40,  1.02it/s]Loading train:  65%|██████▍   | 184/285 [04:13<01:37,  1.03it/s]Loading train:  65%|██████▍   | 185/285 [04:14<01:32,  1.08it/s]Loading train:  65%|██████▌   | 186/285 [04:15<01:38,  1.00it/s]Loading train:  66%|██████▌   | 187/285 [04:16<01:40,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [04:18<01:42,  1.05s/it]Loading train:  66%|██████▋   | 189/285 [04:18<01:33,  1.03it/s]Loading train:  67%|██████▋   | 190/285 [04:19<01:30,  1.05it/s]Loading train:  67%|██████▋   | 191/285 [04:20<01:30,  1.04it/s]Loading train:  67%|██████▋   | 192/285 [04:21<01:28,  1.06it/s]Loading train:  68%|██████▊   | 193/285 [04:22<01:25,  1.07it/s]Loading train:  68%|██████▊   | 194/285 [04:23<01:22,  1.10it/s]Loading train:  68%|██████▊   | 195/285 [04:24<01:24,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [04:25<01:24,  1.06it/s]Loading train:  69%|██████▉   | 197/285 [04:26<01:25,  1.03it/s]Loading train:  69%|██████▉   | 198/285 [04:27<01:24,  1.03it/s]Loading train:  70%|██████▉   | 199/285 [04:28<01:21,  1.06it/s]Loading train:  70%|███████   | 200/285 [04:29<01:20,  1.05it/s]Loading train:  71%|███████   | 201/285 [04:30<01:21,  1.03it/s]Loading train:  71%|███████   | 202/285 [04:31<01:19,  1.04it/s]Loading train:  71%|███████   | 203/285 [04:32<01:18,  1.04it/s]Loading train:  72%|███████▏  | 204/285 [04:33<01:18,  1.03it/s]Loading train:  72%|███████▏  | 205/285 [04:34<01:16,  1.05it/s]Loading train:  72%|███████▏  | 206/285 [04:34<01:12,  1.08it/s]Loading train:  73%|███████▎  | 207/285 [04:35<01:14,  1.05it/s]Loading train:  73%|███████▎  | 208/285 [04:36<01:13,  1.05it/s]Loading train:  73%|███████▎  | 209/285 [04:37<01:13,  1.04it/s]Loading train:  74%|███████▎  | 210/285 [04:38<01:09,  1.08it/s]Loading train:  74%|███████▍  | 211/285 [04:39<01:07,  1.09it/s]Loading train:  74%|███████▍  | 212/285 [04:40<01:08,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [04:41<01:05,  1.11it/s]Loading train:  75%|███████▌  | 214/285 [04:42<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [04:43<01:02,  1.12it/s]Loading train:  76%|███████▌  | 216/285 [04:43<00:59,  1.16it/s]Loading train:  76%|███████▌  | 217/285 [04:44<01:00,  1.12it/s]Loading train:  76%|███████▋  | 218/285 [04:45<01:00,  1.10it/s]Loading train:  77%|███████▋  | 219/285 [04:46<01:00,  1.08it/s]Loading train:  77%|███████▋  | 220/285 [04:47<00:57,  1.14it/s]Loading train:  78%|███████▊  | 221/285 [04:48<00:53,  1.19it/s]Loading train:  78%|███████▊  | 222/285 [04:49<00:54,  1.17it/s]Loading train:  78%|███████▊  | 223/285 [04:50<00:52,  1.18it/s]Loading train:  79%|███████▊  | 224/285 [04:50<00:52,  1.17it/s]Loading train:  79%|███████▉  | 225/285 [04:51<00:52,  1.15it/s]Loading train:  79%|███████▉  | 226/285 [04:52<00:54,  1.09it/s]Loading train:  80%|███████▉  | 227/285 [04:53<00:55,  1.04it/s]Loading train:  80%|████████  | 228/285 [04:54<00:54,  1.04it/s]Loading train:  80%|████████  | 229/285 [04:55<00:53,  1.05it/s]Loading train:  81%|████████  | 230/285 [04:56<00:51,  1.07it/s]Loading train:  81%|████████  | 231/285 [04:57<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [04:58<00:47,  1.11it/s]Loading train:  82%|████████▏ | 233/285 [04:59<00:45,  1.15it/s]Loading train:  82%|████████▏ | 234/285 [05:00<00:45,  1.11it/s]Loading train:  82%|████████▏ | 235/285 [05:00<00:42,  1.17it/s]Loading train:  83%|████████▎ | 236/285 [05:01<00:42,  1.14it/s]Loading train:  83%|████████▎ | 237/285 [05:02<00:43,  1.11it/s]Loading train:  84%|████████▎ | 238/285 [05:03<00:43,  1.09it/s]Loading train:  84%|████████▍ | 239/285 [05:04<00:40,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [05:05<00:41,  1.09it/s]Loading train:  85%|████████▍ | 241/285 [05:06<00:39,  1.11it/s]Loading train:  85%|████████▍ | 242/285 [05:07<00:39,  1.10it/s]Loading train:  85%|████████▌ | 243/285 [05:08<00:38,  1.08it/s]Loading train:  86%|████████▌ | 244/285 [05:09<00:40,  1.01it/s]Loading train:  86%|████████▌ | 245/285 [05:10<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [05:11<00:39,  1.01s/it]Loading train:  87%|████████▋ | 247/285 [05:12<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [05:13<00:36,  1.01it/s]Loading train:  87%|████████▋ | 249/285 [05:14<00:34,  1.04it/s]Loading train:  88%|████████▊ | 250/285 [05:15<00:33,  1.06it/s]Loading train:  88%|████████▊ | 251/285 [05:16<00:30,  1.11it/s]Loading train:  88%|████████▊ | 252/285 [05:16<00:28,  1.15it/s]Loading train:  89%|████████▉ | 253/285 [05:17<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [05:18<00:29,  1.07it/s]Loading train:  89%|████████▉ | 255/285 [05:19<00:28,  1.05it/s]Loading train:  90%|████████▉ | 256/285 [05:20<00:26,  1.08it/s]Loading train:  90%|█████████ | 257/285 [05:21<00:25,  1.11it/s]Loading train:  91%|█████████ | 258/285 [05:22<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [05:23<00:24,  1.06it/s]Loading train:  91%|█████████ | 260/285 [05:24<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [05:25<00:21,  1.12it/s]Loading train:  92%|█████████▏| 262/285 [05:26<00:20,  1.13it/s]Loading train:  92%|█████████▏| 263/285 [05:27<00:19,  1.12it/s]Loading train:  93%|█████████▎| 264/285 [05:28<00:20,  1.04it/s]Loading train:  93%|█████████▎| 265/285 [05:29<00:19,  1.02it/s]Loading train:  93%|█████████▎| 266/285 [05:29<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [05:30<00:15,  1.14it/s]Loading train:  94%|█████████▍| 268/285 [05:31<00:14,  1.14it/s]Loading train:  94%|█████████▍| 269/285 [05:32<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [05:33<00:12,  1.20it/s]Loading train:  95%|█████████▌| 271/285 [05:33<00:11,  1.24it/s]Loading train:  95%|█████████▌| 272/285 [05:34<00:10,  1.24it/s]Loading train:  96%|█████████▌| 273/285 [05:35<00:09,  1.26it/s]Loading train:  96%|█████████▌| 274/285 [05:36<00:08,  1.27it/s]Loading train:  96%|█████████▋| 275/285 [05:37<00:08,  1.19it/s]Loading train:  97%|█████████▋| 276/285 [05:38<00:07,  1.15it/s]Loading train:  97%|█████████▋| 277/285 [05:38<00:06,  1.20it/s]Loading train:  98%|█████████▊| 278/285 [05:39<00:05,  1.23it/s]Loading train:  98%|█████████▊| 279/285 [05:40<00:04,  1.24it/s]Loading train:  98%|█████████▊| 280/285 [05:41<00:03,  1.26it/s]Loading train:  99%|█████████▊| 281/285 [05:41<00:03,  1.28it/s]Loading train:  99%|█████████▉| 282/285 [05:42<00:02,  1.30it/s]Loading train:  99%|█████████▉| 283/285 [05:43<00:01,  1.21it/s]Loading train: 100%|█████████▉| 284/285 [05:44<00:00,  1.15it/s]Loading train: 100%|██████████| 285/285 [05:45<00:00,  1.14it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 25/285 [00:00<00:01, 244.91it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:00, 250.62it/s]concatenating: train:  28%|██▊       | 80/285 [00:00<00:00, 258.36it/s]concatenating: train:  37%|███▋      | 106/285 [00:00<00:00, 256.28it/s]concatenating: train:  46%|████▌     | 131/285 [00:00<00:00, 254.16it/s]concatenating: train:  56%|█████▌    | 160/285 [00:00<00:00, 262.30it/s]concatenating: train:  66%|██████▋   | 189/285 [00:00<00:00, 267.60it/s]concatenating: train:  76%|███████▌  | 217/285 [00:00<00:00, 269.74it/s]concatenating: train:  85%|████████▌ | 243/285 [00:00<00:00, 263.91it/s]concatenating: train:  96%|█████████▌| 274/285 [00:01<00:00, 275.17it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 272.24it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 496.29it/s]2019-07-10 20:48:33.317773: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 20:48:33.317859: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 20:48:33.317873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 20:48:33.317881: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 20:48:33.318298: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.33it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.17it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.80it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.48it/s]loading the weights for Res Unet:  23%|██▎       | 10/44 [00:00<00:04,  8.20it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  7.06it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:02,  9.01it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  9.26it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.48it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.28it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.48it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.60it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.39it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.15it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.57it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.72it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.77it/s]      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 226,723
Trainable params: 52,003
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.3284 - acc: 0.6768 - mDice: 0.1637 - val_loss: 1.8299 - val_acc: 0.9120 - val_mDice: 0.2551

Epoch 00001: val_mDice improved from -inf to 0.25507, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.8570 - acc: 0.9018 - mDice: 0.4149 - val_loss: 0.6679 - val_acc: 0.9340 - val_mDice: 0.5064

Epoch 00002: val_mDice improved from 0.25507 to 0.50643, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.6768 - acc: 0.9088 - mDice: 0.4966 - val_loss: 0.6373 - val_acc: 0.9326 - val_mDice: 0.5238

Epoch 00003: val_mDice improved from 0.50643 to 0.52379, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5897 - acc: 0.9150 - mDice: 0.5414 - val_loss: 0.5753 - val_acc: 0.9392 - val_mDice: 0.5512

Epoch 00004: val_mDice improved from 0.52379 to 0.55115, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5366 - acc: 0.9214 - mDice: 0.5712 - val_loss: 0.5605 - val_acc: 0.9445 - val_mDice: 0.5600

Epoch 00005: val_mDice improved from 0.55115 to 0.56001, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.4986 - acc: 0.9275 - mDice: 0.5936 - val_loss: 0.5591 - val_acc: 0.9451 - val_mDice: 0.5617

Epoch 00006: val_mDice improved from 0.56001 to 0.56172, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.4770 - acc: 0.9322 - mDice: 0.6075 - val_loss: 0.5297 - val_acc: 0.9468 - val_mDice: 0.5798

Epoch 00007: val_mDice improved from 0.56172 to 0.57984, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.4484 - acc: 0.9366 - mDice: 0.6246 - val_loss: 0.5123 - val_acc: 0.9462 - val_mDice: 0.5884

Epoch 00008: val_mDice improved from 0.57984 to 0.58844, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4320 - acc: 0.9394 - mDice: 0.6351 - val_loss: 0.5183 - val_acc: 0.9455 - val_mDice: 0.5863

Epoch 00009: val_mDice did not improve from 0.58844
Epoch 10/300
 - 12s - loss: 0.4173 - acc: 0.9409 - mDice: 0.6446 - val_loss: 0.5019 - val_acc: 0.9488 - val_mDice: 0.5946

Epoch 00010: val_mDice improved from 0.58844 to 0.59457, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 12s - loss: 0.4065 - acc: 0.9418 - mDice: 0.6515 - val_loss: 0.5015 - val_acc: 0.9457 - val_mDice: 0.5933

Epoch 00011: val_mDice did not improve from 0.59457
Epoch 12/300
 - 11s - loss: 0.3963 - acc: 0.9424 - mDice: 0.6584 - val_loss: 0.5047 - val_acc: 0.9480 - val_mDice: 0.5914

Epoch 00012: val_mDice did not improve from 0.59457
Epoch 13/300
 - 11s - loss: 0.3864 - acc: 0.9433 - mDice: 0.6651 - val_loss: 0.4799 - val_acc: 0.9496 - val_mDice: 0.6080

Epoch 00013: val_mDice improved from 0.59457 to 0.60799, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 11s - loss: 0.3780 - acc: 0.9439 - mDice: 0.6710 - val_loss: 0.4972 - val_acc: 0.9505 - val_mDice: 0.5967

Epoch 00014: val_mDice did not improve from 0.60799
Epoch 15/300
 - 12s - loss: 0.3730 - acc: 0.9445 - mDice: 0.6745 - val_loss: 0.5051 - val_acc: 0.9501 - val_mDice: 0.5949

Epoch 00015: val_mDice did not improve from 0.60799
Epoch 16/300
 - 12s - loss: 0.3631 - acc: 0.9451 - mDice: 0.6812 - val_loss: 0.4851 - val_acc: 0.9506 - val_mDice: 0.6040

Epoch 00016: val_mDice did not improve from 0.60799
Epoch 17/300
 - 11s - loss: 0.3591 - acc: 0.9454 - mDice: 0.6841 - val_loss: 0.4746 - val_acc: 0.9501 - val_mDice: 0.6109

Epoch 00017: val_mDice improved from 0.60799 to 0.61086, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 11s - loss: 0.3543 - acc: 0.9456 - mDice: 0.6875 - val_loss: 0.4944 - val_acc: 0.9499 - val_mDice: 0.5984

Epoch 00018: val_mDice did not improve from 0.61086
Epoch 19/300
 - 11s - loss: 0.3483 - acc: 0.9460 - mDice: 0.6916 - val_loss: 0.4913 - val_acc: 0.9513 - val_mDice: 0.6022

Epoch 00019: val_mDice did not improve from 0.61086
Epoch 20/300
 - 11s - loss: 0.3445 - acc: 0.9463 - mDice: 0.6946 - val_loss: 0.4798 - val_acc: 0.9510 - val_mDice: 0.6088

Epoch 00020: val_mDice did not improve from 0.61086
Epoch 21/300
 - 12s - loss: 0.3391 - acc: 0.9467 - mDice: 0.6982 - val_loss: 0.5011 - val_acc: 0.9479 - val_mDice: 0.5951

Epoch 00021: val_mDice did not improve from 0.61086
Epoch 22/300
 - 12s - loss: 0.3351 - acc: 0.9469 - mDice: 0.7012 - val_loss: 0.4781 - val_acc: 0.9489 - val_mDice: 0.6111

Epoch 00022: val_mDice improved from 0.61086 to 0.61108, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 11s - loss: 0.3313 - acc: 0.9472 - mDice: 0.7039 - val_loss: 0.4836 - val_acc: 0.9513 - val_mDice: 0.6085

Epoch 00023: val_mDice did not improve from 0.61108
Epoch 24/300
 - 11s - loss: 0.3292 - acc: 0.9472 - mDice: 0.7054 - val_loss: 0.4817 - val_acc: 0.9522 - val_mDice: 0.6073

Epoch 00024: val_mDice did not improve from 0.61108
Epoch 25/300
 - 11s - loss: 0.3267 - acc: 0.9475 - mDice: 0.7073 - val_loss: 0.5037 - val_acc: 0.9479 - val_mDice: 0.5945

Epoch 00025: val_mDice did not improve from 0.61108
Epoch 26/300
 - 12s - loss: 0.3219 - acc: 0.9479 - mDice: 0.7108 - val_loss: 0.4826 - val_acc: 0.9505 - val_mDice: 0.6101

Epoch 00026: val_mDice did not improve from 0.61108
Epoch 27/300
 - 12s - loss: 0.3177 - acc: 0.9481 - mDice: 0.7139 - val_loss: 0.4943 - val_acc: 0.9510 - val_mDice: 0.6051

Epoch 00027: val_mDice did not improve from 0.61108
Epoch 28/300
 - 12s - loss: 0.3168 - acc: 0.9482 - mDice: 0.7146 - val_loss: 0.5024 - val_acc: 0.9493 - val_mDice: 0.5981

Epoch 00028: val_mDice did not improve from 0.61108
Epoch 29/300
 - 11s - loss: 0.3138 - acc: 0.9482 - mDice: 0.7168 - val_loss: 0.4877 - val_acc: 0.9524 - val_mDice: 0.6084

Epoch 00029: val_mDice did not improve from 0.61108
Epoch 30/300
 - 11s - loss: 0.3104 - acc: 0.9485 - mDice: 0.7193 - val_loss: 0.5136 - val_acc: 0.9473 - val_mDice: 0.5884

Epoch 00030: val_mDice did not improve from 0.61108
Epoch 31/300
 - 11s - loss: 0.3088 - acc: 0.9486 - mDice: 0.7204 - val_loss: 0.4971 - val_acc: 0.9493 - val_mDice: 0.6030

Epoch 00031: val_mDice did not improve from 0.61108
Epoch 32/300
 - 11s - loss: 0.3069 - acc: 0.9487 - mDice: 0.7219 - val_loss: 0.4674 - val_acc: 0.9497 - val_mDice: 0.6166

Epoch 00032: val_mDice improved from 0.61108 to 0.61661, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 12s - loss: 0.3039 - acc: 0.9489 - mDice: 0.7241 - val_loss: 0.4935 - val_acc: 0.9486 - val_mDice: 0.6014

Epoch 00033: val_mDice did not improve from 0.61661
Epoch 34/300
 - 12s - loss: 0.3019 - acc: 0.9491 - mDice: 0.7258 - val_loss: 0.4724 - val_acc: 0.9509 - val_mDice: 0.6166

Epoch 00034: val_mDice improved from 0.61661 to 0.61662, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 35/300
 - 11s - loss: 0.3000 - acc: 0.9492 - mDice: 0.7271 - val_loss: 0.4849 - val_acc: 0.9517 - val_mDice: 0.6074

Epoch 00035: val_mDice did not improve from 0.61662
Epoch 36/300
 - 11s - loss: 0.2989 - acc: 0.9492 - mDice: 0.7280 - val_loss: 0.4690 - val_acc: 0.9503 - val_mDice: 0.6163

Epoch 00036: val_mDice did not improve from 0.61662
Epoch 37/300
 - 11s - loss: 0.2952 - acc: 0.9495 - mDice: 0.7308 - val_loss: 0.4793 - val_acc: 0.9525 - val_mDice: 0.6136

Epoch 00037: val_mDice did not improve from 0.61662
Epoch 38/300
 - 11s - loss: 0.2959 - acc: 0.9494 - mDice: 0.7303 - val_loss: 0.4769 - val_acc: 0.9502 - val_mDice: 0.6141

Epoch 00038: val_mDice did not improve from 0.61662
Epoch 39/300
 - 11s - loss: 0.2942 - acc: 0.9496 - mDice: 0.7315 - val_loss: 0.5157 - val_acc: 0.9517 - val_mDice: 0.6011

Epoch 00039: val_mDice did not improve from 0.61662
Epoch 40/300
 - 11s - loss: 0.2938 - acc: 0.9497 - mDice: 0.7320 - val_loss: 0.4883 - val_acc: 0.9512 - val_mDice: 0.6073

Epoch 00040: val_mDice did not improve from 0.61662
Epoch 41/300
 - 12s - loss: 0.2907 - acc: 0.9499 - mDice: 0.7343 - val_loss: 0.5289 - val_acc: 0.9479 - val_mDice: 0.5850

Epoch 00041: val_mDice did not improve from 0.61662
Epoch 42/300
 - 12s - loss: 0.2891 - acc: 0.9500 - mDice: 0.7354 - val_loss: 0.4882 - val_acc: 0.9518 - val_mDice: 0.6093

Epoch 00042: val_mDice did not improve from 0.61662
Epoch 43/300
 - 12s - loss: 0.2889 - acc: 0.9500 - mDice: 0.7356 - val_loss: 0.5119 - val_acc: 0.9526 - val_mDice: 0.6089

Epoch 00043: val_mDice did not improve from 0.61662
Epoch 44/300
 - 12s - loss: 0.2885 - acc: 0.9500 - mDice: 0.7359 - val_loss: 0.4984 - val_acc: 0.9531 - val_mDice: 0.6023

Epoch 00044: val_mDice did not improve from 0.61662
Epoch 45/300
 - 12s - loss: 0.2836 - acc: 0.9504 - mDice: 0.7396 - val_loss: 0.4735 - val_acc: 0.9516 - val_mDice: 0.6138

Epoch 00045: val_mDice did not improve from 0.61662
Epoch 46/300
 - 13s - loss: 0.2855 - acc: 0.9503 - mDice: 0.7382 - val_loss: 0.5386 - val_acc: 0.9496 - val_mDice: 0.5908

Epoch 00046: val_mDice did not improve from 0.61662
Epoch 47/300
 - 12s - loss: 0.2851 - acc: 0.9505 - mDice: 0.7386 - val_loss: 0.4849 - val_acc: 0.9518 - val_mDice: 0.6085

Epoch 00047: val_mDice did not improve from 0.61662
Epoch 48/300
 - 12s - loss: 0.2825 - acc: 0.9507 - mDice: 0.7405 - val_loss: 0.4877 - val_acc: 0.9515 - val_mDice: 0.6101

Epoch 00048: val_mDice did not improve from 0.61662
Epoch 49/300
 - 12s - loss: 0.2804 - acc: 0.9508 - mDice: 0.7422 - val_loss: 0.4870 - val_acc: 0.9508 - val_mDice: 0.6094

Epoch 00049: val_mDice did not improve from 0.61662
Epoch 50/300
 - 12s - loss: 0.2797 - acc: 0.9509 - mDice: 0.7429 - val_loss: 0.4786 - val_acc: 0.9509 - val_mDice: 0.6158

Epoch 00050: val_mDice did not improve from 0.61662
Epoch 51/300
 - 12s - loss: 0.2801 - acc: 0.9510 - mDice: 0.7425 - val_loss: 0.4782 - val_acc: 0.9514 - val_mDice: 0.6109

Epoch 00051: val_mDice did not improve from 0.61662
Epoch 52/300
 - 12s - loss: 0.2854 - acc: 0.9511 - mDice: 0.7435 - val_loss: 0.5067 - val_acc: 0.9501 - val_mDice: 0.5974

Epoch 00052: val_mDice did not improve from 0.61662
Epoch 53/300
 - 13s - loss: 0.2775 - acc: 0.9512 - mDice: 0.7445 - val_loss: 0.5002 - val_acc: 0.9515 - val_mDice: 0.6051

Epoch 00053: val_mDice did not improve from 0.61662
Epoch 54/300
 - 12s - loss: 0.2771 - acc: 0.9513 - mDice: 0.7449 - val_loss: 0.5227 - val_acc: 0.9516 - val_mDice: 0.5934

Epoch 00054: val_mDice did not improve from 0.61662
Epoch 55/300
 - 12s - loss: 0.2760 - acc: 0.9514 - mDice: 0.7457 - val_loss: 0.4983 - val_acc: 0.9490 - val_mDice: 0.6011

Epoch 00055: val_mDice did not improve from 0.61662
Epoch 56/300
 - 13s - loss: 0.2746 - acc: 0.9514 - mDice: 0.7468 - val_loss: 0.4904 - val_acc: 0.9507 - val_mDice: 0.6063

Epoch 00056: val_mDice did not improve from 0.61662
Epoch 57/300
 - 13s - loss: 0.2757 - acc: 0.9515 - mDice: 0.7460 - val_loss: 0.4816 - val_acc: 0.9489 - val_mDice: 0.6074

Epoch 00057: val_mDice did not improve from 0.61662
Epoch 58/300
 - 12s - loss: 0.2731 - acc: 0.9518 - mDice: 0.7479 - val_loss: 0.4996 - val_acc: 0.9505 - val_mDice: 0.5992

Epoch 00058: val_mDice did not improve from 0.61662
Epoch 59/300
 - 13s - loss: 0.2727 - acc: 0.9519 - mDice: 0.7482 - val_loss: 0.5034 - val_acc: 0.9499 - val_mDice: 0.5957

Epoch 00059: val_mDice did not improve from 0.61662
Epoch 60/300
 - 13s - loss: 0.2715 - acc: 0.9520 - mDice: 0.7493 - val_loss: 0.5285 - val_acc: 0.9477 - val_mDice: 0.5865

Epoch 00060: val_mDice did not improve from 0.61662
Epoch 61/300
 - 12s - loss: 0.2721 - acc: 0.9521 - mDice: 0.7487 - val_loss: 0.5103 - val_acc: 0.9489 - val_mDice: 0.5915

Epoch 00061: val_mDice did not improve from 0.61662
Epoch 62/300
 - 12s - loss: 0.2710 - acc: 0.9522 - mDice: 0.7497 - val_loss: 0.4992 - val_acc: 0.9513 - val_mDice: 0.6017

Epoch 00062: val_mDice did not improve from 0.61662
Epoch 63/300
 - 13s - loss: 0.2693 - acc: 0.9523 - mDice: 0.7510 - val_loss: 0.4933 - val_acc: 0.9515 - val_mDice: 0.6054

Epoch 00063: val_mDice did not improve from 0.61662
Epoch 64/300
 - 12s - loss: 0.2693 - acc: 0.9524 - mDice: 0.7509 - val_loss: 0.5354 - val_acc: 0.9518 - val_mDice: 0.5908

Epoch 00064: val_mDice did not improve from 0.61662
Epoch 65/300
 - 13s - loss: 0.2674 - acc: 0.9526 - mDice: 0.7524 - val_loss: 0.4877 - val_acc: 0.9514 - val_mDice: 0.6099

Epoch 00065: val_mDice did not improve from 0.61662
Epoch 66/300
 - 13s - loss: 0.2689 - acc: 0.9524 - mDice: 0.7512 - val_loss: 0.4897 - val_acc: 0.9532 - val_mDice: 0.6086

Epoch 00066: val_mDice did not improve from 0.61662
Epoch 67/300
 - 13s - loss: 0.2676 - acc: 0.9527 - mDice: 0.7522 - val_loss: 0.4960 - val_acc: 0.9529 - val_mDice: 0.6058

Epoch 00067: val_mDice did not improve from 0.61662
Epoch 68/300
 - 12s - loss: 0.2682 - acc: 0.9528 - mDice: 0.7518 - val_loss: 0.5166 - val_acc: 0.9481 - val_mDice: 0.5877

Epoch 00068: val_mDice did not improve from 0.61662
Epoch 69/300
 - 13s - loss: 0.2653 - acc: 0.9531 - mDice: 0.7541 - val_loss: 0.5089 - val_acc: 0.9528 - val_mDice: 0.6030

Epoch 00069: val_mDice did not improve from 0.61662
Epoch 70/300
 - 13s - loss: 0.2663 - acc: 0.9530 - mDice: 0.7533 - val_loss: 0.4798 - val_acc: 0.9534 - val_mDice: 0.6120

Epoch 00070: val_mDice did not improve from 0.61662
Epoch 71/300
 - 13s - loss: 0.2656 - acc: 0.9531 - mDice: 0.7538 - val_loss: 0.4840 - val_acc: 0.9523 - val_mDice: 0.6102

Epoch 00071: val_mDice did not improve from 0.61662
Epoch 72/300
 - 13s - loss: 0.2637 - acc: 0.9532 - mDice: 0.7552 - val_loss: 0.4976 - val_acc: 0.9501 - val_mDice: 0.6008

Epoch 00072: val_mDice did not improve from 0.61662
Epoch 73/300
 - 13s - loss: 0.2640 - acc: 0.9532 - mDice: 0.7551 - val_loss: 0.5090 - val_acc: 0.9510 - val_mDice: 0.5985

Epoch 00073: val_mDice did not improve from 0.61662
Epoch 74/300
 - 13s - loss: 0.2635 - acc: 0.9533 - mDice: 0.7554 - val_loss: 0.5007 - val_acc: 0.9542 - val_mDice: 0.6089

Epoch 00074: val_mDice did not improve from 0.61662
Restoring model weights from the end of the best epoch
Epoch 00074: early stopping
{'val_loss': [1.8298682953392327, 0.667914451500557, 0.6372937982974771, 0.5752868868785197, 0.5604748332966639, 0.559070289800953, 0.5296552634106002, 0.5123029484429173, 0.5182730512246073, 0.5019458825361796, 0.5014566602653632, 0.5047168025757347, 0.4799255998440961, 0.49719833628425386, 0.5050733212652153, 0.4851187977044942, 0.47463416820131865, 0.4943665735548435, 0.49126499957878494, 0.4797987438446983, 0.5011499763867042, 0.4781067990723935, 0.48356064637946017, 0.4816884045494335, 0.5036944467262183, 0.48263693288717857, 0.4942633043454346, 0.5023683692489922, 0.48766330600450825, 0.5136162235750167, 0.49710165188965183, 0.467382672778721, 0.4934935369971078, 0.4723909500590916, 0.4848615910087884, 0.46897445078002675, 0.4792721411369366, 0.4768834300547339, 0.51573732645152, 0.4883412535630125, 0.5288579533885978, 0.48818823811728196, 0.5119135656170339, 0.4983921966739207, 0.47352460409675895, 0.5385760987937117, 0.4849307713561884, 0.4876561754242668, 0.4869900185968623, 0.4786239905730306, 0.478175781958596, 0.5066916802741962, 0.500186192922752, 0.5227410630140891, 0.4982655527871414, 0.49044923209611263, 0.4815775122722434, 0.4995787596569381, 0.5033640435288073, 0.528520229808445, 0.5103309387601288, 0.499237789122086, 0.4932930409575308, 0.5354122189836129, 0.487655250053832, 0.4897239667743278, 0.49596778607235276, 0.5165767116919576, 0.5089254332654303, 0.4798381428478816, 0.4840443407357072, 0.49764502781063485, 0.5090206701662288, 0.500700415512703], 'val_acc': [0.9119698375296992, 0.9339959681367075, 0.9326096746508635, 0.9391590250270992, 0.9444604942252516, 0.9451278431455516, 0.9467620896227533, 0.9461691173095277, 0.9455389803348306, 0.9488281624277211, 0.9457125443986009, 0.9479914151090484, 0.9496173718788105, 0.9504933603649033, 0.9501297417299708, 0.9505718959776382, 0.9500595068132411, 0.9499231440394951, 0.95127846375524, 0.9509912862458043, 0.9478529788262351, 0.9489252647208102, 0.9512722728638675, 0.9521503378559091, 0.9478880856290209, 0.9505057534692007, 0.9510305420646454, 0.9493364089028129, 0.9523879346234838, 0.9473281955585799, 0.9492620119835411, 0.9496999955710086, 0.9485595492677316, 0.9508549371245187, 0.951737120830813, 0.9503136290518265, 0.9525222205582944, 0.9501607311504513, 0.9516834017284755, 0.9512288999957079, 0.9479108079851672, 0.9517887607633069, 0.9525532086468276, 0.9531110421905304, 0.9515532248512992, 0.9496463134302108, 0.9518424891892758, 0.9515449794311097, 0.9508156543337433, 0.9508879724161585, 0.9513817619345042, 0.9501297384001023, 0.9515284592878885, 0.9516090504284012, 0.9490388738376468, 0.9506917059754526, 0.9488839380567966, 0.9504541355138384, 0.9499210768571779, 0.9477290001661418, 0.9488880248043124, 0.9513280551526799, 0.9514540833467878, 0.9518466328775417, 0.9514375711952507, 0.9531544606778874, 0.9529395646223143, 0.9480575000107622, 0.9528321264176395, 0.9534127052935808, 0.95231355268862, 0.9500636564952701, 0.9510264130278007, 0.9542473647847521], 'val_mDice': [0.2550744139615384, 0.5064314470610805, 0.5237865542899297, 0.5511541433174517, 0.5600121767161279, 0.5617214654411018, 0.5798426287134266, 0.5884441307137133, 0.5862855351836987, 0.5945736432874669, 0.5932928703350728, 0.5913811072956916, 0.607986391922615, 0.5966624148065152, 0.5949105543797243, 0.6040426685823409, 0.6108621552003829, 0.598438653866006, 0.602184954302271, 0.6088036485224463, 0.5951484854660887, 0.6110784401440753, 0.6085064630934646, 0.6072603384209745, 0.5945133064046252, 0.6101279478499343, 0.6050509067887034, 0.5980605919267878, 0.6083546437364716, 0.5884024281075547, 0.6030374459048223, 0.6166135502261156, 0.6013864245494651, 0.6166151076055771, 0.6074090796475969, 0.6163132037530398, 0.6135629535387348, 0.6140835528267162, 0.6011433944355842, 0.6072828250224364, 0.5849892973233868, 0.6092960628051332, 0.6088826250097605, 0.6022518080706037, 0.6137785032474795, 0.5907568801714721, 0.6085350713250357, 0.6101213167499564, 0.6093542349405129, 0.6158204032056158, 0.6109072456146751, 0.5974202102789, 0.6050627677800269, 0.5933811401521694, 0.601096018732593, 0.6062739684595077, 0.6074140091848107, 0.5992022519671051, 0.5956642997331459, 0.5864958183725453, 0.5915212078467428, 0.6016821914544984, 0.6053912359908973, 0.590768442473598, 0.6098996497399314, 0.6085544578189956, 0.6058258837161783, 0.5876705886265419, 0.603043479959392, 0.6119967745669062, 0.6102119021575544, 0.6008100989144608, 0.5984847099421411, 0.6089307812339101], 'loss': [2.3284337640451414, 0.8570274001379092, 0.6767796516600247, 0.5896945549968956, 0.5366237484923791, 0.4986018360222706, 0.47696768298698894, 0.4483740942117585, 0.43198871808623146, 0.4172617676802031, 0.40645621961987904, 0.3962541863904151, 0.3863921946257614, 0.3779682024252661, 0.37296090606776766, 0.3630881897342678, 0.35905233142740955, 0.35425220011535097, 0.3483285318694274, 0.3444960333476314, 0.33911604669403, 0.33513327042662133, 0.3313077033867822, 0.3291722187762959, 0.3267459687723858, 0.32190596448018866, 0.3177459301038165, 0.3167937363838618, 0.3138151220146669, 0.31036487888824993, 0.30882373922083234, 0.3069270311955059, 0.3039098379691308, 0.3019362975164122, 0.30004124825059586, 0.2988768523392299, 0.29519501204623366, 0.2958529958258293, 0.2942405010313713, 0.29380272838273513, 0.2907114915111915, 0.2890840202487182, 0.28886464872162076, 0.2885072483787102, 0.28363204872216685, 0.2854690725140748, 0.28514753648329844, 0.28249589364309596, 0.28039871257904875, 0.2796923306670547, 0.28005982693663145, 0.28544773009891933, 0.27747262940220596, 0.2770668842435292, 0.27598077750570876, 0.2745861657356217, 0.2756805190021491, 0.27307902790480637, 0.2726626097944968, 0.27147409104001097, 0.272098421618723, 0.27096985116496297, 0.26927294820444847, 0.26933086713436455, 0.26738595832186934, 0.26890660873439004, 0.26763161652150885, 0.2682143891632255, 0.2652501113017681, 0.26626277034348, 0.265581232208058, 0.26374793501469274, 0.2640424630304456, 0.2635126161335743], 'acc': [0.6768336194019018, 0.9018257367903745, 0.9088472278833221, 0.9149746467563219, 0.9213518241698249, 0.9274896367151593, 0.9322352527234622, 0.9365947701450423, 0.939415622465842, 0.940864776913802, 0.9417807433828667, 0.9424415144757516, 0.9433263812856694, 0.943939192613468, 0.9445030407820916, 0.9450597201977334, 0.9453635383039237, 0.9456487818387824, 0.9460242872118437, 0.9462647984492857, 0.9466551871745391, 0.9468731188896169, 0.947173070137579, 0.9471944990900047, 0.9474691351373811, 0.9478837526394491, 0.9481117978905497, 0.9481506307110419, 0.9481804997766078, 0.9485137284818113, 0.9486232141765152, 0.9487060955988609, 0.9489189778483971, 0.9490895966748307, 0.949178445128845, 0.9492441848416284, 0.9494637694274942, 0.9493558325575858, 0.9496446849928333, 0.9497049268694019, 0.9498790938488948, 0.9499774663759066, 0.9499711833399603, 0.9500058652444263, 0.9503740551691028, 0.9503408036657385, 0.9504714821958897, 0.9506772304631729, 0.9507757452641766, 0.9508540730877358, 0.9509904334620579, 0.9510770030942568, 0.9511671965336865, 0.9512569274292566, 0.9513632587037129, 0.9514146381704566, 0.9515243125055345, 0.9517792883141876, 0.9518620655899065, 0.9520121432325885, 0.9520915022674686, 0.9522248808480992, 0.9523365069049862, 0.9523799724097372, 0.952604251261481, 0.9524002337006466, 0.9526946256476403, 0.95281539750342, 0.9530656777119807, 0.9530365929079759, 0.9530792541931374, 0.953201030614907, 0.9532406485831905, 0.9532852831550896], 'mDice': [0.16372306106036788, 0.4148905836713255, 0.496638943258762, 0.5414153144520734, 0.5712339523817536, 0.5936253699762396, 0.6074877705723883, 0.6245564675708981, 0.6350967197414058, 0.6445910487648423, 0.6515383338961984, 0.6584384241730525, 0.6650874686522925, 0.6709944444423108, 0.6744903346680782, 0.6811832133756667, 0.68407262379902, 0.6874644130047978, 0.6915960340813857, 0.6945865286324358, 0.6982198351673893, 0.7012452394781429, 0.703946527822638, 0.7054333703676721, 0.7073216995741831, 0.710803214257517, 0.7139053657536517, 0.7146409957518369, 0.7168156779686952, 0.719346793617508, 0.7203858773093241, 0.7218548050146725, 0.7241197413144097, 0.7257606730885212, 0.7271105780833155, 0.7280353001796124, 0.7307795074587131, 0.7302752769101802, 0.7315146006060662, 0.7319671197541626, 0.7342579503716691, 0.7354390026145197, 0.7356229251678016, 0.7359007109413284, 0.7396344395090529, 0.7381995670559502, 0.7385854607385187, 0.7405262642206434, 0.7422054084250691, 0.7428605165572982, 0.7424643956707893, 0.7435011878349145, 0.744452768788541, 0.7448829976011677, 0.7457341344376923, 0.7467846377736946, 0.745961582002982, 0.7478657589519175, 0.74818180908299, 0.7492581334328847, 0.7487471755355618, 0.7496611612969303, 0.7509599125636546, 0.7508607626896228, 0.7524000597729882, 0.7512093602484539, 0.7522496265930312, 0.7518483763601739, 0.7540675468722964, 0.7532720884254351, 0.7538377643053545, 0.7552208301516038, 0.7551108201658614, 0.7554489325596664]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.13s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.90s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:01,  1.91s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:25,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:17,  1.76s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:49,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:04,  1.73s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:48,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:09,  1.76s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:58,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:29,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:45,  1.91s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:20,  1.83s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:37,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:11,  1.81s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:14,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:40,  1.93s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:49,  1.97s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:19,  1.86s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:23,  1.89s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:08,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:09,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:27,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:04,  1.84s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:05,  1.85s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:42,  1.77s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:05,  1.87s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:12,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:48,  1.82s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:57,  1.86s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:59,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:11,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:24,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:57,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:56,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:46,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:05,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:57,  1.92s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<08:02,  1.95s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<08:34,  2.08s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<08:16,  2.02s/it]predicting train subjects:  14%|█▍        | 40/285 [01:15<08:21,  2.05s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<08:07,  2.00s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<08:12,  2.03s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<08:24,  2.09s/it]predicting train subjects:  15%|█▌        | 44/285 [01:23<08:49,  2.20s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<08:27,  2.11s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<08:45,  2.20s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<08:26,  2.13s/it]predicting train subjects:  17%|█▋        | 48/285 [01:32<08:29,  2.15s/it]predicting train subjects:  17%|█▋        | 49/285 [01:34<08:45,  2.23s/it]predicting train subjects:  18%|█▊        | 50/285 [01:36<08:42,  2.22s/it]predicting train subjects:  18%|█▊        | 51/285 [01:39<08:52,  2.27s/it]predicting train subjects:  18%|█▊        | 52/285 [01:41<08:34,  2.21s/it]predicting train subjects:  19%|█▊        | 53/285 [01:43<08:31,  2.21s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<09:00,  2.34s/it]predicting train subjects:  19%|█▉        | 55/285 [01:48<08:35,  2.24s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<08:24,  2.20s/it]predicting train subjects:  20%|██        | 57/285 [01:52<07:58,  2.10s/it]predicting train subjects:  20%|██        | 58/285 [01:54<08:03,  2.13s/it]predicting train subjects:  21%|██        | 59/285 [01:56<08:40,  2.30s/it]predicting train subjects:  21%|██        | 60/285 [01:59<08:39,  2.31s/it]predicting train subjects:  21%|██▏       | 61/285 [02:01<08:14,  2.21s/it]predicting train subjects:  22%|██▏       | 62/285 [02:03<08:15,  2.22s/it]predicting train subjects:  22%|██▏       | 63/285 [02:05<08:06,  2.19s/it]predicting train subjects:  22%|██▏       | 64/285 [02:07<07:49,  2.12s/it]predicting train subjects:  23%|██▎       | 65/285 [02:09<07:45,  2.12s/it]predicting train subjects:  23%|██▎       | 66/285 [02:11<07:53,  2.16s/it]predicting train subjects:  24%|██▎       | 67/285 [02:14<07:47,  2.14s/it]predicting train subjects:  24%|██▍       | 68/285 [02:15<07:30,  2.08s/it]predicting train subjects:  24%|██▍       | 69/285 [02:18<07:40,  2.13s/it]predicting train subjects:  25%|██▍       | 70/285 [02:20<07:43,  2.16s/it]predicting train subjects:  25%|██▍       | 71/285 [02:22<07:36,  2.13s/it]predicting train subjects:  25%|██▌       | 72/285 [02:24<07:27,  2.10s/it]predicting train subjects:  26%|██▌       | 73/285 [02:26<07:36,  2.16s/it]predicting train subjects:  26%|██▌       | 74/285 [02:29<07:46,  2.21s/it]predicting train subjects:  26%|██▋       | 75/285 [02:31<07:49,  2.23s/it]predicting train subjects:  27%|██▋       | 76/285 [02:33<07:43,  2.22s/it]predicting train subjects:  27%|██▋       | 77/285 [02:35<07:19,  2.11s/it]predicting train subjects:  27%|██▋       | 78/285 [02:37<07:16,  2.11s/it]predicting train subjects:  28%|██▊       | 79/285 [02:39<07:21,  2.14s/it]predicting train subjects:  28%|██▊       | 80/285 [02:42<07:24,  2.17s/it]predicting train subjects:  28%|██▊       | 81/285 [02:44<07:14,  2.13s/it]predicting train subjects:  29%|██▉       | 82/285 [02:46<07:13,  2.13s/it]predicting train subjects:  29%|██▉       | 83/285 [02:48<07:06,  2.11s/it]predicting train subjects:  29%|██▉       | 84/285 [02:50<07:00,  2.09s/it]predicting train subjects:  30%|██▉       | 85/285 [02:52<07:06,  2.13s/it]predicting train subjects:  30%|███       | 86/285 [02:54<07:06,  2.14s/it]predicting train subjects:  31%|███       | 87/285 [02:56<06:53,  2.09s/it]predicting train subjects:  31%|███       | 88/285 [02:58<06:55,  2.11s/it]predicting train subjects:  31%|███       | 89/285 [03:00<06:43,  2.06s/it]predicting train subjects:  32%|███▏      | 90/285 [03:03<06:50,  2.10s/it]predicting train subjects:  32%|███▏      | 91/285 [03:05<06:42,  2.07s/it]predicting train subjects:  32%|███▏      | 92/285 [03:07<06:47,  2.11s/it]predicting train subjects:  33%|███▎      | 93/285 [03:09<06:38,  2.07s/it]predicting train subjects:  33%|███▎      | 94/285 [03:11<06:43,  2.11s/it]predicting train subjects:  33%|███▎      | 95/285 [03:13<06:40,  2.11s/it]predicting train subjects:  34%|███▎      | 96/285 [03:15<06:39,  2.11s/it]predicting train subjects:  34%|███▍      | 97/285 [03:18<06:51,  2.19s/it]predicting train subjects:  34%|███▍      | 98/285 [03:20<06:43,  2.16s/it]predicting train subjects:  35%|███▍      | 99/285 [03:22<06:39,  2.15s/it]predicting train subjects:  35%|███▌      | 100/285 [03:24<06:28,  2.10s/it]predicting train subjects:  35%|███▌      | 101/285 [03:26<06:19,  2.06s/it]predicting train subjects:  36%|███▌      | 102/285 [03:28<06:26,  2.11s/it]predicting train subjects:  36%|███▌      | 103/285 [03:30<06:19,  2.08s/it]predicting train subjects:  36%|███▋      | 104/285 [03:32<06:11,  2.05s/it]predicting train subjects:  37%|███▋      | 105/285 [03:34<06:21,  2.12s/it]predicting train subjects:  37%|███▋      | 106/285 [03:36<06:09,  2.06s/it]predicting train subjects:  38%|███▊      | 107/285 [03:38<06:13,  2.10s/it]predicting train subjects:  38%|███▊      | 108/285 [03:41<06:20,  2.15s/it]predicting train subjects:  38%|███▊      | 109/285 [03:43<06:28,  2.21s/it]predicting train subjects:  39%|███▊      | 110/285 [03:45<06:30,  2.23s/it]predicting train subjects:  39%|███▉      | 111/285 [03:47<06:18,  2.17s/it]predicting train subjects:  39%|███▉      | 112/285 [03:49<06:11,  2.15s/it]predicting train subjects:  40%|███▉      | 113/285 [03:51<06:10,  2.15s/it]predicting train subjects:  40%|████      | 114/285 [03:54<06:01,  2.12s/it]predicting train subjects:  40%|████      | 115/285 [03:56<05:59,  2.11s/it]predicting train subjects:  41%|████      | 116/285 [03:58<06:04,  2.16s/it]predicting train subjects:  41%|████      | 117/285 [04:00<05:58,  2.13s/it]predicting train subjects:  41%|████▏     | 118/285 [04:02<05:48,  2.09s/it]predicting train subjects:  42%|████▏     | 119/285 [04:04<05:49,  2.10s/it]predicting train subjects:  42%|████▏     | 120/285 [04:06<05:39,  2.06s/it]predicting train subjects:  42%|████▏     | 121/285 [04:08<05:39,  2.07s/it]predicting train subjects:  43%|████▎     | 122/285 [04:10<05:24,  1.99s/it]predicting train subjects:  43%|████▎     | 123/285 [04:12<05:10,  1.92s/it]predicting train subjects:  44%|████▎     | 124/285 [04:14<05:14,  1.95s/it]predicting train subjects:  44%|████▍     | 125/285 [04:16<05:08,  1.93s/it]predicting train subjects:  44%|████▍     | 126/285 [04:17<05:01,  1.90s/it]predicting train subjects:  45%|████▍     | 127/285 [04:19<04:47,  1.82s/it]predicting train subjects:  45%|████▍     | 128/285 [04:21<04:46,  1.82s/it]predicting train subjects:  45%|████▌     | 129/285 [04:23<04:40,  1.80s/it]predicting train subjects:  46%|████▌     | 130/285 [04:24<04:32,  1.76s/it]predicting train subjects:  46%|████▌     | 131/285 [04:26<04:30,  1.76s/it]predicting train subjects:  46%|████▋     | 132/285 [04:28<04:38,  1.82s/it]predicting train subjects:  47%|████▋     | 133/285 [04:30<04:33,  1.80s/it]predicting train subjects:  47%|████▋     | 134/285 [04:32<04:30,  1.79s/it]predicting train subjects:  47%|████▋     | 135/285 [04:33<04:32,  1.82s/it]predicting train subjects:  48%|████▊     | 136/285 [04:35<04:26,  1.79s/it]predicting train subjects:  48%|████▊     | 137/285 [04:37<04:24,  1.79s/it]predicting train subjects:  48%|████▊     | 138/285 [04:39<04:25,  1.81s/it]predicting train subjects:  49%|████▉     | 139/285 [04:41<04:30,  1.85s/it]predicting train subjects:  49%|████▉     | 140/285 [04:43<04:36,  1.91s/it]predicting train subjects:  49%|████▉     | 141/285 [04:45<04:28,  1.87s/it]predicting train subjects:  50%|████▉     | 142/285 [04:46<04:27,  1.87s/it]predicting train subjects:  50%|█████     | 143/285 [04:48<04:19,  1.82s/it]predicting train subjects:  51%|█████     | 144/285 [04:50<04:22,  1.86s/it]predicting train subjects:  51%|█████     | 145/285 [04:52<04:14,  1.82s/it]predicting train subjects:  51%|█████     | 146/285 [04:54<04:10,  1.80s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:55<04:09,  1.81s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:57<04:14,  1.86s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:59<04:08,  1.83s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:01<04:05,  1.82s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:03<04:09,  1.86s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<04:06,  1.86s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:06<04:00,  1.82s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:08<03:57,  1.81s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:10<03:59,  1.84s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:12<04:08,  1.93s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:14<03:59,  1.87s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:16<03:55,  1.85s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:18<03:47,  1.81s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:19<03:38,  1.75s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:21<03:36,  1.74s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:23<03:30,  1.71s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:24<03:36,  1.77s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:26<03:23,  1.68s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:27<03:14,  1.62s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:29<03:09,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:11,  1.62s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:32<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:34<03:00,  1.55s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:35<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [05:37<02:55,  1.54s/it]predicting train subjects:  60%|██████    | 172/285 [05:38<02:54,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:40<02:51,  1.53s/it]predicting train subjects:  61%|██████    | 174/285 [05:41<02:48,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:43<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:44<02:52,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:46<02:45,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:47<02:40,  1.50s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:49<02:37,  1.49s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:50<02:44,  1.57s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:52<02:47,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:54<02:50,  1.66s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:55<02:43,  1.60s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:57<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:58<02:32,  1.53s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:00<02:41,  1.63s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:02<02:44,  1.68s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:04<02:45,  1.71s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:05<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:07<02:28,  1.56s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:08<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:10<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:11<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:13<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:14<02:13,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:16<02:22,  1.60s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:18<02:26,  1.66s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:20<02:28,  1.71s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:21<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [06:23<02:16,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [06:24<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [06:26<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [06:28<02:18,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:29<02:10,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:31<02:08,  1.60s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:32<02:03,  1.56s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:34<02:08,  1.64s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:36<02:10,  1.70s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:38<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:39<02:03,  1.64s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:41<01:59,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:43<01:59,  1.64s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:44<01:59,  1.66s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:46<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:47<01:56,  1.66s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:49<01:51,  1.61s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:51<01:56,  1.72s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:53<01:58,  1.76s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:55<01:57,  1.78s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:56<01:49,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:58<01:42,  1.61s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:59<01:43,  1.64s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:01<01:38,  1.59s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:02<01:34,  1.55s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:04<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:05<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:07<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [07:09<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [07:11<01:36,  1.73s/it]predicting train subjects:  81%|████████  | 230/285 [07:12<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [07:14<01:26,  1.60s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:16<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:17<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:19<01:23,  1.63s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:20<01:20,  1.61s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:22<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:24<01:23,  1.74s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:26<01:23,  1.77s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:28<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:29<01:15,  1.68s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:31<01:11,  1.63s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:32<01:08,  1.59s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:34<01:05,  1.56s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:35<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:37<01:03,  1.58s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:39<01:05,  1.67s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:41<01:04,  1.71s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:42<01:03,  1.73s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:44<00:59,  1.65s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:45<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:47<00:53,  1.56s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:48<00:50,  1.53s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:50<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:52<00:53,  1.74s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:54<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:55<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:57<00:44,  1.61s/it]predicting train subjects:  91%|█████████ | 258/285 [07:59<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [08:00<00:44,  1.72s/it]predicting train subjects:  91%|█████████ | 260/285 [08:02<00:40,  1.64s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:03<00:37,  1.58s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:05<00:35,  1.54s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:06<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:08<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:10<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:12<00:31,  1.67s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:13<00:29,  1.62s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:15<00:28,  1.69s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:17<00:27,  1.69s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:18<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:20<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:21<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:23<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:24<00:17,  1.56s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:26<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:28<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:30<00:13,  1.65s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:31<00:11,  1.63s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:33<00:10,  1.68s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:34<00:08,  1.65s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:36<00:06,  1.60s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:37<00:04,  1.57s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:39<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:41<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:43<00:00,  1.77s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:37,  1.61s/it]Loading train:   1%|          | 2/285 [00:02<06:58,  1.48s/it]Loading train:   1%|          | 3/285 [00:04<06:55,  1.47s/it]Loading train:   1%|▏         | 4/285 [00:05<06:18,  1.35s/it]Loading train:   2%|▏         | 5/285 [00:06<06:27,  1.38s/it]Loading train:   2%|▏         | 6/285 [00:07<06:07,  1.32s/it]Loading train:   2%|▏         | 7/285 [00:09<06:25,  1.39s/it]Loading train:   3%|▎         | 8/285 [00:10<06:23,  1.39s/it]Loading train:   3%|▎         | 9/285 [00:12<06:50,  1.49s/it]Loading train:   4%|▎         | 10/285 [00:13<06:32,  1.43s/it]Loading train:   4%|▍         | 11/285 [00:14<05:47,  1.27s/it]Loading train:   4%|▍         | 12/285 [00:15<05:26,  1.20s/it]Loading train:   5%|▍         | 13/285 [00:16<04:55,  1.09s/it]Loading train:   5%|▍         | 14/285 [00:17<04:49,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:18<04:44,  1.05s/it]Loading train:   6%|▌         | 16/285 [00:19<04:52,  1.09s/it]Loading train:   6%|▌         | 17/285 [00:20<04:26,  1.01it/s]Loading train:   6%|▋         | 18/285 [00:21<04:23,  1.01it/s]Loading train:   7%|▋         | 19/285 [00:22<04:18,  1.03it/s]Loading train:   7%|▋         | 20/285 [00:23<04:16,  1.03it/s]Loading train:   7%|▋         | 21/285 [00:24<04:09,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:25<04:11,  1.04it/s]Loading train:   8%|▊         | 23/285 [00:26<04:13,  1.04it/s]Loading train:   8%|▊         | 24/285 [00:27<04:06,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:28<04:04,  1.06it/s]Loading train:   9%|▉         | 26/285 [00:29<04:12,  1.03it/s]Loading train:   9%|▉         | 27/285 [00:29<03:56,  1.09it/s]Loading train:  10%|▉         | 28/285 [00:31<04:15,  1.01it/s]Loading train:  10%|█         | 29/285 [00:32<04:13,  1.01it/s]Loading train:  11%|█         | 30/285 [00:33<04:15,  1.00s/it]Loading train:  11%|█         | 31/285 [00:34<04:27,  1.05s/it]Loading train:  11%|█         | 32/285 [00:35<04:12,  1.00it/s]Loading train:  12%|█▏        | 33/285 [00:36<04:07,  1.02it/s]Loading train:  12%|█▏        | 34/285 [00:36<03:52,  1.08it/s]Loading train:  12%|█▏        | 35/285 [00:38<04:14,  1.02s/it]Loading train:  13%|█▎        | 36/285 [00:39<03:57,  1.05it/s]Loading train:  13%|█▎        | 37/285 [00:40<04:02,  1.02it/s]Loading train:  13%|█▎        | 38/285 [00:40<03:59,  1.03it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:41,  1.11it/s]Loading train:  14%|█▍        | 40/285 [00:42<03:38,  1.12it/s]Loading train:  14%|█▍        | 41/285 [00:43<03:47,  1.07it/s]Loading train:  15%|█▍        | 42/285 [00:44<03:39,  1.11it/s]Loading train:  15%|█▌        | 43/285 [00:45<03:45,  1.08it/s]Loading train:  15%|█▌        | 44/285 [00:46<03:42,  1.08it/s]Loading train:  16%|█▌        | 45/285 [00:47<03:35,  1.11it/s]Loading train:  16%|█▌        | 46/285 [00:48<03:37,  1.10it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:33,  1.12it/s]Loading train:  17%|█▋        | 48/285 [00:50<03:41,  1.07it/s]Loading train:  17%|█▋        | 49/285 [00:51<04:03,  1.03s/it]Loading train:  18%|█▊        | 50/285 [00:52<04:00,  1.02s/it]Loading train:  18%|█▊        | 51/285 [00:53<03:55,  1.01s/it]Loading train:  18%|█▊        | 52/285 [00:54<04:09,  1.07s/it]Loading train:  19%|█▊        | 53/285 [00:55<03:59,  1.03s/it]Loading train:  19%|█▉        | 54/285 [00:56<03:53,  1.01s/it]Loading train:  19%|█▉        | 55/285 [00:57<03:31,  1.09it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:25,  1.12it/s]Loading train:  20%|██        | 57/285 [00:58<03:15,  1.17it/s]Loading train:  20%|██        | 58/285 [00:59<03:12,  1.18it/s]Loading train:  21%|██        | 59/285 [01:00<03:07,  1.20it/s]Loading train:  21%|██        | 60/285 [01:01<03:15,  1.15it/s]Loading train:  21%|██▏       | 61/285 [01:02<03:24,  1.09it/s]Loading train:  22%|██▏       | 62/285 [01:03<03:29,  1.06it/s]Loading train:  22%|██▏       | 63/285 [01:04<03:25,  1.08it/s]Loading train:  22%|██▏       | 64/285 [01:05<03:45,  1.02s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:19,  1.18s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:21,  1.19s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:11,  1.16s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:49,  1.06s/it]Loading train:  24%|██▍       | 69/285 [01:11<03:42,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:12<03:44,  1.05s/it]Loading train:  25%|██▍       | 71/285 [01:13<03:39,  1.03s/it]Loading train:  25%|██▌       | 72/285 [01:13<03:27,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:18,  1.07it/s]Loading train:  26%|██▌       | 74/285 [01:15<03:17,  1.07it/s]Loading train:  26%|██▋       | 75/285 [01:16<03:08,  1.11it/s]Loading train:  27%|██▋       | 76/285 [01:17<03:16,  1.06it/s]Loading train:  27%|██▋       | 77/285 [01:18<03:03,  1.13it/s]Loading train:  27%|██▋       | 78/285 [01:19<02:57,  1.17it/s]Loading train:  28%|██▊       | 79/285 [01:19<02:52,  1.19it/s]Loading train:  28%|██▊       | 80/285 [01:20<02:51,  1.19it/s]Loading train:  28%|██▊       | 81/285 [01:21<02:50,  1.20it/s]Loading train:  29%|██▉       | 82/285 [01:22<02:56,  1.15it/s]Loading train:  29%|██▉       | 83/285 [01:23<02:58,  1.13it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:47,  1.20it/s]Loading train:  30%|██▉       | 85/285 [01:25<02:51,  1.17it/s]Loading train:  30%|███       | 86/285 [01:26<02:57,  1.12it/s]Loading train:  31%|███       | 87/285 [01:27<02:58,  1.11it/s]Loading train:  31%|███       | 88/285 [01:27<02:52,  1.14it/s]Loading train:  31%|███       | 89/285 [01:28<02:56,  1.11it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:13,  1.01it/s]Loading train:  32%|███▏      | 91/285 [01:30<02:59,  1.08it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:07,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:32<03:00,  1.06it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:58,  1.07it/s]Loading train:  33%|███▎      | 95/285 [01:34<03:04,  1.03it/s]Loading train:  34%|███▎      | 96/285 [01:35<02:59,  1.05it/s]Loading train:  34%|███▍      | 97/285 [01:36<03:01,  1.03it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:59,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:58,  1.04it/s]Loading train:  35%|███▌      | 100/285 [01:39<03:04,  1.00it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:55,  1.05it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:48,  1.08it/s]Loading train:  36%|███▌      | 103/285 [01:42<02:50,  1.07it/s]Loading train:  36%|███▋      | 104/285 [01:43<02:49,  1.07it/s]Loading train:  37%|███▋      | 105/285 [01:44<02:45,  1.09it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:36,  1.14it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:34,  1.15it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:29,  1.19it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:25,  1.21it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:34,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:31,  1.15it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:44,  1.05it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:46,  1.03it/s]Loading train:  40%|████      | 114/285 [01:52<02:48,  1.01it/s]Loading train:  40%|████      | 115/285 [01:53<02:45,  1.03it/s]Loading train:  41%|████      | 116/285 [01:54<02:41,  1.05it/s]Loading train:  41%|████      | 117/285 [01:54<02:31,  1.11it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:25,  1.14it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:23,  1.15it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:21,  1.17it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:38,  1.03it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:46,  1.02s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:53,  1.07s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:40,  1.00it/s]Loading train:  44%|████▍     | 125/285 [02:02<02:36,  1.02it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:21,  1.12it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:17,  1.15it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:11,  1.19it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:13,  1.17it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:04,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:07<01:57,  1.31it/s]Loading train:  46%|████▋     | 132/285 [02:07<01:54,  1.33it/s]Loading train:  47%|████▋     | 133/285 [02:08<01:53,  1.34it/s]Loading train:  47%|████▋     | 134/285 [02:09<01:52,  1.34it/s]Loading train:  47%|████▋     | 135/285 [02:10<01:59,  1.25it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:57,  1.26it/s]Loading train:  48%|████▊     | 137/285 [02:12<02:02,  1.21it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:59,  1.23it/s]Loading train:  49%|████▉     | 139/285 [02:13<02:01,  1.20it/s]Loading train:  49%|████▉     | 140/285 [02:14<02:07,  1.13it/s]Loading train:  49%|████▉     | 141/285 [02:15<02:03,  1.16it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:55,  1.24it/s]Loading train:  50%|█████     | 143/285 [02:16<01:49,  1.30it/s]Loading train:  51%|█████     | 144/285 [02:17<01:50,  1.28it/s]Loading train:  51%|█████     | 145/285 [02:18<01:46,  1.31it/s]Loading train:  51%|█████     | 146/285 [02:19<01:47,  1.29it/s]Loading train:  52%|█████▏    | 147/285 [02:19<01:46,  1.30it/s]Loading train:  52%|█████▏    | 148/285 [02:20<01:44,  1.31it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:46,  1.28it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:43,  1.31it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:47,  1.24it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:49,  1.21it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:49,  1.20it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:54,  1.14it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:49,  1.18it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:54,  1.13it/s]Loading train:  55%|█████▌    | 157/285 [02:28<01:45,  1.21it/s]Loading train:  55%|█████▌    | 158/285 [02:29<01:47,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:30<01:46,  1.18it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:48,  1.15it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:50,  1.12it/s]Loading train:  57%|█████▋    | 162/285 [02:32<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:33<01:51,  1.10it/s]Loading train:  58%|█████▊    | 164/285 [02:34<01:47,  1.13it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:47,  1.12it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:46,  1.12it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:38,  1.20it/s]Loading train:  59%|█████▉    | 168/285 [02:37<01:39,  1.18it/s]Loading train:  59%|█████▉    | 169/285 [02:38<01:38,  1.17it/s]Loading train:  60%|█████▉    | 170/285 [02:39<01:37,  1.18it/s]Loading train:  60%|██████    | 171/285 [02:40<01:35,  1.20it/s]Loading train:  60%|██████    | 172/285 [02:41<01:36,  1.17it/s]Loading train:  61%|██████    | 173/285 [02:42<01:31,  1.23it/s]Loading train:  61%|██████    | 174/285 [02:42<01:33,  1.19it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:28,  1.24it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:30,  1.21it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:27,  1.24it/s]Loading train:  62%|██████▏   | 178/285 [02:46<01:25,  1.24it/s]Loading train:  63%|██████▎   | 179/285 [02:46<01:22,  1.28it/s]Loading train:  63%|██████▎   | 180/285 [02:47<01:27,  1.20it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:33,  1.12it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:30,  1.14it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:23,  1.22it/s]Loading train:  65%|██████▍   | 184/285 [02:51<01:20,  1.25it/s]Loading train:  65%|██████▍   | 185/285 [02:51<01:13,  1.35it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:22,  1.21it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:26,  1.14it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:25,  1.13it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:23,  1.15it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:20,  1.18it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:21,  1.15it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:18,  1.18it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:18,  1.18it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:16,  1.19it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:15,  1.20it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:15,  1.18it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:15,  1.16it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:19,  1.10it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:15,  1.14it/s]Loading train:  70%|███████   | 200/285 [03:04<01:10,  1.20it/s]Loading train:  71%|███████   | 201/285 [03:05<01:14,  1.13it/s]Loading train:  71%|███████   | 202/285 [03:06<01:12,  1.14it/s]Loading train:  71%|███████   | 203/285 [03:07<01:11,  1.14it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:08,  1.18it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:05,  1.22it/s]Loading train:  72%|███████▏  | 206/285 [03:09<01:04,  1.22it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:05,  1.19it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:06,  1.16it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:08,  1.11it/s]Loading train:  74%|███████▎  | 210/285 [03:13<01:03,  1.18it/s]Loading train:  74%|███████▍  | 211/285 [03:14<00:59,  1.24it/s]Loading train:  74%|███████▍  | 212/285 [03:15<01:03,  1.16it/s]Loading train:  75%|███████▍  | 213/285 [03:16<01:02,  1.15it/s]Loading train:  75%|███████▌  | 214/285 [03:16<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:17<01:02,  1.12it/s]Loading train:  76%|███████▌  | 216/285 [03:18<01:01,  1.12it/s]Loading train:  76%|███████▌  | 217/285 [03:19<00:59,  1.14it/s]Loading train:  76%|███████▋  | 218/285 [03:20<01:00,  1.10it/s]Loading train:  77%|███████▋  | 219/285 [03:21<01:02,  1.06it/s]Loading train:  77%|███████▋  | 220/285 [03:22<00:55,  1.18it/s]Loading train:  78%|███████▊  | 221/285 [03:23<00:52,  1.21it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [03:24<00:50,  1.22it/s]Loading train:  79%|███████▊  | 224/285 [03:25<00:50,  1.22it/s]Loading train:  79%|███████▉  | 225/285 [03:26<00:47,  1.26it/s]Loading train:  79%|███████▉  | 226/285 [03:27<00:50,  1.17it/s]Loading train:  80%|███████▉  | 227/285 [03:28<00:51,  1.14it/s]Loading train:  80%|████████  | 228/285 [03:28<00:49,  1.15it/s]Loading train:  80%|████████  | 229/285 [03:29<00:49,  1.14it/s]Loading train:  81%|████████  | 230/285 [03:30<00:44,  1.25it/s]Loading train:  81%|████████  | 231/285 [03:31<00:41,  1.31it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:40,  1.30it/s]Loading train:  82%|████████▏ | 233/285 [03:32<00:40,  1.30it/s]Loading train:  82%|████████▏ | 234/285 [03:33<00:42,  1.21it/s]Loading train:  82%|████████▏ | 235/285 [03:34<00:41,  1.20it/s]Loading train:  83%|████████▎ | 236/285 [03:35<00:42,  1.16it/s]Loading train:  83%|████████▎ | 237/285 [03:36<00:42,  1.12it/s]Loading train:  84%|████████▎ | 238/285 [03:37<00:42,  1.10it/s]Loading train:  84%|████████▍ | 239/285 [03:38<00:41,  1.10it/s]Loading train:  84%|████████▍ | 240/285 [03:39<00:39,  1.15it/s]Loading train:  85%|████████▍ | 241/285 [03:40<00:39,  1.11it/s]Loading train:  85%|████████▍ | 242/285 [03:40<00:35,  1.22it/s]Loading train:  85%|████████▌ | 243/285 [03:41<00:34,  1.21it/s]Loading train:  86%|████████▌ | 244/285 [03:42<00:35,  1.16it/s]Loading train:  86%|████████▌ | 245/285 [03:43<00:35,  1.14it/s]Loading train:  86%|████████▋ | 246/285 [03:44<00:34,  1.13it/s]Loading train:  87%|████████▋ | 247/285 [03:45<00:33,  1.13it/s]Loading train:  87%|████████▋ | 248/285 [03:46<00:32,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [03:46<00:30,  1.18it/s]Loading train:  88%|████████▊ | 250/285 [03:47<00:30,  1.14it/s]Loading train:  88%|████████▊ | 251/285 [03:48<00:28,  1.21it/s]Loading train:  88%|████████▊ | 252/285 [03:49<00:26,  1.23it/s]Loading train:  89%|████████▉ | 253/285 [03:50<00:27,  1.16it/s]Loading train:  89%|████████▉ | 254/285 [03:51<00:26,  1.18it/s]Loading train:  89%|████████▉ | 255/285 [03:51<00:25,  1.19it/s]Loading train:  90%|████████▉ | 256/285 [03:52<00:23,  1.22it/s]Loading train:  90%|█████████ | 257/285 [03:53<00:23,  1.21it/s]Loading train:  91%|█████████ | 258/285 [03:54<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [03:55<00:22,  1.13it/s]Loading train:  91%|█████████ | 260/285 [03:56<00:21,  1.16it/s]Loading train:  92%|█████████▏| 261/285 [03:56<00:20,  1.19it/s]Loading train:  92%|█████████▏| 262/285 [03:57<00:17,  1.29it/s]Loading train:  92%|█████████▏| 263/285 [03:58<00:17,  1.25it/s]Loading train:  93%|█████████▎| 264/285 [03:59<00:18,  1.17it/s]Loading train:  93%|█████████▎| 265/285 [04:00<00:17,  1.15it/s]Loading train:  93%|█████████▎| 266/285 [04:01<00:16,  1.15it/s]Loading train:  94%|█████████▎| 267/285 [04:02<00:15,  1.18it/s]Loading train:  94%|█████████▍| 268/285 [04:03<00:15,  1.08it/s]Loading train:  94%|█████████▍| 269/285 [04:03<00:14,  1.12it/s]Loading train:  95%|█████████▍| 270/285 [04:04<00:12,  1.16it/s]Loading train:  95%|█████████▌| 271/285 [04:05<00:11,  1.23it/s]Loading train:  95%|█████████▌| 272/285 [04:06<00:11,  1.14it/s]Loading train:  96%|█████████▌| 273/285 [04:07<00:09,  1.28it/s]Loading train:  96%|█████████▌| 274/285 [04:07<00:08,  1.35it/s]Loading train:  96%|█████████▋| 275/285 [04:08<00:07,  1.27it/s]Loading train:  97%|█████████▋| 276/285 [04:09<00:07,  1.22it/s]Loading train:  97%|█████████▋| 277/285 [04:10<00:06,  1.28it/s]Loading train:  98%|█████████▊| 278/285 [04:10<00:05,  1.33it/s]Loading train:  98%|█████████▊| 279/285 [04:11<00:04,  1.24it/s]Loading train:  98%|█████████▊| 280/285 [04:12<00:04,  1.24it/s]Loading train:  99%|█████████▊| 281/285 [04:13<00:03,  1.27it/s]Loading train:  99%|█████████▉| 282/285 [04:13<00:02,  1.34it/s]Loading train:  99%|█████████▉| 283/285 [04:14<00:01,  1.26it/s]Loading train: 100%|█████████▉| 284/285 [04:15<00:00,  1.17it/s]Loading train: 100%|██████████| 285/285 [04:16<00:00,  1.17it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:01, 139.47it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:02, 129.22it/s]concatenating: train:  14%|█▍        | 41/285 [00:00<00:01, 130.60it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:02, 87.46it/s] concatenating: train:  28%|██▊       | 81/285 [00:00<00:01, 111.16it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:01, 137.36it/s]concatenating: train:  49%|████▉     | 141/285 [00:00<00:00, 162.81it/s]concatenating: train:  60%|██████    | 171/285 [00:00<00:00, 188.21it/s]concatenating: train:  72%|███████▏  | 205/285 [00:01<00:00, 215.48it/s]concatenating: train:  84%|████████▍ | 239/285 [00:01<00:00, 241.31it/s]concatenating: train:  94%|█████████▍| 268/285 [00:01<00:00, 252.80it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 227.49it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.45s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.32s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 118.52it/s]2019-07-10 21:17:12.243482: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:17:12.243592: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:17:12.243607: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:17:12.243616: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:17:12.244115: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.35it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.25it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.11it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.61it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.14it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.98it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.06it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.83it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.20it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.72it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.43it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.70it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.94it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.04it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.82it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.04it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.22it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.11it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 226,723
Trainable params: 52,003
Non-trainable params: 174,720
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.9522 - acc: 0.6457 - mDice: 0.0802 - val_loss: 1.8379 - val_acc: 0.9020 - val_mDice: 0.2206

Epoch 00001: val_mDice improved from -inf to 0.22057, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.2354 - acc: 0.8802 - mDice: 0.2844 - val_loss: 1.5023 - val_acc: 0.8921 - val_mDice: 0.3034

Epoch 00002: val_mDice improved from 0.22057 to 0.30340, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.8964 - acc: 0.8889 - mDice: 0.3920 - val_loss: 1.1728 - val_acc: 0.9077 - val_mDice: 0.4113

Epoch 00003: val_mDice improved from 0.30340 to 0.41133, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.7660 - acc: 0.8969 - mDice: 0.4471 - val_loss: 1.0435 - val_acc: 0.9226 - val_mDice: 0.4676

Epoch 00004: val_mDice improved from 0.41133 to 0.46762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.6857 - acc: 0.9064 - mDice: 0.4858 - val_loss: 0.9687 - val_acc: 0.9308 - val_mDice: 0.4928

Epoch 00005: val_mDice improved from 0.46762 to 0.49281, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.6254 - acc: 0.9142 - mDice: 0.5168 - val_loss: 0.8921 - val_acc: 0.9254 - val_mDice: 0.5024

Epoch 00006: val_mDice improved from 0.49281 to 0.50238, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.5837 - acc: 0.9188 - mDice: 0.5396 - val_loss: 0.9161 - val_acc: 0.9103 - val_mDice: 0.4872

Epoch 00007: val_mDice did not improve from 0.50238
Epoch 8/300
 - 10s - loss: 0.5549 - acc: 0.9218 - mDice: 0.5564 - val_loss: 0.8649 - val_acc: 0.9300 - val_mDice: 0.5170

Epoch 00008: val_mDice improved from 0.50238 to 0.51698, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.5349 - acc: 0.9237 - mDice: 0.5682 - val_loss: 0.8535 - val_acc: 0.9266 - val_mDice: 0.5201

Epoch 00009: val_mDice improved from 0.51698 to 0.52011, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.5109 - acc: 0.9258 - mDice: 0.5826 - val_loss: 0.8205 - val_acc: 0.9314 - val_mDice: 0.5299

Epoch 00010: val_mDice improved from 0.52011 to 0.52988, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.4941 - acc: 0.9274 - mDice: 0.5927 - val_loss: 0.8301 - val_acc: 0.9301 - val_mDice: 0.5324

Epoch 00011: val_mDice improved from 0.52988 to 0.53237, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 9s - loss: 0.4838 - acc: 0.9284 - mDice: 0.5993 - val_loss: 0.8682 - val_acc: 0.9353 - val_mDice: 0.5282

Epoch 00012: val_mDice did not improve from 0.53237
Epoch 13/300
 - 10s - loss: 0.4726 - acc: 0.9295 - mDice: 0.6064 - val_loss: 0.7998 - val_acc: 0.9365 - val_mDice: 0.5402

Epoch 00013: val_mDice improved from 0.53237 to 0.54016, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 10s - loss: 0.4627 - acc: 0.9306 - mDice: 0.6127 - val_loss: 0.7805 - val_acc: 0.9283 - val_mDice: 0.5357

Epoch 00014: val_mDice did not improve from 0.54016
Epoch 15/300
 - 9s - loss: 0.4518 - acc: 0.9316 - mDice: 0.6197 - val_loss: 0.7669 - val_acc: 0.9304 - val_mDice: 0.5422

Epoch 00015: val_mDice improved from 0.54016 to 0.54221, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 9s - loss: 0.4454 - acc: 0.9322 - mDice: 0.6239 - val_loss: 0.7478 - val_acc: 0.9359 - val_mDice: 0.5497

Epoch 00016: val_mDice improved from 0.54221 to 0.54969, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 9s - loss: 0.4386 - acc: 0.9330 - mDice: 0.6285 - val_loss: 0.7631 - val_acc: 0.9313 - val_mDice: 0.5452

Epoch 00017: val_mDice did not improve from 0.54969
Epoch 18/300
 - 10s - loss: 0.4300 - acc: 0.9336 - mDice: 0.6341 - val_loss: 0.7637 - val_acc: 0.9365 - val_mDice: 0.5420

Epoch 00018: val_mDice did not improve from 0.54969
Epoch 19/300
 - 10s - loss: 0.4270 - acc: 0.9338 - mDice: 0.6362 - val_loss: 0.7430 - val_acc: 0.9354 - val_mDice: 0.5494

Epoch 00019: val_mDice did not improve from 0.54969
Epoch 20/300
 - 10s - loss: 0.4150 - acc: 0.9348 - mDice: 0.6441 - val_loss: 0.7341 - val_acc: 0.9386 - val_mDice: 0.5517

Epoch 00020: val_mDice improved from 0.54969 to 0.55168, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 10s - loss: 0.4117 - acc: 0.9353 - mDice: 0.6464 - val_loss: 0.7255 - val_acc: 0.9343 - val_mDice: 0.5595

Epoch 00021: val_mDice improved from 0.55168 to 0.55948, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 10s - loss: 0.4065 - acc: 0.9358 - mDice: 0.6499 - val_loss: 0.7036 - val_acc: 0.9385 - val_mDice: 0.5615

Epoch 00022: val_mDice improved from 0.55948 to 0.56154, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 10s - loss: 0.4019 - acc: 0.9360 - mDice: 0.6531 - val_loss: 0.7351 - val_acc: 0.9324 - val_mDice: 0.5474

Epoch 00023: val_mDice did not improve from 0.56154
Epoch 24/300
 - 10s - loss: 0.3978 - acc: 0.9364 - mDice: 0.6558 - val_loss: 0.7185 - val_acc: 0.9363 - val_mDice: 0.5585

Epoch 00024: val_mDice did not improve from 0.56154
Epoch 25/300
 - 10s - loss: 0.3925 - acc: 0.9370 - mDice: 0.6595 - val_loss: 0.7375 - val_acc: 0.9354 - val_mDice: 0.5524

Epoch 00025: val_mDice did not improve from 0.56154
Epoch 26/300
 - 10s - loss: 0.3870 - acc: 0.9374 - mDice: 0.6632 - val_loss: 0.7187 - val_acc: 0.9365 - val_mDice: 0.5548

Epoch 00026: val_mDice did not improve from 0.56154
Epoch 27/300
 - 10s - loss: 0.3853 - acc: 0.9375 - mDice: 0.6645 - val_loss: 0.7201 - val_acc: 0.9288 - val_mDice: 0.5427

Epoch 00027: val_mDice did not improve from 0.56154
Epoch 28/300
 - 10s - loss: 0.3815 - acc: 0.9380 - mDice: 0.6671 - val_loss: 0.7335 - val_acc: 0.9376 - val_mDice: 0.5532

Epoch 00028: val_mDice did not improve from 0.56154
Epoch 29/300
 - 10s - loss: 0.3803 - acc: 0.9381 - mDice: 0.6680 - val_loss: 0.6978 - val_acc: 0.9351 - val_mDice: 0.5534

Epoch 00029: val_mDice did not improve from 0.56154
Epoch 30/300
 - 10s - loss: 0.3761 - acc: 0.9386 - mDice: 0.6711 - val_loss: 0.7315 - val_acc: 0.9350 - val_mDice: 0.5475

Epoch 00030: val_mDice did not improve from 0.56154
Epoch 31/300
 - 10s - loss: 0.3741 - acc: 0.9387 - mDice: 0.6724 - val_loss: 0.7053 - val_acc: 0.9326 - val_mDice: 0.5483

Epoch 00031: val_mDice did not improve from 0.56154
Epoch 32/300
 - 10s - loss: 0.3705 - acc: 0.9390 - mDice: 0.6750 - val_loss: 0.7348 - val_acc: 0.9354 - val_mDice: 0.5418

Epoch 00032: val_mDice did not improve from 0.56154
Epoch 33/300
 - 10s - loss: 0.3690 - acc: 0.9391 - mDice: 0.6759 - val_loss: 0.7135 - val_acc: 0.9392 - val_mDice: 0.5541

Epoch 00033: val_mDice did not improve from 0.56154
Epoch 34/300
 - 10s - loss: 0.3658 - acc: 0.9393 - mDice: 0.6784 - val_loss: 0.6824 - val_acc: 0.9368 - val_mDice: 0.5564

Epoch 00034: val_mDice did not improve from 0.56154
Epoch 35/300
 - 9s - loss: 0.3624 - acc: 0.9396 - mDice: 0.6807 - val_loss: 0.7120 - val_acc: 0.9370 - val_mDice: 0.5558

Epoch 00035: val_mDice did not improve from 0.56154
Epoch 36/300
 - 10s - loss: 0.3623 - acc: 0.9396 - mDice: 0.6807 - val_loss: 0.7348 - val_acc: 0.9407 - val_mDice: 0.5465

Epoch 00036: val_mDice did not improve from 0.56154
Epoch 37/300
 - 10s - loss: 0.3595 - acc: 0.9398 - mDice: 0.6827 - val_loss: 0.6852 - val_acc: 0.9351 - val_mDice: 0.5527

Epoch 00037: val_mDice did not improve from 0.56154
Epoch 38/300
 - 10s - loss: 0.3559 - acc: 0.9402 - mDice: 0.6854 - val_loss: 0.6925 - val_acc: 0.9359 - val_mDice: 0.5569

Epoch 00038: val_mDice did not improve from 0.56154
Epoch 39/300
 - 10s - loss: 0.3534 - acc: 0.9403 - mDice: 0.6872 - val_loss: 0.6947 - val_acc: 0.9392 - val_mDice: 0.5584

Epoch 00039: val_mDice did not improve from 0.56154
Epoch 40/300
 - 10s - loss: 0.3535 - acc: 0.9403 - mDice: 0.6870 - val_loss: 0.6964 - val_acc: 0.9362 - val_mDice: 0.5479

Epoch 00040: val_mDice did not improve from 0.56154
Epoch 41/300
 - 10s - loss: 0.3488 - acc: 0.9406 - mDice: 0.6904 - val_loss: 0.6783 - val_acc: 0.9378 - val_mDice: 0.5506

Epoch 00041: val_mDice did not improve from 0.56154
Epoch 42/300
 - 10s - loss: 0.3512 - acc: 0.9403 - mDice: 0.6886 - val_loss: 0.6672 - val_acc: 0.9387 - val_mDice: 0.5565

Epoch 00042: val_mDice did not improve from 0.56154
Epoch 43/300
 - 10s - loss: 0.3448 - acc: 0.9409 - mDice: 0.6932 - val_loss: 0.6183 - val_acc: 0.9377 - val_mDice: 0.5677

Epoch 00043: val_mDice improved from 0.56154 to 0.56769, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 10s - loss: 0.3438 - acc: 0.9409 - mDice: 0.6940 - val_loss: 0.6707 - val_acc: 0.9392 - val_mDice: 0.5562

Epoch 00044: val_mDice did not improve from 0.56769
Epoch 45/300
 - 9s - loss: 0.3435 - acc: 0.9411 - mDice: 0.6942 - val_loss: 0.6296 - val_acc: 0.9338 - val_mDice: 0.5547

Epoch 00045: val_mDice did not improve from 0.56769
Epoch 46/300
 - 10s - loss: 0.3408 - acc: 0.9411 - mDice: 0.6962 - val_loss: 0.6447 - val_acc: 0.9371 - val_mDice: 0.5611

Epoch 00046: val_mDice did not improve from 0.56769
Epoch 47/300
 - 10s - loss: 0.3397 - acc: 0.9412 - mDice: 0.6970 - val_loss: 0.6639 - val_acc: 0.9359 - val_mDice: 0.5575

Epoch 00047: val_mDice did not improve from 0.56769
Epoch 48/300
 - 10s - loss: 0.3368 - acc: 0.9415 - mDice: 0.6990 - val_loss: 0.6378 - val_acc: 0.9383 - val_mDice: 0.5595

Epoch 00048: val_mDice did not improve from 0.56769
Epoch 49/300
 - 10s - loss: 0.3379 - acc: 0.9415 - mDice: 0.6982 - val_loss: 0.7004 - val_acc: 0.9415 - val_mDice: 0.5473

Epoch 00049: val_mDice did not improve from 0.56769
Epoch 50/300
 - 10s - loss: 0.3389 - acc: 0.9414 - mDice: 0.6984 - val_loss: 0.9343 - val_acc: 0.9293 - val_mDice: 0.4247

Epoch 00050: val_mDice did not improve from 0.56769
Epoch 51/300
 - 9s - loss: 0.6241 - acc: 0.9151 - mDice: 0.5263 - val_loss: 0.9395 - val_acc: 0.9219 - val_mDice: 0.4668

Epoch 00051: val_mDice did not improve from 0.56769
Epoch 52/300
 - 10s - loss: 0.4500 - acc: 0.9319 - mDice: 0.6219 - val_loss: 0.7628 - val_acc: 0.9318 - val_mDice: 0.5282

Epoch 00052: val_mDice did not improve from 0.56769
Epoch 53/300
 - 10s - loss: 0.4083 - acc: 0.9354 - mDice: 0.6491 - val_loss: 0.7668 - val_acc: 0.9312 - val_mDice: 0.5218

Epoch 00053: val_mDice did not improve from 0.56769
Epoch 54/300
 - 9s - loss: 0.3850 - acc: 0.9374 - mDice: 0.6650 - val_loss: 0.7220 - val_acc: 0.9326 - val_mDice: 0.5375

Epoch 00054: val_mDice did not improve from 0.56769
Epoch 55/300
 - 9s - loss: 0.3715 - acc: 0.9386 - mDice: 0.6742 - val_loss: 0.6630 - val_acc: 0.9298 - val_mDice: 0.5434

Epoch 00055: val_mDice did not improve from 0.56769
Epoch 56/300
 - 10s - loss: 0.3614 - acc: 0.9394 - mDice: 0.6814 - val_loss: 0.6435 - val_acc: 0.9339 - val_mDice: 0.5520

Epoch 00056: val_mDice did not improve from 0.56769
Epoch 57/300
 - 10s - loss: 0.3560 - acc: 0.9400 - mDice: 0.6853 - val_loss: 0.6541 - val_acc: 0.9316 - val_mDice: 0.5457

Epoch 00057: val_mDice did not improve from 0.56769
Epoch 58/300
 - 9s - loss: 0.3500 - acc: 0.9405 - mDice: 0.6895 - val_loss: 0.6432 - val_acc: 0.9328 - val_mDice: 0.5515

Epoch 00058: val_mDice did not improve from 0.56769
Epoch 59/300
 - 9s - loss: 0.3459 - acc: 0.9409 - mDice: 0.6926 - val_loss: 0.6297 - val_acc: 0.9373 - val_mDice: 0.5589

Epoch 00059: val_mDice did not improve from 0.56769
Epoch 60/300
 - 10s - loss: 0.3432 - acc: 0.9411 - mDice: 0.6944 - val_loss: 0.6334 - val_acc: 0.9368 - val_mDice: 0.5562

Epoch 00060: val_mDice did not improve from 0.56769
Epoch 61/300
 - 10s - loss: 0.3394 - acc: 0.9416 - mDice: 0.6974 - val_loss: 0.6151 - val_acc: 0.9368 - val_mDice: 0.5649

Epoch 00061: val_mDice did not improve from 0.56769
Epoch 62/300
 - 10s - loss: 0.3355 - acc: 0.9418 - mDice: 0.7000 - val_loss: 0.6344 - val_acc: 0.9345 - val_mDice: 0.5519

Epoch 00062: val_mDice did not improve from 0.56769
Epoch 63/300
 - 10s - loss: 0.3331 - acc: 0.9419 - mDice: 0.7017 - val_loss: 0.6374 - val_acc: 0.9330 - val_mDice: 0.5523

Epoch 00063: val_mDice did not improve from 0.56769
Epoch 64/300
 - 10s - loss: 0.3314 - acc: 0.9421 - mDice: 0.7031 - val_loss: 0.6160 - val_acc: 0.9377 - val_mDice: 0.5557

Epoch 00064: val_mDice did not improve from 0.56769
Epoch 65/300
 - 10s - loss: 0.3309 - acc: 0.9421 - mDice: 0.7034 - val_loss: 0.6242 - val_acc: 0.9387 - val_mDice: 0.5609

Epoch 00065: val_mDice did not improve from 0.56769
Epoch 66/300
 - 10s - loss: 0.3282 - acc: 0.9423 - mDice: 0.7054 - val_loss: 0.5920 - val_acc: 0.9360 - val_mDice: 0.5628

Epoch 00066: val_mDice did not improve from 0.56769
Epoch 67/300
 - 10s - loss: 0.3258 - acc: 0.9425 - mDice: 0.7071 - val_loss: 0.5602 - val_acc: 0.9377 - val_mDice: 0.5666

Epoch 00067: val_mDice did not improve from 0.56769
Epoch 68/300
 - 10s - loss: 0.3250 - acc: 0.9426 - mDice: 0.7078 - val_loss: 0.6173 - val_acc: 0.9379 - val_mDice: 0.5565

Epoch 00068: val_mDice did not improve from 0.56769
Epoch 69/300
 - 11s - loss: 0.3241 - acc: 0.9427 - mDice: 0.7085 - val_loss: 0.6457 - val_acc: 0.9357 - val_mDice: 0.5586

Epoch 00069: val_mDice did not improve from 0.56769
Epoch 70/300
 - 10s - loss: 0.3241 - acc: 0.9427 - mDice: 0.7084 - val_loss: 0.6265 - val_acc: 0.9357 - val_mDice: 0.5574

Epoch 00070: val_mDice did not improve from 0.56769
Epoch 71/300
 - 11s - loss: 0.3219 - acc: 0.9428 - mDice: 0.7101 - val_loss: 0.6241 - val_acc: 0.9331 - val_mDice: 0.5553

Epoch 00071: val_mDice did not improve from 0.56769
Epoch 72/300
 - 10s - loss: 0.3211 - acc: 0.9430 - mDice: 0.7107 - val_loss: 0.5842 - val_acc: 0.9358 - val_mDice: 0.5524

Epoch 00072: val_mDice did not improve from 0.56769
Epoch 73/300
 - 11s - loss: 0.3210 - acc: 0.9429 - mDice: 0.7108 - val_loss: 0.6025 - val_acc: 0.9356 - val_mDice: 0.5631

Epoch 00073: val_mDice did not improve from 0.56769
Epoch 74/300
 - 10s - loss: 0.3211 - acc: 0.9430 - mDice: 0.7108 - val_loss: 0.5800 - val_acc: 0.9346 - val_mDice: 0.5559

Epoch 00074: val_mDice did not improve from 0.56769
Epoch 75/300
 - 10s - loss: 0.3179 - acc: 0.9431 - mDice: 0.7130 - val_loss: 0.6303 - val_acc: 0.9384 - val_mDice: 0.5556

Epoch 00075: val_mDice did not improve from 0.56769
Epoch 76/300
 - 11s - loss: 0.3184 - acc: 0.9432 - mDice: 0.7129 - val_loss: 0.6410 - val_acc: 0.9389 - val_mDice: 0.5485

Epoch 00076: val_mDice did not improve from 0.56769
Epoch 77/300
 - 10s - loss: 0.3416 - acc: 0.9413 - mDice: 0.6958 - val_loss: 0.6157 - val_acc: 0.9353 - val_mDice: 0.5572

Epoch 00077: val_mDice did not improve from 0.56769
Epoch 78/300
 - 11s - loss: 0.3184 - acc: 0.9432 - mDice: 0.7126 - val_loss: 0.5931 - val_acc: 0.9346 - val_mDice: 0.5587

Epoch 00078: val_mDice did not improve from 0.56769
Epoch 79/300
 - 10s - loss: 0.3160 - acc: 0.9433 - mDice: 0.7144 - val_loss: 0.6131 - val_acc: 0.9384 - val_mDice: 0.5630

Epoch 00079: val_mDice did not improve from 0.56769
Epoch 80/300
 - 11s - loss: 0.3142 - acc: 0.9435 - mDice: 0.7157 - val_loss: 0.5783 - val_acc: 0.9334 - val_mDice: 0.5578

Epoch 00080: val_mDice did not improve from 0.56769
Epoch 81/300
 - 11s - loss: 0.3123 - acc: 0.9436 - mDice: 0.7172 - val_loss: 0.6405 - val_acc: 0.9393 - val_mDice: 0.5496

Epoch 00081: val_mDice did not improve from 0.56769
Epoch 82/300
 - 10s - loss: 0.3130 - acc: 0.9436 - mDice: 0.7167 - val_loss: 0.5757 - val_acc: 0.9381 - val_mDice: 0.5567

Epoch 00082: val_mDice did not improve from 0.56769
Epoch 83/300
 - 11s - loss: 0.3124 - acc: 0.9436 - mDice: 0.7171 - val_loss: 0.5683 - val_acc: 0.9384 - val_mDice: 0.5655

Epoch 00083: val_mDice did not improve from 0.56769
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [1.8378911706117482, 1.5022852237407978, 1.172833121739901, 1.043529008443539, 0.9686503479113946, 0.8920873999595642, 0.9161145549554092, 0.8648884433966416, 0.853543045429083, 0.8204511747910426, 0.8300940486101004, 0.8682324450749618, 0.7997973767610697, 0.780496345116542, 0.7669162245897146, 0.747787594795227, 0.7630562277940603, 0.7637033852247092, 0.7430138542101934, 0.7341360679039588, 0.7255073006336505, 0.7035658795099992, 0.7350707856508402, 0.7185394259599539, 0.7374549829042875, 0.7187212476363549, 0.7201451498728532, 0.7334889356906598, 0.697772388274853, 0.7314554429971255, 0.7053060508691348, 0.7348485405628498, 0.7135260449006007, 0.6823630585120275, 0.7119605724628155, 0.7348268834444193, 0.6852283752881564, 0.6924945070193365, 0.6946622041555551, 0.6964071393013, 0.6782553654450637, 0.667157572049361, 0.618309750006749, 0.6707218839572027, 0.6296354761490455, 0.6446638382398165, 0.6639386415481567, 0.6378216972717872, 0.7004450399142045, 0.9343194663524628, 0.9394979133055761, 0.7627562628342555, 0.7667899429798126, 0.7220166142170246, 0.6630356770295364, 0.643519823367779, 0.6541269146479093, 0.6432063625409052, 0.6297335945642911, 0.6334437338205484, 0.615053646839582, 0.6343937241114103, 0.6374359199633965, 0.6159604512728177, 0.6241578551439139, 0.5919689169296851, 0.5601898936124948, 0.6173387811734126, 0.6456831097602844, 0.6265378502699045, 0.6240905523300171, 0.5841765678845919, 0.6025371597363398, 0.580039551624885, 0.6303177728102758, 0.6410146951675415, 0.6157240982239063, 0.5930580221689664, 0.613116381260065, 0.5783158219777621, 0.6404645305413467, 0.5756876629132491, 0.5682505529660445], 'val_acc': [0.9019808517052577, 0.892076545036756, 0.9076923040243295, 0.9226123117483579, 0.9307577013969421, 0.9253582862707285, 0.9103319255205301, 0.9300272877399738, 0.9266272370631878, 0.9314488012057084, 0.9301312634578118, 0.9353434443473816, 0.9364852974048028, 0.9283492060808035, 0.9303693610888261, 0.935914376607308, 0.9312985493586614, 0.9364922436384054, 0.9353897135991317, 0.9385979358966534, 0.9342663586139679, 0.9385447685535138, 0.9324103043629572, 0.9362911513218513, 0.9353966093980349, 0.9364622006049523, 0.9287698750312512, 0.9375531879755167, 0.9350776488964374, 0.935045295036756, 0.932581344476113, 0.935382774242988, 0.9392497493670537, 0.9368111835076258, 0.9369961092105279, 0.9407220895473773, 0.9351331431132096, 0.9358820227476267, 0.9391572773456573, 0.9361501198548537, 0.9378444048074576, 0.938734254011741, 0.9376710401131556, 0.9392451024972476, 0.9337948583639585, 0.9370839710418994, 0.93592592386099, 0.9382534967019007, 0.9414940797365628, 0.9292714458245498, 0.9219443270793328, 0.9318047349269574, 0.9312291764296018, 0.9325559116326846, 0.9298331210246453, 0.9339057826078855, 0.9316013157367706, 0.9328448359782879, 0.9373150926369888, 0.936778859450267, 0.9368481888220861, 0.9344905591928042, 0.933034394796078, 0.9377033779254327, 0.9386533682162945, 0.9360184210997361, 0.9377057093840379, 0.9378906373794262, 0.9357271859279046, 0.9357202121844659, 0.9330736903043894, 0.9357618368588961, 0.9356092535532438, 0.9345992184602298, 0.9383505651584039, 0.9389169055681962, 0.9353064917601072, 0.9346015155315399, 0.9383829281880305, 0.9333926439285278, 0.9393144662563617, 0.938080187027271, 0.9384430669821225], 'val_mDice': [0.22057011838142687, 0.30340158079679197, 0.4113276984829169, 0.4676199360535695, 0.4928116133579841, 0.5023791549297479, 0.4871959755053887, 0.516978897440892, 0.5201129695543876, 0.5298795172801385, 0.5323658407880709, 0.5282407468901231, 0.5401595699099394, 0.5357216235536796, 0.5422116735806832, 0.5496866021018761, 0.5451648120696728, 0.5419526684742707, 0.5493932463801824, 0.551678366959095, 0.5594849357238183, 0.5615387003009136, 0.5474105912905473, 0.5584510633578668, 0.5523665960018451, 0.5547939493105962, 0.5426790748651211, 0.5532387598202779, 0.5534163254957932, 0.5474936188413546, 0.5482923362690669, 0.5418397938975921, 0.5541444558363694, 0.5563524915621831, 0.5557677387618102, 0.5464896041040237, 0.5526836514472961, 0.5569360869435164, 0.5583773582027509, 0.5478543753807361, 0.5506344655385385, 0.5565083264731444, 0.5676911731178944, 0.5562011608137534, 0.5546785295009613, 0.5611045681513273, 0.5575273036956787, 0.5594780594110489, 0.5473188276474292, 0.4247286119140111, 0.46684996067331386, 0.5282021322502539, 0.5218009094779308, 0.5374562508211687, 0.5433662608265877, 0.5520089727181655, 0.5457011140309848, 0.5515019996808126, 0.5588784733643899, 0.5561999414975827, 0.5648982719733164, 0.5519154306787711, 0.552338033914566, 0.5557329712005762, 0.5609178766608238, 0.5627606029693897, 0.5665850736773931, 0.5565363478202087, 0.5585638691599553, 0.5574196439522964, 0.5553485688108665, 0.552428948191496, 0.5631247323292953, 0.5559157889622909, 0.5555869661844693, 0.5484863359194535, 0.5571527618628281, 0.5587087892569028, 0.5629939001340133, 0.5578098858778293, 0.5496353965539199, 0.5567092437010545, 0.5654829499813226], 'loss': [2.952221476722773, 1.2354090008625276, 0.8964196914051288, 0.7660198614109841, 0.6856714027906206, 0.6254402535335281, 0.5836596977311637, 0.5549179322823139, 0.5349168419167311, 0.5108552556778687, 0.49411670134030816, 0.48381731500377584, 0.4726108547001541, 0.4627418230460115, 0.4518022303029113, 0.445405752786046, 0.43858640779981006, 0.42995440702393056, 0.42704455330892316, 0.4149564451741675, 0.41171353692873414, 0.4064569789567557, 0.4018926779540891, 0.3977902176321229, 0.3925244187743618, 0.3870454174197161, 0.3853116997804609, 0.38150590595246503, 0.3803377518720494, 0.37605711757548566, 0.37408420215681626, 0.3704534582790277, 0.36901719085813767, 0.3657732688032766, 0.3623710966831444, 0.36230866378890425, 0.35954734095126006, 0.3558659151637619, 0.3533825582132275, 0.3534699052553011, 0.34882179171157524, 0.3512446020242749, 0.34475893417121983, 0.3438216622004614, 0.34348656798512867, 0.3407589395575271, 0.3396513093323722, 0.33675727029133906, 0.3379024710919511, 0.3388677991471101, 0.6240766855290177, 0.4500320035626525, 0.4082504418693785, 0.3849950975419894, 0.3715113266707456, 0.3613886397191434, 0.3560168419548982, 0.3499865754167609, 0.3459291215324648, 0.34324998081824354, 0.3394189246420072, 0.3355452991615942, 0.33313200207837534, 0.3313824769195723, 0.33088600265576285, 0.3281884131770858, 0.3257955159388333, 0.3249509690196644, 0.324051397827777, 0.3241298927747817, 0.32188922226742317, 0.32110983031895246, 0.32097352925321443, 0.3210514793231744, 0.3179095012861502, 0.3184063789106367, 0.3415880424586277, 0.31844998856680556, 0.315985990543048, 0.3142179209214344, 0.3123020690261224, 0.3129799427619381, 0.31237126418632366], 'acc': [0.6457078613517447, 0.8802219083484419, 0.8889327070364089, 0.8968544910394496, 0.9063581639381503, 0.9141613233191692, 0.918797442105647, 0.9217624226410671, 0.9236912208708145, 0.9257980841316333, 0.9274212096402162, 0.9284200566749252, 0.9294862113326148, 0.9305761787357734, 0.9316071513932008, 0.9322174808245287, 0.9329566574400118, 0.9335780263463807, 0.9338306471792015, 0.934804625251928, 0.935305236571721, 0.9357839394822878, 0.9360254835205127, 0.9364432218845926, 0.9369551810041451, 0.9373869366622946, 0.9375263373592095, 0.9379703929467603, 0.9380695563746612, 0.9386062635263261, 0.9386762286985008, 0.9390027649253319, 0.9390532230578873, 0.9393248214038284, 0.9396067951577161, 0.9395812793014608, 0.9397946849835047, 0.9401507954541183, 0.9402716366949858, 0.9402661419251215, 0.940647857309894, 0.9402910388066827, 0.9408593099242393, 0.9409093907549407, 0.9410563319698863, 0.9411129532436003, 0.941222628961792, 0.9415084776277638, 0.9414500192248886, 0.9413826915431285, 0.9151385549765434, 0.9318731420651184, 0.9354122691595125, 0.9373871367718476, 0.93863255525992, 0.939382309388336, 0.9400153562645075, 0.9404738035840126, 0.9409469452487426, 0.9411379854683285, 0.9415779567332129, 0.9417830256257871, 0.9418560084816847, 0.9420758850359229, 0.9421005156782735, 0.9423411002207932, 0.9425355486024144, 0.9426094200034363, 0.9427371819136076, 0.9427126393286953, 0.9428152407456905, 0.9430133951311676, 0.9428707552574046, 0.9429592558304828, 0.9430909625808658, 0.9431992837624786, 0.9413270240426778, 0.9431736155606433, 0.9432863695181946, 0.943453836510303, 0.943622148197471, 0.9436018635599329, 0.9436125277285535], 'mDice': [0.08024666483860927, 0.2843963275764477, 0.3920133184993068, 0.4471012382729186, 0.4857691136451376, 0.5167779327538317, 0.5396231955667489, 0.5563940641834519, 0.5681767891850252, 0.5825920142030667, 0.5927278569271718, 0.5992821828966969, 0.6063851740685027, 0.6127454387870077, 0.619650895312122, 0.6238725603500833, 0.6285150693833449, 0.6340996349285551, 0.6362122473412858, 0.6440848473153364, 0.6463606574103741, 0.6499471995846587, 0.6531081695810825, 0.655791369210549, 0.6595285801081423, 0.6631686976010274, 0.6644731303658926, 0.6671248782025176, 0.6680376961762687, 0.6711169315870866, 0.6724207230536885, 0.6750387114307861, 0.6759188853319001, 0.6783506541985225, 0.6806734395919883, 0.6807374448493916, 0.6826610654237953, 0.6853733582986101, 0.687186036857085, 0.6870464612601439, 0.6903768054653795, 0.6885757814152461, 0.693206777907293, 0.6940162988493146, 0.6942413618926753, 0.6961671776638736, 0.6969709943265017, 0.6989864686708944, 0.6981887349967619, 0.6984378576146757, 0.5262759987316064, 0.621870523128828, 0.6490783880725071, 0.6650326549429675, 0.6742428733580647, 0.6814011443720019, 0.68530354770932, 0.6895270001830006, 0.692613549028212, 0.6943774663092608, 0.6973545091525771, 0.6999894160906855, 0.7017297179048312, 0.7030521072739332, 0.7033591245215262, 0.7053663378479538, 0.7071120634538973, 0.7077846140106435, 0.7084716268211539, 0.708373010262983, 0.7100649681696425, 0.7107458428891066, 0.7108342940051167, 0.7108159912343858, 0.7129656816995485, 0.7128776858832072, 0.6958306879341124, 0.7126317217782515, 0.7143810211067477, 0.7157005090330026, 0.7171808570433749, 0.7166846327144898, 0.7171097765392805]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.20s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:55,  2.10s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:58,  1.90s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:57,  1.90s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:19,  1.78s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:37,  1.85s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:07,  1.75s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:25,  1.82s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:21,  1.81s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:54,  1.93s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:53,  1.94s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:28,  1.86s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:12,  1.81s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:28,  1.88s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:51,  1.97s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:08,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:34,  1.92s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:38,  1.94s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:09,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:33,  1.94s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:41,  1.98s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<07:59,  1.82s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<07:47,  1.78s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:19,  1.68s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<07:27,  1.72s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<07:35,  1.76s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:18,  1.70s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:21,  1.72s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:30,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:54<07:42,  1.81s/it]predicting train subjects:  11%|█         | 31/285 [00:56<07:44,  1.83s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:23,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:10,  1.71s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:03,  1.70s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:07,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:27,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:04,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:01,  1.72s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<06:50,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<06:43,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<06:52,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:01,  1.75s/it]predicting train subjects:  16%|█▌        | 45/285 [01:20<06:47,  1.70s/it]predicting train subjects:  16%|█▌        | 46/285 [01:22<06:58,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:24<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:52,  1.74s/it]predicting train subjects:  17%|█▋        | 49/285 [01:27<07:08,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:29<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<07:06,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:33<06:44,  1.74s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:41,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<06:46,  1.76s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<06:32,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:37,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:20,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:43<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:45<06:39,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:47<06:47,  1.81s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:30,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:29,  1.75s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:27,  1.75s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:15,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:18,  1.72s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:16,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:15,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<05:56,  1.64s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:00,  1.67s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:03,  1.69s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<05:58,  1.67s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<05:40,  1.60s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<05:49,  1.65s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<05:49,  1.66s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<05:54,  1.69s/it]predicting train subjects:  27%|██▋       | 76/285 [02:13<05:52,  1.68s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<05:40,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:16<05:30,  1.60s/it]predicting train subjects:  28%|██▊       | 79/285 [02:18<05:35,  1.63s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:34,  1.63s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:26,  1.60s/it]predicting train subjects:  29%|██▉       | 82/285 [02:23<05:23,  1.60s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:20,  1.58s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:14,  1.57s/it]predicting train subjects:  30%|██▉       | 85/285 [02:28<05:21,  1.61s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:27,  1.65s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:27,  1.66s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:20,  1.63s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:26,  1.68s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:16,  1.63s/it]predicting train subjects:  32%|███▏      | 92/285 [02:39<05:23,  1.68s/it]predicting train subjects:  33%|███▎      | 93/285 [02:41<05:17,  1.65s/it]predicting train subjects:  33%|███▎      | 94/285 [02:43<05:20,  1.68s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:23,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [02:46<05:25,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:48<05:27,  1.74s/it]predicting train subjects:  34%|███▍      | 98/285 [02:50<05:25,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:52<05:24,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:53<05:24,  1.75s/it]predicting train subjects:  35%|███▌      | 101/285 [02:55<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:57<05:12,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<05:01,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [03:00<05:09,  1.71s/it]predicting train subjects:  37%|███▋      | 105/285 [03:02<05:10,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:03<04:59,  1.67s/it]predicting train subjects:  38%|███▊      | 107/285 [03:05<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 108/285 [03:07<04:54,  1.67s/it]predicting train subjects:  38%|███▊      | 109/285 [03:08<04:58,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:10<05:00,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:12<04:53,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<04:55,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:15<04:57,  1.73s/it]predicting train subjects:  40%|████      | 114/285 [03:17<04:52,  1.71s/it]predicting train subjects:  40%|████      | 115/285 [03:19<04:55,  1.74s/it]predicting train subjects:  41%|████      | 116/285 [03:20<04:46,  1.70s/it]predicting train subjects:  41%|████      | 117/285 [03:22<04:35,  1.64s/it]predicting train subjects:  41%|████▏     | 118/285 [03:23<04:30,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:25<04:34,  1.65s/it]predicting train subjects:  42%|████▏     | 120/285 [03:27<04:24,  1.60s/it]predicting train subjects:  42%|████▏     | 121/285 [03:28<04:19,  1.58s/it]predicting train subjects:  43%|████▎     | 122/285 [03:30<04:08,  1.53s/it]predicting train subjects:  43%|████▎     | 123/285 [03:31<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:33<04:00,  1.49s/it]predicting train subjects:  44%|████▍     | 125/285 [03:34<03:59,  1.50s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:54,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:37<03:46,  1.43s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<03:50,  1.47s/it]predicting train subjects:  45%|████▌     | 129/285 [03:40<03:48,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<03:41,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:43<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:46<03:44,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<03:43,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:49<03:36,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:50<03:30,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:35,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [03:53<03:29,  1.43s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:32,  1.46s/it]predicting train subjects:  49%|████▉     | 140/285 [03:56<03:35,  1.49s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:59<03:29,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [04:00<03:23,  1.43s/it]predicting train subjects:  51%|█████     | 144/285 [04:02<03:26,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:03<03:23,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:05<03:25,  1.48s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:06<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:07<03:20,  1.46s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:09<03:14,  1.43s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:10<03:13,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:12<03:12,  1.44s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:13<03:10,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:15<03:07,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:16<03:10,  1.45s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:06,  1.44s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:19<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:07,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:22<03:07,  1.48s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:23<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<02:58,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:26<02:59,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:29<02:57,  1.46s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:31<02:58,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:32<02:55,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:37<02:57,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:54,  1.50s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:40<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:42<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:35,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:37,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:48<02:39,  1.46s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:49<02:34,  1.43s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:28,  1.39s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:52<02:28,  1.40s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:54<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:55<02:36,  1.51s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:57<02:37,  1.53s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:58<02:29,  1.46s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:01<02:21,  1.42s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:03<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:05<02:34,  1.58s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:06<02:40,  1.65s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:08<02:30,  1.57s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:09<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:11<02:22,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:12<02:25,  1.56s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:14<02:15,  1.48s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:15<02:12,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:16<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:18<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:20<02:20,  1.60s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:22<02:23,  1.65s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:23<02:14,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:24<02:09,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:26<02:11,  1.57s/it]predicting train subjects:  71%|███████   | 202/285 [05:28<02:11,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:29<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:31<02:02,  1.51s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:32<01:57,  1.47s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:33<01:54,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:35<02:00,  1.54s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:37<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:39<02:04,  1.63s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:40<01:55,  1.55s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:41<01:51,  1.50s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:43<01:51,  1.53s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:45<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:46<01:44,  1.48s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:48<01:49,  1.56s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:49<01:41,  1.47s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:51<01:43,  1.53s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:52<01:46,  1.59s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:54<01:47,  1.62s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:55<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:57<01:35,  1.49s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:58<01:35,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:00<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:01<01:27,  1.43s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:02<01:23,  1.39s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:04<01:28,  1.50s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:06<01:30,  1.56s/it]predicting train subjects:  80%|████████  | 228/285 [06:07<01:31,  1.61s/it]predicting train subjects:  80%|████████  | 229/285 [06:09<01:29,  1.60s/it]predicting train subjects:  81%|████████  | 230/285 [06:10<01:23,  1.51s/it]predicting train subjects:  81%|████████  | 231/285 [06:12<01:18,  1.46s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:13<01:19,  1.50s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:15<01:14,  1.43s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:16<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:18<01:14,  1.49s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:20<01:18,  1.59s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:21<01:18,  1.64s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:23<01:18,  1.67s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:25<01:16,  1.67s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:26<01:10,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:27<01:06,  1.52s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:29<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:30<01:00,  1.43s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:32<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:33<00:57,  1.44s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:35<00:59,  1.52s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:37<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:38<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:40<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:41<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:42<00:49,  1.45s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:44<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:46<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:47<00:49,  1.59s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:49<00:47,  1.59s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:50<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [06:51<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [06:53<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [06:55<00:40,  1.56s/it]predicting train subjects:  91%|█████████ | 260/285 [06:56<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:58<00:35,  1.47s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:59<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:00<00:30,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:02<00:32,  1.53s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:04<00:32,  1.62s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:05<00:29,  1.54s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:07<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:08<00:26,  1.57s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:10<00:25,  1.58s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:11<00:22,  1.50s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:13<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:15<00:20,  1.56s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:16<00:17,  1.49s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:17<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:19<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:21<00:14,  1.58s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:22<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:23<00:10,  1.45s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:25<00:08,  1.47s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:26<00:07,  1.45s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:27<00:05,  1.42s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:29<00:04,  1.39s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:31<00:02,  1.49s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:32<00:01,  1.58s/it]predicting train subjects: 100%|██████████| 285/285 [07:34<00:00,  1.62s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:55,  1.67s/it]Loading train:   1%|          | 2/285 [00:02<07:11,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<06:56,  1.48s/it]Loading train:   1%|▏         | 4/285 [00:05<06:19,  1.35s/it]Loading train:   2%|▏         | 5/285 [00:06<06:27,  1.38s/it]Loading train:   2%|▏         | 6/285 [00:07<06:14,  1.34s/it]Loading train:   2%|▏         | 7/285 [00:09<06:24,  1.38s/it]Loading train:   3%|▎         | 8/285 [00:10<06:17,  1.36s/it]Loading train:   3%|▎         | 9/285 [00:12<06:38,  1.44s/it]Loading train:   4%|▎         | 10/285 [00:13<05:59,  1.31s/it]Loading train:   4%|▍         | 11/285 [00:14<05:19,  1.16s/it]Loading train:   4%|▍         | 12/285 [00:15<04:54,  1.08s/it]Loading train:   5%|▍         | 13/285 [00:15<04:21,  1.04it/s]Loading train:   5%|▍         | 14/285 [00:16<04:19,  1.05it/s]Loading train:   5%|▌         | 15/285 [00:17<04:11,  1.07it/s]Loading train:   6%|▌         | 16/285 [00:18<04:22,  1.02it/s]Loading train:   6%|▌         | 17/285 [00:19<04:04,  1.10it/s]Loading train:   6%|▋         | 18/285 [00:20<04:09,  1.07it/s]Loading train:   7%|▋         | 19/285 [00:21<03:58,  1.11it/s]Loading train:   7%|▋         | 20/285 [00:22<03:58,  1.11it/s]Loading train:   7%|▋         | 21/285 [00:23<03:59,  1.10it/s]Loading train:   8%|▊         | 22/285 [00:23<03:50,  1.14it/s]Loading train:   8%|▊         | 23/285 [00:24<03:53,  1.12it/s]Loading train:   8%|▊         | 24/285 [00:25<03:50,  1.13it/s]Loading train:   9%|▉         | 25/285 [00:26<04:04,  1.07it/s]Loading train:   9%|▉         | 26/285 [00:27<03:54,  1.10it/s]Loading train:   9%|▉         | 27/285 [00:28<03:39,  1.18it/s]Loading train:  10%|▉         | 28/285 [00:29<03:43,  1.15it/s]Loading train:  10%|█         | 29/285 [00:30<03:36,  1.18it/s]Loading train:  11%|█         | 30/285 [00:30<03:44,  1.13it/s]Loading train:  11%|█         | 31/285 [00:31<03:46,  1.12it/s]Loading train:  11%|█         | 32/285 [00:32<03:34,  1.18it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:37,  1.16it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:43,  1.12it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:46,  1.10it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:32,  1.17it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:35,  1.15it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:32,  1.16it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:27,  1.19it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:28,  1.18it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:22,  1.20it/s]Loading train:  15%|█▍        | 42/285 [00:41<03:12,  1.26it/s]Loading train:  15%|█▌        | 43/285 [00:42<03:26,  1.17it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:31,  1.14it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:17,  1.21it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:21,  1.18it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:27,  1.14it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:26,  1.15it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:35,  1.09it/s]Loading train:  18%|█▊        | 50/285 [00:48<03:31,  1.11it/s]Loading train:  18%|█▊        | 51/285 [00:49<03:57,  1.02s/it]Loading train:  18%|█▊        | 52/285 [00:50<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:51<03:51,  1.00it/s]Loading train:  19%|█▉        | 54/285 [00:52<03:53,  1.01s/it]Loading train:  19%|█▉        | 55/285 [00:53<03:33,  1.08it/s]Loading train:  20%|█▉        | 56/285 [00:54<03:32,  1.08it/s]Loading train:  20%|██        | 57/285 [00:55<03:32,  1.07it/s]Loading train:  20%|██        | 58/285 [00:56<03:38,  1.04it/s]Loading train:  21%|██        | 59/285 [00:57<03:52,  1.03s/it]Loading train:  21%|██        | 60/285 [00:58<03:46,  1.01s/it]Loading train:  21%|██▏       | 61/285 [00:59<03:44,  1.00s/it]Loading train:  22%|██▏       | 62/285 [01:00<03:40,  1.01it/s]Loading train:  22%|██▏       | 63/285 [01:01<03:35,  1.03it/s]Loading train:  22%|██▏       | 64/285 [01:02<03:54,  1.06s/it]Loading train:  23%|██▎       | 65/285 [01:04<04:31,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:05<04:40,  1.28s/it]Loading train:  24%|██▎       | 67/285 [01:06<04:26,  1.22s/it]Loading train:  24%|██▍       | 68/285 [01:07<04:16,  1.18s/it]Loading train:  24%|██▍       | 69/285 [01:08<03:53,  1.08s/it]Loading train:  25%|██▍       | 70/285 [01:09<03:54,  1.09s/it]Loading train:  25%|██▍       | 71/285 [01:10<03:48,  1.07s/it]Loading train:  25%|██▌       | 72/285 [01:11<03:37,  1.02s/it]Loading train:  26%|██▌       | 73/285 [01:12<03:26,  1.02it/s]Loading train:  26%|██▌       | 74/285 [01:13<03:23,  1.04it/s]Loading train:  26%|██▋       | 75/285 [01:14<03:30,  1.00s/it]Loading train:  27%|██▋       | 76/285 [01:15<03:26,  1.01it/s]Loading train:  27%|██▋       | 77/285 [01:16<03:19,  1.04it/s]Loading train:  27%|██▋       | 78/285 [01:17<03:17,  1.05it/s]Loading train:  28%|██▊       | 79/285 [01:18<03:17,  1.04it/s]Loading train:  28%|██▊       | 80/285 [01:19<03:18,  1.03it/s]Loading train:  28%|██▊       | 81/285 [01:20<03:16,  1.04it/s]Loading train:  29%|██▉       | 82/285 [01:20<03:07,  1.08it/s]Loading train:  29%|██▉       | 83/285 [01:21<03:04,  1.09it/s]Loading train:  29%|██▉       | 84/285 [01:22<03:08,  1.07it/s]Loading train:  30%|██▉       | 85/285 [01:23<02:55,  1.14it/s]Loading train:  30%|███       | 86/285 [01:24<03:09,  1.05it/s]Loading train:  31%|███       | 87/285 [01:25<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:26<03:03,  1.07it/s]Loading train:  31%|███       | 89/285 [01:27<02:56,  1.11it/s]Loading train:  32%|███▏      | 90/285 [01:28<03:04,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:29<03:06,  1.04it/s]Loading train:  32%|███▏      | 92/285 [01:30<03:10,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:31<02:59,  1.07it/s]Loading train:  33%|███▎      | 94/285 [01:32<02:56,  1.08it/s]Loading train:  33%|███▎      | 95/285 [01:33<03:02,  1.04it/s]Loading train:  34%|███▎      | 96/285 [01:34<02:59,  1.05it/s]Loading train:  34%|███▍      | 97/285 [01:35<03:02,  1.03it/s]Loading train:  34%|███▍      | 98/285 [01:36<03:03,  1.02it/s]Loading train:  35%|███▍      | 99/285 [01:37<02:58,  1.04it/s]Loading train:  35%|███▌      | 100/285 [01:38<03:01,  1.02it/s]Loading train:  35%|███▌      | 101/285 [01:38<02:51,  1.07it/s]Loading train:  36%|███▌      | 102/285 [01:39<02:55,  1.04it/s]Loading train:  36%|███▌      | 103/285 [01:40<02:48,  1.08it/s]Loading train:  36%|███▋      | 104/285 [01:41<02:50,  1.06it/s]Loading train:  37%|███▋      | 105/285 [01:42<02:51,  1.05it/s]Loading train:  37%|███▋      | 106/285 [01:43<02:47,  1.07it/s]Loading train:  38%|███▊      | 107/285 [01:44<02:45,  1.07it/s]Loading train:  38%|███▊      | 108/285 [01:45<02:47,  1.06it/s]Loading train:  38%|███▊      | 109/285 [01:46<02:40,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:47<02:41,  1.08it/s]Loading train:  39%|███▉      | 111/285 [01:48<02:33,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:49<02:32,  1.14it/s]Loading train:  40%|███▉      | 113/285 [01:49<02:34,  1.11it/s]Loading train:  40%|████      | 114/285 [01:50<02:38,  1.08it/s]Loading train:  40%|████      | 115/285 [01:51<02:37,  1.08it/s]Loading train:  41%|████      | 116/285 [01:52<02:43,  1.03it/s]Loading train:  41%|████      | 117/285 [01:53<02:32,  1.10it/s]Loading train:  41%|████▏     | 118/285 [01:54<02:28,  1.12it/s]Loading train:  42%|████▏     | 119/285 [01:55<02:29,  1.11it/s]Loading train:  42%|████▏     | 120/285 [01:56<02:32,  1.08it/s]Loading train:  42%|████▏     | 121/285 [01:57<02:53,  1.06s/it]Loading train:  43%|████▎     | 122/285 [01:59<02:57,  1.09s/it]Loading train:  43%|████▎     | 123/285 [02:00<03:03,  1.13s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:53,  1.07s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:42,  1.01s/it]Loading train:  44%|████▍     | 126/285 [02:02<02:30,  1.05it/s]Loading train:  45%|████▍     | 127/285 [02:03<02:20,  1.12it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:15,  1.16it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:09,  1.21it/s]Loading train:  46%|████▌     | 130/285 [02:05<02:01,  1.27it/s]Loading train:  46%|████▌     | 131/285 [02:06<02:05,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:07<02:01,  1.26it/s]Loading train:  47%|████▋     | 133/285 [02:08<02:02,  1.24it/s]Loading train:  47%|████▋     | 134/285 [02:08<01:53,  1.33it/s]Loading train:  47%|████▋     | 135/285 [02:09<01:53,  1.32it/s]Loading train:  48%|████▊     | 136/285 [02:10<01:53,  1.31it/s]Loading train:  48%|████▊     | 137/285 [02:11<02:03,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:53,  1.30it/s]Loading train:  49%|████▉     | 139/285 [02:12<01:53,  1.28it/s]Loading train:  49%|████▉     | 140/285 [02:13<01:52,  1.29it/s]Loading train:  49%|████▉     | 141/285 [02:14<01:48,  1.33it/s]Loading train:  50%|████▉     | 142/285 [02:15<01:45,  1.36it/s]Loading train:  50%|█████     | 143/285 [02:15<01:43,  1.38it/s]Loading train:  51%|█████     | 144/285 [02:16<01:49,  1.28it/s]Loading train:  51%|█████     | 145/285 [02:17<01:49,  1.28it/s]Loading train:  51%|█████     | 146/285 [02:18<01:51,  1.25it/s]Loading train:  52%|█████▏    | 147/285 [02:19<01:49,  1.26it/s]Loading train:  52%|█████▏    | 148/285 [02:19<01:47,  1.28it/s]Loading train:  52%|█████▏    | 149/285 [02:20<01:43,  1.31it/s]Loading train:  53%|█████▎    | 150/285 [02:21<01:36,  1.39it/s]Loading train:  53%|█████▎    | 151/285 [02:21<01:38,  1.36it/s]Loading train:  53%|█████▎    | 152/285 [02:22<01:40,  1.32it/s]Loading train:  54%|█████▎    | 153/285 [02:23<01:37,  1.36it/s]Loading train:  54%|█████▍    | 154/285 [02:24<01:43,  1.26it/s]Loading train:  54%|█████▍    | 155/285 [02:25<01:43,  1.25it/s]Loading train:  55%|█████▍    | 156/285 [02:26<01:50,  1.17it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:51,  1.15it/s]Loading train:  55%|█████▌    | 158/285 [02:27<01:45,  1.21it/s]Loading train:  56%|█████▌    | 159/285 [02:28<01:40,  1.25it/s]Loading train:  56%|█████▌    | 160/285 [02:29<01:41,  1.23it/s]Loading train:  56%|█████▋    | 161/285 [02:30<01:41,  1.22it/s]Loading train:  57%|█████▋    | 162/285 [02:30<01:40,  1.23it/s]Loading train:  57%|█████▋    | 163/285 [02:31<01:34,  1.29it/s]Loading train:  58%|█████▊    | 164/285 [02:32<01:29,  1.35it/s]Loading train:  58%|█████▊    | 165/285 [02:33<01:26,  1.39it/s]Loading train:  58%|█████▊    | 166/285 [02:33<01:31,  1.31it/s]Loading train:  59%|█████▊    | 167/285 [02:34<01:34,  1.25it/s]Loading train:  59%|█████▉    | 168/285 [02:35<01:35,  1.23it/s]Loading train:  59%|█████▉    | 169/285 [02:36<01:32,  1.26it/s]Loading train:  60%|█████▉    | 170/285 [02:37<01:27,  1.31it/s]Loading train:  60%|██████    | 171/285 [02:37<01:28,  1.28it/s]Loading train:  60%|██████    | 172/285 [02:38<01:25,  1.31it/s]Loading train:  61%|██████    | 173/285 [02:39<01:25,  1.31it/s]Loading train:  61%|██████    | 174/285 [02:40<01:25,  1.30it/s]Loading train:  61%|██████▏   | 175/285 [02:40<01:26,  1.27it/s]Loading train:  62%|██████▏   | 176/285 [02:41<01:28,  1.24it/s]Loading train:  62%|██████▏   | 177/285 [02:42<01:24,  1.28it/s]Loading train:  62%|██████▏   | 178/285 [02:43<01:23,  1.28it/s]Loading train:  63%|██████▎   | 179/285 [02:44<01:22,  1.29it/s]Loading train:  63%|██████▎   | 180/285 [02:45<01:31,  1.15it/s]Loading train:  64%|██████▎   | 181/285 [02:46<01:30,  1.15it/s]Loading train:  64%|██████▍   | 182/285 [02:46<01:27,  1.18it/s]Loading train:  64%|██████▍   | 183/285 [02:47<01:21,  1.26it/s]Loading train:  65%|██████▍   | 184/285 [02:48<01:22,  1.23it/s]Loading train:  65%|██████▍   | 185/285 [02:49<01:17,  1.29it/s]Loading train:  65%|██████▌   | 186/285 [02:50<01:27,  1.13it/s]Loading train:  66%|██████▌   | 187/285 [02:51<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [02:52<01:30,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [02:52<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [02:53<01:22,  1.15it/s]Loading train:  67%|██████▋   | 191/285 [02:54<01:22,  1.15it/s]Loading train:  67%|██████▋   | 192/285 [02:55<01:22,  1.13it/s]Loading train:  68%|██████▊   | 193/285 [02:56<01:17,  1.18it/s]Loading train:  68%|██████▊   | 194/285 [02:57<01:16,  1.20it/s]Loading train:  68%|██████▊   | 195/285 [02:57<01:10,  1.28it/s]Loading train:  69%|██████▉   | 196/285 [02:58<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [02:59<01:17,  1.13it/s]Loading train:  69%|██████▉   | 198/285 [03:00<01:22,  1.05it/s]Loading train:  70%|██████▉   | 199/285 [03:01<01:15,  1.13it/s]Loading train:  70%|███████   | 200/285 [03:02<01:09,  1.23it/s]Loading train:  71%|███████   | 201/285 [03:03<01:12,  1.16it/s]Loading train:  71%|███████   | 202/285 [03:04<01:11,  1.16it/s]Loading train:  71%|███████   | 203/285 [03:04<01:07,  1.22it/s]Loading train:  72%|███████▏  | 204/285 [03:05<01:08,  1.18it/s]Loading train:  72%|███████▏  | 205/285 [03:06<01:04,  1.24it/s]Loading train:  72%|███████▏  | 206/285 [03:07<01:09,  1.14it/s]Loading train:  73%|███████▎  | 207/285 [03:08<01:08,  1.14it/s]Loading train:  73%|███████▎  | 208/285 [03:09<01:12,  1.07it/s]Loading train:  73%|███████▎  | 209/285 [03:10<01:11,  1.06it/s]Loading train:  74%|███████▎  | 210/285 [03:11<01:07,  1.12it/s]Loading train:  74%|███████▍  | 211/285 [03:11<01:03,  1.16it/s]Loading train:  74%|███████▍  | 212/285 [03:12<01:01,  1.18it/s]Loading train:  75%|███████▍  | 213/285 [03:13<01:06,  1.09it/s]Loading train:  75%|███████▌  | 214/285 [03:14<01:01,  1.16it/s]Loading train:  75%|███████▌  | 215/285 [03:15<01:07,  1.04it/s]Loading train:  76%|███████▌  | 216/285 [03:16<01:00,  1.15it/s]Loading train:  76%|███████▌  | 217/285 [03:17<00:59,  1.14it/s]Loading train:  76%|███████▋  | 218/285 [03:18<01:00,  1.11it/s]Loading train:  77%|███████▋  | 219/285 [03:19<01:03,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [03:20<00:59,  1.09it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:57,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [03:21<00:57,  1.10it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:52,  1.19it/s]Loading train:  79%|███████▊  | 224/285 [03:23<00:49,  1.23it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:47,  1.25it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:49,  1.19it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:52,  1.10it/s]Loading train:  80%|████████  | 228/285 [03:27<00:51,  1.11it/s]Loading train:  80%|████████  | 229/285 [03:28<00:51,  1.08it/s]Loading train:  81%|████████  | 230/285 [03:28<00:46,  1.18it/s]Loading train:  81%|████████  | 231/285 [03:29<00:43,  1.23it/s]Loading train:  81%|████████▏ | 232/285 [03:30<00:44,  1.19it/s]Loading train:  82%|████████▏ | 233/285 [03:31<00:43,  1.19it/s]Loading train:  82%|████████▏ | 234/285 [03:32<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:32<00:41,  1.21it/s]Loading train:  83%|████████▎ | 236/285 [03:34<00:45,  1.07it/s]Loading train:  83%|████████▎ | 237/285 [03:34<00:44,  1.07it/s]Loading train:  84%|████████▎ | 238/285 [03:35<00:44,  1.06it/s]Loading train:  84%|████████▍ | 239/285 [03:36<00:42,  1.07it/s]Loading train:  84%|████████▍ | 240/285 [03:37<00:39,  1.13it/s]Loading train:  85%|████████▍ | 241/285 [03:38<00:39,  1.11it/s]Loading train:  85%|████████▍ | 242/285 [03:39<00:39,  1.10it/s]Loading train:  85%|████████▌ | 243/285 [03:40<00:37,  1.11it/s]Loading train:  86%|████████▌ | 244/285 [03:41<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [03:42<00:35,  1.13it/s]Loading train:  86%|████████▋ | 246/285 [03:43<00:35,  1.09it/s]Loading train:  87%|████████▋ | 247/285 [03:44<00:34,  1.09it/s]Loading train:  87%|████████▋ | 248/285 [03:44<00:32,  1.15it/s]Loading train:  87%|████████▋ | 249/285 [03:45<00:29,  1.24it/s]Loading train:  88%|████████▊ | 250/285 [03:46<00:27,  1.25it/s]Loading train:  88%|████████▊ | 251/285 [03:46<00:25,  1.33it/s]Loading train:  88%|████████▊ | 252/285 [03:47<00:25,  1.32it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:26,  1.23it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:27,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:50<00:26,  1.15it/s]Loading train:  90%|████████▉ | 256/285 [03:51<00:23,  1.23it/s]Loading train:  90%|█████████ | 257/285 [03:51<00:21,  1.28it/s]Loading train:  91%|█████████ | 258/285 [03:52<00:23,  1.15it/s]Loading train:  91%|█████████ | 259/285 [03:53<00:21,  1.20it/s]Loading train:  91%|█████████ | 260/285 [03:54<00:21,  1.14it/s]Loading train:  92%|█████████▏| 261/285 [03:55<00:20,  1.19it/s]Loading train:  92%|█████████▏| 262/285 [03:56<00:20,  1.14it/s]Loading train:  92%|█████████▏| 263/285 [03:57<00:17,  1.23it/s]Loading train:  93%|█████████▎| 264/285 [03:58<00:17,  1.17it/s]Loading train:  93%|█████████▎| 265/285 [03:59<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [03:59<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:00<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [04:01<00:15,  1.10it/s]Loading train:  94%|█████████▍| 269/285 [04:02<00:14,  1.11it/s]Loading train:  95%|█████████▍| 270/285 [04:03<00:13,  1.13it/s]Loading train:  95%|█████████▌| 271/285 [04:04<00:11,  1.17it/s]Loading train:  95%|█████████▌| 272/285 [04:04<00:10,  1.19it/s]Loading train:  96%|█████████▌| 273/285 [04:05<00:09,  1.23it/s]Loading train:  96%|█████████▌| 274/285 [04:06<00:09,  1.16it/s]Loading train:  96%|█████████▋| 275/285 [04:07<00:09,  1.09it/s]Loading train:  97%|█████████▋| 276/285 [04:08<00:08,  1.10it/s]Loading train:  97%|█████████▋| 277/285 [04:09<00:06,  1.18it/s]Loading train:  98%|█████████▊| 278/285 [04:10<00:05,  1.25it/s]Loading train:  98%|█████████▊| 279/285 [04:11<00:05,  1.18it/s]Loading train:  98%|█████████▊| 280/285 [04:11<00:04,  1.13it/s]Loading train:  99%|█████████▊| 281/285 [04:12<00:03,  1.16it/s]Loading train:  99%|█████████▉| 282/285 [04:13<00:02,  1.16it/s]Loading train:  99%|█████████▉| 283/285 [04:14<00:01,  1.11it/s]Loading train: 100%|█████████▉| 284/285 [04:15<00:00,  1.10it/s]Loading train: 100%|██████████| 285/285 [04:16<00:00,  1.09it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:01, 197.37it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:01, 214.42it/s]concatenating: train:  26%|██▌       | 73/285 [00:00<00:00, 224.00it/s]concatenating: train:  36%|███▋      | 104/285 [00:00<00:00, 243.87it/s]concatenating: train:  47%|████▋     | 135/285 [00:00<00:00, 255.65it/s]concatenating: train:  59%|█████▉    | 169/285 [00:00<00:00, 275.25it/s]concatenating: train:  71%|███████   | 203/285 [00:00<00:00, 290.64it/s]concatenating: train:  84%|████████▎ | 238/285 [00:00<00:00, 301.19it/s]concatenating: train:  94%|█████████▍| 268/285 [00:00<00:00, 296.46it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 292.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 606.67it/s]2019-07-10 21:43:48.837365: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 21:43:48.837527: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 21:43:48.837550: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 21:43:48.837564: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 21:43:48.838180: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.13it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.94it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.85it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.24it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.68it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.59it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.83it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.59it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.53it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.39it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.06it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.51it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.71it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.88it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.29it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.75it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.84it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.03it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.69it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   598         dropout_7[0][0]                  
==================================================================================================
Total params: 133,158
Trainable params: 34,618
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 3.2211 - acc: 0.6297 - mDice: 0.0585 - val_loss: 2.4746 - val_acc: 0.9085 - val_mDice: 0.1566

Epoch 00001: val_mDice improved from -inf to 0.15660, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 9s - loss: 1.5668 - acc: 0.8704 - mDice: 0.2155 - val_loss: 1.9353 - val_acc: 0.9049 - val_mDice: 0.2543

Epoch 00002: val_mDice improved from 0.15660 to 0.25434, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 1.0521 - acc: 0.8745 - mDice: 0.3353 - val_loss: 1.4265 - val_acc: 0.9049 - val_mDice: 0.3776

Epoch 00003: val_mDice improved from 0.25434 to 0.37762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.8667 - acc: 0.8783 - mDice: 0.4029 - val_loss: 1.3040 - val_acc: 0.9068 - val_mDice: 0.4126

Epoch 00004: val_mDice improved from 0.37762 to 0.41265, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.7739 - acc: 0.8824 - mDice: 0.4431 - val_loss: 1.1720 - val_acc: 0.9141 - val_mDice: 0.4754

Epoch 00005: val_mDice improved from 0.41265 to 0.47545, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.7147 - acc: 0.8880 - mDice: 0.4709 - val_loss: 1.1784 - val_acc: 0.9189 - val_mDice: 0.4606

Epoch 00006: val_mDice did not improve from 0.47545
Epoch 7/300
 - 9s - loss: 0.6723 - acc: 0.8949 - mDice: 0.4920 - val_loss: 1.1487 - val_acc: 0.9231 - val_mDice: 0.4933

Epoch 00007: val_mDice improved from 0.47545 to 0.49329, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 9s - loss: 0.6365 - acc: 0.8996 - mDice: 0.5106 - val_loss: 1.0458 - val_acc: 0.9293 - val_mDice: 0.5063

Epoch 00008: val_mDice improved from 0.49329 to 0.50631, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 9s - loss: 0.6098 - acc: 0.9027 - mDice: 0.5249 - val_loss: 1.0196 - val_acc: 0.9295 - val_mDice: 0.5343

Epoch 00009: val_mDice improved from 0.50631 to 0.53429, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 9s - loss: 0.5837 - acc: 0.9057 - mDice: 0.5395 - val_loss: 1.1060 - val_acc: 0.9219 - val_mDice: 0.5178

Epoch 00010: val_mDice did not improve from 0.53429
Epoch 11/300
 - 9s - loss: 0.5636 - acc: 0.9077 - mDice: 0.5510 - val_loss: 1.0199 - val_acc: 0.9298 - val_mDice: 0.5314

Epoch 00011: val_mDice did not improve from 0.53429
Epoch 12/300
 - 9s - loss: 0.5499 - acc: 0.9092 - mDice: 0.5591 - val_loss: 1.0537 - val_acc: 0.9243 - val_mDice: 0.5297

Epoch 00012: val_mDice did not improve from 0.53429
Epoch 13/300
 - 8s - loss: 0.5365 - acc: 0.9110 - mDice: 0.5672 - val_loss: 0.9928 - val_acc: 0.9321 - val_mDice: 0.5345

Epoch 00013: val_mDice improved from 0.53429 to 0.53453, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 8s - loss: 0.5234 - acc: 0.9123 - mDice: 0.5749 - val_loss: 1.0317 - val_acc: 0.9306 - val_mDice: 0.5328

Epoch 00014: val_mDice did not improve from 0.53453
Epoch 15/300
 - 9s - loss: 0.5126 - acc: 0.9137 - mDice: 0.5818 - val_loss: 1.0951 - val_acc: 0.9222 - val_mDice: 0.5156

Epoch 00015: val_mDice did not improve from 0.53453
Epoch 16/300
 - 9s - loss: 0.5002 - acc: 0.9147 - mDice: 0.5892 - val_loss: 0.9935 - val_acc: 0.9318 - val_mDice: 0.5363

Epoch 00016: val_mDice improved from 0.53453 to 0.53626, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 9s - loss: 0.4914 - acc: 0.9159 - mDice: 0.5947 - val_loss: 1.0178 - val_acc: 0.9289 - val_mDice: 0.5418

Epoch 00017: val_mDice improved from 0.53626 to 0.54184, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.4824 - acc: 0.9167 - mDice: 0.6002 - val_loss: 0.9959 - val_acc: 0.9321 - val_mDice: 0.5475

Epoch 00018: val_mDice improved from 0.54184 to 0.54749, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 8s - loss: 0.4753 - acc: 0.9178 - mDice: 0.6050 - val_loss: 0.9989 - val_acc: 0.9291 - val_mDice: 0.5438

Epoch 00019: val_mDice did not improve from 0.54749
Epoch 20/300
 - 9s - loss: 0.4690 - acc: 0.9184 - mDice: 0.6091 - val_loss: 1.0257 - val_acc: 0.9289 - val_mDice: 0.5460

Epoch 00020: val_mDice did not improve from 0.54749
Epoch 21/300
 - 9s - loss: 0.4639 - acc: 0.9188 - mDice: 0.6123 - val_loss: 0.9564 - val_acc: 0.9357 - val_mDice: 0.5523

Epoch 00021: val_mDice improved from 0.54749 to 0.55227, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 8s - loss: 0.4563 - acc: 0.9197 - mDice: 0.6172 - val_loss: 0.9234 - val_acc: 0.9337 - val_mDice: 0.5526

Epoch 00022: val_mDice improved from 0.55227 to 0.55265, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 8s - loss: 0.4499 - acc: 0.9204 - mDice: 0.6213 - val_loss: 0.9617 - val_acc: 0.9357 - val_mDice: 0.5483

Epoch 00023: val_mDice did not improve from 0.55265
Epoch 24/300
 - 9s - loss: 0.4448 - acc: 0.9210 - mDice: 0.6247 - val_loss: 0.9766 - val_acc: 0.9342 - val_mDice: 0.5344

Epoch 00024: val_mDice did not improve from 0.55265
Epoch 25/300
 - 9s - loss: 0.4390 - acc: 0.9217 - mDice: 0.6286 - val_loss: 0.9590 - val_acc: 0.9332 - val_mDice: 0.5441

Epoch 00025: val_mDice did not improve from 0.55265
Epoch 26/300
 - 9s - loss: 0.4345 - acc: 0.9222 - mDice: 0.6315 - val_loss: 1.0089 - val_acc: 0.9200 - val_mDice: 0.5252

Epoch 00026: val_mDice did not improve from 0.55265
Epoch 27/300
 - 9s - loss: 0.4314 - acc: 0.9225 - mDice: 0.6336 - val_loss: 0.9260 - val_acc: 0.9352 - val_mDice: 0.5526

Epoch 00027: val_mDice did not improve from 0.55265
Epoch 28/300
 - 9s - loss: 0.4261 - acc: 0.9231 - mDice: 0.6371 - val_loss: 0.9207 - val_acc: 0.9372 - val_mDice: 0.5551

Epoch 00028: val_mDice improved from 0.55265 to 0.55509, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 10s - loss: 0.4219 - acc: 0.9239 - mDice: 0.6401 - val_loss: 0.8382 - val_acc: 0.9377 - val_mDice: 0.5529

Epoch 00029: val_mDice did not improve from 0.55509
Epoch 30/300
 - 10s - loss: 0.4204 - acc: 0.9239 - mDice: 0.6410 - val_loss: 0.8983 - val_acc: 0.9360 - val_mDice: 0.5599

Epoch 00030: val_mDice improved from 0.55509 to 0.55991, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 10s - loss: 0.4151 - acc: 0.9243 - mDice: 0.6445 - val_loss: 0.8978 - val_acc: 0.9364 - val_mDice: 0.5617

Epoch 00031: val_mDice improved from 0.55991 to 0.56166, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 32/300
 - 11s - loss: 0.4133 - acc: 0.9248 - mDice: 0.6458 - val_loss: 0.8944 - val_acc: 0.9342 - val_mDice: 0.5665

Epoch 00032: val_mDice improved from 0.56166 to 0.56649, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 10s - loss: 0.4090 - acc: 0.9252 - mDice: 0.6487 - val_loss: 0.9168 - val_acc: 0.9342 - val_mDice: 0.5509

Epoch 00033: val_mDice did not improve from 0.56649
Epoch 34/300
 - 11s - loss: 0.4057 - acc: 0.9256 - mDice: 0.6510 - val_loss: 1.0072 - val_acc: 0.9224 - val_mDice: 0.5226

Epoch 00034: val_mDice did not improve from 0.56649
Epoch 35/300
 - 10s - loss: 0.4054 - acc: 0.9256 - mDice: 0.6513 - val_loss: 0.8780 - val_acc: 0.9333 - val_mDice: 0.5619

Epoch 00035: val_mDice did not improve from 0.56649
Epoch 36/300
 - 11s - loss: 0.4009 - acc: 0.9261 - mDice: 0.6543 - val_loss: 0.8944 - val_acc: 0.9354 - val_mDice: 0.5555

Epoch 00036: val_mDice did not improve from 0.56649
Epoch 37/300
 - 10s - loss: 0.3970 - acc: 0.9266 - mDice: 0.6571 - val_loss: 0.8945 - val_acc: 0.9370 - val_mDice: 0.5486

Epoch 00037: val_mDice did not improve from 0.56649
Epoch 38/300
 - 10s - loss: 0.3954 - acc: 0.9268 - mDice: 0.6581 - val_loss: 0.9056 - val_acc: 0.9325 - val_mDice: 0.5512

Epoch 00038: val_mDice did not improve from 0.56649
Epoch 39/300
 - 11s - loss: 0.3913 - acc: 0.9273 - mDice: 0.6609 - val_loss: 0.8850 - val_acc: 0.9365 - val_mDice: 0.5527

Epoch 00039: val_mDice did not improve from 0.56649
Epoch 40/300
 - 10s - loss: 0.3919 - acc: 0.9272 - mDice: 0.6604 - val_loss: 0.8407 - val_acc: 0.9391 - val_mDice: 0.5649

Epoch 00040: val_mDice did not improve from 0.56649
Epoch 41/300
 - 10s - loss: 0.3892 - acc: 0.9277 - mDice: 0.6624 - val_loss: 0.8427 - val_acc: 0.9398 - val_mDice: 0.5617

Epoch 00041: val_mDice did not improve from 0.56649
Epoch 42/300
 - 10s - loss: 0.3866 - acc: 0.9279 - mDice: 0.6643 - val_loss: 0.8691 - val_acc: 0.9375 - val_mDice: 0.5573

Epoch 00042: val_mDice did not improve from 0.56649
Epoch 43/300
 - 11s - loss: 0.3844 - acc: 0.9284 - mDice: 0.6657 - val_loss: 0.8899 - val_acc: 0.9351 - val_mDice: 0.5555

Epoch 00043: val_mDice did not improve from 0.56649
Epoch 44/300
 - 10s - loss: 0.3835 - acc: 0.9287 - mDice: 0.6663 - val_loss: 0.8146 - val_acc: 0.9392 - val_mDice: 0.5678

Epoch 00044: val_mDice improved from 0.56649 to 0.56779, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 11s - loss: 0.3806 - acc: 0.9288 - mDice: 0.6684 - val_loss: 0.8712 - val_acc: 0.9369 - val_mDice: 0.5576

Epoch 00045: val_mDice did not improve from 0.56779
Epoch 46/300
 - 10s - loss: 0.3788 - acc: 0.9291 - mDice: 0.6696 - val_loss: 0.8814 - val_acc: 0.9383 - val_mDice: 0.5549

Epoch 00046: val_mDice did not improve from 0.56779
Epoch 47/300
 - 9s - loss: 0.3771 - acc: 0.9293 - mDice: 0.6708 - val_loss: 0.7969 - val_acc: 0.9378 - val_mDice: 0.5708

Epoch 00047: val_mDice improved from 0.56779 to 0.57084, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 48/300
 - 10s - loss: 0.3750 - acc: 0.9296 - mDice: 0.6723 - val_loss: 0.7526 - val_acc: 0.9417 - val_mDice: 0.5574

Epoch 00048: val_mDice did not improve from 0.57084
Epoch 49/300
 - 10s - loss: 0.3743 - acc: 0.9297 - mDice: 0.6728 - val_loss: 0.8124 - val_acc: 0.9382 - val_mDice: 0.5408

Epoch 00049: val_mDice did not improve from 0.57084
Epoch 50/300
 - 9s - loss: 0.3713 - acc: 0.9302 - mDice: 0.6750 - val_loss: 0.9283 - val_acc: 0.9324 - val_mDice: 0.5413

Epoch 00050: val_mDice did not improve from 0.57084
Epoch 51/300
 - 11s - loss: 0.3693 - acc: 0.9304 - mDice: 0.6762 - val_loss: 0.8096 - val_acc: 0.9408 - val_mDice: 0.5676

Epoch 00051: val_mDice did not improve from 0.57084
Epoch 52/300
 - 10s - loss: 0.3701 - acc: 0.9301 - mDice: 0.6758 - val_loss: 0.8443 - val_acc: 0.9419 - val_mDice: 0.5560

Epoch 00052: val_mDice did not improve from 0.57084
Epoch 53/300
 - 10s - loss: 0.3696 - acc: 0.9304 - mDice: 0.6762 - val_loss: 0.7627 - val_acc: 0.9375 - val_mDice: 0.5497

Epoch 00053: val_mDice did not improve from 0.57084
Epoch 54/300
 - 10s - loss: 0.3663 - acc: 0.9308 - mDice: 0.6785 - val_loss: 0.8369 - val_acc: 0.9390 - val_mDice: 0.5641

Epoch 00054: val_mDice did not improve from 0.57084
Epoch 55/300
 - 10s - loss: 0.3645 - acc: 0.9309 - mDice: 0.6797 - val_loss: 0.7952 - val_acc: 0.9380 - val_mDice: 0.5548

Epoch 00055: val_mDice did not improve from 0.57084
Epoch 56/300
 - 10s - loss: 0.3639 - acc: 0.9312 - mDice: 0.6802 - val_loss: 0.8165 - val_acc: 0.9347 - val_mDice: 0.5592

Epoch 00056: val_mDice did not improve from 0.57084
Epoch 57/300
 - 9s - loss: 0.3622 - acc: 0.9312 - mDice: 0.6813 - val_loss: 0.8710 - val_acc: 0.9349 - val_mDice: 0.5585

Epoch 00057: val_mDice did not improve from 0.57084
Epoch 58/300
 - 10s - loss: 0.3604 - acc: 0.9317 - mDice: 0.6826 - val_loss: 0.9189 - val_acc: 0.9313 - val_mDice: 0.5446

Epoch 00058: val_mDice did not improve from 0.57084
Epoch 59/300
 - 9s - loss: 0.3575 - acc: 0.9317 - mDice: 0.6846 - val_loss: 0.9172 - val_acc: 0.9259 - val_mDice: 0.5372

Epoch 00059: val_mDice did not improve from 0.57084
Epoch 60/300
 - 10s - loss: 0.3587 - acc: 0.9316 - mDice: 0.6839 - val_loss: 0.8638 - val_acc: 0.9346 - val_mDice: 0.5598

Epoch 00060: val_mDice did not improve from 0.57084
Epoch 61/300
 - 9s - loss: 0.3613 - acc: 0.9316 - mDice: 0.6821 - val_loss: 0.8119 - val_acc: 0.9322 - val_mDice: 0.5420

Epoch 00061: val_mDice did not improve from 0.57084
Epoch 62/300
 - 10s - loss: 0.3608 - acc: 0.9316 - mDice: 0.6825 - val_loss: 0.8446 - val_acc: 0.9390 - val_mDice: 0.5626

Epoch 00062: val_mDice did not improve from 0.57084
Epoch 63/300
 - 9s - loss: 0.3556 - acc: 0.9321 - mDice: 0.6861 - val_loss: 0.8555 - val_acc: 0.9331 - val_mDice: 0.5483

Epoch 00063: val_mDice did not improve from 0.57084
Epoch 64/300
 - 9s - loss: 0.3546 - acc: 0.9325 - mDice: 0.6869 - val_loss: 0.7706 - val_acc: 0.9402 - val_mDice: 0.5562

Epoch 00064: val_mDice did not improve from 0.57084
Epoch 65/300
 - 9s - loss: 0.3533 - acc: 0.9326 - mDice: 0.6878 - val_loss: 0.7664 - val_acc: 0.9389 - val_mDice: 0.5538

Epoch 00065: val_mDice did not improve from 0.57084
Epoch 66/300
 - 10s - loss: 0.3520 - acc: 0.9328 - mDice: 0.6886 - val_loss: 0.7647 - val_acc: 0.9378 - val_mDice: 0.5605

Epoch 00066: val_mDice did not improve from 0.57084
Epoch 67/300
 - 8s - loss: 0.3526 - acc: 0.9329 - mDice: 0.6884 - val_loss: 0.6935 - val_acc: 0.9397 - val_mDice: 0.5533

Epoch 00067: val_mDice did not improve from 0.57084
Epoch 68/300
 - 8s - loss: 0.3514 - acc: 0.9332 - mDice: 0.6891 - val_loss: 0.8219 - val_acc: 0.9350 - val_mDice: 0.5551

Epoch 00068: val_mDice did not improve from 0.57084
Epoch 69/300
 - 9s - loss: 0.3489 - acc: 0.9334 - mDice: 0.6910 - val_loss: 0.8018 - val_acc: 0.9357 - val_mDice: 0.5581

Epoch 00069: val_mDice did not improve from 0.57084
Epoch 70/300
 - 8s - loss: 0.3478 - acc: 0.9337 - mDice: 0.6917 - val_loss: 0.8768 - val_acc: 0.9323 - val_mDice: 0.5384

Epoch 00070: val_mDice did not improve from 0.57084
Epoch 71/300
 - 8s - loss: 0.3463 - acc: 0.9340 - mDice: 0.6928 - val_loss: 0.8147 - val_acc: 0.9403 - val_mDice: 0.5655

Epoch 00071: val_mDice did not improve from 0.57084
Epoch 72/300
 - 8s - loss: 0.3462 - acc: 0.9339 - mDice: 0.6928 - val_loss: 0.7992 - val_acc: 0.9365 - val_mDice: 0.5500

Epoch 00072: val_mDice did not improve from 0.57084
Epoch 73/300
 - 8s - loss: 0.3463 - acc: 0.9338 - mDice: 0.6927 - val_loss: 0.8308 - val_acc: 0.9381 - val_mDice: 0.5563

Epoch 00073: val_mDice did not improve from 0.57084
Epoch 74/300
 - 9s - loss: 0.3445 - acc: 0.9342 - mDice: 0.6941 - val_loss: 0.8267 - val_acc: 0.9351 - val_mDice: 0.5396

Epoch 00074: val_mDice did not improve from 0.57084
Epoch 75/300
 - 8s - loss: 0.3429 - acc: 0.9344 - mDice: 0.6951 - val_loss: 0.7655 - val_acc: 0.9413 - val_mDice: 0.5627

Epoch 00075: val_mDice did not improve from 0.57084
Epoch 76/300
 - 8s - loss: 0.3404 - acc: 0.9347 - mDice: 0.6970 - val_loss: 0.7451 - val_acc: 0.9425 - val_mDice: 0.5682

Epoch 00076: val_mDice did not improve from 0.57084
Epoch 77/300
 - 8s - loss: 0.3410 - acc: 0.9347 - mDice: 0.6966 - val_loss: 0.8577 - val_acc: 0.9379 - val_mDice: 0.5524

Epoch 00077: val_mDice did not improve from 0.57084
Epoch 78/300
 - 8s - loss: 0.3428 - acc: 0.9344 - mDice: 0.6954 - val_loss: 0.8113 - val_acc: 0.9361 - val_mDice: 0.5554

Epoch 00078: val_mDice did not improve from 0.57084
Epoch 79/300
 - 8s - loss: 0.3413 - acc: 0.9348 - mDice: 0.6964 - val_loss: 0.7389 - val_acc: 0.9413 - val_mDice: 0.5569

Epoch 00079: val_mDice did not improve from 0.57084
Epoch 80/300
 - 8s - loss: 0.3403 - acc: 0.9348 - mDice: 0.6971 - val_loss: 0.8298 - val_acc: 0.9356 - val_mDice: 0.5551

Epoch 00080: val_mDice did not improve from 0.57084
Epoch 81/300
 - 9s - loss: 0.3387 - acc: 0.9351 - mDice: 0.6983 - val_loss: 0.7349 - val_acc: 0.9412 - val_mDice: 0.5588

Epoch 00081: val_mDice did not improve from 0.57084
Epoch 82/300
 - 8s - loss: 0.3401 - acc: 0.9351 - mDice: 0.6973 - val_loss: 0.8563 - val_acc: 0.9392 - val_mDice: 0.5644

Epoch 00082: val_mDice did not improve from 0.57084
Epoch 83/300
 - 8s - loss: 0.3361 - acc: 0.9355 - mDice: 0.7002 - val_loss: 0.8131 - val_acc: 0.9426 - val_mDice: 0.5619

Epoch 00083: val_mDice did not improve from 0.57084
Epoch 84/300
 - 8s - loss: 0.3365 - acc: 0.9352 - mDice: 0.7000 - val_loss: 0.8313 - val_acc: 0.9399 - val_mDice: 0.5512

Epoch 00084: val_mDice did not improve from 0.57084
Epoch 85/300
 - 8s - loss: 0.3371 - acc: 0.9352 - mDice: 0.6994 - val_loss: 0.7369 - val_acc: 0.9408 - val_mDice: 0.5644

Epoch 00085: val_mDice did not improve from 0.57084
Epoch 86/300
 - 8s - loss: 0.3340 - acc: 0.9358 - mDice: 0.7017 - val_loss: 0.8024 - val_acc: 0.9404 - val_mDice: 0.5621

Epoch 00086: val_mDice did not improve from 0.57084
Epoch 87/300
 - 8s - loss: 0.3350 - acc: 0.9355 - mDice: 0.7010 - val_loss: 0.7417 - val_acc: 0.9405 - val_mDice: 0.5594

Epoch 00087: val_mDice did not improve from 0.57084
Restoring model weights from the end of the best epoch
Epoch 00087: early stopping
{'val_loss': [2.474635601043701, 1.935276985168457, 1.4265114466349285, 1.3040148417154949, 1.172046729496547, 1.178408452442714, 1.1486703327723913, 1.0457793871561687, 1.0196322940644764, 1.1059751283554804, 1.0199145589556013, 1.0537455422537667, 0.9928447632562547, 1.031720274970645, 1.0950916721707298, 0.9934630393981934, 1.0177854469844274, 0.9959250858851841, 0.998939900171189, 1.0257023629688082, 0.9564401081630162, 0.923371916725522, 0.9617473397936139, 0.9765983195531935, 0.9590045724596296, 1.008907636006673, 0.9259670007796514, 0.9206643104553223, 0.8382024083818708, 0.8983440512702578, 0.8978440080370221, 0.8944487287884667, 0.9167716276077997, 1.0072013423556374, 0.8780240558442616, 0.8943675132024855, 0.8945068518320719, 0.905557564326695, 0.8850024995349702, 0.8406547137669155, 0.842655204591297, 0.8690979140145438, 0.8899076893216088, 0.8145832788376581, 0.871163459051223, 0.8814408097948346, 0.7969087759653727, 0.7526321978796096, 0.8124070848737445, 0.9282909574962798, 0.8096494504383632, 0.8442638374510265, 0.7626753648122152, 0.8369488943190801, 0.7951732249487014, 0.8164739949362618, 0.8710234278724307, 0.9188689958481562, 0.917216107958839, 0.8637920561290923, 0.8118695985703241, 0.8446433203560966, 0.8555352006639753, 0.7706148283822196, 0.7663782437642416, 0.7646821339925131, 0.6935241790044875, 0.8219068163917178, 0.801756427401588, 0.8767677034650531, 0.814743371236892, 0.7992164520990281, 0.8308413596380324, 0.8267418089367095, 0.7655426888238817, 0.7451056525820777, 0.8576734747205462, 0.8113448506309873, 0.7389133317129952, 0.8298415229434059, 0.7348756336030506, 0.8563231967744374, 0.8131151085808164, 0.8313373951684861, 0.7368915762220111, 0.8024094672430129, 0.7417426790509906], 'val_acc': [0.9084752826463609, 0.9048855503400167, 0.9048924190657479, 0.9068406394549778, 0.9140751106398446, 0.9189445830526806, 0.9231135362670535, 0.9293291852587745, 0.9294780237334115, 0.9218521061397734, 0.9298282748176938, 0.9242994586626688, 0.932140568892161, 0.9305861081395831, 0.9221771898723784, 0.9317536864961896, 0.9289308786392212, 0.9321016470591227, 0.9291048759505862, 0.9288621573221116, 0.9357234551793053, 0.9336698963528588, 0.9357417679968334, 0.9341918769336882, 0.9332097314652943, 0.9199794076737904, 0.9352014745984759, 0.9371909584317889, 0.9376763105392456, 0.9360302459625971, 0.9364102738244193, 0.9342193319683983, 0.9342262006941295, 0.922426734651838, 0.9332555078324818, 0.9354097758020673, 0.93700320096243, 0.9324542369161334, 0.9365178545316061, 0.939125432854607, 0.9398351936113267, 0.9374656734012422, 0.9351327731495812, 0.9391895560991197, 0.9368887344996134, 0.938328742980957, 0.9378044803937277, 0.9417422300293332, 0.9382097011520749, 0.932440459728241, 0.9408447628929502, 0.9418589813368661, 0.937461066813696, 0.9389880838848296, 0.9380082516443162, 0.9346794855026972, 0.9349107174646287, 0.9313003449212938, 0.9259065928913298, 0.9345879100617909, 0.9321977779978797, 0.938958344005403, 0.9330540157499767, 0.9401648555483136, 0.938903394199553, 0.9377632765542894, 0.9396703527087257, 0.9349862479028248, 0.9356753599076044, 0.9323351894106183, 0.9403228050186521, 0.9364674659002394, 0.9380791896865481, 0.9350755441756475, 0.9412500035195124, 0.9424679563159034, 0.9378663187935239, 0.9360531313078744, 0.9412980874379476, 0.935634141876584, 0.9411904953774952, 0.939242212545304, 0.9425984507515317, 0.939896978083111, 0.9408264926501683, 0.9404120587167286, 0.9404532795860654], 'val_mDice': [0.15659677134161548, 0.2543398254063158, 0.3776207517921215, 0.41264894707239275, 0.4754475952968711, 0.4605906607210359, 0.49328881892419996, 0.5063070734696729, 0.5342902660015083, 0.517822223582438, 0.5314294323325157, 0.529720160932768, 0.5345343053340912, 0.5328112349268936, 0.5155601400349822, 0.5362602411991074, 0.5418355979380154, 0.5474885262194134, 0.543807021031777, 0.5459705144166946, 0.552273846807934, 0.552648647732678, 0.5482536728183428, 0.5343966177176862, 0.5440974645316601, 0.525163685636861, 0.5526065159411657, 0.5550889511193547, 0.5529313470636096, 0.5599087377389272, 0.5616579084169298, 0.5664899822856698, 0.5508702322840691, 0.522573843420971, 0.5618709755085763, 0.5555062121933415, 0.5485915999327388, 0.551218966288226, 0.5527370465653283, 0.5649005174636841, 0.5617316854851586, 0.5573374341641154, 0.5554971762356304, 0.5677886610584599, 0.5575782905022303, 0.5549385597308477, 0.5708352540220533, 0.5573947525450161, 0.5407875875631968, 0.5413268985492843, 0.5676089126084533, 0.5559787372393268, 0.5496668854639644, 0.5640710370526427, 0.5548106119746253, 0.5591688298043751, 0.5584953501820564, 0.5445871452490488, 0.5371673651749179, 0.5598277378649938, 0.5419614432113511, 0.5626171947944731, 0.5482596378950846, 0.5562420803166571, 0.5537898554688409, 0.5605214043032556, 0.5533408845464388, 0.5550781676457042, 0.5580818834049361, 0.5384294099750973, 0.5655105048347087, 0.5500472351199105, 0.5562531724572182, 0.5395577725555215, 0.5626724523802599, 0.5682462579792454, 0.5524043540159861, 0.5554309946795305, 0.5569488015912828, 0.5551456351365361, 0.558802298846699, 0.5643523115487326, 0.5619479439088276, 0.5512425544716063, 0.5643926133357343, 0.5621212078701883, 0.5593960086504618], 'loss': [3.221142097960002, 1.5667718411043519, 1.0521348710921496, 0.8667212367310606, 0.7738775531864589, 0.7146747416215341, 0.6723303695462309, 0.6365343525342131, 0.609787409363488, 0.583720174993144, 0.5635704685664025, 0.5499134793983895, 0.5365167956534254, 0.523446978454257, 0.5125744301205958, 0.5002161637537508, 0.4914258007187822, 0.4824380295996448, 0.47528221147791694, 0.4690014271578027, 0.46389730848947974, 0.4562681190984107, 0.44987769575736786, 0.44481701660252776, 0.4390244048605173, 0.43451389127989276, 0.43140753667571075, 0.42611764112556744, 0.42190657911995644, 0.42040493467282947, 0.4151019133456484, 0.41328514510550574, 0.4090333668016298, 0.40573902572076953, 0.40535950769297024, 0.4008760938404014, 0.3969595330584732, 0.39542412789474224, 0.3912614276120951, 0.39190510362932535, 0.3892231883284718, 0.386564430012417, 0.3844301344710829, 0.3834528785887678, 0.38056860430083894, 0.37878178863574113, 0.3770689930797703, 0.374976459319637, 0.3742709351523616, 0.3712529581717404, 0.36930693515077456, 0.3701368588139056, 0.36960336483809586, 0.36632829306441417, 0.36446602727283467, 0.36387379788952523, 0.3622194238715211, 0.3604285266671954, 0.35749896463342135, 0.358673845610454, 0.36133589974620883, 0.36079262309343757, 0.35563805532726633, 0.35457426155029476, 0.3532903213272992, 0.3519648822235974, 0.35258421598313655, 0.35139247617648933, 0.3489052777015016, 0.34780053757325013, 0.34634466510368767, 0.3462454904267984, 0.34633933194735755, 0.3444560710660336, 0.342909699044109, 0.34043290827898065, 0.34102590861567783, 0.342768760971511, 0.3413263730789532, 0.34027731038252235, 0.338730540329812, 0.3401092751788707, 0.33609514219673103, 0.3364557302915133, 0.3370688897705685, 0.3339584463532545, 0.3350272947178656], 'acc': [0.6297227457317975, 0.8704167733377222, 0.8744871587061068, 0.8782714929037386, 0.8824048633517524, 0.8879846157838275, 0.8948841241023342, 0.8995821428868912, 0.902684339535634, 0.9057459675877315, 0.907744167683923, 0.9092347623641398, 0.9109742280741475, 0.9123151141231589, 0.913676895306063, 0.914690363377258, 0.9158675164323288, 0.916704437993316, 0.9177556058816743, 0.9183846486311141, 0.9188039208368596, 0.9197041687764068, 0.9204375334091216, 0.9209710207890057, 0.9217100399110918, 0.9221513468405174, 0.9225308346063479, 0.923137374838492, 0.9239110878282873, 0.9239430846633859, 0.9242984945773619, 0.9248002611168185, 0.925167230677692, 0.9256467737511722, 0.9256107139867786, 0.9261033457323423, 0.9265640782257346, 0.9267979020646755, 0.9272855081401028, 0.927236982133776, 0.927691731789403, 0.9278851030234636, 0.9283991932225453, 0.9286623315266936, 0.9287782348096313, 0.9290779417756667, 0.9293124172897589, 0.9295573881625302, 0.9297385937978657, 0.9302454112305539, 0.9303524872000469, 0.9301125851352251, 0.9303653215497865, 0.9307578984358555, 0.9308922951198944, 0.9311890106613016, 0.9311548569240574, 0.9316621364392549, 0.9317288704637344, 0.9316101378389744, 0.9316239235647984, 0.9316473044318594, 0.9321180854157168, 0.932471503670422, 0.932612180939662, 0.9327853919914147, 0.9328857935621763, 0.9331567412239061, 0.9333828962076738, 0.9336954390402816, 0.9340239243399828, 0.9338695316708154, 0.9337835632837735, 0.9342004444664881, 0.9343512046881809, 0.9347489926427551, 0.9346561439928577, 0.9344120767848764, 0.9347591194799463, 0.9348188799103722, 0.9350870254068722, 0.9350745319423819, 0.9354522566655616, 0.9352395899819345, 0.9351949585709058, 0.9358005558040208, 0.9354936660818449], 'mDice': [0.058457055065370786, 0.21546864034423072, 0.3352666322909639, 0.40285462337535816, 0.44307000301052935, 0.4708572800032592, 0.49197118124199757, 0.5106051839889533, 0.5248715837658635, 0.5395223859166832, 0.5510486092713611, 0.5590752563151132, 0.5672107273520637, 0.5748596637493065, 0.5817545658135106, 0.5891970454072226, 0.5947394334950473, 0.600246787576839, 0.6049704279126472, 0.6090785044798255, 0.6123158468753358, 0.6172459445892328, 0.6213421866754495, 0.6246767371565431, 0.6285889021849757, 0.6315300226992947, 0.633584414761214, 0.6371479468215102, 0.6400772621573247, 0.6409853028842013, 0.6445173267824517, 0.6458234922353164, 0.6486801436601495, 0.6509598954831196, 0.6513407908355613, 0.6542954393749594, 0.6571154244515577, 0.6581188145689544, 0.6608893920489536, 0.6603658764560443, 0.6623783493078764, 0.6642639323744398, 0.6656741265940809, 0.6663069101756125, 0.6684049780322381, 0.6695656782978183, 0.6708414342928788, 0.6723408793722799, 0.6728373104284465, 0.6749500100590118, 0.6762402906729487, 0.6757783859893493, 0.6761658975377992, 0.6785284876019044, 0.6797312805940817, 0.6802495770402007, 0.6813061530589598, 0.6826146324751394, 0.6846440547184147, 0.6838669897458768, 0.6820882853111229, 0.6825231581909109, 0.6860635481819335, 0.6868839755737646, 0.68777550067749, 0.6885981636169629, 0.6883948161718311, 0.6891306541042795, 0.6909613652290901, 0.6916761309373854, 0.6927765377551024, 0.6928407036777817, 0.6927153318172387, 0.6941457537067679, 0.6951495820165531, 0.6970338941838485, 0.6966409777799782, 0.6953794110917576, 0.6963801074859975, 0.6971458930350555, 0.6982793213086067, 0.6973389110653437, 0.7002007606541097, 0.69998094498686, 0.6994360202489985, 0.70171099214028, 0.700983674466001]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.15s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.94s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.76s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:44,  1.85s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:59,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:43,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:19,  1.56s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:23,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:43,  1.67s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:30,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:54,  1.72s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:46,  1.70s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:03,  1.77s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:41,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:55,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:06,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:09,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:40,  1.72s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:41,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:28,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:33,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:53,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:29,  1.71s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:33,  1.73s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:15,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:32,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:43,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.73s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:31,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:34,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:44,  1.82s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:55,  1.87s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:30,  1.78s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:34,  1.80s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:37,  1.82s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:45,  1.86s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:16,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:14,  1.75s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:25,  1.80s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:05,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:48,  1.67s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:32,  1.61s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:43,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<06:55,  1.73s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:45,  1.69s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:54,  1.73s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:39,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:47,  1.72s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:57,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<06:59,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:44,  1.74s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<06:53,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:34,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:38,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:24,  1.68s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:30,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:42,  1.78s/it]predicting train subjects:  21%|██        | 60/285 [01:44<06:55,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:35,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:40,  1.80s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:51<06:22,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:22,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:27,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<06:11,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:07,  1.70s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:13,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:16,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:02,  1.70s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:01,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<05:56,  1.69s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<05:58,  1.71s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:01,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:44,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:50,  1.70s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:51,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:42,  1.68s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:43,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:41,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:35,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:42,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:42,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:29,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:33,  1.71s/it]predicting train subjects:  32%|███▏      | 91/285 [02:37<05:27,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:36,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:30,  1.72s/it]predicting train subjects:  33%|███▎      | 94/285 [02:42<05:27,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:30,  1.74s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:26,  1.73s/it]predicting train subjects:  34%|███▍      | 97/285 [02:47<05:22,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [02:49<05:15,  1.69s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:11,  1.67s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:14,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:03,  1.65s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:04,  1.66s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<04:54,  1.62s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<04:54,  1.63s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<04:56,  1.65s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<04:47,  1.61s/it]predicting train subjects:  38%|███▊      | 107/285 [03:03<04:51,  1.64s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<04:45,  1.61s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<04:54,  1.68s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<04:54,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:55,  1.71s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<04:58,  1.74s/it]predicting train subjects:  40%|████      | 114/285 [03:15<04:56,  1.73s/it]predicting train subjects:  40%|████      | 115/285 [03:17<04:53,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:55,  1.75s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:45,  1.70s/it]predicting train subjects:  41%|████▏     | 118/285 [03:22<04:37,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:43,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<04:34,  1.66s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:27,  1.63s/it]predicting train subjects:  43%|████▎     | 122/285 [03:28<04:15,  1.57s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:07,  1.53s/it]predicting train subjects:  44%|████▎     | 124/285 [03:31<04:09,  1.55s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<04:02,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:34<03:56,  1.49s/it]predicting train subjects:  45%|████▍     | 127/285 [03:36<03:49,  1.45s/it]predicting train subjects:  45%|████▍     | 128/285 [03:37<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:39<03:45,  1.45s/it]predicting train subjects:  46%|████▌     | 130/285 [03:40<03:39,  1.42s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<03:34,  1.39s/it]predicting train subjects:  46%|████▋     | 132/285 [03:43<03:41,  1.44s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:36,  1.43s/it]predicting train subjects:  47%|████▋     | 134/285 [03:46<03:32,  1.41s/it]predicting train subjects:  47%|████▋     | 135/285 [03:47<03:28,  1.39s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:25,  1.38s/it]predicting train subjects:  48%|████▊     | 137/285 [03:50<03:34,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [03:51<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:53<03:36,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:55<03:38,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [03:56<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:57<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [03:59<03:23,  1.43s/it]predicting train subjects:  51%|█████     | 144/285 [04:00<03:27,  1.47s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:26,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [04:03<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:06<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:09<03:16,  1.46s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:12<03:14,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:13<03:09,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:15<03:12,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:16<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:18<03:14,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:19<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:21<03:08,  1.49s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:22<03:04,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:24<02:58,  1.43s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:25<02:59,  1.45s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:27<02:58,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:28<03:01,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:30<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:31<02:52,  1.44s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:33<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:34<02:57,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:35<02:52,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:37<02:47,  1.44s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:38<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:40<02:41,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:41<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:42<02:34,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [04:44<02:33,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:45<02:38,  1.44s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:47<02:41,  1.48s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:48<02:35,  1.44s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:50<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:51<02:30,  1.42s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:53<02:40,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:54<02:39,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:56<02:41,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:57<02:33,  1.51s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:59<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:00<02:21,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:02<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:03<02:34,  1.57s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:05<02:39,  1.64s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:07<02:29,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:08<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:10<02:23,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:11<02:22,  1.54s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:12<02:15,  1.47s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:14<02:11,  1.44s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:15<02:06,  1.41s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:17<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:19<02:19,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:20<02:21,  1.62s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:22<02:10,  1.52s/it]predicting train subjects:  70%|███████   | 200/285 [05:23<02:05,  1.47s/it]predicting train subjects:  71%|███████   | 201/285 [05:25<02:10,  1.55s/it]predicting train subjects:  71%|███████   | 202/285 [05:26<02:09,  1.55s/it]predicting train subjects:  71%|███████   | 203/285 [05:28<02:07,  1.56s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:29<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:31<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:32<01:55,  1.46s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:34<02:00,  1.55s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:36<02:03,  1.61s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:37<02:07,  1.68s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:39<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:40<01:52,  1.52s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:42<01:52,  1.53s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:43<01:50,  1.54s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:45<01:44,  1.47s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:46<01:48,  1.55s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:48<01:42,  1.48s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:49<01:46,  1.57s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:51<01:49,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:53<01:50,  1.67s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:54<01:41,  1.56s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:56<01:36,  1.51s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:57<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:59<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:00<01:28,  1.46s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:01<01:25,  1.42s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:03<01:31,  1.55s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:05<01:36,  1.66s/it]predicting train subjects:  80%|████████  | 228/285 [06:07<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:09<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:10<01:26,  1.58s/it]predicting train subjects:  81%|████████  | 231/285 [06:11<01:22,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:13<01:22,  1.56s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:14<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:16<01:21,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:18<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:19<01:18,  1.60s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:21<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:23<01:19,  1.69s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:25<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:26<01:12,  1.61s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:27<01:09,  1.57s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:29<01:04,  1.49s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:30<01:00,  1.44s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:32<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:33<00:59,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:35<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:37<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:38<00:59,  1.62s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:40<00:54,  1.53s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:41<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:42<00:48,  1.43s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:44<00:47,  1.42s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:46<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:48<00:50,  1.64s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:49<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:50<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [06:52<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [06:54<00:42,  1.57s/it]predicting train subjects:  91%|█████████ | 259/285 [06:55<00:40,  1.58s/it]predicting train subjects:  91%|█████████ | 260/285 [06:57<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:58<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:59<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:01<00:31,  1.43s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:03<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:04<00:32,  1.65s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:06<00:29,  1.55s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:07<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:09<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:11<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:12<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:13<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:15<00:19,  1.53s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:16<00:17,  1.47s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:18<00:15,  1.44s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:19<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:21<00:14,  1.63s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:23<00:12,  1.52s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:24<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:26<00:09,  1.53s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:27<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:28<00:05,  1.45s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:30<00:04,  1.41s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:32<00:03,  1.55s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:33<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 285/285 [07:35<00:00,  1.67s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:40,  1.62s/it]Loading train:   1%|          | 2/285 [00:02<07:02,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<07:08,  1.52s/it]Loading train:   1%|▏         | 4/285 [00:05<06:27,  1.38s/it]Loading train:   2%|▏         | 5/285 [00:07<06:47,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:08<06:39,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<06:59,  1.51s/it]Loading train:   3%|▎         | 8/285 [00:11<06:39,  1.44s/it]Loading train:   3%|▎         | 9/285 [00:13<07:04,  1.54s/it]Loading train:   4%|▎         | 10/285 [00:14<06:30,  1.42s/it]Loading train:   4%|▍         | 11/285 [00:15<05:46,  1.26s/it]Loading train:   4%|▍         | 12/285 [00:16<05:33,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:04,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:18<04:50,  1.07s/it]Loading train:   5%|▌         | 15/285 [00:19<04:57,  1.10s/it]Loading train:   6%|▌         | 16/285 [00:20<05:01,  1.12s/it]Loading train:   6%|▌         | 17/285 [00:21<04:46,  1.07s/it]Loading train:   6%|▋         | 18/285 [00:22<04:51,  1.09s/it]Loading train:   7%|▋         | 19/285 [00:23<04:53,  1.10s/it]Loading train:   7%|▋         | 20/285 [00:24<04:54,  1.11s/it]Loading train:   7%|▋         | 21/285 [00:26<05:09,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:27<04:56,  1.13s/it]Loading train:   8%|▊         | 23/285 [00:28<04:57,  1.14s/it]Loading train:   8%|▊         | 24/285 [00:29<04:52,  1.12s/it]Loading train:   9%|▉         | 25/285 [00:30<05:04,  1.17s/it]Loading train:   9%|▉         | 26/285 [00:32<05:12,  1.21s/it]Loading train:   9%|▉         | 27/285 [00:32<04:46,  1.11s/it]Loading train:  10%|▉         | 28/285 [00:33<04:40,  1.09s/it]Loading train:  10%|█         | 29/285 [00:35<04:44,  1.11s/it]Loading train:  11%|█         | 30/285 [00:36<04:50,  1.14s/it]Loading train:  11%|█         | 31/285 [00:37<04:48,  1.13s/it]Loading train:  11%|█         | 32/285 [00:38<04:27,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:17,  1.02s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:14,  1.01s/it]Loading train:  12%|█▏        | 35/285 [00:41<04:20,  1.04s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:06,  1.01it/s]Loading train:  13%|█▎        | 37/285 [00:43<04:05,  1.01it/s]Loading train:  13%|█▎        | 38/285 [00:44<04:12,  1.02s/it]Loading train:  14%|█▎        | 39/285 [00:45<04:06,  1.00s/it]Loading train:  14%|█▍        | 40/285 [00:46<04:04,  1.00it/s]Loading train:  14%|█▍        | 41/285 [00:47<03:59,  1.02it/s]Loading train:  15%|█▍        | 42/285 [00:48<03:56,  1.03it/s]Loading train:  15%|█▌        | 43/285 [00:49<03:54,  1.03it/s]Loading train:  15%|█▌        | 44/285 [00:50<04:07,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:51<03:52,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:52<04:05,  1.03s/it]Loading train:  16%|█▋        | 47/285 [00:53<04:00,  1.01s/it]Loading train:  17%|█▋        | 48/285 [00:54<03:56,  1.00it/s]Loading train:  17%|█▋        | 49/285 [00:55<04:25,  1.12s/it]Loading train:  18%|█▊        | 50/285 [00:56<04:22,  1.12s/it]Loading train:  18%|█▊        | 51/285 [00:58<04:30,  1.16s/it]Loading train:  18%|█▊        | 52/285 [00:58<04:17,  1.11s/it]Loading train:  19%|█▊        | 53/285 [01:00<04:24,  1.14s/it]Loading train:  19%|█▉        | 54/285 [01:01<04:22,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:02<04:17,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:03<04:10,  1.09s/it]Loading train:  20%|██        | 57/285 [01:04<04:02,  1.06s/it]Loading train:  20%|██        | 58/285 [01:05<04:01,  1.06s/it]Loading train:  21%|██        | 59/285 [01:06<04:13,  1.12s/it]Loading train:  21%|██        | 60/285 [01:07<04:15,  1.14s/it]Loading train:  21%|██▏       | 61/285 [01:08<04:07,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:10<04:04,  1.10s/it]Loading train:  22%|██▏       | 63/285 [01:11<03:58,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:12<04:24,  1.20s/it]Loading train:  23%|██▎       | 65/285 [01:14<04:45,  1.30s/it]Loading train:  23%|██▎       | 66/285 [01:15<04:49,  1.32s/it]Loading train:  24%|██▎       | 67/285 [01:16<04:27,  1.23s/it]Loading train:  24%|██▍       | 68/285 [01:17<04:14,  1.17s/it]Loading train:  24%|██▍       | 69/285 [01:18<04:02,  1.12s/it]Loading train:  25%|██▍       | 70/285 [01:19<03:53,  1.08s/it]Loading train:  25%|██▍       | 71/285 [01:20<03:45,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:21<03:38,  1.02s/it]Loading train:  26%|██▌       | 73/285 [01:22<03:36,  1.02s/it]Loading train:  26%|██▌       | 74/285 [01:23<03:34,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:24<03:39,  1.04s/it]Loading train:  27%|██▋       | 76/285 [01:25<03:38,  1.05s/it]Loading train:  27%|██▋       | 77/285 [01:26<03:38,  1.05s/it]Loading train:  27%|██▋       | 78/285 [01:27<03:34,  1.03s/it]Loading train:  28%|██▊       | 79/285 [01:28<03:33,  1.04s/it]Loading train:  28%|██▊       | 80/285 [01:29<03:34,  1.04s/it]Loading train:  28%|██▊       | 81/285 [01:30<03:25,  1.01s/it]Loading train:  29%|██▉       | 82/285 [01:31<03:29,  1.03s/it]Loading train:  29%|██▉       | 83/285 [01:32<03:24,  1.01s/it]Loading train:  29%|██▉       | 84/285 [01:33<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:34<03:30,  1.05s/it]Loading train:  30%|███       | 86/285 [01:36<03:34,  1.08s/it]Loading train:  31%|███       | 87/285 [01:37<03:31,  1.07s/it]Loading train:  31%|███       | 88/285 [01:38<03:30,  1.07s/it]Loading train:  31%|███       | 89/285 [01:39<03:31,  1.08s/it]Loading train:  32%|███▏      | 90/285 [01:40<03:33,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:41<03:25,  1.06s/it]Loading train:  32%|███▏      | 92/285 [01:42<03:32,  1.10s/it]Loading train:  33%|███▎      | 93/285 [01:43<03:24,  1.07s/it]Loading train:  33%|███▎      | 94/285 [01:44<03:29,  1.10s/it]Loading train:  33%|███▎      | 95/285 [01:46<03:40,  1.16s/it]Loading train:  34%|███▎      | 96/285 [01:47<03:38,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:48<03:31,  1.12s/it]Loading train:  34%|███▍      | 98/285 [01:49<03:20,  1.07s/it]Loading train:  35%|███▍      | 99/285 [01:50<03:23,  1.09s/it]Loading train:  35%|███▌      | 100/285 [01:51<03:23,  1.10s/it]Loading train:  35%|███▌      | 101/285 [01:52<03:23,  1.11s/it]Loading train:  36%|███▌      | 102/285 [01:53<03:18,  1.09s/it]Loading train:  36%|███▌      | 103/285 [01:54<03:14,  1.07s/it]Loading train:  36%|███▋      | 104/285 [01:55<03:10,  1.05s/it]Loading train:  37%|███▋      | 105/285 [01:56<03:14,  1.08s/it]Loading train:  37%|███▋      | 106/285 [01:57<03:06,  1.04s/it]Loading train:  38%|███▊      | 107/285 [01:58<03:05,  1.04s/it]Loading train:  38%|███▊      | 108/285 [01:59<02:58,  1.01s/it]Loading train:  38%|███▊      | 109/285 [02:00<03:00,  1.03s/it]Loading train:  39%|███▊      | 110/285 [02:01<02:54,  1.00it/s]Loading train:  39%|███▉      | 111/285 [02:02<02:50,  1.02it/s]Loading train:  39%|███▉      | 112/285 [02:03<02:51,  1.01it/s]Loading train:  40%|███▉      | 113/285 [02:04<02:48,  1.02it/s]Loading train:  40%|████      | 114/285 [02:05<02:55,  1.03s/it]Loading train:  40%|████      | 115/285 [02:06<02:55,  1.03s/it]Loading train:  41%|████      | 116/285 [02:07<02:51,  1.02s/it]Loading train:  41%|████      | 117/285 [02:08<02:50,  1.01s/it]Loading train:  41%|████▏     | 118/285 [02:09<02:48,  1.01s/it]Loading train:  42%|████▏     | 119/285 [02:10<02:52,  1.04s/it]Loading train:  42%|████▏     | 120/285 [02:12<02:53,  1.05s/it]Loading train:  42%|████▏     | 121/285 [02:13<03:11,  1.16s/it]Loading train:  43%|████▎     | 122/285 [02:14<03:11,  1.18s/it]Loading train:  43%|████▎     | 123/285 [02:15<03:11,  1.18s/it]Loading train:  44%|████▎     | 124/285 [02:16<02:56,  1.10s/it]Loading train:  44%|████▍     | 125/285 [02:17<02:47,  1.05s/it]Loading train:  44%|████▍     | 126/285 [02:18<02:41,  1.01s/it]Loading train:  45%|████▍     | 127/285 [02:19<02:42,  1.03s/it]Loading train:  45%|████▍     | 128/285 [02:20<02:37,  1.01s/it]Loading train:  45%|████▌     | 129/285 [02:21<02:35,  1.00it/s]Loading train:  46%|████▌     | 130/285 [02:22<02:26,  1.06it/s]Loading train:  46%|████▌     | 131/285 [02:23<02:19,  1.11it/s]Loading train:  46%|████▋     | 132/285 [02:24<02:21,  1.08it/s]Loading train:  47%|████▋     | 133/285 [02:25<02:22,  1.07it/s]Loading train:  47%|████▋     | 134/285 [02:26<02:21,  1.07it/s]Loading train:  47%|████▋     | 135/285 [02:26<02:13,  1.13it/s]Loading train:  48%|████▊     | 136/285 [02:27<02:09,  1.15it/s]Loading train:  48%|████▊     | 137/285 [02:28<02:08,  1.15it/s]Loading train:  48%|████▊     | 138/285 [02:29<02:06,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:30<02:05,  1.16it/s]Loading train:  49%|████▉     | 140/285 [02:31<02:05,  1.16it/s]Loading train:  49%|████▉     | 141/285 [02:32<02:06,  1.14it/s]Loading train:  50%|████▉     | 142/285 [02:32<02:06,  1.13it/s]Loading train:  50%|█████     | 143/285 [02:33<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:34<01:59,  1.18it/s]Loading train:  51%|█████     | 145/285 [02:35<01:57,  1.20it/s]Loading train:  51%|█████     | 146/285 [02:36<01:58,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:37<01:55,  1.20it/s]Loading train:  52%|█████▏    | 148/285 [02:37<01:55,  1.19it/s]Loading train:  52%|█████▏    | 149/285 [02:38<01:50,  1.23it/s]Loading train:  53%|█████▎    | 150/285 [02:39<01:49,  1.23it/s]Loading train:  53%|█████▎    | 151/285 [02:40<01:49,  1.22it/s]Loading train:  53%|█████▎    | 152/285 [02:41<01:49,  1.22it/s]Loading train:  54%|█████▎    | 153/285 [02:41<01:46,  1.24it/s]Loading train:  54%|█████▍    | 154/285 [02:42<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:43<01:51,  1.16it/s]Loading train:  55%|█████▍    | 156/285 [02:44<01:55,  1.11it/s]Loading train:  55%|█████▌    | 157/285 [02:45<01:54,  1.12it/s]Loading train:  55%|█████▌    | 158/285 [02:46<02:00,  1.06it/s]Loading train:  56%|█████▌    | 159/285 [02:47<01:55,  1.09it/s]Loading train:  56%|█████▌    | 160/285 [02:48<01:55,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [02:49<01:53,  1.09it/s]Loading train:  57%|█████▋    | 162/285 [02:50<01:52,  1.09it/s]Loading train:  57%|█████▋    | 163/285 [02:51<01:54,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [02:52<01:53,  1.07it/s]Loading train:  58%|█████▊    | 165/285 [02:53<01:49,  1.09it/s]Loading train:  58%|█████▊    | 166/285 [02:53<01:48,  1.10it/s]Loading train:  59%|█████▊    | 167/285 [02:54<01:50,  1.07it/s]Loading train:  59%|█████▉    | 168/285 [02:55<01:43,  1.13it/s]Loading train:  59%|█████▉    | 169/285 [02:56<01:41,  1.14it/s]Loading train:  60%|█████▉    | 170/285 [02:57<01:37,  1.17it/s]Loading train:  60%|██████    | 171/285 [02:58<01:35,  1.19it/s]Loading train:  60%|██████    | 172/285 [02:59<01:37,  1.16it/s]Loading train:  61%|██████    | 173/285 [02:59<01:37,  1.15it/s]Loading train:  61%|██████    | 174/285 [03:00<01:34,  1.17it/s]Loading train:  61%|██████▏   | 175/285 [03:01<01:34,  1.17it/s]Loading train:  62%|██████▏   | 176/285 [03:02<01:35,  1.14it/s]Loading train:  62%|██████▏   | 177/285 [03:03<01:32,  1.16it/s]Loading train:  62%|██████▏   | 178/285 [03:04<01:31,  1.16it/s]Loading train:  63%|██████▎   | 179/285 [03:05<01:32,  1.14it/s]Loading train:  63%|██████▎   | 180/285 [03:06<01:35,  1.10it/s]Loading train:  64%|██████▎   | 181/285 [03:07<01:37,  1.07it/s]Loading train:  64%|██████▍   | 182/285 [03:08<01:36,  1.07it/s]Loading train:  64%|██████▍   | 183/285 [03:09<01:34,  1.08it/s]Loading train:  65%|██████▍   | 184/285 [03:09<01:30,  1.11it/s]Loading train:  65%|██████▍   | 185/285 [03:10<01:27,  1.14it/s]Loading train:  65%|██████▌   | 186/285 [03:11<01:30,  1.09it/s]Loading train:  66%|██████▌   | 187/285 [03:12<01:31,  1.07it/s]Loading train:  66%|██████▌   | 188/285 [03:13<01:32,  1.05it/s]Loading train:  66%|██████▋   | 189/285 [03:14<01:30,  1.06it/s]Loading train:  67%|██████▋   | 190/285 [03:15<01:24,  1.13it/s]Loading train:  67%|██████▋   | 191/285 [03:16<01:25,  1.10it/s]Loading train:  67%|██████▋   | 192/285 [03:17<01:23,  1.12it/s]Loading train:  68%|██████▊   | 193/285 [03:17<01:19,  1.16it/s]Loading train:  68%|██████▊   | 194/285 [03:18<01:16,  1.19it/s]Loading train:  68%|██████▊   | 195/285 [03:19<01:14,  1.21it/s]Loading train:  69%|██████▉   | 196/285 [03:20<01:21,  1.09it/s]Loading train:  69%|██████▉   | 197/285 [03:21<01:27,  1.01it/s]Loading train:  69%|██████▉   | 198/285 [03:22<01:27,  1.00s/it]Loading train:  70%|██████▉   | 199/285 [03:23<01:26,  1.00s/it]Loading train:  70%|███████   | 200/285 [03:24<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:25<01:24,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:26<01:24,  1.01s/it]Loading train:  71%|███████   | 203/285 [03:27<01:23,  1.02s/it]Loading train:  72%|███████▏  | 204/285 [03:28<01:19,  1.02it/s]Loading train:  72%|███████▏  | 205/285 [03:29<01:18,  1.02it/s]Loading train:  72%|███████▏  | 206/285 [03:30<01:14,  1.06it/s]Loading train:  73%|███████▎  | 207/285 [03:31<01:17,  1.01it/s]Loading train:  73%|███████▎  | 208/285 [03:32<01:17,  1.01s/it]Loading train:  73%|███████▎  | 209/285 [03:33<01:17,  1.03s/it]Loading train:  74%|███████▎  | 210/285 [03:34<01:10,  1.06it/s]Loading train:  74%|███████▍  | 211/285 [03:35<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:36<01:07,  1.07it/s]Loading train:  75%|███████▍  | 213/285 [03:37<01:09,  1.04it/s]Loading train:  75%|███████▌  | 214/285 [03:38<01:09,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [03:39<01:12,  1.03s/it]Loading train:  76%|███████▌  | 216/285 [03:40<01:06,  1.03it/s]Loading train:  76%|███████▌  | 217/285 [03:41<01:09,  1.03s/it]Loading train:  76%|███████▋  | 218/285 [03:42<01:08,  1.02s/it]Loading train:  77%|███████▋  | 219/285 [03:43<01:07,  1.03s/it]Loading train:  77%|███████▋  | 220/285 [03:44<01:02,  1.03it/s]Loading train:  78%|███████▊  | 221/285 [03:45<00:58,  1.10it/s]Loading train:  78%|███████▊  | 222/285 [03:46<01:00,  1.05it/s]Loading train:  78%|███████▊  | 223/285 [03:47<00:57,  1.09it/s]Loading train:  79%|███████▊  | 224/285 [03:48<00:57,  1.05it/s]Loading train:  79%|███████▉  | 225/285 [03:49<00:55,  1.08it/s]Loading train:  79%|███████▉  | 226/285 [03:50<01:00,  1.02s/it]Loading train:  80%|███████▉  | 227/285 [03:51<00:59,  1.03s/it]Loading train:  80%|████████  | 228/285 [03:52<00:59,  1.04s/it]Loading train:  80%|████████  | 229/285 [03:53<00:55,  1.00it/s]Loading train:  81%|████████  | 230/285 [03:54<00:55,  1.00s/it]Loading train:  81%|████████  | 231/285 [03:55<00:55,  1.04s/it]Loading train:  81%|████████▏ | 232/285 [03:56<00:54,  1.02s/it]Loading train:  82%|████████▏ | 233/285 [03:57<00:52,  1.00s/it]Loading train:  82%|████████▏ | 234/285 [03:58<00:54,  1.06s/it]Loading train:  82%|████████▏ | 235/285 [03:59<00:50,  1.01s/it]Loading train:  83%|████████▎ | 236/285 [04:00<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:01<00:51,  1.08s/it]Loading train:  84%|████████▎ | 238/285 [04:02<00:49,  1.05s/it]Loading train:  84%|████████▍ | 239/285 [04:03<00:46,  1.01s/it]Loading train:  84%|████████▍ | 240/285 [04:04<00:43,  1.03it/s]Loading train:  85%|████████▍ | 241/285 [04:05<00:41,  1.07it/s]Loading train:  85%|████████▍ | 242/285 [04:06<00:40,  1.07it/s]Loading train:  85%|████████▌ | 243/285 [04:07<00:39,  1.07it/s]Loading train:  86%|████████▌ | 244/285 [04:08<00:41,  1.00s/it]Loading train:  86%|████████▌ | 245/285 [04:09<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [04:10<00:37,  1.03it/s]Loading train:  87%|████████▋ | 247/285 [04:11<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [04:12<00:37,  1.00s/it]Loading train:  87%|████████▋ | 249/285 [04:13<00:35,  1.00it/s]Loading train:  88%|████████▊ | 250/285 [04:14<00:33,  1.04it/s]Loading train:  88%|████████▊ | 251/285 [04:15<00:31,  1.07it/s]Loading train:  88%|████████▊ | 252/285 [04:15<00:29,  1.13it/s]Loading train:  89%|████████▉ | 253/285 [04:16<00:29,  1.09it/s]Loading train:  89%|████████▉ | 254/285 [04:17<00:29,  1.05it/s]Loading train:  89%|████████▉ | 255/285 [04:18<00:28,  1.04it/s]Loading train:  90%|████████▉ | 256/285 [04:19<00:26,  1.10it/s]Loading train:  90%|█████████ | 257/285 [04:20<00:25,  1.12it/s]Loading train:  91%|█████████ | 258/285 [04:21<00:24,  1.10it/s]Loading train:  91%|█████████ | 259/285 [04:22<00:24,  1.08it/s]Loading train:  91%|█████████ | 260/285 [04:23<00:21,  1.15it/s]Loading train:  92%|█████████▏| 261/285 [04:24<00:20,  1.14it/s]Loading train:  92%|█████████▏| 262/285 [04:24<00:18,  1.21it/s]Loading train:  92%|█████████▏| 263/285 [04:25<00:18,  1.22it/s]Loading train:  93%|█████████▎| 264/285 [04:26<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:27<00:18,  1.06it/s]Loading train:  93%|█████████▎| 266/285 [04:28<00:17,  1.07it/s]Loading train:  94%|█████████▎| 267/285 [04:29<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [04:30<00:17,  1.03s/it]Loading train:  94%|█████████▍| 269/285 [04:31<00:16,  1.02s/it]Loading train:  95%|█████████▍| 270/285 [04:32<00:14,  1.02it/s]Loading train:  95%|█████████▌| 271/285 [04:33<00:14,  1.00s/it]Loading train:  95%|█████████▌| 272/285 [04:34<00:13,  1.01s/it]Loading train:  96%|█████████▌| 273/285 [04:35<00:11,  1.01it/s]Loading train:  96%|█████████▌| 274/285 [04:36<00:11,  1.02s/it]Loading train:  96%|█████████▋| 275/285 [04:38<00:10,  1.06s/it]Loading train:  97%|█████████▋| 276/285 [04:38<00:09,  1.03s/it]Loading train:  97%|█████████▋| 277/285 [04:39<00:07,  1.01it/s]Loading train:  98%|█████████▊| 278/285 [04:40<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:41<00:05,  1.05it/s]Loading train:  98%|█████████▊| 280/285 [04:42<00:04,  1.07it/s]Loading train:  99%|█████████▊| 281/285 [04:43<00:03,  1.09it/s]Loading train:  99%|█████████▉| 282/285 [04:44<00:02,  1.11it/s]Loading train:  99%|█████████▉| 283/285 [04:45<00:02,  1.00s/it]Loading train: 100%|█████████▉| 284/285 [04:46<00:01,  1.04s/it]Loading train: 100%|██████████| 285/285 [04:47<00:00,  1.05s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:01, 255.35it/s]concatenating: train:  19%|█▊        | 53/285 [00:00<00:00, 259.46it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:00, 265.69it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 273.07it/s]concatenating: train:  49%|████▉     | 140/285 [00:00<00:00, 273.39it/s]concatenating: train:  60%|██████    | 172/285 [00:00<00:00, 284.39it/s]concatenating: train:  71%|███████   | 202/285 [00:00<00:00, 288.02it/s]concatenating: train:  80%|████████  | 229/285 [00:00<00:00, 278.61it/s]concatenating: train:  90%|████████▉ | 256/285 [00:00<00:00, 254.84it/s]concatenating: train:  99%|█████████▊| 281/285 [00:01<00:00, 240.80it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 266.26it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.47s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.36s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 214.69it/s]2019-07-10 22:10:21.788153: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:10:21.788259: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:10:21.788275: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:10:21.788302: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:10:21.788721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.93it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.59it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.17it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.12it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.94it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.02it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.75it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.21it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.78it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.48it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.83it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.94it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.13it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.71it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.74it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  8.88it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.04it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.99it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 231,413
Trainable params: 56,653
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 18s - loss: 2.2549 - acc: 0.7105 - mDice: 0.1687 - val_loss: 5.5310 - val_acc: 0.9136 - val_mDice: 0.0370

Epoch 00001: val_mDice improved from -inf to 0.03701, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.8435 - acc: 0.8955 - mDice: 0.4133 - val_loss: 0.7378 - val_acc: 0.9188 - val_mDice: 0.4917

Epoch 00002: val_mDice improved from 0.03701 to 0.49166, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6691 - acc: 0.9022 - mDice: 0.4946 - val_loss: 0.6437 - val_acc: 0.9214 - val_mDice: 0.5152

Epoch 00003: val_mDice improved from 0.49166 to 0.51521, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5843 - acc: 0.9105 - mDice: 0.5402 - val_loss: 0.6086 - val_acc: 0.9323 - val_mDice: 0.5355

Epoch 00004: val_mDice improved from 0.51521 to 0.53551, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5378 - acc: 0.9196 - mDice: 0.5674 - val_loss: 0.5381 - val_acc: 0.9458 - val_mDice: 0.5789

Epoch 00005: val_mDice improved from 0.53551 to 0.57887, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.5023 - acc: 0.9289 - mDice: 0.5886 - val_loss: 0.5174 - val_acc: 0.9475 - val_mDice: 0.5879

Epoch 00006: val_mDice improved from 0.57887 to 0.58790, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4748 - acc: 0.9335 - mDice: 0.6057 - val_loss: 0.5743 - val_acc: 0.9458 - val_mDice: 0.5638

Epoch 00007: val_mDice did not improve from 0.58790
Epoch 8/300
 - 13s - loss: 0.4535 - acc: 0.9361 - mDice: 0.6192 - val_loss: 0.5593 - val_acc: 0.9477 - val_mDice: 0.5669

Epoch 00008: val_mDice did not improve from 0.58790
Epoch 9/300
 - 13s - loss: 0.4361 - acc: 0.9377 - mDice: 0.6305 - val_loss: 0.4860 - val_acc: 0.9478 - val_mDice: 0.6043

Epoch 00009: val_mDice improved from 0.58790 to 0.60432, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.4259 - acc: 0.9390 - mDice: 0.6376 - val_loss: 0.5126 - val_acc: 0.9485 - val_mDice: 0.5901

Epoch 00010: val_mDice did not improve from 0.60432
Epoch 11/300
 - 14s - loss: 0.4117 - acc: 0.9401 - mDice: 0.6470 - val_loss: 0.5100 - val_acc: 0.9481 - val_mDice: 0.5938

Epoch 00011: val_mDice did not improve from 0.60432
Epoch 12/300
 - 14s - loss: 0.4038 - acc: 0.9409 - mDice: 0.6523 - val_loss: 0.5103 - val_acc: 0.9493 - val_mDice: 0.5950

Epoch 00012: val_mDice did not improve from 0.60432
Epoch 13/300
 - 14s - loss: 0.3934 - acc: 0.9419 - mDice: 0.6594 - val_loss: 0.4840 - val_acc: 0.9494 - val_mDice: 0.6065

Epoch 00013: val_mDice improved from 0.60432 to 0.60646, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 14s - loss: 0.3883 - acc: 0.9426 - mDice: 0.6631 - val_loss: 0.4905 - val_acc: 0.9496 - val_mDice: 0.6034

Epoch 00014: val_mDice did not improve from 0.60646
Epoch 15/300
 - 13s - loss: 0.3774 - acc: 0.9434 - mDice: 0.6704 - val_loss: 0.5055 - val_acc: 0.9506 - val_mDice: 0.5988

Epoch 00015: val_mDice did not improve from 0.60646
Epoch 16/300
 - 13s - loss: 0.3670 - acc: 0.9438 - mDice: 0.6777 - val_loss: 0.4928 - val_acc: 0.9456 - val_mDice: 0.6020

Epoch 00016: val_mDice did not improve from 0.60646
Epoch 17/300
 - 14s - loss: 0.3560 - acc: 0.9444 - mDice: 0.6858 - val_loss: 0.4968 - val_acc: 0.9481 - val_mDice: 0.6004

Epoch 00017: val_mDice did not improve from 0.60646
Epoch 18/300
 - 14s - loss: 0.3499 - acc: 0.9448 - mDice: 0.6901 - val_loss: 0.5126 - val_acc: 0.9471 - val_mDice: 0.5907

Epoch 00018: val_mDice did not improve from 0.60646
Epoch 19/300
 - 13s - loss: 0.3458 - acc: 0.9452 - mDice: 0.6931 - val_loss: 0.5223 - val_acc: 0.9437 - val_mDice: 0.5864

Epoch 00019: val_mDice did not improve from 0.60646
Epoch 20/300
 - 13s - loss: 0.3401 - acc: 0.9457 - mDice: 0.6972 - val_loss: 0.4847 - val_acc: 0.9496 - val_mDice: 0.6058

Epoch 00020: val_mDice did not improve from 0.60646
Epoch 21/300
 - 14s - loss: 0.3383 - acc: 0.9462 - mDice: 0.6987 - val_loss: 0.5357 - val_acc: 0.9468 - val_mDice: 0.5861

Epoch 00021: val_mDice did not improve from 0.60646
Epoch 22/300
 - 14s - loss: 0.3340 - acc: 0.9466 - mDice: 0.7018 - val_loss: 0.4919 - val_acc: 0.9482 - val_mDice: 0.6014

Epoch 00022: val_mDice did not improve from 0.60646
Epoch 23/300
 - 13s - loss: 0.3288 - acc: 0.9470 - mDice: 0.7055 - val_loss: 0.5000 - val_acc: 0.9462 - val_mDice: 0.5992

Epoch 00023: val_mDice did not improve from 0.60646
Epoch 24/300
 - 14s - loss: 0.3246 - acc: 0.9473 - mDice: 0.7088 - val_loss: 0.5204 - val_acc: 0.9496 - val_mDice: 0.5846

Epoch 00024: val_mDice did not improve from 0.60646
Epoch 25/300
 - 13s - loss: 0.3212 - acc: 0.9475 - mDice: 0.7112 - val_loss: 0.5030 - val_acc: 0.9504 - val_mDice: 0.5981

Epoch 00025: val_mDice did not improve from 0.60646
Epoch 26/300
 - 13s - loss: 0.3196 - acc: 0.9476 - mDice: 0.7125 - val_loss: 0.5358 - val_acc: 0.9477 - val_mDice: 0.5810

Epoch 00026: val_mDice did not improve from 0.60646
Epoch 27/300
 - 13s - loss: 0.3194 - acc: 0.9476 - mDice: 0.7128 - val_loss: 0.5443 - val_acc: 0.9489 - val_mDice: 0.5749

Epoch 00027: val_mDice did not improve from 0.60646
Epoch 28/300
 - 13s - loss: 0.3141 - acc: 0.9479 - mDice: 0.7166 - val_loss: 0.4948 - val_acc: 0.9483 - val_mDice: 0.6001

Epoch 00028: val_mDice did not improve from 0.60646
Epoch 29/300
 - 13s - loss: 0.3116 - acc: 0.9481 - mDice: 0.7185 - val_loss: 0.5230 - val_acc: 0.9497 - val_mDice: 0.5864

Epoch 00029: val_mDice did not improve from 0.60646
Epoch 30/300
 - 13s - loss: 0.3077 - acc: 0.9484 - mDice: 0.7214 - val_loss: 0.5033 - val_acc: 0.9485 - val_mDice: 0.5950

Epoch 00030: val_mDice did not improve from 0.60646
Epoch 31/300
 - 13s - loss: 0.3061 - acc: 0.9486 - mDice: 0.7227 - val_loss: 0.5287 - val_acc: 0.9487 - val_mDice: 0.5841

Epoch 00031: val_mDice did not improve from 0.60646
Epoch 32/300
 - 13s - loss: 0.3051 - acc: 0.9488 - mDice: 0.7233 - val_loss: 0.4962 - val_acc: 0.9500 - val_mDice: 0.6001

Epoch 00032: val_mDice did not improve from 0.60646
Epoch 33/300
 - 13s - loss: 0.3033 - acc: 0.9490 - mDice: 0.7248 - val_loss: 0.4820 - val_acc: 0.9499 - val_mDice: 0.6088

Epoch 00033: val_mDice improved from 0.60646 to 0.60876, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 13s - loss: 0.3020 - acc: 0.9491 - mDice: 0.7257 - val_loss: 0.5263 - val_acc: 0.9487 - val_mDice: 0.5869

Epoch 00034: val_mDice did not improve from 0.60876
Epoch 35/300
 - 13s - loss: 0.3007 - acc: 0.9492 - mDice: 0.7268 - val_loss: 0.5483 - val_acc: 0.9482 - val_mDice: 0.5781

Epoch 00035: val_mDice did not improve from 0.60876
Epoch 36/300
 - 13s - loss: 0.2975 - acc: 0.9493 - mDice: 0.7290 - val_loss: 0.4991 - val_acc: 0.9497 - val_mDice: 0.5975

Epoch 00036: val_mDice did not improve from 0.60876
Epoch 37/300
 - 13s - loss: 0.2951 - acc: 0.9496 - mDice: 0.7310 - val_loss: 0.5210 - val_acc: 0.9497 - val_mDice: 0.5895

Epoch 00037: val_mDice did not improve from 0.60876
Epoch 38/300
 - 13s - loss: 0.2924 - acc: 0.9498 - mDice: 0.7330 - val_loss: 0.5191 - val_acc: 0.9482 - val_mDice: 0.5917

Epoch 00038: val_mDice did not improve from 0.60876
Epoch 39/300
 - 13s - loss: 0.2905 - acc: 0.9500 - mDice: 0.7344 - val_loss: 0.5430 - val_acc: 0.9497 - val_mDice: 0.5890

Epoch 00039: val_mDice did not improve from 0.60876
Epoch 40/300
 - 12s - loss: 0.2921 - acc: 0.9499 - mDice: 0.7333 - val_loss: 0.5075 - val_acc: 0.9499 - val_mDice: 0.6004

Epoch 00040: val_mDice did not improve from 0.60876
Epoch 41/300
 - 13s - loss: 0.2892 - acc: 0.9501 - mDice: 0.7357 - val_loss: 0.5509 - val_acc: 0.9482 - val_mDice: 0.5773

Epoch 00041: val_mDice did not improve from 0.60876
Epoch 42/300
 - 12s - loss: 0.2871 - acc: 0.9502 - mDice: 0.7370 - val_loss: 0.4928 - val_acc: 0.9504 - val_mDice: 0.6039

Epoch 00042: val_mDice did not improve from 0.60876
Epoch 43/300
 - 13s - loss: 0.2875 - acc: 0.9504 - mDice: 0.7369 - val_loss: 0.4944 - val_acc: 0.9503 - val_mDice: 0.6014

Epoch 00043: val_mDice did not improve from 0.60876
Epoch 44/300
 - 13s - loss: 0.2864 - acc: 0.9506 - mDice: 0.7377 - val_loss: 0.5198 - val_acc: 0.9495 - val_mDice: 0.5913

Epoch 00044: val_mDice did not improve from 0.60876
Epoch 45/300
 - 13s - loss: 0.2831 - acc: 0.9505 - mDice: 0.7401 - val_loss: 0.5094 - val_acc: 0.9497 - val_mDice: 0.5941

Epoch 00045: val_mDice did not improve from 0.60876
Epoch 46/300
 - 13s - loss: 0.2825 - acc: 0.9507 - mDice: 0.7406 - val_loss: 0.5147 - val_acc: 0.9503 - val_mDice: 0.5958

Epoch 00046: val_mDice did not improve from 0.60876
Epoch 47/300
 - 12s - loss: 0.2818 - acc: 0.9508 - mDice: 0.7412 - val_loss: 0.4911 - val_acc: 0.9491 - val_mDice: 0.6021

Epoch 00047: val_mDice did not improve from 0.60876
Epoch 48/300
 - 13s - loss: 0.2799 - acc: 0.9510 - mDice: 0.7427 - val_loss: 0.4902 - val_acc: 0.9509 - val_mDice: 0.6022

Epoch 00048: val_mDice did not improve from 0.60876
Epoch 49/300
 - 13s - loss: 0.2796 - acc: 0.9510 - mDice: 0.7429 - val_loss: 0.5110 - val_acc: 0.9488 - val_mDice: 0.5959

Epoch 00049: val_mDice did not improve from 0.60876
Epoch 50/300
 - 13s - loss: 0.2762 - acc: 0.9513 - mDice: 0.7454 - val_loss: 0.5370 - val_acc: 0.9488 - val_mDice: 0.5795

Epoch 00050: val_mDice did not improve from 0.60876
Epoch 51/300
 - 13s - loss: 0.2775 - acc: 0.9513 - mDice: 0.7445 - val_loss: 0.5118 - val_acc: 0.9494 - val_mDice: 0.5931

Epoch 00051: val_mDice did not improve from 0.60876
Epoch 52/300
 - 13s - loss: 0.2774 - acc: 0.9513 - mDice: 0.7446 - val_loss: 0.5179 - val_acc: 0.9502 - val_mDice: 0.5920

Epoch 00052: val_mDice did not improve from 0.60876
Epoch 53/300
 - 13s - loss: 0.2763 - acc: 0.9514 - mDice: 0.7454 - val_loss: 0.4928 - val_acc: 0.9511 - val_mDice: 0.6041

Epoch 00053: val_mDice did not improve from 0.60876
Epoch 54/300
 - 13s - loss: 0.2737 - acc: 0.9516 - mDice: 0.7474 - val_loss: 0.5165 - val_acc: 0.9490 - val_mDice: 0.5936

Epoch 00054: val_mDice did not improve from 0.60876
Epoch 55/300
 - 13s - loss: 0.2726 - acc: 0.9516 - mDice: 0.7484 - val_loss: 0.5306 - val_acc: 0.9483 - val_mDice: 0.5819

Epoch 00055: val_mDice did not improve from 0.60876
Epoch 56/300
 - 13s - loss: 0.2726 - acc: 0.9518 - mDice: 0.7484 - val_loss: 0.5010 - val_acc: 0.9495 - val_mDice: 0.5970

Epoch 00056: val_mDice did not improve from 0.60876
Epoch 57/300
 - 13s - loss: 0.2707 - acc: 0.9519 - mDice: 0.7499 - val_loss: 0.4856 - val_acc: 0.9499 - val_mDice: 0.6074

Epoch 00057: val_mDice did not improve from 0.60876
Epoch 58/300
 - 13s - loss: 0.2706 - acc: 0.9520 - mDice: 0.7498 - val_loss: 0.5391 - val_acc: 0.9455 - val_mDice: 0.5806

Epoch 00058: val_mDice did not improve from 0.60876
Epoch 59/300
 - 13s - loss: 0.2699 - acc: 0.9520 - mDice: 0.7504 - val_loss: 0.5328 - val_acc: 0.9493 - val_mDice: 0.5876

Epoch 00059: val_mDice did not improve from 0.60876
Epoch 60/300
 - 13s - loss: 0.2702 - acc: 0.9520 - mDice: 0.7502 - val_loss: 0.5024 - val_acc: 0.9477 - val_mDice: 0.5991

Epoch 00060: val_mDice did not improve from 0.60876
Epoch 61/300
 - 13s - loss: 0.2691 - acc: 0.9520 - mDice: 0.7511 - val_loss: 0.5018 - val_acc: 0.9504 - val_mDice: 0.5999

Epoch 00061: val_mDice did not improve from 0.60876
Epoch 62/300
 - 13s - loss: 0.2666 - acc: 0.9522 - mDice: 0.7530 - val_loss: 0.5269 - val_acc: 0.9465 - val_mDice: 0.5851

Epoch 00062: val_mDice did not improve from 0.60876
Epoch 63/300
 - 13s - loss: 0.2691 - acc: 0.9520 - mDice: 0.7515 - val_loss: 0.5239 - val_acc: 0.9497 - val_mDice: 0.5919

Epoch 00063: val_mDice did not improve from 0.60876
Epoch 64/300
 - 14s - loss: 0.2673 - acc: 0.9522 - mDice: 0.7526 - val_loss: 0.4896 - val_acc: 0.9505 - val_mDice: 0.6030

Epoch 00064: val_mDice did not improve from 0.60876
Epoch 65/300
 - 13s - loss: 0.2645 - acc: 0.9524 - mDice: 0.7546 - val_loss: 0.5145 - val_acc: 0.9498 - val_mDice: 0.5931

Epoch 00065: val_mDice did not improve from 0.60876
Epoch 66/300
 - 13s - loss: 0.2655 - acc: 0.9524 - mDice: 0.7538 - val_loss: 0.4841 - val_acc: 0.9495 - val_mDice: 0.6063

Epoch 00066: val_mDice did not improve from 0.60876
Epoch 67/300
 - 13s - loss: 0.2637 - acc: 0.9524 - mDice: 0.7553 - val_loss: 0.4955 - val_acc: 0.9506 - val_mDice: 0.6015

Epoch 00067: val_mDice did not improve from 0.60876
Epoch 68/300
 - 13s - loss: 0.2626 - acc: 0.9526 - mDice: 0.7561 - val_loss: 0.5064 - val_acc: 0.9492 - val_mDice: 0.5969

Epoch 00068: val_mDice did not improve from 0.60876
Epoch 69/300
 - 13s - loss: 0.2617 - acc: 0.9527 - mDice: 0.7568 - val_loss: 0.5313 - val_acc: 0.9470 - val_mDice: 0.5838

Epoch 00069: val_mDice did not improve from 0.60876
Epoch 70/300
 - 13s - loss: 0.2607 - acc: 0.9527 - mDice: 0.7577 - val_loss: 0.5017 - val_acc: 0.9503 - val_mDice: 0.5984

Epoch 00070: val_mDice did not improve from 0.60876
Epoch 71/300
 - 13s - loss: 0.2608 - acc: 0.9528 - mDice: 0.7576 - val_loss: 0.4922 - val_acc: 0.9505 - val_mDice: 0.6045

Epoch 00071: val_mDice did not improve from 0.60876
Epoch 72/300
 - 13s - loss: 0.2617 - acc: 0.9528 - mDice: 0.7570 - val_loss: 0.5064 - val_acc: 0.9488 - val_mDice: 0.5949

Epoch 00072: val_mDice did not improve from 0.60876
Epoch 73/300
 - 13s - loss: 0.2589 - acc: 0.9529 - mDice: 0.7591 - val_loss: 0.5074 - val_acc: 0.9520 - val_mDice: 0.5966

Epoch 00073: val_mDice did not improve from 0.60876
Restoring model weights from the end of the best epoch
Epoch 00073: early stopping
{'val_loss': [5.531015649188165, 0.7378283878944439, 0.6436698143708639, 0.6085897997104922, 0.5381000315010881, 0.517421233254438, 0.5743432760904621, 0.5592793222912197, 0.4860157780141138, 0.5125758155098175, 0.509974680133372, 0.5103388045753181, 0.48400894223644747, 0.4904976503809071, 0.5054736010855136, 0.4927517402105491, 0.49675782466067947, 0.5125915121765776, 0.5223482817244929, 0.48468089070400044, 0.535656967642587, 0.4918983472126156, 0.49999710268148495, 0.5203790628044299, 0.5029868683335501, 0.5358395809567841, 0.5442613220081649, 0.49484247335508547, 0.5229732627309235, 0.5033079245902973, 0.5286508352396875, 0.49618716746069197, 0.4819819337828865, 0.526266102018303, 0.5482852615457673, 0.49908959232895067, 0.5209705596529571, 0.5190620865235781, 0.5430213972176919, 0.5074580921141129, 0.5508748878979816, 0.4927901056225739, 0.49444826221998844, 0.5198073390475865, 0.5094499351592038, 0.5146706836849617, 0.49108278718074605, 0.49024773876094285, 0.5109698885645946, 0.5369520603611483, 0.5118266077680961, 0.5178609377179066, 0.4927862806027162, 0.51650793392565, 0.5305883984325984, 0.5010186407153167, 0.4855768101175404, 0.539116832131114, 0.5328066918437041, 0.5024167782101552, 0.5017651812324311, 0.5269308866069303, 0.5238811666739054, 0.48957694509175903, 0.5144799101952068, 0.4840922602062119, 0.4955089252088323, 0.5063900637893037, 0.5313469571108259, 0.5016743667298855, 0.4921882921756979, 0.5064439277409175, 0.5074282974504226], 'val_acc': [0.9136185566140287, 0.9187753943091664, 0.9214137363034254, 0.9323121768802238, 0.9458426789864481, 0.9475244580034438, 0.9458282623211098, 0.9476752594196597, 0.9477889314710095, 0.9484748357501109, 0.9480512971318634, 0.9493487960133473, 0.9493714880676909, 0.9496442372572489, 0.9506276659459375, 0.9456174956353683, 0.9481008845334612, 0.9470947195031789, 0.9436816106961426, 0.9495533018804795, 0.9468405965986199, 0.9482083330607282, 0.9462248962684716, 0.9495987615771799, 0.9504024476312393, 0.9476649584716925, 0.9488983766992665, 0.9482723764201116, 0.9496504204899239, 0.9484562700687174, 0.9487289556577885, 0.9500099057591828, 0.9498735373246603, 0.9486711288297642, 0.9481980071387477, 0.9497103354784363, 0.9496710963089373, 0.9482455190333574, 0.9497351293457287, 0.9498508492661588, 0.9481628667042908, 0.9504252192694381, 0.9502847277918341, 0.9494830822811446, 0.9497475021378288, 0.9502908760608908, 0.9491132744197739, 0.9508590591686398, 0.9487950735251997, 0.9487599597296901, 0.9493735565819554, 0.9502309747248389, 0.9510594906087694, 0.9489975448427254, 0.9482661558929102, 0.9495388622390492, 0.9498653042249839, 0.9455162829526976, 0.9492909428793624, 0.9476566874115161, 0.9503983292499734, 0.9465203741409259, 0.9497413122454169, 0.950540867930684, 0.9497826522289041, 0.9495202402828792, 0.9505780682217475, 0.9491731587734968, 0.9470099989928347, 0.9502723100465104, 0.9504830234543571, 0.9487950901745418, 0.9520243253121828], 'val_mDice': [0.03701273976258059, 0.49165972251465867, 0.5152071702746706, 0.5355081861245565, 0.5788705302350348, 0.5879019831811916, 0.5637998973857091, 0.5669411593975302, 0.6043178049545714, 0.5901200724713629, 0.593835741115016, 0.5949557596744772, 0.6064614706865236, 0.6033951640129089, 0.598769825930036, 0.602014519648845, 0.60041653776968, 0.5907407256478038, 0.5864084163191599, 0.605839649059253, 0.5861087424795055, 0.6014300052014143, 0.5991930325604018, 0.5846354941416053, 0.5980733712958224, 0.5809745748615798, 0.5749232948825346, 0.6000578190361321, 0.5863692833724634, 0.5950180578498201, 0.5840693509112523, 0.6001387175235002, 0.6087641862517629, 0.586921597326268, 0.5780826663837753, 0.5974753948563304, 0.5894744369570769, 0.5917407713788848, 0.5890216344561656, 0.6003542825496396, 0.5773423377362044, 0.6038705573401637, 0.6013596410857899, 0.5912834392579575, 0.5940897038529039, 0.5958120466610572, 0.6020658449087729, 0.6021708706237751, 0.5959383122747837, 0.5794650652555114, 0.5931394106848946, 0.5920395804517096, 0.6040624686459589, 0.5936401749456395, 0.5818604071047053, 0.5969533031213217, 0.6074054893834631, 0.5805897256515545, 0.587555056177704, 0.5991264585010166, 0.5998839476255066, 0.5850895583296621, 0.5919023425885419, 0.6029656759187496, 0.5931220554106729, 0.6062773366214177, 0.6015330373241915, 0.5968705961824129, 0.5837586612008804, 0.5984108464677906, 0.6045187132318592, 0.5948518354799495, 0.5965853709748338], 'loss': [2.2548895823229023, 0.8434519220635974, 0.6690839960985302, 0.5843177096275364, 0.537765942188099, 0.5022680715215823, 0.47481064700747905, 0.45352746248180315, 0.43607099242189873, 0.42592553105121095, 0.41166520874118906, 0.4038236514752379, 0.39335211753734844, 0.38825504625358453, 0.37744153586194107, 0.36701898101264174, 0.35597561873496797, 0.34988394193767197, 0.3457686988822801, 0.34010213288234525, 0.33827867781627047, 0.3339595549016741, 0.32881612379490816, 0.3245930804788699, 0.3212052556149912, 0.31963871599191623, 0.31939667026030916, 0.31407747942081665, 0.31159779725981906, 0.30771393085881704, 0.30608971744741686, 0.3051004336245939, 0.30329789098983795, 0.3020069858398217, 0.30071452184379455, 0.2975145588691286, 0.29506120166385896, 0.29241766640254535, 0.2904813741976695, 0.2921059293627096, 0.2892194066644462, 0.28705798513547415, 0.28750840372707087, 0.2863533882886118, 0.2831490959946376, 0.28254013152159113, 0.281798955103611, 0.27988854026127, 0.27959482148058384, 0.2762473419184493, 0.2775154518562363, 0.27742819030244237, 0.2762801766973404, 0.273692522285408, 0.2725809288306678, 0.27255761977225296, 0.27069990794699306, 0.2705921575733016, 0.26988018076343606, 0.27022161127357375, 0.2691277627758676, 0.2665504946648169, 0.2691084410161158, 0.26728522625794554, 0.2645374803584383, 0.2655257904937302, 0.2636735799213775, 0.26262855315531763, 0.26174447410156393, 0.26070221142015465, 0.26080721855507677, 0.2616569593586918, 0.2589351271879867], 'acc': [0.7105155036467742, 0.8955372233489755, 0.9022324765977059, 0.9104729278480673, 0.9195909944113534, 0.928906547345404, 0.9334758418680608, 0.9360956978865435, 0.9377161420012967, 0.9389676885059226, 0.9401136512531966, 0.9409479237668856, 0.9418809087595501, 0.9425872404372392, 0.9434021341178056, 0.943830045234611, 0.9443640609068273, 0.9448457563191572, 0.9451738605474077, 0.9456829050807715, 0.9462122477468897, 0.946649971075044, 0.9469872434624503, 0.9472697510788639, 0.9474785199846281, 0.9475954022356111, 0.9475877287340971, 0.947946955403772, 0.9481230545138736, 0.9484060469175448, 0.9486408986126466, 0.9487642471933538, 0.948963148269536, 0.9490900002957611, 0.9491563071729856, 0.9493463230797892, 0.9495565829846563, 0.9498300666084776, 0.9499958539202572, 0.9499437669141445, 0.9501466763109808, 0.9502249893640409, 0.9504025150121904, 0.95055080050964, 0.9504986103567499, 0.9507151577092354, 0.9507686926332878, 0.9509733952823324, 0.9509851365598171, 0.9513060968397853, 0.9512915317837329, 0.9512543088080518, 0.9513674663774108, 0.9515783507075616, 0.9516108572713547, 0.9517551955168598, 0.9519398573547218, 0.9519690200430811, 0.951988801029823, 0.9519736950358926, 0.9520265654530454, 0.9522305825204477, 0.9520408663151863, 0.9522440747740507, 0.952426379198057, 0.9523930627466982, 0.9523846651044237, 0.9526032220725822, 0.9526900725033306, 0.952744034694097, 0.9527587159209363, 0.9527644963671157, 0.9529065584949429], 'mDice': [0.16874559530829572, 0.41334173197736146, 0.4946186589744121, 0.5401739942976206, 0.5674401893477302, 0.588597115864714, 0.6056687843110734, 0.6191549627916348, 0.630493432203868, 0.6376299606150748, 0.6469677448415541, 0.6522677219691188, 0.6594368667717068, 0.6631314847134445, 0.6704498966576051, 0.677700427809375, 0.6857967088148619, 0.690110350419971, 0.6930955928509859, 0.6971599723861521, 0.6987245351451069, 0.7017637233213171, 0.7055083855675766, 0.7087658801620793, 0.7111621785349566, 0.7125134131116458, 0.7128242724348625, 0.7165569485185012, 0.7185391844322034, 0.7213536259084152, 0.7226596982590378, 0.7232548418235145, 0.7248057660554776, 0.7256791456210172, 0.7267584636264505, 0.7290148617629034, 0.7309645536996253, 0.7330138395927381, 0.7344415775539244, 0.7333279951654562, 0.7357431153678198, 0.7370217522825072, 0.736902360926266, 0.7377219681944711, 0.7400824826473076, 0.7405515084157068, 0.7412117151099673, 0.7426550511402032, 0.7428950335840392, 0.7453988292600184, 0.7445264768382315, 0.7446194693976111, 0.7454395437609376, 0.7473881505594087, 0.7483638177658957, 0.7483627940242271, 0.7498983682601075, 0.7498401055362748, 0.7504419215422402, 0.7502383057617049, 0.7511163367391976, 0.7530355264169122, 0.7515427464883342, 0.7525799951874854, 0.7546071860013877, 0.7538328716278492, 0.7553308696361429, 0.7561460061080055, 0.7568071638373701, 0.757729931011042, 0.7576389179712261, 0.7569901626241615, 0.7590528564654133]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.13s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:29,  2.01s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:53,  1.89s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:13,  1.96s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:45,  1.87s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:09,  1.96s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<08:29,  1.83s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<08:40,  1.87s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:29,  1.84s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:54,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:22,  2.05s/it]predicting train subjects:   4%|▍         | 11/285 [00:21<08:56,  1.96s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:15,  2.03s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:45,  1.93s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:35,  1.90s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<08:51,  1.97s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<08:59,  2.01s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:34,  1.92s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:29,  1.91s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:09,  1.84s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:11,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:26,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:31,  1.95s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:05,  1.86s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:31,  1.97s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:42,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:13,  1.91s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:07,  1.90s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:00,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:57<08:20,  1.96s/it]predicting train subjects:  11%|█         | 31/285 [00:59<08:26,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [01:01<08:00,  1.90s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<07:54,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<07:55,  1.89s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<08:05,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:08<07:40,  1.85s/it]predicting train subjects:  13%|█▎        | 37/285 [01:10<07:40,  1.86s/it]predicting train subjects:  13%|█▎        | 38/285 [01:12<07:51,  1.91s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:40,  1.87s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:39,  1.88s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:20,  1.81s/it]predicting train subjects:  15%|█▍        | 42/285 [01:19<07:19,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:31,  1.87s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:44,  1.93s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:21,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:35,  1.91s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:31<07:13,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:33<07:38,  1.94s/it]predicting train subjects:  18%|█▊        | 50/285 [01:35<07:26,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:37<07:39,  1.96s/it]predicting train subjects:  18%|█▊        | 52/285 [01:39<07:18,  1.88s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<07:16,  1.88s/it]predicting train subjects:  19%|█▉        | 54/285 [01:43<07:36,  1.98s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<07:17,  1.90s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<07:13,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:48<06:58,  1.83s/it]predicting train subjects:  20%|██        | 58/285 [01:50<07:00,  1.85s/it]predicting train subjects:  21%|██        | 59/285 [01:52<07:12,  1.91s/it]predicting train subjects:  21%|██        | 60/285 [01:54<07:26,  1.98s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<07:03,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [01:57<06:59,  1.88s/it]predicting train subjects:  22%|██▏       | 63/285 [01:59<06:53,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [02:01<06:41,  1.82s/it]predicting train subjects:  23%|██▎       | 65/285 [02:03<06:49,  1.86s/it]predicting train subjects:  23%|██▎       | 66/285 [02:05<06:53,  1.89s/it]predicting train subjects:  24%|██▎       | 67/285 [02:07<06:54,  1.90s/it]predicting train subjects:  24%|██▍       | 68/285 [02:09<06:44,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:11<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 70/285 [02:13<06:48,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:14<06:50,  1.92s/it]predicting train subjects:  25%|██▌       | 72/285 [02:16<06:41,  1.88s/it]predicting train subjects:  26%|██▌       | 73/285 [02:18<06:39,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:20<06:38,  1.89s/it]predicting train subjects:  26%|██▋       | 75/285 [02:22<06:42,  1.92s/it]predicting train subjects:  27%|██▋       | 76/285 [02:24<06:41,  1.92s/it]predicting train subjects:  27%|██▋       | 77/285 [02:26<06:29,  1.87s/it]predicting train subjects:  27%|██▋       | 78/285 [02:27<06:18,  1.83s/it]predicting train subjects:  28%|██▊       | 79/285 [02:29<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:31<06:20,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:33<06:18,  1.86s/it]predicting train subjects:  29%|██▉       | 82/285 [02:35<06:21,  1.88s/it]predicting train subjects:  29%|██▉       | 83/285 [02:37<06:18,  1.87s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<06:10,  1.84s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<06:22,  1.91s/it]predicting train subjects:  30%|███       | 86/285 [02:43<06:17,  1.90s/it]predicting train subjects:  31%|███       | 87/285 [02:44<06:14,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:46<06:01,  1.84s/it]predicting train subjects:  31%|███       | 89/285 [02:48<06:04,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<06:05,  1.87s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<05:58,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:55<05:51,  1.83s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:53,  1.85s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:57,  1.88s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:54,  1.88s/it]predicting train subjects:  34%|███▍      | 97/285 [03:03<05:53,  1.88s/it]predicting train subjects:  34%|███▍      | 98/285 [03:05<05:54,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:07<05:48,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:09<05:47,  1.88s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:40,  1.85s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:43,  1.88s/it]predicting train subjects:  36%|███▌      | 103/285 [03:14<05:35,  1.84s/it]predicting train subjects:  36%|███▋      | 104/285 [03:16<05:33,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:18<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:20<05:29,  1.84s/it]predicting train subjects:  38%|███▊      | 107/285 [03:22<05:28,  1.84s/it]predicting train subjects:  38%|███▊      | 108/285 [03:23<05:21,  1.82s/it]predicting train subjects:  38%|███▊      | 109/285 [03:25<05:21,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:27<05:29,  1.88s/it]predicting train subjects:  39%|███▉      | 111/285 [03:29<05:21,  1.85s/it]predicting train subjects:  39%|███▉      | 112/285 [03:31<05:20,  1.85s/it]predicting train subjects:  40%|███▉      | 113/285 [03:33<05:26,  1.90s/it]predicting train subjects:  40%|████      | 114/285 [03:35<05:25,  1.90s/it]predicting train subjects:  40%|████      | 115/285 [03:37<05:20,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:39<05:23,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:12,  1.86s/it]predicting train subjects:  41%|████▏     | 118/285 [03:42<05:03,  1.81s/it]predicting train subjects:  42%|████▏     | 119/285 [03:44<05:08,  1.86s/it]predicting train subjects:  42%|████▏     | 120/285 [03:46<04:58,  1.81s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<04:48,  1.76s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:37,  1.71s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:25,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:29,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:16,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:11,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:17,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:13,  1.62s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:04,  1.59s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:05,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [04:06<04:04,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<03:58,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<03:53,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:52,  1.56s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:14<03:54,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:58,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:18<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<03:48,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:21<03:49,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:22<03:44,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:24<03:47,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:26<03:41,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:27<03:46,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:29<03:40,  1.60s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:30<03:41,  1.62s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:32<03:35,  1.59s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:34<03:33,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:35<03:36,  1.61s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:37<03:29,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:38<03:24,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:40<03:26,  1.58s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:41<03:24,  1.57s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:43<03:26,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:45<03:20,  1.56s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:46<03:17,  1.55s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:48<03:12,  1.53s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:49<03:14,  1.55s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:52<03:13,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:16,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:56<03:11,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:06,  1.55s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:59<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:09,  1.60s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:02<03:04,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<03:00,  1.55s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<02:56,  1.53s/it]predicting train subjects:  60%|██████    | 171/285 [05:07<02:57,  1.56s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<02:56,  1.56s/it]predicting train subjects:  61%|██████    | 173/285 [05:10<02:56,  1.57s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:53,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:13<02:56,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:15<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:16<02:52,  1.59s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:18<02:45,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:19<02:42,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:21<02:53,  1.65s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:23<02:53,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:24<02:54,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:26<02:45,  1.62s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:28<02:43,  1.62s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:29<02:37,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:31<02:45,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:33<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:35<02:55,  1.81s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:36<02:42,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:38<02:34,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:40<02:39,  1.69s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:41<02:39,  1.72s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:43<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:44<02:29,  1.64s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:46<02:22,  1.58s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:48<02:33,  1.72s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:50<02:35,  1.77s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:52<02:39,  1.84s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:53<02:28,  1.73s/it]predicting train subjects:  70%|███████   | 200/285 [05:55<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:57<02:25,  1.74s/it]predicting train subjects:  71%|███████   | 202/285 [05:58<02:24,  1.75s/it]predicting train subjects:  71%|███████   | 203/285 [06:00<02:23,  1.75s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:02<02:15,  1.68s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:03<02:09,  1.61s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:05<02:03,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:07<02:11,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:09<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:10<02:15,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:12<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:14<02:03,  1.67s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:15<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:17<02:06,  1.76s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:19<02:00,  1.70s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:21<02:02,  1.75s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:22<01:55,  1.67s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:24<01:59,  1.75s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:26<02:00,  1.80s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:28<02:00,  1.83s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:29<01:52,  1.73s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:31<01:45,  1.65s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:33<01:45,  1.68s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:34<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:35<01:35,  1.57s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:37<01:32,  1.53s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:39<01:36,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:41<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [06:43<01:40,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [06:44<01:37,  1.74s/it]predicting train subjects:  81%|████████  | 230/285 [06:46<01:30,  1.65s/it]predicting train subjects:  81%|████████  | 231/285 [06:47<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:49<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:50<01:22,  1.58s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:52<01:25,  1.68s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:54<01:20,  1.61s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:56<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:58<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:59<01:25,  1.81s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:01<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:03<01:17,  1.72s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:04<01:14,  1.68s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:06<01:09,  1.62s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:07<01:06,  1.58s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:09<01:07,  1.65s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:11<01:03,  1.60s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:13<01:06,  1.70s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:14<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:16<01:05,  1.78s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:18<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:19<00:57,  1.66s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:21<00:55,  1.63s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:22<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:24<00:54,  1.69s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:26<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:28<00:52,  1.75s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:29<00:48,  1.68s/it]predicting train subjects:  90%|█████████ | 257/285 [07:31<00:46,  1.65s/it]predicting train subjects:  91%|█████████ | 258/285 [07:33<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [07:35<00:43,  1.69s/it]predicting train subjects:  91%|█████████ | 260/285 [07:36<00:40,  1.61s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:37<00:37,  1.56s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:35,  1.53s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:40<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:42<00:35,  1.67s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:44<00:34,  1.70s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:46<00:30,  1.62s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:47<00:28,  1.57s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:49<00:28,  1.67s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:51<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:52<00:23,  1.59s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:57<00:18,  1.55s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:58<00:16,  1.53s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:00<00:16,  1.66s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:02<00:15,  1.71s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:03<00:12,  1.62s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:05<00:10,  1.57s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:06<00:09,  1.60s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:08<00:07,  1.60s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:10<00:06,  1.58s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:11<00:04,  1.55s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:13<00:03,  1.66s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:15<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:17<00:00,  1.78s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:10,  1.51s/it]Loading train:   1%|          | 2/285 [00:02<06:42,  1.42s/it]Loading train:   1%|          | 3/285 [00:04<06:38,  1.41s/it]Loading train:   1%|▏         | 4/285 [00:05<06:05,  1.30s/it]Loading train:   2%|▏         | 5/285 [00:06<06:14,  1.34s/it]Loading train:   2%|▏         | 6/285 [00:07<06:04,  1.31s/it]Loading train:   2%|▏         | 7/285 [00:09<06:21,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:07,  1.33s/it]Loading train:   3%|▎         | 9/285 [00:12<06:25,  1.40s/it]Loading train:   4%|▎         | 10/285 [00:13<05:51,  1.28s/it]Loading train:   4%|▍         | 11/285 [00:13<05:05,  1.11s/it]Loading train:   4%|▍         | 12/285 [00:14<04:53,  1.08s/it]Loading train:   5%|▍         | 13/285 [00:15<04:32,  1.00s/it]Loading train:   5%|▍         | 14/285 [00:16<04:36,  1.02s/it]Loading train:   5%|▌         | 15/285 [00:17<04:35,  1.02s/it]Loading train:   6%|▌         | 16/285 [00:18<04:31,  1.01s/it]Loading train:   6%|▌         | 17/285 [00:19<04:11,  1.07it/s]Loading train:   6%|▋         | 18/285 [00:20<04:17,  1.04it/s]Loading train:   7%|▋         | 19/285 [00:21<03:57,  1.12it/s]Loading train:   7%|▋         | 20/285 [00:22<04:01,  1.10it/s]Loading train:   7%|▋         | 21/285 [00:23<04:17,  1.03it/s]Loading train:   8%|▊         | 22/285 [00:24<04:05,  1.07it/s]Loading train:   8%|▊         | 23/285 [00:25<04:20,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:26<04:05,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:27<04:13,  1.02it/s]Loading train:   9%|▉         | 26/285 [00:28<04:13,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:28<03:55,  1.09it/s]Loading train:  10%|▉         | 28/285 [00:29<04:05,  1.05it/s]Loading train:  10%|█         | 29/285 [00:30<03:59,  1.07it/s]Loading train:  11%|█         | 30/285 [00:31<04:07,  1.03it/s]Loading train:  11%|█         | 31/285 [00:32<04:06,  1.03it/s]Loading train:  11%|█         | 32/285 [00:33<03:52,  1.09it/s]Loading train:  12%|█▏        | 33/285 [00:34<03:57,  1.06it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:44,  1.12it/s]Loading train:  12%|█▏        | 35/285 [00:36<04:02,  1.03it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:53,  1.06it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:51,  1.07it/s]Loading train:  13%|█▎        | 38/285 [00:39<04:05,  1.01it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:55,  1.04it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:49,  1.07it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:36,  1.13it/s]Loading train:  15%|█▍        | 42/285 [00:42<03:28,  1.17it/s]Loading train:  15%|█▌        | 43/285 [00:43<03:36,  1.12it/s]Loading train:  15%|█▌        | 44/285 [00:44<03:51,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:45<03:47,  1.05it/s]Loading train:  16%|█▌        | 46/285 [00:46<03:55,  1.02it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:40,  1.08it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:36,  1.10it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:55,  1.00it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:51,  1.01it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:50,  1.01it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:50,  1.01it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:59,  1.03s/it]Loading train:  19%|█▉        | 54/285 [00:54<03:56,  1.02s/it]Loading train:  19%|█▉        | 55/285 [00:55<03:45,  1.02it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:43,  1.02it/s]Loading train:  20%|██        | 57/285 [00:57<03:31,  1.08it/s]Loading train:  20%|██        | 58/285 [00:58<03:29,  1.08it/s]Loading train:  21%|██        | 59/285 [00:59<03:26,  1.09it/s]Loading train:  21%|██        | 60/285 [01:00<03:25,  1.10it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:18,  1.13it/s]Loading train:  22%|██▏       | 62/285 [01:01<03:15,  1.14it/s]Loading train:  22%|██▏       | 63/285 [01:02<03:26,  1.07it/s]Loading train:  22%|██▏       | 64/285 [01:04<03:50,  1.04s/it]Loading train:  23%|██▎       | 65/285 [01:05<04:24,  1.20s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:30,  1.23s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:13,  1.16s/it]Loading train:  24%|██▍       | 68/285 [01:08<03:47,  1.05s/it]Loading train:  24%|██▍       | 69/285 [01:09<03:44,  1.04s/it]Loading train:  25%|██▍       | 70/285 [01:10<03:40,  1.02s/it]Loading train:  25%|██▍       | 71/285 [01:11<03:32,  1.01it/s]Loading train:  25%|██▌       | 72/285 [01:12<03:19,  1.07it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:42,  1.05s/it]Loading train:  26%|██▌       | 74/285 [01:15<03:39,  1.04s/it]Loading train:  26%|██▋       | 75/285 [01:16<03:34,  1.02s/it]Loading train:  27%|██▋       | 76/285 [01:16<03:23,  1.03it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:25,  1.01it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:10,  1.09it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:18,  1.04it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:10,  1.08it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:10,  1.07it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:07,  1.08it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:06,  1.08it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:52,  1.16it/s]Loading train:  30%|██▉       | 85/285 [01:25<02:59,  1.11it/s]Loading train:  30%|███       | 86/285 [01:26<03:06,  1.07it/s]Loading train:  31%|███       | 87/285 [01:26<03:01,  1.09it/s]Loading train:  31%|███       | 88/285 [01:27<02:51,  1.15it/s]Loading train:  31%|███       | 89/285 [01:28<02:58,  1.10it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:08,  1.03it/s]Loading train:  32%|███▏      | 91/285 [01:30<03:02,  1.06it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:06,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:32<02:58,  1.07it/s]Loading train:  33%|███▎      | 94/285 [01:33<03:06,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:59,  1.06it/s]Loading train:  34%|███▎      | 96/285 [01:35<03:08,  1.01it/s]Loading train:  34%|███▍      | 97/285 [01:36<03:06,  1.01it/s]Loading train:  34%|███▍      | 98/285 [01:37<03:04,  1.01it/s]Loading train:  35%|███▍      | 99/285 [01:38<03:07,  1.01s/it]Loading train:  35%|███▌      | 100/285 [01:39<03:03,  1.01it/s]Loading train:  35%|███▌      | 101/285 [01:40<03:04,  1.00s/it]Loading train:  36%|███▌      | 102/285 [01:41<03:04,  1.01s/it]Loading train:  36%|███▌      | 103/285 [01:42<02:59,  1.02it/s]Loading train:  36%|███▋      | 104/285 [01:43<02:55,  1.03it/s]Loading train:  37%|███▋      | 105/285 [01:44<02:52,  1.04it/s]Loading train:  37%|███▋      | 106/285 [01:45<02:50,  1.05it/s]Loading train:  38%|███▊      | 107/285 [01:46<02:46,  1.07it/s]Loading train:  38%|███▊      | 108/285 [01:47<02:38,  1.12it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:38,  1.11it/s]Loading train:  39%|███▊      | 110/285 [01:49<02:46,  1.05it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:37,  1.11it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:38,  1.09it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:33,  1.12it/s]Loading train:  40%|████      | 114/285 [01:52<02:35,  1.10it/s]Loading train:  40%|████      | 115/285 [01:53<02:31,  1.12it/s]Loading train:  41%|████      | 116/285 [01:54<02:35,  1.08it/s]Loading train:  41%|████      | 117/285 [01:55<02:29,  1.12it/s]Loading train:  41%|████▏     | 118/285 [01:56<02:24,  1.16it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:25,  1.14it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:22,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:59<02:43,  1.00it/s]Loading train:  43%|████▎     | 122/285 [02:00<02:49,  1.04s/it]Loading train:  43%|████▎     | 123/285 [02:01<02:55,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:02<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [02:03<02:35,  1.03it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:27,  1.08it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:25,  1.08it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:21,  1.11it/s]Loading train:  45%|████▌     | 129/285 [02:06<02:14,  1.16it/s]Loading train:  46%|████▌     | 130/285 [02:07<02:17,  1.13it/s]Loading train:  46%|████▌     | 131/285 [02:08<02:13,  1.15it/s]Loading train:  46%|████▋     | 132/285 [02:09<02:12,  1.15it/s]Loading train:  47%|████▋     | 133/285 [02:09<02:07,  1.19it/s]Loading train:  47%|████▋     | 134/285 [02:10<02:04,  1.21it/s]Loading train:  47%|████▋     | 135/285 [02:11<02:03,  1.22it/s]Loading train:  48%|████▊     | 136/285 [02:12<02:02,  1.22it/s]Loading train:  48%|████▊     | 137/285 [02:13<02:05,  1.18it/s]Loading train:  48%|████▊     | 138/285 [02:14<02:06,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:14<02:05,  1.17it/s]Loading train:  49%|████▉     | 140/285 [02:15<02:02,  1.18it/s]Loading train:  49%|████▉     | 141/285 [02:16<01:58,  1.22it/s]Loading train:  50%|████▉     | 142/285 [02:17<01:56,  1.23it/s]Loading train:  50%|█████     | 143/285 [02:18<01:53,  1.25it/s]Loading train:  51%|█████     | 144/285 [02:19<01:56,  1.21it/s]Loading train:  51%|█████     | 145/285 [02:19<01:54,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:20<01:54,  1.21it/s]Loading train:  52%|█████▏    | 147/285 [02:21<01:52,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:22<01:52,  1.22it/s]Loading train:  52%|█████▏    | 149/285 [02:23<01:48,  1.25it/s]Loading train:  53%|█████▎    | 150/285 [02:23<01:46,  1.27it/s]Loading train:  53%|█████▎    | 151/285 [02:24<01:53,  1.18it/s]Loading train:  53%|█████▎    | 152/285 [02:25<01:48,  1.22it/s]Loading train:  54%|█████▎    | 153/285 [02:26<01:47,  1.23it/s]Loading train:  54%|█████▍    | 154/285 [02:27<01:49,  1.20it/s]Loading train:  54%|█████▍    | 155/285 [02:28<01:52,  1.16it/s]Loading train:  55%|█████▍    | 156/285 [02:28<01:47,  1.20it/s]Loading train:  55%|█████▌    | 157/285 [02:29<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:30<01:46,  1.20it/s]Loading train:  56%|█████▌    | 159/285 [02:31<01:41,  1.24it/s]Loading train:  56%|█████▌    | 160/285 [02:32<01:35,  1.31it/s]Loading train:  56%|█████▋    | 161/285 [02:32<01:38,  1.26it/s]Loading train:  57%|█████▋    | 162/285 [02:33<01:39,  1.24it/s]Loading train:  57%|█████▋    | 163/285 [02:34<01:36,  1.27it/s]Loading train:  58%|█████▊    | 164/285 [02:35<01:35,  1.27it/s]Loading train:  58%|█████▊    | 165/285 [02:35<01:32,  1.30it/s]Loading train:  58%|█████▊    | 166/285 [02:36<01:30,  1.31it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:30,  1.30it/s]Loading train:  59%|█████▉    | 168/285 [02:38<01:30,  1.30it/s]Loading train:  59%|█████▉    | 169/285 [02:39<01:30,  1.28it/s]Loading train:  60%|█████▉    | 170/285 [02:39<01:27,  1.31it/s]Loading train:  60%|██████    | 171/285 [02:40<01:24,  1.35it/s]Loading train:  60%|██████    | 172/285 [02:41<01:20,  1.40it/s]Loading train:  61%|██████    | 173/285 [02:41<01:19,  1.41it/s]Loading train:  61%|██████    | 174/285 [02:42<01:21,  1.36it/s]Loading train:  61%|██████▏   | 175/285 [02:43<01:24,  1.30it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:33,  1.16it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:26,  1.24it/s]Loading train:  62%|██████▏   | 178/285 [02:45<01:22,  1.30it/s]Loading train:  63%|██████▎   | 179/285 [02:46<01:21,  1.30it/s]Loading train:  63%|██████▎   | 180/285 [02:47<01:25,  1.22it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:25,  1.20it/s]Loading train:  64%|██████▍   | 183/285 [02:49<01:19,  1.29it/s]Loading train:  65%|██████▍   | 184/285 [02:50<01:20,  1.26it/s]Loading train:  65%|██████▍   | 185/285 [02:51<01:21,  1.22it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:24,  1.18it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:27,  1.12it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:31,  1.06it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:23,  1.15it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:19,  1.20it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:22,  1.14it/s]Loading train:  67%|██████▋   | 192/285 [02:57<01:19,  1.17it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:22,  1.11it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:18,  1.16it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:13,  1.23it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:16,  1.16it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:15,  1.17it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:20,  1.08it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:15,  1.14it/s]Loading train:  70%|███████   | 200/285 [03:04<01:12,  1.17it/s]Loading train:  71%|███████   | 201/285 [03:05<01:15,  1.11it/s]Loading train:  71%|███████   | 202/285 [03:06<01:18,  1.06it/s]Loading train:  71%|███████   | 203/285 [03:07<01:17,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:20,  1.01it/s]Loading train:  72%|███████▏  | 205/285 [03:09<01:20,  1.00s/it]Loading train:  72%|███████▏  | 206/285 [03:11<01:20,  1.02s/it]Loading train:  73%|███████▎  | 207/285 [03:11<01:17,  1.01it/s]Loading train:  73%|███████▎  | 208/285 [03:12<01:14,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [03:13<01:12,  1.05it/s]Loading train:  74%|███████▎  | 210/285 [03:14<01:06,  1.13it/s]Loading train:  74%|███████▍  | 211/285 [03:15<01:04,  1.15it/s]Loading train:  74%|███████▍  | 212/285 [03:16<01:03,  1.15it/s]Loading train:  75%|███████▍  | 213/285 [03:17<01:01,  1.17it/s]Loading train:  75%|███████▌  | 214/285 [03:18<01:04,  1.11it/s]Loading train:  75%|███████▌  | 215/285 [03:18<01:02,  1.12it/s]Loading train:  76%|███████▌  | 216/285 [03:19<01:00,  1.14it/s]Loading train:  76%|███████▌  | 217/285 [03:20<01:00,  1.12it/s]Loading train:  76%|███████▋  | 218/285 [03:21<01:02,  1.08it/s]Loading train:  77%|███████▋  | 219/285 [03:22<01:03,  1.05it/s]Loading train:  77%|███████▋  | 220/285 [03:23<00:58,  1.12it/s]Loading train:  78%|███████▊  | 221/285 [03:24<00:56,  1.12it/s]Loading train:  78%|███████▊  | 222/285 [03:25<00:58,  1.09it/s]Loading train:  78%|███████▊  | 223/285 [03:26<00:54,  1.14it/s]Loading train:  79%|███████▊  | 224/285 [03:27<00:53,  1.13it/s]Loading train:  79%|███████▉  | 225/285 [03:28<00:56,  1.06it/s]Loading train:  79%|███████▉  | 226/285 [03:29<01:00,  1.03s/it]Loading train:  80%|███████▉  | 227/285 [03:30<01:00,  1.04s/it]Loading train:  80%|████████  | 228/285 [03:31<00:58,  1.03s/it]Loading train:  80%|████████  | 229/285 [03:32<00:54,  1.03it/s]Loading train:  81%|████████  | 230/285 [03:33<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [03:34<00:50,  1.06it/s]Loading train:  81%|████████▏ | 232/285 [03:35<00:50,  1.05it/s]Loading train:  82%|████████▏ | 233/285 [03:35<00:47,  1.11it/s]Loading train:  82%|████████▏ | 234/285 [03:36<00:48,  1.05it/s]Loading train:  82%|████████▏ | 235/285 [03:37<00:44,  1.12it/s]Loading train:  83%|████████▎ | 236/285 [03:38<00:44,  1.09it/s]Loading train:  83%|████████▎ | 237/285 [03:39<00:46,  1.03it/s]Loading train:  84%|████████▎ | 238/285 [03:40<00:47,  1.00s/it]Loading train:  84%|████████▍ | 239/285 [03:41<00:43,  1.05it/s]Loading train:  84%|████████▍ | 240/285 [03:42<00:41,  1.10it/s]Loading train:  85%|████████▍ | 241/285 [03:43<00:42,  1.03it/s]Loading train:  85%|████████▍ | 242/285 [03:44<00:42,  1.01it/s]Loading train:  85%|████████▌ | 243/285 [03:45<00:43,  1.02s/it]Loading train:  86%|████████▌ | 244/285 [03:46<00:41,  1.02s/it]Loading train:  86%|████████▌ | 245/285 [03:47<00:38,  1.05it/s]Loading train:  86%|████████▋ | 246/285 [03:48<00:40,  1.04s/it]Loading train:  87%|████████▋ | 247/285 [03:49<00:38,  1.02s/it]Loading train:  87%|████████▋ | 248/285 [03:50<00:37,  1.02s/it]Loading train:  87%|████████▋ | 249/285 [03:51<00:33,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [03:52<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [03:53<00:28,  1.19it/s]Loading train:  88%|████████▊ | 252/285 [03:53<00:28,  1.18it/s]Loading train:  89%|████████▉ | 253/285 [03:54<00:28,  1.12it/s]Loading train:  89%|████████▉ | 254/285 [03:56<00:30,  1.01it/s]Loading train:  89%|████████▉ | 255/285 [03:57<00:30,  1.02s/it]Loading train:  90%|████████▉ | 256/285 [03:58<00:28,  1.00it/s]Loading train:  90%|█████████ | 257/285 [03:59<00:27,  1.03it/s]Loading train:  91%|█████████ | 258/285 [04:00<00:28,  1.04s/it]Loading train:  91%|█████████ | 259/285 [04:01<00:27,  1.06s/it]Loading train:  91%|█████████ | 260/285 [04:02<00:24,  1.04it/s]Loading train:  92%|█████████▏| 261/285 [04:03<00:23,  1.02it/s]Loading train:  92%|█████████▏| 262/285 [04:04<00:22,  1.01it/s]Loading train:  92%|█████████▏| 263/285 [04:04<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [04:05<00:19,  1.07it/s]Loading train:  93%|█████████▎| 265/285 [04:06<00:19,  1.03it/s]Loading train:  93%|█████████▎| 266/285 [04:07<00:16,  1.14it/s]Loading train:  94%|█████████▎| 267/285 [04:08<00:15,  1.17it/s]Loading train:  94%|█████████▍| 268/285 [04:09<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [04:10<00:15,  1.03it/s]Loading train:  95%|█████████▍| 270/285 [04:11<00:13,  1.09it/s]Loading train:  95%|█████████▌| 271/285 [04:12<00:12,  1.12it/s]Loading train:  95%|█████████▌| 272/285 [04:13<00:12,  1.06it/s]Loading train:  96%|█████████▌| 273/285 [04:14<00:10,  1.10it/s]Loading train:  96%|█████████▌| 274/285 [04:14<00:09,  1.19it/s]Loading train:  96%|█████████▋| 275/285 [04:16<00:09,  1.07it/s]Loading train:  97%|█████████▋| 276/285 [04:17<00:09,  1.02s/it]Loading train:  97%|█████████▋| 277/285 [04:17<00:07,  1.07it/s]Loading train:  98%|█████████▊| 278/285 [04:18<00:06,  1.07it/s]Loading train:  98%|█████████▊| 279/285 [04:19<00:05,  1.06it/s]Loading train:  98%|█████████▊| 280/285 [04:20<00:04,  1.11it/s]Loading train:  99%|█████████▊| 281/285 [04:21<00:03,  1.12it/s]Loading train:  99%|█████████▉| 282/285 [04:22<00:02,  1.20it/s]Loading train:  99%|█████████▉| 283/285 [04:23<00:01,  1.19it/s]Loading train: 100%|█████████▉| 284/285 [04:24<00:00,  1.14it/s]Loading train: 100%|██████████| 285/285 [04:24<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:00, 274.62it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:00, 267.68it/s]concatenating: train:  28%|██▊       | 81/285 [00:00<00:00, 264.70it/s]concatenating: train:  39%|███▉      | 111/285 [00:00<00:00, 274.28it/s]concatenating: train:  50%|█████     | 143/285 [00:00<00:00, 285.99it/s]concatenating: train:  60%|██████    | 172/285 [00:00<00:00, 284.93it/s]concatenating: train:  72%|███████▏  | 205/285 [00:00<00:00, 295.11it/s]concatenating: train:  83%|████████▎ | 237/285 [00:00<00:00, 300.54it/s]concatenating: train:  95%|█████████▍| 270/285 [00:00<00:00, 307.09it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 296.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.27s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 41.96it/s]2019-07-10 22:39:53.767161: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 22:39:53.767331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 22:39:53.767350: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 22:39:53.767362: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 22:39:53.767910: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.89it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.69it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.44it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.76it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.26it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.19it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.33it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.02it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.51it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.34it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.65it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.27it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.50it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.23it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.17it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.58it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.78it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.19it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 231,413
Trainable params: 56,653
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 3.0060 - acc: 0.5448 - mDice: 0.0794 - val_loss: 2.1964 - val_acc: 0.8975 - val_mDice: 0.1865

Epoch 00001: val_mDice improved from -inf to 0.18654, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 1.3273 - acc: 0.8777 - mDice: 0.2624 - val_loss: 1.4883 - val_acc: 0.9090 - val_mDice: 0.3196

Epoch 00002: val_mDice improved from 0.18654 to 0.31956, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.9755 - acc: 0.8873 - mDice: 0.3632 - val_loss: 1.2071 - val_acc: 0.9119 - val_mDice: 0.3911

Epoch 00003: val_mDice improved from 0.31956 to 0.39110, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.8231 - acc: 0.8935 - mDice: 0.4234 - val_loss: 1.0569 - val_acc: 0.9147 - val_mDice: 0.4473

Epoch 00004: val_mDice improved from 0.39110 to 0.44731, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.7253 - acc: 0.8997 - mDice: 0.4678 - val_loss: 1.0476 - val_acc: 0.9188 - val_mDice: 0.4554

Epoch 00005: val_mDice improved from 0.44731 to 0.45541, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.6662 - acc: 0.9053 - mDice: 0.4975 - val_loss: 0.9438 - val_acc: 0.9224 - val_mDice: 0.4882

Epoch 00006: val_mDice improved from 0.45541 to 0.48818, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.6081 - acc: 0.9107 - mDice: 0.5276 - val_loss: 0.9751 - val_acc: 0.9262 - val_mDice: 0.4961

Epoch 00007: val_mDice improved from 0.48818 to 0.49613, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.5709 - acc: 0.9149 - mDice: 0.5480 - val_loss: 0.8732 - val_acc: 0.9279 - val_mDice: 0.5206

Epoch 00008: val_mDice improved from 0.49613 to 0.52060, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.5425 - acc: 0.9188 - mDice: 0.5647 - val_loss: 0.9088 - val_acc: 0.9277 - val_mDice: 0.5260

Epoch 00009: val_mDice improved from 0.52060 to 0.52603, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.5188 - acc: 0.9220 - mDice: 0.5787 - val_loss: 0.8788 - val_acc: 0.9314 - val_mDice: 0.5330

Epoch 00010: val_mDice improved from 0.52603 to 0.53299, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 12s - loss: 0.5019 - acc: 0.9242 - mDice: 0.5888 - val_loss: 0.8531 - val_acc: 0.9327 - val_mDice: 0.5422

Epoch 00011: val_mDice improved from 0.53299 to 0.54217, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 11s - loss: 0.4860 - acc: 0.9263 - mDice: 0.5986 - val_loss: 0.8590 - val_acc: 0.9338 - val_mDice: 0.5393

Epoch 00012: val_mDice did not improve from 0.54217
Epoch 13/300
 - 12s - loss: 0.4761 - acc: 0.9276 - mDice: 0.6049 - val_loss: 0.8472 - val_acc: 0.9303 - val_mDice: 0.5433

Epoch 00013: val_mDice improved from 0.54217 to 0.54329, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 12s - loss: 0.4637 - acc: 0.9290 - mDice: 0.6127 - val_loss: 0.8464 - val_acc: 0.9331 - val_mDice: 0.5514

Epoch 00014: val_mDice improved from 0.54329 to 0.55144, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 12s - loss: 0.4548 - acc: 0.9301 - mDice: 0.6182 - val_loss: 0.8637 - val_acc: 0.9311 - val_mDice: 0.5394

Epoch 00015: val_mDice did not improve from 0.55144
Epoch 16/300
 - 11s - loss: 0.4467 - acc: 0.9309 - mDice: 0.6236 - val_loss: 0.8510 - val_acc: 0.9241 - val_mDice: 0.5394

Epoch 00016: val_mDice did not improve from 0.55144
Epoch 17/300
 - 11s - loss: 0.4375 - acc: 0.9319 - mDice: 0.6296 - val_loss: 0.8448 - val_acc: 0.9324 - val_mDice: 0.5437

Epoch 00017: val_mDice did not improve from 0.55144
Epoch 18/300
 - 12s - loss: 0.4332 - acc: 0.9324 - mDice: 0.6324 - val_loss: 0.8452 - val_acc: 0.9304 - val_mDice: 0.5417

Epoch 00018: val_mDice did not improve from 0.55144
Epoch 19/300
 - 12s - loss: 0.4240 - acc: 0.9336 - mDice: 0.6383 - val_loss: 0.8779 - val_acc: 0.9335 - val_mDice: 0.5328

Epoch 00019: val_mDice did not improve from 0.55144
Epoch 20/300
 - 12s - loss: 0.4196 - acc: 0.9341 - mDice: 0.6412 - val_loss: 0.8336 - val_acc: 0.9321 - val_mDice: 0.5522

Epoch 00020: val_mDice improved from 0.55144 to 0.55216, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 12s - loss: 0.4156 - acc: 0.9345 - mDice: 0.6438 - val_loss: 0.8473 - val_acc: 0.9289 - val_mDice: 0.5315

Epoch 00021: val_mDice did not improve from 0.55216
Epoch 22/300
 - 12s - loss: 0.4090 - acc: 0.9352 - mDice: 0.6483 - val_loss: 0.8495 - val_acc: 0.9311 - val_mDice: 0.5354

Epoch 00022: val_mDice did not improve from 0.55216
Epoch 23/300
 - 11s - loss: 0.4029 - acc: 0.9357 - mDice: 0.6524 - val_loss: 0.8435 - val_acc: 0.9315 - val_mDice: 0.5466

Epoch 00023: val_mDice did not improve from 0.55216
Epoch 24/300
 - 12s - loss: 0.3989 - acc: 0.9358 - mDice: 0.6549 - val_loss: 0.8480 - val_acc: 0.9298 - val_mDice: 0.5404

Epoch 00024: val_mDice did not improve from 0.55216
Epoch 25/300
 - 11s - loss: 0.3933 - acc: 0.9363 - mDice: 0.6589 - val_loss: 0.8490 - val_acc: 0.9280 - val_mDice: 0.5415

Epoch 00025: val_mDice did not improve from 0.55216
Epoch 26/300
 - 11s - loss: 0.3836 - acc: 0.9365 - mDice: 0.6658 - val_loss: 0.8774 - val_acc: 0.9306 - val_mDice: 0.5184

Epoch 00026: val_mDice did not improve from 0.55216
Epoch 27/300
 - 10s - loss: 0.3765 - acc: 0.9369 - mDice: 0.6708 - val_loss: 0.8107 - val_acc: 0.9268 - val_mDice: 0.5480

Epoch 00027: val_mDice did not improve from 0.55216
Epoch 28/300
 - 11s - loss: 0.3722 - acc: 0.9370 - mDice: 0.6740 - val_loss: 0.8307 - val_acc: 0.9285 - val_mDice: 0.5373

Epoch 00028: val_mDice did not improve from 0.55216
Epoch 29/300
 - 10s - loss: 0.3711 - acc: 0.9371 - mDice: 0.6747 - val_loss: 0.7976 - val_acc: 0.9308 - val_mDice: 0.5524

Epoch 00029: val_mDice improved from 0.55216 to 0.55236, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 10s - loss: 0.3659 - acc: 0.9374 - mDice: 0.6783 - val_loss: 0.8230 - val_acc: 0.9323 - val_mDice: 0.5382

Epoch 00030: val_mDice did not improve from 0.55236
Epoch 31/300
 - 10s - loss: 0.3634 - acc: 0.9377 - mDice: 0.6803 - val_loss: 0.8323 - val_acc: 0.9291 - val_mDice: 0.5289

Epoch 00031: val_mDice did not improve from 0.55236
Epoch 32/300
 - 10s - loss: 0.3639 - acc: 0.9376 - mDice: 0.6797 - val_loss: 0.8238 - val_acc: 0.9312 - val_mDice: 0.5311

Epoch 00032: val_mDice did not improve from 0.55236
Epoch 33/300
 - 11s - loss: 0.3576 - acc: 0.9379 - mDice: 0.6842 - val_loss: 0.8227 - val_acc: 0.9276 - val_mDice: 0.5326

Epoch 00033: val_mDice did not improve from 0.55236
Epoch 34/300
 - 10s - loss: 0.3566 - acc: 0.9380 - mDice: 0.6851 - val_loss: 0.8050 - val_acc: 0.9304 - val_mDice: 0.5373

Epoch 00034: val_mDice did not improve from 0.55236
Epoch 35/300
 - 10s - loss: 0.3534 - acc: 0.9382 - mDice: 0.6873 - val_loss: 0.7773 - val_acc: 0.9286 - val_mDice: 0.5544

Epoch 00035: val_mDice improved from 0.55236 to 0.55437, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 36/300
 - 10s - loss: 0.3528 - acc: 0.9382 - mDice: 0.6878 - val_loss: 0.7925 - val_acc: 0.9276 - val_mDice: 0.5370

Epoch 00036: val_mDice did not improve from 0.55437
Epoch 37/300
 - 10s - loss: 0.3493 - acc: 0.9387 - mDice: 0.6903 - val_loss: 0.8033 - val_acc: 0.9292 - val_mDice: 0.5325

Epoch 00037: val_mDice did not improve from 0.55437
Epoch 38/300
 - 10s - loss: 0.3480 - acc: 0.9387 - mDice: 0.6913 - val_loss: 0.7591 - val_acc: 0.9280 - val_mDice: 0.5542

Epoch 00038: val_mDice did not improve from 0.55437
Epoch 39/300
 - 10s - loss: 0.3442 - acc: 0.9389 - mDice: 0.6939 - val_loss: 0.8146 - val_acc: 0.9267 - val_mDice: 0.5260

Epoch 00039: val_mDice did not improve from 0.55437
Epoch 40/300
 - 10s - loss: 0.3420 - acc: 0.9391 - mDice: 0.6955 - val_loss: 0.7989 - val_acc: 0.9284 - val_mDice: 0.5360

Epoch 00040: val_mDice did not improve from 0.55437
Epoch 41/300
 - 10s - loss: 0.3416 - acc: 0.9390 - mDice: 0.6958 - val_loss: 0.7855 - val_acc: 0.9297 - val_mDice: 0.5284

Epoch 00041: val_mDice did not improve from 0.55437
Epoch 42/300
 - 11s - loss: 0.3392 - acc: 0.9393 - mDice: 0.6976 - val_loss: 0.7880 - val_acc: 0.9309 - val_mDice: 0.5368

Epoch 00042: val_mDice did not improve from 0.55437
Epoch 43/300
 - 10s - loss: 0.3396 - acc: 0.9394 - mDice: 0.6973 - val_loss: 0.7768 - val_acc: 0.9288 - val_mDice: 0.5410

Epoch 00043: val_mDice did not improve from 0.55437
Epoch 44/300
 - 10s - loss: 0.3381 - acc: 0.9393 - mDice: 0.6984 - val_loss: 0.7693 - val_acc: 0.9293 - val_mDice: 0.5418

Epoch 00044: val_mDice did not improve from 0.55437
Epoch 45/300
 - 10s - loss: 0.3344 - acc: 0.9398 - mDice: 0.7011 - val_loss: 0.7661 - val_acc: 0.9291 - val_mDice: 0.5385

Epoch 00045: val_mDice did not improve from 0.55437
Epoch 46/300
 - 10s - loss: 0.3326 - acc: 0.9399 - mDice: 0.7024 - val_loss: 0.7710 - val_acc: 0.9296 - val_mDice: 0.5426

Epoch 00046: val_mDice did not improve from 0.55437
Epoch 47/300
 - 10s - loss: 0.3312 - acc: 0.9399 - mDice: 0.7034 - val_loss: 0.7502 - val_acc: 0.9344 - val_mDice: 0.5507

Epoch 00047: val_mDice did not improve from 0.55437
Epoch 48/300
 - 10s - loss: 0.3300 - acc: 0.9401 - mDice: 0.7043 - val_loss: 0.7729 - val_acc: 0.9290 - val_mDice: 0.5330

Epoch 00048: val_mDice did not improve from 0.55437
Epoch 49/300
 - 10s - loss: 0.3276 - acc: 0.9403 - mDice: 0.7060 - val_loss: 0.7773 - val_acc: 0.9293 - val_mDice: 0.5289

Epoch 00049: val_mDice did not improve from 0.55437
Epoch 50/300
 - 10s - loss: 0.3285 - acc: 0.9401 - mDice: 0.7055 - val_loss: 0.7830 - val_acc: 0.9307 - val_mDice: 0.5260

Epoch 00050: val_mDice did not improve from 0.55437
Epoch 51/300
 - 10s - loss: 0.3294 - acc: 0.9401 - mDice: 0.7048 - val_loss: 0.7565 - val_acc: 0.9332 - val_mDice: 0.5368

Epoch 00051: val_mDice did not improve from 0.55437
Epoch 52/300
 - 10s - loss: 0.3261 - acc: 0.9404 - mDice: 0.7072 - val_loss: 0.7490 - val_acc: 0.9289 - val_mDice: 0.5427

Epoch 00052: val_mDice did not improve from 0.55437
Epoch 53/300
 - 10s - loss: 0.3234 - acc: 0.9408 - mDice: 0.7092 - val_loss: 0.7524 - val_acc: 0.9334 - val_mDice: 0.5455

Epoch 00053: val_mDice did not improve from 0.55437
Epoch 54/300
 - 10s - loss: 0.3245 - acc: 0.9408 - mDice: 0.7085 - val_loss: 0.7537 - val_acc: 0.9317 - val_mDice: 0.5373

Epoch 00054: val_mDice did not improve from 0.55437
Epoch 55/300
 - 10s - loss: 0.3221 - acc: 0.9407 - mDice: 0.7102 - val_loss: 0.7528 - val_acc: 0.9298 - val_mDice: 0.5431

Epoch 00055: val_mDice did not improve from 0.55437
Epoch 56/300
 - 10s - loss: 0.3213 - acc: 0.9409 - mDice: 0.7107 - val_loss: 0.7687 - val_acc: 0.9278 - val_mDice: 0.5355

Epoch 00056: val_mDice did not improve from 0.55437
Epoch 57/300
 - 10s - loss: 0.3197 - acc: 0.9410 - mDice: 0.7119 - val_loss: 0.7411 - val_acc: 0.9313 - val_mDice: 0.5440

Epoch 00057: val_mDice did not improve from 0.55437
Epoch 58/300
 - 10s - loss: 0.3184 - acc: 0.9412 - mDice: 0.7129 - val_loss: 0.7577 - val_acc: 0.9295 - val_mDice: 0.5371

Epoch 00058: val_mDice did not improve from 0.55437
Epoch 59/300
 - 10s - loss: 0.3180 - acc: 0.9412 - mDice: 0.7132 - val_loss: 0.7517 - val_acc: 0.9312 - val_mDice: 0.5366

Epoch 00059: val_mDice did not improve from 0.55437
Epoch 60/300
 - 10s - loss: 0.3151 - acc: 0.9415 - mDice: 0.7153 - val_loss: 0.7682 - val_acc: 0.9320 - val_mDice: 0.5400

Epoch 00060: val_mDice did not improve from 0.55437
Epoch 61/300
 - 10s - loss: 0.3148 - acc: 0.9415 - mDice: 0.7156 - val_loss: 0.7294 - val_acc: 0.9328 - val_mDice: 0.5488

Epoch 00061: val_mDice did not improve from 0.55437
Epoch 62/300
 - 10s - loss: 0.3148 - acc: 0.9415 - mDice: 0.7156 - val_loss: 0.7514 - val_acc: 0.9273 - val_mDice: 0.5368

Epoch 00062: val_mDice did not improve from 0.55437
Epoch 63/300
 - 10s - loss: 0.3142 - acc: 0.9416 - mDice: 0.7161 - val_loss: 0.7523 - val_acc: 0.9307 - val_mDice: 0.5350

Epoch 00063: val_mDice did not improve from 0.55437
Epoch 64/300
 - 10s - loss: 0.3144 - acc: 0.9417 - mDice: 0.7160 - val_loss: 0.7225 - val_acc: 0.9330 - val_mDice: 0.5469

Epoch 00064: val_mDice did not improve from 0.55437
Epoch 65/300
 - 10s - loss: 0.3122 - acc: 0.9418 - mDice: 0.7176 - val_loss: 0.7244 - val_acc: 0.9320 - val_mDice: 0.5460

Epoch 00065: val_mDice did not improve from 0.55437
Epoch 66/300
 - 11s - loss: 0.3112 - acc: 0.9418 - mDice: 0.7182 - val_loss: 0.7571 - val_acc: 0.9309 - val_mDice: 0.5267

Epoch 00066: val_mDice did not improve from 0.55437
Epoch 67/300
 - 10s - loss: 0.3107 - acc: 0.9420 - mDice: 0.7187 - val_loss: 0.7186 - val_acc: 0.9319 - val_mDice: 0.5489

Epoch 00067: val_mDice did not improve from 0.55437
Epoch 68/300
 - 10s - loss: 0.3081 - acc: 0.9422 - mDice: 0.7207 - val_loss: 0.8035 - val_acc: 0.9261 - val_mDice: 0.5149

Epoch 00068: val_mDice did not improve from 0.55437
Epoch 69/300
 - 10s - loss: 0.3080 - acc: 0.9421 - mDice: 0.7207 - val_loss: 0.7316 - val_acc: 0.9345 - val_mDice: 0.5344

Epoch 00069: val_mDice did not improve from 0.55437
Epoch 70/300
 - 10s - loss: 0.3064 - acc: 0.9423 - mDice: 0.7219 - val_loss: 0.7344 - val_acc: 0.9300 - val_mDice: 0.5354

Epoch 00070: val_mDice did not improve from 0.55437
Epoch 71/300
 - 10s - loss: 0.3077 - acc: 0.9423 - mDice: 0.7210 - val_loss: 0.7547 - val_acc: 0.9318 - val_mDice: 0.5246

Epoch 00071: val_mDice did not improve from 0.55437
Epoch 72/300
 - 10s - loss: 0.3063 - acc: 0.9424 - mDice: 0.7221 - val_loss: 0.7225 - val_acc: 0.9335 - val_mDice: 0.5389

Epoch 00072: val_mDice did not improve from 0.55437
Epoch 73/300
 - 10s - loss: 0.3041 - acc: 0.9426 - mDice: 0.7237 - val_loss: 0.7252 - val_acc: 0.9332 - val_mDice: 0.5395

Epoch 00073: val_mDice did not improve from 0.55437
Epoch 74/300
 - 10s - loss: 0.3036 - acc: 0.9427 - mDice: 0.7240 - val_loss: 0.7450 - val_acc: 0.9303 - val_mDice: 0.5411

Epoch 00074: val_mDice did not improve from 0.55437
Epoch 75/300
 - 10s - loss: 0.3047 - acc: 0.9425 - mDice: 0.7233 - val_loss: 0.7076 - val_acc: 0.9334 - val_mDice: 0.5479

Epoch 00075: val_mDice did not improve from 0.55437
Restoring model weights from the end of the best epoch
Epoch 00075: early stopping
{'val_loss': [2.1964034117185154, 1.488256064745096, 1.2070845594772925, 1.056919439480855, 1.047573332603161, 0.9437554914217728, 0.9751130800980788, 0.873192704640902, 0.9087760425530947, 0.878751087647218, 0.8530708092909592, 0.859039843082428, 0.8471987201617315, 0.8463578797303714, 0.8636652941887195, 0.8509658529208257, 0.844824167398306, 0.8451758462649125, 0.8779069414505591, 0.83358201613793, 0.8472591042518616, 0.8494855234256158, 0.8435377386900095, 0.8479614303662226, 0.8490333923926721, 0.8774432425315564, 0.8106555434373709, 0.8307401950542743, 0.7976409586576315, 0.8229719262856704, 0.832276844061338, 0.8237578983490284, 0.8226972245253049, 0.8049554687279922, 0.7773409669215863, 0.7924934511001294, 0.8032782077789307, 0.7591383571808155, 0.8146178791156182, 0.7988577003662403, 0.7854920098414788, 0.7879990568527808, 0.7768049400586349, 0.7692669240327982, 0.7660798178269312, 0.7710034205363347, 0.750248120381282, 0.7729377792431757, 0.7772764403086442, 0.7829974843905523, 0.756499205644314, 0.7489707217766688, 0.7523552156411685, 0.7537445609386151, 0.7528236118646768, 0.7686765423187842, 0.741079683487232, 0.7576723007055429, 0.7516631827904627, 0.7681842996523931, 0.7294272986742166, 0.7514440417289734, 0.7523063925596384, 0.7225289046764374, 0.7244152770592616, 0.7571188853337214, 0.7186231177586776, 0.8035381940694956, 0.7316476267117721, 0.7343988143480741, 0.7547053878123944, 0.72246620288262, 0.7251997223267188, 0.7449828294607309, 0.7075875172248254], 'val_acc': [0.8975198704462785, 0.9090467920670142, 0.9118782121401566, 0.9146657861196078, 0.9187569411901327, 0.9224112652815305, 0.9262458361112155, 0.9279401050164149, 0.9277251569124368, 0.931437237904622, 0.9327431321144104, 0.9338479936122894, 0.9303046533694634, 0.9331060304091527, 0.9310627579689026, 0.9241147293494298, 0.9323872167330521, 0.930397072663674, 0.9334527643827292, 0.9321444974495814, 0.9288623401751885, 0.9311043986907372, 0.9315204253563514, 0.9298169154387254, 0.9279562418277447, 0.9305958656164316, 0.9268144506674546, 0.9284601647120255, 0.9307600076381977, 0.9322531200372256, 0.9291119575500488, 0.931166790998899, 0.927623443878614, 0.9304017080710485, 0.9285941995107211, 0.9276465452634372, 0.9292367605062631, 0.9279863032010885, 0.926668834227782, 0.9283769405805148, 0.9297291338443756, 0.9308732312459213, 0.9288322719243857, 0.9292599146182721, 0.9290772974491119, 0.9296320218306321, 0.9344420157946073, 0.9290495812892914, 0.9293061471902407, 0.9306536660744593, 0.9332216359101809, 0.9289409197293795, 0.9333626054800473, 0.9316729880296267, 0.9298492692984067, 0.9277967925255115, 0.9313077559837928, 0.9295141719854795, 0.9311760526437026, 0.9320428096331083, 0.9327662724715012, 0.9273067552309769, 0.9306536729519184, 0.9329835589115436, 0.9319734940162072, 0.9308686462732462, 0.9318694311838883, 0.9261164183800037, 0.9345298638710609, 0.9300342018787677, 0.931818615931731, 0.9334758543051206, 0.9332123742653773, 0.9302768982373751, 0.9333811173072228], 'val_mDice': [0.18653652974619314, 0.3195579658047511, 0.3910989666787478, 0.4473144675676639, 0.45541269847979915, 0.4881754139294991, 0.4961317405104637, 0.5206022640833488, 0.52603377487797, 0.5329928363745029, 0.5421729855812513, 0.5393255805739989, 0.543285550406346, 0.551435126708104, 0.5394010612597833, 0.539411312685563, 0.5437071294738696, 0.541724586716065, 0.5327610877844003, 0.5521601278048295, 0.5315057709813118, 0.5353981434152677, 0.5466441065073013, 0.540446977202709, 0.5414555302033057, 0.5184070124075963, 0.5480443898301858, 0.5372960733679625, 0.5523622809694364, 0.5382337856751221, 0.5288923852718793, 0.5311202647594305, 0.5326146827294276, 0.5373048363969877, 0.5543669055287654, 0.537046206685213, 0.5324584153982309, 0.5541513287104093, 0.5260283689086254, 0.53596969636587, 0.5284458616605172, 0.5367673389040507, 0.5410029997046177, 0.5417694202982463, 0.5384694905235217, 0.5425865466778095, 0.5506619312442266, 0.5330057344757594, 0.5289147782784241, 0.5260031108672802, 0.5368211447046354, 0.5426523914703956, 0.5455448610278276, 0.5373298434110788, 0.5431444220818006, 0.535481660411908, 0.5440091559520135, 0.5370978747422879, 0.5366472722246096, 0.5400031524208876, 0.5487511180914365, 0.5368304372980044, 0.5350023387716367, 0.5469152572063299, 0.5459967060731008, 0.5266895431738633, 0.5488852319809107, 0.5148855224251747, 0.5343886292897738, 0.5354249271062704, 0.5246145650744438, 0.5388853698968887, 0.5395378585045154, 0.5410740323937856, 0.5479488155016532], 'loss': [3.005992108832467, 1.3273264821644564, 0.9755233329929769, 0.8231151423187787, 0.725344473520988, 0.6661797356288899, 0.6080771565250417, 0.5708745667759172, 0.5424918167421565, 0.518826263275004, 0.5018824615360219, 0.4860422184994374, 0.47612527415759665, 0.4636690457934967, 0.45484809586397784, 0.44665775613889014, 0.43745497885219153, 0.43319823378996797, 0.4240490629352415, 0.41956623857128855, 0.41555675486296645, 0.4090345249419655, 0.4028682842373815, 0.3989138417162381, 0.39329720753910113, 0.38357727366609456, 0.3764679068312108, 0.37215507657152147, 0.3710740229129835, 0.3658884490046413, 0.36340223884248296, 0.36388377937775396, 0.3576423925941395, 0.356568877625859, 0.3533978752244237, 0.35277566574304337, 0.34925545533127994, 0.34797786416014015, 0.34423685569412693, 0.3420148004517392, 0.34162658051976985, 0.3391851818557156, 0.33960424805989203, 0.338103323776344, 0.33443005290526606, 0.33255288384722176, 0.3311838780691359, 0.3300190165200533, 0.3275859266956563, 0.3285346130300995, 0.3293501560394256, 0.32607591513622997, 0.3233820340333912, 0.32453595072561486, 0.3221488785811877, 0.3212584590055423, 0.31973344835201156, 0.31837360607756465, 0.3180483355273029, 0.31509966757600294, 0.3147814303298482, 0.3148225359560258, 0.31416280922069106, 0.31436636352147673, 0.3121828471647905, 0.3112038298170142, 0.31074371730820627, 0.3080722086655855, 0.3080069489538653, 0.30641285185553124, 0.3077198607306149, 0.30626442341592097, 0.3040851745797426, 0.3036345638307953, 0.3046845323257997], 'acc': [0.5448248459700122, 0.8776526972837008, 0.8872591719453233, 0.8934881325842412, 0.8997391737783833, 0.9053212058980625, 0.9106757770734202, 0.9149075278461414, 0.9187724801168817, 0.9219577823861174, 0.9242466081335439, 0.9263069168245793, 0.927613218068351, 0.929036502209051, 0.9300735280993767, 0.9309487619611552, 0.931881101014022, 0.9324493718732165, 0.9335648153943681, 0.9340691266657516, 0.9344747627418023, 0.9351560579480406, 0.9356726725020335, 0.9358061580742394, 0.9363402674902435, 0.9364973814804308, 0.9368501443281546, 0.9369932042324355, 0.9370710395264865, 0.9373665381970907, 0.9376648083380048, 0.9375743815118972, 0.937893645114524, 0.9380042687955844, 0.9382334378475217, 0.9382479378880911, 0.938721588817149, 0.9386631040173814, 0.9388697672118936, 0.9391408799033889, 0.9390447523324986, 0.9393216066174453, 0.9394300371686064, 0.9393290346490933, 0.9397747976131504, 0.9399024707512652, 0.9399440625018874, 0.9400570827756082, 0.94029480543214, 0.9400914232526155, 0.9400867027274623, 0.9404035059770051, 0.9408027116062566, 0.9407593509944879, 0.9407288646231847, 0.940871591400003, 0.940979780525692, 0.9412089457186915, 0.9412263724226293, 0.9415430849706468, 0.9414878005659537, 0.9415391852723093, 0.9415510225304816, 0.9416652876853855, 0.9417598178814799, 0.9418151071950495, 0.9419609381793489, 0.9422013444796289, 0.9421151482530112, 0.9423335881500593, 0.9422539117909506, 0.9423683926010994, 0.942630677538517, 0.9426556231900136, 0.9424957581071256], 'mDice': [0.07940665080100312, 0.26243685589256205, 0.36318980483488544, 0.4233845724595997, 0.467847146226462, 0.4975315966498837, 0.5276202096123762, 0.5480288601796763, 0.5646551110246882, 0.5786550604944177, 0.588752986913588, 0.5986320441536366, 0.6049090062605547, 0.6127150335798269, 0.6182115562428498, 0.6235789609639217, 0.629603024553925, 0.6324015653607239, 0.6383262685191133, 0.6412374358395748, 0.6438483748061734, 0.6483388480187606, 0.6524470144506421, 0.654920650575144, 0.6588882231617792, 0.6658165177812571, 0.6707886214033326, 0.6739748839928327, 0.6747114980758407, 0.6782688964263084, 0.6802598254977255, 0.6797011907905667, 0.6842251389182539, 0.6850534832522646, 0.6872789049119975, 0.6877552100700238, 0.6902900234223468, 0.6913418875270078, 0.6938862251826431, 0.6954880108706221, 0.6958027696802994, 0.6976431949182837, 0.6972970112293813, 0.6983736564804572, 0.7011425810349248, 0.7024478434658816, 0.7033673478791187, 0.7042519961359491, 0.7059943928969673, 0.7054765478640941, 0.7047508257754469, 0.7071843417513407, 0.7092119689677283, 0.7085277113672179, 0.7101672709202576, 0.7107267015745288, 0.7119359310225434, 0.7129467709922245, 0.7132275194564582, 0.7153474334299283, 0.7155883865119852, 0.7156356618785444, 0.716090690657561, 0.7160365523683357, 0.7175622174498627, 0.7182039844806175, 0.7186937230622582, 0.7206800989171054, 0.7206784183552682, 0.7218973172785094, 0.7209607105924449, 0.7220841776364889, 0.7236772007985297, 0.7239792106237994, 0.7233135081696398]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.22s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.98s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:34,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:58,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:55,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:24,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:39,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:20,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:33,  1.63s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:30,  1.63s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:55,  1.72s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:11,  1.79s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:42,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<07:59,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:48,  1.72s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:51,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:59,  1.78s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:03,  1.80s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:37,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:40,  1.72s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:27,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:27,  1.69s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:43,  1.76s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:32,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:30,  1.72s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:21,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:46,  1.80s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<08:03,  1.87s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:48,  1.81s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:46,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:46,  1.82s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:55,  1.87s/it]predicting train subjects:  11%|█         | 31/285 [00:53<08:00,  1.89s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:40,  1.82s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:29,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:31,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:46,  1.86s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:29,  1.81s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:30,  1.82s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:16,  1.78s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:27,  1.83s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<07:11,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<07:01,  1.73s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<07:19,  1.82s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:25,  1.85s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<07:08,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:23,  1.86s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<07:11,  1.81s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<07:23,  1.87s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:35,  1.93s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:23,  1.89s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:25,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<07:04,  1.82s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<07:03,  1.83s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<07:14,  1.88s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:50,  1.79s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:52,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:36,  1.74s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:34,  1.74s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:45,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:53,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:48,  1.83s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:56,  1.87s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:58,  1.89s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<06:51,  1.86s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:44,  1.84s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:34,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [01:59<06:29,  1.79s/it]predicting train subjects:  24%|██▍       | 68/285 [02:01<06:17,  1.74s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:18,  1.75s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:29,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:08<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:06,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<06:05,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<06:10,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<06:17,  1.80s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:55,  1.72s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:51,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:37,  1.65s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:39,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:34,  1.66s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:45,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:54,  1.78s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:59,  1.81s/it]predicting train subjects:  31%|███       | 88/285 [02:35<05:42,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:37<05:43,  1.75s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:50,  1.80s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<05:46,  1.79s/it]predicting train subjects:  32%|███▏      | 92/285 [02:43<05:55,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:44<05:46,  1.81s/it]predicting train subjects:  33%|███▎      | 94/285 [02:46<05:48,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:48<05:43,  1.81s/it]predicting train subjects:  34%|███▎      | 96/285 [02:50<05:40,  1.80s/it]predicting train subjects:  34%|███▍      | 97/285 [02:52<05:39,  1.81s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<05:34,  1.79s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<05:31,  1.78s/it]predicting train subjects:  35%|███▌      | 100/285 [02:57<05:36,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [02:59<05:30,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:01<05:34,  1.83s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:25,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:26,  1.81s/it]predicting train subjects:  37%|███▋      | 105/285 [03:06<05:30,  1.83s/it]predicting train subjects:  37%|███▋      | 106/285 [03:08<05:15,  1.76s/it]predicting train subjects:  38%|███▊      | 107/285 [03:10<05:18,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:11<05:11,  1.76s/it]predicting train subjects:  38%|███▊      | 109/285 [03:13<05:15,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:15<05:17,  1.81s/it]predicting train subjects:  39%|███▉      | 111/285 [03:17<05:15,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:19<05:13,  1.81s/it]predicting train subjects:  40%|███▉      | 113/285 [03:20<05:08,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:22<05:05,  1.79s/it]predicting train subjects:  40%|████      | 115/285 [03:24<05:10,  1.83s/it]predicting train subjects:  41%|████      | 116/285 [03:26<05:22,  1.91s/it]predicting train subjects:  41%|████      | 117/285 [03:28<05:21,  1.92s/it]predicting train subjects:  41%|████▏     | 118/285 [03:30<05:10,  1.86s/it]predicting train subjects:  42%|████▏     | 119/285 [03:32<05:07,  1.85s/it]predicting train subjects:  42%|████▏     | 120/285 [03:33<04:55,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:35<04:50,  1.77s/it]predicting train subjects:  43%|████▎     | 122/285 [03:37<04:42,  1.73s/it]predicting train subjects:  43%|████▎     | 123/285 [03:38<04:23,  1.63s/it]predicting train subjects:  44%|████▎     | 124/285 [03:40<04:19,  1.61s/it]predicting train subjects:  44%|████▍     | 125/285 [03:41<04:15,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:43<04:11,  1.58s/it]predicting train subjects:  45%|████▍     | 127/285 [03:44<04:05,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:46<04:05,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:47<04:03,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:49<03:57,  1.53s/it]predicting train subjects:  46%|████▌     | 131/285 [03:50<03:59,  1.55s/it]predicting train subjects:  46%|████▋     | 132/285 [03:52<03:59,  1.57s/it]predicting train subjects:  47%|████▋     | 133/285 [03:54<04:02,  1.60s/it]predicting train subjects:  47%|████▋     | 134/285 [03:55<03:59,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [03:57<03:50,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [03:58<03:44,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:00<03:50,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:02<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:03<03:53,  1.60s/it]predicting train subjects:  49%|████▉     | 140/285 [04:05<03:58,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:06<03:54,  1.63s/it]predicting train subjects:  50%|████▉     | 142/285 [04:08<03:50,  1.61s/it]predicting train subjects:  50%|█████     | 143/285 [04:10<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:11<03:46,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:13<03:46,  1.62s/it]predicting train subjects:  51%|█████     | 146/285 [04:15<03:50,  1.66s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:16<03:42,  1.61s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:18<03:43,  1.63s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:19<03:32,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:21<03:28,  1.55s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:23<03:38,  1.63s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:24<03:37,  1.63s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:26<03:38,  1.66s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:28<03:45,  1.72s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:29<03:43,  1.72s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:31<03:36,  1.68s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:32<03:25,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:37<03:16,  1.58s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:19,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:40<03:13,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:42<03:16,  1.61s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:43<03:08,  1.56s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:45<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<03:08,  1.58s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:48<03:07,  1.59s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:50<03:02,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:51<03:00,  1.56s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:53<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [04:54<02:51,  1.50s/it]predicting train subjects:  60%|██████    | 172/285 [04:56<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [04:57<02:56,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [04:59<02:50,  1.53s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:01<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:02<02:59,  1.64s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:04<03:02,  1.69s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:06<02:51,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:07<02:42,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:09<02:52,  1.64s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:11<02:57,  1.71s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:12<02:58,  1.74s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:14<02:47,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:15<02:39,  1.58s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:17<02:33,  1.54s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:19<02:45,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:21<02:49,  1.72s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:22<02:49,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:40,  1.67s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:25<02:33,  1.61s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:27<02:35,  1.65s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:29<02:34,  1.67s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:30<02:25,  1.58s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:32<02:26,  1.61s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:33<02:17,  1.52s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:35<02:30,  1.69s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:37<02:35,  1.77s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:39<02:37,  1.81s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:41<02:28,  1.72s/it]predicting train subjects:  70%|███████   | 200/285 [05:42<02:18,  1.63s/it]predicting train subjects:  71%|███████   | 201/285 [05:44<02:26,  1.75s/it]predicting train subjects:  71%|███████   | 202/285 [05:46<02:26,  1.77s/it]predicting train subjects:  71%|███████   | 203/285 [05:48<02:24,  1.76s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:49<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:50<02:07,  1.60s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:52<02:03,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:54<02:08,  1.65s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:09,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:57<02:11,  1.73s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:59<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:00<01:55,  1.56s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:02<01:56,  1.59s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:04<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:05<01:51,  1.57s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:07<01:55,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:08<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:10<01:50,  1.62s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:12<01:52,  1.68s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:14<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:15<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:16<01:39,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:18<01:38,  1.57s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:19<01:33,  1.50s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:21<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:22<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:24<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:26<01:35,  1.65s/it]predicting train subjects:  80%|████████  | 228/285 [06:28<01:37,  1.71s/it]predicting train subjects:  80%|████████  | 229/285 [06:29<01:34,  1.68s/it]predicting train subjects:  81%|████████  | 230/285 [06:31<01:26,  1.57s/it]predicting train subjects:  81%|████████  | 231/285 [06:32<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:34<01:24,  1.60s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:35<01:19,  1.54s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:37<01:21,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:38<01:16,  1.53s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:40<01:20,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:42<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:44<01:20,  1.71s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:46<01:18,  1.72s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:47<01:12,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:48<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:50<01:05,  1.52s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:51<01:02,  1.48s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:53<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:54<01:00,  1.52s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:56<01:03,  1.62s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:58<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:00<01:01,  1.67s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:01<00:57,  1.58s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:02<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:04<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:05<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:07<00:50,  1.57s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:09<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:11<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:12<00:45,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:17<00:42,  1.63s/it]predicting train subjects:  91%|█████████ | 260/285 [07:18<00:38,  1.55s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:20<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:21<00:33,  1.48s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:22<00:31,  1.45s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:24<00:33,  1.59s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:26<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:27<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:29<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:31<00:27,  1.61s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:32<00:26,  1.63s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:34<00:22,  1.52s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:35<00:20,  1.48s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:37<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:38<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:39<00:15,  1.45s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:41<00:16,  1.60s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:43<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:45<00:12,  1.57s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:46<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:48<00:09,  1.59s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:49<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:50<00:05,  1.48s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:52<00:04,  1.43s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:53<00:03,  1.52s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:55<00:01,  1.65s/it]predicting train subjects: 100%|██████████| 285/285 [07:57<00:00,  1.71s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:10,  1.94s/it]Loading train:   1%|          | 2/285 [00:03<08:22,  1.77s/it]Loading train:   1%|          | 3/285 [00:04<08:00,  1.70s/it]Loading train:   1%|▏         | 4/285 [00:06<07:14,  1.55s/it]Loading train:   2%|▏         | 5/285 [00:07<07:27,  1.60s/it]Loading train:   2%|▏         | 6/285 [00:09<07:05,  1.53s/it]Loading train:   2%|▏         | 7/285 [00:10<07:08,  1.54s/it]Loading train:   3%|▎         | 8/285 [00:12<06:59,  1.51s/it]Loading train:   3%|▎         | 9/285 [00:14<07:26,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<06:49,  1.49s/it]Loading train:   4%|▍         | 11/285 [00:16<06:00,  1.31s/it]Loading train:   4%|▍         | 12/285 [00:17<05:54,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:18<05:16,  1.16s/it]Loading train:   5%|▍         | 14/285 [00:19<05:06,  1.13s/it]Loading train:   5%|▌         | 15/285 [00:20<05:09,  1.15s/it]Loading train:   6%|▌         | 16/285 [00:21<05:00,  1.12s/it]Loading train:   6%|▌         | 17/285 [00:22<04:36,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:23<04:50,  1.09s/it]Loading train:   7%|▋         | 19/285 [00:24<04:47,  1.08s/it]Loading train:   7%|▋         | 20/285 [00:25<04:47,  1.09s/it]Loading train:   7%|▋         | 21/285 [00:27<05:03,  1.15s/it]Loading train:   8%|▊         | 22/285 [00:27<04:39,  1.06s/it]Loading train:   8%|▊         | 23/285 [00:28<04:31,  1.04s/it]Loading train:   8%|▊         | 24/285 [00:29<04:14,  1.03it/s]Loading train:   9%|▉         | 25/285 [00:30<04:24,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:31<04:19,  1.00s/it]Loading train:   9%|▉         | 27/285 [00:32<04:07,  1.04it/s]Loading train:  10%|▉         | 28/285 [00:33<04:19,  1.01s/it]Loading train:  10%|█         | 29/285 [00:34<04:22,  1.03s/it]Loading train:  11%|█         | 30/285 [00:36<04:43,  1.11s/it]Loading train:  11%|█         | 31/285 [00:37<04:51,  1.15s/it]Loading train:  11%|█         | 32/285 [00:38<04:43,  1.12s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:45,  1.13s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:46,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:59,  1.20s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:46,  1.15s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:52,  1.18s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:45,  1.16s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:37,  1.13s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:37,  1.13s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:30,  1.11s/it]Loading train:  15%|█▍        | 42/285 [00:49<04:05,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:50<04:15,  1.06s/it]Loading train:  15%|█▌        | 44/285 [00:51<04:16,  1.06s/it]Loading train:  16%|█▌        | 45/285 [00:52<04:14,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:53<04:16,  1.07s/it]Loading train:  16%|█▋        | 47/285 [00:54<03:53,  1.02it/s]Loading train:  17%|█▋        | 48/285 [00:55<04:03,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:56<03:58,  1.01s/it]Loading train:  18%|█▊        | 50/285 [00:57<04:08,  1.06s/it]Loading train:  18%|█▊        | 51/285 [00:58<03:57,  1.01s/it]Loading train:  18%|█▊        | 52/285 [00:59<03:57,  1.02s/it]Loading train:  19%|█▊        | 53/285 [01:01<04:05,  1.06s/it]Loading train:  19%|█▉        | 54/285 [01:02<04:15,  1.11s/it]Loading train:  19%|█▉        | 55/285 [01:03<03:51,  1.01s/it]Loading train:  20%|█▉        | 56/285 [01:04<04:00,  1.05s/it]Loading train:  20%|██        | 57/285 [01:05<03:47,  1.00it/s]Loading train:  20%|██        | 58/285 [01:06<03:59,  1.06s/it]Loading train:  21%|██        | 59/285 [01:07<04:08,  1.10s/it]Loading train:  21%|██        | 60/285 [01:08<03:56,  1.05s/it]Loading train:  21%|██▏       | 61/285 [01:09<04:01,  1.08s/it]Loading train:  22%|██▏       | 62/285 [01:10<03:55,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:11<03:52,  1.05s/it]Loading train:  22%|██▏       | 64/285 [01:12<04:15,  1.16s/it]Loading train:  23%|██▎       | 65/285 [01:14<05:03,  1.38s/it]Loading train:  23%|██▎       | 66/285 [01:16<05:21,  1.47s/it]Loading train:  24%|██▎       | 67/285 [01:17<05:03,  1.39s/it]Loading train:  24%|██▍       | 68/285 [01:18<04:28,  1.24s/it]Loading train:  24%|██▍       | 69/285 [01:19<04:22,  1.21s/it]Loading train:  25%|██▍       | 70/285 [01:20<04:09,  1.16s/it]Loading train:  25%|██▍       | 71/285 [01:21<04:04,  1.14s/it]Loading train:  25%|██▌       | 72/285 [01:22<03:48,  1.07s/it]Loading train:  26%|██▌       | 73/285 [01:24<03:53,  1.10s/it]Loading train:  26%|██▌       | 74/285 [01:24<03:45,  1.07s/it]Loading train:  26%|██▋       | 75/285 [01:26<03:50,  1.10s/it]Loading train:  27%|██▋       | 76/285 [01:27<03:55,  1.13s/it]Loading train:  27%|██▋       | 77/285 [01:28<03:43,  1.07s/it]Loading train:  27%|██▋       | 78/285 [01:29<03:29,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:30<03:23,  1.01it/s]Loading train:  28%|██▊       | 80/285 [01:31<03:24,  1.00it/s]Loading train:  28%|██▊       | 81/285 [01:32<03:29,  1.03s/it]Loading train:  29%|██▉       | 82/285 [01:33<03:25,  1.01s/it]Loading train:  29%|██▉       | 83/285 [01:34<03:34,  1.06s/it]Loading train:  29%|██▉       | 84/285 [01:35<03:43,  1.11s/it]Loading train:  30%|██▉       | 85/285 [01:36<03:30,  1.05s/it]Loading train:  30%|███       | 86/285 [01:38<03:54,  1.18s/it]Loading train:  31%|███       | 87/285 [01:39<03:55,  1.19s/it]Loading train:  31%|███       | 88/285 [01:40<03:41,  1.12s/it]Loading train:  31%|███       | 89/285 [01:41<03:28,  1.06s/it]Loading train:  32%|███▏      | 90/285 [01:41<03:16,  1.01s/it]Loading train:  32%|███▏      | 91/285 [01:42<03:05,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:43<02:58,  1.08it/s]Loading train:  33%|███▎      | 93/285 [01:44<02:51,  1.12it/s]Loading train:  33%|███▎      | 94/285 [01:45<02:48,  1.13it/s]Loading train:  33%|███▎      | 95/285 [01:46<02:50,  1.11it/s]Loading train:  34%|███▎      | 96/285 [01:47<02:57,  1.06it/s]Loading train:  34%|███▍      | 97/285 [01:48<03:07,  1.00it/s]Loading train:  34%|███▍      | 98/285 [01:49<03:06,  1.00it/s]Loading train:  35%|███▍      | 99/285 [01:50<03:07,  1.01s/it]Loading train:  35%|███▌      | 100/285 [01:51<03:11,  1.03s/it]Loading train:  35%|███▌      | 101/285 [01:52<03:17,  1.08s/it]Loading train:  36%|███▌      | 102/285 [01:53<03:21,  1.10s/it]Loading train:  36%|███▌      | 103/285 [01:54<03:15,  1.08s/it]Loading train:  36%|███▋      | 104/285 [01:56<03:16,  1.09s/it]Loading train:  37%|███▋      | 105/285 [01:57<03:09,  1.05s/it]Loading train:  37%|███▋      | 106/285 [01:57<03:01,  1.01s/it]Loading train:  38%|███▊      | 107/285 [01:58<02:54,  1.02it/s]Loading train:  38%|███▊      | 108/285 [01:59<02:56,  1.00it/s]Loading train:  38%|███▊      | 109/285 [02:00<02:52,  1.02it/s]Loading train:  39%|███▊      | 110/285 [02:01<03:00,  1.03s/it]Loading train:  39%|███▉      | 111/285 [02:02<02:53,  1.00it/s]Loading train:  39%|███▉      | 112/285 [02:04<03:02,  1.05s/it]Loading train:  40%|███▉      | 113/285 [02:05<02:56,  1.02s/it]Loading train:  40%|████      | 114/285 [02:06<02:52,  1.01s/it]Loading train:  40%|████      | 115/285 [02:06<02:49,  1.00it/s]Loading train:  41%|████      | 116/285 [02:08<02:53,  1.02s/it]Loading train:  41%|████      | 117/285 [02:08<02:47,  1.00it/s]Loading train:  41%|████▏     | 118/285 [02:09<02:42,  1.03it/s]Loading train:  42%|████▏     | 119/285 [02:11<03:02,  1.10s/it]Loading train:  42%|████▏     | 120/285 [02:12<03:02,  1.11s/it]Loading train:  42%|████▏     | 121/285 [02:13<03:20,  1.22s/it]Loading train:  43%|████▎     | 122/285 [02:15<03:16,  1.20s/it]Loading train:  43%|████▎     | 123/285 [02:16<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:17<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:18<02:52,  1.08s/it]Loading train:  44%|████▍     | 126/285 [02:19<02:48,  1.06s/it]Loading train:  45%|████▍     | 127/285 [02:20<02:41,  1.02s/it]Loading train:  45%|████▍     | 128/285 [02:21<02:40,  1.02s/it]Loading train:  45%|████▌     | 129/285 [02:22<02:33,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:22<02:30,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:23<02:27,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:24<02:23,  1.07it/s]Loading train:  47%|████▋     | 133/285 [02:25<02:33,  1.01s/it]Loading train:  47%|████▋     | 134/285 [02:26<02:30,  1.01it/s]Loading train:  47%|████▋     | 135/285 [02:27<02:26,  1.02it/s]Loading train:  48%|████▊     | 136/285 [02:28<02:22,  1.04it/s]Loading train:  48%|████▊     | 137/285 [02:29<02:17,  1.08it/s]Loading train:  48%|████▊     | 138/285 [02:30<02:16,  1.08it/s]Loading train:  49%|████▉     | 139/285 [02:31<02:12,  1.10it/s]Loading train:  49%|████▉     | 140/285 [02:32<02:12,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:33<02:19,  1.03it/s]Loading train:  50%|████▉     | 142/285 [02:34<02:17,  1.04it/s]Loading train:  50%|█████     | 143/285 [02:35<02:18,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:36<02:12,  1.06it/s]Loading train:  51%|█████     | 145/285 [02:37<02:09,  1.08it/s]Loading train:  51%|█████     | 146/285 [02:38<02:08,  1.08it/s]Loading train:  52%|█████▏    | 147/285 [02:38<01:59,  1.15it/s]Loading train:  52%|█████▏    | 148/285 [02:39<02:01,  1.12it/s]Loading train:  52%|█████▏    | 149/285 [02:40<01:56,  1.17it/s]Loading train:  53%|█████▎    | 150/285 [02:41<01:53,  1.19it/s]Loading train:  53%|█████▎    | 151/285 [02:42<01:55,  1.16it/s]Loading train:  53%|█████▎    | 152/285 [02:43<01:55,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [02:44<01:58,  1.11it/s]Loading train:  54%|█████▍    | 154/285 [02:45<01:58,  1.10it/s]Loading train:  54%|█████▍    | 155/285 [02:45<01:55,  1.13it/s]Loading train:  55%|█████▍    | 156/285 [02:46<01:57,  1.09it/s]Loading train:  55%|█████▌    | 157/285 [02:47<01:55,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [02:48<01:55,  1.10it/s]Loading train:  56%|█████▌    | 159/285 [02:49<01:54,  1.10it/s]Loading train:  56%|█████▌    | 160/285 [02:50<01:49,  1.14it/s]Loading train:  56%|█████▋    | 161/285 [02:51<01:57,  1.06it/s]Loading train:  57%|█████▋    | 162/285 [02:52<01:47,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:53<01:46,  1.15it/s]Loading train:  58%|█████▊    | 164/285 [02:53<01:43,  1.17it/s]Loading train:  58%|█████▊    | 165/285 [02:54<01:45,  1.13it/s]Loading train:  58%|█████▊    | 166/285 [02:55<01:42,  1.16it/s]Loading train:  59%|█████▊    | 167/285 [02:56<01:40,  1.17it/s]Loading train:  59%|█████▉    | 168/285 [02:57<01:36,  1.21it/s]Loading train:  59%|█████▉    | 169/285 [02:57<01:29,  1.30it/s]Loading train:  60%|█████▉    | 170/285 [02:58<01:26,  1.33it/s]Loading train:  60%|██████    | 171/285 [02:59<01:22,  1.39it/s]Loading train:  60%|██████    | 172/285 [02:59<01:19,  1.42it/s]Loading train:  61%|██████    | 173/285 [03:00<01:25,  1.31it/s]Loading train:  61%|██████    | 174/285 [03:01<01:28,  1.25it/s]Loading train:  61%|██████▏   | 175/285 [03:02<01:32,  1.19it/s]Loading train:  62%|██████▏   | 176/285 [03:03<01:32,  1.17it/s]Loading train:  62%|██████▏   | 177/285 [03:04<01:32,  1.16it/s]Loading train:  62%|██████▏   | 178/285 [03:05<01:26,  1.23it/s]Loading train:  63%|██████▎   | 179/285 [03:05<01:31,  1.16it/s]Loading train:  63%|██████▎   | 180/285 [03:07<01:39,  1.06it/s]Loading train:  64%|██████▎   | 181/285 [03:08<01:40,  1.03it/s]Loading train:  64%|██████▍   | 182/285 [03:09<01:38,  1.05it/s]Loading train:  64%|██████▍   | 183/285 [03:10<01:36,  1.06it/s]Loading train:  65%|██████▍   | 184/285 [03:10<01:30,  1.11it/s]Loading train:  65%|██████▍   | 185/285 [03:11<01:28,  1.13it/s]Loading train:  65%|██████▌   | 186/285 [03:12<01:35,  1.04it/s]Loading train:  66%|██████▌   | 187/285 [03:14<01:41,  1.04s/it]Loading train:  66%|██████▌   | 188/285 [03:15<01:44,  1.08s/it]Loading train:  66%|██████▋   | 189/285 [03:16<01:39,  1.03s/it]Loading train:  67%|██████▋   | 190/285 [03:16<01:32,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [03:17<01:31,  1.03it/s]Loading train:  67%|██████▋   | 192/285 [03:18<01:30,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [03:19<01:31,  1.00it/s]Loading train:  68%|██████▊   | 194/285 [03:20<01:28,  1.03it/s]Loading train:  68%|██████▊   | 195/285 [03:21<01:23,  1.08it/s]Loading train:  69%|██████▉   | 196/285 [03:22<01:23,  1.06it/s]Loading train:  69%|██████▉   | 197/285 [03:23<01:23,  1.05it/s]Loading train:  69%|██████▉   | 198/285 [03:24<01:26,  1.01it/s]Loading train:  70%|██████▉   | 199/285 [03:25<01:21,  1.06it/s]Loading train:  70%|███████   | 200/285 [03:26<01:17,  1.09it/s]Loading train:  71%|███████   | 201/285 [03:27<01:24,  1.01s/it]Loading train:  71%|███████   | 202/285 [03:28<01:19,  1.05it/s]Loading train:  71%|███████   | 203/285 [03:29<01:16,  1.07it/s]Loading train:  72%|███████▏  | 204/285 [03:30<01:11,  1.13it/s]Loading train:  72%|███████▏  | 205/285 [03:30<01:09,  1.15it/s]Loading train:  72%|███████▏  | 206/285 [03:31<01:09,  1.14it/s]Loading train:  73%|███████▎  | 207/285 [03:32<01:12,  1.07it/s]Loading train:  73%|███████▎  | 208/285 [03:33<01:12,  1.06it/s]Loading train:  73%|███████▎  | 209/285 [03:34<01:12,  1.05it/s]Loading train:  74%|███████▎  | 210/285 [03:35<01:08,  1.09it/s]Loading train:  74%|███████▍  | 211/285 [03:36<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:37<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:38<01:06,  1.09it/s]Loading train:  75%|███████▌  | 214/285 [03:39<01:03,  1.12it/s]Loading train:  75%|███████▌  | 215/285 [03:40<01:09,  1.01it/s]Loading train:  76%|███████▌  | 216/285 [03:41<01:07,  1.03it/s]Loading train:  76%|███████▌  | 217/285 [03:42<01:06,  1.03it/s]Loading train:  76%|███████▋  | 218/285 [03:43<01:09,  1.04s/it]Loading train:  77%|███████▋  | 219/285 [03:45<01:20,  1.22s/it]Loading train:  77%|███████▋  | 220/285 [03:46<01:21,  1.25s/it]Loading train:  78%|███████▊  | 221/285 [03:47<01:10,  1.11s/it]Loading train:  78%|███████▊  | 222/285 [03:49<01:19,  1.26s/it]Loading train:  78%|███████▊  | 223/285 [03:50<01:15,  1.21s/it]Loading train:  79%|███████▊  | 224/285 [03:51<01:10,  1.16s/it]Loading train:  79%|███████▉  | 225/285 [03:52<01:17,  1.29s/it]Loading train:  79%|███████▉  | 226/285 [03:54<01:21,  1.38s/it]Loading train:  80%|███████▉  | 227/285 [03:55<01:17,  1.34s/it]Loading train:  80%|████████  | 228/285 [03:57<01:18,  1.37s/it]Loading train:  80%|████████  | 229/285 [03:58<01:14,  1.33s/it]Loading train:  81%|████████  | 230/285 [03:59<01:09,  1.27s/it]Loading train:  81%|████████  | 231/285 [04:00<01:13,  1.37s/it]Loading train:  81%|████████▏ | 232/285 [04:02<01:08,  1.28s/it]Loading train:  82%|████████▏ | 233/285 [04:03<01:14,  1.42s/it]Loading train:  82%|████████▏ | 234/285 [04:05<01:13,  1.45s/it]Loading train:  82%|████████▏ | 235/285 [04:06<01:04,  1.30s/it]Loading train:  83%|████████▎ | 236/285 [04:07<01:09,  1.41s/it]Loading train:  83%|████████▎ | 237/285 [04:09<01:07,  1.41s/it]Loading train:  84%|████████▎ | 238/285 [04:10<01:08,  1.46s/it]Loading train:  84%|████████▍ | 239/285 [04:12<01:08,  1.49s/it]Loading train:  84%|████████▍ | 240/285 [04:13<01:00,  1.35s/it]Loading train:  85%|████████▍ | 241/285 [04:14<00:52,  1.20s/it]Loading train:  85%|████████▍ | 242/285 [04:16<01:00,  1.40s/it]Loading train:  85%|████████▌ | 243/285 [04:17<01:00,  1.45s/it]Loading train:  86%|████████▌ | 244/285 [04:19<01:03,  1.55s/it]Loading train:  86%|████████▌ | 245/285 [04:20<00:55,  1.39s/it]Loading train:  86%|████████▋ | 246/285 [04:22<00:56,  1.44s/it]Loading train:  87%|████████▋ | 247/285 [04:23<00:53,  1.41s/it]Loading train:  87%|████████▋ | 248/285 [04:24<00:49,  1.35s/it]Loading train:  87%|████████▋ | 249/285 [04:26<00:49,  1.39s/it]Loading train:  88%|████████▊ | 250/285 [04:27<00:49,  1.41s/it]Loading train:  88%|████████▊ | 251/285 [04:28<00:43,  1.27s/it]Loading train:  88%|████████▊ | 252/285 [04:29<00:41,  1.26s/it]Loading train:  89%|████████▉ | 253/285 [04:30<00:39,  1.22s/it]Loading train:  89%|████████▉ | 254/285 [04:32<00:38,  1.25s/it]Loading train:  89%|████████▉ | 255/285 [04:33<00:38,  1.27s/it]Loading train:  90%|████████▉ | 256/285 [04:34<00:34,  1.19s/it]Loading train:  90%|█████████ | 257/285 [04:35<00:32,  1.15s/it]Loading train:  91%|█████████ | 258/285 [04:37<00:34,  1.28s/it]Loading train:  91%|█████████ | 259/285 [04:38<00:35,  1.36s/it]Loading train:  91%|█████████ | 260/285 [04:39<00:30,  1.22s/it]Loading train:  92%|█████████▏| 261/285 [04:40<00:28,  1.18s/it]Loading train:  92%|█████████▏| 262/285 [04:42<00:29,  1.28s/it]Loading train:  92%|█████████▏| 263/285 [04:43<00:31,  1.41s/it]Loading train:  93%|█████████▎| 264/285 [04:45<00:30,  1.47s/it]Loading train:  93%|█████████▎| 265/285 [04:47<00:30,  1.52s/it]Loading train:  93%|█████████▎| 266/285 [04:48<00:25,  1.33s/it]Loading train:  94%|█████████▎| 267/285 [04:49<00:24,  1.38s/it]Loading train:  94%|█████████▍| 268/285 [04:51<00:24,  1.46s/it]Loading train:  94%|█████████▍| 269/285 [04:52<00:24,  1.51s/it]Loading train:  95%|█████████▍| 270/285 [04:53<00:20,  1.34s/it]Loading train:  95%|█████████▌| 271/285 [04:54<00:18,  1.29s/it]Loading train:  95%|█████████▌| 272/285 [04:56<00:18,  1.39s/it]Loading train:  96%|█████████▌| 273/285 [04:57<00:15,  1.33s/it]Loading train:  96%|█████████▌| 274/285 [04:58<00:13,  1.21s/it]Loading train:  96%|█████████▋| 275/285 [05:00<00:13,  1.32s/it]Loading train:  97%|█████████▋| 276/285 [05:02<00:13,  1.52s/it]Loading train:  97%|█████████▋| 277/285 [05:03<00:11,  1.47s/it]Loading train:  98%|█████████▊| 278/285 [05:04<00:09,  1.35s/it]Loading train:  98%|█████████▊| 279/285 [05:06<00:08,  1.43s/it]Loading train:  98%|█████████▊| 280/285 [05:07<00:07,  1.41s/it]Loading train:  99%|█████████▊| 281/285 [05:08<00:04,  1.21s/it]Loading train:  99%|█████████▉| 282/285 [05:09<00:03,  1.26s/it]Loading train:  99%|█████████▉| 283/285 [05:12<00:03,  1.54s/it]Loading train: 100%|█████████▉| 284/285 [05:13<00:01,  1.51s/it]Loading train: 100%|██████████| 285/285 [05:14<00:00,  1.37s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:05, 47.94it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:05, 49.07it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:05, 52.45it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:05, 50.44it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:05, 43.14it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:07, 36.10it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:10, 24.62it/s]concatenating: train:  13%|█▎        | 38/285 [00:01<00:10, 22.71it/s]concatenating: train:  15%|█▌        | 44/285 [00:01<00:08, 27.75it/s]concatenating: train:  21%|██        | 59/285 [00:01<00:06, 36.65it/s]concatenating: train:  32%|███▏      | 91/285 [00:01<00:03, 49.89it/s]concatenating: train:  44%|████▍     | 125/285 [00:01<00:02, 66.96it/s]concatenating: train:  56%|█████▌    | 159/285 [00:01<00:01, 88.21it/s]concatenating: train:  65%|██████▍   | 184/285 [00:02<00:01, 64.96it/s]concatenating: train:  71%|███████   | 203/285 [00:02<00:01, 56.42it/s]concatenating: train:  76%|███████▌  | 217/285 [00:03<00:01, 45.78it/s]concatenating: train:  80%|████████  | 228/285 [00:03<00:01, 42.43it/s]concatenating: train:  83%|████████▎ | 237/285 [00:03<00:01, 38.91it/s]concatenating: train:  86%|████████▌ | 245/285 [00:03<00:01, 38.99it/s]concatenating: train:  90%|█████████ | 257/285 [00:04<00:00, 48.43it/s]concatenating: train:  95%|█████████▍| 270/285 [00:04<00:00, 59.62it/s]concatenating: train:  99%|█████████▉| 283/285 [00:04<00:00, 70.74it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 66.58it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.66s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.62s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.51s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 22.92it/s]2019-07-10 23:07:29.889064: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:07:29.889204: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:07:29.889223: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:07:29.889236: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:07:29.889805: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.36it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.20it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.78it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.20it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.70it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.62it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.59it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.21it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.48it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:05,  4.09it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:05,  4.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.38it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.37it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.76it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.37it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.43it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.16it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.89it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.04it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  6.41it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  4.39it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.83it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   598         dropout_7[0][0]                  
==================================================================================================
Total params: 139,198
Trainable params: 40,618
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 17s - loss: 3.4962 - acc: 0.3406 - mDice: 0.0460 - val_loss: 3.8392 - val_acc: 0.6390 - val_mDice: 0.0450

Epoch 00001: val_mDice improved from -inf to 0.04503, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.7937 - acc: 0.8532 - mDice: 0.1754 - val_loss: 2.4237 - val_acc: 0.9031 - val_mDice: 0.1606

Epoch 00002: val_mDice improved from 0.04503 to 0.16056, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 1.3103 - acc: 0.8685 - mDice: 0.2592 - val_loss: 1.7816 - val_acc: 0.9076 - val_mDice: 0.2883

Epoch 00003: val_mDice improved from 0.16056 to 0.28830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 1.1107 - acc: 0.8715 - mDice: 0.3137 - val_loss: 1.5600 - val_acc: 0.9094 - val_mDice: 0.3306

Epoch 00004: val_mDice improved from 0.28830 to 0.33061, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.9671 - acc: 0.8741 - mDice: 0.3620 - val_loss: 1.3264 - val_acc: 0.9112 - val_mDice: 0.3982

Epoch 00005: val_mDice improved from 0.33061 to 0.39817, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.8647 - acc: 0.8764 - mDice: 0.4025 - val_loss: 1.2742 - val_acc: 0.9128 - val_mDice: 0.4226

Epoch 00006: val_mDice improved from 0.39817 to 0.42263, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.8014 - acc: 0.8779 - mDice: 0.4305 - val_loss: 1.1967 - val_acc: 0.9130 - val_mDice: 0.4374

Epoch 00007: val_mDice improved from 0.42263 to 0.43744, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.7521 - acc: 0.8792 - mDice: 0.4535 - val_loss: 1.1600 - val_acc: 0.9131 - val_mDice: 0.4478

Epoch 00008: val_mDice improved from 0.43744 to 0.44783, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.7143 - acc: 0.8804 - mDice: 0.4723 - val_loss: 1.1494 - val_acc: 0.9149 - val_mDice: 0.4469

Epoch 00009: val_mDice did not improve from 0.44783
Epoch 10/300
 - 9s - loss: 0.6841 - acc: 0.8813 - mDice: 0.4876 - val_loss: 1.0957 - val_acc: 0.9150 - val_mDice: 0.4721

Epoch 00010: val_mDice improved from 0.44783 to 0.47206, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.6611 - acc: 0.8820 - mDice: 0.4992 - val_loss: 1.1076 - val_acc: 0.9162 - val_mDice: 0.4755

Epoch 00011: val_mDice improved from 0.47206 to 0.47549, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 10s - loss: 0.6458 - acc: 0.8828 - mDice: 0.5077 - val_loss: 1.0770 - val_acc: 0.9155 - val_mDice: 0.4717

Epoch 00012: val_mDice did not improve from 0.47549
Epoch 13/300
 - 11s - loss: 0.6238 - acc: 0.8835 - mDice: 0.5193 - val_loss: 1.0874 - val_acc: 0.9147 - val_mDice: 0.4720

Epoch 00013: val_mDice did not improve from 0.47549
Epoch 14/300
 - 10s - loss: 0.6132 - acc: 0.8842 - mDice: 0.5252 - val_loss: 1.0959 - val_acc: 0.9168 - val_mDice: 0.4735

Epoch 00014: val_mDice did not improve from 0.47549
Epoch 15/300
 - 10s - loss: 0.5963 - acc: 0.8846 - mDice: 0.5345 - val_loss: 1.0243 - val_acc: 0.9177 - val_mDice: 0.4821

Epoch 00015: val_mDice improved from 0.47549 to 0.48206, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.5841 - acc: 0.8855 - mDice: 0.5414 - val_loss: 1.1132 - val_acc: 0.9176 - val_mDice: 0.4611

Epoch 00016: val_mDice did not improve from 0.48206
Epoch 17/300
 - 10s - loss: 0.5731 - acc: 0.8860 - mDice: 0.5478 - val_loss: 1.0341 - val_acc: 0.9161 - val_mDice: 0.4921

Epoch 00017: val_mDice improved from 0.48206 to 0.49208, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 10s - loss: 0.5649 - acc: 0.8865 - mDice: 0.5523 - val_loss: 1.0237 - val_acc: 0.9181 - val_mDice: 0.4854

Epoch 00018: val_mDice did not improve from 0.49208
Epoch 19/300
 - 10s - loss: 0.5519 - acc: 0.8873 - mDice: 0.5599 - val_loss: 1.0630 - val_acc: 0.9186 - val_mDice: 0.4795

Epoch 00019: val_mDice did not improve from 0.49208
Epoch 20/300
 - 11s - loss: 0.5448 - acc: 0.8880 - mDice: 0.5641 - val_loss: 1.0001 - val_acc: 0.9186 - val_mDice: 0.4897

Epoch 00020: val_mDice did not improve from 0.49208
Epoch 21/300
 - 10s - loss: 0.5353 - acc: 0.8888 - mDice: 0.5698 - val_loss: 0.9889 - val_acc: 0.9220 - val_mDice: 0.5055

Epoch 00021: val_mDice improved from 0.49208 to 0.50546, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 10s - loss: 0.5287 - acc: 0.8897 - mDice: 0.5738 - val_loss: 1.0080 - val_acc: 0.9228 - val_mDice: 0.5030

Epoch 00022: val_mDice did not improve from 0.50546
Epoch 23/300
 - 9s - loss: 0.5271 - acc: 0.8904 - mDice: 0.5747 - val_loss: 1.0309 - val_acc: 0.9209 - val_mDice: 0.4852

Epoch 00023: val_mDice did not improve from 0.50546
Epoch 24/300
 - 9s - loss: 0.5178 - acc: 0.8914 - mDice: 0.5803 - val_loss: 1.0004 - val_acc: 0.9243 - val_mDice: 0.5009

Epoch 00024: val_mDice did not improve from 0.50546
Epoch 25/300
 - 9s - loss: 0.5129 - acc: 0.8921 - mDice: 0.5833 - val_loss: 0.9817 - val_acc: 0.9227 - val_mDice: 0.4939

Epoch 00025: val_mDice did not improve from 0.50546
Epoch 26/300
 - 9s - loss: 0.5080 - acc: 0.8930 - mDice: 0.5863 - val_loss: 0.9397 - val_acc: 0.9254 - val_mDice: 0.5158

Epoch 00026: val_mDice improved from 0.50546 to 0.51582, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 9s - loss: 0.5042 - acc: 0.8938 - mDice: 0.5885 - val_loss: 0.9224 - val_acc: 0.9220 - val_mDice: 0.4969

Epoch 00027: val_mDice did not improve from 0.51582
Epoch 28/300
 - 9s - loss: 0.4977 - acc: 0.8949 - mDice: 0.5927 - val_loss: 0.9030 - val_acc: 0.9271 - val_mDice: 0.5201

Epoch 00028: val_mDice improved from 0.51582 to 0.52011, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 9s - loss: 0.4935 - acc: 0.8959 - mDice: 0.5951 - val_loss: 0.8885 - val_acc: 0.9273 - val_mDice: 0.5242

Epoch 00029: val_mDice improved from 0.52011 to 0.52416, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 9s - loss: 0.4876 - acc: 0.8969 - mDice: 0.5990 - val_loss: 0.9483 - val_acc: 0.9289 - val_mDice: 0.5149

Epoch 00030: val_mDice did not improve from 0.52416
Epoch 31/300
 - 9s - loss: 0.4855 - acc: 0.8981 - mDice: 0.6003 - val_loss: 0.9429 - val_acc: 0.9290 - val_mDice: 0.5051

Epoch 00031: val_mDice did not improve from 0.52416
Epoch 32/300
 - 9s - loss: 0.4811 - acc: 0.8996 - mDice: 0.6030 - val_loss: 1.0016 - val_acc: 0.9291 - val_mDice: 0.5241

Epoch 00032: val_mDice did not improve from 0.52416
Epoch 33/300
 - 9s - loss: 0.4777 - acc: 0.9010 - mDice: 0.6050 - val_loss: 0.8481 - val_acc: 0.9309 - val_mDice: 0.5210

Epoch 00033: val_mDice did not improve from 0.52416
Epoch 34/300
 - 9s - loss: 0.4755 - acc: 0.9042 - mDice: 0.6065 - val_loss: 0.8408 - val_acc: 0.9332 - val_mDice: 0.5245

Epoch 00034: val_mDice improved from 0.52416 to 0.52453, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 35/300
 - 9s - loss: 0.4722 - acc: 0.9102 - mDice: 0.6084 - val_loss: 0.9450 - val_acc: 0.9325 - val_mDice: 0.5230

Epoch 00035: val_mDice did not improve from 0.52453
Epoch 36/300
 - 9s - loss: 0.4662 - acc: 0.9154 - mDice: 0.6120 - val_loss: 0.7992 - val_acc: 0.9320 - val_mDice: 0.5392

Epoch 00036: val_mDice improved from 0.52453 to 0.53923, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 37/300
 - 9s - loss: 0.4626 - acc: 0.9182 - mDice: 0.6141 - val_loss: 0.8269 - val_acc: 0.9306 - val_mDice: 0.5302

Epoch 00037: val_mDice did not improve from 0.53923
Epoch 38/300
 - 9s - loss: 0.4585 - acc: 0.9189 - mDice: 0.6165 - val_loss: 0.7941 - val_acc: 0.9325 - val_mDice: 0.5256

Epoch 00038: val_mDice did not improve from 0.53923
Epoch 39/300
 - 9s - loss: 0.4597 - acc: 0.9192 - mDice: 0.6157 - val_loss: 0.8998 - val_acc: 0.9255 - val_mDice: 0.5234

Epoch 00039: val_mDice did not improve from 0.53923
Epoch 40/300
 - 9s - loss: 0.4553 - acc: 0.9194 - mDice: 0.6184 - val_loss: 0.8186 - val_acc: 0.9286 - val_mDice: 0.5311

Epoch 00040: val_mDice did not improve from 0.53923
Epoch 41/300
 - 9s - loss: 0.4507 - acc: 0.9199 - mDice: 0.6215 - val_loss: 0.8154 - val_acc: 0.9344 - val_mDice: 0.5262

Epoch 00041: val_mDice did not improve from 0.53923
Epoch 42/300
 - 9s - loss: 0.4509 - acc: 0.9202 - mDice: 0.6214 - val_loss: 0.9428 - val_acc: 0.9216 - val_mDice: 0.5190

Epoch 00042: val_mDice did not improve from 0.53923
Epoch 43/300
 - 9s - loss: 0.4468 - acc: 0.9206 - mDice: 0.6240 - val_loss: 0.7548 - val_acc: 0.9328 - val_mDice: 0.5303

Epoch 00043: val_mDice did not improve from 0.53923
Epoch 44/300
 - 9s - loss: 0.4450 - acc: 0.9211 - mDice: 0.6251 - val_loss: 0.7961 - val_acc: 0.9317 - val_mDice: 0.5327

Epoch 00044: val_mDice did not improve from 0.53923
Epoch 45/300
 - 9s - loss: 0.4434 - acc: 0.9212 - mDice: 0.6262 - val_loss: 0.7550 - val_acc: 0.9280 - val_mDice: 0.5248

Epoch 00045: val_mDice did not improve from 0.53923
Epoch 46/300
 - 9s - loss: 0.4404 - acc: 0.9217 - mDice: 0.6282 - val_loss: 0.7996 - val_acc: 0.9279 - val_mDice: 0.5258

Epoch 00046: val_mDice did not improve from 0.53923
Epoch 47/300
 - 9s - loss: 0.4360 - acc: 0.9222 - mDice: 0.6311 - val_loss: 0.9103 - val_acc: 0.9151 - val_mDice: 0.4846

Epoch 00047: val_mDice did not improve from 0.53923
Epoch 48/300
 - 9s - loss: 0.4342 - acc: 0.9225 - mDice: 0.6320 - val_loss: 0.9013 - val_acc: 0.9189 - val_mDice: 0.5056

Epoch 00048: val_mDice did not improve from 0.53923
Epoch 49/300
 - 9s - loss: 0.4317 - acc: 0.9228 - mDice: 0.6337 - val_loss: 0.7683 - val_acc: 0.9273 - val_mDice: 0.5256

Epoch 00049: val_mDice did not improve from 0.53923
Epoch 50/300
 - 9s - loss: 0.4300 - acc: 0.9231 - mDice: 0.6349 - val_loss: 0.8710 - val_acc: 0.9251 - val_mDice: 0.5300

Epoch 00050: val_mDice did not improve from 0.53923
Epoch 51/300
 - 9s - loss: 0.4289 - acc: 0.9236 - mDice: 0.6359 - val_loss: 0.8179 - val_acc: 0.9276 - val_mDice: 0.5317

Epoch 00051: val_mDice did not improve from 0.53923
Epoch 52/300
 - 9s - loss: 0.4274 - acc: 0.9240 - mDice: 0.6368 - val_loss: 0.8189 - val_acc: 0.9310 - val_mDice: 0.5365

Epoch 00052: val_mDice did not improve from 0.53923
Epoch 53/300
 - 9s - loss: 0.4256 - acc: 0.9243 - mDice: 0.6380 - val_loss: 0.8412 - val_acc: 0.9244 - val_mDice: 0.5233

Epoch 00053: val_mDice did not improve from 0.53923
Epoch 54/300
 - 9s - loss: 0.4241 - acc: 0.9245 - mDice: 0.6389 - val_loss: 0.7141 - val_acc: 0.9309 - val_mDice: 0.5360

Epoch 00054: val_mDice did not improve from 0.53923
Epoch 55/300
 - 9s - loss: 0.4232 - acc: 0.9249 - mDice: 0.6396 - val_loss: 0.6930 - val_acc: 0.9360 - val_mDice: 0.5232

Epoch 00055: val_mDice did not improve from 0.53923
Epoch 56/300
 - 9s - loss: 0.4212 - acc: 0.9252 - mDice: 0.6409 - val_loss: 0.8273 - val_acc: 0.9326 - val_mDice: 0.5343

Epoch 00056: val_mDice did not improve from 0.53923
Epoch 57/300
 - 9s - loss: 0.4190 - acc: 0.9257 - mDice: 0.6423 - val_loss: 0.7045 - val_acc: 0.9368 - val_mDice: 0.5330

Epoch 00057: val_mDice did not improve from 0.53923
Epoch 58/300
 - 9s - loss: 0.4151 - acc: 0.9261 - mDice: 0.6448 - val_loss: 0.8431 - val_acc: 0.9279 - val_mDice: 0.5278

Epoch 00058: val_mDice did not improve from 0.53923
Epoch 59/300
 - 9s - loss: 0.4152 - acc: 0.9263 - mDice: 0.6450 - val_loss: 0.9363 - val_acc: 0.9200 - val_mDice: 0.5032

Epoch 00059: val_mDice did not improve from 0.53923
Epoch 60/300
 - 9s - loss: 0.4145 - acc: 0.9262 - mDice: 0.6452 - val_loss: 0.6719 - val_acc: 0.9373 - val_mDice: 0.5289

Epoch 00060: val_mDice did not improve from 0.53923
Epoch 61/300
 - 9s - loss: 0.4143 - acc: 0.9266 - mDice: 0.6455 - val_loss: 0.7162 - val_acc: 0.9320 - val_mDice: 0.5302

Epoch 00061: val_mDice did not improve from 0.53923
Epoch 62/300
 - 9s - loss: 0.4099 - acc: 0.9270 - mDice: 0.6484 - val_loss: 0.7875 - val_acc: 0.9219 - val_mDice: 0.5117

Epoch 00062: val_mDice did not improve from 0.53923
Epoch 63/300
 - 9s - loss: 0.4117 - acc: 0.9271 - mDice: 0.6472 - val_loss: 0.7573 - val_acc: 0.9219 - val_mDice: 0.5247

Epoch 00063: val_mDice did not improve from 0.53923
Epoch 64/300
 - 9s - loss: 0.4085 - acc: 0.9271 - mDice: 0.6493 - val_loss: 0.8077 - val_acc: 0.9228 - val_mDice: 0.4927

Epoch 00064: val_mDice did not improve from 0.53923
Epoch 65/300
 - 9s - loss: 0.4072 - acc: 0.9276 - mDice: 0.6502 - val_loss: 0.7507 - val_acc: 0.9341 - val_mDice: 0.5424

Epoch 00065: val_mDice improved from 0.53923 to 0.54238, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 66/300
 - 9s - loss: 0.4078 - acc: 0.9274 - mDice: 0.6497 - val_loss: 0.7435 - val_acc: 0.9250 - val_mDice: 0.4983

Epoch 00066: val_mDice did not improve from 0.54238
Epoch 67/300
 - 9s - loss: 0.4056 - acc: 0.9280 - mDice: 0.6513 - val_loss: 0.7855 - val_acc: 0.9199 - val_mDice: 0.5193

Epoch 00067: val_mDice did not improve from 0.54238
Epoch 68/300
 - 9s - loss: 0.4047 - acc: 0.9281 - mDice: 0.6519 - val_loss: 0.7722 - val_acc: 0.9309 - val_mDice: 0.5259

Epoch 00068: val_mDice did not improve from 0.54238
Epoch 69/300
 - 9s - loss: 0.4029 - acc: 0.9282 - mDice: 0.6531 - val_loss: 0.7003 - val_acc: 0.9354 - val_mDice: 0.5317

Epoch 00069: val_mDice did not improve from 0.54238
Epoch 70/300
 - 9s - loss: 0.4003 - acc: 0.9283 - mDice: 0.6549 - val_loss: 0.7389 - val_acc: 0.9337 - val_mDice: 0.5316

Epoch 00070: val_mDice did not improve from 0.54238
Epoch 71/300
 - 9s - loss: 0.4014 - acc: 0.9282 - mDice: 0.6542 - val_loss: 0.7342 - val_acc: 0.9310 - val_mDice: 0.5330

Epoch 00071: val_mDice did not improve from 0.54238
Epoch 72/300
 - 9s - loss: 0.4016 - acc: 0.9282 - mDice: 0.6541 - val_loss: 0.6688 - val_acc: 0.9302 - val_mDice: 0.5352

Epoch 00072: val_mDice did not improve from 0.54238
Epoch 73/300
 - 9s - loss: 0.3980 - acc: 0.9286 - mDice: 0.6565 - val_loss: 0.6331 - val_acc: 0.9385 - val_mDice: 0.5439

Epoch 00073: val_mDice improved from 0.54238 to 0.54386, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 74/300
 - 9s - loss: 0.3962 - acc: 0.9290 - mDice: 0.6577 - val_loss: 0.8019 - val_acc: 0.9199 - val_mDice: 0.4993

Epoch 00074: val_mDice did not improve from 0.54386
Epoch 75/300
 - 9s - loss: 0.3960 - acc: 0.9291 - mDice: 0.6579 - val_loss: 0.8131 - val_acc: 0.9233 - val_mDice: 0.5069

Epoch 00075: val_mDice did not improve from 0.54386
Epoch 76/300
 - 9s - loss: 0.3944 - acc: 0.9292 - mDice: 0.6590 - val_loss: 0.7410 - val_acc: 0.9285 - val_mDice: 0.5210

Epoch 00076: val_mDice did not improve from 0.54386
Epoch 77/300
 - 9s - loss: 0.3963 - acc: 0.9290 - mDice: 0.6577 - val_loss: 0.7834 - val_acc: 0.9192 - val_mDice: 0.5041

Epoch 00077: val_mDice did not improve from 0.54386
Epoch 78/300
 - 9s - loss: 0.3918 - acc: 0.9295 - mDice: 0.6608 - val_loss: 0.6895 - val_acc: 0.9338 - val_mDice: 0.5320

Epoch 00078: val_mDice did not improve from 0.54386
Epoch 79/300
 - 9s - loss: 0.3940 - acc: 0.9293 - mDice: 0.6593 - val_loss: 0.6667 - val_acc: 0.9360 - val_mDice: 0.5328

Epoch 00079: val_mDice did not improve from 0.54386
Epoch 80/300
 - 9s - loss: 0.3918 - acc: 0.9295 - mDice: 0.6607 - val_loss: 0.7395 - val_acc: 0.9235 - val_mDice: 0.5299

Epoch 00080: val_mDice did not improve from 0.54386
Epoch 81/300
 - 9s - loss: 0.3914 - acc: 0.9294 - mDice: 0.6612 - val_loss: 0.6615 - val_acc: 0.9346 - val_mDice: 0.5322

Epoch 00081: val_mDice did not improve from 0.54386
Epoch 82/300
 - 9s - loss: 0.3920 - acc: 0.9297 - mDice: 0.6606 - val_loss: 0.7105 - val_acc: 0.9273 - val_mDice: 0.5283

Epoch 00082: val_mDice did not improve from 0.54386
Epoch 83/300
 - 9s - loss: 0.3874 - acc: 0.9299 - mDice: 0.6637 - val_loss: 0.8120 - val_acc: 0.9275 - val_mDice: 0.5302

Epoch 00083: val_mDice did not improve from 0.54386
Epoch 84/300
 - 9s - loss: 0.3864 - acc: 0.9301 - mDice: 0.6645 - val_loss: 0.6652 - val_acc: 0.9361 - val_mDice: 0.5312

Epoch 00084: val_mDice did not improve from 0.54386
Epoch 85/300
 - 9s - loss: 0.3866 - acc: 0.9302 - mDice: 0.6643 - val_loss: 0.6473 - val_acc: 0.9355 - val_mDice: 0.5326

Epoch 00085: val_mDice did not improve from 0.54386
Epoch 86/300
 - 9s - loss: 0.3870 - acc: 0.9303 - mDice: 0.6642 - val_loss: 0.6435 - val_acc: 0.9342 - val_mDice: 0.5354

Epoch 00086: val_mDice did not improve from 0.54386
Epoch 87/300
 - 9s - loss: 0.3831 - acc: 0.9305 - mDice: 0.6668 - val_loss: 0.7429 - val_acc: 0.9249 - val_mDice: 0.5346

Epoch 00087: val_mDice did not improve from 0.54386
Epoch 88/300
 - 9s - loss: 0.3840 - acc: 0.9305 - mDice: 0.6661 - val_loss: 0.8574 - val_acc: 0.9134 - val_mDice: 0.4918

Epoch 00088: val_mDice did not improve from 0.54386
Epoch 89/300
 - 9s - loss: 0.3820 - acc: 0.9306 - mDice: 0.6676 - val_loss: 0.7514 - val_acc: 0.9302 - val_mDice: 0.5199

Epoch 00089: val_mDice did not improve from 0.54386
Epoch 90/300
 - 9s - loss: 0.3811 - acc: 0.9308 - mDice: 0.6682 - val_loss: 0.7533 - val_acc: 0.9213 - val_mDice: 0.5189

Epoch 00090: val_mDice did not improve from 0.54386
Epoch 91/300
 - 9s - loss: 0.3802 - acc: 0.9309 - mDice: 0.6687 - val_loss: 0.7090 - val_acc: 0.9304 - val_mDice: 0.5284

Epoch 00091: val_mDice did not improve from 0.54386
Epoch 92/300
 - 9s - loss: 0.3814 - acc: 0.9310 - mDice: 0.6679 - val_loss: 0.6748 - val_acc: 0.9274 - val_mDice: 0.5303

Epoch 00092: val_mDice did not improve from 0.54386
Epoch 93/300
 - 9s - loss: 0.3817 - acc: 0.9309 - mDice: 0.6679 - val_loss: 0.6930 - val_acc: 0.9370 - val_mDice: 0.5370

Epoch 00093: val_mDice did not improve from 0.54386
Epoch 94/300
 - 9s - loss: 0.3821 - acc: 0.9309 - mDice: 0.6676 - val_loss: 0.7395 - val_acc: 0.9288 - val_mDice: 0.5369

Epoch 00094: val_mDice did not improve from 0.54386
Epoch 95/300
 - 9s - loss: 0.3803 - acc: 0.9308 - mDice: 0.6688 - val_loss: 0.6829 - val_acc: 0.9260 - val_mDice: 0.5257

Epoch 00095: val_mDice did not improve from 0.54386
Epoch 96/300
 - 9s - loss: 0.3806 - acc: 0.9310 - mDice: 0.6688 - val_loss: 0.6399 - val_acc: 0.9329 - val_mDice: 0.5423

Epoch 00096: val_mDice did not improve from 0.54386
Epoch 97/300
 - 9s - loss: 0.3757 - acc: 0.9315 - mDice: 0.6720 - val_loss: 0.7851 - val_acc: 0.9237 - val_mDice: 0.5215

Epoch 00097: val_mDice did not improve from 0.54386
Epoch 98/300
 - 9s - loss: 0.3765 - acc: 0.9313 - mDice: 0.6714 - val_loss: 0.8188 - val_acc: 0.9193 - val_mDice: 0.4848

Epoch 00098: val_mDice did not improve from 0.54386
Epoch 99/300
 - 9s - loss: 0.3778 - acc: 0.9313 - mDice: 0.6706 - val_loss: 0.6580 - val_acc: 0.9363 - val_mDice: 0.5285

Epoch 00099: val_mDice did not improve from 0.54386
Epoch 100/300
 - 9s - loss: 0.3786 - acc: 0.9311 - mDice: 0.6701 - val_loss: 0.8017 - val_acc: 0.9324 - val_mDice: 0.5175

Epoch 00100: val_mDice did not improve from 0.54386
Epoch 101/300
 - 9s - loss: 0.3758 - acc: 0.9315 - mDice: 0.6719 - val_loss: 0.6598 - val_acc: 0.9324 - val_mDice: 0.5356

Epoch 00101: val_mDice did not improve from 0.54386
Epoch 102/300
 - 9s - loss: 0.3740 - acc: 0.9315 - mDice: 0.6733 - val_loss: 0.6976 - val_acc: 0.9335 - val_mDice: 0.5374

Epoch 00102: val_mDice did not improve from 0.54386
Epoch 103/300
 - 9s - loss: 0.3740 - acc: 0.9317 - mDice: 0.6732 - val_loss: 0.7262 - val_acc: 0.9304 - val_mDice: 0.5243

Epoch 00103: val_mDice did not improve from 0.54386
Epoch 104/300
 - 9s - loss: 0.3731 - acc: 0.9317 - mDice: 0.6738 - val_loss: 0.6480 - val_acc: 0.9342 - val_mDice: 0.5340

Epoch 00104: val_mDice did not improve from 0.54386
Epoch 105/300
 - 10s - loss: 0.3719 - acc: 0.9318 - mDice: 0.6746 - val_loss: 0.7307 - val_acc: 0.9337 - val_mDice: 0.5269

Epoch 00105: val_mDice did not improve from 0.54386
Epoch 106/300
 - 9s - loss: 0.3692 - acc: 0.9321 - mDice: 0.6766 - val_loss: 0.8066 - val_acc: 0.9206 - val_mDice: 0.5134

Epoch 00106: val_mDice did not improve from 0.54386
Epoch 107/300
 - 9s - loss: 0.3722 - acc: 0.9318 - mDice: 0.6748 - val_loss: 0.7466 - val_acc: 0.9310 - val_mDice: 0.5267

Epoch 00107: val_mDice did not improve from 0.54386
Epoch 108/300
 - 9s - loss: 0.3688 - acc: 0.9321 - mDice: 0.6770 - val_loss: 0.7386 - val_acc: 0.9240 - val_mDice: 0.5243

Epoch 00108: val_mDice did not improve from 0.54386
Epoch 109/300
 - 10s - loss: 0.3708 - acc: 0.9319 - mDice: 0.6756 - val_loss: 0.6774 - val_acc: 0.9370 - val_mDice: 0.5157

Epoch 00109: val_mDice did not improve from 0.54386
Epoch 110/300
 - 9s - loss: 0.3696 - acc: 0.9321 - mDice: 0.6763 - val_loss: 0.6835 - val_acc: 0.9327 - val_mDice: 0.5314

Epoch 00110: val_mDice did not improve from 0.54386
Epoch 111/300
 - 9s - loss: 0.3689 - acc: 0.9320 - mDice: 0.6769 - val_loss: 0.7287 - val_acc: 0.9211 - val_mDice: 0.5143

Epoch 00111: val_mDice did not improve from 0.54386
Epoch 112/300
 - 9s - loss: 0.3674 - acc: 0.9322 - mDice: 0.6780 - val_loss: 0.7448 - val_acc: 0.9227 - val_mDice: 0.5178

Epoch 00112: val_mDice did not improve from 0.54386
Epoch 113/300
 - 10s - loss: 0.3692 - acc: 0.9321 - mDice: 0.6766 - val_loss: 0.8046 - val_acc: 0.9196 - val_mDice: 0.4979

Epoch 00113: val_mDice did not improve from 0.54386
Restoring model weights from the end of the best epoch
Epoch 00113: early stopping
{'val_loss': [3.8391967046828497, 2.4237170673552013, 1.7815861701965332, 1.5599745114644368, 1.3264398007165819, 1.2742486681256975, 1.1966889812832786, 1.1599940685998826, 1.1494255974179222, 1.095732847849528, 1.1075675941648937, 1.0770226546696253, 1.087357725415911, 1.0958507515135265, 1.0243010293869745, 1.1131786505381267, 1.034079528990246, 1.0237447080158053, 1.063013610385713, 1.0001370566231864, 0.9889392171587262, 1.0079900877816337, 1.030921152659825, 1.000431355975923, 0.9817223094758534, 0.9396602312723795, 0.922382672627767, 0.9030169305347261, 0.8885298683529809, 0.9483102162679037, 0.9429012934366862, 1.0015857106163388, 0.8480916590917678, 0.8407595611753917, 0.9450061661856515, 0.7992320287795294, 0.8269132659548805, 0.7941286223275321, 0.8998412518274217, 0.8186495644705636, 0.8154406320481074, 0.9428134872799828, 0.754802908216204, 0.7961395581563314, 0.754959469749814, 0.7996388162885394, 0.9102941354115804, 0.9012542906261626, 0.7682628290993827, 0.8710475989750454, 0.8179296084812709, 0.8189427852630615, 0.841219425201416, 0.714082536243257, 0.6930255889892578, 0.827338037036714, 0.704450766245524, 0.8430761723291307, 0.9362521058037168, 0.6718839690798805, 0.7162488869258335, 0.7875207946414039, 0.7572903406052363, 0.8076562995002383, 0.7507455916631789, 0.7434573514120919, 0.7854641619182768, 0.7722068060012091, 0.7002759660993304, 0.738868963150751, 0.7341901574816022, 0.6687929743812198, 0.6331414041065034, 0.8018693469819569, 0.813113462357294, 0.7410440104348319, 0.7834450630914598, 0.6894732316335043, 0.666729904356457, 0.7395275206792922, 0.6615253289540609, 0.7105029083433605, 0.8120059626443046, 0.6652123701004755, 0.647283463251023, 0.6434571288880848, 0.7428575243268695, 0.8574033124106271, 0.7514409564790272, 0.7532762686411539, 0.7090263026101249, 0.6748081729525611, 0.6929810387747628, 0.7394953909374419, 0.682942924045381, 0.6399088473547072, 0.7850974173772902, 0.8188379378545851, 0.6579814751942953, 0.8016974585396903, 0.6597872348058791, 0.6976471969059536, 0.7261961641765776, 0.6479643867129371, 0.730710642678397, 0.8065694740840367, 0.7466299987974621, 0.7386362779708135, 0.6773575033460345, 0.683509179524013, 0.7286995138440814, 0.7448054722377232, 0.8045739559900194], 'val_acc': [0.6390018207686288, 0.9031341785476321, 0.9075549330030169, 0.9093566991034008, 0.9111629809652056, 0.9128159398124331, 0.912985330536252, 0.9130975376991999, 0.9149129816464016, 0.9149816689037141, 0.9161950520106724, 0.9155425571259999, 0.9147069596108937, 0.9168246473584857, 0.917708328792027, 0.9175778457096645, 0.9161492586135864, 0.918056343282972, 0.9185553959437779, 0.9185943376450312, 0.9219597294217065, 0.9227976202964783, 0.9209203407877967, 0.924271978083111, 0.9226854131335304, 0.9253548270180112, 0.9219825863838196, 0.9270878916695005, 0.9272573533512297, 0.9288507501284281, 0.9289995488666353, 0.929141484555744, 0.9309203312510536, 0.9332486334301177, 0.9325389237630934, 0.9320192478951954, 0.9305517304511297, 0.9324679772059122, 0.9255013920011974, 0.9286423893201918, 0.934375022138868, 0.9216048547199794, 0.9327564211118788, 0.9316735381171817, 0.9280082356362116, 0.92786401226407, 0.9151282225336347, 0.918898792493911, 0.9272687946047101, 0.9251373552140736, 0.927564107236408, 0.9309684038162231, 0.9244070478848049, 0.9309043061165583, 0.9360142208281017, 0.9326396470978147, 0.9368108738036383, 0.927870878151485, 0.9200366423243568, 0.9372870666640145, 0.9320375408445086, 0.921888740289779, 0.9218933128175282, 0.9228022240457081, 0.9341369299661546, 0.9250068579401288, 0.9199244748978388, 0.9308837056159973, 0.9354052344957987, 0.9336538655417306, 0.9310073398408436, 0.9302403926849365, 0.9384890000025431, 0.9199221361251104, 0.9233035956110273, 0.9284752493812924, 0.9192422174272084, 0.933818709282648, 0.9359752819651649, 0.9234775418326968, 0.9346428314844767, 0.92733747618539, 0.9274976906322298, 0.9360828768639338, 0.9354945222536722, 0.9341758290926615, 0.9249038469223749, 0.9134203337487721, 0.9302495349021185, 0.9212546007973808, 0.9304006667364211, 0.9273946938060579, 0.9369849023364839, 0.9287660036768232, 0.9259798328081766, 0.9328594179380507, 0.9237294111933027, 0.9193154545057387, 0.9363049694469997, 0.9324335853258768, 0.9323672340029762, 0.9335416697320484, 0.9304395800545102, 0.9341621143477303, 0.933724806422279, 0.9206295552707854, 0.9309615208989098, 0.9240476034936451, 0.9369642876443409, 0.9326854177883693, 0.9210668660345531, 0.922712919257936, 0.9196016760099501], 'val_mDice': [0.045032683022630714, 0.16055881550779477, 0.2882962091160672, 0.3306083396254551, 0.39816942456222715, 0.42263195096027284, 0.43744006664270446, 0.44782634256851106, 0.446927224951131, 0.47205675836829913, 0.47549168534931685, 0.47165994470318157, 0.4719917069943178, 0.4735409039117041, 0.4820627932037626, 0.4611384050831908, 0.49208196554155575, 0.4854015507513568, 0.47947278725249426, 0.4896913465289843, 0.5054585128313019, 0.5029640309512615, 0.48523365138542085, 0.5009455097218355, 0.49387222581676077, 0.515815099612588, 0.4969141795521691, 0.5201116935128257, 0.5241616217508203, 0.5148880034685135, 0.5050907502216953, 0.5241417173473608, 0.520966020723184, 0.5245277402656419, 0.5229508617804164, 0.5392305719710532, 0.5302217698522976, 0.5256425376449313, 0.5233689367416359, 0.5311102411221891, 0.5261509830043429, 0.5190157058338324, 0.5303144281109174, 0.5326916880550838, 0.5247813346130508, 0.5257911288312503, 0.4846228499497686, 0.5056261760847909, 0.5256075518471854, 0.5299553679568427, 0.531700947809787, 0.5365076375504335, 0.5233236359698432, 0.5360187041972365, 0.5231783757252353, 0.5343002219285283, 0.5329601722104209, 0.5278431503545671, 0.5031870270059222, 0.5289282115797201, 0.5301919224716368, 0.5117486442128817, 0.5246703305414745, 0.49267005884931203, 0.5423831847451982, 0.49832607557376224, 0.5193402862974575, 0.5259484829647201, 0.5317377629024642, 0.5315667607244992, 0.5330427436246759, 0.5351880290323779, 0.5438554964604831, 0.4992754911737783, 0.5069166013882274, 0.5209667276413668, 0.5041316304178465, 0.532031637394712, 0.5328315567402613, 0.5298826307767913, 0.5321863909207639, 0.5282615440941992, 0.5302177687131223, 0.5312193901765914, 0.5325879738444373, 0.5354279151984623, 0.5345898240449882, 0.49184567836068926, 0.5199050211480686, 0.5188837225238482, 0.5284428397814432, 0.5303192278813749, 0.5369770757499195, 0.5369255021214485, 0.5257147946173236, 0.54228182119273, 0.5214549854752564, 0.48483661083238466, 0.5285460044230733, 0.5175133045940172, 0.5356322502096494, 0.5374396773321288, 0.5242836656314986, 0.5339977794459888, 0.5268786567307654, 0.5133859646462259, 0.5267214759119919, 0.5242758036724159, 0.5156780080426306, 0.531380879737082, 0.5143099588652452, 0.5178494535031772, 0.49790854113442556], 'loss': [3.496201632499511, 1.7936936561050547, 1.3103266811012326, 1.1107491173678932, 0.9671145748696807, 0.864718757602827, 0.8014118889519445, 0.7521184766386799, 0.7142676575486775, 0.6840633612872319, 0.6610611213271688, 0.6457600537604947, 0.6238331955959738, 0.6131667774009043, 0.5962884048057793, 0.5840787585355746, 0.5730547254568629, 0.5648612198122714, 0.5518971551974569, 0.5447806634607861, 0.53526015770741, 0.5287026596340527, 0.5270933909799543, 0.5177806830599241, 0.5128793007541029, 0.5080430008139205, 0.5042312029976823, 0.49769672589975905, 0.49347862644946616, 0.48755883644811676, 0.48546791164567527, 0.48110118392852774, 0.4776920040827715, 0.47554773297961656, 0.47217660712579873, 0.4661506888653608, 0.46258243215734474, 0.4584548318342411, 0.45974757588849674, 0.4553399645675463, 0.45069229110992093, 0.45088771214851964, 0.44683217450743673, 0.44503083185628356, 0.44341576309109415, 0.4403709826245114, 0.435952541167184, 0.43421940472467524, 0.4317265783968242, 0.4300050938809702, 0.42885927637349164, 0.427387833675714, 0.4255532829522949, 0.424078113470368, 0.42323954956987037, 0.4212460470884458, 0.4190493785268612, 0.4150826620221345, 0.41519299546532806, 0.4144856806019264, 0.4142938299183214, 0.40989320240706545, 0.41170236228149887, 0.4084745562556899, 0.40723033386410284, 0.40780696168280484, 0.4056364051956006, 0.4046567832375621, 0.4029308381293444, 0.40027513782344204, 0.40143494374356287, 0.40156058950738593, 0.3979702440787309, 0.39621985233287393, 0.39600198654303875, 0.394356285075542, 0.39632938198094564, 0.3917789099210486, 0.3939862754651984, 0.3918226383222834, 0.39136783373316797, 0.3919996684666702, 0.3874244824445429, 0.3863800061916556, 0.38660560909415204, 0.38702082473095933, 0.3831184909985845, 0.3840034566726302, 0.38197050650546793, 0.3811471474717664, 0.38016082149078695, 0.3814427322371056, 0.38169636596759116, 0.38212187601716985, 0.3803323275244992, 0.3805946558685185, 0.375666232255697, 0.3764950121979689, 0.3777921241396582, 0.37857402892431724, 0.37579445014897167, 0.37400792225123786, 0.3739839756456625, 0.3730978239575447, 0.37193058242406235, 0.36924088883772277, 0.372214466816018, 0.3687777242863686, 0.370833249652411, 0.36964722687577106, 0.3688610139979272, 0.36740528036455483, 0.36924528647576865], 'acc': [0.3406003910939726, 0.8531681459281448, 0.8684900562520061, 0.87153667096621, 0.8741155289629188, 0.8763893567254049, 0.877886749207916, 0.8791839517056884, 0.8803738736223802, 0.8813161549826497, 0.8820363132623158, 0.8828044809172648, 0.8834770221298361, 0.8842157186146345, 0.8846491942038903, 0.8854520276306634, 0.8860029828946026, 0.8864782859025627, 0.8872795449830168, 0.8879697153235944, 0.8888403741017642, 0.8896940023034483, 0.8904453962667843, 0.8913882798672366, 0.8920774593481053, 0.8929946667683338, 0.8938305674202299, 0.8948823154857445, 0.8959407807200865, 0.8968833400629976, 0.8980668454310878, 0.8995953960893975, 0.9010405109318, 0.9042177613309659, 0.9101647661673166, 0.9154336712643983, 0.9181755709124135, 0.9188926464242239, 0.9191519838319893, 0.9193555972515008, 0.9199236269881552, 0.920173723274328, 0.9206465242201822, 0.9210874126990315, 0.9211706920972743, 0.9216898782004597, 0.9222430405944029, 0.9225457092229631, 0.9228021942491312, 0.9231250719089188, 0.923646509980613, 0.9239834507398346, 0.9242585224063727, 0.9245348721541534, 0.9248928075492187, 0.9252104463548773, 0.9256528682370441, 0.9261027502834349, 0.926323295903615, 0.9262270631876575, 0.9265974908176589, 0.926990483603267, 0.927072116961846, 0.9271032842731163, 0.9276225171683036, 0.927388320579128, 0.9280033477450786, 0.9281197879754304, 0.9282092760242155, 0.9283156117332081, 0.9282400252411355, 0.9282203529389902, 0.9285972893916046, 0.9289827300837119, 0.9290835704673847, 0.9292402580819976, 0.9289826594820274, 0.9295104445118607, 0.9293075977480432, 0.9294745514037546, 0.9293809127481268, 0.9296667147215929, 0.9298606869662821, 0.9301362667144414, 0.9301574256279024, 0.9302899891732169, 0.9305323194234799, 0.9304803959409097, 0.9305656436598782, 0.9308257922285987, 0.9308843739878035, 0.9309798834961412, 0.9309267306433539, 0.9308639298819246, 0.9307843359973312, 0.9309684823123343, 0.9315231249055261, 0.9313194926979685, 0.9312749089752522, 0.9311374323042183, 0.931454747518823, 0.9314742128192195, 0.9316748574401962, 0.931667207166228, 0.9317721773462533, 0.9321065462001008, 0.9318485508218812, 0.932121655983297, 0.9319334309846191, 0.9320881239407688, 0.9320041275516235, 0.9321916612076672, 0.9321116657874845], 'mDice': [0.04597444594529798, 0.17542332357665766, 0.2591710616932316, 0.31369438707679137, 0.3619942589143533, 0.402457171043082, 0.43049296105852564, 0.4534668541492376, 0.47226247749324934, 0.4875721263476413, 0.49920694784826686, 0.5076819572095722, 0.5193118056465901, 0.5251776831605565, 0.5345321965741587, 0.5414345776480886, 0.5478399639670183, 0.5523211606233273, 0.5598894977514423, 0.5640748805776368, 0.5698035237921073, 0.5737780015983861, 0.5747466609154865, 0.5803129650021831, 0.5833355794988065, 0.5863278721002616, 0.5885038543280687, 0.5927038637916546, 0.595053881941123, 0.5989524457917546, 0.6002921678207733, 0.603004538716437, 0.605031761953958, 0.6065238417286576, 0.6084266946291405, 0.6120389706026228, 0.6140555918549949, 0.6165300786024072, 0.6156916989741446, 0.6184412305907108, 0.6215191002707503, 0.621430864965201, 0.6239716817768686, 0.6250938566429252, 0.6262085807330351, 0.6281756224465871, 0.6311116792895051, 0.6320239787665272, 0.6337088978954747, 0.6348957255876246, 0.6359128760353825, 0.6367969277600505, 0.6379787661171107, 0.6389303626939697, 0.6396341099545104, 0.6409302517148325, 0.6423077735226118, 0.6448110639991524, 0.6449849384930039, 0.6452269676978679, 0.6455035360879422, 0.6483838510853444, 0.6472427410175742, 0.6493256439334376, 0.650196193522609, 0.649724034013283, 0.6512503411261038, 0.6519339255383876, 0.6530734059528875, 0.654914671673305, 0.6542063104249113, 0.6541038512700965, 0.6565234073329482, 0.6576710559739436, 0.6579326196100203, 0.6589530256641654, 0.6576883955706928, 0.6607831168638987, 0.6593368554221014, 0.6607219138677717, 0.661164351412389, 0.6605937318786252, 0.6637044034069481, 0.6644726578201521, 0.6642614585001482, 0.6641831916491374, 0.6668019575927444, 0.6661171202648576, 0.6675585652905345, 0.6681570339368353, 0.6687396865187983, 0.6679135271871804, 0.6678884647153167, 0.6675580249302461, 0.6688245057783905, 0.6687537331973654, 0.671960401275334, 0.6714095766888617, 0.6705603110254764, 0.6700537945462579, 0.6719359517419226, 0.6733268777000805, 0.6732217958489664, 0.6738004285245358, 0.6745539816537758, 0.6766448116196772, 0.6747843617875382, 0.6770202285732771, 0.6756012292296206, 0.676310331117723, 0.6768586634325572, 0.677961659059144, 0.676572623546123]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:25,  1.99s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:40,  1.84s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:25,  1.79s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:53,  1.69s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:09,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:44,  1.67s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:16,  1.79s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:02,  1.74s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:19,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:41,  1.90s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:06,  1.78s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:18,  1.83s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:03,  1.78s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:08,  1.80s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:27,  1.88s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:33,  1.91s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:07,  1.82s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:11,  1.84s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:54,  1.78s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:56,  1.80s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:09,  1.85s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:48,  1.78s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:00,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:39,  1.76s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:55,  1.83s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<07:58,  1.85s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:39,  1.78s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:47,  1.82s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:56,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:03,  1.90s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:09,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:40,  1.82s/it]predicting train subjects:  12%|█▏        | 33/285 [00:59<07:36,  1.81s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:40,  1.83s/it]predicting train subjects:  12%|█▏        | 35/285 [01:03<07:47,  1.87s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:28,  1.80s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:36,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:41,  1.87s/it]predicting train subjects:  14%|█▎        | 39/285 [01:10<07:26,  1.81s/it]predicting train subjects:  14%|█▍        | 40/285 [01:12<07:27,  1.83s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:15,  1.78s/it]predicting train subjects:  15%|█▍        | 42/285 [01:15<07:01,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:17<07:11,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:19<07:31,  1.87s/it]predicting train subjects:  16%|█▌        | 45/285 [01:21<07:34,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:23<07:52,  1.98s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<07:34,  1.91s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<07:45,  1.96s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<07:59,  2.03s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:51,  2.01s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<07:58,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:35,  1.95s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:38,  1.98s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:51,  2.04s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:21,  1.92s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:20,  1.93s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:58,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:57,  1.84s/it]predicting train subjects:  21%|██        | 59/285 [01:48<07:03,  1.87s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:07,  1.90s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<07:04,  1.89s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<07:10,  1.93s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<07:11,  1.94s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:56,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<07:00,  1.91s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:58,  1.91s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:53,  1.90s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:47,  1.88s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:41,  1.86s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:51,  1.92s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:33,  1.85s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:35,  1.87s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:37,  1.88s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:53,  1.97s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:54,  1.98s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:38,  1.91s/it]predicting train subjects:  27%|██▋       | 78/285 [02:25<06:31,  1.89s/it]predicting train subjects:  28%|██▊       | 79/285 [02:27<06:35,  1.92s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:34,  1.92s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:19,  1.86s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:15,  1.85s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<05:58,  1.78s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<06:06,  1.82s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<06:06,  1.83s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:14,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:13,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:43<06:08,  1.87s/it]predicting train subjects:  31%|███       | 89/285 [02:45<06:08,  1.88s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<06:07,  1.89s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<06:02,  1.88s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<05:53,  1.84s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:53,  1.85s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<06:05,  1.92s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<06:16,  1.99s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<06:07,  1.95s/it]predicting train subjects:  34%|███▍      | 98/285 [03:02<05:54,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:04<05:47,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:06<06:02,  1.96s/it]predicting train subjects:  35%|███▌      | 101/285 [03:08<05:39,  1.84s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:43,  1.87s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:28,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:37,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:42,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<05:28,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:36,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:28,  1.86s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:31,  1.88s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:42,  1.96s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:27,  1.88s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:28,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:27,  1.90s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:27,  1.92s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:19,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:23,  1.92s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:18,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:40<05:09,  1.85s/it]predicting train subjects:  42%|████▏     | 119/285 [03:42<05:22,  1.94s/it]predicting train subjects:  42%|████▏     | 120/285 [03:44<05:10,  1.88s/it]predicting train subjects:  42%|████▏     | 121/285 [03:46<05:06,  1.87s/it]predicting train subjects:  43%|████▎     | 122/285 [03:47<04:51,  1.79s/it]predicting train subjects:  43%|████▎     | 123/285 [03:49<04:45,  1.76s/it]predicting train subjects:  44%|████▎     | 124/285 [03:51<04:43,  1.76s/it]predicting train subjects:  44%|████▍     | 125/285 [03:52<04:28,  1.68s/it]predicting train subjects:  44%|████▍     | 126/285 [03:54<04:31,  1.71s/it]predicting train subjects:  45%|████▍     | 127/285 [03:56<04:26,  1.68s/it]predicting train subjects:  45%|████▍     | 128/285 [03:57<04:28,  1.71s/it]predicting train subjects:  45%|████▌     | 129/285 [03:59<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:00<04:08,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [04:02<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [04:04<04:22,  1.72s/it]predicting train subjects:  47%|████▋     | 133/285 [04:06<04:19,  1.71s/it]predicting train subjects:  47%|████▋     | 134/285 [04:07<04:11,  1.67s/it]predicting train subjects:  47%|████▋     | 135/285 [04:09<03:58,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:10<03:54,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<04:12,  1.71s/it]predicting train subjects:  48%|████▊     | 138/285 [04:14<04:00,  1.63s/it]predicting train subjects:  49%|████▉     | 139/285 [04:15<04:02,  1.66s/it]predicting train subjects:  49%|████▉     | 140/285 [04:17<03:59,  1.65s/it]predicting train subjects:  49%|████▉     | 141/285 [04:18<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:20<03:48,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:21<03:42,  1.57s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:43,  1.59s/it]predicting train subjects:  51%|█████     | 145/285 [04:25<03:41,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:26<03:41,  1.59s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:29<03:35,  1.58s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:43,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:33<03:39,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:35<03:43,  1.67s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:36<03:37,  1.64s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:38<03:32,  1.61s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:39<03:32,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:41<03:26,  1.59s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:42<03:27,  1.61s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:44<03:19,  1.56s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:45<03:17,  1.56s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:47<03:18,  1.58s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:49<03:24,  1.64s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:51<03:26,  1.67s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:52<03:19,  1.62s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:18,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:55<03:11,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:06,  1.55s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:58<03:11,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:14,  1.65s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:02<03:14,  1.66s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:04<03:14,  1.67s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:05<03:08,  1.63s/it]predicting train subjects:  60%|██████    | 171/285 [05:07<03:07,  1.64s/it]predicting train subjects:  60%|██████    | 172/285 [05:08<03:02,  1.61s/it]predicting train subjects:  61%|██████    | 173/285 [05:10<02:57,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [05:11<02:52,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:13<02:57,  1.62s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:15<02:56,  1.62s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:16<02:53,  1.61s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:18<02:46,  1.56s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:19<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:21<02:57,  1.69s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:23<02:59,  1.72s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:25<02:58,  1.73s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:26<02:47,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:28<02:45,  1.64s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:29<02:35,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:31<02:46,  1.68s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:33<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:35<02:50,  1.76s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:36<02:41,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:38<02:39,  1.68s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:40<02:48,  1.79s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:42<02:45,  1.78s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:43<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:45<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:46<02:25,  1.61s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:48<02:34,  1.74s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:50<02:39,  1.81s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:52<02:42,  1.87s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:54<02:29,  1.74s/it]predicting train subjects:  70%|███████   | 200/285 [05:55<02:24,  1.70s/it]predicting train subjects:  71%|███████   | 201/285 [05:57<02:28,  1.77s/it]predicting train subjects:  71%|███████   | 202/285 [05:59<02:25,  1.76s/it]predicting train subjects:  71%|███████   | 203/285 [06:01<02:26,  1.78s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:02<02:16,  1.68s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:04<02:12,  1.66s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:06<02:10,  1.65s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:08<02:18,  1.77s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:10<02:20,  1.82s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:11<02:19,  1.83s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:13<02:08,  1.72s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:15<02:06,  1.71s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:17<02:20,  1.93s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:19<02:20,  1.95s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:21<02:25,  2.05s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:24<02:34,  2.20s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:26<02:27,  2.14s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:28<02:29,  2.20s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:31<02:32,  2.27s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:33<02:38,  2.39s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:35<02:26,  2.25s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:38<02:25,  2.28s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:40<02:18,  2.19s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:41<02:07,  2.06s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:43<02:01,  2.00s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:45<01:57,  1.96s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:47<01:56,  1.97s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:49<01:56,  2.01s/it]predicting train subjects:  80%|████████  | 228/285 [06:51<01:56,  2.05s/it]predicting train subjects:  80%|████████  | 229/285 [06:53<01:57,  2.09s/it]predicting train subjects:  81%|████████  | 230/285 [06:55<01:49,  1.98s/it]predicting train subjects:  81%|████████  | 231/285 [06:57<01:45,  1.95s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:59<01:43,  1.96s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:01<01:39,  1.91s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:03<01:41,  1.99s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:05<01:40,  2.01s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:07<01:42,  2.10s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:09<01:38,  2.04s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:12<01:40,  2.14s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:14<01:38,  2.14s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:16<01:32,  2.05s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:17<01:24,  1.92s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:19<01:21,  1.89s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:21<01:17,  1.85s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:23<01:23,  2.03s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:25<01:16,  1.92s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:27<01:18,  2.00s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:29<01:18,  2.06s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:31<01:16,  2.07s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:33<01:10,  1.95s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:35<01:05,  1.88s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:36<01:00,  1.79s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:38<00:57,  1.75s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:40<01:02,  1.95s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:43<01:04,  2.07s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:45<01:01,  2.05s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:46<00:54,  1.89s/it]predicting train subjects:  90%|█████████ | 257/285 [07:48<00:51,  1.84s/it]predicting train subjects:  91%|█████████ | 258/285 [07:50<00:53,  2.00s/it]predicting train subjects:  91%|█████████ | 259/285 [07:53<00:54,  2.09s/it]predicting train subjects:  91%|█████████ | 260/285 [07:54<00:48,  1.93s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:56<00:46,  1.92s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:58<00:43,  1.88s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:59<00:38,  1.74s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:02<00:38,  1.85s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:04<00:40,  2.00s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:06<00:36,  1.91s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:07<00:33,  1.84s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:10<00:34,  2.01s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:12<00:31,  1.96s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:13<00:28,  1.91s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:15<00:27,  1.93s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:17<00:25,  1.97s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:19<00:23,  1.94s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:21<00:20,  1.86s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:23<00:19,  1.95s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:25<00:17,  2.00s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:27<00:15,  1.88s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:28<00:12,  1.83s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:30<00:10,  1.82s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:32<00:08,  1.74s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:34<00:06,  1.72s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:35<00:05,  1.78s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:38<00:03,  1.95s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:40<00:01,  1.99s/it]predicting train subjects: 100%|██████████| 285/285 [08:42<00:00,  2.06s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:02,  1.91s/it]Loading train:   1%|          | 2/285 [00:03<08:32,  1.81s/it]Loading train:   1%|          | 3/285 [00:05<09:21,  1.99s/it]Loading train:   1%|▏         | 4/285 [00:07<09:16,  1.98s/it]Loading train:   2%|▏         | 5/285 [00:10<09:28,  2.03s/it]Loading train:   2%|▏         | 6/285 [00:11<09:03,  1.95s/it]Loading train:   2%|▏         | 7/285 [00:14<10:12,  2.20s/it]Loading train:   3%|▎         | 8/285 [00:16<09:53,  2.14s/it]Loading train:   3%|▎         | 9/285 [00:19<11:01,  2.40s/it]Loading train:   4%|▎         | 10/285 [00:21<10:13,  2.23s/it]Loading train:   4%|▍         | 11/285 [00:23<09:23,  2.06s/it]Loading train:   4%|▍         | 12/285 [00:25<09:36,  2.11s/it]Loading train:   5%|▍         | 13/285 [00:26<08:58,  1.98s/it]Loading train:   5%|▍         | 14/285 [00:28<08:08,  1.80s/it]Loading train:   5%|▌         | 15/285 [00:30<08:22,  1.86s/it]Loading train:   6%|▌         | 16/285 [00:31<07:59,  1.78s/it]Loading train:   6%|▌         | 17/285 [00:33<07:56,  1.78s/it]Loading train:   6%|▋         | 18/285 [00:35<08:08,  1.83s/it]Loading train:   7%|▋         | 19/285 [00:37<08:23,  1.89s/it]Loading train:   7%|▋         | 20/285 [00:39<08:06,  1.84s/it]Loading train:   7%|▋         | 21/285 [00:41<08:16,  1.88s/it]Loading train:   8%|▊         | 22/285 [00:43<07:59,  1.82s/it]Loading train:   8%|▊         | 23/285 [00:45<08:16,  1.90s/it]Loading train:   8%|▊         | 24/285 [00:47<08:17,  1.90s/it]Loading train:   9%|▉         | 25/285 [00:49<08:30,  1.96s/it]Loading train:   9%|▉         | 26/285 [00:50<08:14,  1.91s/it]Loading train:   9%|▉         | 27/285 [00:52<08:10,  1.90s/it]Loading train:  10%|▉         | 28/285 [00:54<07:58,  1.86s/it]Loading train:  10%|█         | 29/285 [00:56<07:29,  1.76s/it]Loading train:  11%|█         | 30/285 [00:58<07:46,  1.83s/it]Loading train:  11%|█         | 31/285 [01:00<07:58,  1.88s/it]Loading train:  11%|█         | 32/285 [01:01<07:30,  1.78s/it]Loading train:  12%|█▏        | 33/285 [01:03<07:55,  1.89s/it]Loading train:  12%|█▏        | 34/285 [01:05<07:37,  1.82s/it]Loading train:  12%|█▏        | 35/285 [01:07<07:42,  1.85s/it]Loading train:  13%|█▎        | 36/285 [01:08<07:13,  1.74s/it]Loading train:  13%|█▎        | 37/285 [01:10<07:07,  1.72s/it]Loading train:  13%|█▎        | 38/285 [01:12<07:36,  1.85s/it]Loading train:  14%|█▎        | 39/285 [01:14<07:17,  1.78s/it]Loading train:  14%|█▍        | 40/285 [01:16<07:15,  1.78s/it]Loading train:  14%|█▍        | 41/285 [01:18<07:24,  1.82s/it]Loading train:  15%|█▍        | 42/285 [01:19<07:08,  1.76s/it]Loading train:  15%|█▌        | 43/285 [01:21<07:24,  1.84s/it]Loading train:  15%|█▌        | 44/285 [01:23<07:37,  1.90s/it]Loading train:  16%|█▌        | 45/285 [01:25<07:39,  1.91s/it]Loading train:  16%|█▌        | 46/285 [01:27<07:42,  1.94s/it]Loading train:  16%|█▋        | 47/285 [01:29<07:41,  1.94s/it]Loading train:  17%|█▋        | 48/285 [01:31<07:22,  1.87s/it]Loading train:  17%|█▋        | 49/285 [01:33<07:50,  1.99s/it]Loading train:  18%|█▊        | 50/285 [01:35<08:09,  2.08s/it]Loading train:  18%|█▊        | 51/285 [01:37<07:56,  2.04s/it]Loading train:  18%|█▊        | 52/285 [01:39<07:47,  2.01s/it]Loading train:  19%|█▊        | 53/285 [01:41<07:54,  2.05s/it]Loading train:  19%|█▉        | 54/285 [01:43<07:12,  1.87s/it]Loading train:  19%|█▉        | 55/285 [01:44<06:48,  1.78s/it]Loading train:  20%|█▉        | 56/285 [01:46<06:32,  1.71s/it]Loading train:  20%|██        | 57/285 [01:47<06:02,  1.59s/it]Loading train:  20%|██        | 58/285 [01:49<06:03,  1.60s/it]Loading train:  21%|██        | 59/285 [01:51<06:59,  1.86s/it]Loading train:  21%|██        | 60/285 [01:53<07:08,  1.90s/it]Loading train:  21%|██▏       | 61/285 [01:56<07:40,  2.06s/it]Loading train:  22%|██▏       | 62/285 [01:58<07:22,  1.98s/it]Loading train:  22%|██▏       | 63/285 [01:59<06:58,  1.88s/it]Loading train:  22%|██▏       | 64/285 [02:01<07:21,  2.00s/it]Loading train:  23%|██▎       | 65/285 [02:04<07:44,  2.11s/it]Loading train:  23%|██▎       | 66/285 [02:06<08:11,  2.24s/it]Loading train:  24%|██▎       | 67/285 [02:08<07:24,  2.04s/it]Loading train:  24%|██▍       | 68/285 [02:10<07:03,  1.95s/it]Loading train:  24%|██▍       | 69/285 [02:11<06:46,  1.88s/it]Loading train:  25%|██▍       | 70/285 [02:13<06:26,  1.80s/it]Loading train:  25%|██▍       | 71/285 [02:15<06:20,  1.78s/it]Loading train:  25%|██▌       | 72/285 [02:17<06:16,  1.77s/it]Loading train:  26%|██▌       | 73/285 [02:18<06:13,  1.76s/it]Loading train:  26%|██▌       | 74/285 [02:20<06:13,  1.77s/it]Loading train:  26%|██▋       | 75/285 [02:22<05:59,  1.71s/it]Loading train:  27%|██▋       | 76/285 [02:23<05:53,  1.69s/it]Loading train:  27%|██▋       | 77/285 [02:25<06:21,  1.83s/it]Loading train:  27%|██▋       | 78/285 [02:27<06:00,  1.74s/it]Loading train:  28%|██▊       | 79/285 [02:28<05:44,  1.67s/it]Loading train:  28%|██▊       | 80/285 [02:30<05:35,  1.64s/it]Loading train:  28%|██▊       | 81/285 [02:32<06:06,  1.80s/it]Loading train:  29%|██▉       | 82/285 [02:34<06:06,  1.81s/it]Loading train:  29%|██▉       | 83/285 [02:36<06:03,  1.80s/it]Loading train:  29%|██▉       | 84/285 [02:37<05:40,  1.70s/it]Loading train:  30%|██▉       | 85/285 [02:39<06:00,  1.80s/it]Loading train:  30%|███       | 86/285 [02:41<05:50,  1.76s/it]Loading train:  31%|███       | 87/285 [02:43<05:47,  1.75s/it]Loading train:  31%|███       | 88/285 [02:44<05:17,  1.61s/it]Loading train:  31%|███       | 89/285 [02:46<05:20,  1.64s/it]Loading train:  32%|███▏      | 90/285 [02:47<05:07,  1.58s/it]Loading train:  32%|███▏      | 91/285 [02:48<04:32,  1.40s/it]Loading train:  32%|███▏      | 92/285 [02:50<04:45,  1.48s/it]Loading train:  33%|███▎      | 93/285 [02:51<04:52,  1.52s/it]Loading train:  33%|███▎      | 94/285 [02:53<05:16,  1.66s/it]Loading train:  33%|███▎      | 95/285 [02:55<05:28,  1.73s/it]Loading train:  34%|███▎      | 96/285 [02:57<05:09,  1.64s/it]Loading train:  34%|███▍      | 97/285 [02:58<04:45,  1.52s/it]Loading train:  34%|███▍      | 98/285 [02:59<04:35,  1.47s/it]Loading train:  35%|███▍      | 99/285 [03:01<04:53,  1.58s/it]Loading train:  35%|███▌      | 100/285 [03:03<05:30,  1.79s/it]Loading train:  35%|███▌      | 101/285 [03:05<05:22,  1.75s/it]Loading train:  36%|███▌      | 102/285 [03:07<05:13,  1.71s/it]Loading train:  36%|███▌      | 103/285 [03:09<05:24,  1.78s/it]Loading train:  36%|███▋      | 104/285 [03:10<05:22,  1.78s/it]Loading train:  37%|███▋      | 105/285 [03:12<04:59,  1.66s/it]Loading train:  37%|███▋      | 106/285 [03:13<04:48,  1.61s/it]Loading train:  38%|███▊      | 107/285 [03:15<04:44,  1.60s/it]Loading train:  38%|███▊      | 108/285 [03:16<04:22,  1.48s/it]Loading train:  38%|███▊      | 109/285 [03:18<04:21,  1.49s/it]Loading train:  39%|███▊      | 110/285 [03:19<04:35,  1.58s/it]Loading train:  39%|███▉      | 111/285 [03:21<04:35,  1.58s/it]Loading train:  39%|███▉      | 112/285 [03:23<04:43,  1.64s/it]Loading train:  40%|███▉      | 113/285 [03:25<04:57,  1.73s/it]Loading train:  40%|████      | 114/285 [03:26<04:49,  1.69s/it]Loading train:  40%|████      | 115/285 [03:28<04:51,  1.71s/it]Loading train:  41%|████      | 116/285 [03:30<05:06,  1.81s/it]Loading train:  41%|████      | 117/285 [03:32<04:58,  1.78s/it]Loading train:  41%|████▏     | 118/285 [03:34<04:57,  1.78s/it]Loading train:  42%|████▏     | 119/285 [03:35<05:00,  1.81s/it]Loading train:  42%|████▏     | 120/285 [03:37<04:44,  1.73s/it]Loading train:  42%|████▏     | 121/285 [03:39<04:41,  1.72s/it]Loading train:  43%|████▎     | 122/285 [03:41<04:58,  1.83s/it]Loading train:  43%|████▎     | 123/285 [03:43<05:39,  2.09s/it]Loading train:  44%|████▎     | 124/285 [03:45<04:51,  1.81s/it]Loading train:  44%|████▍     | 125/285 [03:46<04:10,  1.57s/it]Loading train:  44%|████▍     | 126/285 [03:47<04:14,  1.60s/it]Loading train:  45%|████▍     | 127/285 [03:49<04:09,  1.58s/it]Loading train:  45%|████▍     | 128/285 [03:50<04:01,  1.54s/it]Loading train:  45%|████▌     | 129/285 [03:52<03:48,  1.46s/it]Loading train:  46%|████▌     | 130/285 [03:53<03:28,  1.34s/it]Loading train:  46%|████▌     | 131/285 [03:54<03:10,  1.24s/it]Loading train:  46%|████▋     | 132/285 [03:55<03:00,  1.18s/it]Loading train:  47%|████▋     | 133/285 [03:56<02:52,  1.14s/it]Loading train:  47%|████▋     | 134/285 [03:57<02:45,  1.10s/it]Loading train:  47%|████▋     | 135/285 [03:58<02:40,  1.07s/it]Loading train:  48%|████▊     | 136/285 [03:59<02:35,  1.04s/it]Loading train:  48%|████▊     | 137/285 [04:00<02:35,  1.05s/it]Loading train:  48%|████▊     | 138/285 [04:01<02:28,  1.01s/it]Loading train:  49%|████▉     | 139/285 [04:02<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [04:03<02:27,  1.02s/it]Loading train:  49%|████▉     | 141/285 [04:04<02:22,  1.01it/s]Loading train:  50%|████▉     | 142/285 [04:05<02:24,  1.01s/it]Loading train:  50%|█████     | 143/285 [04:06<02:17,  1.04it/s]Loading train:  51%|█████     | 144/285 [04:07<02:20,  1.00it/s]Loading train:  51%|█████     | 145/285 [04:08<02:26,  1.05s/it]Loading train:  51%|█████     | 146/285 [04:09<02:21,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [04:10<02:12,  1.04it/s]Loading train:  52%|█████▏    | 148/285 [04:10<02:05,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [04:11<01:58,  1.14it/s]Loading train:  53%|█████▎    | 150/285 [04:12<01:53,  1.18it/s]Loading train:  53%|█████▎    | 151/285 [04:13<01:54,  1.17it/s]Loading train:  53%|█████▎    | 152/285 [04:14<01:55,  1.15it/s]Loading train:  54%|█████▎    | 153/285 [04:15<01:57,  1.13it/s]Loading train:  54%|█████▍    | 154/285 [04:16<02:00,  1.09it/s]Loading train:  54%|█████▍    | 155/285 [04:17<02:01,  1.07it/s]Loading train:  55%|█████▍    | 156/285 [04:17<01:57,  1.10it/s]Loading train:  55%|█████▌    | 157/285 [04:18<01:55,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [04:19<01:53,  1.11it/s]Loading train:  56%|█████▌    | 159/285 [04:20<01:51,  1.13it/s]Loading train:  56%|█████▌    | 160/285 [04:21<02:00,  1.04it/s]Loading train:  56%|█████▋    | 161/285 [04:22<02:02,  1.01it/s]Loading train:  57%|█████▋    | 162/285 [04:23<01:59,  1.03it/s]Loading train:  57%|█████▋    | 163/285 [04:24<02:00,  1.01it/s]Loading train:  58%|█████▊    | 164/285 [04:25<01:56,  1.04it/s]Loading train:  58%|█████▊    | 165/285 [04:26<01:58,  1.01it/s]Loading train:  58%|█████▊    | 166/285 [04:27<01:56,  1.02it/s]Loading train:  59%|█████▊    | 167/285 [04:28<01:54,  1.03it/s]Loading train:  59%|█████▉    | 168/285 [04:29<01:57,  1.00s/it]Loading train:  59%|█████▉    | 169/285 [04:30<01:55,  1.01it/s]Loading train:  60%|█████▉    | 170/285 [04:31<01:54,  1.00it/s]Loading train:  60%|██████    | 171/285 [04:32<01:49,  1.04it/s]Loading train:  60%|██████    | 172/285 [04:33<01:52,  1.00it/s]Loading train:  61%|██████    | 173/285 [04:34<01:52,  1.00s/it]Loading train:  61%|██████    | 174/285 [04:35<01:51,  1.01s/it]Loading train:  61%|██████▏   | 175/285 [04:36<01:53,  1.03s/it]Loading train:  62%|██████▏   | 176/285 [04:37<01:55,  1.06s/it]Loading train:  62%|██████▏   | 177/285 [04:38<01:53,  1.05s/it]Loading train:  62%|██████▏   | 178/285 [04:39<01:51,  1.04s/it]Loading train:  63%|██████▎   | 179/285 [04:41<01:53,  1.07s/it]Loading train:  63%|██████▎   | 180/285 [04:42<01:58,  1.13s/it]Loading train:  64%|██████▎   | 181/285 [04:43<01:51,  1.07s/it]Loading train:  64%|██████▍   | 182/285 [04:44<01:49,  1.07s/it]Loading train:  64%|██████▍   | 183/285 [04:45<01:48,  1.07s/it]Loading train:  65%|██████▍   | 184/285 [04:46<01:44,  1.03s/it]Loading train:  65%|██████▍   | 185/285 [04:47<01:43,  1.04s/it]Loading train:  65%|██████▌   | 186/285 [04:48<01:47,  1.08s/it]Loading train:  66%|██████▌   | 187/285 [04:49<01:49,  1.12s/it]Loading train:  66%|██████▌   | 188/285 [04:51<01:54,  1.18s/it]Loading train:  66%|██████▋   | 189/285 [04:52<01:49,  1.14s/it]Loading train:  67%|██████▋   | 190/285 [04:53<01:42,  1.08s/it]Loading train:  67%|██████▋   | 191/285 [04:54<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [04:55<01:42,  1.11s/it]Loading train:  68%|██████▊   | 193/285 [04:56<01:38,  1.07s/it]Loading train:  68%|██████▊   | 194/285 [04:57<01:36,  1.06s/it]Loading train:  68%|██████▊   | 195/285 [04:58<01:30,  1.00s/it]Loading train:  69%|██████▉   | 196/285 [04:59<01:32,  1.04s/it]Loading train:  69%|██████▉   | 197/285 [05:00<01:35,  1.08s/it]Loading train:  69%|██████▉   | 198/285 [05:01<01:36,  1.11s/it]Loading train:  70%|██████▉   | 199/285 [05:02<01:30,  1.05s/it]Loading train:  70%|███████   | 200/285 [05:03<01:23,  1.01it/s]Loading train:  71%|███████   | 201/285 [05:04<01:27,  1.04s/it]Loading train:  71%|███████   | 202/285 [05:05<01:28,  1.07s/it]Loading train:  71%|███████   | 203/285 [05:06<01:28,  1.08s/it]Loading train:  72%|███████▏  | 204/285 [05:07<01:24,  1.04s/it]Loading train:  72%|███████▏  | 205/285 [05:08<01:22,  1.03s/it]Loading train:  72%|███████▏  | 206/285 [05:09<01:17,  1.02it/s]Loading train:  73%|███████▎  | 207/285 [05:10<01:20,  1.03s/it]Loading train:  73%|███████▎  | 208/285 [05:11<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [05:13<01:21,  1.08s/it]Loading train:  74%|███████▎  | 210/285 [05:14<01:17,  1.03s/it]Loading train:  74%|███████▍  | 211/285 [05:14<01:14,  1.01s/it]Loading train:  74%|███████▍  | 212/285 [05:15<01:12,  1.00it/s]Loading train:  75%|███████▍  | 213/285 [05:16<01:11,  1.00it/s]Loading train:  75%|███████▌  | 214/285 [05:17<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [05:18<01:07,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [05:19<01:05,  1.06it/s]Loading train:  76%|███████▌  | 217/285 [05:20<01:08,  1.01s/it]Loading train:  76%|███████▋  | 218/285 [05:21<01:07,  1.01s/it]Loading train:  77%|███████▋  | 219/285 [05:22<01:07,  1.02s/it]Loading train:  77%|███████▋  | 220/285 [05:23<01:05,  1.01s/it]Loading train:  78%|███████▊  | 221/285 [05:24<01:04,  1.01s/it]Loading train:  78%|███████▊  | 222/285 [05:25<01:01,  1.02it/s]Loading train:  78%|███████▊  | 223/285 [05:26<00:58,  1.05it/s]Loading train:  79%|███████▊  | 224/285 [05:27<00:55,  1.10it/s]Loading train:  79%|███████▉  | 225/285 [05:28<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [05:29<00:52,  1.13it/s]Loading train:  80%|███████▉  | 227/285 [05:30<00:52,  1.10it/s]Loading train:  80%|████████  | 228/285 [05:31<00:55,  1.03it/s]Loading train:  80%|████████  | 229/285 [05:32<00:56,  1.01s/it]Loading train:  81%|████████  | 230/285 [05:33<00:55,  1.01s/it]Loading train:  81%|████████  | 231/285 [05:34<00:52,  1.02it/s]Loading train:  81%|████████▏ | 232/285 [05:35<00:53,  1.00s/it]Loading train:  82%|████████▏ | 233/285 [05:36<00:50,  1.04it/s]Loading train:  82%|████████▏ | 234/285 [05:37<00:53,  1.04s/it]Loading train:  82%|████████▏ | 235/285 [05:38<00:53,  1.06s/it]Loading train:  83%|████████▎ | 236/285 [05:39<00:54,  1.11s/it]Loading train:  83%|████████▎ | 237/285 [05:40<00:54,  1.14s/it]Loading train:  84%|████████▎ | 238/285 [05:42<00:52,  1.12s/it]Loading train:  84%|████████▍ | 239/285 [05:43<00:50,  1.10s/it]Loading train:  84%|████████▍ | 240/285 [05:44<00:47,  1.05s/it]Loading train:  85%|████████▍ | 241/285 [05:44<00:43,  1.02it/s]Loading train:  85%|████████▍ | 242/285 [05:45<00:42,  1.02it/s]Loading train:  85%|████████▌ | 243/285 [05:46<00:41,  1.01it/s]Loading train:  86%|████████▌ | 244/285 [05:47<00:41,  1.01s/it]Loading train:  86%|████████▌ | 245/285 [05:48<00:40,  1.02s/it]Loading train:  86%|████████▋ | 246/285 [05:50<00:42,  1.09s/it]Loading train:  87%|████████▋ | 247/285 [05:51<00:40,  1.07s/it]Loading train:  87%|████████▋ | 248/285 [05:52<00:40,  1.09s/it]Loading train:  87%|████████▋ | 249/285 [05:53<00:37,  1.05s/it]Loading train:  88%|████████▊ | 250/285 [05:54<00:36,  1.05s/it]Loading train:  88%|████████▊ | 251/285 [05:55<00:33,  1.00it/s]Loading train:  88%|████████▊ | 252/285 [05:56<00:32,  1.00it/s]Loading train:  89%|████████▉ | 253/285 [05:57<00:32,  1.01s/it]Loading train:  89%|████████▉ | 254/285 [05:58<00:32,  1.04s/it]Loading train:  89%|████████▉ | 255/285 [05:59<00:31,  1.05s/it]Loading train:  90%|████████▉ | 256/285 [06:00<00:29,  1.01s/it]Loading train:  90%|█████████ | 257/285 [06:01<00:27,  1.00it/s]Loading train:  91%|█████████ | 258/285 [06:02<00:27,  1.03s/it]Loading train:  91%|█████████ | 259/285 [06:03<00:28,  1.08s/it]Loading train:  91%|█████████ | 260/285 [06:04<00:26,  1.05s/it]Loading train:  92%|█████████▏| 261/285 [06:05<00:25,  1.08s/it]Loading train:  92%|█████████▏| 262/285 [06:06<00:25,  1.10s/it]Loading train:  92%|█████████▏| 263/285 [06:07<00:23,  1.07s/it]Loading train:  93%|█████████▎| 264/285 [06:09<00:22,  1.09s/it]Loading train:  93%|█████████▎| 265/285 [06:10<00:21,  1.08s/it]Loading train:  93%|█████████▎| 266/285 [06:11<00:19,  1.05s/it]Loading train:  94%|█████████▎| 267/285 [06:12<00:18,  1.04s/it]Loading train:  94%|█████████▍| 268/285 [06:13<00:18,  1.11s/it]Loading train:  94%|█████████▍| 269/285 [06:14<00:17,  1.12s/it]Loading train:  95%|█████████▍| 270/285 [06:15<00:15,  1.06s/it]Loading train:  95%|█████████▌| 271/285 [06:16<00:15,  1.07s/it]Loading train:  95%|█████████▌| 272/285 [06:17<00:13,  1.06s/it]Loading train:  96%|█████████▌| 273/285 [06:18<00:12,  1.03s/it]Loading train:  96%|█████████▌| 274/285 [06:19<00:11,  1.07s/it]Loading train:  96%|█████████▋| 275/285 [06:20<00:11,  1.12s/it]Loading train:  97%|█████████▋| 276/285 [06:22<00:10,  1.12s/it]Loading train:  97%|█████████▋| 277/285 [06:22<00:08,  1.05s/it]Loading train:  98%|█████████▊| 278/285 [06:23<00:06,  1.00it/s]Loading train:  98%|█████████▊| 279/285 [06:24<00:06,  1.02s/it]Loading train:  98%|█████████▊| 280/285 [06:25<00:05,  1.01s/it]Loading train:  99%|█████████▊| 281/285 [06:26<00:04,  1.01s/it]Loading train:  99%|█████████▉| 282/285 [06:27<00:02,  1.01it/s]Loading train:  99%|█████████▉| 283/285 [06:29<00:02,  1.04s/it]Loading train: 100%|█████████▉| 284/285 [06:30<00:01,  1.12s/it]Loading train: 100%|██████████| 285/285 [06:31<00:00,  1.11s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 69.23it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:03, 75.58it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:02, 85.05it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:02, 94.10it/s]concatenating: train:  23%|██▎       | 66/285 [00:00<00:01, 114.36it/s]concatenating: train:  32%|███▏      | 91/285 [00:00<00:01, 136.58it/s]concatenating: train:  43%|████▎     | 122/285 [00:00<00:00, 163.34it/s]concatenating: train:  54%|█████▍    | 154/285 [00:00<00:00, 191.27it/s]concatenating: train:  62%|██████▏   | 178/285 [00:00<00:00, 171.97it/s]concatenating: train:  70%|██████▉   | 199/285 [00:01<00:00, 167.80it/s]concatenating: train:  81%|████████▏ | 232/285 [00:01<00:00, 196.10it/s]concatenating: train:  93%|█████████▎| 266/285 [00:01<00:00, 223.60it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 206.41it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.41s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.41s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 61.89it/s]2019-07-10 23:40:54.754517: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-10 23:40:54.754619: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-10 23:40:54.754637: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-10 23:40:54.754646: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-10 23:40:54.755095: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.10it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.95it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.45it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  7.06it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.51it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.59it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.52it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.94it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.46it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  9.26it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.65it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.83it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.85it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.82it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.93it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.52it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.87it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 237,903
Trainable params: 63,103
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 19s - loss: 2.1187 - acc: 0.6166 - mDice: 0.2515 - val_loss: 0.5364 - val_acc: 0.9483 - val_mDice: 0.5718

Epoch 00001: val_mDice improved from -inf to 0.57176, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.5209 - acc: 0.9337 - mDice: 0.5802 - val_loss: 0.4622 - val_acc: 0.9525 - val_mDice: 0.6194

Epoch 00002: val_mDice improved from 0.57176 to 0.61937, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.4365 - acc: 0.9394 - mDice: 0.6321 - val_loss: 0.4419 - val_acc: 0.9529 - val_mDice: 0.6306

Epoch 00003: val_mDice improved from 0.61937 to 0.63058, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.4020 - acc: 0.9425 - mDice: 0.6546 - val_loss: 0.4505 - val_acc: 0.9539 - val_mDice: 0.6291

Epoch 00004: val_mDice did not improve from 0.63058
Epoch 5/300
 - 13s - loss: 0.3803 - acc: 0.9449 - mDice: 0.6697 - val_loss: 0.4490 - val_acc: 0.9550 - val_mDice: 0.6296

Epoch 00005: val_mDice did not improve from 0.63058
Epoch 6/300
 - 13s - loss: 0.3635 - acc: 0.9463 - mDice: 0.6812 - val_loss: 0.4587 - val_acc: 0.9540 - val_mDice: 0.6269

Epoch 00006: val_mDice did not improve from 0.63058
Epoch 7/300
 - 13s - loss: 0.3531 - acc: 0.9472 - mDice: 0.6890 - val_loss: 0.4729 - val_acc: 0.9482 - val_mDice: 0.6151

Epoch 00007: val_mDice did not improve from 0.63058
Epoch 8/300
 - 13s - loss: 0.3417 - acc: 0.9481 - mDice: 0.6968 - val_loss: 0.4507 - val_acc: 0.9533 - val_mDice: 0.6290

Epoch 00008: val_mDice did not improve from 0.63058
Epoch 9/300
 - 13s - loss: 0.3334 - acc: 0.9488 - mDice: 0.7028 - val_loss: 0.4542 - val_acc: 0.9541 - val_mDice: 0.6330

Epoch 00009: val_mDice improved from 0.63058 to 0.63300, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.3268 - acc: 0.9493 - mDice: 0.7074 - val_loss: 0.4340 - val_acc: 0.9543 - val_mDice: 0.6380

Epoch 00010: val_mDice improved from 0.63300 to 0.63803, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3205 - acc: 0.9499 - mDice: 0.7123 - val_loss: 0.4634 - val_acc: 0.9532 - val_mDice: 0.6243

Epoch 00011: val_mDice did not improve from 0.63803
Epoch 12/300
 - 13s - loss: 0.3172 - acc: 0.9501 - mDice: 0.7146 - val_loss: 0.4445 - val_acc: 0.9538 - val_mDice: 0.6342

Epoch 00012: val_mDice did not improve from 0.63803
Epoch 13/300
 - 13s - loss: 0.3102 - acc: 0.9507 - mDice: 0.7197 - val_loss: 0.4415 - val_acc: 0.9547 - val_mDice: 0.6358

Epoch 00013: val_mDice did not improve from 0.63803
Epoch 14/300
 - 13s - loss: 0.3061 - acc: 0.9511 - mDice: 0.7230 - val_loss: 0.4631 - val_acc: 0.9537 - val_mDice: 0.6229

Epoch 00014: val_mDice did not improve from 0.63803
Epoch 15/300
 - 13s - loss: 0.3051 - acc: 0.9511 - mDice: 0.7239 - val_loss: 0.4717 - val_acc: 0.9558 - val_mDice: 0.6221

Epoch 00015: val_mDice did not improve from 0.63803
Epoch 16/300
 - 13s - loss: 0.2992 - acc: 0.9516 - mDice: 0.7282 - val_loss: 0.4454 - val_acc: 0.9541 - val_mDice: 0.6320

Epoch 00016: val_mDice did not improve from 0.63803
Epoch 17/300
 - 13s - loss: 0.2942 - acc: 0.9520 - mDice: 0.7320 - val_loss: 0.4424 - val_acc: 0.9559 - val_mDice: 0.6340

Epoch 00017: val_mDice did not improve from 0.63803
Epoch 18/300
 - 13s - loss: 0.2908 - acc: 0.9521 - mDice: 0.7344 - val_loss: 0.4636 - val_acc: 0.9555 - val_mDice: 0.6248

Epoch 00018: val_mDice did not improve from 0.63803
Epoch 19/300
 - 13s - loss: 0.2876 - acc: 0.9524 - mDice: 0.7369 - val_loss: 0.4514 - val_acc: 0.9556 - val_mDice: 0.6327

Epoch 00019: val_mDice did not improve from 0.63803
Epoch 20/300
 - 13s - loss: 0.2863 - acc: 0.9526 - mDice: 0.7380 - val_loss: 0.4432 - val_acc: 0.9559 - val_mDice: 0.6338

Epoch 00020: val_mDice did not improve from 0.63803
Epoch 21/300
 - 13s - loss: 0.2834 - acc: 0.9528 - mDice: 0.7403 - val_loss: 0.4487 - val_acc: 0.9549 - val_mDice: 0.6300

Epoch 00021: val_mDice did not improve from 0.63803
Epoch 22/300
 - 13s - loss: 0.2810 - acc: 0.9530 - mDice: 0.7421 - val_loss: 0.4415 - val_acc: 0.9544 - val_mDice: 0.6329

Epoch 00022: val_mDice did not improve from 0.63803
Epoch 23/300
 - 13s - loss: 0.2807 - acc: 0.9532 - mDice: 0.7424 - val_loss: 0.4577 - val_acc: 0.9539 - val_mDice: 0.6273

Epoch 00023: val_mDice did not improve from 0.63803
Epoch 24/300
 - 13s - loss: 0.2775 - acc: 0.9534 - mDice: 0.7447 - val_loss: 0.4541 - val_acc: 0.9565 - val_mDice: 0.6307

Epoch 00024: val_mDice did not improve from 0.63803
Epoch 25/300
 - 13s - loss: 0.2756 - acc: 0.9536 - mDice: 0.7466 - val_loss: 0.4491 - val_acc: 0.9555 - val_mDice: 0.6281

Epoch 00025: val_mDice did not improve from 0.63803
Epoch 26/300
 - 13s - loss: 0.2744 - acc: 0.9537 - mDice: 0.7472 - val_loss: 0.4924 - val_acc: 0.9546 - val_mDice: 0.6128

Epoch 00026: val_mDice did not improve from 0.63803
Epoch 27/300
 - 13s - loss: 0.2718 - acc: 0.9538 - mDice: 0.7492 - val_loss: 0.4341 - val_acc: 0.9557 - val_mDice: 0.6401

Epoch 00027: val_mDice improved from 0.63803 to 0.64011, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 13s - loss: 0.2690 - acc: 0.9542 - mDice: 0.7514 - val_loss: 0.4623 - val_acc: 0.9558 - val_mDice: 0.6277

Epoch 00028: val_mDice did not improve from 0.64011
Epoch 29/300
 - 13s - loss: 0.2670 - acc: 0.9543 - mDice: 0.7529 - val_loss: 0.4442 - val_acc: 0.9537 - val_mDice: 0.6338

Epoch 00029: val_mDice did not improve from 0.64011
Epoch 30/300
 - 13s - loss: 0.2665 - acc: 0.9544 - mDice: 0.7533 - val_loss: 0.4577 - val_acc: 0.9551 - val_mDice: 0.6241

Epoch 00030: val_mDice did not improve from 0.64011
Epoch 31/300
 - 13s - loss: 0.2645 - acc: 0.9545 - mDice: 0.7549 - val_loss: 0.4683 - val_acc: 0.9544 - val_mDice: 0.6211

Epoch 00031: val_mDice did not improve from 0.64011
Epoch 32/300
 - 13s - loss: 0.2648 - acc: 0.9545 - mDice: 0.7547 - val_loss: 0.4687 - val_acc: 0.9555 - val_mDice: 0.6208

Epoch 00032: val_mDice did not improve from 0.64011
Epoch 33/300
 - 13s - loss: 0.2664 - acc: 0.9545 - mDice: 0.7535 - val_loss: 0.4597 - val_acc: 0.9566 - val_mDice: 0.6284

Epoch 00033: val_mDice did not improve from 0.64011
Epoch 34/300
 - 13s - loss: 0.2612 - acc: 0.9548 - mDice: 0.7575 - val_loss: 0.5054 - val_acc: 0.9542 - val_mDice: 0.6090

Epoch 00034: val_mDice did not improve from 0.64011
Epoch 35/300
 - 13s - loss: 0.2596 - acc: 0.9550 - mDice: 0.7588 - val_loss: 0.4531 - val_acc: 0.9539 - val_mDice: 0.6295

Epoch 00035: val_mDice did not improve from 0.64011
Epoch 36/300
 - 13s - loss: 0.2593 - acc: 0.9550 - mDice: 0.7591 - val_loss: 0.4551 - val_acc: 0.9553 - val_mDice: 0.6302

Epoch 00036: val_mDice did not improve from 0.64011
Epoch 37/300
 - 13s - loss: 0.2565 - acc: 0.9552 - mDice: 0.7612 - val_loss: 0.5013 - val_acc: 0.9554 - val_mDice: 0.6108

Epoch 00037: val_mDice did not improve from 0.64011
Epoch 38/300
 - 13s - loss: 0.2562 - acc: 0.9552 - mDice: 0.7615 - val_loss: 0.4369 - val_acc: 0.9556 - val_mDice: 0.6374

Epoch 00038: val_mDice did not improve from 0.64011
Epoch 39/300
 - 13s - loss: 0.2559 - acc: 0.9553 - mDice: 0.7617 - val_loss: 0.4626 - val_acc: 0.9553 - val_mDice: 0.6272

Epoch 00039: val_mDice did not improve from 0.64011
Epoch 40/300
 - 13s - loss: 0.2537 - acc: 0.9555 - mDice: 0.7635 - val_loss: 0.4648 - val_acc: 0.9566 - val_mDice: 0.6224

Epoch 00040: val_mDice did not improve from 0.64011
Epoch 41/300
 - 13s - loss: 0.2516 - acc: 0.9556 - mDice: 0.7651 - val_loss: 0.4795 - val_acc: 0.9561 - val_mDice: 0.6194

Epoch 00041: val_mDice did not improve from 0.64011
Epoch 42/300
 - 13s - loss: 0.2516 - acc: 0.9556 - mDice: 0.7651 - val_loss: 0.5019 - val_acc: 0.9545 - val_mDice: 0.6077

Epoch 00042: val_mDice did not improve from 0.64011
Epoch 43/300
 - 13s - loss: 0.2506 - acc: 0.9556 - mDice: 0.7659 - val_loss: 0.4556 - val_acc: 0.9548 - val_mDice: 0.6267

Epoch 00043: val_mDice did not improve from 0.64011
Epoch 44/300
 - 13s - loss: 0.2502 - acc: 0.9557 - mDice: 0.7662 - val_loss: 0.4531 - val_acc: 0.9551 - val_mDice: 0.6276

Epoch 00044: val_mDice did not improve from 0.64011
Epoch 45/300
 - 13s - loss: 0.2491 - acc: 0.9558 - mDice: 0.7671 - val_loss: 0.4732 - val_acc: 0.9553 - val_mDice: 0.6192

Epoch 00045: val_mDice did not improve from 0.64011
Epoch 46/300
 - 13s - loss: 0.2499 - acc: 0.9558 - mDice: 0.7665 - val_loss: 0.4439 - val_acc: 0.9565 - val_mDice: 0.6336

Epoch 00046: val_mDice did not improve from 0.64011
Epoch 47/300
 - 14s - loss: 0.2476 - acc: 0.9558 - mDice: 0.7684 - val_loss: 0.4620 - val_acc: 0.9557 - val_mDice: 0.6229

Epoch 00047: val_mDice did not improve from 0.64011
Epoch 48/300
 - 13s - loss: 0.2465 - acc: 0.9559 - mDice: 0.7691 - val_loss: 0.4492 - val_acc: 0.9559 - val_mDice: 0.6313

Epoch 00048: val_mDice did not improve from 0.64011
Epoch 49/300
 - 13s - loss: 0.2468 - acc: 0.9559 - mDice: 0.7691 - val_loss: 0.4409 - val_acc: 0.9545 - val_mDice: 0.6357

Epoch 00049: val_mDice did not improve from 0.64011
Epoch 50/300
 - 13s - loss: 0.2460 - acc: 0.9561 - mDice: 0.7696 - val_loss: 0.4637 - val_acc: 0.9545 - val_mDice: 0.6216

Epoch 00050: val_mDice did not improve from 0.64011
Epoch 51/300
 - 13s - loss: 0.2427 - acc: 0.9562 - mDice: 0.7722 - val_loss: 0.4547 - val_acc: 0.9547 - val_mDice: 0.6276

Epoch 00051: val_mDice did not improve from 0.64011
Epoch 52/300
 - 14s - loss: 0.2431 - acc: 0.9562 - mDice: 0.7719 - val_loss: 0.4629 - val_acc: 0.9558 - val_mDice: 0.6233

Epoch 00052: val_mDice did not improve from 0.64011
Epoch 53/300
 - 13s - loss: 0.2431 - acc: 0.9563 - mDice: 0.7719 - val_loss: 0.4571 - val_acc: 0.9554 - val_mDice: 0.6274

Epoch 00053: val_mDice did not improve from 0.64011
Epoch 54/300
 - 13s - loss: 0.2447 - acc: 0.9562 - mDice: 0.7708 - val_loss: 0.4797 - val_acc: 0.9555 - val_mDice: 0.6166

Epoch 00054: val_mDice did not improve from 0.64011
Epoch 55/300
 - 13s - loss: 0.2404 - acc: 0.9564 - mDice: 0.7742 - val_loss: 0.4611 - val_acc: 0.9560 - val_mDice: 0.6246

Epoch 00055: val_mDice did not improve from 0.64011
Epoch 56/300
 - 13s - loss: 0.2403 - acc: 0.9564 - mDice: 0.7742 - val_loss: 0.4628 - val_acc: 0.9540 - val_mDice: 0.6243

Epoch 00056: val_mDice did not improve from 0.64011
Epoch 57/300
 - 13s - loss: 0.2400 - acc: 0.9564 - mDice: 0.7744 - val_loss: 0.4636 - val_acc: 0.9559 - val_mDice: 0.6249

Epoch 00057: val_mDice did not improve from 0.64011
Epoch 58/300
 - 13s - loss: 0.2399 - acc: 0.9565 - mDice: 0.7745 - val_loss: 0.4470 - val_acc: 0.9568 - val_mDice: 0.6326

Epoch 00058: val_mDice did not improve from 0.64011
Epoch 59/300
 - 13s - loss: 0.2380 - acc: 0.9566 - mDice: 0.7760 - val_loss: 0.4487 - val_acc: 0.9552 - val_mDice: 0.6323

Epoch 00059: val_mDice did not improve from 0.64011
Epoch 60/300
 - 13s - loss: 0.2397 - acc: 0.9565 - mDice: 0.7747 - val_loss: 0.4645 - val_acc: 0.9565 - val_mDice: 0.6235

Epoch 00060: val_mDice did not improve from 0.64011
Epoch 61/300
 - 14s - loss: 0.2366 - acc: 0.9566 - mDice: 0.7771 - val_loss: 0.4955 - val_acc: 0.9543 - val_mDice: 0.6106

Epoch 00061: val_mDice did not improve from 0.64011
Epoch 62/300
 - 13s - loss: 0.2383 - acc: 0.9567 - mDice: 0.7758 - val_loss: 0.4609 - val_acc: 0.9555 - val_mDice: 0.6244

Epoch 00062: val_mDice did not improve from 0.64011
Epoch 63/300
 - 14s - loss: 0.2364 - acc: 0.9568 - mDice: 0.7774 - val_loss: 0.4719 - val_acc: 0.9547 - val_mDice: 0.6172

Epoch 00063: val_mDice did not improve from 0.64011
Epoch 64/300
 - 13s - loss: 0.2364 - acc: 0.9568 - mDice: 0.7773 - val_loss: 0.4557 - val_acc: 0.9565 - val_mDice: 0.6279

Epoch 00064: val_mDice did not improve from 0.64011
Epoch 65/300
 - 14s - loss: 0.2356 - acc: 0.9569 - mDice: 0.7780 - val_loss: 0.4687 - val_acc: 0.9556 - val_mDice: 0.6213

Epoch 00065: val_mDice did not improve from 0.64011
Epoch 66/300
 - 13s - loss: 0.2350 - acc: 0.9569 - mDice: 0.7784 - val_loss: 0.4543 - val_acc: 0.9560 - val_mDice: 0.6289

Epoch 00066: val_mDice did not improve from 0.64011
Epoch 67/300
 - 13s - loss: 0.2344 - acc: 0.9570 - mDice: 0.7789 - val_loss: 0.4607 - val_acc: 0.9551 - val_mDice: 0.6279

Epoch 00067: val_mDice did not improve from 0.64011
Restoring model weights from the end of the best epoch
Epoch 00067: early stopping
{'val_loss': [0.5363558620713943, 0.46222340094976583, 0.4419007973963988, 0.45050847197378147, 0.4489735095194598, 0.45869751882286713, 0.47286253101998865, 0.4507142628371383, 0.4542008518506695, 0.4339800523646051, 0.46344897234240057, 0.4445315865831002, 0.44151546235857064, 0.46305040740434017, 0.4717420332924614, 0.44535698304629195, 0.44235882679177396, 0.46357939463087966, 0.4513872109311919, 0.4431806496401739, 0.4487330840286596, 0.4415022091492594, 0.4576635920135669, 0.4540667543864117, 0.4491293736676264, 0.49241584006634503, 0.4341201472548799, 0.4623058428311481, 0.4441897412918133, 0.4577228020689341, 0.4683349945025737, 0.4687316324457776, 0.45970231461125377, 0.5053721712954218, 0.4531399920666018, 0.45513862238249964, 0.5012517121917043, 0.43693461231679226, 0.46264577111718375, 0.4647853657520017, 0.4795379245747401, 0.5018945955697385, 0.45562239898649676, 0.4531161688559548, 0.4732064814540927, 0.4438507663471073, 0.46197169552968204, 0.4492437939404109, 0.4409259201428078, 0.4637433167276436, 0.4547386825417673, 0.4629103970927233, 0.4570993528019783, 0.47973020183307497, 0.4610906699516254, 0.462753609572043, 0.46364520914727747, 0.4470139112552451, 0.4487107809029478, 0.4645399361349351, 0.4955403458472737, 0.46086378170791287, 0.47191146265861045, 0.45573854679501924, 0.46866428119510245, 0.45430179947581373, 0.46074567460481014], 'val_acc': [0.9482992281460895, 0.9525201820128457, 0.9528858461859506, 0.9539230066304766, 0.9550097514797189, 0.9540263014798723, 0.9482372692843389, 0.9533259026165115, 0.9541420027530393, 0.9543176349980871, 0.9531585704014954, 0.953807300362507, 0.9547308340418938, 0.9537122872288667, 0.9558464991313785, 0.9540841566117783, 0.9558568217234904, 0.9555014604962738, 0.9556130423892144, 0.9558775168557406, 0.9549415690938854, 0.9543568605151256, 0.9539292178340464, 0.9564704468796373, 0.9554973261316395, 0.9545965367855307, 0.9557184080837825, 0.9558299490193415, 0.9536874763792453, 0.9550882491319539, 0.9543609922158651, 0.9555076487237515, 0.9565861511496858, 0.9542411698975377, 0.9538506905459825, 0.9553258445675813, 0.9553651180347251, 0.9556150942541367, 0.9552803978573676, 0.9566254229518955, 0.9561378359794617, 0.9545345676011879, 0.9548341375489474, 0.9551068504429396, 0.9552989905106954, 0.9564911080472296, 0.9556543743810174, 0.9559435967626518, 0.9545118232679101, 0.9544622585094175, 0.9546833301389683, 0.9557865614997608, 0.9553754303042449, 0.9555365879442439, 0.9560427679029923, 0.9539664078025178, 0.9558898993044592, 0.9567514511460032, 0.9551853807278852, 0.9564973219146942, 0.9543320942857412, 0.9554932067514131, 0.9546523160774615, 0.9565035058133429, 0.9555779002898233, 0.9559621937448086, 0.9551357820047347], 'val_mDice': [0.5717594220651595, 0.6193653871227243, 0.6305804818702143, 0.6290882249784203, 0.6295892612894154, 0.6269058701712326, 0.6151025831366385, 0.6289513567306476, 0.6329982913406201, 0.6380325415946918, 0.6242580866680465, 0.6341597427868976, 0.6358215146224592, 0.6229193313827728, 0.6221334204993434, 0.6319781708317762, 0.6340462998304953, 0.6247982332826326, 0.6326525677515807, 0.6338156934557014, 0.6299566010523109, 0.6328734019615131, 0.6272623375807395, 0.6306703327088382, 0.6280726517378951, 0.6128184402455165, 0.6401119758296945, 0.627651703091307, 0.6338098169039081, 0.6241237597758543, 0.621122992238519, 0.6207984302962959, 0.6284356899767615, 0.6090082852534076, 0.6294573332344353, 0.6301755199219261, 0.610788372974822, 0.6374203236409406, 0.6271535647648007, 0.622443247440807, 0.6194130128988341, 0.6076801422587986, 0.6266665735058279, 0.6275921557202685, 0.6192084604135438, 0.6336282105419223, 0.6228905949512673, 0.6312848312894725, 0.6357297807432419, 0.6215631249230668, 0.6276214762106954, 0.6232755653685031, 0.6273670462922677, 0.6166412420778967, 0.6245988121245827, 0.6243127314738055, 0.6249264025821366, 0.6325835555625361, 0.632267434836766, 0.6234623253678476, 0.6105784923670678, 0.6243727789910812, 0.6172157183039788, 0.6278743484166748, 0.621268159184376, 0.6288912589323588, 0.6279439479945093], 'loss': [2.1186544814470007, 0.5209125738979898, 0.43648203039252415, 0.40202618945392216, 0.38028701791692665, 0.3634755023845978, 0.3530687294905693, 0.34173106329158387, 0.333391157630339, 0.3268200941633395, 0.32053261009912254, 0.31723918474958673, 0.3102392914245074, 0.3060923955141995, 0.3050772370037628, 0.2991656792718311, 0.2941898679325546, 0.29079126274687656, 0.2876158597831483, 0.28627250874446997, 0.2833852138591224, 0.2810155713904249, 0.28070247581526964, 0.27753295427112495, 0.2755712545922454, 0.2744282065887128, 0.2717707953297373, 0.2690320487771897, 0.26698175733446927, 0.26647497559287153, 0.2644565934063231, 0.26481334727045874, 0.26637083097231634, 0.26119850203496336, 0.2596444669216392, 0.25927978157380344, 0.256487454021362, 0.2562091029532419, 0.25586590173132673, 0.2537199580671351, 0.2516225709302786, 0.2515600595908723, 0.2506223427454674, 0.2501837019972679, 0.24914546723501738, 0.24988727378764708, 0.24760852878934891, 0.2464597276139315, 0.2467846087910538, 0.24598164631467806, 0.24272289843115435, 0.24306071739844473, 0.24312268271307808, 0.244730332467325, 0.2403684508682992, 0.24030181428107242, 0.24004467418446246, 0.23987193398486426, 0.23804599648889038, 0.23966922596349388, 0.2366385276664557, 0.2382988443182325, 0.23639174574347702, 0.23636459948307456, 0.2356304803284014, 0.23504645734608262, 0.23440966915151962], 'acc': [0.6165845186435537, 0.9337214495639553, 0.939418461534311, 0.9424685243167984, 0.9449369149409077, 0.9463201480963334, 0.9471925474493522, 0.9480944353279404, 0.9488414518811475, 0.9493095042022393, 0.9498827181852667, 0.9501204130034205, 0.9506600287821381, 0.9510676771407228, 0.9511178299840658, 0.9516353736736112, 0.9519794744108051, 0.9521333548499507, 0.9523748597069819, 0.9526324904268197, 0.9527981944492158, 0.952977193660787, 0.9531743207708123, 0.953399686805953, 0.9536430410073802, 0.9536770593236392, 0.9538234499283693, 0.9541814700333059, 0.9543107804873691, 0.9543762203038346, 0.9544892153230395, 0.9545486532072571, 0.9544611981404476, 0.9547626997292104, 0.9549712869480969, 0.9550402930674811, 0.9551973972021381, 0.9551748201079789, 0.9552591330221708, 0.9554793033703215, 0.9556046037475019, 0.9555523362296592, 0.9555819647016495, 0.9557080105053405, 0.955799798103636, 0.9558008427804582, 0.955842883938389, 0.9558744625317804, 0.9559333566603633, 0.9560697355546188, 0.9562460787155667, 0.956187184427917, 0.9562976019560762, 0.9562012644435032, 0.9564358137653879, 0.9564094885775521, 0.9564460047669975, 0.9565315267909983, 0.9566062302229991, 0.9565417792638541, 0.9566311486782406, 0.9566629315038099, 0.9568434414517665, 0.9567826961933427, 0.9568947231929927, 0.9569402424755857, 0.9569829229299335], 'mDice': [0.2514984937435752, 0.5802064360269086, 0.6321252602409235, 0.6546231980002022, 0.669675110972049, 0.6812177617223582, 0.6889636269822553, 0.6968184625795351, 0.7028362227806786, 0.707368278742343, 0.7122501961273745, 0.7146005363845077, 0.719712212129094, 0.7229749317146076, 0.7239448812381744, 0.7282043719407254, 0.7319594668923922, 0.734414126026261, 0.7368784280204025, 0.7380253181894596, 0.7403057367088397, 0.7420653560427655, 0.7423890916767881, 0.7447089482662653, 0.7466114708024376, 0.7472333087620409, 0.7492342759247381, 0.7514213567225217, 0.7529441818524326, 0.7533360196285717, 0.7549157260803153, 0.7547361785683404, 0.7535390020338748, 0.7575108419802901, 0.7587809418873631, 0.7591199291069896, 0.7612304853319142, 0.761455176410433, 0.7616842829397473, 0.7634670584687844, 0.765063417190937, 0.7650947615566756, 0.765892090315549, 0.7662452827234374, 0.767078449163722, 0.7665301748989624, 0.7683588640926567, 0.7691439167423891, 0.7690664333855948, 0.769642234085549, 0.7722160816127702, 0.7719224956967811, 0.7718726496156034, 0.7707573275350289, 0.7741501781066696, 0.7741563463774611, 0.7743892424519913, 0.774485518003132, 0.775951034223116, 0.7746762921364633, 0.7770916678781999, 0.7758053902362753, 0.7774102487833396, 0.7773243662844971, 0.7780401555484601, 0.7783893094389509, 0.7788858028234957]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.50s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.25s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.03s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:04,  1.92s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:29,  1.80s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:35,  1.83s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:15,  1.76s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:32,  1.83s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:08,  1.75s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:19,  1.80s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:17,  1.80s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:54,  1.94s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:11,  2.00s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:50,  1.94s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:08,  2.01s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:41,  1.92s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:47,  1.95s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:07,  2.03s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:14,  2.06s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:47,  1.97s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:48,  1.98s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:24,  1.90s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:26,  1.91s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:51,  2.01s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:24,  1.92s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:36,  1.97s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:23,  1.93s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:36,  1.99s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:57,  2.08s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:26,  1.96s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:27,  1.97s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:23,  1.97s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:47,  2.07s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:48,  2.08s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:16,  1.96s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:14,  1.96s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:20,  2.00s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:35,  2.06s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<08:02,  1.94s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<08:10,  1.98s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<08:21,  2.03s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:03,  1.96s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:05,  1.98s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:48,  1.92s/it]predicting train subjects:  15%|█▍        | 42/285 [01:21<07:31,  1.86s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:34,  1.88s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:48,  1.95s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:33,  1.89s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:55,  1.99s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:36,  1.92s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<07:36,  1.93s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<07:47,  1.98s/it]predicting train subjects:  18%|█▊        | 50/285 [01:37<07:37,  1.95s/it]predicting train subjects:  18%|█▊        | 51/285 [01:39<07:44,  1.99s/it]predicting train subjects:  18%|█▊        | 52/285 [01:40<07:19,  1.88s/it]predicting train subjects:  19%|█▊        | 53/285 [01:42<07:27,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:45<07:44,  2.01s/it]predicting train subjects:  19%|█▉        | 55/285 [01:46<07:19,  1.91s/it]predicting train subjects:  20%|█▉        | 56/285 [01:48<07:08,  1.87s/it]predicting train subjects:  20%|██        | 57/285 [01:50<06:51,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [01:52<06:49,  1.81s/it]predicting train subjects:  21%|██        | 59/285 [01:54<07:02,  1.87s/it]predicting train subjects:  21%|██        | 60/285 [01:56<07:50,  2.09s/it]predicting train subjects:  21%|██▏       | 61/285 [01:59<08:05,  2.17s/it]predicting train subjects:  22%|██▏       | 62/285 [02:01<08:30,  2.29s/it]predicting train subjects:  22%|██▏       | 63/285 [02:03<08:29,  2.29s/it]predicting train subjects:  22%|██▏       | 64/285 [02:06<08:32,  2.32s/it]predicting train subjects:  23%|██▎       | 65/285 [02:08<08:45,  2.39s/it]predicting train subjects:  23%|██▎       | 66/285 [02:11<08:43,  2.39s/it]predicting train subjects:  24%|██▎       | 67/285 [02:13<08:23,  2.31s/it]predicting train subjects:  24%|██▍       | 68/285 [02:15<08:02,  2.22s/it]predicting train subjects:  24%|██▍       | 69/285 [02:17<08:05,  2.25s/it]predicting train subjects:  25%|██▍       | 70/285 [02:19<08:01,  2.24s/it]predicting train subjects:  25%|██▍       | 71/285 [02:22<07:59,  2.24s/it]predicting train subjects:  25%|██▌       | 72/285 [02:24<07:51,  2.21s/it]predicting train subjects:  26%|██▌       | 73/285 [02:27<08:43,  2.47s/it]predicting train subjects:  26%|██▌       | 74/285 [02:29<08:40,  2.47s/it]predicting train subjects:  26%|██▋       | 75/285 [02:32<08:47,  2.51s/it]predicting train subjects:  27%|██▋       | 76/285 [02:34<08:30,  2.44s/it]predicting train subjects:  27%|██▋       | 77/285 [02:36<08:06,  2.34s/it]predicting train subjects:  27%|██▋       | 78/285 [02:38<07:49,  2.27s/it]predicting train subjects:  28%|██▊       | 79/285 [02:41<07:39,  2.23s/it]predicting train subjects:  28%|██▊       | 80/285 [02:43<07:48,  2.29s/it]predicting train subjects:  28%|██▊       | 81/285 [02:45<07:38,  2.25s/it]predicting train subjects:  29%|██▉       | 82/285 [02:47<07:33,  2.24s/it]predicting train subjects:  29%|██▉       | 83/285 [02:49<07:07,  2.11s/it]predicting train subjects:  29%|██▉       | 84/285 [02:51<07:13,  2.16s/it]predicting train subjects:  30%|██▉       | 85/285 [02:54<07:09,  2.15s/it]predicting train subjects:  30%|███       | 86/285 [02:56<07:31,  2.27s/it]predicting train subjects:  31%|███       | 87/285 [02:58<07:34,  2.30s/it]predicting train subjects:  31%|███       | 88/285 [03:01<07:31,  2.29s/it]predicting train subjects:  31%|███       | 89/285 [03:03<07:30,  2.30s/it]predicting train subjects:  32%|███▏      | 90/285 [03:06<07:40,  2.36s/it]predicting train subjects:  32%|███▏      | 91/285 [03:08<07:35,  2.35s/it]predicting train subjects:  32%|███▏      | 92/285 [03:10<07:31,  2.34s/it]predicting train subjects:  33%|███▎      | 93/285 [03:12<07:24,  2.31s/it]predicting train subjects:  33%|███▎      | 94/285 [03:15<07:16,  2.28s/it]predicting train subjects:  33%|███▎      | 95/285 [03:17<07:37,  2.41s/it]predicting train subjects:  34%|███▎      | 96/285 [03:20<07:35,  2.41s/it]predicting train subjects:  34%|███▍      | 97/285 [03:22<07:27,  2.38s/it]predicting train subjects:  34%|███▍      | 98/285 [03:24<07:15,  2.33s/it]predicting train subjects:  35%|███▍      | 99/285 [03:27<07:05,  2.29s/it]predicting train subjects:  35%|███▌      | 100/285 [03:29<07:07,  2.31s/it]predicting train subjects:  35%|███▌      | 101/285 [03:31<07:09,  2.33s/it]predicting train subjects:  36%|███▌      | 102/285 [03:34<07:05,  2.33s/it]predicting train subjects:  36%|███▌      | 103/285 [03:36<06:54,  2.28s/it]predicting train subjects:  36%|███▋      | 104/285 [03:38<07:04,  2.34s/it]predicting train subjects:  37%|███▋      | 105/285 [03:41<07:19,  2.44s/it]predicting train subjects:  37%|███▋      | 106/285 [03:43<07:07,  2.39s/it]predicting train subjects:  38%|███▊      | 107/285 [03:45<06:48,  2.29s/it]predicting train subjects:  38%|███▊      | 108/285 [03:47<06:31,  2.21s/it]predicting train subjects:  38%|███▊      | 109/285 [03:50<06:42,  2.28s/it]predicting train subjects:  39%|███▊      | 110/285 [03:52<06:40,  2.29s/it]predicting train subjects:  39%|███▉      | 111/285 [03:54<06:29,  2.24s/it]predicting train subjects:  39%|███▉      | 112/285 [03:57<06:52,  2.38s/it]predicting train subjects:  40%|███▉      | 113/285 [03:59<06:49,  2.38s/it]predicting train subjects:  40%|████      | 114/285 [04:02<06:45,  2.37s/it]predicting train subjects:  40%|████      | 115/285 [04:04<06:41,  2.36s/it]predicting train subjects:  41%|████      | 116/285 [04:06<06:34,  2.33s/it]predicting train subjects:  41%|████      | 117/285 [04:08<06:24,  2.29s/it]predicting train subjects:  41%|████▏     | 118/285 [04:11<06:17,  2.26s/it]predicting train subjects:  42%|████▏     | 119/285 [04:13<06:16,  2.27s/it]predicting train subjects:  42%|████▏     | 120/285 [04:15<06:08,  2.23s/it]predicting train subjects:  42%|████▏     | 121/285 [04:17<06:05,  2.23s/it]predicting train subjects:  43%|████▎     | 122/285 [04:19<05:47,  2.13s/it]predicting train subjects:  43%|████▎     | 123/285 [04:21<05:30,  2.04s/it]predicting train subjects:  44%|████▎     | 124/285 [04:23<05:33,  2.07s/it]predicting train subjects:  44%|████▍     | 125/285 [04:25<05:26,  2.04s/it]predicting train subjects:  44%|████▍     | 126/285 [04:27<05:25,  2.05s/it]predicting train subjects:  45%|████▍     | 127/285 [04:29<05:15,  1.99s/it]predicting train subjects:  45%|████▍     | 128/285 [04:31<05:14,  2.00s/it]predicting train subjects:  45%|████▌     | 129/285 [04:33<05:15,  2.02s/it]predicting train subjects:  46%|████▌     | 130/285 [04:36<05:30,  2.13s/it]predicting train subjects:  46%|████▌     | 131/285 [04:37<05:12,  2.03s/it]predicting train subjects:  46%|████▋     | 132/285 [04:39<05:06,  2.00s/it]predicting train subjects:  47%|████▋     | 133/285 [04:41<05:02,  1.99s/it]predicting train subjects:  47%|████▋     | 134/285 [04:43<05:02,  2.00s/it]predicting train subjects:  47%|████▋     | 135/285 [04:45<04:51,  1.94s/it]predicting train subjects:  48%|████▊     | 136/285 [04:47<04:52,  1.96s/it]predicting train subjects:  48%|████▊     | 137/285 [04:49<04:51,  1.97s/it]predicting train subjects:  48%|████▊     | 138/285 [04:51<04:47,  1.96s/it]predicting train subjects:  49%|████▉     | 139/285 [04:53<04:42,  1.94s/it]predicting train subjects:  49%|████▉     | 140/285 [04:55<04:51,  2.01s/it]predicting train subjects:  49%|████▉     | 141/285 [04:57<04:44,  1.98s/it]predicting train subjects:  50%|████▉     | 142/285 [04:59<04:44,  1.99s/it]predicting train subjects:  50%|█████     | 143/285 [05:01<04:40,  1.98s/it]predicting train subjects:  51%|█████     | 144/285 [05:03<04:38,  1.98s/it]predicting train subjects:  51%|█████     | 145/285 [05:05<04:36,  1.97s/it]predicting train subjects:  51%|█████     | 146/285 [05:07<04:38,  2.00s/it]predicting train subjects:  52%|█████▏    | 147/285 [05:09<04:30,  1.96s/it]predicting train subjects:  52%|█████▏    | 148/285 [05:11<04:32,  1.99s/it]predicting train subjects:  52%|█████▏    | 149/285 [05:13<04:37,  2.04s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:15<04:33,  2.02s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:17<04:40,  2.09s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:19<04:40,  2.11s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:21<04:28,  2.04s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:23<04:23,  2.01s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:25<04:19,  1.99s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:27<04:15,  1.98s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:29<04:09,  1.95s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:31<04:04,  1.92s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:33<04:01,  1.92s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:35<04:01,  1.93s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:37<04:07,  1.99s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:39<04:05,  2.00s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:41<04:06,  2.02s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:43<03:55,  1.94s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:44<03:42,  1.85s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:46<03:41,  1.87s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:48<03:51,  1.96s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:50<03:51,  1.98s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:52<03:43,  1.92s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:54<03:38,  1.90s/it]predicting train subjects:  60%|██████    | 171/285 [05:56<03:36,  1.90s/it]predicting train subjects:  60%|██████    | 172/285 [05:58<03:33,  1.89s/it]predicting train subjects:  61%|██████    | 173/285 [06:00<03:36,  1.94s/it]predicting train subjects:  61%|██████    | 174/285 [06:02<03:35,  1.94s/it]predicting train subjects:  61%|██████▏   | 175/285 [06:04<03:35,  1.96s/it]predicting train subjects:  62%|██████▏   | 176/285 [06:06<03:43,  2.05s/it]predicting train subjects:  62%|██████▏   | 177/285 [06:08<03:39,  2.03s/it]predicting train subjects:  62%|██████▏   | 178/285 [06:10<03:26,  1.93s/it]predicting train subjects:  63%|██████▎   | 179/285 [06:12<03:22,  1.91s/it]predicting train subjects:  63%|██████▎   | 180/285 [06:14<03:32,  2.02s/it]predicting train subjects:  64%|██████▎   | 181/285 [06:16<03:35,  2.07s/it]predicting train subjects:  64%|██████▍   | 182/285 [06:18<03:34,  2.08s/it]predicting train subjects:  64%|██████▍   | 183/285 [06:20<03:29,  2.05s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:22<03:24,  2.02s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:24<03:18,  1.98s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:26<03:29,  2.12s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:29<03:34,  2.19s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:31<03:34,  2.22s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:33<03:21,  2.10s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:35<03:12,  2.02s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:37<03:06,  1.99s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:39<03:16,  2.11s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:41<03:08,  2.04s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:43<03:03,  2.02s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:45<02:55,  1.95s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:47<03:05,  2.08s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:49<03:10,  2.17s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:52<03:06,  2.14s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:53<02:57,  2.06s/it]predicting train subjects:  70%|███████   | 200/285 [06:55<02:47,  1.97s/it]predicting train subjects:  71%|███████   | 201/285 [06:57<02:42,  1.93s/it]predicting train subjects:  71%|███████   | 202/285 [06:59<02:35,  1.87s/it]predicting train subjects:  71%|███████   | 203/285 [07:00<02:29,  1.83s/it]predicting train subjects:  72%|███████▏  | 204/285 [07:02<02:18,  1.71s/it]predicting train subjects:  72%|███████▏  | 205/285 [07:03<02:12,  1.65s/it]predicting train subjects:  72%|███████▏  | 206/285 [07:05<02:03,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [07:07<02:10,  1.67s/it]predicting train subjects:  73%|███████▎  | 208/285 [07:09<02:14,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [07:10<02:15,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [07:12<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [07:13<02:00,  1.63s/it]predicting train subjects:  74%|███████▍  | 212/285 [07:15<02:01,  1.66s/it]predicting train subjects:  75%|███████▍  | 213/285 [07:17<02:01,  1.68s/it]predicting train subjects:  75%|███████▌  | 214/285 [07:18<01:54,  1.62s/it]predicting train subjects:  75%|███████▌  | 215/285 [07:20<01:55,  1.65s/it]predicting train subjects:  76%|███████▌  | 216/285 [07:22<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:23<01:51,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:25<01:55,  1.72s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:27<01:56,  1.77s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:29<01:49,  1.68s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:30<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:32<01:43,  1.64s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:33<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:35<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:36<01:32,  1.55s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:38<01:38,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:40<01:40,  1.74s/it]predicting train subjects:  80%|████████  | 228/285 [07:42<01:43,  1.81s/it]predicting train subjects:  80%|████████  | 229/285 [07:44<01:39,  1.78s/it]predicting train subjects:  81%|████████  | 230/285 [07:45<01:32,  1.69s/it]predicting train subjects:  81%|████████  | 231/285 [07:47<01:28,  1.64s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:49<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:50<01:23,  1.61s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:52<01:25,  1.67s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:53<01:19,  1.58s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:55<01:22,  1.69s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:57<01:23,  1.74s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:59<01:22,  1.76s/it]predicting train subjects:  84%|████████▍ | 239/285 [08:00<01:20,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [08:02<01:14,  1.66s/it]predicting train subjects:  85%|████████▍ | 241/285 [08:03<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [08:05<01:07,  1.57s/it]predicting train subjects:  85%|████████▌ | 243/285 [08:06<01:04,  1.54s/it]predicting train subjects:  86%|████████▌ | 244/285 [08:08<01:05,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [08:10<01:01,  1.55s/it]predicting train subjects:  86%|████████▋ | 246/285 [08:12<01:04,  1.67s/it]predicting train subjects:  87%|████████▋ | 247/285 [08:13<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [08:15<01:03,  1.71s/it]predicting train subjects:  87%|████████▋ | 249/285 [08:17<00:59,  1.65s/it]predicting train subjects:  88%|████████▊ | 250/285 [08:18<00:56,  1.61s/it]predicting train subjects:  88%|████████▊ | 251/285 [08:19<00:52,  1.55s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:21<00:50,  1.52s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:23<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:25<00:53,  1.73s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:27<00:52,  1.74s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:28<00:48,  1.67s/it]predicting train subjects:  90%|█████████ | 257/285 [08:30<00:45,  1.64s/it]predicting train subjects:  91%|█████████ | 258/285 [08:31<00:45,  1.68s/it]predicting train subjects:  91%|█████████ | 259/285 [08:33<00:43,  1.69s/it]predicting train subjects:  91%|█████████ | 260/285 [08:35<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:36<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:38<00:36,  1.59s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:39<00:34,  1.55s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:41<00:35,  1.68s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:43<00:35,  1.77s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:45<00:32,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:46<00:29,  1.66s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:48<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:50<00:27,  1.75s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:51<00:24,  1.66s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:53<00:22,  1.63s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:55<00:21,  1.68s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:56<00:19,  1.61s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:58<00:17,  1.56s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:59<00:16,  1.64s/it]predicting train subjects:  97%|█████████▋| 276/285 [09:01<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [09:03<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [09:04<00:11,  1.61s/it]predicting train subjects:  98%|█████████▊| 279/285 [09:06<00:09,  1.65s/it]predicting train subjects:  98%|█████████▊| 280/285 [09:08<00:08,  1.60s/it]predicting train subjects:  99%|█████████▊| 281/285 [09:09<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [09:11<00:04,  1.54s/it]predicting train subjects:  99%|█████████▉| 283/285 [09:12<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:14<00:01,  1.77s/it]predicting train subjects: 100%|██████████| 285/285 [09:16<00:00,  1.83s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:45,  1.85s/it]Loading train:   1%|          | 2/285 [00:03<07:53,  1.67s/it]Loading train:   1%|          | 3/285 [00:04<07:27,  1.59s/it]Loading train:   1%|▏         | 4/285 [00:05<07:02,  1.50s/it]Loading train:   2%|▏         | 5/285 [00:07<07:11,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:08<06:48,  1.47s/it]Loading train:   2%|▏         | 7/285 [00:10<06:52,  1.48s/it]Loading train:   3%|▎         | 8/285 [00:11<06:43,  1.46s/it]Loading train:   3%|▎         | 9/285 [00:13<07:02,  1.53s/it]Loading train:   4%|▎         | 10/285 [00:14<06:21,  1.39s/it]Loading train:   4%|▍         | 11/285 [00:15<05:28,  1.20s/it]Loading train:   4%|▍         | 12/285 [00:16<05:06,  1.12s/it]Loading train:   5%|▍         | 13/285 [00:16<04:44,  1.05s/it]Loading train:   5%|▍         | 14/285 [00:17<04:40,  1.04s/it]Loading train:   5%|▌         | 15/285 [00:19<04:47,  1.07s/it]Loading train:   6%|▌         | 16/285 [00:20<04:37,  1.03s/it]Loading train:   6%|▌         | 17/285 [00:21<04:34,  1.03s/it]Loading train:   6%|▋         | 18/285 [00:22<04:34,  1.03s/it]Loading train:   7%|▋         | 19/285 [00:23<04:37,  1.04s/it]Loading train:   7%|▋         | 20/285 [00:24<04:36,  1.04s/it]Loading train:   7%|▋         | 21/285 [00:25<04:40,  1.06s/it]Loading train:   8%|▊         | 22/285 [00:26<04:31,  1.03s/it]Loading train:   8%|▊         | 23/285 [00:27<04:25,  1.01s/it]Loading train:   8%|▊         | 24/285 [00:28<04:25,  1.02s/it]Loading train:   9%|▉         | 25/285 [00:29<04:21,  1.01s/it]Loading train:   9%|▉         | 26/285 [00:30<04:23,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:31<04:10,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:32<04:08,  1.03it/s]Loading train:  10%|█         | 29/285 [00:33<04:14,  1.01it/s]Loading train:  11%|█         | 30/285 [00:34<04:24,  1.04s/it]Loading train:  11%|█         | 31/285 [00:35<04:30,  1.07s/it]Loading train:  11%|█         | 32/285 [00:36<04:22,  1.04s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:19,  1.03s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:15,  1.02s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:17,  1.03s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:14,  1.02s/it]Loading train:  13%|█▎        | 37/285 [00:41<04:16,  1.04s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:28,  1.09s/it]Loading train:  14%|█▎        | 39/285 [00:43<04:12,  1.03s/it]Loading train:  14%|█▍        | 40/285 [00:44<04:07,  1.01s/it]Loading train:  14%|█▍        | 41/285 [00:45<04:14,  1.05s/it]Loading train:  15%|█▍        | 42/285 [00:46<03:54,  1.03it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:59,  1.01it/s]Loading train:  15%|█▌        | 44/285 [00:48<04:08,  1.03s/it]Loading train:  16%|█▌        | 45/285 [00:49<04:13,  1.06s/it]Loading train:  16%|█▌        | 46/285 [00:50<04:16,  1.07s/it]Loading train:  16%|█▋        | 47/285 [00:51<04:11,  1.06s/it]Loading train:  17%|█▋        | 48/285 [00:53<04:15,  1.08s/it]Loading train:  17%|█▋        | 49/285 [00:54<04:22,  1.11s/it]Loading train:  18%|█▊        | 50/285 [00:55<04:14,  1.08s/it]Loading train:  18%|█▊        | 51/285 [00:56<04:29,  1.15s/it]Loading train:  18%|█▊        | 52/285 [00:57<04:24,  1.13s/it]Loading train:  19%|█▊        | 53/285 [00:58<04:13,  1.09s/it]Loading train:  19%|█▉        | 54/285 [00:59<04:07,  1.07s/it]Loading train:  19%|█▉        | 55/285 [01:00<03:57,  1.03s/it]Loading train:  20%|█▉        | 56/285 [01:01<03:50,  1.01s/it]Loading train:  20%|██        | 57/285 [01:02<03:47,  1.00it/s]Loading train:  20%|██        | 58/285 [01:03<03:39,  1.03it/s]Loading train:  21%|██        | 59/285 [01:04<03:39,  1.03it/s]Loading train:  21%|██        | 60/285 [01:05<03:44,  1.00it/s]Loading train:  21%|██▏       | 61/285 [01:06<03:37,  1.03it/s]Loading train:  22%|██▏       | 62/285 [01:07<03:47,  1.02s/it]Loading train:  22%|██▏       | 63/285 [01:08<03:49,  1.03s/it]Loading train:  22%|██▏       | 64/285 [01:09<04:08,  1.12s/it]Loading train:  23%|██▎       | 65/285 [01:11<04:33,  1.24s/it]Loading train:  23%|██▎       | 66/285 [01:12<04:40,  1.28s/it]Loading train:  24%|██▎       | 67/285 [01:13<04:22,  1.21s/it]Loading train:  24%|██▍       | 68/285 [01:14<04:02,  1.12s/it]Loading train:  24%|██▍       | 69/285 [01:15<04:04,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:16<03:55,  1.10s/it]Loading train:  25%|██▍       | 71/285 [01:17<03:47,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:18<03:35,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:19<03:33,  1.01s/it]Loading train:  26%|██▌       | 74/285 [01:20<03:39,  1.04s/it]Loading train:  26%|██▋       | 75/285 [01:22<03:41,  1.06s/it]Loading train:  27%|██▋       | 76/285 [01:23<03:46,  1.08s/it]Loading train:  27%|██▋       | 77/285 [01:24<03:41,  1.07s/it]Loading train:  27%|██▋       | 78/285 [01:25<03:28,  1.01s/it]Loading train:  28%|██▊       | 79/285 [01:26<03:31,  1.03s/it]Loading train:  28%|██▊       | 80/285 [01:27<03:22,  1.01it/s]Loading train:  28%|██▊       | 81/285 [01:27<03:04,  1.11it/s]Loading train:  29%|██▉       | 82/285 [01:28<03:03,  1.11it/s]Loading train:  29%|██▉       | 83/285 [01:29<02:56,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:30<02:50,  1.18it/s]Loading train:  30%|██▉       | 85/285 [01:31<03:01,  1.10it/s]Loading train:  30%|███       | 86/285 [01:32<03:12,  1.04it/s]Loading train:  31%|███       | 87/285 [01:33<03:23,  1.03s/it]Loading train:  31%|███       | 88/285 [01:34<03:11,  1.03it/s]Loading train:  31%|███       | 89/285 [01:35<03:26,  1.05s/it]Loading train:  32%|███▏      | 90/285 [01:36<03:22,  1.04s/it]Loading train:  32%|███▏      | 91/285 [01:37<03:09,  1.02it/s]Loading train:  32%|███▏      | 92/285 [01:38<03:14,  1.01s/it]Loading train:  33%|███▎      | 93/285 [01:39<03:11,  1.00it/s]Loading train:  33%|███▎      | 94/285 [01:40<03:14,  1.02s/it]Loading train:  33%|███▎      | 95/285 [01:41<03:20,  1.06s/it]Loading train:  34%|███▎      | 96/285 [01:42<03:20,  1.06s/it]Loading train:  34%|███▍      | 97/285 [01:43<03:14,  1.03s/it]Loading train:  34%|███▍      | 98/285 [01:44<03:12,  1.03s/it]Loading train:  35%|███▍      | 99/285 [01:45<03:11,  1.03s/it]Loading train:  35%|███▌      | 100/285 [01:47<03:22,  1.09s/it]Loading train:  35%|███▌      | 101/285 [01:47<03:08,  1.03s/it]Loading train:  36%|███▌      | 102/285 [01:48<03:06,  1.02s/it]Loading train:  36%|███▌      | 103/285 [01:49<02:55,  1.03it/s]Loading train:  36%|███▋      | 104/285 [01:50<02:56,  1.03it/s]Loading train:  37%|███▋      | 105/285 [01:51<02:55,  1.02it/s]Loading train:  37%|███▋      | 106/285 [01:52<02:53,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:53<02:55,  1.01it/s]Loading train:  38%|███▊      | 108/285 [01:54<02:56,  1.00it/s]Loading train:  38%|███▊      | 109/285 [01:55<03:01,  1.03s/it]Loading train:  39%|███▊      | 110/285 [01:57<03:06,  1.07s/it]Loading train:  39%|███▉      | 111/285 [01:58<03:02,  1.05s/it]Loading train:  39%|███▉      | 112/285 [01:59<03:02,  1.05s/it]Loading train:  40%|███▉      | 113/285 [02:00<02:57,  1.03s/it]Loading train:  40%|████      | 114/285 [02:01<02:56,  1.03s/it]Loading train:  40%|████      | 115/285 [02:02<02:50,  1.00s/it]Loading train:  41%|████      | 116/285 [02:03<02:51,  1.01s/it]Loading train:  41%|████      | 117/285 [02:03<02:42,  1.04it/s]Loading train:  41%|████▏     | 118/285 [02:04<02:36,  1.06it/s]Loading train:  42%|████▏     | 119/285 [02:05<02:37,  1.06it/s]Loading train:  42%|████▏     | 120/285 [02:06<02:41,  1.02it/s]Loading train:  42%|████▏     | 121/285 [02:08<02:58,  1.09s/it]Loading train:  43%|████▎     | 122/285 [02:09<03:04,  1.13s/it]Loading train:  43%|████▎     | 123/285 [02:10<03:19,  1.23s/it]Loading train:  44%|████▎     | 124/285 [02:11<03:01,  1.13s/it]Loading train:  44%|████▍     | 125/285 [02:12<02:50,  1.07s/it]Loading train:  44%|████▍     | 126/285 [02:13<02:39,  1.00s/it]Loading train:  45%|████▍     | 127/285 [02:14<02:29,  1.06it/s]Loading train:  45%|████▍     | 128/285 [02:15<02:31,  1.03it/s]Loading train:  45%|████▌     | 129/285 [02:16<02:26,  1.07it/s]Loading train:  46%|████▌     | 130/285 [02:17<02:33,  1.01it/s]Loading train:  46%|████▌     | 131/285 [02:18<02:30,  1.02it/s]Loading train:  46%|████▋     | 132/285 [02:19<02:32,  1.00it/s]Loading train:  47%|████▋     | 133/285 [02:20<02:28,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:21<02:23,  1.05it/s]Loading train:  47%|████▋     | 135/285 [02:22<02:18,  1.08it/s]Loading train:  48%|████▊     | 136/285 [02:22<02:14,  1.11it/s]Loading train:  48%|████▊     | 137/285 [02:23<02:15,  1.10it/s]Loading train:  48%|████▊     | 138/285 [02:24<02:17,  1.07it/s]Loading train:  49%|████▉     | 139/285 [02:25<02:12,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:26<02:12,  1.09it/s]Loading train:  49%|████▉     | 141/285 [02:27<02:12,  1.09it/s]Loading train:  50%|████▉     | 142/285 [02:28<02:10,  1.09it/s]Loading train:  50%|█████     | 143/285 [02:29<02:03,  1.15it/s]Loading train:  51%|█████     | 144/285 [02:30<02:09,  1.09it/s]Loading train:  51%|█████     | 145/285 [02:31<02:05,  1.12it/s]Loading train:  51%|█████     | 146/285 [02:31<02:05,  1.11it/s]Loading train:  52%|█████▏    | 147/285 [02:32<02:03,  1.11it/s]Loading train:  52%|█████▏    | 148/285 [02:33<02:00,  1.13it/s]Loading train:  52%|█████▏    | 149/285 [02:34<01:57,  1.16it/s]Loading train:  53%|█████▎    | 150/285 [02:35<01:50,  1.22it/s]Loading train:  53%|█████▎    | 151/285 [02:36<01:55,  1.16it/s]Loading train:  53%|█████▎    | 152/285 [02:37<01:58,  1.12it/s]Loading train:  54%|█████▎    | 153/285 [02:38<01:58,  1.11it/s]Loading train:  54%|█████▍    | 154/285 [02:39<02:11,  1.00s/it]Loading train:  54%|█████▍    | 155/285 [02:40<02:07,  1.02it/s]Loading train:  55%|█████▍    | 156/285 [02:41<02:00,  1.07it/s]Loading train:  55%|█████▌    | 157/285 [02:41<01:55,  1.11it/s]Loading train:  55%|█████▌    | 158/285 [02:42<01:52,  1.13it/s]Loading train:  56%|█████▌    | 159/285 [02:43<01:50,  1.14it/s]Loading train:  56%|█████▌    | 160/285 [02:44<01:56,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [02:45<01:55,  1.07it/s]Loading train:  57%|█████▋    | 162/285 [02:46<01:53,  1.09it/s]Loading train:  57%|█████▋    | 163/285 [02:47<01:58,  1.03it/s]Loading train:  58%|█████▊    | 164/285 [02:48<02:05,  1.03s/it]Loading train:  58%|█████▊    | 165/285 [02:49<01:58,  1.01it/s]Loading train:  58%|█████▊    | 166/285 [02:50<01:54,  1.04it/s]Loading train:  59%|█████▊    | 167/285 [02:51<01:52,  1.05it/s]Loading train:  59%|█████▉    | 168/285 [02:52<01:49,  1.07it/s]Loading train:  59%|█████▉    | 169/285 [02:53<01:44,  1.11it/s]Loading train:  60%|█████▉    | 170/285 [02:54<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [02:54<01:40,  1.14it/s]Loading train:  60%|██████    | 172/285 [02:55<01:43,  1.09it/s]Loading train:  61%|██████    | 173/285 [02:56<01:40,  1.12it/s]Loading train:  61%|██████    | 174/285 [02:57<01:44,  1.06it/s]Loading train:  61%|██████▏   | 175/285 [02:58<01:43,  1.06it/s]Loading train:  62%|██████▏   | 176/285 [02:59<01:42,  1.06it/s]Loading train:  62%|██████▏   | 177/285 [03:00<01:37,  1.10it/s]Loading train:  62%|██████▏   | 178/285 [03:01<01:33,  1.14it/s]Loading train:  63%|██████▎   | 179/285 [03:02<01:37,  1.09it/s]Loading train:  63%|██████▎   | 180/285 [03:03<01:46,  1.02s/it]Loading train:  64%|██████▎   | 181/285 [03:04<01:45,  1.01s/it]Loading train:  64%|██████▍   | 182/285 [03:05<01:38,  1.04it/s]Loading train:  64%|██████▍   | 183/285 [03:06<01:38,  1.04it/s]Loading train:  65%|██████▍   | 184/285 [03:07<01:33,  1.08it/s]Loading train:  65%|██████▍   | 185/285 [03:08<01:27,  1.14it/s]Loading train:  65%|██████▌   | 186/285 [03:09<01:29,  1.10it/s]Loading train:  66%|██████▌   | 187/285 [03:10<01:36,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:11<01:33,  1.04it/s]Loading train:  66%|██████▋   | 189/285 [03:11<01:28,  1.09it/s]Loading train:  67%|██████▋   | 190/285 [03:12<01:25,  1.12it/s]Loading train:  67%|██████▋   | 191/285 [03:13<01:23,  1.12it/s]Loading train:  67%|██████▋   | 192/285 [03:14<01:19,  1.17it/s]Loading train:  68%|██████▊   | 193/285 [03:15<01:15,  1.22it/s]Loading train:  68%|██████▊   | 194/285 [03:15<01:14,  1.22it/s]Loading train:  68%|██████▊   | 195/285 [03:16<01:12,  1.24it/s]Loading train:  69%|██████▉   | 196/285 [03:17<01:17,  1.15it/s]Loading train:  69%|██████▉   | 197/285 [03:18<01:18,  1.11it/s]Loading train:  69%|██████▉   | 198/285 [03:19<01:20,  1.08it/s]Loading train:  70%|██████▉   | 199/285 [03:20<01:15,  1.14it/s]Loading train:  70%|███████   | 200/285 [03:21<01:11,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:22<01:18,  1.07it/s]Loading train:  71%|███████   | 202/285 [03:23<01:13,  1.13it/s]Loading train:  71%|███████   | 203/285 [03:23<01:10,  1.16it/s]Loading train:  72%|███████▏  | 204/285 [03:24<01:10,  1.16it/s]Loading train:  72%|███████▏  | 205/285 [03:25<01:15,  1.06it/s]Loading train:  72%|███████▏  | 206/285 [03:26<01:08,  1.15it/s]Loading train:  73%|███████▎  | 207/285 [03:27<01:13,  1.06it/s]Loading train:  73%|███████▎  | 208/285 [03:28<01:14,  1.03it/s]Loading train:  73%|███████▎  | 209/285 [03:29<01:13,  1.03it/s]Loading train:  74%|███████▎  | 210/285 [03:30<01:09,  1.07it/s]Loading train:  74%|███████▍  | 211/285 [03:31<01:06,  1.12it/s]Loading train:  74%|███████▍  | 212/285 [03:32<01:06,  1.10it/s]Loading train:  75%|███████▍  | 213/285 [03:33<01:04,  1.12it/s]Loading train:  75%|███████▌  | 214/285 [03:33<01:00,  1.18it/s]Loading train:  75%|███████▌  | 215/285 [03:35<01:05,  1.07it/s]Loading train:  76%|███████▌  | 216/285 [03:35<01:00,  1.14it/s]Loading train:  76%|███████▌  | 217/285 [03:36<01:01,  1.10it/s]Loading train:  76%|███████▋  | 218/285 [03:37<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [03:38<01:03,  1.04it/s]Loading train:  77%|███████▋  | 220/285 [03:39<00:59,  1.09it/s]Loading train:  78%|███████▊  | 221/285 [03:40<00:55,  1.15it/s]Loading train:  78%|███████▊  | 222/285 [03:41<00:55,  1.13it/s]Loading train:  78%|███████▊  | 223/285 [03:42<00:53,  1.17it/s]Loading train:  79%|███████▊  | 224/285 [03:42<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [03:43<00:51,  1.17it/s]Loading train:  79%|███████▉  | 226/285 [03:44<00:53,  1.10it/s]Loading train:  80%|███████▉  | 227/285 [03:45<00:54,  1.07it/s]Loading train:  80%|████████  | 228/285 [03:46<00:55,  1.04it/s]Loading train:  80%|████████  | 229/285 [03:47<00:53,  1.05it/s]Loading train:  81%|████████  | 230/285 [03:48<00:50,  1.08it/s]Loading train:  81%|████████  | 231/285 [03:49<00:47,  1.13it/s]Loading train:  81%|████████▏ | 232/285 [03:50<00:46,  1.13it/s]Loading train:  82%|████████▏ | 233/285 [03:51<00:45,  1.14it/s]Loading train:  82%|████████▏ | 234/285 [03:52<00:47,  1.08it/s]Loading train:  82%|████████▏ | 235/285 [03:52<00:43,  1.15it/s]Loading train:  83%|████████▎ | 236/285 [03:53<00:43,  1.12it/s]Loading train:  83%|████████▎ | 237/285 [03:54<00:42,  1.12it/s]Loading train:  84%|████████▎ | 238/285 [03:55<00:42,  1.11it/s]Loading train:  84%|████████▍ | 239/285 [03:56<00:40,  1.14it/s]Loading train:  84%|████████▍ | 240/285 [03:57<00:38,  1.16it/s]Loading train:  85%|████████▍ | 241/285 [03:58<00:37,  1.16it/s]Loading train:  85%|████████▍ | 242/285 [03:59<00:36,  1.19it/s]Loading train:  85%|████████▌ | 243/285 [03:59<00:36,  1.16it/s]Loading train:  86%|████████▌ | 244/285 [04:00<00:36,  1.11it/s]Loading train:  86%|████████▌ | 245/285 [04:01<00:35,  1.12it/s]Loading train:  86%|████████▋ | 246/285 [04:02<00:36,  1.08it/s]Loading train:  87%|████████▋ | 247/285 [04:03<00:36,  1.04it/s]Loading train:  87%|████████▋ | 248/285 [04:04<00:34,  1.06it/s]Loading train:  87%|████████▋ | 249/285 [04:05<00:32,  1.12it/s]Loading train:  88%|████████▊ | 250/285 [04:06<00:30,  1.13it/s]Loading train:  88%|████████▊ | 251/285 [04:07<00:29,  1.16it/s]Loading train:  88%|████████▊ | 252/285 [04:08<00:28,  1.16it/s]Loading train:  89%|████████▉ | 253/285 [04:09<00:30,  1.04it/s]Loading train:  89%|████████▉ | 254/285 [04:10<00:30,  1.03it/s]Loading train:  89%|████████▉ | 255/285 [04:11<00:29,  1.03it/s]Loading train:  90%|████████▉ | 256/285 [04:12<00:27,  1.05it/s]Loading train:  90%|█████████ | 257/285 [04:13<00:26,  1.07it/s]Loading train:  91%|█████████ | 258/285 [04:14<00:26,  1.01it/s]Loading train:  91%|█████████ | 259/285 [04:15<00:25,  1.02it/s]Loading train:  91%|█████████ | 260/285 [04:15<00:23,  1.08it/s]Loading train:  92%|█████████▏| 261/285 [04:16<00:21,  1.14it/s]Loading train:  92%|█████████▏| 262/285 [04:17<00:19,  1.20it/s]Loading train:  92%|█████████▏| 263/285 [04:18<00:18,  1.20it/s]Loading train:  93%|█████████▎| 264/285 [04:19<00:18,  1.12it/s]Loading train:  93%|█████████▎| 265/285 [04:20<00:18,  1.06it/s]Loading train:  93%|█████████▎| 266/285 [04:21<00:17,  1.08it/s]Loading train:  94%|█████████▎| 267/285 [04:22<00:16,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [04:23<00:16,  1.04it/s]Loading train:  94%|█████████▍| 269/285 [04:24<00:15,  1.04it/s]Loading train:  95%|█████████▍| 270/285 [04:24<00:13,  1.09it/s]Loading train:  95%|█████████▌| 271/285 [04:25<00:12,  1.15it/s]Loading train:  95%|█████████▌| 272/285 [04:26<00:11,  1.13it/s]Loading train:  96%|█████████▌| 273/285 [04:27<00:10,  1.17it/s]Loading train:  96%|█████████▌| 274/285 [04:28<00:09,  1.18it/s]Loading train:  96%|█████████▋| 275/285 [04:29<00:09,  1.10it/s]Loading train:  97%|█████████▋| 276/285 [04:30<00:08,  1.04it/s]Loading train:  97%|█████████▋| 277/285 [04:31<00:07,  1.09it/s]Loading train:  98%|█████████▊| 278/285 [04:32<00:06,  1.10it/s]Loading train:  98%|█████████▊| 279/285 [04:33<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:33<00:04,  1.18it/s]Loading train:  99%|█████████▊| 281/285 [04:34<00:03,  1.20it/s]Loading train:  99%|█████████▉| 282/285 [04:35<00:02,  1.20it/s]Loading train:  99%|█████████▉| 283/285 [04:36<00:01,  1.09it/s]Loading train: 100%|█████████▉| 284/285 [04:37<00:00,  1.13it/s]Loading train: 100%|██████████| 285/285 [04:38<00:00,  1.07it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 119.11it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:02, 124.18it/s]concatenating: train:  21%|██▏       | 61/285 [00:00<00:01, 153.40it/s]concatenating: train:  34%|███▍      | 97/285 [00:00<00:01, 185.10it/s]concatenating: train:  46%|████▌     | 131/285 [00:00<00:00, 213.26it/s]concatenating: train:  55%|█████▍    | 156/285 [00:00<00:00, 211.74it/s]concatenating: train:  64%|██████▍   | 182/285 [00:00<00:00, 223.81it/s]concatenating: train:  75%|███████▌  | 215/285 [00:00<00:00, 246.63it/s]concatenating: train:  88%|████████▊ | 251/285 [00:00<00:00, 271.87it/s]concatenating: train:  99%|█████████▉| 283/285 [00:01<00:00, 284.33it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 274.62it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.24s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 375.62it/s]2019-07-11 00:10:11.760265: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:10:11.760385: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:10:11.760400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:10:11.760409: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:10:11.760831: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.01it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.96it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.65it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.29it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.52it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  7.45it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:04,  6.52it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.43it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.47it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.10it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.04it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.52it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.77it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:00,  9.49it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.69it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.87it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.31it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.62it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 237,903
Trainable params: 63,103
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 16s - loss: 2.6861 - acc: 0.6052 - mDice: 0.1188 - val_loss: 2.1705 - val_acc: 0.9074 - val_mDice: 0.2089

Epoch 00001: val_mDice improved from -inf to 0.20885, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.8877 - acc: 0.8853 - mDice: 0.4074 - val_loss: 0.9628 - val_acc: 0.9151 - val_mDice: 0.4913

Epoch 00002: val_mDice improved from 0.20885 to 0.49132, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6285 - acc: 0.8908 - mDice: 0.5220 - val_loss: 0.8333 - val_acc: 0.9182 - val_mDice: 0.5416

Epoch 00003: val_mDice improved from 0.49132 to 0.54158, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5239 - acc: 0.8956 - mDice: 0.5779 - val_loss: 0.8002 - val_acc: 0.9244 - val_mDice: 0.5581

Epoch 00004: val_mDice improved from 0.54158 to 0.55810, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.4761 - acc: 0.9004 - mDice: 0.6072 - val_loss: 0.7995 - val_acc: 0.9266 - val_mDice: 0.5508

Epoch 00005: val_mDice did not improve from 0.55810
Epoch 6/300
 - 11s - loss: 0.4505 - acc: 0.9056 - mDice: 0.6237 - val_loss: 0.7486 - val_acc: 0.9294 - val_mDice: 0.5713

Epoch 00006: val_mDice improved from 0.55810 to 0.57132, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4298 - acc: 0.9123 - mDice: 0.6370 - val_loss: 0.7325 - val_acc: 0.9375 - val_mDice: 0.5847

Epoch 00007: val_mDice improved from 0.57132 to 0.58466, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.4176 - acc: 0.9194 - mDice: 0.6448 - val_loss: 0.7450 - val_acc: 0.9417 - val_mDice: 0.5864

Epoch 00008: val_mDice improved from 0.58466 to 0.58635, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4065 - acc: 0.9268 - mDice: 0.6522 - val_loss: 0.7372 - val_acc: 0.9426 - val_mDice: 0.5769

Epoch 00009: val_mDice did not improve from 0.58635
Epoch 10/300
 - 11s - loss: 0.3964 - acc: 0.9326 - mDice: 0.6586 - val_loss: 0.7624 - val_acc: 0.9432 - val_mDice: 0.5809

Epoch 00010: val_mDice did not improve from 0.58635
Epoch 11/300
 - 11s - loss: 0.3856 - acc: 0.9359 - mDice: 0.6658 - val_loss: 0.7672 - val_acc: 0.9402 - val_mDice: 0.5816

Epoch 00011: val_mDice did not improve from 0.58635
Epoch 12/300
 - 11s - loss: 0.3781 - acc: 0.9376 - mDice: 0.6708 - val_loss: 0.7590 - val_acc: 0.9410 - val_mDice: 0.5791

Epoch 00012: val_mDice did not improve from 0.58635
Epoch 13/300
 - 11s - loss: 0.3703 - acc: 0.9387 - mDice: 0.6760 - val_loss: 0.7417 - val_acc: 0.9407 - val_mDice: 0.5911

Epoch 00013: val_mDice improved from 0.58635 to 0.59113, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 11s - loss: 0.3640 - acc: 0.9395 - mDice: 0.6803 - val_loss: 0.7465 - val_acc: 0.9409 - val_mDice: 0.5788

Epoch 00014: val_mDice did not improve from 0.59113
Epoch 15/300
 - 11s - loss: 0.3575 - acc: 0.9401 - mDice: 0.6848 - val_loss: 0.7343 - val_acc: 0.9403 - val_mDice: 0.5926

Epoch 00015: val_mDice improved from 0.59113 to 0.59260, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 11s - loss: 0.3544 - acc: 0.9404 - mDice: 0.6871 - val_loss: 0.7606 - val_acc: 0.9410 - val_mDice: 0.5712

Epoch 00016: val_mDice did not improve from 0.59260
Epoch 17/300
 - 11s - loss: 0.3520 - acc: 0.9407 - mDice: 0.6888 - val_loss: 0.7679 - val_acc: 0.9433 - val_mDice: 0.5824

Epoch 00017: val_mDice did not improve from 0.59260
Epoch 18/300
 - 11s - loss: 0.3463 - acc: 0.9412 - mDice: 0.6928 - val_loss: 0.7800 - val_acc: 0.9409 - val_mDice: 0.5733

Epoch 00018: val_mDice did not improve from 0.59260
Epoch 19/300
 - 11s - loss: 0.3423 - acc: 0.9416 - mDice: 0.6957 - val_loss: 0.7408 - val_acc: 0.9381 - val_mDice: 0.5893

Epoch 00019: val_mDice did not improve from 0.59260
Epoch 20/300
 - 11s - loss: 0.3380 - acc: 0.9420 - mDice: 0.6987 - val_loss: 0.7325 - val_acc: 0.9417 - val_mDice: 0.5942

Epoch 00020: val_mDice improved from 0.59260 to 0.59415, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 11s - loss: 0.3335 - acc: 0.9423 - mDice: 0.7020 - val_loss: 0.7516 - val_acc: 0.9394 - val_mDice: 0.5862

Epoch 00021: val_mDice did not improve from 0.59415
Epoch 22/300
 - 11s - loss: 0.3318 - acc: 0.9424 - mDice: 0.7033 - val_loss: 0.7442 - val_acc: 0.9408 - val_mDice: 0.5823

Epoch 00022: val_mDice did not improve from 0.59415
Epoch 23/300
 - 11s - loss: 0.3302 - acc: 0.9427 - mDice: 0.7045 - val_loss: 0.7350 - val_acc: 0.9426 - val_mDice: 0.5942

Epoch 00023: val_mDice did not improve from 0.59415
Epoch 24/300
 - 11s - loss: 0.3255 - acc: 0.9431 - mDice: 0.7078 - val_loss: 0.7281 - val_acc: 0.9399 - val_mDice: 0.5923

Epoch 00024: val_mDice did not improve from 0.59415
Epoch 25/300
 - 11s - loss: 0.3248 - acc: 0.9431 - mDice: 0.7085 - val_loss: 0.7352 - val_acc: 0.9378 - val_mDice: 0.5899

Epoch 00025: val_mDice did not improve from 0.59415
Epoch 26/300
 - 11s - loss: 0.3222 - acc: 0.9434 - mDice: 0.7104 - val_loss: 0.7460 - val_acc: 0.9413 - val_mDice: 0.5834

Epoch 00026: val_mDice did not improve from 0.59415
Epoch 27/300
 - 11s - loss: 0.3182 - acc: 0.9438 - mDice: 0.7133 - val_loss: 0.7420 - val_acc: 0.9400 - val_mDice: 0.5840

Epoch 00027: val_mDice did not improve from 0.59415
Epoch 28/300
 - 11s - loss: 0.3183 - acc: 0.9436 - mDice: 0.7132 - val_loss: 0.7592 - val_acc: 0.9429 - val_mDice: 0.5745

Epoch 00028: val_mDice did not improve from 0.59415
Epoch 29/300
 - 11s - loss: 0.3150 - acc: 0.9439 - mDice: 0.7157 - val_loss: 0.7301 - val_acc: 0.9383 - val_mDice: 0.5876

Epoch 00029: val_mDice did not improve from 0.59415
Epoch 30/300
 - 11s - loss: 0.3129 - acc: 0.9441 - mDice: 0.7172 - val_loss: 0.7109 - val_acc: 0.9421 - val_mDice: 0.5974

Epoch 00030: val_mDice improved from 0.59415 to 0.59735, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 11s - loss: 0.3097 - acc: 0.9444 - mDice: 0.7195 - val_loss: 0.7139 - val_acc: 0.9424 - val_mDice: 0.5910

Epoch 00031: val_mDice did not improve from 0.59735
Epoch 32/300
 - 11s - loss: 0.3082 - acc: 0.9444 - mDice: 0.7207 - val_loss: 0.7182 - val_acc: 0.9413 - val_mDice: 0.5927

Epoch 00032: val_mDice did not improve from 0.59735
Epoch 33/300
 - 11s - loss: 0.3086 - acc: 0.9445 - mDice: 0.7205 - val_loss: 0.7185 - val_acc: 0.9411 - val_mDice: 0.5909

Epoch 00033: val_mDice did not improve from 0.59735
Epoch 34/300
 - 11s - loss: 0.3076 - acc: 0.9445 - mDice: 0.7212 - val_loss: 0.7140 - val_acc: 0.9383 - val_mDice: 0.5839

Epoch 00034: val_mDice did not improve from 0.59735
Epoch 35/300
 - 11s - loss: 0.3036 - acc: 0.9448 - mDice: 0.7242 - val_loss: 0.7245 - val_acc: 0.9413 - val_mDice: 0.5799

Epoch 00035: val_mDice did not improve from 0.59735
Epoch 36/300
 - 11s - loss: 0.3037 - acc: 0.9449 - mDice: 0.7241 - val_loss: 0.7067 - val_acc: 0.9403 - val_mDice: 0.5880

Epoch 00036: val_mDice did not improve from 0.59735
Epoch 37/300
 - 11s - loss: 0.3026 - acc: 0.9451 - mDice: 0.7251 - val_loss: 0.6945 - val_acc: 0.9385 - val_mDice: 0.5949

Epoch 00037: val_mDice did not improve from 0.59735
Epoch 38/300
 - 11s - loss: 0.2985 - acc: 0.9453 - mDice: 0.7280 - val_loss: 0.7060 - val_acc: 0.9424 - val_mDice: 0.5858

Epoch 00038: val_mDice did not improve from 0.59735
Epoch 39/300
 - 11s - loss: 0.2981 - acc: 0.9454 - mDice: 0.7284 - val_loss: 0.6940 - val_acc: 0.9445 - val_mDice: 0.5906

Epoch 00039: val_mDice did not improve from 0.59735
Epoch 40/300
 - 11s - loss: 0.2969 - acc: 0.9454 - mDice: 0.7293 - val_loss: 0.7061 - val_acc: 0.9414 - val_mDice: 0.5916

Epoch 00040: val_mDice did not improve from 0.59735
Epoch 41/300
 - 11s - loss: 0.2959 - acc: 0.9455 - mDice: 0.7301 - val_loss: 0.7032 - val_acc: 0.9396 - val_mDice: 0.5891

Epoch 00041: val_mDice did not improve from 0.59735
Epoch 42/300
 - 11s - loss: 0.2930 - acc: 0.9457 - mDice: 0.7322 - val_loss: 0.6990 - val_acc: 0.9410 - val_mDice: 0.5918

Epoch 00042: val_mDice did not improve from 0.59735
Epoch 43/300
 - 11s - loss: 0.2924 - acc: 0.9458 - mDice: 0.7327 - val_loss: 0.6923 - val_acc: 0.9404 - val_mDice: 0.5902

Epoch 00043: val_mDice did not improve from 0.59735
Epoch 44/300
 - 11s - loss: 0.2921 - acc: 0.9459 - mDice: 0.7330 - val_loss: 0.6864 - val_acc: 0.9398 - val_mDice: 0.5914

Epoch 00044: val_mDice did not improve from 0.59735
Epoch 45/300
 - 11s - loss: 0.2910 - acc: 0.9459 - mDice: 0.7338 - val_loss: 0.6841 - val_acc: 0.9399 - val_mDice: 0.5836

Epoch 00045: val_mDice did not improve from 0.59735
Epoch 46/300
 - 11s - loss: 0.2890 - acc: 0.9460 - mDice: 0.7353 - val_loss: 0.6854 - val_acc: 0.9441 - val_mDice: 0.5834

Epoch 00046: val_mDice did not improve from 0.59735
Epoch 47/300
 - 11s - loss: 0.2881 - acc: 0.9461 - mDice: 0.7360 - val_loss: 0.6897 - val_acc: 0.9407 - val_mDice: 0.5836

Epoch 00047: val_mDice did not improve from 0.59735
Epoch 48/300
 - 12s - loss: 0.2869 - acc: 0.9461 - mDice: 0.7369 - val_loss: 0.7074 - val_acc: 0.9403 - val_mDice: 0.5805

Epoch 00048: val_mDice did not improve from 0.59735
Epoch 49/300
 - 13s - loss: 0.2862 - acc: 0.9462 - mDice: 0.7373 - val_loss: 0.6920 - val_acc: 0.9399 - val_mDice: 0.5823

Epoch 00049: val_mDice did not improve from 0.59735
Epoch 50/300
 - 12s - loss: 0.2861 - acc: 0.9461 - mDice: 0.7376 - val_loss: 0.7014 - val_acc: 0.9416 - val_mDice: 0.5807

Epoch 00050: val_mDice did not improve from 0.59735
Epoch 51/300
 - 12s - loss: 0.2834 - acc: 0.9465 - mDice: 0.7397 - val_loss: 0.6983 - val_acc: 0.9324 - val_mDice: 0.5711

Epoch 00051: val_mDice did not improve from 0.59735
Epoch 52/300
 - 13s - loss: 0.2833 - acc: 0.9464 - mDice: 0.7397 - val_loss: 0.6824 - val_acc: 0.9401 - val_mDice: 0.5722

Epoch 00052: val_mDice did not improve from 0.59735
Epoch 53/300
 - 12s - loss: 0.2823 - acc: 0.9465 - mDice: 0.7405 - val_loss: 0.6689 - val_acc: 0.9394 - val_mDice: 0.5887

Epoch 00053: val_mDice did not improve from 0.59735
Epoch 54/300
 - 12s - loss: 0.2809 - acc: 0.9467 - mDice: 0.7415 - val_loss: 0.6575 - val_acc: 0.9408 - val_mDice: 0.5882

Epoch 00054: val_mDice did not improve from 0.59735
Epoch 55/300
 - 13s - loss: 0.2817 - acc: 0.9466 - mDice: 0.7409 - val_loss: 0.6502 - val_acc: 0.9412 - val_mDice: 0.5851

Epoch 00055: val_mDice did not improve from 0.59735
Epoch 56/300
 - 12s - loss: 0.2799 - acc: 0.9468 - mDice: 0.7424 - val_loss: 0.6689 - val_acc: 0.9405 - val_mDice: 0.5854

Epoch 00056: val_mDice did not improve from 0.59735
Epoch 57/300
 - 12s - loss: 0.2793 - acc: 0.9469 - mDice: 0.7428 - val_loss: 0.6506 - val_acc: 0.9409 - val_mDice: 0.5833

Epoch 00057: val_mDice did not improve from 0.59735
Epoch 58/300
 - 13s - loss: 0.2790 - acc: 0.9468 - mDice: 0.7430 - val_loss: 0.6544 - val_acc: 0.9397 - val_mDice: 0.5852

Epoch 00058: val_mDice did not improve from 0.59735
Epoch 59/300
 - 12s - loss: 0.2780 - acc: 0.9469 - mDice: 0.7437 - val_loss: 0.6383 - val_acc: 0.9382 - val_mDice: 0.5872

Epoch 00059: val_mDice did not improve from 0.59735
Epoch 60/300
 - 12s - loss: 0.2768 - acc: 0.9470 - mDice: 0.7447 - val_loss: 0.6577 - val_acc: 0.9432 - val_mDice: 0.5797

Epoch 00060: val_mDice did not improve from 0.59735
Epoch 61/300
 - 12s - loss: 0.2765 - acc: 0.9472 - mDice: 0.7449 - val_loss: 0.6411 - val_acc: 0.9405 - val_mDice: 0.5902

Epoch 00061: val_mDice did not improve from 0.59735
Epoch 62/300
 - 13s - loss: 0.2761 - acc: 0.9472 - mDice: 0.7453 - val_loss: 0.6546 - val_acc: 0.9416 - val_mDice: 0.5796

Epoch 00062: val_mDice did not improve from 0.59735
Epoch 63/300
 - 12s - loss: 0.2737 - acc: 0.9473 - mDice: 0.7471 - val_loss: 0.6403 - val_acc: 0.9396 - val_mDice: 0.5907

Epoch 00063: val_mDice did not improve from 0.59735
Epoch 64/300
 - 12s - loss: 0.2749 - acc: 0.9472 - mDice: 0.7463 - val_loss: 0.6579 - val_acc: 0.9424 - val_mDice: 0.5743

Epoch 00064: val_mDice did not improve from 0.59735
Epoch 65/300
 - 13s - loss: 0.2744 - acc: 0.9474 - mDice: 0.7466 - val_loss: 0.6336 - val_acc: 0.9419 - val_mDice: 0.5900

Epoch 00065: val_mDice did not improve from 0.59735
Epoch 66/300
 - 12s - loss: 0.2721 - acc: 0.9477 - mDice: 0.7484 - val_loss: 0.6309 - val_acc: 0.9413 - val_mDice: 0.5915

Epoch 00066: val_mDice did not improve from 0.59735
Epoch 67/300
 - 12s - loss: 0.2743 - acc: 0.9474 - mDice: 0.7467 - val_loss: 0.6384 - val_acc: 0.9412 - val_mDice: 0.5827

Epoch 00067: val_mDice did not improve from 0.59735
Epoch 68/300
 - 13s - loss: 0.2742 - acc: 0.9474 - mDice: 0.7468 - val_loss: 0.6559 - val_acc: 0.9413 - val_mDice: 0.5727

Epoch 00068: val_mDice did not improve from 0.59735
Epoch 69/300
 - 12s - loss: 0.2708 - acc: 0.9477 - mDice: 0.7494 - val_loss: 0.6400 - val_acc: 0.9421 - val_mDice: 0.5806

Epoch 00069: val_mDice did not improve from 0.59735
Epoch 70/300
 - 12s - loss: 0.2701 - acc: 0.9479 - mDice: 0.7500 - val_loss: 0.6412 - val_acc: 0.9403 - val_mDice: 0.5869

Epoch 00070: val_mDice did not improve from 0.59735
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [2.170462402013632, 0.9627569753390092, 0.8333183939640338, 0.8001520725396963, 0.7995301828934596, 0.7486262390246758, 0.7325259894132614, 0.7450026663450094, 0.7371828120488387, 0.7624348688584107, 0.767243620294791, 0.758971590262193, 0.7416723301777473, 0.7465241494087073, 0.7342916910464947, 0.7606051587141477, 0.7679313409786958, 0.7800480448282682, 0.7408389632518475, 0.7325313481000754, 0.7515532546318494, 0.7441766732014142, 0.7349755454521912, 0.7281332245239844, 0.7352485209703445, 0.7459860008496505, 0.741970874942266, 0.7591964075198541, 0.7300767119114215, 0.7109362253775964, 0.7138565010749377, 0.7182408571243286, 0.7184900114169488, 0.7139940674488361, 0.724539204285695, 0.7067195177078247, 0.6945394953856101, 0.7060367820354608, 0.6939610472092261, 0.7060802452839338, 0.7032262224417466, 0.6990136504173279, 0.6922736775416595, 0.6863912917100466, 0.6840590078097123, 0.6854376575121512, 0.6897372981676688, 0.7073681331597842, 0.6919742077589035, 0.7014065854824506, 0.6983206707697648, 0.6824300220379462, 0.6689101790006344, 0.6574813517240378, 0.650231285737111, 0.6689465366877042, 0.650572697703655, 0.65437379020911, 0.6383169006842834, 0.6577329429296347, 0.6411467022620715, 0.6545774076993649, 0.6402763277292252, 0.6579463115105262, 0.63355214206072, 0.6308926997276453, 0.638433902309491, 0.6559231166656201, 0.6400215385051874, 0.6411784142255783], 'val_acc': [0.9074426843569829, 0.9151188272696275, 0.918211444066121, 0.924447584610719, 0.9265671051465548, 0.929359305363435, 0.9374884183590229, 0.9416813048032614, 0.9425758329721597, 0.9431582689285278, 0.9402181712480692, 0.9410364100566277, 0.9407405876196347, 0.9409393622325017, 0.9402829294021313, 0.9410433883850391, 0.9432669098560627, 0.9409277691290929, 0.9380524387726417, 0.9416535611336048, 0.9394161288554852, 0.9407613988106067, 0.9426128107767838, 0.939920037984848, 0.9378258906877958, 0.9412952776138599, 0.9400494648860052, 0.9429178994435531, 0.9383390247821808, 0.9421458840370178, 0.9424463991935437, 0.9412814264114087, 0.9410711114223187, 0.9383228650459876, 0.9412860343089471, 0.9403060124470637, 0.9384962159853715, 0.9424001253568209, 0.9444665335691892, 0.9413854296390827, 0.9395548403263092, 0.9409647836134984, 0.9404215812683105, 0.9397582274216872, 0.939894593678988, 0.9441129015042231, 0.9406804946752695, 0.9402644336223602, 0.9398692021003137, 0.9415565133094788, 0.9323779688431666, 0.9401165224038638, 0.9393652998484098, 0.9407521142409399, 0.9412005429084485, 0.9404608928240262, 0.9408792761655954, 0.9396634720838987, 0.9381610728227175, 0.9432045244253598, 0.9405348644806788, 0.9416489211412576, 0.9395802319049835, 0.9424001253568209, 0.9418962758321029, 0.9413345799996302, 0.9412259803368495, 0.9413114671523755, 0.942143603013112, 0.9402551765625293], 'val_mDice': [0.20885063077394778, 0.4913242058112071, 0.5415816278411791, 0.5580971332696768, 0.5507952748582914, 0.5713178664445877, 0.5846622677949759, 0.5863541083840224, 0.5768538552981156, 0.5809121464307492, 0.5815527725678223, 0.579084071975488, 0.5911329864309385, 0.5788027821825101, 0.5925974754186777, 0.5712491015975292, 0.5823840292600485, 0.5733280600263522, 0.5892746970057487, 0.5941519760168515, 0.5862180796953348, 0.5823166341735766, 0.5941515754048641, 0.5923232797246712, 0.5899273976683617, 0.5834243297576904, 0.584012545645237, 0.5745267965472661, 0.5875603946355673, 0.5973515636645831, 0.591044045984745, 0.5926706332426804, 0.5908609399428735, 0.5838686336691563, 0.5799173340201378, 0.5880129348773223, 0.5948762291899095, 0.5857639473218185, 0.5905658247379156, 0.5916027071384283, 0.5891251323314813, 0.5918184788181231, 0.5902266032420672, 0.5914239906347715, 0.5835711193772463, 0.5833810183864373, 0.5835617774954209, 0.5804710153203744, 0.5822633699728892, 0.5806741519616201, 0.5711063123666323, 0.5721915324146931, 0.5886819924299533, 0.5881989626930311, 0.5851282924413681, 0.5854101633796325, 0.5833452636232743, 0.5851872242414035, 0.5872484869681872, 0.5797051982237742, 0.5902304517535063, 0.5796428941763364, 0.5907274943131667, 0.5743323575991851, 0.5899708586243483, 0.5914793610572815, 0.5826926162609687, 0.5727026496942227, 0.5805807801393362, 0.5869151371029707], 'loss': [2.6861318114454056, 0.8876978378503467, 0.6284921414395007, 0.5238841127603903, 0.47614321041445795, 0.4504705511076824, 0.42976979721816144, 0.4175928104993526, 0.4064946336097782, 0.39641133429302033, 0.38557747588830055, 0.37805162728201097, 0.3703026982605111, 0.3639913062778641, 0.3574519180277446, 0.35435664377000997, 0.3519609844559268, 0.34633401139057574, 0.3423076123590125, 0.3379907283403222, 0.3335400005443657, 0.3318353106282266, 0.3301822104643579, 0.32553274020446815, 0.3247792902005331, 0.322177772747682, 0.3182407894291078, 0.31833956039975425, 0.3149572653704702, 0.31289294513237387, 0.3097330647443676, 0.3081865293215773, 0.3086456055489675, 0.30761387709496946, 0.3036460003971141, 0.30368890507980034, 0.30255955146278807, 0.2985137637598449, 0.2980527319525986, 0.2969304136213842, 0.2958727659422083, 0.2930366790795979, 0.29237396291543954, 0.29208919311387727, 0.29095474806568955, 0.28904993282542574, 0.28807727640585234, 0.2868968764733842, 0.2861844871351555, 0.2860792508525931, 0.28335893791803496, 0.2832816026834811, 0.2822520582012768, 0.2809470541047553, 0.2817319527324755, 0.279867751065363, 0.2793253662813131, 0.2790320283739063, 0.2780069231651679, 0.276838439582602, 0.2765428693017693, 0.27610563514231096, 0.2737231444363707, 0.274865804893399, 0.2744322928881652, 0.272121041959572, 0.27432267074708977, 0.2741780149522198, 0.27078134541602566, 0.27014042189571347], 'acc': [0.6052049479146598, 0.8853294214704958, 0.8908082519104854, 0.8955570384770711, 0.9003634725748959, 0.9055847359805225, 0.9122858206845182, 0.9193819645563087, 0.9267910326812404, 0.9325991513587711, 0.9359231481668222, 0.9375607223899055, 0.9386778864255418, 0.9394943056693214, 0.9401232800140247, 0.9404423869668718, 0.9406956139112612, 0.9412466303774277, 0.9416027869628956, 0.9420219913604657, 0.9423314564993029, 0.9423968138415952, 0.9426958610856928, 0.9430617489388626, 0.94310260406117, 0.9434435964180382, 0.9437907288009189, 0.9436340080870481, 0.943920283951707, 0.9440749166230153, 0.9444024927126001, 0.9443987922552799, 0.9444844994137761, 0.9444591826281292, 0.9448312125027449, 0.9449144570488646, 0.9450746319626658, 0.945295528601228, 0.9454280798377822, 0.9454031392270916, 0.9455284185430655, 0.9456768478512115, 0.9458036092905764, 0.9459215535247258, 0.9459190051746711, 0.9460351735664054, 0.9460605797837561, 0.9461108377297998, 0.9462438785182169, 0.9460982634640154, 0.9464825767108812, 0.9463642571758083, 0.946493128019319, 0.9467485427339721, 0.9466161038023975, 0.9468466441954324, 0.9469263451264087, 0.9467726653433369, 0.9469204251697821, 0.9470193221550811, 0.9471542918900882, 0.9471597882101239, 0.9472988159753493, 0.9472480720065567, 0.9474359575171516, 0.9476635909592832, 0.9473690492997121, 0.9474221431911074, 0.9477307444116588, 0.9479166386444763], 'mDice': [0.11880391024834366, 0.4074056050708832, 0.5219751018159868, 0.5779306046045608, 0.6072224188937172, 0.6236622360627128, 0.6369583591987844, 0.6448410177301197, 0.6521823932233358, 0.6585836328396353, 0.665801178174387, 0.6708046430197081, 0.6760030147511065, 0.6802819199770082, 0.6848209034271877, 0.6870536020263187, 0.6888336989532854, 0.6927643790298268, 0.69567059510794, 0.6987323128604299, 0.7020104541875752, 0.7032611673579471, 0.7044677434345349, 0.7078246200292475, 0.7084855134445595, 0.7103787747177484, 0.7133019845017118, 0.7132422031758622, 0.7156845977866406, 0.71716510945005, 0.7195355698684809, 0.7207275789063058, 0.7204502575909598, 0.7211966506561691, 0.7241570291666046, 0.7240995126578417, 0.7250603450781568, 0.7279863208298708, 0.7283938040122504, 0.7292672676880905, 0.7301067178466822, 0.7321623685471436, 0.7326735645645298, 0.7330081643053804, 0.7337512332531377, 0.7353066786797979, 0.7359702768970501, 0.7369054554078914, 0.7373463674564814, 0.7375640087678271, 0.739706240604694, 0.7396568567629924, 0.7405483886169396, 0.7414668887938827, 0.7408960961024611, 0.7423718503169509, 0.7427783741960223, 0.7430069942453696, 0.7437494902783167, 0.7446714741579228, 0.7449355187763931, 0.7452783845375355, 0.7471303324203347, 0.7462683821487479, 0.7465679019313011, 0.7483894913924155, 0.7467044698931486, 0.7468438224797758, 0.7494470851344177, 0.7500143677042956]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.80s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.50s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.28s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<12:08,  2.57s/it]predicting train subjects:   1%|          | 2/285 [00:04<10:49,  2.30s/it]predicting train subjects:   1%|          | 3/285 [00:06<10:24,  2.22s/it]predicting train subjects:   1%|▏         | 4/285 [00:08<09:47,  2.09s/it]predicting train subjects:   2%|▏         | 5/285 [00:10<10:19,  2.21s/it]predicting train subjects:   2%|▏         | 6/285 [00:12<09:38,  2.07s/it]predicting train subjects:   2%|▏         | 7/285 [00:14<09:50,  2.12s/it]predicting train subjects:   3%|▎         | 8/285 [00:17<10:16,  2.22s/it]predicting train subjects:   3%|▎         | 9/285 [00:20<11:20,  2.46s/it]predicting train subjects:   4%|▎         | 10/285 [00:22<11:26,  2.50s/it]predicting train subjects:   4%|▍         | 11/285 [00:24<10:57,  2.40s/it]predicting train subjects:   4%|▍         | 12/285 [00:27<10:45,  2.36s/it]predicting train subjects:   5%|▍         | 13/285 [00:29<10:39,  2.35s/it]predicting train subjects:   5%|▍         | 14/285 [00:31<10:25,  2.31s/it]predicting train subjects:   5%|▌         | 15/285 [00:34<11:07,  2.47s/it]predicting train subjects:   6%|▌         | 16/285 [00:36<11:06,  2.48s/it]predicting train subjects:   6%|▌         | 17/285 [00:38<10:16,  2.30s/it]predicting train subjects:   6%|▋         | 18/285 [00:41<10:37,  2.39s/it]predicting train subjects:   7%|▋         | 19/285 [00:43<09:57,  2.25s/it]predicting train subjects:   7%|▋         | 20/285 [00:46<10:36,  2.40s/it]predicting train subjects:   7%|▋         | 21/285 [00:48<10:30,  2.39s/it]predicting train subjects:   8%|▊         | 22/285 [00:50<10:21,  2.36s/it]predicting train subjects:   8%|▊         | 23/285 [00:53<10:41,  2.45s/it]predicting train subjects:   8%|▊         | 24/285 [00:55<10:02,  2.31s/it]predicting train subjects:   9%|▉         | 25/285 [00:57<10:04,  2.33s/it]predicting train subjects:   9%|▉         | 26/285 [01:00<10:02,  2.32s/it]predicting train subjects:   9%|▉         | 27/285 [01:02<09:49,  2.29s/it]predicting train subjects:  10%|▉         | 28/285 [01:04<09:57,  2.32s/it]predicting train subjects:  10%|█         | 29/285 [01:06<09:34,  2.24s/it]predicting train subjects:  11%|█         | 30/285 [01:09<10:06,  2.38s/it]predicting train subjects:  11%|█         | 31/285 [01:11<09:49,  2.32s/it]predicting train subjects:  11%|█         | 32/285 [01:13<09:09,  2.17s/it]predicting train subjects:  12%|█▏        | 33/285 [01:16<09:38,  2.29s/it]predicting train subjects:  12%|█▏        | 34/285 [01:18<09:35,  2.29s/it]predicting train subjects:  12%|█▏        | 35/285 [01:20<09:35,  2.30s/it]predicting train subjects:  13%|█▎        | 36/285 [01:22<09:03,  2.18s/it]predicting train subjects:  13%|█▎        | 37/285 [01:24<09:00,  2.18s/it]predicting train subjects:  13%|█▎        | 38/285 [01:27<09:29,  2.31s/it]predicting train subjects:  14%|█▎        | 39/285 [01:29<08:59,  2.19s/it]predicting train subjects:  14%|█▍        | 40/285 [01:31<09:04,  2.22s/it]predicting train subjects:  14%|█▍        | 41/285 [01:33<08:16,  2.03s/it]predicting train subjects:  15%|█▍        | 42/285 [01:34<08:00,  1.98s/it]predicting train subjects:  15%|█▌        | 43/285 [01:37<08:15,  2.05s/it]predicting train subjects:  15%|█▌        | 44/285 [01:39<08:04,  2.01s/it]predicting train subjects:  16%|█▌        | 45/285 [01:40<07:24,  1.85s/it]predicting train subjects:  16%|█▌        | 46/285 [01:42<07:21,  1.85s/it]predicting train subjects:  16%|█▋        | 47/285 [01:44<07:00,  1.77s/it]predicting train subjects:  17%|█▋        | 48/285 [01:45<06:58,  1.77s/it]predicting train subjects:  17%|█▋        | 49/285 [01:47<07:07,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:49<07:06,  1.82s/it]predicting train subjects:  18%|█▊        | 51/285 [01:51<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:53<06:54,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:54<06:48,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:56<06:56,  1.80s/it]predicting train subjects:  19%|█▉        | 55/285 [01:58<06:38,  1.73s/it]predicting train subjects:  20%|█▉        | 56/285 [01:59<06:35,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [02:01<06:20,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [02:03<06:24,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [02:05<06:31,  1.73s/it]predicting train subjects:  21%|██        | 60/285 [02:06<06:39,  1.77s/it]predicting train subjects:  21%|██▏       | 61/285 [02:08<06:29,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [02:10<06:27,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [02:12<06:29,  1.76s/it]predicting train subjects:  22%|██▏       | 64/285 [02:13<06:16,  1.70s/it]predicting train subjects:  23%|██▎       | 65/285 [02:15<06:20,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [02:17<06:18,  1.73s/it]predicting train subjects:  24%|██▎       | 67/285 [02:18<06:16,  1.73s/it]predicting train subjects:  24%|██▍       | 68/285 [02:20<06:07,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [02:22<06:14,  1.73s/it]predicting train subjects:  25%|██▍       | 70/285 [02:24<06:14,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:25<06:12,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:27<05:57,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:29<06:01,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:30<06:01,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:32<06:04,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:34<06:04,  1.74s/it]predicting train subjects:  27%|██▋       | 77/285 [02:36<05:49,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:37<05:42,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:39<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:40<05:40,  1.66s/it]predicting train subjects:  28%|██▊       | 81/285 [02:42<05:33,  1.63s/it]predicting train subjects:  29%|██▉       | 82/285 [02:44<05:32,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:45<05:23,  1.60s/it]predicting train subjects:  29%|██▉       | 84/285 [02:47<05:20,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:49<05:30,  1.65s/it]predicting train subjects:  30%|███       | 86/285 [02:50<05:32,  1.67s/it]predicting train subjects:  31%|███       | 87/285 [02:52<05:37,  1.71s/it]predicting train subjects:  31%|███       | 88/285 [02:54<05:24,  1.65s/it]predicting train subjects:  31%|███       | 89/285 [02:55<05:25,  1.66s/it]predicting train subjects:  32%|███▏      | 90/285 [02:57<05:29,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:59<05:21,  1.66s/it]predicting train subjects:  32%|███▏      | 92/285 [03:00<05:25,  1.69s/it]predicting train subjects:  33%|███▎      | 93/285 [03:02<05:16,  1.65s/it]predicting train subjects:  33%|███▎      | 94/285 [03:04<05:20,  1.68s/it]predicting train subjects:  33%|███▎      | 95/285 [03:05<05:22,  1.70s/it]predicting train subjects:  34%|███▎      | 96/285 [03:07<05:20,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [03:09<05:23,  1.72s/it]predicting train subjects:  34%|███▍      | 98/285 [03:11<05:26,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [03:12<05:22,  1.73s/it]predicting train subjects:  35%|███▌      | 100/285 [03:14<05:26,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [03:16<05:12,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [03:18<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [03:19<05:02,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [03:21<05:01,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [03:22<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [03:24<04:51,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [03:26<04:54,  1.66s/it]predicting train subjects:  38%|███▊      | 108/285 [03:27<04:45,  1.61s/it]predicting train subjects:  38%|███▊      | 109/285 [03:29<04:50,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:31<04:54,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:32<04:46,  1.64s/it]predicting train subjects:  39%|███▉      | 112/285 [03:34<04:46,  1.66s/it]predicting train subjects:  40%|███▉      | 113/285 [03:36<04:49,  1.68s/it]predicting train subjects:  40%|████      | 114/285 [03:37<04:46,  1.68s/it]predicting train subjects:  40%|████      | 115/285 [03:39<04:45,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:41<04:45,  1.69s/it]predicting train subjects:  41%|████      | 117/285 [03:42<04:34,  1.63s/it]predicting train subjects:  41%|████▏     | 118/285 [03:44<04:29,  1.61s/it]predicting train subjects:  42%|████▏     | 119/285 [03:46<04:35,  1.66s/it]predicting train subjects:  42%|████▏     | 120/285 [03:47<04:26,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:49<04:18,  1.58s/it]predicting train subjects:  43%|████▎     | 122/285 [03:50<04:13,  1.55s/it]predicting train subjects:  43%|████▎     | 123/285 [03:51<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:53<04:06,  1.53s/it]predicting train subjects:  44%|████▍     | 125/285 [03:55<04:01,  1.51s/it]predicting train subjects:  44%|████▍     | 126/285 [03:56<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<03:52,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<03:55,  1.50s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<03:43,  1.44s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<03:40,  1.43s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<03:45,  1.48s/it]predicting train subjects:  47%|████▋     | 133/285 [04:06<03:44,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<03:37,  1.44s/it]predicting train subjects:  47%|████▋     | 135/285 [04:09<03:31,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [04:10<03:28,  1.40s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<03:34,  1.45s/it]predicting train subjects:  48%|████▊     | 138/285 [04:13<03:29,  1.42s/it]predicting train subjects:  49%|████▉     | 139/285 [04:15<03:34,  1.47s/it]predicting train subjects:  49%|████▉     | 140/285 [04:16<03:42,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [04:18<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [04:19<03:29,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [04:21<03:28,  1.47s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:24<03:25,  1.47s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:24,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:19,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:31<03:15,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:13,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:08,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:14,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:41<03:08,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:07,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:02,  1.45s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:01,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<03:02,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:01,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:00,  1.49s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<02:54,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<02:55,  1.48s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:56<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<02:47,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [05:03<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [05:04<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [05:06<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:07<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:09<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:11<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:12<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:13<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:15<02:40,  1.53s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:17<02:41,  1.55s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:18<02:40,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:20<02:30,  1.48s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:21<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:24<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:39,  1.63s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:42,  1.68s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:31,  1.58s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:23,  1.51s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:23,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:24,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:18,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:36<02:13,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:07,  1.42s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:41<02:19,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:22,  1.64s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:44<02:12,  1.54s/it]predicting train subjects:  70%|███████   | 200/285 [05:46<02:05,  1.47s/it]predicting train subjects:  71%|███████   | 201/285 [05:47<02:09,  1.54s/it]predicting train subjects:  71%|███████   | 202/285 [05:49<02:09,  1.56s/it]predicting train subjects:  71%|███████   | 203/285 [05:51<02:08,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:52<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:53<01:58,  1.48s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:55<01:52,  1.42s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:56<01:58,  1.52s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:58<02:00,  1.56s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:00<02:02,  1.61s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:01<01:55,  1.54s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:03<01:51,  1.51s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:04<01:50,  1.51s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:06<01:49,  1.51s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:07<01:43,  1.46s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:09<01:46,  1.52s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:10<01:39,  1.44s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:12<01:44,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:13<01:46,  1.59s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:15<01:47,  1.63s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:16<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:18<01:36,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:19<01:36,  1.53s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:21<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:22<01:27,  1.43s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:23<01:25,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:25<01:29,  1.52s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:27<01:35,  1.64s/it]predicting train subjects:  80%|████████  | 228/285 [06:29<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:31<01:33,  1.67s/it]predicting train subjects:  81%|████████  | 230/285 [06:32<01:25,  1.56s/it]predicting train subjects:  81%|████████  | 231/285 [06:33<01:20,  1.50s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:35<01:20,  1.52s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:36<01:15,  1.45s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:38<01:17,  1.52s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:39<01:12,  1.45s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:41<01:14,  1.53s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:42<01:15,  1.58s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:44<01:15,  1.62s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:46<01:14,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:47<01:09,  1.54s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:49<01:06,  1.51s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:50<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:51<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:53<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:54<00:59,  1.48s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:56<01:00,  1.54s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:58<01:00,  1.59s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:59<00:59,  1.61s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:01<00:55,  1.54s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:02<00:53,  1.52s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:04<00:49,  1.46s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:05<00:47,  1.43s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:07<00:49,  1.54s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:08<00:49,  1.60s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:10<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:11<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:13<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [07:15<00:41,  1.55s/it]predicting train subjects:  91%|█████████ | 259/285 [07:16<00:40,  1.56s/it]predicting train subjects:  91%|█████████ | 260/285 [07:17<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:19<00:34,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:20<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:21<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:23<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:25<00:31,  1.58s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:26<00:28,  1.51s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:28<00:26,  1.49s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:30<00:26,  1.58s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:31<00:25,  1.59s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:33<00:22,  1.51s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:34<00:20,  1.47s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:36<00:19,  1.52s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:37<00:17,  1.45s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:38<00:15,  1.42s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:40<00:15,  1.51s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:42<00:14,  1.57s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:43<00:11,  1.49s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:44<00:10,  1.47s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:46<00:09,  1.52s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:47<00:07,  1.47s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:49<00:05,  1.44s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:50<00:04,  1.38s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:52<00:02,  1.47s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:53<00:01,  1.55s/it]predicting train subjects: 100%|██████████| 285/285 [07:55<00:00,  1.62s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:48,  1.65s/it]Loading train:   1%|          | 2/285 [00:02<07:15,  1.54s/it]Loading train:   1%|          | 3/285 [00:04<07:06,  1.51s/it]Loading train:   1%|▏         | 4/285 [00:05<06:41,  1.43s/it]Loading train:   2%|▏         | 5/285 [00:07<06:50,  1.47s/it]Loading train:   2%|▏         | 6/285 [00:08<06:24,  1.38s/it]Loading train:   2%|▏         | 7/285 [00:09<06:43,  1.45s/it]Loading train:   3%|▎         | 8/285 [00:11<06:30,  1.41s/it]Loading train:   3%|▎         | 9/285 [00:12<06:41,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:01,  1.32s/it]Loading train:   4%|▍         | 11/285 [00:14<05:22,  1.18s/it]Loading train:   4%|▍         | 12/285 [00:15<05:19,  1.17s/it]Loading train:   5%|▍         | 13/285 [00:16<04:53,  1.08s/it]Loading train:   5%|▍         | 14/285 [00:17<04:48,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:57,  1.10s/it]Loading train:   6%|▌         | 16/285 [00:20<05:02,  1.12s/it]Loading train:   6%|▌         | 17/285 [00:21<04:48,  1.08s/it]Loading train:   6%|▋         | 18/285 [00:21<04:35,  1.03s/it]Loading train:   7%|▋         | 19/285 [00:22<04:19,  1.03it/s]Loading train:   7%|▋         | 20/285 [00:23<04:13,  1.04it/s]Loading train:   7%|▋         | 21/285 [00:24<04:32,  1.03s/it]Loading train:   8%|▊         | 22/285 [00:25<04:18,  1.02it/s]Loading train:   8%|▊         | 23/285 [00:26<04:30,  1.03s/it]Loading train:   8%|▊         | 24/285 [00:27<04:06,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:28<04:10,  1.04it/s]Loading train:   9%|▉         | 26/285 [00:29<04:15,  1.02it/s]Loading train:   9%|▉         | 27/285 [00:30<03:57,  1.09it/s]Loading train:  10%|▉         | 28/285 [00:31<03:54,  1.10it/s]Loading train:  10%|█         | 29/285 [00:32<04:01,  1.06it/s]Loading train:  11%|█         | 30/285 [00:33<04:17,  1.01s/it]Loading train:  11%|█         | 31/285 [00:34<04:27,  1.05s/it]Loading train:  11%|█         | 32/285 [00:35<04:19,  1.02s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:26,  1.06s/it]Loading train:  12%|█▏        | 34/285 [00:37<04:15,  1.02s/it]Loading train:  12%|█▏        | 35/285 [00:38<04:14,  1.02s/it]Loading train:  13%|█▎        | 36/285 [00:39<04:16,  1.03s/it]Loading train:  13%|█▎        | 37/285 [00:40<04:09,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:41<04:09,  1.01s/it]Loading train:  14%|█▎        | 39/285 [00:42<03:56,  1.04it/s]Loading train:  14%|█▍        | 40/285 [00:43<03:54,  1.04it/s]Loading train:  14%|█▍        | 41/285 [00:44<03:44,  1.09it/s]Loading train:  15%|█▍        | 42/285 [00:45<03:47,  1.07it/s]Loading train:  15%|█▌        | 43/285 [00:46<03:46,  1.07it/s]Loading train:  15%|█▌        | 44/285 [00:47<04:00,  1.00it/s]Loading train:  16%|█▌        | 45/285 [00:48<03:50,  1.04it/s]Loading train:  16%|█▌        | 46/285 [00:49<04:03,  1.02s/it]Loading train:  16%|█▋        | 47/285 [00:50<03:59,  1.01s/it]Loading train:  17%|█▋        | 48/285 [00:51<04:04,  1.03s/it]Loading train:  17%|█▋        | 49/285 [00:52<04:03,  1.03s/it]Loading train:  18%|█▊        | 50/285 [00:53<04:01,  1.03s/it]Loading train:  18%|█▊        | 51/285 [00:54<04:15,  1.09s/it]Loading train:  18%|█▊        | 52/285 [00:55<04:02,  1.04s/it]Loading train:  19%|█▊        | 53/285 [00:56<04:01,  1.04s/it]Loading train:  19%|█▉        | 54/285 [00:58<04:18,  1.12s/it]Loading train:  19%|█▉        | 55/285 [00:58<03:54,  1.02s/it]Loading train:  20%|█▉        | 56/285 [01:00<03:57,  1.04s/it]Loading train:  20%|██        | 57/285 [01:00<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:01<03:46,  1.00it/s]Loading train:  21%|██        | 59/285 [01:02<03:46,  1.00s/it]Loading train:  21%|██        | 60/285 [01:03<03:46,  1.01s/it]Loading train:  21%|██▏       | 61/285 [01:04<03:41,  1.01it/s]Loading train:  22%|██▏       | 62/285 [01:05<03:44,  1.01s/it]Loading train:  22%|██▏       | 63/285 [01:06<03:44,  1.01s/it]Loading train:  22%|██▏       | 64/285 [01:08<04:03,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:09<04:44,  1.29s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:54,  1.34s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:31,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:13<04:07,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:14<03:56,  1.10s/it]Loading train:  25%|██▍       | 70/285 [01:15<03:53,  1.08s/it]Loading train:  25%|██▍       | 71/285 [01:16<03:52,  1.08s/it]Loading train:  25%|██▌       | 72/285 [01:17<03:49,  1.08s/it]Loading train:  26%|██▌       | 73/285 [01:18<03:42,  1.05s/it]Loading train:  26%|██▌       | 74/285 [01:19<03:27,  1.01it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:23,  1.03it/s]Loading train:  27%|██▋       | 76/285 [01:21<03:31,  1.01s/it]Loading train:  27%|██▋       | 77/285 [01:22<03:22,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:23<03:20,  1.03it/s]Loading train:  28%|██▊       | 79/285 [01:24<03:19,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:25<03:21,  1.02it/s]Loading train:  28%|██▊       | 81/285 [01:26<03:22,  1.01it/s]Loading train:  29%|██▉       | 82/285 [01:27<03:24,  1.01s/it]Loading train:  29%|██▉       | 83/285 [01:28<03:18,  1.02it/s]Loading train:  29%|██▉       | 84/285 [01:29<03:13,  1.04it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:23,  1.02s/it]Loading train:  30%|███       | 86/285 [01:31<03:24,  1.03s/it]Loading train:  31%|███       | 87/285 [01:32<03:34,  1.09s/it]Loading train:  31%|███       | 88/285 [01:33<03:23,  1.03s/it]Loading train:  31%|███       | 89/285 [01:34<03:15,  1.00it/s]Loading train:  32%|███▏      | 90/285 [01:35<03:09,  1.03it/s]Loading train:  32%|███▏      | 91/285 [01:36<03:04,  1.05it/s]Loading train:  32%|███▏      | 92/285 [01:37<03:16,  1.02s/it]Loading train:  33%|███▎      | 93/285 [01:38<03:03,  1.04it/s]Loading train:  33%|███▎      | 94/285 [01:39<03:09,  1.01it/s]Loading train:  33%|███▎      | 95/285 [01:40<03:10,  1.00s/it]Loading train:  34%|███▎      | 96/285 [01:41<03:02,  1.04it/s]Loading train:  34%|███▍      | 97/285 [01:42<03:03,  1.03it/s]Loading train:  34%|███▍      | 98/285 [01:42<02:55,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:43<02:51,  1.09it/s]Loading train:  35%|███▌      | 100/285 [01:44<02:54,  1.06it/s]Loading train:  35%|███▌      | 101/285 [01:45<03:02,  1.01it/s]Loading train:  36%|███▌      | 102/285 [01:47<03:11,  1.05s/it]Loading train:  36%|███▌      | 103/285 [01:48<03:04,  1.02s/it]Loading train:  36%|███▋      | 104/285 [01:49<03:03,  1.02s/it]Loading train:  37%|███▋      | 105/285 [01:50<03:04,  1.02s/it]Loading train:  37%|███▋      | 106/285 [01:51<03:03,  1.03s/it]Loading train:  38%|███▊      | 107/285 [01:52<03:07,  1.05s/it]Loading train:  38%|███▊      | 108/285 [01:53<03:00,  1.02s/it]Loading train:  38%|███▊      | 109/285 [01:54<02:59,  1.02s/it]Loading train:  39%|███▊      | 110/285 [01:55<02:56,  1.01s/it]Loading train:  39%|███▉      | 111/285 [01:56<02:49,  1.03it/s]Loading train:  39%|███▉      | 112/285 [01:57<02:46,  1.04it/s]Loading train:  40%|███▉      | 113/285 [01:58<02:58,  1.04s/it]Loading train:  40%|████      | 114/285 [01:59<02:49,  1.01it/s]Loading train:  40%|████      | 115/285 [02:00<02:43,  1.04it/s]Loading train:  41%|████      | 116/285 [02:01<02:42,  1.04it/s]Loading train:  41%|████      | 117/285 [02:02<02:41,  1.04it/s]Loading train:  41%|████▏     | 118/285 [02:02<02:36,  1.07it/s]Loading train:  42%|████▏     | 119/285 [02:03<02:42,  1.02it/s]Loading train:  42%|████▏     | 120/285 [02:04<02:41,  1.02it/s]Loading train:  42%|████▏     | 121/285 [02:06<03:02,  1.11s/it]Loading train:  43%|████▎     | 122/285 [02:07<03:02,  1.12s/it]Loading train:  43%|████▎     | 123/285 [02:08<03:05,  1.15s/it]Loading train:  44%|████▎     | 124/285 [02:09<02:52,  1.07s/it]Loading train:  44%|████▍     | 125/285 [02:10<02:37,  1.02it/s]Loading train:  44%|████▍     | 126/285 [02:11<02:31,  1.05it/s]Loading train:  45%|████▍     | 127/285 [02:12<02:22,  1.11it/s]Loading train:  45%|████▍     | 128/285 [02:12<02:17,  1.14it/s]Loading train:  45%|████▌     | 129/285 [02:13<02:18,  1.12it/s]Loading train:  46%|████▌     | 130/285 [02:14<02:11,  1.18it/s]Loading train:  46%|████▌     | 131/285 [02:15<02:09,  1.19it/s]Loading train:  46%|████▋     | 132/285 [02:16<02:16,  1.12it/s]Loading train:  47%|████▋     | 133/285 [02:17<02:13,  1.14it/s]Loading train:  47%|████▋     | 134/285 [02:18<02:12,  1.14it/s]Loading train:  47%|████▋     | 135/285 [02:18<02:06,  1.18it/s]Loading train:  48%|████▊     | 136/285 [02:19<02:03,  1.20it/s]Loading train:  48%|████▊     | 137/285 [02:20<02:03,  1.20it/s]Loading train:  48%|████▊     | 138/285 [02:21<02:06,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:22<02:09,  1.13it/s]Loading train:  49%|████▉     | 140/285 [02:23<02:06,  1.14it/s]Loading train:  49%|████▉     | 141/285 [02:24<02:04,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:24<02:04,  1.15it/s]Loading train:  50%|█████     | 143/285 [02:25<02:01,  1.17it/s]Loading train:  51%|█████     | 144/285 [02:26<01:59,  1.18it/s]Loading train:  51%|█████     | 145/285 [02:27<01:56,  1.20it/s]Loading train:  51%|█████     | 146/285 [02:28<01:54,  1.21it/s]Loading train:  52%|█████▏    | 147/285 [02:28<01:51,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:29<01:52,  1.22it/s]Loading train:  52%|█████▏    | 149/285 [02:30<01:52,  1.21it/s]Loading train:  53%|█████▎    | 150/285 [02:31<01:47,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:32<01:53,  1.18it/s]Loading train:  53%|█████▎    | 152/285 [02:33<02:00,  1.11it/s]Loading train:  54%|█████▎    | 153/285 [02:34<01:56,  1.13it/s]Loading train:  54%|█████▍    | 154/285 [02:35<01:55,  1.13it/s]Loading train:  54%|█████▍    | 155/285 [02:35<01:49,  1.18it/s]Loading train:  55%|█████▍    | 156/285 [02:36<01:46,  1.21it/s]Loading train:  55%|█████▌    | 157/285 [02:37<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:38<01:49,  1.16it/s]Loading train:  56%|█████▌    | 159/285 [02:39<01:49,  1.15it/s]Loading train:  56%|█████▌    | 160/285 [02:40<01:47,  1.16it/s]Loading train:  56%|█████▋    | 161/285 [02:41<01:49,  1.14it/s]Loading train:  57%|█████▋    | 162/285 [02:41<01:45,  1.17it/s]Loading train:  57%|█████▋    | 163/285 [02:42<01:45,  1.16it/s]Loading train:  58%|█████▊    | 164/285 [02:43<01:41,  1.20it/s]Loading train:  58%|█████▊    | 165/285 [02:44<01:40,  1.19it/s]Loading train:  58%|█████▊    | 166/285 [02:45<01:43,  1.15it/s]Loading train:  59%|█████▊    | 167/285 [02:46<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [02:47<01:44,  1.12it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:45,  1.10it/s]Loading train:  60%|█████▉    | 170/285 [02:49<01:44,  1.11it/s]Loading train:  60%|██████    | 171/285 [02:49<01:39,  1.15it/s]Loading train:  60%|██████    | 172/285 [02:50<01:38,  1.14it/s]Loading train:  61%|██████    | 173/285 [02:51<01:35,  1.17it/s]Loading train:  61%|██████    | 174/285 [02:52<01:34,  1.18it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:33,  1.17it/s]Loading train:  62%|██████▏   | 176/285 [02:53<01:30,  1.21it/s]Loading train:  62%|██████▏   | 177/285 [02:54<01:28,  1.22it/s]Loading train:  62%|██████▏   | 178/285 [02:55<01:24,  1.27it/s]Loading train:  63%|██████▎   | 179/285 [02:56<01:20,  1.31it/s]Loading train:  63%|██████▎   | 180/285 [02:57<01:25,  1.23it/s]Loading train:  64%|██████▎   | 181/285 [02:58<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [02:58<01:25,  1.20it/s]Loading train:  64%|██████▍   | 183/285 [02:59<01:21,  1.25it/s]Loading train:  65%|██████▍   | 184/285 [03:00<01:25,  1.17it/s]Loading train:  65%|██████▍   | 185/285 [03:01<01:28,  1.13it/s]Loading train:  65%|██████▌   | 186/285 [03:02<01:31,  1.08it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:37,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:04<01:37,  1.00s/it]Loading train:  66%|██████▋   | 189/285 [03:05<01:27,  1.09it/s]Loading train:  67%|██████▋   | 190/285 [03:06<01:24,  1.12it/s]Loading train:  67%|██████▋   | 191/285 [03:07<01:21,  1.15it/s]Loading train:  67%|██████▋   | 192/285 [03:08<01:24,  1.11it/s]Loading train:  68%|██████▊   | 193/285 [03:08<01:21,  1.13it/s]Loading train:  68%|██████▊   | 194/285 [03:09<01:23,  1.09it/s]Loading train:  68%|██████▊   | 195/285 [03:10<01:28,  1.02it/s]Loading train:  69%|██████▉   | 196/285 [03:12<01:29,  1.01s/it]Loading train:  69%|██████▉   | 197/285 [03:13<01:31,  1.04s/it]Loading train:  69%|██████▉   | 198/285 [03:14<01:30,  1.04s/it]Loading train:  70%|██████▉   | 199/285 [03:14<01:21,  1.05it/s]Loading train:  70%|███████   | 200/285 [03:15<01:18,  1.09it/s]Loading train:  71%|███████   | 201/285 [03:16<01:18,  1.07it/s]Loading train:  71%|███████   | 202/285 [03:17<01:18,  1.05it/s]Loading train:  71%|███████   | 203/285 [03:18<01:18,  1.05it/s]Loading train:  72%|███████▏  | 204/285 [03:19<01:12,  1.12it/s]Loading train:  72%|███████▏  | 205/285 [03:20<01:08,  1.18it/s]Loading train:  72%|███████▏  | 206/285 [03:21<01:06,  1.19it/s]Loading train:  73%|███████▎  | 207/285 [03:22<01:09,  1.12it/s]Loading train:  73%|███████▎  | 208/285 [03:23<01:12,  1.06it/s]Loading train:  73%|███████▎  | 209/285 [03:24<01:12,  1.06it/s]Loading train:  74%|███████▎  | 210/285 [03:24<01:09,  1.07it/s]Loading train:  74%|███████▍  | 211/285 [03:25<01:09,  1.07it/s]Loading train:  74%|███████▍  | 212/285 [03:26<01:05,  1.11it/s]Loading train:  75%|███████▍  | 213/285 [03:27<01:03,  1.13it/s]Loading train:  75%|███████▌  | 214/285 [03:28<01:02,  1.13it/s]Loading train:  75%|███████▌  | 215/285 [03:29<01:03,  1.10it/s]Loading train:  76%|███████▌  | 216/285 [03:30<01:04,  1.07it/s]Loading train:  76%|███████▌  | 217/285 [03:31<01:12,  1.07s/it]Loading train:  76%|███████▋  | 218/285 [03:32<01:09,  1.04s/it]Loading train:  77%|███████▋  | 219/285 [03:33<01:07,  1.02s/it]Loading train:  77%|███████▋  | 220/285 [03:34<01:04,  1.01it/s]Loading train:  78%|███████▊  | 221/285 [03:35<01:01,  1.04it/s]Loading train:  78%|███████▊  | 222/285 [03:36<01:01,  1.02it/s]Loading train:  78%|███████▊  | 223/285 [03:37<00:58,  1.07it/s]Loading train:  79%|███████▊  | 224/285 [03:38<00:59,  1.03it/s]Loading train:  79%|███████▉  | 225/285 [03:39<00:53,  1.11it/s]Loading train:  79%|███████▉  | 226/285 [03:40<00:56,  1.04it/s]Loading train:  80%|███████▉  | 227/285 [03:41<01:00,  1.04s/it]Loading train:  80%|████████  | 228/285 [03:42<01:00,  1.06s/it]Loading train:  80%|████████  | 229/285 [03:43<00:57,  1.02s/it]Loading train:  81%|████████  | 230/285 [03:44<00:54,  1.01it/s]Loading train:  81%|████████  | 231/285 [03:45<00:50,  1.06it/s]Loading train:  81%|████████▏ | 232/285 [03:46<00:49,  1.08it/s]Loading train:  82%|████████▏ | 233/285 [03:46<00:45,  1.13it/s]Loading train:  82%|████████▏ | 234/285 [03:48<00:47,  1.07it/s]Loading train:  82%|████████▏ | 235/285 [03:48<00:45,  1.10it/s]Loading train:  83%|████████▎ | 236/285 [03:49<00:46,  1.06it/s]Loading train:  83%|████████▎ | 237/285 [03:50<00:46,  1.04it/s]Loading train:  84%|████████▎ | 238/285 [03:51<00:46,  1.02it/s]Loading train:  84%|████████▍ | 239/285 [03:52<00:45,  1.01it/s]Loading train:  84%|████████▍ | 240/285 [03:53<00:44,  1.02it/s]Loading train:  85%|████████▍ | 241/285 [03:54<00:40,  1.08it/s]Loading train:  85%|████████▍ | 242/285 [03:55<00:39,  1.09it/s]Loading train:  85%|████████▌ | 243/285 [03:56<00:37,  1.13it/s]Loading train:  86%|████████▌ | 244/285 [03:57<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [03:58<00:33,  1.18it/s]Loading train:  86%|████████▋ | 246/285 [03:59<00:34,  1.12it/s]Loading train:  87%|████████▋ | 247/285 [04:00<00:35,  1.07it/s]Loading train:  87%|████████▋ | 248/285 [04:01<00:35,  1.04it/s]Loading train:  87%|████████▋ | 249/285 [04:02<00:34,  1.06it/s]Loading train:  88%|████████▊ | 250/285 [04:02<00:32,  1.07it/s]Loading train:  88%|████████▊ | 251/285 [04:03<00:31,  1.09it/s]Loading train:  88%|████████▊ | 252/285 [04:04<00:28,  1.14it/s]Loading train:  89%|████████▉ | 253/285 [04:05<00:31,  1.03it/s]Loading train:  89%|████████▉ | 254/285 [04:06<00:30,  1.02it/s]Loading train:  89%|████████▉ | 255/285 [04:07<00:28,  1.03it/s]Loading train:  90%|████████▉ | 256/285 [04:08<00:26,  1.11it/s]Loading train:  90%|█████████ | 257/285 [04:09<00:23,  1.18it/s]Loading train:  91%|█████████ | 258/285 [04:10<00:24,  1.12it/s]Loading train:  91%|█████████ | 259/285 [04:11<00:22,  1.15it/s]Loading train:  91%|█████████ | 260/285 [04:11<00:20,  1.21it/s]Loading train:  92%|█████████▏| 261/285 [04:12<00:19,  1.26it/s]Loading train:  92%|█████████▏| 262/285 [04:13<00:17,  1.31it/s]Loading train:  92%|█████████▏| 263/285 [04:13<00:16,  1.37it/s]Loading train:  93%|█████████▎| 264/285 [04:14<00:17,  1.23it/s]Loading train:  93%|█████████▎| 265/285 [04:16<00:18,  1.08it/s]Loading train:  93%|█████████▎| 266/285 [04:16<00:17,  1.09it/s]Loading train:  94%|█████████▎| 267/285 [04:17<00:16,  1.12it/s]Loading train:  94%|█████████▍| 268/285 [04:18<00:15,  1.07it/s]Loading train:  94%|█████████▍| 269/285 [04:19<00:15,  1.05it/s]Loading train:  95%|█████████▍| 270/285 [04:20<00:13,  1.08it/s]Loading train:  95%|█████████▌| 271/285 [04:21<00:12,  1.12it/s]Loading train:  95%|█████████▌| 272/285 [04:22<00:11,  1.15it/s]Loading train:  96%|█████████▌| 273/285 [04:22<00:09,  1.22it/s]Loading train:  96%|█████████▌| 274/285 [04:23<00:08,  1.23it/s]Loading train:  96%|█████████▋| 275/285 [04:24<00:08,  1.14it/s]Loading train:  97%|█████████▋| 276/285 [04:25<00:08,  1.08it/s]Loading train:  97%|█████████▋| 277/285 [04:26<00:07,  1.13it/s]Loading train:  98%|█████████▊| 278/285 [04:27<00:06,  1.15it/s]Loading train:  98%|█████████▊| 279/285 [04:28<00:05,  1.10it/s]Loading train:  98%|█████████▊| 280/285 [04:29<00:04,  1.13it/s]Loading train:  99%|█████████▊| 281/285 [04:30<00:03,  1.17it/s]Loading train:  99%|█████████▉| 282/285 [04:30<00:02,  1.19it/s]Loading train:  99%|█████████▉| 283/285 [04:31<00:01,  1.12it/s]Loading train: 100%|█████████▉| 284/285 [04:32<00:00,  1.05it/s]Loading train: 100%|██████████| 285/285 [04:34<00:00,  1.02it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 64.56it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:03, 74.34it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:03, 82.34it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:02, 86.94it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:02, 92.35it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:01, 116.67it/s]concatenating: train:  41%|████▏     | 118/285 [00:00<00:01, 146.15it/s]concatenating: train:  53%|█████▎    | 151/285 [00:00<00:00, 174.77it/s]concatenating: train:  65%|██████▍   | 184/285 [00:00<00:00, 203.26it/s]concatenating: train:  77%|███████▋  | 220/285 [00:01<00:00, 233.57it/s]concatenating: train:  90%|█████████ | 257/285 [00:01<00:00, 261.74it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 239.02it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.21s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 641.95it/s]2019-07-11 00:36:59.606696: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 00:36:59.606821: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 00:36:59.606837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 00:36:59.606846: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 00:36:59.607285: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.58it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.48it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.20it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.59it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.87it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.68it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.05it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.88it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.51it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.99it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.70it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.03it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.25it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.84it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.47it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.91it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.07it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.06it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.03it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 13)   598         dropout_7[0][0]                  
==================================================================================================
Total params: 147,038
Trainable params: 48,418
Non-trainable params: 98,620
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 3.1708 - acc: 0.4586 - mDice: 0.0856 - val_loss: 2.6607 - val_acc: 0.7507 - val_mDice: 0.1810

Epoch 00001: val_mDice improved from -inf to 0.18101, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.5860 - acc: 0.7068 - mDice: 0.2573 - val_loss: 1.6972 - val_acc: 0.8867 - val_mDice: 0.3672

Epoch 00002: val_mDice improved from 0.18101 to 0.36723, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.8672 - acc: 0.8781 - mDice: 0.4276 - val_loss: 1.4520 - val_acc: 0.9106 - val_mDice: 0.3573

Epoch 00003: val_mDice did not improve from 0.36723
Epoch 4/300
 - 10s - loss: 0.6179 - acc: 0.8989 - mDice: 0.5214 - val_loss: 1.4959 - val_acc: 0.9174 - val_mDice: 0.3398

Epoch 00004: val_mDice did not improve from 0.36723
Epoch 5/300
 - 10s - loss: 0.5472 - acc: 0.9167 - mDice: 0.5610 - val_loss: 1.0482 - val_acc: 0.9394 - val_mDice: 0.5415

Epoch 00005: val_mDice improved from 0.36723 to 0.54153, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.5085 - acc: 0.9221 - mDice: 0.5841 - val_loss: 1.0189 - val_acc: 0.9431 - val_mDice: 0.5561

Epoch 00006: val_mDice improved from 0.54153 to 0.55614, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.4792 - acc: 0.9251 - mDice: 0.6021 - val_loss: 1.0258 - val_acc: 0.9423 - val_mDice: 0.5380

Epoch 00007: val_mDice did not improve from 0.55614
Epoch 8/300
 - 10s - loss: 0.4586 - acc: 0.9270 - mDice: 0.6153 - val_loss: 0.9844 - val_acc: 0.9433 - val_mDice: 0.5673

Epoch 00008: val_mDice improved from 0.55614 to 0.56729, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4400 - acc: 0.9290 - mDice: 0.6276 - val_loss: 0.9932 - val_acc: 0.9436 - val_mDice: 0.5485

Epoch 00009: val_mDice did not improve from 0.56729
Epoch 10/300
 - 10s - loss: 0.4291 - acc: 0.9298 - mDice: 0.6349 - val_loss: 0.9938 - val_acc: 0.9441 - val_mDice: 0.5379

Epoch 00010: val_mDice did not improve from 0.56729
Epoch 11/300
 - 10s - loss: 0.4212 - acc: 0.9306 - mDice: 0.6402 - val_loss: 0.9463 - val_acc: 0.9462 - val_mDice: 0.5634

Epoch 00011: val_mDice did not improve from 0.56729
Epoch 12/300
 - 10s - loss: 0.4115 - acc: 0.9314 - mDice: 0.6467 - val_loss: 0.9053 - val_acc: 0.9463 - val_mDice: 0.5651

Epoch 00012: val_mDice did not improve from 0.56729
Epoch 13/300
 - 10s - loss: 0.4030 - acc: 0.9322 - mDice: 0.6524 - val_loss: 0.8773 - val_acc: 0.9398 - val_mDice: 0.5798

Epoch 00013: val_mDice improved from 0.56729 to 0.57984, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 10s - loss: 0.3973 - acc: 0.9326 - mDice: 0.6563 - val_loss: 0.9114 - val_acc: 0.9463 - val_mDice: 0.5697

Epoch 00014: val_mDice did not improve from 0.57984
Epoch 15/300
 - 10s - loss: 0.3932 - acc: 0.9330 - mDice: 0.6592 - val_loss: 0.8388 - val_acc: 0.9438 - val_mDice: 0.5863

Epoch 00015: val_mDice improved from 0.57984 to 0.58630, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 10s - loss: 0.3862 - acc: 0.9336 - mDice: 0.6641 - val_loss: 0.8898 - val_acc: 0.9413 - val_mDice: 0.5615

Epoch 00016: val_mDice did not improve from 0.58630
Epoch 17/300
 - 10s - loss: 0.3813 - acc: 0.9340 - mDice: 0.6676 - val_loss: 0.8650 - val_acc: 0.9435 - val_mDice: 0.5477

Epoch 00017: val_mDice did not improve from 0.58630
Epoch 18/300
 - 10s - loss: 0.3776 - acc: 0.9342 - mDice: 0.6701 - val_loss: 0.8927 - val_acc: 0.9465 - val_mDice: 0.5601

Epoch 00018: val_mDice did not improve from 0.58630
Epoch 19/300
 - 10s - loss: 0.3707 - acc: 0.9348 - mDice: 0.6750 - val_loss: 0.8759 - val_acc: 0.9405 - val_mDice: 0.5664

Epoch 00019: val_mDice did not improve from 0.58630
Epoch 20/300
 - 10s - loss: 0.3718 - acc: 0.9345 - mDice: 0.6741 - val_loss: 0.8332 - val_acc: 0.9451 - val_mDice: 0.5774

Epoch 00020: val_mDice did not improve from 0.58630
Epoch 21/300
 - 10s - loss: 0.3672 - acc: 0.9349 - mDice: 0.6774 - val_loss: 0.8293 - val_acc: 0.9447 - val_mDice: 0.5598

Epoch 00021: val_mDice did not improve from 0.58630
Epoch 22/300
 - 10s - loss: 0.3635 - acc: 0.9353 - mDice: 0.6801 - val_loss: 0.8544 - val_acc: 0.9437 - val_mDice: 0.5500

Epoch 00022: val_mDice did not improve from 0.58630
Epoch 23/300
 - 10s - loss: 0.3600 - acc: 0.9355 - mDice: 0.6824 - val_loss: 0.8072 - val_acc: 0.9435 - val_mDice: 0.5860

Epoch 00023: val_mDice did not improve from 0.58630
Epoch 24/300
 - 10s - loss: 0.3581 - acc: 0.9359 - mDice: 0.6840 - val_loss: 0.7936 - val_acc: 0.9419 - val_mDice: 0.5862

Epoch 00024: val_mDice did not improve from 0.58630
Epoch 25/300
 - 10s - loss: 0.3530 - acc: 0.9362 - mDice: 0.6875 - val_loss: 0.8051 - val_acc: 0.9433 - val_mDice: 0.5534

Epoch 00025: val_mDice did not improve from 0.58630
Epoch 26/300
 - 10s - loss: 0.3532 - acc: 0.9360 - mDice: 0.6875 - val_loss: 0.8220 - val_acc: 0.9368 - val_mDice: 0.5468

Epoch 00026: val_mDice did not improve from 0.58630
Epoch 27/300
 - 10s - loss: 0.3489 - acc: 0.9365 - mDice: 0.6906 - val_loss: 0.7959 - val_acc: 0.9467 - val_mDice: 0.5534

Epoch 00027: val_mDice did not improve from 0.58630
Epoch 28/300
 - 10s - loss: 0.3476 - acc: 0.9367 - mDice: 0.6915 - val_loss: 0.7468 - val_acc: 0.9444 - val_mDice: 0.5696

Epoch 00028: val_mDice did not improve from 0.58630
Epoch 29/300
 - 10s - loss: 0.3465 - acc: 0.9367 - mDice: 0.6923 - val_loss: 0.8381 - val_acc: 0.9447 - val_mDice: 0.5440

Epoch 00029: val_mDice did not improve from 0.58630
Epoch 30/300
 - 10s - loss: 0.3423 - acc: 0.9371 - mDice: 0.6953 - val_loss: 0.7537 - val_acc: 0.9396 - val_mDice: 0.5759

Epoch 00030: val_mDice did not improve from 0.58630
Epoch 31/300
 - 10s - loss: 0.3413 - acc: 0.9373 - mDice: 0.6960 - val_loss: 0.7938 - val_acc: 0.9445 - val_mDice: 0.5671

Epoch 00031: val_mDice did not improve from 0.58630
Epoch 32/300
 - 10s - loss: 0.3394 - acc: 0.9374 - mDice: 0.6975 - val_loss: 0.7453 - val_acc: 0.9403 - val_mDice: 0.5732

Epoch 00032: val_mDice did not improve from 0.58630
Epoch 33/300
 - 10s - loss: 0.3380 - acc: 0.9374 - mDice: 0.6986 - val_loss: 0.8423 - val_acc: 0.9355 - val_mDice: 0.5570

Epoch 00033: val_mDice did not improve from 0.58630
Epoch 34/300
 - 10s - loss: 0.3339 - acc: 0.9377 - mDice: 0.7015 - val_loss: 0.7424 - val_acc: 0.9444 - val_mDice: 0.5837

Epoch 00034: val_mDice did not improve from 0.58630
Epoch 35/300
 - 10s - loss: 0.3340 - acc: 0.9379 - mDice: 0.7015 - val_loss: 0.8525 - val_acc: 0.9309 - val_mDice: 0.5431

Epoch 00035: val_mDice did not improve from 0.58630
Epoch 36/300
 - 10s - loss: 0.3322 - acc: 0.9379 - mDice: 0.7027 - val_loss: 0.7446 - val_acc: 0.9364 - val_mDice: 0.5465

Epoch 00036: val_mDice did not improve from 0.58630
Epoch 37/300
 - 10s - loss: 0.3300 - acc: 0.9382 - mDice: 0.7043 - val_loss: 0.7214 - val_acc: 0.9397 - val_mDice: 0.5499

Epoch 00037: val_mDice did not improve from 0.58630
Epoch 38/300
 - 10s - loss: 0.3282 - acc: 0.9382 - mDice: 0.7057 - val_loss: 0.6727 - val_acc: 0.9465 - val_mDice: 0.5871

Epoch 00038: val_mDice improved from 0.58630 to 0.58706, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 10s - loss: 0.3279 - acc: 0.9383 - mDice: 0.7059 - val_loss: 0.7476 - val_acc: 0.9408 - val_mDice: 0.5689

Epoch 00039: val_mDice did not improve from 0.58706
Epoch 40/300
 - 10s - loss: 0.3274 - acc: 0.9384 - mDice: 0.7063 - val_loss: 0.7219 - val_acc: 0.9417 - val_mDice: 0.5617

Epoch 00040: val_mDice did not improve from 0.58706
Epoch 41/300
 - 10s - loss: 0.3242 - acc: 0.9387 - mDice: 0.7086 - val_loss: 0.6917 - val_acc: 0.9422 - val_mDice: 0.5657

Epoch 00041: val_mDice did not improve from 0.58706
Epoch 42/300
 - 10s - loss: 0.3242 - acc: 0.9387 - mDice: 0.7087 - val_loss: 0.6432 - val_acc: 0.9463 - val_mDice: 0.5700

Epoch 00042: val_mDice did not improve from 0.58706
Epoch 43/300
 - 10s - loss: 0.3240 - acc: 0.9388 - mDice: 0.7089 - val_loss: 0.6799 - val_acc: 0.9455 - val_mDice: 0.5678

Epoch 00043: val_mDice did not improve from 0.58706
Epoch 44/300
 - 10s - loss: 0.3220 - acc: 0.9388 - mDice: 0.7103 - val_loss: 0.6681 - val_acc: 0.9456 - val_mDice: 0.5598

Epoch 00044: val_mDice did not improve from 0.58706
Epoch 45/300
 - 10s - loss: 0.3205 - acc: 0.9392 - mDice: 0.7114 - val_loss: 0.7217 - val_acc: 0.9379 - val_mDice: 0.5722

Epoch 00045: val_mDice did not improve from 0.58706
Epoch 46/300
 - 10s - loss: 0.3190 - acc: 0.9392 - mDice: 0.7125 - val_loss: 0.7724 - val_acc: 0.9361 - val_mDice: 0.5499

Epoch 00046: val_mDice did not improve from 0.58706
Epoch 47/300
 - 10s - loss: 0.3181 - acc: 0.9394 - mDice: 0.7131 - val_loss: 0.7314 - val_acc: 0.9385 - val_mDice: 0.5484

Epoch 00047: val_mDice did not improve from 0.58706
Epoch 48/300
 - 10s - loss: 0.3178 - acc: 0.9395 - mDice: 0.7134 - val_loss: 0.6652 - val_acc: 0.9460 - val_mDice: 0.5417

Epoch 00048: val_mDice did not improve from 0.58706
Epoch 49/300
 - 10s - loss: 0.3167 - acc: 0.9396 - mDice: 0.7143 - val_loss: 0.6179 - val_acc: 0.9473 - val_mDice: 0.5838

Epoch 00049: val_mDice did not improve from 0.58706
Epoch 50/300
 - 10s - loss: 0.3159 - acc: 0.9396 - mDice: 0.7149 - val_loss: 0.7473 - val_acc: 0.9346 - val_mDice: 0.5448

Epoch 00050: val_mDice did not improve from 0.58706
Epoch 51/300
 - 10s - loss: 0.3128 - acc: 0.9398 - mDice: 0.7172 - val_loss: 0.6272 - val_acc: 0.9416 - val_mDice: 0.5716

Epoch 00051: val_mDice did not improve from 0.58706
Epoch 52/300
 - 10s - loss: 0.3124 - acc: 0.9400 - mDice: 0.7174 - val_loss: 0.6317 - val_acc: 0.9419 - val_mDice: 0.5651

Epoch 00052: val_mDice did not improve from 0.58706
Epoch 53/300
 - 10s - loss: 0.3106 - acc: 0.9401 - mDice: 0.7189 - val_loss: 0.5932 - val_acc: 0.9439 - val_mDice: 0.5723

Epoch 00053: val_mDice did not improve from 0.58706
Epoch 54/300
 - 10s - loss: 0.3109 - acc: 0.9402 - mDice: 0.7186 - val_loss: 0.6684 - val_acc: 0.9406 - val_mDice: 0.5452

Epoch 00054: val_mDice did not improve from 0.58706
Epoch 55/300
 - 10s - loss: 0.3108 - acc: 0.9401 - mDice: 0.7187 - val_loss: 0.6107 - val_acc: 0.9419 - val_mDice: 0.5773

Epoch 00055: val_mDice did not improve from 0.58706
Epoch 56/300
 - 10s - loss: 0.3086 - acc: 0.9404 - mDice: 0.7203 - val_loss: 0.6685 - val_acc: 0.9393 - val_mDice: 0.5563

Epoch 00056: val_mDice did not improve from 0.58706
Epoch 57/300
 - 10s - loss: 0.3079 - acc: 0.9406 - mDice: 0.7209 - val_loss: 0.6744 - val_acc: 0.9417 - val_mDice: 0.5157

Epoch 00057: val_mDice did not improve from 0.58706
Epoch 58/300
 - 10s - loss: 0.3079 - acc: 0.9405 - mDice: 0.7209 - val_loss: 0.6167 - val_acc: 0.9409 - val_mDice: 0.5617

Epoch 00058: val_mDice did not improve from 0.58706
Epoch 59/300
 - 10s - loss: 0.3077 - acc: 0.9405 - mDice: 0.7210 - val_loss: 0.5887 - val_acc: 0.9455 - val_mDice: 0.5767

Epoch 00059: val_mDice did not improve from 0.58706
Epoch 60/300
 - 10s - loss: 0.3056 - acc: 0.9406 - mDice: 0.7226 - val_loss: 0.6543 - val_acc: 0.9342 - val_mDice: 0.5616

Epoch 00060: val_mDice did not improve from 0.58706
Epoch 61/300
 - 10s - loss: 0.3054 - acc: 0.9408 - mDice: 0.7228 - val_loss: 0.6117 - val_acc: 0.9467 - val_mDice: 0.5843

Epoch 00061: val_mDice did not improve from 0.58706
Epoch 62/300
 - 10s - loss: 0.3052 - acc: 0.9408 - mDice: 0.7229 - val_loss: 0.6583 - val_acc: 0.9355 - val_mDice: 0.5553

Epoch 00062: val_mDice did not improve from 0.58706
Epoch 63/300
 - 10s - loss: 0.3048 - acc: 0.9409 - mDice: 0.7232 - val_loss: 0.5852 - val_acc: 0.9471 - val_mDice: 0.5641

Epoch 00063: val_mDice did not improve from 0.58706
Epoch 64/300
 - 10s - loss: 0.3035 - acc: 0.9410 - mDice: 0.7241 - val_loss: 0.6020 - val_acc: 0.9411 - val_mDice: 0.5575

Epoch 00064: val_mDice did not improve from 0.58706
Epoch 65/300
 - 10s - loss: 0.3048 - acc: 0.9409 - mDice: 0.7233 - val_loss: 0.5775 - val_acc: 0.9464 - val_mDice: 0.5749

Epoch 00065: val_mDice did not improve from 0.58706
Epoch 66/300
 - 10s - loss: 0.3018 - acc: 0.9412 - mDice: 0.7255 - val_loss: 0.5985 - val_acc: 0.9451 - val_mDice: 0.5557

Epoch 00066: val_mDice did not improve from 0.58706
Epoch 67/300
 - 10s - loss: 0.3012 - acc: 0.9412 - mDice: 0.7259 - val_loss: 0.6083 - val_acc: 0.9418 - val_mDice: 0.5554

Epoch 00067: val_mDice did not improve from 0.58706
Epoch 68/300
 - 10s - loss: 0.3006 - acc: 0.9413 - mDice: 0.7263 - val_loss: 0.6161 - val_acc: 0.9353 - val_mDice: 0.5622

Epoch 00068: val_mDice did not improve from 0.58706
Epoch 69/300
 - 10s - loss: 0.3011 - acc: 0.9415 - mDice: 0.7260 - val_loss: 0.6109 - val_acc: 0.9400 - val_mDice: 0.5548

Epoch 00069: val_mDice did not improve from 0.58706
Epoch 70/300
 - 10s - loss: 0.3009 - acc: 0.9414 - mDice: 0.7262 - val_loss: 0.6238 - val_acc: 0.9390 - val_mDice: 0.5485

Epoch 00070: val_mDice did not improve from 0.58706
Epoch 71/300
 - 10s - loss: 0.2993 - acc: 0.9415 - mDice: 0.7274 - val_loss: 0.6134 - val_acc: 0.9425 - val_mDice: 0.5729

Epoch 00071: val_mDice did not improve from 0.58706
Epoch 72/300
 - 10s - loss: 0.2985 - acc: 0.9416 - mDice: 0.7281 - val_loss: 0.5854 - val_acc: 0.9418 - val_mDice: 0.5665

Epoch 00072: val_mDice did not improve from 0.58706
Epoch 73/300
 - 10s - loss: 0.2972 - acc: 0.9417 - mDice: 0.7289 - val_loss: 0.6099 - val_acc: 0.9462 - val_mDice: 0.5449

Epoch 00073: val_mDice did not improve from 0.58706
Epoch 74/300
 - 10s - loss: 0.2978 - acc: 0.9417 - mDice: 0.7286 - val_loss: 0.5805 - val_acc: 0.9428 - val_mDice: 0.5738

Epoch 00074: val_mDice did not improve from 0.58706
Epoch 75/300
 - 10s - loss: 0.2969 - acc: 0.9418 - mDice: 0.7293 - val_loss: 0.6063 - val_acc: 0.9441 - val_mDice: 0.5526

Epoch 00075: val_mDice did not improve from 0.58706
Epoch 76/300
 - 10s - loss: 0.2969 - acc: 0.9417 - mDice: 0.7292 - val_loss: 0.6399 - val_acc: 0.9394 - val_mDice: 0.5560

Epoch 00076: val_mDice did not improve from 0.58706
Epoch 77/300
 - 10s - loss: 0.2950 - acc: 0.9419 - mDice: 0.7307 - val_loss: 0.5950 - val_acc: 0.9395 - val_mDice: 0.5658

Epoch 00077: val_mDice did not improve from 0.58706
Epoch 78/300
 - 10s - loss: 0.2935 - acc: 0.9422 - mDice: 0.7318 - val_loss: 0.5619 - val_acc: 0.9450 - val_mDice: 0.5591

Epoch 00078: val_mDice did not improve from 0.58706
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
{'val_loss': [2.6606885138012113, 1.6971970058622814, 1.4520300342923118, 1.495913028717041, 1.0481500057947069, 1.018899054754348, 1.0258345831008184, 0.9844478766123453, 0.993161122004191, 0.9937568278539748, 0.9462562742687407, 0.9052555788130987, 0.8773341576258341, 0.9114385729744321, 0.8388122490474156, 0.8897957347688221, 0.8649895985921224, 0.8926529997871036, 0.8758684907640729, 0.8331701755523682, 0.829339549655006, 0.8543670290992373, 0.8071540253502982, 0.7936336937404814, 0.8051006226312547, 0.8219609374091739, 0.7958503904796782, 0.7467732883635021, 0.83814423424857, 0.7536712033408028, 0.7937606743403843, 0.7452566396622431, 0.8422686940147763, 0.7424121073314122, 0.8524500301906041, 0.7446365242912656, 0.7213648727961949, 0.6727007286889213, 0.7476448331560407, 0.7219155629475912, 0.691655090876988, 0.6431712139220465, 0.6798717351186843, 0.6680950550805955, 0.7217167104993548, 0.7724440779004779, 0.7313882282802037, 0.6651687735602969, 0.6178965795607794, 0.7473017261141822, 0.6271625246320452, 0.6317151387532552, 0.5931524833043417, 0.6684069406418574, 0.61072952406747, 0.6684624467577253, 0.6743691535223097, 0.6167287485940116, 0.5887366306214106, 0.6543240547180176, 0.6116910832268851, 0.658277568363008, 0.585176081884475, 0.6020159267243885, 0.5774858508791242, 0.5985002971830822, 0.6082596097673688, 0.6160906610034761, 0.6108518100920177, 0.6238194647289458, 0.6133580491656349, 0.5853956086294991, 0.6099096479870024, 0.5804769879295713, 0.6062891596839541, 0.6399148872920445, 0.5949668146315075, 0.5618881838662284], 'val_acc': [0.750691416717711, 0.8866964152881077, 0.9105632049696786, 0.9173786469868251, 0.9393589524995714, 0.94308150382269, 0.942314536798568, 0.9432646518661862, 0.9435508336339679, 0.9441277640206474, 0.9461950546219235, 0.9463164153553191, 0.9398054139954704, 0.9463049485569909, 0.9438209817523048, 0.94132323492141, 0.9434683890569777, 0.9465133008502778, 0.9405013748577663, 0.945146537962414, 0.9447000736281985, 0.9437202442260015, 0.9434592383248466, 0.9419001596314567, 0.9432806826773144, 0.9368360865683782, 0.9467055996259054, 0.9443681240081787, 0.9447252523331415, 0.9396085341771444, 0.9444574344725836, 0.940286173706963, 0.935492197672526, 0.944407065709432, 0.9308928790546599, 0.9364331393014818, 0.9397184110823131, 0.946456029301598, 0.9407692211014884, 0.9417101371855963, 0.9421955091612679, 0.9462706106049674, 0.9454555596624102, 0.945583789121537, 0.9379166563351949, 0.9360714072272891, 0.9384844501813253, 0.9460393729664031, 0.9472962475958324, 0.9345741782869611, 0.9415613725071862, 0.9419001738230387, 0.943889646303086, 0.9406410058339437, 0.9418543804259527, 0.9392902680805751, 0.9416575233141581, 0.9408676681064424, 0.945451001326243, 0.9341643651326498, 0.9467170408793858, 0.9355059351239886, 0.9471039232753572, 0.941135551248278, 0.9463736414909363, 0.9451442332494826, 0.9417971628052848, 0.9353411197662354, 0.9400435033298674, 0.9390384554862976, 0.942477129754566, 0.9418131709098816, 0.9462271048909142, 0.9428182187534514, 0.9441231602714175, 0.9393635534104847, 0.9394665899730864, 0.9449999928474426], 'val_mDice': [0.18101079584587187, 0.367233112365717, 0.3572700956927812, 0.33983865322181284, 0.5415308863988945, 0.5561394038654509, 0.5380439368032274, 0.5672895076374213, 0.5484676556218238, 0.5378895669820762, 0.5634123702489194, 0.5651259681298619, 0.5798404165321872, 0.5697062207119805, 0.5863038425644239, 0.5614981727585906, 0.5476608423604852, 0.5600649100683984, 0.5664211965742565, 0.5774272733501026, 0.5598011251006808, 0.5500219137895674, 0.586015560442493, 0.5861506529507183, 0.553434645490987, 0.5468203404120037, 0.5534253858384632, 0.5696206440528234, 0.5439861175559816, 0.5759421739549864, 0.5670616605452129, 0.5732042761076064, 0.5569996819609687, 0.583714386891751, 0.5430920901043075, 0.5465361474170571, 0.5499180787730784, 0.5870606093889191, 0.5688648241616431, 0.5617196063200632, 0.5657114569275152, 0.5700005255639553, 0.5677535576479775, 0.5598033900771823, 0.5721725230770451, 0.5499060008497465, 0.5484464682993435, 0.5416933785946596, 0.5837799530653727, 0.5447860789440927, 0.5715968427913529, 0.5651234491240411, 0.5722744745158014, 0.5452327593451455, 0.5773287399538926, 0.5562570492426554, 0.5156811525424322, 0.561671067561422, 0.5767393834179356, 0.5616196816166242, 0.5843130208197094, 0.5553040149666014, 0.5641131825035527, 0.5575350585083166, 0.5749040535163312, 0.5556761343919095, 0.5553545121635709, 0.562153737459864, 0.5548422357865742, 0.5484796915025938, 0.5729387109833104, 0.566500801060881, 0.5448625788447403, 0.5738021062598342, 0.5525811958525862, 0.5560397534143358, 0.5658258091480959, 0.5590598998325211], 'loss': [3.170818759959765, 1.5859658249499642, 0.8672141845869333, 0.6179077324321188, 0.5472134989776982, 0.5084723324784429, 0.47921314910815493, 0.4586048586384189, 0.43998056467452307, 0.42907286572254116, 0.42123446541874077, 0.41150799858471276, 0.4029643385424558, 0.3972666832794912, 0.39318809966395674, 0.3861950746110255, 0.38133237898315286, 0.37761668271703114, 0.370652011221306, 0.3718148670905308, 0.3672368033602906, 0.36346590301193943, 0.3599862050051769, 0.35808436626847456, 0.35304159878052704, 0.35318187349721003, 0.3488550624257686, 0.3476218438766723, 0.34646548984343545, 0.3423088312103083, 0.3413344617751331, 0.3393858539154931, 0.33798550239688563, 0.33385025170213894, 0.3339911722507186, 0.3322049940347166, 0.32999102034986144, 0.3281846944998978, 0.3279363557348735, 0.3273607095657159, 0.32415338154470663, 0.32420420470278183, 0.3239579000338806, 0.3220272115287189, 0.3205042841785189, 0.3189506510767101, 0.3181282853216065, 0.31780343385981025, 0.31666238787823703, 0.31588970033654085, 0.3127806744284544, 0.31235643328442747, 0.3105698822549894, 0.3108767006113186, 0.31080412060303886, 0.3086471027932186, 0.3079183796179738, 0.30792040195289505, 0.30765461043192743, 0.3056348733803613, 0.3054146192736632, 0.3052183304686571, 0.3048213035046353, 0.30353111768127383, 0.30477736374075665, 0.3017937614838696, 0.30115787740362293, 0.3006449507131773, 0.30110511273369756, 0.30088895324891257, 0.29931392136717755, 0.2984547607926751, 0.2972043582256391, 0.29775362049703635, 0.2969245745803847, 0.2968777505814144, 0.29495823931459614, 0.29348404714430093], 'acc': [0.45855487925895544, 0.7068439379279867, 0.8780755528094614, 0.8988661104621101, 0.9167363693058227, 0.9221072056653391, 0.9251467459160905, 0.9270435450783533, 0.9289685506822517, 0.9298491929453969, 0.9305731732421972, 0.9313996665873508, 0.9322417317867188, 0.9326360004932315, 0.9330052910959741, 0.9336440890470129, 0.9340087484826191, 0.9342358290678002, 0.9348203635339863, 0.9344524414364211, 0.9348924719967868, 0.935344905448323, 0.935470055449048, 0.9358583686322819, 0.9361847898324422, 0.9359803698369481, 0.9364991373401721, 0.93666433466407, 0.9366737429360698, 0.9371445396857981, 0.9372592679746858, 0.9373844188487389, 0.9374494391621159, 0.9377186944977911, 0.9379097964116919, 0.9378501972711819, 0.9381613495240948, 0.9382425681092685, 0.9383272132203371, 0.938388038766345, 0.9386588692871941, 0.9387119066078631, 0.9387890032106726, 0.9388069604342674, 0.9392339259598649, 0.9391613005212858, 0.9394343833209049, 0.9395431540870519, 0.9395512158364626, 0.9396291882035267, 0.9398423923516701, 0.9400122219228735, 0.9401053722386924, 0.9401764172751113, 0.940141496882173, 0.9403922395460725, 0.9405698764639046, 0.9405306433583354, 0.9405488345419393, 0.9406203847412248, 0.9408046989305782, 0.9408135962022024, 0.9408858445353974, 0.9410246213392093, 0.9408821578956142, 0.9411934285189619, 0.9411988463479015, 0.9412755523547056, 0.9414889595516389, 0.9413675398341212, 0.9415008485696439, 0.9416425929194543, 0.9417432743459164, 0.9416679602517819, 0.9417874386987637, 0.9416678258626705, 0.9419472291218147, 0.9422319632792763], 'mDice': [0.08562575394500652, 0.25733815437225516, 0.42755030163087804, 0.5213942029169581, 0.5609508814415491, 0.5840781717854748, 0.6020570971015701, 0.6153330330056264, 0.6275668703270988, 0.6348573668788617, 0.640170091076901, 0.6467253079482396, 0.6524052409416038, 0.656344712136774, 0.6591992647127998, 0.664050875094807, 0.6676046484487007, 0.670084464359265, 0.6749715102254391, 0.6741309661683215, 0.6773743589236508, 0.6800958451012185, 0.6824141460989215, 0.6839937683311942, 0.6874931744580465, 0.687459722393989, 0.69060425833514, 0.6914542914126359, 0.6923286207314744, 0.6953180586875738, 0.6960291684834465, 0.6974927550546232, 0.6985632887184448, 0.7014546635892319, 0.7014596415595648, 0.7027218110165615, 0.7043232866305249, 0.7057093775798664, 0.705897367388981, 0.7062976731255677, 0.7086101098397989, 0.7086590591574625, 0.7089084089089617, 0.710292893037967, 0.7114083804513348, 0.7125010815962032, 0.7131423286695758, 0.7134470494468708, 0.7143318019943796, 0.7148780224524138, 0.7171712727911651, 0.7174340369776308, 0.7188617011497355, 0.7186238637934859, 0.7186950069069518, 0.7202812413478004, 0.7208840864137208, 0.7208670670411158, 0.7209792105200572, 0.7225758790372309, 0.7227678619553548, 0.7228766748251105, 0.723186789230963, 0.7241485975761737, 0.7232955689717057, 0.7254764988676579, 0.7259340654201812, 0.7263239832634133, 0.7260291891243271, 0.7262367632937426, 0.7274258919297235, 0.7280648156629952, 0.7289458266889426, 0.7285861538765126, 0.7292967782053663, 0.7291982393056091, 0.7306924760858746, 0.7318088391945499]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.46s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.22s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:07,  1.93s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:17,  1.76s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:18,  1.77s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:47,  1.66s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:16,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:55,  1.70s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:13,  1.78s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:57,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:12,  1.78s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:22,  1.83s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:34,  1.89s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:21,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:23,  1.86s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:29,  1.89s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:39,  1.93s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:12,  1.84s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:12,  1.84s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:49,  1.77s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:56,  1.80s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:16,  1.88s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:48,  1.78s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<07:46,  1.78s/it]predicting train subjects:   8%|▊         | 24/285 [00:42<07:20,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:31,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:46<07:41,  1.78s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:22,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:32,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:29,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:36,  1.79s/it]predicting train subjects:  11%|█         | 31/285 [00:55<07:52,  1.86s/it]predicting train subjects:  11%|█         | 32/285 [00:57<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:28,  1.78s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:26,  1.78s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:28,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:08,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:18,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:28,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:09,  1.75s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:24,  1.81s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:11,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<06:52,  1.70s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<07:00,  1.74s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:06,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<06:49,  1.71s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:01,  1.76s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:53,  1.75s/it]predicting train subjects:  17%|█▋        | 49/285 [01:27<07:06,  1.81s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:01,  1.80s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:09,  1.84s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:46,  1.75s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<06:47,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<06:55,  1.80s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:33,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:35,  1.73s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:24,  1.69s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:41,  1.77s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:52,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:33,  1.75s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:36,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:36,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:27,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:23,  1.75s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:23,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:08,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:20,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:22,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:29,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:14,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:07,  1.73s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:02,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<05:57,  1.70s/it]predicting train subjects:  27%|██▋       | 76/285 [02:14<06:00,  1.73s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<05:50,  1.69s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:41,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:19<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:40,  1.67s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:41,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:25<05:31,  1.64s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:28,  1.63s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:31<05:43,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:32<05:45,  1.75s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:37,  1.71s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:38,  1.73s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:42,  1.76s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:30,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:36,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:31,  1.73s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:29,  1.72s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:36,  1.77s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:32,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:34,  1.78s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:29,  1.76s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:25,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:28,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:21,  1.76s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:12,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:12,  1.73s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:13,  1.74s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:09,  1.73s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:09,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<05:01,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:01,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:12<05:04,  1.74s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<05:00,  1.72s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:06,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:12,  1.82s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:04,  1.78s/it]predicting train subjects:  40%|████      | 115/285 [03:21<05:02,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:23<05:03,  1.80s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:56,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [03:26<04:48,  1.73s/it]predicting train subjects:  42%|████▏     | 119/285 [03:28<04:50,  1.75s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:40,  1.70s/it]predicting train subjects:  42%|████▏     | 121/285 [03:31<04:28,  1.64s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:13,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:34<04:03,  1.50s/it]predicting train subjects:  44%|████▎     | 124/285 [03:36<04:01,  1.50s/it]predicting train subjects:  44%|████▍     | 125/285 [03:37<03:56,  1.48s/it]predicting train subjects:  44%|████▍     | 126/285 [03:38<03:51,  1.46s/it]predicting train subjects:  45%|████▍     | 127/285 [03:40<03:48,  1.44s/it]predicting train subjects:  45%|████▍     | 128/285 [03:41<03:52,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:43<03:47,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:44<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:46<03:38,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [03:47<03:46,  1.48s/it]predicting train subjects:  47%|████▋     | 133/285 [03:49<03:44,  1.47s/it]predicting train subjects:  47%|████▋     | 134/285 [03:50<03:43,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:52<03:38,  1.45s/it]predicting train subjects:  48%|████▊     | 136/285 [03:53<03:35,  1.45s/it]predicting train subjects:  48%|████▊     | 137/285 [03:55<03:38,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:56<03:32,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:58<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:59<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [04:00<03:32,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [04:02<03:29,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [04:03<03:26,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [04:05<03:29,  1.48s/it]predicting train subjects:  51%|█████     | 145/285 [04:06<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:08<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:09<03:22,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:11<03:23,  1.49s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:12<03:18,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:14<03:15,  1.45s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:15<03:19,  1.49s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:17<03:14,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:18<03:09,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:20<03:12,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:21<03:08,  1.45s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:23<03:12,  1.50s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:24<03:10,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:25<03:06,  1.47s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:27<03:01,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:28<02:58,  1.43s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:30<03:02,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:31<02:59,  1.46s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:33<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:34<02:58,  1.48s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:36<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:37<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:39<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:40<02:51,  1.47s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:42<02:47,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:43<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:44<02:41,  1.41s/it]predicting train subjects:  60%|██████    | 172/285 [04:46<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:47<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:48<02:32,  1.37s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:50<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:51<02:38,  1.45s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:53<02:33,  1.42s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:54<02:30,  1.41s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:56<02:27,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:57<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:59<02:40,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:01<02:40,  1.56s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:02<02:32,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:03<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:05<02:24,  1.44s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:06<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:08<02:36,  1.60s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:10<02:41,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:11<02:29,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:13<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:14<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:16<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:17<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:19<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:20<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:22<02:17,  1.54s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:24<02:22,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:25<02:25,  1.67s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:27<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:28<02:08,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:30<02:13,  1.59s/it]predicting train subjects:  71%|███████   | 202/285 [05:31<02:11,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:33<02:09,  1.58s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:34<02:02,  1.52s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:36<01:57,  1.47s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:37<01:53,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:39<02:00,  1.55s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:41<02:05,  1.63s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:43<02:08,  1.69s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:44<01:58,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:45<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:47<01:52,  1.54s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:49<01:52,  1.56s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:50<01:46,  1.50s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:52<01:51,  1.59s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:53<01:44,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:55<01:47,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:57<01:50,  1.65s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:58<01:53,  1.73s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:00<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:01<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:03<01:39,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:04<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:06<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:07<01:26,  1.44s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:09<01:31,  1.55s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:11<01:34,  1.62s/it]predicting train subjects:  80%|████████  | 228/285 [06:12<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [06:14<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:25,  1.56s/it]predicting train subjects:  81%|████████  | 231/285 [06:17<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:22,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:21<01:20,  1.58s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:23<01:14,  1.49s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:24<01:16,  1.55s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:26<01:16,  1.60s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:28<01:16,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:30<01:14,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:31<01:09,  1.55s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:32<01:06,  1.50s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:34<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<00:59,  1.42s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:37<01:02,  1.53s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:38<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:01,  1.58s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:03,  1.66s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:43<01:00,  1.64s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:45<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:46<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:48<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:49<00:47,  1.44s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:51<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:53<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:54<00:49,  1.64s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:56<00:45,  1.58s/it]predicting train subjects:  90%|█████████ | 257/285 [06:57<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [06:59<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [07:01<00:42,  1.62s/it]predicting train subjects:  91%|█████████ | 260/285 [07:02<00:38,  1.54s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:03<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:05<00:33,  1.44s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:06<00:30,  1.41s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:08<00:31,  1.51s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:09<00:31,  1.59s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:11<00:29,  1.53s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:12<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:14<00:26,  1.59s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:16<00:25,  1.61s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:17<00:22,  1.51s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:18<00:20,  1.46s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:20<00:19,  1.53s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:21<00:17,  1.46s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:23<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:25<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:26<00:14,  1.63s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:28<00:12,  1.54s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:29<00:10,  1.51s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:31<00:09,  1.54s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:32<00:07,  1.50s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:34<00:05,  1.48s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:35<00:04,  1.44s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:37<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:39<00:01,  1.64s/it]predicting train subjects: 100%|██████████| 285/285 [07:40<00:00,  1.68s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:14,  1.74s/it]Loading train:   1%|          | 2/285 [00:03<07:37,  1.62s/it]Loading train:   1%|          | 3/285 [00:04<07:35,  1.62s/it]Loading train:   1%|▏         | 4/285 [00:05<07:08,  1.52s/it]Loading train:   2%|▏         | 5/285 [00:07<07:26,  1.59s/it]Loading train:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]Loading train:   2%|▏         | 7/285 [00:10<07:10,  1.55s/it]Loading train:   3%|▎         | 8/285 [00:12<06:58,  1.51s/it]Loading train:   3%|▎         | 9/285 [00:13<07:23,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<06:59,  1.53s/it]Loading train:   4%|▍         | 11/285 [00:16<06:15,  1.37s/it]Loading train:   4%|▍         | 12/285 [00:17<06:10,  1.36s/it]Loading train:   5%|▍         | 13/285 [00:18<05:48,  1.28s/it]Loading train:   5%|▍         | 14/285 [00:19<05:41,  1.26s/it]Loading train:   5%|▌         | 15/285 [00:21<05:45,  1.28s/it]Loading train:   6%|▌         | 16/285 [00:22<05:46,  1.29s/it]Loading train:   6%|▌         | 17/285 [00:23<05:24,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:24<05:21,  1.21s/it]Loading train:   7%|▋         | 19/285 [00:25<04:57,  1.12s/it]Loading train:   7%|▋         | 20/285 [00:26<05:02,  1.14s/it]Loading train:   7%|▋         | 21/285 [00:28<05:32,  1.26s/it]Loading train:   8%|▊         | 22/285 [00:29<05:21,  1.22s/it]Loading train:   8%|▊         | 23/285 [00:30<05:06,  1.17s/it]Loading train:   8%|▊         | 24/285 [00:31<04:55,  1.13s/it]Loading train:   9%|▉         | 25/285 [00:33<05:13,  1.20s/it]Loading train:   9%|▉         | 26/285 [00:34<05:24,  1.25s/it]Loading train:   9%|▉         | 27/285 [00:35<05:05,  1.19s/it]Loading train:  10%|▉         | 28/285 [00:36<04:59,  1.16s/it]Loading train:  10%|█         | 29/285 [00:37<04:43,  1.11s/it]Loading train:  11%|█         | 30/285 [00:38<05:03,  1.19s/it]Loading train:  11%|█         | 31/285 [00:40<05:11,  1.23s/it]Loading train:  11%|█         | 32/285 [00:41<04:57,  1.18s/it]Loading train:  12%|█▏        | 33/285 [00:42<04:56,  1.18s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:45,  1.14s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:41,  1.13s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:14,  1.02s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:08,  1.00s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:15,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:02,  1.02it/s]Loading train:  14%|█▍        | 40/285 [00:49<04:02,  1.01it/s]Loading train:  14%|█▍        | 41/285 [00:50<03:56,  1.03it/s]Loading train:  15%|█▍        | 42/285 [00:51<04:07,  1.02s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:19,  1.07s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:33,  1.13s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:28,  1.12s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:37,  1.16s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:24,  1.11s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:29,  1.14s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:35,  1.17s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:38,  1.18s/it]Loading train:  18%|█▊        | 51/285 [01:02<04:42,  1.21s/it]Loading train:  18%|█▊        | 52/285 [01:03<04:39,  1.20s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:35,  1.19s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:32,  1.18s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:23,  1.15s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:15,  1.12s/it]Loading train:  20%|██        | 57/285 [01:08<04:08,  1.09s/it]Loading train:  20%|██        | 58/285 [01:09<04:08,  1.10s/it]Loading train:  21%|██        | 59/285 [01:11<04:12,  1.12s/it]Loading train:  21%|██        | 60/285 [01:12<04:24,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:21,  1.17s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:20,  1.17s/it]Loading train:  22%|██▏       | 63/285 [01:15<04:16,  1.16s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:46,  1.30s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:06,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:14,  1.43s/it]Loading train:  24%|██▎       | 67/285 [01:21<04:57,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:22<04:40,  1.29s/it]Loading train:  24%|██▍       | 69/285 [01:24<04:31,  1.26s/it]Loading train:  25%|██▍       | 70/285 [01:25<04:24,  1.23s/it]Loading train:  25%|██▍       | 71/285 [01:26<04:20,  1.22s/it]Loading train:  25%|██▌       | 72/285 [01:27<04:08,  1.17s/it]Loading train:  26%|██▌       | 73/285 [01:28<04:03,  1.15s/it]Loading train:  26%|██▌       | 74/285 [01:29<03:59,  1.13s/it]Loading train:  26%|██▋       | 75/285 [01:30<03:54,  1.12s/it]Loading train:  27%|██▋       | 76/285 [01:31<03:54,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:32<03:40,  1.06s/it]Loading train:  27%|██▋       | 78/285 [01:34<03:52,  1.12s/it]Loading train:  28%|██▊       | 79/285 [01:35<04:00,  1.17s/it]Loading train:  28%|██▊       | 80/285 [01:36<03:51,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:37<03:46,  1.11s/it]Loading train:  29%|██▉       | 82/285 [01:38<03:51,  1.14s/it]Loading train:  29%|██▉       | 83/285 [01:39<03:36,  1.07s/it]Loading train:  29%|██▉       | 84/285 [01:40<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:41<03:24,  1.02s/it]Loading train:  30%|███       | 86/285 [01:42<03:29,  1.05s/it]Loading train:  31%|███       | 87/285 [01:43<03:45,  1.14s/it]Loading train:  31%|███       | 88/285 [01:45<03:45,  1.15s/it]Loading train:  31%|███       | 89/285 [01:46<03:47,  1.16s/it]Loading train:  32%|███▏      | 90/285 [01:47<03:42,  1.14s/it]Loading train:  32%|███▏      | 91/285 [01:48<03:32,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:49<03:30,  1.09s/it]Loading train:  33%|███▎      | 93/285 [01:50<03:33,  1.11s/it]Loading train:  33%|███▎      | 94/285 [01:52<03:51,  1.21s/it]Loading train:  33%|███▎      | 95/285 [01:53<03:51,  1.22s/it]Loading train:  34%|███▎      | 96/285 [01:54<03:49,  1.21s/it]Loading train:  34%|███▍      | 97/285 [01:55<03:43,  1.19s/it]Loading train:  34%|███▍      | 98/285 [01:56<03:39,  1.17s/it]Loading train:  35%|███▍      | 99/285 [01:57<03:28,  1.12s/it]Loading train:  35%|███▌      | 100/285 [01:58<03:26,  1.12s/it]Loading train:  35%|███▌      | 101/285 [01:59<03:17,  1.07s/it]Loading train:  36%|███▌      | 102/285 [02:00<03:12,  1.05s/it]Loading train:  36%|███▌      | 103/285 [02:02<03:17,  1.08s/it]Loading train:  36%|███▋      | 104/285 [02:03<03:18,  1.09s/it]Loading train:  37%|███▋      | 105/285 [02:04<03:18,  1.10s/it]Loading train:  37%|███▋      | 106/285 [02:05<03:07,  1.05s/it]Loading train:  38%|███▊      | 107/285 [02:06<03:02,  1.02s/it]Loading train:  38%|███▊      | 108/285 [02:07<02:59,  1.01s/it]Loading train:  38%|███▊      | 109/285 [02:08<03:19,  1.13s/it]Loading train:  39%|███▊      | 110/285 [02:10<03:33,  1.22s/it]Loading train:  39%|███▉      | 111/285 [02:11<03:26,  1.19s/it]Loading train:  39%|███▉      | 112/285 [02:12<03:27,  1.20s/it]Loading train:  40%|███▉      | 113/285 [02:13<03:27,  1.21s/it]Loading train:  40%|████      | 114/285 [02:14<03:16,  1.15s/it]Loading train:  40%|████      | 115/285 [02:15<03:16,  1.16s/it]Loading train:  41%|████      | 116/285 [02:17<03:24,  1.21s/it]Loading train:  41%|████      | 117/285 [02:18<03:19,  1.19s/it]Loading train:  41%|████▏     | 118/285 [02:19<03:23,  1.22s/it]Loading train:  42%|████▏     | 119/285 [02:20<03:16,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:21<03:09,  1.15s/it]Loading train:  42%|████▏     | 121/285 [02:23<03:24,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:24<03:24,  1.26s/it]Loading train:  43%|████▎     | 123/285 [02:25<03:23,  1.25s/it]Loading train:  44%|████▎     | 124/285 [02:26<03:15,  1.21s/it]Loading train:  44%|████▍     | 125/285 [02:27<03:04,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:28<02:56,  1.11s/it]Loading train:  45%|████▍     | 127/285 [02:29<02:46,  1.05s/it]Loading train:  45%|████▍     | 128/285 [02:30<02:43,  1.04s/it]Loading train:  45%|████▌     | 129/285 [02:31<02:37,  1.01s/it]Loading train:  46%|████▌     | 130/285 [02:32<02:31,  1.02it/s]Loading train:  46%|████▌     | 131/285 [02:33<02:29,  1.03it/s]Loading train:  46%|████▋     | 132/285 [02:34<02:32,  1.00it/s]Loading train:  47%|████▋     | 133/285 [02:35<02:28,  1.02it/s]Loading train:  47%|████▋     | 134/285 [02:36<02:35,  1.03s/it]Loading train:  47%|████▋     | 135/285 [02:37<02:29,  1.01it/s]Loading train:  48%|████▊     | 136/285 [02:38<02:22,  1.05it/s]Loading train:  48%|████▊     | 137/285 [02:39<02:27,  1.00it/s]Loading train:  48%|████▊     | 138/285 [02:40<02:24,  1.02it/s]Loading train:  49%|████▉     | 139/285 [02:41<02:26,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:42<02:24,  1.00it/s]Loading train:  49%|████▉     | 141/285 [02:43<02:32,  1.06s/it]Loading train:  50%|████▉     | 142/285 [02:44<02:28,  1.04s/it]Loading train:  50%|█████     | 143/285 [02:45<02:27,  1.04s/it]Loading train:  51%|█████     | 144/285 [02:46<02:23,  1.01s/it]Loading train:  51%|█████     | 145/285 [02:47<02:21,  1.01s/it]Loading train:  51%|█████     | 146/285 [02:48<02:16,  1.01it/s]Loading train:  52%|█████▏    | 147/285 [02:49<02:14,  1.03it/s]Loading train:  52%|█████▏    | 148/285 [02:50<02:25,  1.06s/it]Loading train:  52%|█████▏    | 149/285 [02:51<02:22,  1.05s/it]Loading train:  53%|█████▎    | 150/285 [02:52<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:54<02:29,  1.11s/it]Loading train:  53%|█████▎    | 152/285 [02:55<02:22,  1.07s/it]Loading train:  54%|█████▎    | 153/285 [02:56<02:21,  1.07s/it]Loading train:  54%|█████▍    | 154/285 [02:57<02:23,  1.10s/it]Loading train:  54%|█████▍    | 155/285 [02:58<02:25,  1.12s/it]Loading train:  55%|█████▍    | 156/285 [02:59<02:28,  1.15s/it]Loading train:  55%|█████▌    | 157/285 [03:00<02:24,  1.13s/it]Loading train:  55%|█████▌    | 158/285 [03:02<02:22,  1.12s/it]Loading train:  56%|█████▌    | 159/285 [03:03<02:21,  1.12s/it]Loading train:  56%|█████▌    | 160/285 [03:04<02:13,  1.07s/it]Loading train:  56%|█████▋    | 161/285 [03:05<02:13,  1.08s/it]Loading train:  57%|█████▋    | 162/285 [03:06<02:10,  1.06s/it]Loading train:  57%|█████▋    | 163/285 [03:07<02:05,  1.03s/it]Loading train:  58%|█████▊    | 164/285 [03:08<02:10,  1.08s/it]Loading train:  58%|█████▊    | 165/285 [03:09<02:03,  1.03s/it]Loading train:  58%|█████▊    | 166/285 [03:10<02:07,  1.07s/it]Loading train:  59%|█████▊    | 167/285 [03:11<02:04,  1.05s/it]Loading train:  59%|█████▉    | 168/285 [03:12<01:57,  1.01s/it]Loading train:  59%|█████▉    | 169/285 [03:13<01:54,  1.01it/s]Loading train:  60%|█████▉    | 170/285 [03:14<01:54,  1.01it/s]Loading train:  60%|██████    | 171/285 [03:15<01:53,  1.00it/s]Loading train:  60%|██████    | 172/285 [03:16<01:51,  1.01it/s]Loading train:  61%|██████    | 173/285 [03:17<01:52,  1.00s/it]Loading train:  61%|██████    | 174/285 [03:18<01:50,  1.01it/s]Loading train:  61%|██████▏   | 175/285 [03:19<01:58,  1.08s/it]Loading train:  62%|██████▏   | 176/285 [03:20<01:56,  1.07s/it]Loading train:  62%|██████▏   | 177/285 [03:21<01:54,  1.06s/it]Loading train:  62%|██████▏   | 178/285 [03:22<01:50,  1.03s/it]Loading train:  63%|██████▎   | 179/285 [03:23<01:48,  1.02s/it]Loading train:  63%|██████▎   | 180/285 [03:24<01:57,  1.12s/it]Loading train:  64%|██████▎   | 181/285 [03:26<01:54,  1.10s/it]Loading train:  64%|██████▍   | 182/285 [03:27<01:55,  1.12s/it]Loading train:  64%|██████▍   | 183/285 [03:28<01:51,  1.10s/it]Loading train:  65%|██████▍   | 184/285 [03:29<01:51,  1.11s/it]Loading train:  65%|██████▍   | 185/285 [03:30<01:48,  1.08s/it]Loading train:  65%|██████▌   | 186/285 [03:31<01:51,  1.12s/it]Loading train:  66%|██████▌   | 187/285 [03:32<01:47,  1.10s/it]Loading train:  66%|██████▌   | 188/285 [03:34<01:54,  1.18s/it]Loading train:  66%|██████▋   | 189/285 [03:34<01:46,  1.11s/it]Loading train:  67%|██████▋   | 190/285 [03:36<01:47,  1.13s/it]Loading train:  67%|██████▋   | 191/285 [03:37<01:46,  1.13s/it]Loading train:  67%|██████▋   | 192/285 [03:38<01:39,  1.07s/it]Loading train:  68%|██████▊   | 193/285 [03:39<01:35,  1.04s/it]Loading train:  68%|██████▊   | 194/285 [03:40<01:36,  1.06s/it]Loading train:  68%|██████▊   | 195/285 [03:41<01:34,  1.05s/it]Loading train:  69%|██████▉   | 196/285 [03:42<01:37,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:43<01:44,  1.18s/it]Loading train:  69%|██████▉   | 198/285 [03:45<01:44,  1.20s/it]Loading train:  70%|██████▉   | 199/285 [03:46<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [03:46<01:30,  1.07s/it]Loading train:  71%|███████   | 201/285 [03:48<01:29,  1.07s/it]Loading train:  71%|███████   | 202/285 [03:49<01:30,  1.09s/it]Loading train:  71%|███████   | 203/285 [03:50<01:29,  1.09s/it]Loading train:  72%|███████▏  | 204/285 [03:51<01:27,  1.08s/it]Loading train:  72%|███████▏  | 205/285 [03:52<01:21,  1.02s/it]Loading train:  72%|███████▏  | 206/285 [03:53<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [03:54<01:22,  1.06s/it]Loading train:  73%|███████▎  | 208/285 [03:55<01:23,  1.09s/it]Loading train:  73%|███████▎  | 209/285 [03:56<01:25,  1.12s/it]Loading train:  74%|███████▎  | 210/285 [03:57<01:16,  1.02s/it]Loading train:  74%|███████▍  | 211/285 [03:58<01:11,  1.04it/s]Loading train:  74%|███████▍  | 212/285 [03:59<01:10,  1.04it/s]Loading train:  75%|███████▍  | 213/285 [04:00<01:13,  1.02s/it]Loading train:  75%|███████▌  | 214/285 [04:01<01:08,  1.03it/s]Loading train:  75%|███████▌  | 215/285 [04:02<01:13,  1.05s/it]Loading train:  76%|███████▌  | 216/285 [04:03<01:10,  1.02s/it]Loading train:  76%|███████▌  | 217/285 [04:04<01:12,  1.06s/it]Loading train:  76%|███████▋  | 218/285 [04:05<01:14,  1.12s/it]Loading train:  77%|███████▋  | 219/285 [04:07<01:12,  1.10s/it]Loading train:  77%|███████▋  | 220/285 [04:08<01:09,  1.07s/it]Loading train:  78%|███████▊  | 221/285 [04:08<01:05,  1.03s/it]Loading train:  78%|███████▊  | 222/285 [04:10<01:09,  1.10s/it]Loading train:  78%|███████▊  | 223/285 [04:11<01:07,  1.09s/it]Loading train:  79%|███████▊  | 224/285 [04:12<01:06,  1.09s/it]Loading train:  79%|███████▉  | 225/285 [04:13<01:02,  1.05s/it]Loading train:  79%|███████▉  | 226/285 [04:14<01:02,  1.06s/it]Loading train:  80%|███████▉  | 227/285 [04:15<01:06,  1.14s/it]Loading train:  80%|████████  | 228/285 [04:16<01:05,  1.14s/it]Loading train:  80%|████████  | 229/285 [04:17<00:59,  1.06s/it]Loading train:  81%|████████  | 230/285 [04:18<01:00,  1.09s/it]Loading train:  81%|████████  | 231/285 [04:19<00:58,  1.08s/it]Loading train:  81%|████████▏ | 232/285 [04:21<00:56,  1.07s/it]Loading train:  82%|████████▏ | 233/285 [04:22<00:56,  1.09s/it]Loading train:  82%|████████▏ | 234/285 [04:23<00:55,  1.08s/it]Loading train:  82%|████████▏ | 235/285 [04:24<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [04:25<00:53,  1.10s/it]Loading train:  83%|████████▎ | 237/285 [04:26<00:51,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [04:27<00:53,  1.15s/it]Loading train:  84%|████████▍ | 239/285 [04:28<00:51,  1.12s/it]Loading train:  84%|████████▍ | 240/285 [04:29<00:49,  1.11s/it]Loading train:  85%|████████▍ | 241/285 [04:30<00:47,  1.08s/it]Loading train:  85%|████████▍ | 242/285 [04:32<00:46,  1.08s/it]Loading train:  85%|████████▌ | 243/285 [04:33<00:44,  1.06s/it]Loading train:  86%|████████▌ | 244/285 [04:34<00:44,  1.08s/it]Loading train:  86%|████████▌ | 245/285 [04:35<00:42,  1.06s/it]Loading train:  86%|████████▋ | 246/285 [04:36<00:42,  1.08s/it]Loading train:  87%|████████▋ | 247/285 [04:37<00:41,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [04:38<00:37,  1.03s/it]Loading train:  87%|████████▋ | 249/285 [04:39<00:37,  1.05s/it]Loading train:  88%|████████▊ | 250/285 [04:40<00:36,  1.04s/it]Loading train:  88%|████████▊ | 251/285 [04:41<00:33,  1.00it/s]Loading train:  88%|████████▊ | 252/285 [04:42<00:32,  1.00it/s]Loading train:  89%|████████▉ | 253/285 [04:43<00:33,  1.04s/it]Loading train:  89%|████████▉ | 254/285 [04:44<00:34,  1.10s/it]Loading train:  89%|████████▉ | 255/285 [04:45<00:31,  1.06s/it]Loading train:  90%|████████▉ | 256/285 [04:46<00:30,  1.04s/it]Loading train:  90%|█████████ | 257/285 [04:47<00:28,  1.02s/it]Loading train:  91%|█████████ | 258/285 [04:48<00:29,  1.10s/it]Loading train:  91%|█████████ | 259/285 [04:49<00:27,  1.05s/it]Loading train:  91%|█████████ | 260/285 [04:50<00:26,  1.07s/it]Loading train:  92%|█████████▏| 261/285 [04:51<00:25,  1.04s/it]Loading train:  92%|█████████▏| 262/285 [04:52<00:23,  1.04s/it]Loading train:  92%|█████████▏| 263/285 [04:54<00:23,  1.09s/it]Loading train:  93%|█████████▎| 264/285 [04:55<00:24,  1.16s/it]Loading train:  93%|█████████▎| 265/285 [04:56<00:22,  1.15s/it]Loading train:  93%|█████████▎| 266/285 [04:57<00:20,  1.10s/it]Loading train:  94%|█████████▎| 267/285 [04:58<00:19,  1.10s/it]Loading train:  94%|█████████▍| 268/285 [04:59<00:19,  1.16s/it]Loading train:  94%|█████████▍| 269/285 [05:00<00:17,  1.10s/it]Loading train:  95%|█████████▍| 270/285 [05:02<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [05:03<00:15,  1.11s/it]Loading train:  95%|█████████▌| 272/285 [05:04<00:14,  1.12s/it]Loading train:  96%|█████████▌| 273/285 [05:05<00:13,  1.12s/it]Loading train:  96%|█████████▌| 274/285 [05:06<00:12,  1.10s/it]Loading train:  96%|█████████▋| 275/285 [05:07<00:12,  1.20s/it]Loading train:  97%|█████████▋| 276/285 [05:09<00:11,  1.23s/it]Loading train:  97%|█████████▋| 277/285 [05:10<00:09,  1.16s/it]Loading train:  98%|█████████▊| 278/285 [05:11<00:08,  1.16s/it]Loading train:  98%|█████████▊| 279/285 [05:12<00:06,  1.16s/it]Loading train:  98%|█████████▊| 280/285 [05:13<00:05,  1.14s/it]Loading train:  99%|█████████▊| 281/285 [05:14<00:04,  1.08s/it]Loading train:  99%|█████████▉| 282/285 [05:15<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [05:16<00:02,  1.13s/it]Loading train: 100%|█████████▉| 284/285 [05:17<00:01,  1.12s/it]Loading train: 100%|██████████| 285/285 [05:19<00:00,  1.17s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.46it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 47.36it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:05, 51.07it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:04, 54.04it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:03, 63.38it/s]concatenating: train:  20%|█▉        | 56/285 [00:00<00:02, 78.99it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:01, 100.86it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:01, 123.98it/s]concatenating: train:  48%|████▊     | 137/285 [00:00<00:01, 145.91it/s]concatenating: train:  55%|█████▌    | 158/285 [00:01<00:00, 160.29it/s]concatenating: train:  64%|██████▎   | 181/285 [00:01<00:00, 175.51it/s]concatenating: train:  71%|███████   | 203/285 [00:01<00:00, 172.75it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 172.87it/s]concatenating: train:  85%|████████▌ | 243/285 [00:01<00:00, 137.09it/s]concatenating: train:  95%|█████████▌| 271/285 [00:01<00:00, 161.20it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 160.31it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 71.57it/s]2019-07-11 01:03:30.101758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:03:30.101864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:03:30.101892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:03:30.101903: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:03:30.102315: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.00it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.88it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.99it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.48it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.93it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.52it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.91it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.68it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.09it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.84it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.48it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.84it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.90it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.84it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.58it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.11it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.24it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.58it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.17it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 246,193
Trainable params: 71,353
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 2.1475 - acc: 0.7467 - mDice: 0.1802 - val_loss: 2.9331 - val_acc: 0.9149 - val_mDice: 0.1710

Epoch 00001: val_mDice improved from -inf to 0.17105, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.7848 - acc: 0.8985 - mDice: 0.4417 - val_loss: 0.6353 - val_acc: 0.9294 - val_mDice: 0.5229

Epoch 00002: val_mDice improved from 0.17105 to 0.52288, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.6147 - acc: 0.9048 - mDice: 0.5253 - val_loss: 0.5469 - val_acc: 0.9301 - val_mDice: 0.5669

Epoch 00003: val_mDice improved from 0.52288 to 0.56695, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.5402 - acc: 0.9113 - mDice: 0.5678 - val_loss: 0.5364 - val_acc: 0.9355 - val_mDice: 0.5738

Epoch 00004: val_mDice improved from 0.56695 to 0.57380, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.4903 - acc: 0.9197 - mDice: 0.5976 - val_loss: 0.5542 - val_acc: 0.9413 - val_mDice: 0.5672

Epoch 00005: val_mDice did not improve from 0.57380
Epoch 6/300
 - 14s - loss: 0.4595 - acc: 0.9286 - mDice: 0.6169 - val_loss: 0.5993 - val_acc: 0.9398 - val_mDice: 0.5353

Epoch 00006: val_mDice did not improve from 0.57380
Epoch 7/300
 - 14s - loss: 0.4369 - acc: 0.9337 - mDice: 0.6313 - val_loss: 0.6085 - val_acc: 0.9427 - val_mDice: 0.5445

Epoch 00007: val_mDice did not improve from 0.57380
Epoch 8/300
 - 14s - loss: 0.4171 - acc: 0.9369 - mDice: 0.6441 - val_loss: 0.5294 - val_acc: 0.9444 - val_mDice: 0.5782

Epoch 00008: val_mDice improved from 0.57380 to 0.57821, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.3979 - acc: 0.9393 - mDice: 0.6566 - val_loss: 0.5067 - val_acc: 0.9487 - val_mDice: 0.5922

Epoch 00009: val_mDice improved from 0.57821 to 0.59218, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.3866 - acc: 0.9408 - mDice: 0.6645 - val_loss: 0.4989 - val_acc: 0.9487 - val_mDice: 0.5941

Epoch 00010: val_mDice improved from 0.59218 to 0.59410, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.3769 - acc: 0.9422 - mDice: 0.6714 - val_loss: 0.4941 - val_acc: 0.9449 - val_mDice: 0.5953

Epoch 00011: val_mDice improved from 0.59410 to 0.59534, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 14s - loss: 0.3688 - acc: 0.9431 - mDice: 0.6769 - val_loss: 0.5247 - val_acc: 0.9481 - val_mDice: 0.5824

Epoch 00012: val_mDice did not improve from 0.59534
Epoch 13/300
 - 14s - loss: 0.3608 - acc: 0.9441 - mDice: 0.6826 - val_loss: 0.5051 - val_acc: 0.9485 - val_mDice: 0.5926

Epoch 00013: val_mDice did not improve from 0.59534
Epoch 14/300
 - 14s - loss: 0.3525 - acc: 0.9450 - mDice: 0.6884 - val_loss: 0.5095 - val_acc: 0.9479 - val_mDice: 0.5897

Epoch 00014: val_mDice did not improve from 0.59534
Epoch 15/300
 - 14s - loss: 0.3438 - acc: 0.9458 - mDice: 0.6947 - val_loss: 0.5543 - val_acc: 0.9447 - val_mDice: 0.5728

Epoch 00015: val_mDice did not improve from 0.59534
Epoch 16/300
 - 15s - loss: 0.3395 - acc: 0.9463 - mDice: 0.6978 - val_loss: 0.5130 - val_acc: 0.9455 - val_mDice: 0.5900

Epoch 00016: val_mDice did not improve from 0.59534
Epoch 17/300
 - 14s - loss: 0.3360 - acc: 0.9468 - mDice: 0.7005 - val_loss: 0.5074 - val_acc: 0.9469 - val_mDice: 0.5949

Epoch 00017: val_mDice did not improve from 0.59534
Epoch 18/300
 - 15s - loss: 0.3308 - acc: 0.9471 - mDice: 0.7042 - val_loss: 0.4789 - val_acc: 0.9481 - val_mDice: 0.6097

Epoch 00018: val_mDice improved from 0.59534 to 0.60965, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 14s - loss: 0.3248 - acc: 0.9476 - mDice: 0.7085 - val_loss: 0.5127 - val_acc: 0.9488 - val_mDice: 0.5946

Epoch 00019: val_mDice did not improve from 0.60965
Epoch 20/300
 - 14s - loss: 0.3218 - acc: 0.9480 - mDice: 0.7108 - val_loss: 0.5520 - val_acc: 0.9470 - val_mDice: 0.5785

Epoch 00020: val_mDice did not improve from 0.60965
Epoch 21/300
 - 14s - loss: 0.3173 - acc: 0.9483 - mDice: 0.7141 - val_loss: 0.5022 - val_acc: 0.9467 - val_mDice: 0.5941

Epoch 00021: val_mDice did not improve from 0.60965
Epoch 22/300
 - 15s - loss: 0.3137 - acc: 0.9485 - mDice: 0.7169 - val_loss: 0.5060 - val_acc: 0.9481 - val_mDice: 0.6003

Epoch 00022: val_mDice did not improve from 0.60965
Epoch 23/300
 - 14s - loss: 0.3092 - acc: 0.9489 - mDice: 0.7202 - val_loss: 0.5147 - val_acc: 0.9457 - val_mDice: 0.5888

Epoch 00023: val_mDice did not improve from 0.60965
Epoch 24/300
 - 14s - loss: 0.3062 - acc: 0.9491 - mDice: 0.7225 - val_loss: 0.4920 - val_acc: 0.9489 - val_mDice: 0.6049

Epoch 00024: val_mDice did not improve from 0.60965
Epoch 25/300
 - 14s - loss: 0.3062 - acc: 0.9491 - mDice: 0.7225 - val_loss: 0.4680 - val_acc: 0.9498 - val_mDice: 0.6160

Epoch 00025: val_mDice improved from 0.60965 to 0.61602, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 15s - loss: 0.3014 - acc: 0.9495 - mDice: 0.7261 - val_loss: 0.5143 - val_acc: 0.9481 - val_mDice: 0.5948

Epoch 00026: val_mDice did not improve from 0.61602
Epoch 27/300
 - 14s - loss: 0.2989 - acc: 0.9497 - mDice: 0.7281 - val_loss: 0.5075 - val_acc: 0.9496 - val_mDice: 0.5975

Epoch 00027: val_mDice did not improve from 0.61602
Epoch 28/300
 - 14s - loss: 0.2954 - acc: 0.9501 - mDice: 0.7307 - val_loss: 0.5330 - val_acc: 0.9482 - val_mDice: 0.5893

Epoch 00028: val_mDice did not improve from 0.61602
Epoch 29/300
 - 14s - loss: 0.2944 - acc: 0.9502 - mDice: 0.7317 - val_loss: 0.4984 - val_acc: 0.9497 - val_mDice: 0.6041

Epoch 00029: val_mDice did not improve from 0.61602
Epoch 30/300
 - 14s - loss: 0.2908 - acc: 0.9505 - mDice: 0.7342 - val_loss: 0.4856 - val_acc: 0.9508 - val_mDice: 0.6085

Epoch 00030: val_mDice did not improve from 0.61602
Epoch 31/300
 - 15s - loss: 0.2897 - acc: 0.9505 - mDice: 0.7350 - val_loss: 0.5078 - val_acc: 0.9467 - val_mDice: 0.5939

Epoch 00031: val_mDice did not improve from 0.61602
Epoch 32/300
 - 14s - loss: 0.2867 - acc: 0.9508 - mDice: 0.7374 - val_loss: 0.5156 - val_acc: 0.9479 - val_mDice: 0.5919

Epoch 00032: val_mDice did not improve from 0.61602
Epoch 33/300
 - 14s - loss: 0.2875 - acc: 0.9508 - mDice: 0.7368 - val_loss: 0.5380 - val_acc: 0.9471 - val_mDice: 0.5773

Epoch 00033: val_mDice did not improve from 0.61602
Epoch 34/300
 - 14s - loss: 0.2848 - acc: 0.9509 - mDice: 0.7388 - val_loss: 0.4791 - val_acc: 0.9493 - val_mDice: 0.6109

Epoch 00034: val_mDice did not improve from 0.61602
Epoch 35/300
 - 16s - loss: 0.2827 - acc: 0.9511 - mDice: 0.7403 - val_loss: 0.4818 - val_acc: 0.9481 - val_mDice: 0.6085

Epoch 00035: val_mDice did not improve from 0.61602
Epoch 36/300
 - 16s - loss: 0.2804 - acc: 0.9514 - mDice: 0.7422 - val_loss: 0.5443 - val_acc: 0.9462 - val_mDice: 0.5818

Epoch 00036: val_mDice did not improve from 0.61602
Epoch 37/300
 - 17s - loss: 0.2795 - acc: 0.9515 - mDice: 0.7429 - val_loss: 0.5141 - val_acc: 0.9476 - val_mDice: 0.5925

Epoch 00037: val_mDice did not improve from 0.61602
Epoch 38/300
 - 16s - loss: 0.2779 - acc: 0.9516 - mDice: 0.7442 - val_loss: 0.4956 - val_acc: 0.9508 - val_mDice: 0.6054

Epoch 00038: val_mDice did not improve from 0.61602
Epoch 39/300
 - 18s - loss: 0.2757 - acc: 0.9518 - mDice: 0.7458 - val_loss: 0.5083 - val_acc: 0.9472 - val_mDice: 0.5961

Epoch 00039: val_mDice did not improve from 0.61602
Epoch 40/300
 - 16s - loss: 0.2739 - acc: 0.9520 - mDice: 0.7473 - val_loss: 0.5249 - val_acc: 0.9484 - val_mDice: 0.5938

Epoch 00040: val_mDice did not improve from 0.61602
Epoch 41/300
 - 17s - loss: 0.2730 - acc: 0.9520 - mDice: 0.7481 - val_loss: 0.5343 - val_acc: 0.9501 - val_mDice: 0.5886

Epoch 00041: val_mDice did not improve from 0.61602
Epoch 42/300
 - 16s - loss: 0.2721 - acc: 0.9520 - mDice: 0.7487 - val_loss: 0.4749 - val_acc: 0.9484 - val_mDice: 0.6104

Epoch 00042: val_mDice did not improve from 0.61602
Epoch 43/300
 - 16s - loss: 0.2721 - acc: 0.9521 - mDice: 0.7487 - val_loss: 0.5079 - val_acc: 0.9481 - val_mDice: 0.5981

Epoch 00043: val_mDice did not improve from 0.61602
Epoch 44/300
 - 16s - loss: 0.2705 - acc: 0.9522 - mDice: 0.7499 - val_loss: 0.5400 - val_acc: 0.9502 - val_mDice: 0.5858

Epoch 00044: val_mDice did not improve from 0.61602
Epoch 45/300
 - 15s - loss: 0.2681 - acc: 0.9525 - mDice: 0.7518 - val_loss: 0.4939 - val_acc: 0.9509 - val_mDice: 0.6024

Epoch 00045: val_mDice did not improve from 0.61602
Epoch 46/300
 - 16s - loss: 0.2667 - acc: 0.9525 - mDice: 0.7530 - val_loss: 0.4987 - val_acc: 0.9491 - val_mDice: 0.5998

Epoch 00046: val_mDice did not improve from 0.61602
Epoch 47/300
 - 16s - loss: 0.2665 - acc: 0.9526 - mDice: 0.7530 - val_loss: 0.5143 - val_acc: 0.9501 - val_mDice: 0.5962

Epoch 00047: val_mDice did not improve from 0.61602
Epoch 48/300
 - 16s - loss: 0.2641 - acc: 0.9528 - mDice: 0.7549 - val_loss: 0.5219 - val_acc: 0.9467 - val_mDice: 0.5921

Epoch 00048: val_mDice did not improve from 0.61602
Epoch 49/300
 - 16s - loss: 0.2636 - acc: 0.9528 - mDice: 0.7553 - val_loss: 0.4872 - val_acc: 0.9465 - val_mDice: 0.6026

Epoch 00049: val_mDice did not improve from 0.61602
Epoch 50/300
 - 16s - loss: 0.2644 - acc: 0.9527 - mDice: 0.7547 - val_loss: 0.4877 - val_acc: 0.9472 - val_mDice: 0.6080

Epoch 00050: val_mDice did not improve from 0.61602
Epoch 51/300
 - 16s - loss: 0.2611 - acc: 0.9531 - mDice: 0.7572 - val_loss: 0.5564 - val_acc: 0.9491 - val_mDice: 0.5841

Epoch 00051: val_mDice did not improve from 0.61602
Epoch 52/300
 - 16s - loss: 0.2612 - acc: 0.9529 - mDice: 0.7572 - val_loss: 0.4881 - val_acc: 0.9493 - val_mDice: 0.6060

Epoch 00052: val_mDice did not improve from 0.61602
Epoch 53/300
 - 16s - loss: 0.2603 - acc: 0.9531 - mDice: 0.7579 - val_loss: 0.5283 - val_acc: 0.9501 - val_mDice: 0.5873

Epoch 00053: val_mDice did not improve from 0.61602
Epoch 54/300
 - 14s - loss: 0.2580 - acc: 0.9532 - mDice: 0.7597 - val_loss: 0.5052 - val_acc: 0.9499 - val_mDice: 0.5976

Epoch 00054: val_mDice did not improve from 0.61602
Epoch 55/300
 - 15s - loss: 0.2584 - acc: 0.9532 - mDice: 0.7594 - val_loss: 0.5459 - val_acc: 0.9487 - val_mDice: 0.5807

Epoch 00055: val_mDice did not improve from 0.61602
Epoch 56/300
 - 14s - loss: 0.2575 - acc: 0.9534 - mDice: 0.7602 - val_loss: 0.5418 - val_acc: 0.9487 - val_mDice: 0.5827

Epoch 00056: val_mDice did not improve from 0.61602
Epoch 57/300
 - 15s - loss: 0.2566 - acc: 0.9534 - mDice: 0.7609 - val_loss: 0.5337 - val_acc: 0.9441 - val_mDice: 0.5834

Epoch 00057: val_mDice did not improve from 0.61602
Epoch 58/300
 - 14s - loss: 0.2563 - acc: 0.9534 - mDice: 0.7612 - val_loss: 0.5002 - val_acc: 0.9485 - val_mDice: 0.5986

Epoch 00058: val_mDice did not improve from 0.61602
Epoch 59/300
 - 14s - loss: 0.2548 - acc: 0.9536 - mDice: 0.7623 - val_loss: 0.4887 - val_acc: 0.9510 - val_mDice: 0.6103

Epoch 00059: val_mDice did not improve from 0.61602
Epoch 60/300
 - 14s - loss: 0.2540 - acc: 0.9536 - mDice: 0.7630 - val_loss: 0.4786 - val_acc: 0.9497 - val_mDice: 0.6126

Epoch 00060: val_mDice did not improve from 0.61602
Epoch 61/300
 - 14s - loss: 0.2537 - acc: 0.9537 - mDice: 0.7631 - val_loss: 0.5078 - val_acc: 0.9503 - val_mDice: 0.6013

Epoch 00061: val_mDice did not improve from 0.61602
Epoch 62/300
 - 14s - loss: 0.2534 - acc: 0.9537 - mDice: 0.7634 - val_loss: 0.4926 - val_acc: 0.9481 - val_mDice: 0.6047

Epoch 00062: val_mDice did not improve from 0.61602
Epoch 63/300
 - 14s - loss: 0.2544 - acc: 0.9537 - mDice: 0.7628 - val_loss: 0.5188 - val_acc: 0.9496 - val_mDice: 0.5922

Epoch 00063: val_mDice did not improve from 0.61602
Epoch 64/300
 - 14s - loss: 0.2504 - acc: 0.9539 - mDice: 0.7658 - val_loss: 0.5093 - val_acc: 0.9469 - val_mDice: 0.5966

Epoch 00064: val_mDice did not improve from 0.61602
Epoch 65/300
 - 14s - loss: 0.2503 - acc: 0.9540 - mDice: 0.7659 - val_loss: 0.5159 - val_acc: 0.9497 - val_mDice: 0.5919

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.07s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:00,  1.90s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:31,  1.81s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:23,  1.79s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:57,  1.70s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:13,  1.76s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:57,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:16,  1.79s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:06,  1.75s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:40,  1.88s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<08:51,  1.93s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:31,  1.87s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:52,  1.95s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:34,  1.89s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:36,  1.91s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:48,  1.96s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:58,  2.00s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:29,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:32,  1.92s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:12,  1.85s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:10,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:26,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:02,  1.83s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:12,  1.88s/it]predicting train subjects:   8%|▊         | 24/285 [00:44<07:49,  1.80s/it]predicting train subjects:   9%|▉         | 25/285 [00:46<08:08,  1.88s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:50<08:02,  1.87s/it]predicting train subjects:  10%|▉         | 28/285 [00:52<08:07,  1.90s/it]predicting train subjects:  10%|█         | 29/285 [00:54<08:03,  1.89s/it]predicting train subjects:  11%|█         | 30/285 [00:56<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:58<08:29,  2.01s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:59,  1.90s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:51,  1.87s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:45,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:09,  1.96s/it]predicting train subjects:  13%|█▎        | 36/285 [01:07<07:42,  1.86s/it]predicting train subjects:  13%|█▎        | 37/285 [01:09<07:36,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:11<07:55,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:34,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:31,  1.84s/it]predicting train subjects:  14%|█▍        | 41/285 [01:16<07:11,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:18<07:05,  1.75s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:09,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:29,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:08,  1.78s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:33,  1.90s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:15,  1.83s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:16,  1.84s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:33,  1.92s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:26,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:34,  1.94s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:12,  1.86s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:14,  1.87s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:26,  1.93s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:02,  1.84s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:09,  1.88s/it]predicting train subjects:  20%|██        | 57/285 [01:46<06:53,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:53,  1.82s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:04,  1.88s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:16,  1.94s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:54,  1.85s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:55,  1.86s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:49,  1.84s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:38,  1.80s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:39,  1.82s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:39,  1.82s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:46,  1.86s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:37,  1.83s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:36,  1.84s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:37,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:37,  1.86s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:24,  1.81s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:28,  1.83s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:29,  1.85s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:30,  1.86s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:29,  1.86s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:19,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:13,  1.81s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:18,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:16,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:08,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<05:59,  1.78s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:49,  1.74s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:39<05:55,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:57,  1.82s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:58,  1.83s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<05:58,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:52,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<05:57,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:47,  1.81s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:47,  1.82s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:47,  1.83s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:51,  1.86s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:54,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [03:01<05:49,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [03:03<05:47,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:05<05:43,  1.86s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:37,  1.83s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:38,  1.85s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:29,  1.81s/it]predicting train subjects:  36%|███▋      | 104/285 [03:12<05:34,  1.85s/it]predicting train subjects:  37%|███▋      | 105/285 [03:14<05:41,  1.90s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:32,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:27,  1.84s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:21<05:20,  1.82s/it]predicting train subjects:  39%|███▊      | 110/285 [03:23<05:18,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:25<05:10,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:10,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:16,  1.84s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:18,  1.86s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:14,  1.85s/it]predicting train subjects:  41%|████      | 116/285 [03:34<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:36<05:08,  1.84s/it]predicting train subjects:  41%|████▏     | 118/285 [03:37<04:58,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<05:03,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:41<04:54,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:47,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:44<04:35,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:46<04:22,  1.62s/it]predicting train subjects:  44%|████▎     | 124/285 [03:47<04:21,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:49<04:13,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:50<04:11,  1.58s/it]predicting train subjects:  45%|████▍     | 127/285 [03:52<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:54<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:55<04:06,  1.58s/it]predicting train subjects:  46%|████▌     | 130/285 [03:57<04:05,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [03:58<03:59,  1.55s/it]predicting train subjects:  46%|████▋     | 132/285 [04:00<04:02,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:01<03:58,  1.57s/it]predicting train subjects:  47%|████▋     | 134/285 [04:03<04:00,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [04:05<03:55,  1.57s/it]predicting train subjects:  48%|████▊     | 136/285 [04:06<03:50,  1.55s/it]predicting train subjects:  48%|████▊     | 137/285 [04:08<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:09<03:52,  1.58s/it]predicting train subjects:  49%|████▉     | 139/285 [04:11<03:55,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:13<03:55,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:14<03:47,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:16<03:45,  1.58s/it]predicting train subjects:  50%|█████     | 143/285 [04:17<03:36,  1.52s/it]predicting train subjects:  51%|█████     | 144/285 [04:19<03:36,  1.54s/it]predicting train subjects:  51%|█████     | 145/285 [04:20<03:34,  1.53s/it]predicting train subjects:  51%|█████     | 146/285 [04:22<03:38,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:23<03:32,  1.54s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:25<03:35,  1.57s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:27<03:31,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:28<03:32,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:30<03:31,  1.58s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:31<03:28,  1.57s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:33<03:26,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:35<03:30,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:36<03:25,  1.58s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:38<03:25,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:39<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:41<03:21,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:42<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:44<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:46<03:19,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:47<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:49<03:17,  1.62s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:50<03:17,  1.63s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:52<03:14,  1.62s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:54<03:12,  1.62s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:55<03:16,  1.66s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:57<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:59<03:06,  1.60s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:00<03:00,  1.57s/it]predicting train subjects:  60%|██████    | 171/285 [05:02<02:59,  1.58s/it]predicting train subjects:  60%|██████    | 172/285 [05:03<02:59,  1.59s/it]predicting train subjects:  61%|██████    | 173/285 [05:05<02:55,  1.56s/it]predicting train subjects:  61%|██████    | 174/285 [05:06<02:54,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:08<02:56,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:10<02:58,  1.64s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:11<02:54,  1.62s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:13<02:49,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:14<02:46,  1.57s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:16<02:52,  1.64s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:18<02:56,  1.69s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:20<02:56,  1.72s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:21<02:46,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:23<02:43,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:24<02:36,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:26<02:44,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:28<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:30<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:31<02:42,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:33<02:36,  1.65s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:35<02:36,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:36<02:36,  1.68s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:38<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:39<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:41<02:23,  1.60s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:43<02:30,  1.70s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:45<02:35,  1.77s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:47<02:36,  1.80s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:48<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:15,  1.59s/it]predicting train subjects:  71%|███████   | 201/285 [05:51<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:53<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:55<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:56<02:12,  1.63s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:58<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:59<02:05,  1.59s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:01<02:12,  1.70s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:03<02:18,  1.80s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:05<02:19,  1.83s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:11,  1.75s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:08<02:05,  1.69s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<02:07,  1.75s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<02:08,  1.78s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<02:01,  1.71s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:16<02:02,  1.75s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:53,  1.65s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:57,  1.73s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:23<01:59,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:51,  1.71s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:26<01:45,  1.65s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:29<01:41,  1.64s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:37,  1.61s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:32<01:33,  1.56s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:34<01:39,  1.68s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:36<01:41,  1.74s/it]predicting train subjects:  80%|████████  | 228/285 [06:38<01:42,  1.79s/it]predicting train subjects:  80%|████████  | 229/285 [06:39<01:39,  1.78s/it]predicting train subjects:  81%|████████  | 230/285 [06:41<01:34,  1.71s/it]predicting train subjects:  81%|████████  | 231/285 [06:42<01:29,  1.66s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:44<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:46<01:24,  1.63s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:48<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:49<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:51<01:25,  1.75s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:53<01:25,  1.79s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:55<01:25,  1.81s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:57<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:58<01:16,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:00<01:12,  1.64s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:01<01:09,  1.62s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:03<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:05<01:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:06<01:04,  1.62s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:08<01:06,  1.70s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:10<01:07,  1.77s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:12<01:05,  1.77s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:13<01:00,  1.69s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:15<00:57,  1.66s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:16<00:55,  1.62s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:18<00:52,  1.59s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:20<00:54,  1.70s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:22<00:53,  1.72s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:23<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:25<00:48,  1.69s/it]predicting train subjects:  90%|█████████ | 257/285 [07:26<00:46,  1.65s/it]predicting train subjects:  91%|█████████ | 258/285 [07:28<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [07:30<00:44,  1.70s/it]predicting train subjects:  91%|█████████ | 260/285 [07:31<00:41,  1.65s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:33<00:39,  1.64s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:35<00:36,  1.60s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:36<00:35,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:38<00:35,  1.70s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:40<00:34,  1.74s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:41<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:43<00:29,  1.62s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:45<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:46<00:27,  1.70s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:48<00:24,  1.63s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:49<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:51<00:21,  1.62s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:53<00:19,  1.59s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:54<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:56<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:58<00:15,  1.75s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:00<00:13,  1.67s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:01<00:11,  1.64s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:03<00:10,  1.68s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:04<00:08,  1.65s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:06<00:06,  1.62s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:08<00:04,  1.59s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:09<00:03,  1.70s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:11<00:01,  1.76s/it]predicting train subjects: 100%|██████████| 285/285 [08:13<00:00,  1.80s/it]
Epoch 00065: val_mDice did not improve from 0.61602
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
{'val_loss': [2.9331273459855405, 0.6352781646744499, 0.5469479714025999, 0.5363754213855253, 0.5541971189349724, 0.5993458099205401, 0.608516062438155, 0.5293527165604703, 0.5067193931041483, 0.4988844561177259, 0.4940658581323464, 0.5247492373988615, 0.5051188598797974, 0.5094915598464411, 0.5542637802369101, 0.5129907757210332, 0.5073519349098206, 0.4789484832539905, 0.512680073690148, 0.5520032184750008, 0.5022074906519671, 0.5059935570429157, 0.514739052543427, 0.4919676038140025, 0.4680193153173564, 0.5143103256571893, 0.507478591117113, 0.5330112266806917, 0.4984046567085735, 0.48563218749435255, 0.5077537807672383, 0.5156094195456479, 0.5379607950508928, 0.4791161348033884, 0.48175570984792443, 0.5442920793368163, 0.5141009108980275, 0.49564348019701143, 0.5082985705503539, 0.52485603826672, 0.5343085930334123, 0.4749187464154632, 0.5078577062937134, 0.5400016207934758, 0.49392890563890257, 0.49873892621621074, 0.5142837852739089, 0.5219065713482862, 0.4871873619170162, 0.4876908626636313, 0.5563652418845193, 0.48812544212660974, 0.5282557766530767, 0.50515793521977, 0.5459158097565507, 0.5417847277065895, 0.5337114144303945, 0.5002373813250878, 0.4886905937221463, 0.478617031481013, 0.5078203984478998, 0.492621125788662, 0.5187705488844291, 0.5093402219884222, 0.5159477901192351], 'val_acc': [0.9149036454088861, 0.9293866270747264, 0.9300994296979638, 0.9354608012311285, 0.9412540327237305, 0.9397871211254397, 0.9426898956298828, 0.9444150548407485, 0.9487372380395175, 0.9486855914472868, 0.9448551222598752, 0.9480512808155082, 0.9485471608252499, 0.947927335454099, 0.9446898708796369, 0.9455286723941398, 0.9468860449737677, 0.9480636972288846, 0.9488302023051172, 0.947022424063869, 0.9467166525691582, 0.9481050182321218, 0.9457063441835968, 0.9488922017912625, 0.9497537303237276, 0.9480822915471466, 0.9495905228167273, 0.9482207271639861, 0.9496731438450308, 0.9507640327155257, 0.9466587977702391, 0.9479004584211211, 0.9470637270858168, 0.9492723255850083, 0.9481422078676064, 0.9462104662836597, 0.9476050368234432, 0.9507578175161138, 0.9472290227533052, 0.948388064040818, 0.9501194407820036, 0.9484273251874487, 0.9481401513408683, 0.9502000016207136, 0.9508755956282163, 0.949138022334882, 0.9500594911628595, 0.9467001171085422, 0.9465306870764194, 0.9472145484812433, 0.9490678213828103, 0.9493301907065195, 0.9501442040145064, 0.9499314167646057, 0.9487434216051794, 0.9487248406063911, 0.9441444107940077, 0.9484872428398559, 0.9510491277252495, 0.9497392390693367, 0.9502578544217115, 0.9480802413471584, 0.9496235714278407, 0.9469232206238049, 0.9496545738348082], 'val_mDice': [0.17104885498238676, 0.5228810073943112, 0.5669476160124027, 0.5738023845843097, 0.5672285260434923, 0.5353248289177538, 0.5445316094259977, 0.5782141885277945, 0.5921801635006952, 0.594097578325751, 0.595344385621268, 0.5824125925255887, 0.5926192386190319, 0.5896680997736627, 0.572801457437057, 0.5899749721228743, 0.5949255953953919, 0.6096522318584293, 0.5946460852409874, 0.5785003314471112, 0.5941405622652789, 0.6002794490846176, 0.588825473239302, 0.6048853670418596, 0.6160158188649396, 0.5947778404757963, 0.5974736053850398, 0.5892860742920604, 0.6041269112565664, 0.608501446646685, 0.593856950045964, 0.5919053404690833, 0.5773240853954293, 0.6108945694715617, 0.6084982736150646, 0.581823679321971, 0.5924647087491425, 0.6053663558800128, 0.596066155580169, 0.5938451849548511, 0.5885624219585397, 0.6104264565686274, 0.5981262003243303, 0.5858095041866409, 0.6023958668362495, 0.5997856119491535, 0.5962107860842231, 0.5921086182807411, 0.6025922771272713, 0.6079524815415537, 0.5841220270987996, 0.6059624862404509, 0.5872559524115237, 0.5976060359171649, 0.5807335373409633, 0.5827363812723639, 0.5833683633271542, 0.5986373134831476, 0.6102926970860145, 0.6126373746541626, 0.6013116933114036, 0.6047092962531404, 0.5922108086127809, 0.5965592628084747, 0.5918808909101859], 'loss': [2.147459437210091, 0.7848446630755058, 0.6147001342513476, 0.5402355440093648, 0.4903002963574596, 0.4595218662615468, 0.43690941214438106, 0.41713195116287105, 0.3979294244552008, 0.38660302599636887, 0.37687711276706026, 0.36878601619701395, 0.3608138875714328, 0.3525172459745477, 0.34383408616917643, 0.3395493447985124, 0.3359902764735324, 0.33075798748560276, 0.32481538050575043, 0.3218226521553138, 0.31725087663679497, 0.3137108769449791, 0.30924394131550814, 0.30624449815172805, 0.3061653053855969, 0.3014379610673683, 0.2989423305508774, 0.2953641072680933, 0.29444083552118755, 0.2907583787254139, 0.28973918991387265, 0.2866839919044304, 0.28752778964840986, 0.28484861938939504, 0.2827418192163622, 0.2804227764651534, 0.2795256429992141, 0.27788010231485477, 0.27572088109356835, 0.2738710965545899, 0.2730107618848143, 0.2720900202416223, 0.27209326612859125, 0.270496689177184, 0.26812059167007835, 0.2666531407257212, 0.26651389379334095, 0.264146096414811, 0.2636468978474443, 0.2643655173743864, 0.2611495351036301, 0.2612387795936801, 0.2602587442717893, 0.25802571278084313, 0.25842807470476387, 0.2575162779492144, 0.256632911059132, 0.2562527003390721, 0.2548217810071584, 0.2539947088131178, 0.25374540303548265, 0.25344270308528954, 0.2543535747904513, 0.2504189439013622, 0.25033602874222277], 'acc': [0.7467176211139331, 0.8984927809820814, 0.9048280620729473, 0.9112557128268995, 0.9196788309141284, 0.9285991657410667, 0.9337384065643686, 0.93685143640323, 0.9392660472830762, 0.9407778866611387, 0.94222299513828, 0.9431045983983088, 0.9440940825237076, 0.9449518981481662, 0.94580361335848, 0.9462528367505069, 0.9467601254675735, 0.9471040223653875, 0.9476475482815186, 0.9479642395658707, 0.9482657392328454, 0.948460973037574, 0.9488586135844469, 0.9490721941182546, 0.949072617891989, 0.9495239332411636, 0.9496908293402239, 0.9501314304095845, 0.9501998709227342, 0.9504704157009305, 0.950526105647292, 0.950819916048897, 0.9508489559181219, 0.9509399994825539, 0.9510717446115449, 0.9513606391897856, 0.9514916806229838, 0.9516444347807346, 0.9517623467627424, 0.9519824932248859, 0.9520213886106152, 0.9519884563090981, 0.9521333768239085, 0.952241719798139, 0.9524775991985971, 0.9525436248649966, 0.9525653385374582, 0.9527820021126708, 0.9528287501027658, 0.9527023813542856, 0.9530653757802555, 0.9528968493232448, 0.9530512136342018, 0.9532115647141096, 0.9532494925055445, 0.9533898387331309, 0.9534106066164502, 0.9533995884636455, 0.9535780041041597, 0.9535800158136726, 0.9536787131715526, 0.9537090239497054, 0.9536831200944138, 0.953852173614772, 0.9539562021781596], 'mDice': [0.1802443671387435, 0.441685510661424, 0.5252542129224386, 0.5677641116678763, 0.5975887558927827, 0.6169075061147701, 0.6312681664751023, 0.6440975649814825, 0.6566468172847014, 0.6645134295339996, 0.6714031679406547, 0.6768828114778425, 0.6826225214323689, 0.6883869290085675, 0.6947348169184259, 0.6978019884868707, 0.7005047709825908, 0.7042390715159802, 0.7085230658077855, 0.7108174087493406, 0.7140852346651941, 0.7168846403641558, 0.720199327506269, 0.7225244096678383, 0.7225464918561364, 0.7260918444482389, 0.7280523577947177, 0.7307177396662309, 0.7316892637055227, 0.7342172365881741, 0.7350085841746549, 0.7374113928024484, 0.7368337911014547, 0.7388355112025164, 0.7403473393160445, 0.7422371772267798, 0.7428854165705167, 0.7442217492263864, 0.7458013767517248, 0.7473029287206433, 0.7481124756493461, 0.7486717253590675, 0.7487450669835151, 0.7499201276074969, 0.751794151663553, 0.7529537154694449, 0.7530037816018426, 0.7549055598704204, 0.7553184174204514, 0.7547379998715119, 0.7572188613318804, 0.7571959973264576, 0.7579187237549617, 0.7596568132977777, 0.7594311304792561, 0.760194971062676, 0.7608562744940868, 0.7612103126575066, 0.762258756083475, 0.7629825492211919, 0.7631424909829769, 0.7634067435999801, 0.7627955913303478, 0.7657535077180162, 0.7658925337908568]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:00,  1.69s/it]Loading train:   1%|          | 2/285 [00:02<07:17,  1.55s/it]Loading train:   1%|          | 3/285 [00:04<07:02,  1.50s/it]Loading train:   1%|▏         | 4/285 [00:05<06:50,  1.46s/it]Loading train:   2%|▏         | 5/285 [00:07<07:08,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<06:45,  1.45s/it]Loading train:   2%|▏         | 7/285 [00:10<06:53,  1.49s/it]Loading train:   3%|▎         | 8/285 [00:11<06:43,  1.46s/it]Loading train:   3%|▎         | 9/285 [00:13<06:57,  1.51s/it]Loading train:   4%|▎         | 10/285 [00:14<06:28,  1.41s/it]Loading train:   4%|▍         | 11/285 [00:15<05:47,  1.27s/it]Loading train:   4%|▍         | 12/285 [00:16<05:41,  1.25s/it]Loading train:   5%|▍         | 13/285 [00:17<05:23,  1.19s/it]Loading train:   5%|▍         | 14/285 [00:18<05:34,  1.23s/it]Loading train:   5%|▌         | 15/285 [00:20<05:23,  1.20s/it]Loading train:   6%|▌         | 16/285 [00:21<05:29,  1.22s/it]Loading train:   6%|▌         | 17/285 [00:22<04:57,  1.11s/it]Loading train:   6%|▋         | 18/285 [00:23<04:58,  1.12s/it]Loading train:   7%|▋         | 19/285 [00:24<04:53,  1.10s/it]Loading train:   7%|▋         | 20/285 [00:25<04:53,  1.11s/it]Loading train:   7%|▋         | 21/285 [00:26<05:01,  1.14s/it]Loading train:   8%|▊         | 22/285 [00:27<04:53,  1.12s/it]Loading train:   8%|▊         | 23/285 [00:28<04:48,  1.10s/it]Loading train:   8%|▊         | 24/285 [00:29<04:22,  1.00s/it]Loading train:   9%|▉         | 25/285 [00:30<04:26,  1.03s/it]Loading train:   9%|▉         | 26/285 [00:31<04:45,  1.10s/it]Loading train:   9%|▉         | 27/285 [00:33<04:41,  1.09s/it]Loading train:  10%|▉         | 28/285 [00:34<04:41,  1.09s/it]Loading train:  10%|█         | 29/285 [00:35<04:37,  1.08s/it]Loading train:  11%|█         | 30/285 [00:36<04:57,  1.17s/it]Loading train:  11%|█         | 31/285 [00:37<05:04,  1.20s/it]Loading train:  11%|█         | 32/285 [00:38<04:51,  1.15s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:43,  1.13s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:40,  1.12s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:46,  1.15s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:36,  1.11s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:26,  1.07s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:35,  1.12s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:29,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:24,  1.08s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:19,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:49<04:06,  1.01s/it]Loading train:  15%|█▌        | 43/285 [00:50<04:05,  1.01s/it]Loading train:  15%|█▌        | 44/285 [00:51<04:23,  1.09s/it]Loading train:  16%|█▌        | 45/285 [00:52<04:16,  1.07s/it]Loading train:  16%|█▌        | 46/285 [00:53<04:21,  1.09s/it]Loading train:  16%|█▋        | 47/285 [00:55<04:25,  1.11s/it]Loading train:  17%|█▋        | 48/285 [00:56<04:21,  1.10s/it]Loading train:  17%|█▋        | 49/285 [00:57<04:41,  1.19s/it]Loading train:  18%|█▊        | 50/285 [00:58<04:29,  1.15s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:34,  1.17s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:26,  1.14s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:26,  1.15s/it]Loading train:  19%|█▉        | 54/285 [01:03<04:32,  1.18s/it]Loading train:  19%|█▉        | 55/285 [01:04<04:16,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:05<04:17,  1.12s/it]Loading train:  20%|██        | 57/285 [01:06<04:16,  1.12s/it]Loading train:  20%|██        | 58/285 [01:07<04:17,  1.13s/it]Loading train:  21%|██        | 59/285 [01:09<04:26,  1.18s/it]Loading train:  21%|██        | 60/285 [01:10<04:17,  1.15s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:10,  1.12s/it]Loading train:  22%|██▏       | 62/285 [01:12<04:04,  1.10s/it]Loading train:  22%|██▏       | 63/285 [01:13<03:58,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:14,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:16<04:38,  1.27s/it]Loading train:  23%|██▎       | 66/285 [01:17<04:45,  1.30s/it]Loading train:  24%|██▎       | 67/285 [01:18<04:29,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:08,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:05,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:21<04:05,  1.14s/it]Loading train:  25%|██▍       | 71/285 [01:22<03:53,  1.09s/it]Loading train:  25%|██▌       | 72/285 [01:23<03:40,  1.04s/it]Loading train:  26%|██▌       | 73/285 [01:24<03:43,  1.06s/it]Loading train:  26%|██▌       | 74/285 [01:25<03:55,  1.11s/it]Loading train:  26%|██▋       | 75/285 [01:26<03:46,  1.08s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:41,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:28<03:27,  1.00it/s]Loading train:  27%|██▋       | 78/285 [01:29<03:18,  1.05it/s]Loading train:  28%|██▊       | 79/285 [01:30<03:23,  1.01it/s]Loading train:  28%|██▊       | 80/285 [01:31<03:28,  1.02s/it]Loading train:  28%|██▊       | 81/285 [01:32<03:19,  1.02it/s]Loading train:  29%|██▉       | 82/285 [01:33<03:21,  1.01it/s]Loading train:  29%|██▉       | 83/285 [01:34<03:16,  1.03it/s]Loading train:  29%|██▉       | 84/285 [01:35<03:15,  1.03it/s]Loading train:  30%|██▉       | 85/285 [01:36<03:15,  1.03it/s]Loading train:  30%|███       | 86/285 [01:38<03:38,  1.10s/it]Loading train:  31%|███       | 87/285 [01:39<03:43,  1.13s/it]Loading train:  31%|███       | 88/285 [01:40<03:33,  1.08s/it]Loading train:  31%|███       | 89/285 [01:41<03:37,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:42<03:45,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:43<03:31,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:44<03:28,  1.08s/it]Loading train:  33%|███▎      | 93/285 [01:45<03:28,  1.09s/it]Loading train:  33%|███▎      | 94/285 [01:46<03:36,  1.13s/it]Loading train:  33%|███▎      | 95/285 [01:48<03:40,  1.16s/it]Loading train:  34%|███▎      | 96/285 [01:49<03:36,  1.15s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:39,  1.17s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:31,  1.13s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:29,  1.13s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:29,  1.13s/it]Loading train:  35%|███▌      | 101/285 [01:54<03:15,  1.06s/it]Loading train:  36%|███▌      | 102/285 [01:56<03:38,  1.20s/it]Loading train:  36%|███▌      | 103/285 [01:57<03:20,  1.10s/it]Loading train:  36%|███▋      | 104/285 [01:58<03:19,  1.10s/it]Loading train:  37%|███▋      | 105/285 [01:59<03:22,  1.12s/it]Loading train:  37%|███▋      | 106/285 [02:00<03:17,  1.10s/it]Loading train:  38%|███▊      | 107/285 [02:01<03:17,  1.11s/it]Loading train:  38%|███▊      | 108/285 [02:02<03:18,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:03<03:14,  1.11s/it]Loading train:  39%|███▊      | 110/285 [02:05<03:28,  1.19s/it]Loading train:  39%|███▉      | 111/285 [02:06<03:13,  1.11s/it]Loading train:  39%|███▉      | 112/285 [02:07<03:16,  1.14s/it]Loading train:  40%|███▉      | 113/285 [02:08<03:20,  1.17s/it]Loading train:  40%|████      | 114/285 [02:09<03:25,  1.20s/it]Loading train:  40%|████      | 115/285 [02:10<03:16,  1.16s/it]Loading train:  41%|████      | 116/285 [02:12<03:16,  1.16s/it]Loading train:  41%|████      | 117/285 [02:13<03:06,  1.11s/it]Loading train:  41%|████▏     | 118/285 [02:14<03:03,  1.10s/it]Loading train:  42%|████▏     | 119/285 [02:15<02:58,  1.07s/it]Loading train:  42%|████▏     | 120/285 [02:16<02:53,  1.05s/it]Loading train:  42%|████▏     | 121/285 [02:17<03:13,  1.18s/it]Loading train:  43%|████▎     | 122/285 [02:18<03:17,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:20<03:23,  1.26s/it]Loading train:  44%|████▎     | 124/285 [02:21<03:14,  1.21s/it]Loading train:  44%|████▍     | 125/285 [02:22<02:59,  1.12s/it]Loading train:  44%|████▍     | 126/285 [02:23<02:51,  1.08s/it]Loading train:  45%|████▍     | 127/285 [02:24<02:51,  1.09s/it]Loading train:  45%|████▍     | 128/285 [02:25<02:42,  1.04s/it]Loading train:  45%|████▌     | 129/285 [02:26<02:41,  1.04s/it]Loading train:  46%|████▌     | 130/285 [02:27<02:29,  1.03it/s]Loading train:  46%|████▌     | 131/285 [02:27<02:23,  1.07it/s]Loading train:  46%|████▋     | 132/285 [02:28<02:22,  1.07it/s]Loading train:  47%|████▋     | 133/285 [02:29<02:21,  1.07it/s]Loading train:  47%|████▋     | 134/285 [02:30<02:14,  1.12it/s]Loading train:  47%|████▋     | 135/285 [02:31<02:14,  1.11it/s]Loading train:  48%|████▊     | 136/285 [02:32<02:17,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:33<02:27,  1.00it/s]Loading train:  48%|████▊     | 138/285 [02:35<02:41,  1.10s/it]Loading train:  49%|████▉     | 139/285 [02:36<02:45,  1.14s/it]Loading train:  49%|████▉     | 140/285 [02:37<03:04,  1.28s/it]Loading train:  49%|████▉     | 141/285 [02:38<02:52,  1.20s/it]Loading train:  50%|████▉     | 142/285 [02:39<02:38,  1.11s/it]Loading train:  50%|█████     | 143/285 [02:40<02:32,  1.08s/it]Loading train:  51%|█████     | 144/285 [02:41<02:30,  1.07s/it]Loading train:  51%|█████     | 145/285 [02:42<02:30,  1.08s/it]Loading train:  51%|█████     | 146/285 [02:43<02:23,  1.03s/it]Loading train:  52%|█████▏    | 147/285 [02:44<02:21,  1.02s/it]Loading train:  52%|█████▏    | 148/285 [02:45<02:14,  1.01it/s]Loading train:  52%|█████▏    | 149/285 [02:46<02:16,  1.00s/it]Loading train:  53%|█████▎    | 150/285 [02:47<02:08,  1.05it/s]Loading train:  53%|█████▎    | 151/285 [02:48<02:10,  1.03it/s]Loading train:  53%|█████▎    | 152/285 [02:49<02:08,  1.03it/s]Loading train:  54%|█████▎    | 153/285 [02:50<02:08,  1.03it/s]Loading train:  54%|█████▍    | 154/285 [02:51<02:14,  1.03s/it]Loading train:  54%|█████▍    | 155/285 [02:52<02:12,  1.02s/it]Loading train:  55%|█████▍    | 156/285 [02:53<02:08,  1.00it/s]Loading train:  55%|█████▌    | 157/285 [02:54<02:07,  1.00it/s]Loading train:  55%|█████▌    | 158/285 [02:55<02:09,  1.02s/it]Loading train:  56%|█████▌    | 159/285 [02:56<02:06,  1.00s/it]Loading train:  56%|█████▌    | 160/285 [02:57<02:06,  1.01s/it]Loading train:  56%|█████▋    | 161/285 [02:58<02:05,  1.02s/it]Loading train:  57%|█████▋    | 162/285 [02:59<02:01,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [03:00<01:56,  1.05it/s]Loading train:  58%|█████▊    | 164/285 [03:01<02:01,  1.00s/it]Loading train:  58%|█████▊    | 165/285 [03:02<01:56,  1.03it/s]Loading train:  58%|█████▊    | 166/285 [03:03<01:58,  1.01it/s]Loading train:  59%|█████▊    | 167/285 [03:04<01:54,  1.03it/s]Loading train:  59%|█████▉    | 168/285 [03:05<02:00,  1.03s/it]Loading train:  59%|█████▉    | 169/285 [03:06<01:52,  1.03it/s]Loading train:  60%|█████▉    | 170/285 [03:07<01:55,  1.00s/it]Loading train:  60%|██████    | 171/285 [03:08<01:50,  1.03it/s]Loading train:  60%|██████    | 172/285 [03:09<01:46,  1.06it/s]Loading train:  61%|██████    | 173/285 [03:10<01:46,  1.05it/s]Loading train:  61%|██████    | 174/285 [03:11<01:47,  1.03it/s]Loading train:  61%|██████▏   | 175/285 [03:12<01:50,  1.01s/it]Loading train:  62%|██████▏   | 176/285 [03:13<01:50,  1.02s/it]Loading train:  62%|██████▏   | 177/285 [03:14<01:52,  1.04s/it]Loading train:  62%|██████▏   | 178/285 [03:15<01:46,  1.01it/s]Loading train:  63%|██████▎   | 179/285 [03:16<01:41,  1.05it/s]Loading train:  63%|██████▎   | 180/285 [03:17<01:47,  1.03s/it]Loading train:  64%|██████▎   | 181/285 [03:18<01:46,  1.03s/it]Loading train:  64%|██████▍   | 182/285 [03:19<01:46,  1.04s/it]Loading train:  64%|██████▍   | 183/285 [03:20<01:42,  1.00s/it]Loading train:  65%|██████▍   | 184/285 [03:21<01:38,  1.02it/s]Loading train:  65%|██████▍   | 185/285 [03:22<01:31,  1.09it/s]Loading train:  65%|██████▌   | 186/285 [03:23<01:40,  1.01s/it]Loading train:  66%|██████▌   | 187/285 [03:24<01:42,  1.05s/it]Loading train:  66%|██████▌   | 188/285 [03:25<01:43,  1.07s/it]Loading train:  66%|██████▋   | 189/285 [03:26<01:37,  1.01s/it]Loading train:  67%|██████▋   | 190/285 [03:27<01:37,  1.03s/it]Loading train:  67%|██████▋   | 191/285 [03:28<01:40,  1.07s/it]Loading train:  67%|██████▋   | 192/285 [03:29<01:36,  1.04s/it]Loading train:  68%|██████▊   | 193/285 [03:31<01:40,  1.09s/it]Loading train:  68%|██████▊   | 194/285 [03:32<01:38,  1.09s/it]Loading train:  68%|██████▊   | 195/285 [03:33<01:38,  1.09s/it]Loading train:  69%|██████▉   | 196/285 [03:34<01:39,  1.12s/it]Loading train:  69%|██████▉   | 197/285 [03:35<01:34,  1.07s/it]Loading train:  69%|██████▉   | 198/285 [03:36<01:33,  1.07s/it]Loading train:  70%|██████▉   | 199/285 [03:37<01:29,  1.04s/it]Loading train:  70%|███████   | 200/285 [03:38<01:21,  1.05it/s]Loading train:  71%|███████   | 201/285 [03:39<01:19,  1.06it/s]Loading train:  71%|███████   | 202/285 [03:39<01:17,  1.07it/s]Loading train:  71%|███████   | 203/285 [03:41<01:19,  1.03it/s]Loading train:  72%|███████▏  | 204/285 [03:42<01:19,  1.02it/s]Loading train:  72%|███████▏  | 205/285 [03:42<01:17,  1.03it/s]Loading train:  72%|███████▏  | 206/285 [03:44<01:17,  1.01it/s]Loading train:  73%|███████▎  | 207/285 [03:45<01:17,  1.00it/s]Loading train:  73%|███████▎  | 208/285 [03:46<01:20,  1.05s/it]Loading train:  73%|███████▎  | 209/285 [03:47<01:20,  1.06s/it]Loading train:  74%|███████▎  | 210/285 [03:48<01:20,  1.07s/it]Loading train:  74%|███████▍  | 211/285 [03:49<01:13,  1.00it/s]Loading train:  74%|███████▍  | 212/285 [03:50<01:11,  1.02it/s]Loading train:  75%|███████▍  | 213/285 [03:51<01:10,  1.02it/s]Loading train:  75%|███████▌  | 214/285 [03:51<01:07,  1.06it/s]Loading train:  75%|███████▌  | 215/285 [03:53<01:15,  1.08s/it]Loading train:  76%|███████▌  | 216/285 [03:54<01:11,  1.03s/it]Loading train:  76%|███████▌  | 217/285 [03:55<01:10,  1.04s/it]Loading train:  76%|███████▋  | 218/285 [03:56<01:07,  1.01s/it]Loading train:  77%|███████▋  | 219/285 [03:57<01:10,  1.07s/it]Loading train:  77%|███████▋  | 220/285 [03:58<01:04,  1.01it/s]Loading train:  78%|███████▊  | 221/285 [03:59<01:01,  1.05it/s]Loading train:  78%|███████▊  | 222/285 [04:00<00:58,  1.07it/s]Loading train:  78%|███████▊  | 223/285 [04:00<00:55,  1.12it/s]Loading train:  79%|███████▊  | 224/285 [04:01<00:58,  1.04it/s]Loading train:  79%|███████▉  | 225/285 [04:02<00:54,  1.10it/s]Loading train:  79%|███████▉  | 226/285 [04:03<00:57,  1.02it/s]Loading train:  80%|███████▉  | 227/285 [04:04<00:56,  1.03it/s]Loading train:  80%|████████  | 228/285 [04:06<01:01,  1.09s/it]Loading train:  80%|████████  | 229/285 [04:07<01:00,  1.08s/it]Loading train:  81%|████████  | 230/285 [04:08<00:55,  1.01s/it]Loading train:  81%|████████  | 231/285 [04:08<00:51,  1.05it/s]Loading train:  81%|████████▏ | 232/285 [04:10<00:54,  1.03s/it]Loading train:  82%|████████▏ | 233/285 [04:11<00:51,  1.00it/s]Loading train:  82%|████████▏ | 234/285 [04:12<00:51,  1.02s/it]Loading train:  82%|████████▏ | 235/285 [04:12<00:47,  1.05it/s]Loading train:  83%|████████▎ | 236/285 [04:14<00:49,  1.00s/it]Loading train:  83%|████████▎ | 237/285 [04:15<00:49,  1.02s/it]Loading train:  84%|████████▎ | 238/285 [04:16<00:48,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [04:17<00:47,  1.04s/it]Loading train:  84%|████████▍ | 240/285 [04:18<00:45,  1.01s/it]Loading train:  85%|████████▍ | 241/285 [04:19<00:44,  1.00s/it]Loading train:  85%|████████▍ | 242/285 [04:19<00:40,  1.06it/s]Loading train:  85%|████████▌ | 243/285 [04:20<00:39,  1.07it/s]Loading train:  86%|████████▌ | 244/285 [04:21<00:40,  1.02it/s]Loading train:  86%|████████▌ | 245/285 [04:23<00:39,  1.01it/s]Loading train:  86%|████████▋ | 246/285 [04:24<00:40,  1.05s/it]Loading train:  87%|████████▋ | 247/285 [04:25<00:40,  1.05s/it]Loading train:  87%|████████▋ | 248/285 [04:26<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:27<00:35,  1.00it/s]Loading train:  88%|████████▊ | 250/285 [04:28<00:35,  1.01s/it]Loading train:  88%|████████▊ | 251/285 [04:28<00:31,  1.07it/s]Loading train:  88%|████████▊ | 252/285 [04:30<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [04:31<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [04:32<00:33,  1.09s/it]Loading train:  89%|████████▉ | 255/285 [04:33<00:35,  1.19s/it]Loading train:  90%|████████▉ | 256/285 [04:34<00:32,  1.13s/it]Loading train:  90%|█████████ | 257/285 [04:35<00:30,  1.08s/it]Loading train:  91%|█████████ | 258/285 [04:37<00:29,  1.11s/it]Loading train:  91%|█████████ | 259/285 [04:37<00:27,  1.05s/it]Loading train:  91%|█████████ | 260/285 [04:38<00:26,  1.06s/it]Loading train:  92%|█████████▏| 261/285 [04:39<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [04:40<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [04:41<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:42<00:19,  1.09it/s]Loading train:  93%|█████████▎| 265/285 [04:43<00:19,  1.00it/s]Loading train:  93%|█████████▎| 266/285 [04:44<00:19,  1.00s/it]Loading train:  94%|█████████▎| 267/285 [04:45<00:17,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [04:46<00:17,  1.03s/it]Loading train:  94%|█████████▍| 269/285 [04:47<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:48<00:14,  1.03it/s]Loading train:  95%|█████████▌| 271/285 [04:49<00:12,  1.08it/s]Loading train:  95%|█████████▌| 272/285 [04:50<00:11,  1.09it/s]Loading train:  96%|█████████▌| 273/285 [04:51<00:10,  1.14it/s]Loading train:  96%|█████████▌| 274/285 [04:52<00:09,  1.12it/s]Loading train:  96%|█████████▋| 275/285 [04:53<00:09,  1.05it/s]Loading train:  97%|█████████▋| 276/285 [04:54<00:09,  1.02s/it]Loading train:  97%|█████████▋| 277/285 [04:55<00:08,  1.01s/it]Loading train:  98%|█████████▊| 278/285 [04:56<00:06,  1.01it/s]Loading train:  98%|█████████▊| 279/285 [04:57<00:06,  1.04s/it]Loading train:  98%|█████████▊| 280/285 [04:58<00:04,  1.00it/s]Loading train:  99%|█████████▊| 281/285 [04:59<00:04,  1.00s/it]Loading train:  99%|█████████▉| 282/285 [05:00<00:03,  1.01s/it]Loading train:  99%|█████████▉| 283/285 [05:01<00:02,  1.07s/it]Loading train: 100%|█████████▉| 284/285 [05:02<00:01,  1.06s/it]Loading train: 100%|██████████| 285/285 [05:03<00:00,  1.08s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 46.14it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:07, 36.81it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:06, 40.95it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:05, 47.63it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:04, 54.50it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:04, 60.52it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:03, 68.09it/s]concatenating: train:  22%|██▏       | 63/285 [00:00<00:02, 78.80it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 99.06it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:01, 111.67it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:01, 115.35it/s]concatenating: train:  49%|████▉     | 140/285 [00:01<00:01, 131.08it/s]concatenating: train:  59%|█████▊    | 167/285 [00:01<00:00, 154.51it/s]concatenating: train:  71%|███████   | 203/285 [00:01<00:00, 185.54it/s]concatenating: train:  84%|████████▍ | 239/285 [00:01<00:00, 217.02it/s]concatenating: train:  96%|█████████▌| 274/285 [00:01<00:00, 244.30it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 164.51it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.44s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.40s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 129.87it/s]2019-07-11 01:33:37.736400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 01:33:37.736489: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 01:33:37.736503: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 01:33:37.736512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 01:33:37.736901: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.07it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  6.08it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:06,  5.81it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.38it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.67it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.47it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.78it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.51it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.24it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.99it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.62it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.75it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.31it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.89it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.56it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.95it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.22it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.87it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.91it/s] 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 13)   793         dropout_7[0][0]                  
==================================================================================================
Total params: 246,193
Trainable params: 71,353
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 2.6934 - acc: 0.3652 - mDice: 0.1182 - val_loss: 2.2860 - val_acc: 0.9005 - val_mDice: 0.1964

Epoch 00001: val_mDice improved from -inf to 0.19643, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.9938 - acc: 0.8838 - mDice: 0.3617 - val_loss: 1.1913 - val_acc: 0.9145 - val_mDice: 0.4171

Epoch 00002: val_mDice improved from 0.19643 to 0.41708, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 12s - loss: 0.7403 - acc: 0.8914 - mDice: 0.4620 - val_loss: 1.0019 - val_acc: 0.9145 - val_mDice: 0.4715

Epoch 00003: val_mDice improved from 0.41708 to 0.47154, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.6427 - acc: 0.8963 - mDice: 0.5102 - val_loss: 0.9057 - val_acc: 0.9184 - val_mDice: 0.5286

Epoch 00004: val_mDice improved from 0.47154 to 0.52857, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.5827 - acc: 0.9006 - mDice: 0.5428 - val_loss: 0.9066 - val_acc: 0.9222 - val_mDice: 0.5301

Epoch 00005: val_mDice improved from 0.52857 to 0.53013, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.5470 - acc: 0.9043 - mDice: 0.5633 - val_loss: 0.9123 - val_acc: 0.9240 - val_mDice: 0.5286

Epoch 00006: val_mDice did not improve from 0.53013
Epoch 7/300
 - 12s - loss: 0.5153 - acc: 0.9083 - mDice: 0.5821 - val_loss: 0.8849 - val_acc: 0.9291 - val_mDice: 0.5450

Epoch 00007: val_mDice improved from 0.53013 to 0.54499, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.4974 - acc: 0.9118 - mDice: 0.5931 - val_loss: 0.8700 - val_acc: 0.9311 - val_mDice: 0.5456

Epoch 00008: val_mDice improved from 0.54499 to 0.54560, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 12s - loss: 0.4742 - acc: 0.9161 - mDice: 0.6074 - val_loss: 0.8591 - val_acc: 0.9365 - val_mDice: 0.5423

Epoch 00009: val_mDice did not improve from 0.54560
Epoch 10/300
 - 12s - loss: 0.4594 - acc: 0.9213 - mDice: 0.6166 - val_loss: 0.8513 - val_acc: 0.9409 - val_mDice: 0.5562

Epoch 00010: val_mDice improved from 0.54560 to 0.55622, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 12s - loss: 0.4450 - acc: 0.9268 - mDice: 0.6257 - val_loss: 0.8445 - val_acc: 0.9383 - val_mDice: 0.5534

Epoch 00011: val_mDice did not improve from 0.55622
Epoch 12/300
 - 12s - loss: 0.4343 - acc: 0.9304 - mDice: 0.6324 - val_loss: 0.8655 - val_acc: 0.9361 - val_mDice: 0.5542

Epoch 00012: val_mDice did not improve from 0.55622
Epoch 13/300
 - 12s - loss: 0.4261 - acc: 0.9319 - mDice: 0.6378 - val_loss: 0.8325 - val_acc: 0.9381 - val_mDice: 0.5608

Epoch 00013: val_mDice improved from 0.55622 to 0.56083, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 12s - loss: 0.4188 - acc: 0.9332 - mDice: 0.6426 - val_loss: 0.8862 - val_acc: 0.9360 - val_mDice: 0.5515

Epoch 00014: val_mDice did not improve from 0.56083
Epoch 15/300
 - 12s - loss: 0.4103 - acc: 0.9342 - mDice: 0.6482 - val_loss: 0.8604 - val_acc: 0.9339 - val_mDice: 0.5515

Epoch 00015: val_mDice did not improve from 0.56083
Epoch 16/300
 - 12s - loss: 0.4013 - acc: 0.9351 - mDice: 0.6541 - val_loss: 0.8179 - val_acc: 0.9392 - val_mDice: 0.5675

Epoch 00016: val_mDice improved from 0.56083 to 0.56750, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 12s - loss: 0.3950 - acc: 0.9357 - mDice: 0.6584 - val_loss: 0.8637 - val_acc: 0.9281 - val_mDice: 0.5374

Epoch 00017: val_mDice did not improve from 0.56750
Epoch 18/300
 - 12s - loss: 0.3925 - acc: 0.9364 - mDice: 0.6603 - val_loss: 0.8545 - val_acc: 0.9365 - val_mDice: 0.5591

Epoch 00018: val_mDice did not improve from 0.56750
Epoch 19/300
 - 12s - loss: 0.3861 - acc: 0.9370 - mDice: 0.6646 - val_loss: 0.8475 - val_acc: 0.9337 - val_mDice: 0.5503

Epoch 00019: val_mDice did not improve from 0.56750
Epoch 20/300
 - 12s - loss: 0.3830 - acc: 0.9372 - mDice: 0.6667 - val_loss: 0.8462 - val_acc: 0.9371 - val_mDice: 0.5634

Epoch 00020: val_mDice did not improve from 0.56750
Epoch 21/300
 - 12s - loss: 0.3760 - acc: 0.9381 - mDice: 0.6716 - val_loss: 0.8432 - val_acc: 0.9428 - val_mDice: 0.5621

Epoch 00021: val_mDice did not improve from 0.56750
Epoch 22/300
 - 12s - loss: 0.3741 - acc: 0.9382 - mDice: 0.6729 - val_loss: 0.8441 - val_acc: 0.9378 - val_mDice: 0.5629

Epoch 00022: val_mDice did not improve from 0.56750
Epoch 23/300
 - 12s - loss: 0.3702 - acc: 0.9385 - mDice: 0.6756 - val_loss: 0.8440 - val_acc: 0.9355 - val_mDice: 0.5572

Epoch 00023: val_mDice did not improve from 0.56750
Epoch 24/300
 - 13s - loss: 0.3680 - acc: 0.9388 - mDice: 0.6774 - val_loss: 0.8219 - val_acc: 0.9388 - val_mDice: 0.5705

Epoch 00024: val_mDice improved from 0.56750 to 0.57051, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 13s - loss: 0.3624 - acc: 0.9393 - mDice: 0.6811 - val_loss: 0.8141 - val_acc: 0.9368 - val_mDice: 0.5537

Epoch 00025: val_mDice did not improve from 0.57051
Epoch 26/300
 - 13s - loss: 0.3593 - acc: 0.9396 - mDice: 0.6834 - val_loss: 0.8286 - val_acc: 0.9401 - val_mDice: 0.5533

Epoch 00026: val_mDice did not improve from 0.57051
Epoch 27/300
 - 13s - loss: 0.3578 - acc: 0.9397 - mDice: 0.6843 - val_loss: 0.8324 - val_acc: 0.9373 - val_mDice: 0.5610

Epoch 00027: val_mDice did not improve from 0.57051
Epoch 28/300
 - 12s - loss: 0.3541 - acc: 0.9401 - mDice: 0.6869 - val_loss: 0.8298 - val_acc: 0.9359 - val_mDice: 0.5640

Epoch 00028: val_mDice did not improve from 0.57051
Epoch 29/300
 - 14s - loss: 0.3504 - acc: 0.9404 - mDice: 0.6896 - val_loss: 0.8604 - val_acc: 0.9354 - val_mDice: 0.5493

Epoch 00029: val_mDice did not improve from 0.57051
Epoch 30/300
 - 13s - loss: 0.3492 - acc: 0.9406 - mDice: 0.6905 - val_loss: 0.8604 - val_acc: 0.9351 - val_mDice: 0.5389

Epoch 00030: val_mDice did not improve from 0.57051
Epoch 31/300
 - 14s - loss: 0.3455 - acc: 0.9409 - mDice: 0.6932 - val_loss: 0.8656 - val_acc: 0.9388 - val_mDice: 0.5605

Epoch 00031: val_mDice did not improve from 0.57051
Epoch 32/300
 - 14s - loss: 0.3460 - acc: 0.9410 - mDice: 0.6927 - val_loss: 0.8318 - val_acc: 0.9377 - val_mDice: 0.5660

Epoch 00032: val_mDice did not improve from 0.57051
Epoch 33/300
 - 13s - loss: 0.3411 - acc: 0.9412 - mDice: 0.6963 - val_loss: 0.8486 - val_acc: 0.9399 - val_mDice: 0.5627

Epoch 00033: val_mDice did not improve from 0.57051
Epoch 34/300
 - 14s - loss: 0.3397 - acc: 0.9414 - mDice: 0.6973 - val_loss: 0.8633 - val_acc: 0.9350 - val_mDice: 0.5423

Epoch 00034: val_mDice did not improve from 0.57051
Epoch 35/300
 - 13s - loss: 0.3362 - acc: 0.9417 - mDice: 0.6999 - val_loss: 0.8751 - val_acc: 0.9321 - val_mDice: 0.5492

Epoch 00035: val_mDice did not improve from 0.57051
Epoch 36/300
 - 14s - loss: 0.3354 - acc: 0.9419 - mDice: 0.7005 - val_loss: 0.8669 - val_acc: 0.9337 - val_mDice: 0.5511

Epoch 00036: val_mDice did not improve from 0.57051
Epoch 37/300
 - 13s - loss: 0.3333 - acc: 0.9419 - mDice: 0.7020 - val_loss: 0.8698 - val_acc: 0.9386 - val_mDice: 0.5584

Epoch 00037: val_mDice did not improve from 0.57051
Epoch 38/300
 - 13s - loss: 0.3317 - acc: 0.9421 - mDice: 0.7032 - val_loss: 0.8175 - val_acc: 0.9413 - val_mDice: 0.5630

Epoch 00038: val_mDice did not improve from 0.57051
Epoch 39/300
 - 13s - loss: 0.3315 - acc: 0.9424 - mDice: 0.7034 - val_loss: 0.7926 - val_acc: 0.9392 - val_mDice: 0.5677

Epoch 00039: val_mDice did not improve from 0.57051
Epoch 40/300
 - 13s - loss: 0.3274 - acc: 0.9426 - mDice: 0.7064 - val_loss: 0.8189 - val_acc: 0.9397 - val_mDice: 0.5584

Epoch 00040: val_mDice did not improve from 0.57051
Epoch 41/300
 - 13s - loss: 0.3248 - acc: 0.9429 - mDice: 0.7083 - val_loss: 0.8524 - val_acc: 0.9349 - val_mDice: 0.5380

Epoch 00041: val_mDice did not improve from 0.57051
Epoch 42/300
 - 14s - loss: 0.3253 - acc: 0.9428 - mDice: 0.7079 - val_loss: 0.7610 - val_acc: 0.9418 - val_mDice: 0.5643

Epoch 00042: val_mDice did not improve from 0.57051
Epoch 43/300
 - 13s - loss: 0.3225 - acc: 0.9431 - mDice: 0.7101 - val_loss: 0.8383 - val_acc: 0.9373 - val_mDice: 0.5493

Epoch 00043: val_mDice did not improve from 0.57051
Epoch 44/300
 - 13s - loss: 0.3225 - acc: 0.9431 - mDice: 0.7100 - val_loss: 0.8455 - val_acc: 0.9393 - val_mDice: 0.5613

Epoch 00044: val_mDice did not improve from 0.57051
Epoch 45/300
 - 13s - loss: 0.3208 - acc: 0.9432 - mDice: 0.7113 - val_loss: 0.8056 - val_acc: 0.9369 - val_mDice: 0.5577

Epoch 00045: val_mDice did not improve from 0.57051
Epoch 46/300
 - 12s - loss: 0.3201 - acc: 0.9434 - mDice: 0.7118 - val_loss: 0.8048 - val_acc: 0.9379 - val_mDice: 0.5640

Epoch 00046: val_mDice did not improve from 0.57051
Epoch 47/300
 - 12s - loss: 0.3173 - acc: 0.9435 - mDice: 0.7139 - val_loss: 0.7825 - val_acc: 0.9399 - val_mDice: 0.5705

Epoch 00047: val_mDice did not improve from 0.57051
Epoch 48/300
 - 12s - loss: 0.3145 - acc: 0.9437 - mDice: 0.7160 - val_loss: 0.7789 - val_acc: 0.9367 - val_mDice: 0.5590

Epoch 00048: val_mDice did not improve from 0.57051
Epoch 49/300
 - 12s - loss: 0.3162 - acc: 0.9436 - mDice: 0.7146 - val_loss: 0.8075 - val_acc: 0.9358 - val_mDice: 0.5511

Epoch 00049: val_mDice did not improve from 0.57051
Epoch 50/300
 - 11s - loss: 0.3141 - acc: 0.9437 - mDice: 0.7162 - val_loss: 0.7768 - val_acc: 0.9432 - val_mDice: 0.5714

Epoch 00050: val_mDice improved from 0.57051 to 0.57144, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB0_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 51/300
 - 12s - loss: 0.3144 - acc: 0.9438 - mDice: 0.7161 - val_loss: 0.7683 - val_acc: 0.9412 - val_mDice: 0.5629

Epoch 00051: val_mDice did not improve from 0.57144
Epoch 52/300
 - 12s - loss: 0.3110 - acc: 0.9441 - mDice: 0.7186 - val_loss: 0.8031 - val_acc: 0.9371 - val_mDice: 0.5493

Epoch 00052: val_mDice did not improve from 0.57144
Epoch 53/300
 - 12s - loss: 0.3093 - acc: 0.9441 - mDice: 0.7198 - val_loss: 0.7856 - val_acc: 0.9408 - val_mDice: 0.5614

Epoch 00053: val_mDice did not improve from 0.57144
Epoch 54/300
 - 12s - loss: 0.3097 - acc: 0.9442 - mDice: 0.7195 - val_loss: 0.7997 - val_acc: 0.9397 - val_mDice: 0.5536

Epoch 00054: val_mDice did not improve from 0.57144
Epoch 55/300
 - 12s - loss: 0.3086 - acc: 0.9443 - mDice: 0.7204 - val_loss: 0.7553 - val_acc: 0.9406 - val_mDice: 0.5513

Epoch 00055: val_mDice did not improve from 0.57144
Epoch 56/300
 - 12s - loss: 0.3065 - acc: 0.9445 - mDice: 0.7219 - val_loss: 0.7694 - val_acc: 0.9383 - val_mDice: 0.5609

Epoch 00056: val_mDice did not improve from 0.57144
Epoch 57/300
 - 12s - loss: 0.3065 - acc: 0.9445 - mDice: 0.7221 - val_loss: 0.7690 - val_acc: 0.9374 - val_mDice: 0.5631

Epoch 00057: val_mDice did not improve from 0.57144
Epoch 58/300
 - 12s - loss: 0.3047 - acc: 0.9446 - mDice: 0.7233 - val_loss: 0.7399 - val_acc: 0.9394 - val_mDice: 0.5646

Epoch 00058: val_mDice did not improve from 0.57144
Epoch 59/300
 - 12s - loss: 0.3035 - acc: 0.9447 - mDice: 0.7241 - val_loss: 0.7670 - val_acc: 0.9365 - val_mDice: 0.5489

Epoch 00059: val_mDice did not improve from 0.57144
Epoch 60/300
 - 12s - loss: 0.3038 - acc: 0.9447 - mDice: 0.7240 - val_loss: 0.7671 - val_acc: 0.9399 - val_mDice: 0.5593

Epoch 00060: val_mDice did not improve from 0.57144
Epoch 61/300
 - 12s - loss: 0.3023 - acc: 0.9449 - mDice: 0.7251 - val_loss: 0.7473 - val_acc: 0.9427 - val_mDice: 0.5628

Epoch 00061: val_mDice did not improve from 0.57144
Epoch 62/300
 - 12s - loss: 0.3007 - acc: 0.9450 - mDice: 0.7263 - val_loss: 0.7706 - val_acc: 0.9360 - val_mDice: 0.5534

Epoch 00062: val_mDice did not improve from 0.57144
Epoch 63/300
 - 12s - loss: 0.3015 - acc: 0.9450 - mDice: 0.7257 - val_loss: 0.7224 - val_acc: 0.9391 - val_mDice: 0.5686

Epoch 00063: val_mDice did not improve from 0.57144
Epoch 64/300
 - 12s - loss: 0.2983 - acc: 0.9452 - mDice: 0.7281 - val_loss: 0.7904 - val_acc: 0.9360 - val_mDice: 0.5542

Epoch 00064: val_mDice did not improve from 0.57144
Epoch 65/300
 - 12s - loss: 0.2973 - acc: 0.9453 - mDice: 0.7288 - val_loss: 0.7325 - val_acc: 0.9406 - val_mDice: 0.5634

Epoch 00065: val_mDice did not improve from 0.57144
Epoch 66/300
 - 12s - loss: 0.2994 - acc: 0.9452 - mDice: 0.7273 - val_loss: 0.7214 - val_acc: 0.9415 - val_mDice: 0.5657

Epoch 00066: val_mDice did not improve from 0.57144
Epoch 67/300
 - 11s - loss: 0.2970 - acc: 0.9453 - mDice: 0.7291 - val_loss: 0.7408 - val_acc: 0.9406 - val_mDice: 0.5534

Epoch 00067: val_mDice did not improve from 0.57144
Epoch 68/300
 - 12s - loss: 0.2979 - acc: 0.9452 - mDice: 0.7283 - val_loss: 0.7158 - val_acc: 0.9419 - val_mDice: 0.5613

Epoch 00068: val_mDice did not improve from 0.57144
Epoch 69/300
 - 12s - loss: 0.2968 - acc: 0.9454 - mDice: 0.7292 - val_loss: 0.7342 - val_acc: 0.9380 - val_mDice: 0.5606

Epoch 00069: val_mDice did not improve from 0.57144
Epoch 70/300
 - 12s - loss: 0.2933 - acc: 0.9456 - mDice: 0.7319 - val_loss: 0.7385 - val_acc: 0.9407 - val_mDice: 0.5701

Epoch 00070: val_mDice did not improve from 0.57144
Epoch 71/300
 - 12s - loss: 0.2956 - acc: 0.9455 - mDice: 0.7301 - val_loss: 0.7856 - val_acc: 0.9378 - val_mDice: 0.5495

Epoch 00071: val_mDice did not improve from 0.57144
Epoch 72/300
 - 12s - loss: 0.2921 - acc: 0.9459 - mDice: 0.7328 - val_loss: 0.7082 - val_acc: 0.9393 - val_mDice: 0.5637

Epoch 00072: val_mDice did not improve from 0.57144
Epoch 73/300
 - 12s - loss: 0.2916 - acc: 0.9459 - mDice: 0.7333 - val_loss: 0.7672 - val_acc: 0.9409 - val_mDice: 0.5524

Epoch 00073: val_mDice did not improve from 0.57144
Epoch 74/300
 - 12s - loss: 0.2932 - acc: 0.9458 - mDice: 0.7320 - val_loss: 0.7267 - val_acc: 0.9390 - val_mDice: 0.5559

Epoch 00074: val_mDice did not improve from 0.57144
Epoch 75/300
 - 12s - loss: 0.2933 - acc: 0.9456 - mDice: 0.7320 - val_loss: 0.7472 - val_acc: 0.9376 - val_mDice: 0.5579

Epoch 00075: val_mDice did not improve from 0.57144
Epoch 76/300
 - 12s - loss: 0.2898 - acc: 0.9461 - mDice: 0.7345 - val_loss: 0.7235 - val_acc: 0.9403 - val_mDice: 0.5589

Epoch 00076: val_mDice did not improve from 0.57144
Epoch 77/300
 - 12s - loss: 0.2893 - acc: 0.9461 - mDice: 0.7350 - val_loss: 0.7393 - val_acc: 0.9420 - val_mDice: 0.5622

Epoch 00077: val_mDice did not improve from 0.57144
Epoch 78/300
 - 12s - loss: 0.2902 - acc: 0.9460 - mDice: 0.7343 - val_loss: 0.7364 - val_acc: 0.9391 - val_mDice: 0.5650

Epoch 00078: val_mDice did not improve from 0.57144
Epoch 79/300
 - 12s - loss: 0.2881 - acc: 0.9462 - mDice: 0.7359 - val_loss: 0.7161 - val_acc: 0.9392 - val_mDice: 0.5681

Epoch 00079: val_mDice did not improve from 0.57144
Epoch 80/300
 - 11s - loss: 0.2865 - acc: 0.9464 - mDice: 0.7372 - val_loss: 0.7160 - val_acc: 0.9372 - val_mDice: 0.5507

Epoch 00080: val_mDice did not improve from 0.57144
Epoch 81/300
 - 12s - loss: 0.2871 - acc: 0.9463 - mDice: 0.7367 - val_loss: 0.7529 - val_acc: 0.9374 - val_mDice: 0.5527

Epoch 00081: val_mDice did not improve from 0.57144
Epoch 82/300
 - 12s - loss: 0.2874 - acc: 0.9463 - mDice: 0.7365 - val_loss: 0.7397 - val_acc: 0.9375 - val_mDice: 0.5490

Epoch 00082: val_mDice did not improve from 0.57144
Epoch 83/300
 - 12s - loss: 0.2865 - acc: 0.9462 - mDice: 0.7370 - val_loss: 0.7203 - val_acc: 0.9386 - val_mDice: 0.5551

Epoch 00083: val_mDice did not improve from 0.57144
Epoch 84/300
 - 12s - loss: 0.2867 - acc: 0.9463 - mDice: 0.7371 - val_loss: 0.7859 - val_acc: 0.9391 - val_mDice: 0.5548

Epoch 00084: val_mDice did not improve from 0.57144
Epoch 85/300
 - 12s - loss: 0.2854 - acc: 0.9463 - mDice: 0.7381 - val_loss: 0.7448 - val_acc: 0.9395 - val_mDice: 0.5543

Epoch 00085: val_mDice did not improve from 0.57144
Epoch 86/300
 - 12s - loss: 0.2862 - acc: 0.9465 - mDice: 0.7375 - val_loss: 0.7076 - val_acc: 0.9413 - val_mDice: 0.5541

Epoch 00086: val_mDice did not improve from 0.57144
Epoch 87/300
 - 12s - loss: 0.2840 - acc: 0.9467 - mDice: 0.7391 - val_loss: 0.7565 - val_acc: 0.9396 - val_mDice: 0.5500

Epoch 00087: val_mDice did not improve from 0.57144
Epoch 88/300
 - 11s - loss: 0.2825 - acc: 0.9467 - mDice: 0.7403 - val_loss: 0.6972 - val_acc: 0.9420 - val_mDice: 0.5648

Epoch 00088: val_mDice did not improve from 0.57144
Epoch 89/300
 - 11s - loss: 0.2835 - acc: 0.9465 - mDice: 0.7395 - val_loss: 0.7225 - val_acc: 0.9379 - val_mDice: 0.5610

Epoch 00089: val_mDice did not improve from 0.57144
Epoch 90/300
 - 12s - loss: 0.2820 - acc: 0.9466 - mDice: 0.7405 - val_loss: 0.7276 - val_acc: 0.9381 - val_mDice: 0.5464

Epoch 00090: val_mDice did not improve from 0.57144
Restoring model weights from the end of the best epoch
Epoch 00090: early stopping
{'val_loss': [2.286030494249784, 1.1913157059596136, 1.0019294802959149, 0.9057351557108072, 0.9065923117674314, 0.9122566007650815, 0.884876189323572, 0.8700321202094738, 0.8591002455124488, 0.8512986990121695, 0.8444587313211881, 0.8655071120995742, 0.8325334810293638, 0.8861571275270902, 0.8604340232335604, 0.8178568551173577, 0.8636655188523806, 0.8544589418631333, 0.8475449520807999, 0.8462080817956191, 0.843204915523529, 0.8441324234008789, 0.8440104722976685, 0.8219157411501958, 0.8140587485753573, 0.828557129089649, 0.8323532067812406, 0.8297667365807754, 0.8604214489459991, 0.8604329480574682, 0.8656231875603015, 0.8317514612124517, 0.8485645009921148, 0.8633460792211386, 0.8751296882445996, 0.8669209296886737, 0.8697839608559241, 0.8174761487887456, 0.7925500938525567, 0.8189238447409409, 0.8523738980293274, 0.7610130791480725, 0.8383337626090417, 0.8455044673039362, 0.805557335798557, 0.8048367569079766, 0.7825227219324845, 0.7788527011871338, 0.8075220149296981, 0.7767730080164396, 0.7682799467673669, 0.8030772438416114, 0.7856057423811692, 0.7997088501086602, 0.755318494943472, 0.7694365840691787, 0.7690359216469985, 0.7398672929176917, 0.7670460733083578, 0.7670683562755585, 0.7473226258387933, 0.770572339112942, 0.7223546757147863, 0.7903915070570432, 0.7325483881510221, 0.7214488753905663, 0.7407911970065191, 0.7157539885777694, 0.7342211695817801, 0.7384919340793903, 0.7856448957553277, 0.7082330378202292, 0.7671716580024133, 0.7267215870893918, 0.7472459444632897, 0.7234907333667462, 0.7392734495493082, 0.736400109070998, 0.7160681027632493, 0.7160341602105361, 0.7529411613941193, 0.7396509532745068, 0.7203201949596405, 0.7858574298711923, 0.7447929703272306, 0.7075890692380759, 0.7564532252458426, 0.6971772771615249, 0.7225050788659316, 0.727567012493427], 'val_acc': [0.9005269683324374, 0.914527063186352, 0.914501646390328, 0.9183547634344834, 0.9221592751833109, 0.924017642553036, 0.9290680656066308, 0.9311297925618979, 0.9365476851279919, 0.9408584649746234, 0.9383043463413532, 0.9361155010186709, 0.9380685801689441, 0.9360183775424957, 0.9338988317893102, 0.9392011692890754, 0.9281065097221961, 0.9364830095034379, 0.9336931315752176, 0.9371301508866824, 0.9427861410837907, 0.9378397579376514, 0.9355121942666861, 0.9387620251912338, 0.9368227811960074, 0.9400910437107086, 0.9372896597935603, 0.935932858632161, 0.935396650662789, 0.9351169398197761, 0.9387712501562558, 0.9377195674639481, 0.9398969113826752, 0.9350499419065622, 0.9321005688263819, 0.9336954653263092, 0.9386140750004694, 0.941279106415235, 0.9391549665194291, 0.9396657852026132, 0.9348857998847961, 0.9417552466575916, 0.9372896873033963, 0.9392913327767298, 0.936862058364428, 0.937855954353626, 0.9398899743190179, 0.9366840720176697, 0.9357595420800723, 0.9431536335211533, 0.9411681730013627, 0.9370746841797462, 0.9407729460642889, 0.939656525850296, 0.9405741462340722, 0.9383436693595006, 0.9374260604381561, 0.9393861087468954, 0.9364783488787137, 0.9398991946990674, 0.9426728762113131, 0.9359906751375932, 0.9391041077100314, 0.9360137833998754, 0.9406226988022144, 0.9415218417461102, 0.9405533373355865, 0.9419471277640417, 0.9380408548391782, 0.9406504470568436, 0.9378443841750805, 0.9393444726100335, 0.940911604807927, 0.9389746532990382, 0.9376456118547, 0.9403430085915786, 0.9420488178730011, 0.9391156526712271, 0.939175743323106, 0.9372295806041131, 0.9373775147474729, 0.9375323492747086, 0.9386487855361059, 0.939108704145138, 0.9395386416178483, 0.9412536919116974, 0.9395733017187852, 0.9420372706193191, 0.9378905961146722, 0.9381009730008932], 'val_mDice': [0.19642636294548327, 0.4170819910672995, 0.4715367979728259, 0.5285690421095262, 0.5301273511006281, 0.5285760536789894, 0.5449936364132625, 0.5455985630934055, 0.5422567885655624, 0.5562193508331592, 0.553366849055657, 0.5542407173376817, 0.5608348238926667, 0.5515446078318816, 0.5515242582903459, 0.5674999230183088, 0.5374295677130039, 0.5591060530680877, 0.5502701708330557, 0.5633873887933217, 0.5620624262552995, 0.5628638559809098, 0.5572354549971911, 0.5705090956046031, 0.5536783687197245, 0.5533171049677409, 0.5610039526453385, 0.5639801151477374, 0.5492696323646948, 0.5388593696630918, 0.5604992296833259, 0.565976760421808, 0.5627149801987869, 0.5423438798349637, 0.5492265614179465, 0.551084884084188, 0.5584307605257401, 0.5630196327200303, 0.5676952219353273, 0.5584475329289069, 0.5380484238266945, 0.5643385132917991, 0.5492639128978436, 0.5612974184063765, 0.5576964840292931, 0.5640239818738058, 0.570480034328424, 0.559044613287999, 0.5511183796020654, 0.5714400407786553, 0.5628536956814619, 0.5493212731984946, 0.5614163096134479, 0.5536315770676503, 0.5513158552348614, 0.5609422483696387, 0.5631312108956851, 0.5645971212249535, 0.548894448349109, 0.5592569760405101, 0.5628179672818917, 0.5534356752267251, 0.5685701708380992, 0.5542425043307818, 0.5633921892597125, 0.56568054912182, 0.5534401707924329, 0.5613474762783601, 0.5605858386709139, 0.5700727755633684, 0.5495319959635918, 0.5637226540308732, 0.552429138467862, 0.555887236044957, 0.5579321894508141, 0.558909511910035, 0.5622342630074575, 0.5650380571874288, 0.5681248717010021, 0.550746703090576, 0.5526982201979711, 0.5490155827540618, 0.5550701795862272, 0.5548108500929979, 0.5542822296802814, 0.5541409319983079, 0.5499879671977117, 0.5648453350250537, 0.5610455457980816, 0.5463690591546205], 'loss': [2.693412377541217, 0.9938270416765935, 0.7402951011224107, 0.6426854334193755, 0.5826976789184066, 0.5469715212814749, 0.5153281857779817, 0.4974215066126217, 0.47421129159598424, 0.4594441873087474, 0.44500675489626984, 0.4342612621227468, 0.4260932070862859, 0.41876718907088883, 0.4102936176662019, 0.4013078254927989, 0.3950309861270328, 0.3925259140137431, 0.3860917919859349, 0.38299691848601847, 0.37595731348148365, 0.37410837592458984, 0.370152085802382, 0.3680054048138286, 0.362432660370925, 0.3593127478299233, 0.3577934362940448, 0.35408083615867697, 0.3504070488935817, 0.34920962128891647, 0.34547968763855674, 0.34598689385251147, 0.34114539983867775, 0.3397362882455732, 0.33619021762509105, 0.3353612084379058, 0.33334606464835076, 0.3316940520534895, 0.33149533255353336, 0.32738962617789447, 0.32480520691080506, 0.3252533056947519, 0.32246419170361695, 0.32254323017264075, 0.3207642068109158, 0.3200698295367838, 0.31734257215537964, 0.3145028211215562, 0.316223366662034, 0.3141001555012192, 0.3143999670266028, 0.3110494340361017, 0.3092958039433976, 0.30972475526430265, 0.3085789046010045, 0.3065334141424834, 0.306480544591691, 0.3047302337680302, 0.3034974013122039, 0.3038118496340689, 0.3022719581309889, 0.3007416742474437, 0.3014982937227302, 0.29828559507976693, 0.29730706085503944, 0.29941690484008415, 0.2969798268503801, 0.29790984340548726, 0.29683187024835006, 0.2932797948158415, 0.29564348199342677, 0.29211308162260524, 0.29155563840366516, 0.29324259223296373, 0.2932571919490125, 0.2898292901451535, 0.28928486291392314, 0.290215504047979, 0.28811919934622293, 0.2864610855675905, 0.28706050938833444, 0.28744662917321057, 0.28652252777854337, 0.28668739883527866, 0.2853748416791793, 0.28616474648688667, 0.2839568691682213, 0.2824727014719995, 0.283461281632757, 0.2820315054204426], 'acc': [0.3652275878186047, 0.8837960879488052, 0.8913631591092811, 0.8963190531594325, 0.9006127879143113, 0.9042742937228826, 0.908256278748905, 0.911825888916365, 0.9161288259621532, 0.921294223077071, 0.9268380113108884, 0.9303713999176711, 0.9319294073380943, 0.9332403826513469, 0.9342109425518881, 0.9350783953441967, 0.9357208693026396, 0.9363713920814551, 0.9369816971992772, 0.9371997804689218, 0.9380736148776267, 0.938215813887006, 0.9384992295312868, 0.9387725307571374, 0.9393265714155488, 0.9395811036868167, 0.9396653224717622, 0.9401245430849866, 0.940388935029831, 0.9405791099403745, 0.9409089946696253, 0.9410320762766471, 0.9412313827583956, 0.9413857750981471, 0.9417023110530435, 0.9418768490700993, 0.9419272852089092, 0.9421370957078699, 0.9423608983188585, 0.9425907303109926, 0.9429015929074698, 0.942832756507532, 0.9431455278433987, 0.9431078594834517, 0.9431872479119424, 0.943358797868943, 0.943492434093634, 0.9436694573929507, 0.9435504303475011, 0.9437220665424125, 0.9437717720996759, 0.9441040514426445, 0.9441269022517128, 0.9441950336039577, 0.9442910037554796, 0.9445133638988834, 0.9444993967490146, 0.944640238198431, 0.9446842276301318, 0.9447115409487477, 0.9448535589783501, 0.9450419534289461, 0.9449549367987866, 0.9452050976963002, 0.9452549376952124, 0.9451708694638048, 0.9453314670192287, 0.9451734402308789, 0.9454475020577324, 0.9456300250577782, 0.9455138117495492, 0.945870053605445, 0.9459225065943655, 0.9457691576025049, 0.9456396445757039, 0.9460677608598876, 0.9461183763458468, 0.9459958867009557, 0.9462380265492548, 0.9463935846619684, 0.946341490768632, 0.9463167258055681, 0.9462346299805237, 0.9463058871821834, 0.9463103186828035, 0.946472333666694, 0.9466769589683419, 0.9466925216240053, 0.946497497331675, 0.9466395536428183], 'mDice': [0.11815988082367589, 0.3617183729740985, 0.46202663305906705, 0.510244135342983, 0.5427855666378795, 0.5632858694033969, 0.5820698128034189, 0.5931339990847513, 0.6074454578913128, 0.6165923764595057, 0.6257389333100157, 0.6324359591922164, 0.6377985681608398, 0.6425618291791708, 0.6482047863489454, 0.6540571195518774, 0.6583773991195938, 0.6602508266407725, 0.6645553701315091, 0.6666808269191665, 0.6715558516377839, 0.6728874100130839, 0.6755934386502703, 0.6773871945233227, 0.6810609371385308, 0.6833501859233684, 0.684341723789404, 0.6869490530606753, 0.6895600467725158, 0.6905284207827884, 0.6932287878967306, 0.6927302923631725, 0.6962978987415416, 0.6973320539175974, 0.6998866160538412, 0.700458832599795, 0.7020432763265462, 0.7032289539801286, 0.7033760414499094, 0.7064111117759029, 0.7083479777963841, 0.7078905350759792, 0.7100960698655905, 0.7100031792672261, 0.7113397965998071, 0.7118384236175944, 0.7138810523880217, 0.7159620616572991, 0.714648101532755, 0.716160023079404, 0.7161132347910296, 0.7185790471558772, 0.7197735710666484, 0.7194990012342943, 0.72041132058603, 0.7218869888594501, 0.7220574035521837, 0.7232576272567458, 0.72414367825939, 0.7239624057475309, 0.7250574907341379, 0.7262785209838089, 0.725690788270846, 0.7281332004667262, 0.7288118917476116, 0.7273444832663117, 0.729050805271194, 0.7283255081274386, 0.7291816230916586, 0.7319282558827803, 0.7301140118599554, 0.7328336254527711, 0.7332520779182052, 0.7320401671846821, 0.732030560194561, 0.7345013990400463, 0.7350108910561224, 0.7342803239228705, 0.7359178646633483, 0.7371600503896443, 0.7367010729884371, 0.7364758690663681, 0.7370257368004653, 0.7370649560135712, 0.7380900224020568, 0.7374672225719336, 0.7391259103070696, 0.7402576143414202, 0.7394662751028329, 0.7405469519872347]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.11s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.89s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.73s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:23,  1.77s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:44,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:44,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:18,  1.56s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:15,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:25,  1.61s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:45,  1.69s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:04,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:39,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:54,  1.74s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:41,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:51,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:05,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:06,  1.81s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:46,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:41,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:27,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:40,  1.74s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:54,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:41,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:26,  1.71s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:38,  1.76s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:45,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:24,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:21,  1.72s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:21,  1.73s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:31,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:32,  1.78s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:06,  1.68s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:08,  1.70s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:04,  1.69s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:23,  1.77s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:10,  1.73s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:06,  1.72s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:58,  1.70s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:07,  1.74s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:59,  1.72s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:48,  1.68s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:52,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:05,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:50,  1.71s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:55,  1.74s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:05,  1.80s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<07:00,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:10,  1.84s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:54,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:50,  1.77s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<06:53,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:35,  1.72s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:38,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:32,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:38,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:50,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:38,  1.78s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:37,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:24,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:24,  1.77s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:09,  1.70s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:07,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<05:55,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<05:58,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<05:55,  1.68s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:02,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:06,  1.75s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:50,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:46,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:42,  1.66s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:50,  1.71s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:45,  1.69s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 83/285 [02:23<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:38,  1.68s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:49,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:43,  1.74s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:33,  1.69s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:34,  1.71s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:34,  1.72s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:23,  1.67s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:30,  1.71s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:19,  1.66s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:18,  1.67s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:24,  1.71s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:47<05:24,  1.73s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:21,  1.73s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:26,  1.76s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:09,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:12,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<04:59,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<05:01,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<05:03,  1.69s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<04:54,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [03:03<04:57,  1.67s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<04:48,  1.63s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<04:52,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:08<04:55,  1.69s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<04:47,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:49,  1.67s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<05:03,  1.77s/it]predicting train subjects:  40%|████      | 114/285 [03:15<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:17<04:57,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:56,  1.76s/it]predicting train subjects:  41%|████      | 117/285 [03:20<04:42,  1.68s/it]predicting train subjects:  41%|████▏     | 118/285 [03:22<04:31,  1.63s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:32,  1.64s/it]predicting train subjects:  42%|████▏     | 120/285 [03:25<04:26,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:22,  1.60s/it]predicting train subjects:  43%|████▎     | 122/285 [03:28<04:14,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:29<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:31<04:04,  1.52s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<04:00,  1.51s/it]predicting train subjects:  44%|████▍     | 126/285 [03:34<03:58,  1.50s/it]predicting train subjects:  45%|████▍     | 127/285 [03:35<03:52,  1.47s/it]predicting train subjects:  45%|████▍     | 128/285 [03:37<03:55,  1.50s/it]predicting train subjects:  45%|████▌     | 129/285 [03:38<03:51,  1.48s/it]predicting train subjects:  46%|████▌     | 130/285 [03:40<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:41<03:39,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [03:43<03:43,  1.46s/it]predicting train subjects:  47%|████▋     | 133/285 [03:44<03:42,  1.47s/it]predicting train subjects:  47%|████▋     | 134/285 [03:46<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:47<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:48<03:34,  1.44s/it]predicting train subjects:  48%|████▊     | 137/285 [03:50<03:43,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:52<03:39,  1.50s/it]predicting train subjects:  49%|████▉     | 139/285 [03:53<03:41,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [03:55<03:41,  1.53s/it]predicting train subjects:  49%|████▉     | 141/285 [03:56<03:33,  1.48s/it]predicting train subjects:  50%|████▉     | 142/285 [03:57<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [03:59<03:24,  1.44s/it]predicting train subjects:  51%|█████     | 144/285 [04:00<03:29,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:02<03:27,  1.48s/it]predicting train subjects:  51%|█████     | 146/285 [04:04<03:32,  1.53s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:05<03:26,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:07<03:27,  1.52s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:08<03:24,  1.50s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:09<03:21,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:11<03:23,  1.52s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:12<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:14<03:13,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:16<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:19<03:20,  1.56s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:19,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:22<03:18,  1.56s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:23<03:12,  1.53s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<03:07,  1.50s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:26<03:09,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<03:07,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:29<03:06,  1.53s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:31<03:00,  1.49s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:32<02:53,  1.45s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<02:56,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<02:59,  1.52s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:37<02:52,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:40<02:47,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:47,  1.47s/it]predicting train subjects:  60%|██████    | 172/285 [04:43<02:45,  1.47s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:44,  1.47s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:39,  1.44s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:44,  1.49s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:49<02:47,  1.54s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:42,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:53<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:55<02:45,  1.58s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:47,  1.61s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:58<02:45,  1.61s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:37,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:01<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:25,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:04<02:34,  1.56s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:06<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:08<02:43,  1.69s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:09<02:33,  1.60s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:11<02:29,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:12<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:14<02:32,  1.64s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:15<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:17<02:19,  1.54s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:18<02:12,  1.48s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:20<02:20,  1.57s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:22<02:23,  1.63s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:23<02:24,  1.67s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:25<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:26<02:08,  1.52s/it]predicting train subjects:  71%|███████   | 201/285 [05:28<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:30<02:13,  1.61s/it]predicting train subjects:  71%|███████   | 203/285 [05:31<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:33<02:06,  1.56s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:34<02:03,  1.54s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:36<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:37<02:04,  1.59s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:39<02:07,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:41<02:09,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:42<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:44<01:55,  1.56s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:45<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:47<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:48<01:47,  1.52s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:50<01:52,  1.61s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:52<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:48,  1.60s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:55<01:51,  1.66s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:57<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:58<01:43,  1.59s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:00<01:37,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:01<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:03<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:04<01:30,  1.49s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:06<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:07<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:09<01:36,  1.66s/it]predicting train subjects:  80%|████████  | 228/285 [06:11<01:36,  1.69s/it]predicting train subjects:  80%|████████  | 229/285 [06:13<01:32,  1.66s/it]predicting train subjects:  81%|████████  | 230/285 [06:14<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:15<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:17<01:23,  1.57s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:18<01:18,  1.51s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:20<01:21,  1.60s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:21<01:15,  1.52s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:23<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:25<01:20,  1.67s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:27<01:20,  1.71s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:29<01:19,  1.74s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:30<01:14,  1.67s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:32<01:11,  1.63s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:33<01:08,  1.59s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:35<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:37<01:06,  1.63s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:38<01:02,  1.57s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:40<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:42<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:44<01:09,  1.88s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:46<01:03,  1.76s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:47<00:59,  1.71s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:49<00:56,  1.65s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:50<00:50,  1.54s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:52<00:52,  1.63s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:54<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:55<00:51,  1.71s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:57<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [06:58<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:00<00:44,  1.64s/it]predicting train subjects:  91%|█████████ | 259/285 [07:02<00:43,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:03<00:39,  1.57s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:05<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:06<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:07<00:32,  1.48s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:09<00:33,  1.61s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:11<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:13<00:31,  1.67s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:15<00:29,  1.67s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:16<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:18<00:27,  1.71s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:20<00:24,  1.64s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:21<00:22,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:23<00:21,  1.66s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:24<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:26<00:17,  1.59s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:28<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:30<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:31<00:13,  1.63s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:33<00:11,  1.65s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:35<00:10,  1.70s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:36<00:08,  1.64s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:38<00:06,  1.60s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:39<00:04,  1.55s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:41<00:03,  1.69s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:43<00:01,  1.75s/it]predicting train subjects: 100%|██████████| 285/285 [07:45<00:00,  1.77s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:31,  2.01s/it]Loading train:   1%|          | 2/285 [00:03<08:42,  1.85s/it]Loading train:   1%|          | 3/285 [00:05<08:14,  1.75s/it]Loading train:   1%|▏         | 4/285 [00:06<07:48,  1.67s/it]Loading train:   2%|▏         | 5/285 [00:08<08:05,  1.73s/it]Loading train:   2%|▏         | 6/285 [00:09<07:44,  1.66s/it]Loading train:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]Loading train:   3%|▎         | 8/285 [00:13<07:49,  1.70s/it]Loading train:   3%|▎         | 9/285 [00:15<08:26,  1.84s/it]Loading train:   4%|▎         | 10/285 [00:17<07:57,  1.74s/it]Loading train:   4%|▍         | 11/285 [00:18<07:01,  1.54s/it]Loading train:   4%|▍         | 12/285 [00:19<06:39,  1.47s/it]Loading train:   5%|▍         | 13/285 [00:20<06:08,  1.35s/it]Loading train:   5%|▍         | 14/285 [00:21<06:10,  1.37s/it]Loading train:   5%|▌         | 15/285 [00:23<06:18,  1.40s/it]Loading train:   6%|▌         | 16/285 [00:24<06:02,  1.35s/it]Loading train:   6%|▌         | 17/285 [00:25<06:00,  1.35s/it]Loading train:   6%|▋         | 18/285 [00:27<05:45,  1.29s/it]Loading train:   7%|▋         | 19/285 [00:28<05:33,  1.25s/it]Loading train:   7%|▋         | 20/285 [00:29<05:50,  1.32s/it]Loading train:   7%|▋         | 21/285 [00:31<05:53,  1.34s/it]Loading train:   8%|▊         | 22/285 [00:32<05:41,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:33<05:26,  1.25s/it]Loading train:   8%|▊         | 24/285 [00:34<05:27,  1.25s/it]Loading train:   9%|▉         | 25/285 [00:36<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:37<05:36,  1.30s/it]Loading train:   9%|▉         | 27/285 [00:38<05:34,  1.29s/it]Loading train:  10%|▉         | 28/285 [00:40<05:37,  1.31s/it]Loading train:  10%|█         | 29/285 [00:41<05:54,  1.38s/it]Loading train:  11%|█         | 30/285 [00:43<06:14,  1.47s/it]Loading train:  11%|█         | 31/285 [00:44<06:09,  1.45s/it]Loading train:  11%|█         | 32/285 [00:45<05:40,  1.35s/it]Loading train:  12%|█▏        | 33/285 [00:47<06:10,  1.47s/it]Loading train:  12%|█▏        | 34/285 [00:49<06:21,  1.52s/it]Loading train:  12%|█▏        | 35/285 [00:50<06:07,  1.47s/it]Loading train:  13%|█▎        | 36/285 [00:51<05:45,  1.39s/it]Loading train:  13%|█▎        | 37/285 [00:53<05:42,  1.38s/it]Loading train:  13%|█▎        | 38/285 [00:54<05:41,  1.38s/it]Loading train:  14%|█▎        | 39/285 [00:55<05:29,  1.34s/it]Loading train:  14%|█▍        | 40/285 [00:57<05:24,  1.32s/it]Loading train:  14%|█▍        | 41/285 [00:57<04:54,  1.21s/it]Loading train:  15%|█▍        | 42/285 [00:59<04:56,  1.22s/it]Loading train:  15%|█▌        | 43/285 [01:00<04:59,  1.24s/it]Loading train:  15%|█▌        | 44/285 [01:01<05:06,  1.27s/it]Loading train:  16%|█▌        | 45/285 [01:03<04:57,  1.24s/it]Loading train:  16%|█▌        | 46/285 [01:04<04:49,  1.21s/it]Loading train:  16%|█▋        | 47/285 [01:05<04:34,  1.15s/it]Loading train:  17%|█▋        | 48/285 [01:06<04:49,  1.22s/it]Loading train:  17%|█▋        | 49/285 [01:08<05:06,  1.30s/it]Loading train:  18%|█▊        | 50/285 [01:10<05:59,  1.53s/it]Loading train:  18%|█▊        | 51/285 [01:11<05:54,  1.52s/it]Loading train:  18%|█▊        | 52/285 [01:13<05:46,  1.49s/it]Loading train:  19%|█▊        | 53/285 [01:14<05:32,  1.43s/it]Loading train:  19%|█▉        | 54/285 [01:15<05:39,  1.47s/it]Loading train:  19%|█▉        | 55/285 [01:16<05:10,  1.35s/it]Loading train:  20%|█▉        | 56/285 [01:18<05:14,  1.37s/it]Loading train:  20%|██        | 57/285 [01:19<05:08,  1.35s/it]Loading train:  20%|██        | 58/285 [01:21<05:13,  1.38s/it]Loading train:  21%|██        | 59/285 [01:22<05:04,  1.35s/it]Loading train:  21%|██        | 60/285 [01:23<05:14,  1.40s/it]Loading train:  21%|██▏       | 61/285 [01:24<04:42,  1.26s/it]Loading train:  22%|██▏       | 62/285 [01:26<04:55,  1.32s/it]Loading train:  22%|██▏       | 63/285 [01:27<04:58,  1.35s/it]Loading train:  22%|██▏       | 64/285 [01:29<05:16,  1.43s/it]Loading train:  23%|██▎       | 65/285 [01:31<05:31,  1.51s/it]Loading train:  23%|██▎       | 66/285 [01:32<05:29,  1.51s/it]Loading train:  24%|██▎       | 67/285 [01:33<05:15,  1.45s/it]Loading train:  24%|██▍       | 68/285 [01:35<04:54,  1.36s/it]Loading train:  24%|██▍       | 69/285 [01:36<04:51,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:37<04:58,  1.39s/it]Loading train:  25%|██▍       | 71/285 [01:39<04:52,  1.37s/it]Loading train:  25%|██▌       | 72/285 [01:40<04:40,  1.32s/it]Loading train:  26%|██▌       | 73/285 [01:41<04:58,  1.41s/it]Loading train:  26%|██▌       | 74/285 [01:43<04:40,  1.33s/it]Loading train:  26%|██▋       | 75/285 [01:44<04:42,  1.35s/it]Loading train:  27%|██▋       | 76/285 [01:45<04:48,  1.38s/it]Loading train:  27%|██▋       | 77/285 [01:47<04:53,  1.41s/it]Loading train:  27%|██▋       | 78/285 [01:49<05:04,  1.47s/it]Loading train:  28%|██▊       | 79/285 [01:50<04:34,  1.33s/it]Loading train:  28%|██▊       | 80/285 [01:51<04:33,  1.33s/it]Loading train:  28%|██▊       | 81/285 [01:52<04:24,  1.30s/it]Loading train:  29%|██▉       | 82/285 [01:53<04:10,  1.23s/it]Loading train:  29%|██▉       | 83/285 [01:54<03:58,  1.18s/it]Loading train:  29%|██▉       | 84/285 [01:56<04:16,  1.27s/it]Loading train:  30%|██▉       | 85/285 [01:57<04:19,  1.30s/it]Loading train:  30%|███       | 86/285 [01:59<04:40,  1.41s/it]Loading train:  31%|███       | 87/285 [02:00<04:33,  1.38s/it]Loading train:  31%|███       | 88/285 [02:01<04:19,  1.32s/it]Loading train:  31%|███       | 89/285 [02:03<04:27,  1.37s/it]Loading train:  32%|███▏      | 90/285 [02:04<04:15,  1.31s/it]Loading train:  32%|███▏      | 91/285 [02:05<04:16,  1.32s/it]Loading train:  32%|███▏      | 92/285 [02:07<04:21,  1.36s/it]Loading train:  33%|███▎      | 93/285 [02:08<04:06,  1.28s/it]Loading train:  33%|███▎      | 94/285 [02:09<04:02,  1.27s/it]Loading train:  33%|███▎      | 95/285 [02:10<04:00,  1.26s/it]Loading train:  34%|███▎      | 96/285 [02:12<04:00,  1.27s/it]Loading train:  34%|███▍      | 97/285 [02:13<03:59,  1.27s/it]Loading train:  34%|███▍      | 98/285 [02:14<04:08,  1.33s/it]Loading train:  35%|███▍      | 99/285 [02:16<04:05,  1.32s/it]Loading train:  35%|███▌      | 100/285 [02:17<04:02,  1.31s/it]Loading train:  35%|███▌      | 101/285 [02:18<03:47,  1.24s/it]Loading train:  36%|███▌      | 102/285 [02:19<04:02,  1.32s/it]Loading train:  36%|███▌      | 103/285 [02:21<04:17,  1.42s/it]Loading train:  36%|███▋      | 104/285 [02:23<04:27,  1.48s/it]Loading train:  37%|███▋      | 105/285 [02:24<04:37,  1.54s/it]Loading train:  37%|███▋      | 106/285 [02:25<04:09,  1.39s/it]Loading train:  38%|███▊      | 107/285 [02:27<04:13,  1.42s/it]Loading train:  38%|███▊      | 108/285 [02:28<03:56,  1.33s/it]Loading train:  38%|███▊      | 109/285 [02:29<03:41,  1.26s/it]Loading train:  39%|███▊      | 110/285 [02:31<03:45,  1.29s/it]Loading train:  39%|███▉      | 111/285 [02:32<03:28,  1.20s/it]Loading train:  39%|███▉      | 112/285 [02:33<03:32,  1.23s/it]Loading train:  40%|███▉      | 113/285 [02:34<03:38,  1.27s/it]Loading train:  40%|████      | 114/285 [02:35<03:32,  1.25s/it]Loading train:  40%|████      | 115/285 [02:37<03:30,  1.24s/it]Loading train:  41%|████      | 116/285 [02:38<03:41,  1.31s/it]Loading train:  41%|████      | 117/285 [02:39<03:32,  1.26s/it]Loading train:  41%|████▏     | 118/285 [02:40<03:18,  1.19s/it]Loading train:  42%|████▏     | 119/285 [02:42<03:23,  1.23s/it]Loading train:  42%|████▏     | 120/285 [02:43<03:08,  1.14s/it]Loading train:  42%|████▏     | 121/285 [02:44<03:35,  1.32s/it]Loading train:  43%|████▎     | 122/285 [02:46<03:33,  1.31s/it]Loading train:  43%|████▎     | 123/285 [02:47<03:37,  1.34s/it]Loading train:  44%|████▎     | 124/285 [02:48<03:33,  1.33s/it]Loading train:  44%|████▍     | 125/285 [02:49<03:21,  1.26s/it]Loading train:  44%|████▍     | 126/285 [02:51<03:22,  1.27s/it]Loading train:  45%|████▍     | 127/285 [02:52<03:13,  1.23s/it]Loading train:  45%|████▍     | 128/285 [02:53<03:08,  1.20s/it]Loading train:  45%|████▌     | 129/285 [02:54<03:08,  1.21s/it]Loading train:  46%|████▌     | 130/285 [02:55<02:59,  1.16s/it]Loading train:  46%|████▌     | 131/285 [02:56<03:05,  1.21s/it]Loading train:  46%|████▋     | 132/285 [02:58<02:57,  1.16s/it]Loading train:  47%|████▋     | 133/285 [02:59<03:08,  1.24s/it]Loading train:  47%|████▋     | 134/285 [03:00<02:57,  1.17s/it]Loading train:  47%|████▋     | 135/285 [03:01<02:54,  1.16s/it]Loading train:  48%|████▊     | 136/285 [03:02<02:51,  1.15s/it]Loading train:  48%|████▊     | 137/285 [03:03<02:51,  1.16s/it]Loading train:  48%|████▊     | 138/285 [03:05<02:47,  1.14s/it]Loading train:  49%|████▉     | 139/285 [03:06<02:57,  1.22s/it]Loading train:  49%|████▉     | 140/285 [03:07<02:56,  1.22s/it]Loading train:  49%|████▉     | 141/285 [03:08<03:01,  1.26s/it]Loading train:  50%|████▉     | 142/285 [03:10<02:56,  1.23s/it]Loading train:  50%|█████     | 143/285 [03:11<02:51,  1.21s/it]Loading train:  51%|█████     | 144/285 [03:12<02:44,  1.16s/it]Loading train:  51%|█████     | 145/285 [03:13<02:55,  1.25s/it]Loading train:  51%|█████     | 146/285 [03:15<02:59,  1.29s/it]Loading train:  52%|█████▏    | 147/285 [03:16<02:52,  1.25s/it]Loading train:  52%|█████▏    | 148/285 [03:17<02:47,  1.22s/it]Loading train:  52%|█████▏    | 149/285 [03:18<02:40,  1.18s/it]Loading train:  53%|█████▎    | 150/285 [03:19<02:33,  1.14s/it]Loading train:  53%|█████▎    | 151/285 [03:21<02:53,  1.29s/it]Loading train:  53%|█████▎    | 152/285 [03:22<02:49,  1.27s/it]Loading train:  54%|█████▎    | 153/285 [03:23<02:37,  1.19s/it]Loading train:  54%|█████▍    | 154/285 [03:25<02:59,  1.37s/it]Loading train:  54%|█████▍    | 155/285 [03:26<02:46,  1.28s/it]Loading train:  55%|█████▍    | 156/285 [03:27<02:36,  1.22s/it]Loading train:  55%|█████▌    | 157/285 [03:28<02:44,  1.28s/it]Loading train:  55%|█████▌    | 158/285 [03:29<02:32,  1.20s/it]Loading train:  56%|█████▌    | 159/285 [03:31<02:39,  1.26s/it]Loading train:  56%|█████▌    | 160/285 [03:32<02:34,  1.24s/it]Loading train:  56%|█████▋    | 161/285 [03:33<02:29,  1.20s/it]Loading train:  57%|█████▋    | 162/285 [03:34<02:30,  1.22s/it]Loading train:  57%|█████▋    | 163/285 [03:35<02:22,  1.17s/it]Loading train:  58%|█████▊    | 164/285 [03:37<02:24,  1.19s/it]Loading train:  58%|█████▊    | 165/285 [03:38<02:18,  1.16s/it]Loading train:  58%|█████▊    | 166/285 [03:39<02:14,  1.13s/it]Loading train:  59%|█████▊    | 167/285 [03:40<02:13,  1.13s/it]Loading train:  59%|█████▉    | 168/285 [03:41<02:16,  1.17s/it]Loading train:  59%|█████▉    | 169/285 [03:42<02:13,  1.15s/it]Loading train:  60%|█████▉    | 170/285 [03:43<02:09,  1.12s/it]Loading train:  60%|██████    | 171/285 [03:45<02:14,  1.18s/it]Loading train:  60%|██████    | 172/285 [03:46<02:15,  1.20s/it]Loading train:  61%|██████    | 173/285 [03:47<02:08,  1.15s/it]Loading train:  61%|██████    | 174/285 [03:48<02:08,  1.15s/it]Loading train:  61%|██████▏   | 175/285 [03:49<02:04,  1.14s/it]Loading train:  62%|██████▏   | 176/285 [03:50<02:04,  1.14s/it]Loading train:  62%|██████▏   | 177/285 [03:52<02:05,  1.16s/it]Loading train:  62%|██████▏   | 178/285 [03:53<02:02,  1.15s/it]Loading train:  63%|██████▎   | 179/285 [03:54<02:00,  1.13s/it]Loading train:  63%|██████▎   | 180/285 [03:55<02:02,  1.17s/it]Loading train:  64%|██████▎   | 181/285 [03:56<02:08,  1.23s/it]Loading train:  64%|██████▍   | 182/285 [03:57<02:01,  1.18s/it]Loading train:  64%|██████▍   | 183/285 [03:59<01:59,  1.17s/it]Loading train:  65%|██████▍   | 184/285 [04:00<01:58,  1.17s/it]Loading train:  65%|██████▍   | 185/285 [04:01<01:53,  1.13s/it]Loading train:  65%|██████▌   | 186/285 [04:02<02:02,  1.24s/it]Loading train:  66%|██████▌   | 187/285 [04:04<02:03,  1.26s/it]Loading train:  66%|██████▌   | 188/285 [04:05<02:00,  1.24s/it]Loading train:  66%|██████▋   | 189/285 [04:06<01:59,  1.25s/it]Loading train:  67%|██████▋   | 190/285 [04:07<01:55,  1.22s/it]Loading train:  67%|██████▋   | 191/285 [04:08<01:53,  1.20s/it]Loading train:  67%|██████▋   | 192/285 [04:10<01:49,  1.18s/it]Loading train:  68%|██████▊   | 193/285 [04:11<01:44,  1.14s/it]Loading train:  68%|██████▊   | 194/285 [04:12<01:41,  1.11s/it]Loading train:  68%|██████▊   | 195/285 [04:13<01:41,  1.13s/it]Loading train:  69%|██████▉   | 196/285 [04:14<01:43,  1.17s/it]Loading train:  69%|██████▉   | 197/285 [04:15<01:43,  1.18s/it]Loading train:  69%|██████▉   | 198/285 [04:17<01:46,  1.22s/it]Loading train:  70%|██████▉   | 199/285 [04:18<01:39,  1.16s/it]Loading train:  70%|███████   | 200/285 [04:19<01:38,  1.16s/it]Loading train:  71%|███████   | 201/285 [04:20<01:40,  1.20s/it]Loading train:  71%|███████   | 202/285 [04:21<01:42,  1.23s/it]Loading train:  71%|███████   | 203/285 [04:23<01:40,  1.23s/it]Loading train:  72%|███████▏  | 204/285 [04:24<01:32,  1.14s/it]Loading train:  72%|███████▏  | 205/285 [04:25<01:27,  1.09s/it]Loading train:  72%|███████▏  | 206/285 [04:26<01:29,  1.13s/it]Loading train:  73%|███████▎  | 207/285 [04:27<01:34,  1.21s/it]Loading train:  73%|███████▎  | 208/285 [04:28<01:31,  1.19s/it]Loading train:  73%|███████▎  | 209/285 [04:30<01:37,  1.29s/it]Loading train:  74%|███████▎  | 210/285 [04:31<01:30,  1.20s/it]Loading train:  74%|███████▍  | 211/285 [04:32<01:26,  1.17s/it]Loading train:  74%|███████▍  | 212/285 [04:33<01:27,  1.20s/it]Loading train:  75%|███████▍  | 213/285 [04:34<01:25,  1.19s/it]Loading train:  75%|███████▌  | 214/285 [04:35<01:20,  1.14s/it]Loading train:  75%|███████▌  | 215/285 [04:36<01:18,  1.13s/it]Loading train:  76%|███████▌  | 216/285 [04:37<01:14,  1.07s/it]Loading train:  76%|███████▌  | 217/285 [04:39<01:19,  1.16s/it]Loading train:  76%|███████▋  | 218/285 [04:40<01:19,  1.18s/it]Loading train:  77%|███████▋  | 219/285 [04:41<01:21,  1.24s/it]Loading train:  77%|███████▋  | 220/285 [04:42<01:16,  1.17s/it]Loading train:  78%|███████▊  | 221/285 [04:43<01:08,  1.07s/it]Loading train:  78%|███████▊  | 222/285 [04:44<01:04,  1.03s/it]Loading train:  78%|███████▊  | 223/285 [04:45<01:07,  1.09s/it]Loading train:  79%|███████▊  | 224/285 [04:46<01:05,  1.07s/it]Loading train:  79%|███████▉  | 225/285 [04:47<01:02,  1.05s/it]Loading train:  79%|███████▉  | 226/285 [04:49<01:12,  1.22s/it]Loading train:  80%|███████▉  | 227/285 [04:50<01:11,  1.23s/it]Loading train:  80%|████████  | 228/285 [04:51<01:09,  1.23s/it]Loading train:  80%|████████  | 229/285 [04:52<01:04,  1.15s/it]Loading train:  81%|████████  | 230/285 [04:53<00:59,  1.08s/it]Loading train:  81%|████████  | 231/285 [04:54<00:56,  1.04s/it]Loading train:  81%|████████▏ | 232/285 [04:55<00:52,  1.01it/s]Loading train:  82%|████████▏ | 233/285 [04:56<00:47,  1.10it/s]Loading train:  82%|████████▏ | 234/285 [04:57<00:48,  1.05it/s]Loading train:  82%|████████▏ | 235/285 [04:58<00:48,  1.04it/s]Loading train:  83%|████████▎ | 236/285 [04:59<00:48,  1.00it/s]Loading train:  83%|████████▎ | 237/285 [05:00<00:48,  1.00s/it]Loading train:  84%|████████▎ | 238/285 [05:01<00:49,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [05:02<00:46,  1.02s/it]Loading train:  84%|████████▍ | 240/285 [05:03<00:42,  1.05it/s]Loading train:  85%|████████▍ | 241/285 [05:04<00:40,  1.09it/s]Loading train:  85%|████████▍ | 242/285 [05:04<00:36,  1.17it/s]Loading train:  85%|████████▌ | 243/285 [05:05<00:34,  1.20it/s]Loading train:  86%|████████▌ | 244/285 [05:06<00:35,  1.15it/s]Loading train:  86%|████████▌ | 245/285 [05:07<00:33,  1.20it/s]Loading train:  86%|████████▋ | 246/285 [05:08<00:36,  1.06it/s]Loading train:  87%|████████▋ | 247/285 [05:09<00:39,  1.03s/it]Loading train:  87%|████████▋ | 248/285 [05:10<00:38,  1.03s/it]Loading train:  87%|████████▋ | 249/285 [05:11<00:37,  1.03s/it]Loading train:  88%|████████▊ | 250/285 [05:12<00:35,  1.02s/it]Loading train:  88%|████████▊ | 251/285 [05:13<00:33,  1.01it/s]Loading train:  88%|████████▊ | 252/285 [05:14<00:32,  1.01it/s]Loading train:  89%|████████▉ | 253/285 [05:16<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [05:17<00:31,  1.03s/it]Loading train:  89%|████████▉ | 255/285 [05:17<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [05:18<00:28,  1.03it/s]Loading train:  90%|█████████ | 257/285 [05:19<00:26,  1.06it/s]Loading train:  91%|█████████ | 258/285 [05:20<00:27,  1.02s/it]Loading train:  91%|█████████ | 259/285 [05:21<00:26,  1.02s/it]Loading train:  91%|█████████ | 260/285 [05:22<00:24,  1.01it/s]Loading train:  92%|█████████▏| 261/285 [05:23<00:23,  1.01it/s]Loading train:  92%|█████████▏| 262/285 [05:24<00:21,  1.06it/s]Loading train:  92%|█████████▏| 263/285 [05:25<00:20,  1.09it/s]Loading train:  93%|█████████▎| 264/285 [05:26<00:21,  1.03s/it]Loading train:  93%|█████████▎| 265/285 [05:27<00:21,  1.06s/it]Loading train:  93%|█████████▎| 266/285 [05:28<00:18,  1.02it/s]Loading train:  94%|█████████▎| 267/285 [05:29<00:16,  1.06it/s]Loading train:  94%|█████████▍| 268/285 [05:30<00:16,  1.03it/s]Loading train:  94%|█████████▍| 269/285 [05:31<00:16,  1.00s/it]Loading train:  95%|█████████▍| 270/285 [05:32<00:14,  1.02it/s]Loading train:  95%|█████████▌| 271/285 [05:33<00:13,  1.04it/s]Loading train:  95%|█████████▌| 272/285 [05:34<00:12,  1.00it/s]Loading train:  96%|█████████▌| 273/285 [05:35<00:11,  1.02it/s]Loading train:  96%|█████████▌| 274/285 [05:36<00:10,  1.05it/s]Loading train:  96%|█████████▋| 275/285 [05:37<00:10,  1.03s/it]Loading train:  97%|█████████▋| 276/285 [05:38<00:09,  1.03s/it]Loading train:  97%|█████████▋| 277/285 [05:39<00:07,  1.02it/s]Loading train:  98%|█████████▊| 278/285 [05:40<00:06,  1.06it/s]Loading train:  98%|█████████▊| 279/285 [05:41<00:05,  1.09it/s]Loading train:  98%|█████████▊| 280/285 [05:42<00:04,  1.09it/s]Loading train:  99%|█████████▊| 281/285 [05:43<00:04,  1.05s/it]Loading train:  99%|█████████▉| 282/285 [05:44<00:03,  1.00s/it]Loading train:  99%|█████████▉| 283/285 [05:46<00:02,  1.18s/it]Loading train: 100%|█████████▉| 284/285 [05:48<00:01,  1.42s/it]Loading train: 100%|██████████| 285/285 [05:49<00:00,  1.40s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 3/285 [00:00<00:13, 21.49it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:10, 26.99it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:09, 29.77it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:09, 27.24it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:07, 34.43it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:06, 40.54it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:04, 51.75it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:02, 68.91it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 84.06it/s]concatenating: train:  41%|████      | 116/285 [00:01<00:02, 57.98it/s]concatenating: train:  45%|████▍     | 128/285 [00:01<00:02, 63.77it/s]concatenating: train:  49%|████▉     | 139/285 [00:01<00:02, 62.99it/s]concatenating: train:  52%|█████▏    | 149/285 [00:02<00:02, 49.42it/s]concatenating: train:  55%|█████▌    | 157/285 [00:02<00:02, 44.67it/s]concatenating: train:  58%|█████▊    | 166/285 [00:02<00:02, 52.56it/s]concatenating: train:  61%|██████    | 174/285 [00:02<00:02, 50.16it/s]concatenating: train:  66%|██████▌   | 187/285 [00:02<00:01, 61.14it/s]concatenating: train:  69%|██████▉   | 196/285 [00:02<00:01, 65.86it/s]concatenating: train:  72%|███████▏  | 205/285 [00:02<00:01, 67.21it/s]concatenating: train:  75%|███████▍  | 213/285 [00:03<00:01, 54.85it/s]concatenating: train:  77%|███████▋  | 220/285 [00:03<00:01, 52.82it/s]concatenating: train:  87%|████████▋ | 247/285 [00:03<00:00, 69.59it/s]concatenating: train:  99%|█████████▉| 283/285 [00:03<00:00, 91.65it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 80.52it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.84s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.83s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 21.41it/s]2019-07-11 02:06:26.221892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:06:26.221989: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:06:26.222004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:06:26.222012: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:06:26.222446: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.62it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.56it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.83it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.15it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:09,  3.89it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  4.73it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  4.66it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.80it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:06,  4.00it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  4.86it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.37it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.56it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.28it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.63it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  6.49it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.16it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.63it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.06it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  7.26it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  6.55it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.33it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.06it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 10)   4060        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 55)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   728         concatenate_8[0][0]              
==================================================================================================
Total params: 133,148
Trainable params: 34,628
Non-trainable params: 98,520
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 3.1618 - acc: 0.6791 - mDice: 0.0833 - val_loss: 2.3911 - val_acc: 0.8970 - val_mDice: 0.2142

Epoch 00001: val_mDice improved from -inf to 0.21420, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.3041 - acc: 0.8701 - mDice: 0.2932 - val_loss: 1.3909 - val_acc: 0.9049 - val_mDice: 0.4234

Epoch 00002: val_mDice improved from 0.21420 to 0.42339, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.7418 - acc: 0.8740 - mDice: 0.4614 - val_loss: 1.2794 - val_acc: 0.9057 - val_mDice: 0.4573

Epoch 00003: val_mDice improved from 0.42339 to 0.45731, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 9s - loss: 0.6059 - acc: 0.8769 - mDice: 0.5295 - val_loss: 1.1356 - val_acc: 0.9081 - val_mDice: 0.5167

Epoch 00004: val_mDice improved from 0.45731 to 0.51671, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5442 - acc: 0.8794 - mDice: 0.5649 - val_loss: 1.0249 - val_acc: 0.9121 - val_mDice: 0.5673

Epoch 00005: val_mDice improved from 0.51671 to 0.56731, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.5075 - acc: 0.8823 - mDice: 0.5870 - val_loss: 1.0220 - val_acc: 0.9150 - val_mDice: 0.5656

Epoch 00006: val_mDice did not improve from 0.56731
Epoch 7/300
 - 10s - loss: 0.4845 - acc: 0.8869 - mDice: 0.6015 - val_loss: 0.9767 - val_acc: 0.9197 - val_mDice: 0.5735

Epoch 00007: val_mDice improved from 0.56731 to 0.57347, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.4633 - acc: 0.8932 - mDice: 0.6149 - val_loss: 0.9501 - val_acc: 0.9228 - val_mDice: 0.5779

Epoch 00008: val_mDice improved from 0.57347 to 0.57792, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4491 - acc: 0.9008 - mDice: 0.6242 - val_loss: 0.9385 - val_acc: 0.9310 - val_mDice: 0.5813

Epoch 00009: val_mDice improved from 0.57792 to 0.58134, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.4352 - acc: 0.9096 - mDice: 0.6333 - val_loss: 0.9400 - val_acc: 0.9395 - val_mDice: 0.5837

Epoch 00010: val_mDice improved from 0.58134 to 0.58371, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.4246 - acc: 0.9222 - mDice: 0.6397 - val_loss: 0.9320 - val_acc: 0.9440 - val_mDice: 0.5772

Epoch 00011: val_mDice did not improve from 0.58371
Epoch 12/300
 - 10s - loss: 0.4167 - acc: 0.9279 - mDice: 0.6446 - val_loss: 0.9469 - val_acc: 0.9441 - val_mDice: 0.5830

Epoch 00012: val_mDice did not improve from 0.58371
Epoch 13/300
 - 10s - loss: 0.4080 - acc: 0.9305 - mDice: 0.6502 - val_loss: 0.9369 - val_acc: 0.9389 - val_mDice: 0.5819

Epoch 00013: val_mDice did not improve from 0.58371
Epoch 14/300
 - 10s - loss: 0.4027 - acc: 0.9315 - mDice: 0.6537 - val_loss: 0.8792 - val_acc: 0.9459 - val_mDice: 0.5955

Epoch 00014: val_mDice improved from 0.58371 to 0.59553, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 10s - loss: 0.3959 - acc: 0.9324 - mDice: 0.6581 - val_loss: 0.9203 - val_acc: 0.9475 - val_mDice: 0.5888

Epoch 00015: val_mDice did not improve from 0.59553
Epoch 16/300
 - 10s - loss: 0.3917 - acc: 0.9328 - mDice: 0.6610 - val_loss: 0.8736 - val_acc: 0.9427 - val_mDice: 0.5968

Epoch 00016: val_mDice improved from 0.59553 to 0.59678, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 10s - loss: 0.3864 - acc: 0.9335 - mDice: 0.6646 - val_loss: 0.9296 - val_acc: 0.9467 - val_mDice: 0.5797

Epoch 00017: val_mDice did not improve from 0.59678
Epoch 18/300
 - 11s - loss: 0.3812 - acc: 0.9341 - mDice: 0.6681 - val_loss: 0.9013 - val_acc: 0.9382 - val_mDice: 0.5657

Epoch 00018: val_mDice did not improve from 0.59678
Epoch 19/300
 - 10s - loss: 0.3789 - acc: 0.9344 - mDice: 0.6698 - val_loss: 0.8890 - val_acc: 0.9449 - val_mDice: 0.5938

Epoch 00019: val_mDice did not improve from 0.59678
Epoch 20/300
 - 11s - loss: 0.3742 - acc: 0.9349 - mDice: 0.6731 - val_loss: 0.8676 - val_acc: 0.9476 - val_mDice: 0.5894

Epoch 00020: val_mDice did not improve from 0.59678
Epoch 21/300
 - 10s - loss: 0.3722 - acc: 0.9352 - mDice: 0.6744 - val_loss: 0.8737 - val_acc: 0.9430 - val_mDice: 0.5969

Epoch 00021: val_mDice improved from 0.59678 to 0.59695, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 10s - loss: 0.3680 - acc: 0.9355 - mDice: 0.6774 - val_loss: 0.9098 - val_acc: 0.9441 - val_mDice: 0.5774

Epoch 00022: val_mDice did not improve from 0.59695
Epoch 23/300
 - 10s - loss: 0.3653 - acc: 0.9358 - mDice: 0.6792 - val_loss: 0.8300 - val_acc: 0.9467 - val_mDice: 0.6001

Epoch 00023: val_mDice improved from 0.59695 to 0.60011, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 11s - loss: 0.3623 - acc: 0.9362 - mDice: 0.6815 - val_loss: 0.8384 - val_acc: 0.9435 - val_mDice: 0.5945

Epoch 00024: val_mDice did not improve from 0.60011
Epoch 25/300
 - 10s - loss: 0.3606 - acc: 0.9364 - mDice: 0.6825 - val_loss: 0.9214 - val_acc: 0.9469 - val_mDice: 0.5705

Epoch 00025: val_mDice did not improve from 0.60011
Epoch 26/300
 - 11s - loss: 0.3577 - acc: 0.9366 - mDice: 0.6845 - val_loss: 0.8773 - val_acc: 0.9395 - val_mDice: 0.5742

Epoch 00026: val_mDice did not improve from 0.60011
Epoch 27/300
 - 10s - loss: 0.3539 - acc: 0.9369 - mDice: 0.6873 - val_loss: 0.9118 - val_acc: 0.9473 - val_mDice: 0.5844

Epoch 00027: val_mDice did not improve from 0.60011
Epoch 28/300
 - 10s - loss: 0.3514 - acc: 0.9373 - mDice: 0.6890 - val_loss: 0.8995 - val_acc: 0.9445 - val_mDice: 0.5766

Epoch 00028: val_mDice did not improve from 0.60011
Epoch 29/300
 - 9s - loss: 0.3497 - acc: 0.9374 - mDice: 0.6902 - val_loss: 0.7978 - val_acc: 0.9465 - val_mDice: 0.5980

Epoch 00029: val_mDice did not improve from 0.60011
Epoch 30/300
 - 10s - loss: 0.3489 - acc: 0.9373 - mDice: 0.6908 - val_loss: 0.8438 - val_acc: 0.9479 - val_mDice: 0.6024

Epoch 00030: val_mDice improved from 0.60011 to 0.60244, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 9s - loss: 0.3458 - acc: 0.9375 - mDice: 0.6930 - val_loss: 0.8837 - val_acc: 0.9457 - val_mDice: 0.5685

Epoch 00031: val_mDice did not improve from 0.60244
Epoch 32/300
 - 9s - loss: 0.3458 - acc: 0.9379 - mDice: 0.6931 - val_loss: 0.8942 - val_acc: 0.9465 - val_mDice: 0.5805

Epoch 00032: val_mDice did not improve from 0.60244
Epoch 33/300
 - 10s - loss: 0.3429 - acc: 0.9381 - mDice: 0.6952 - val_loss: 0.9478 - val_acc: 0.9443 - val_mDice: 0.5463

Epoch 00033: val_mDice did not improve from 0.60244
Epoch 34/300
 - 9s - loss: 0.3401 - acc: 0.9384 - mDice: 0.6971 - val_loss: 0.8465 - val_acc: 0.9461 - val_mDice: 0.5856

Epoch 00034: val_mDice did not improve from 0.60244
Epoch 35/300
 - 9s - loss: 0.3392 - acc: 0.9382 - mDice: 0.6978 - val_loss: 0.8765 - val_acc: 0.9463 - val_mDice: 0.5714

Epoch 00035: val_mDice did not improve from 0.60244
Epoch 36/300
 - 9s - loss: 0.3401 - acc: 0.9383 - mDice: 0.6971 - val_loss: 0.8218 - val_acc: 0.9468 - val_mDice: 0.5988

Epoch 00036: val_mDice did not improve from 0.60244
Epoch 37/300
 - 9s - loss: 0.3359 - acc: 0.9387 - mDice: 0.7001 - val_loss: 0.8426 - val_acc: 0.9426 - val_mDice: 0.6000

Epoch 00037: val_mDice did not improve from 0.60244
Epoch 38/300
 - 9s - loss: 0.3357 - acc: 0.9388 - mDice: 0.7003 - val_loss: 0.7922 - val_acc: 0.9447 - val_mDice: 0.5988

Epoch 00038: val_mDice did not improve from 0.60244
Epoch 39/300
 - 9s - loss: 0.3332 - acc: 0.9389 - mDice: 0.7021 - val_loss: 0.8111 - val_acc: 0.9468 - val_mDice: 0.5946

Epoch 00039: val_mDice did not improve from 0.60244
Epoch 40/300
 - 9s - loss: 0.3329 - acc: 0.9388 - mDice: 0.7024 - val_loss: 0.8332 - val_acc: 0.9459 - val_mDice: 0.5747

Epoch 00040: val_mDice did not improve from 0.60244
Epoch 41/300
 - 9s - loss: 0.3310 - acc: 0.9390 - mDice: 0.7037 - val_loss: 0.8277 - val_acc: 0.9430 - val_mDice: 0.5765

Epoch 00041: val_mDice did not improve from 0.60244
Epoch 42/300
 - 9s - loss: 0.3313 - acc: 0.9390 - mDice: 0.7036 - val_loss: 0.7569 - val_acc: 0.9438 - val_mDice: 0.5865

Epoch 00042: val_mDice did not improve from 0.60244
Epoch 43/300
 - 9s - loss: 0.3298 - acc: 0.9392 - mDice: 0.7046 - val_loss: 0.8238 - val_acc: 0.9402 - val_mDice: 0.5747

Epoch 00043: val_mDice did not improve from 0.60244
Epoch 44/300
 - 9s - loss: 0.3268 - acc: 0.9394 - mDice: 0.7067 - val_loss: 0.7792 - val_acc: 0.9477 - val_mDice: 0.5955

Epoch 00044: val_mDice did not improve from 0.60244
Epoch 45/300
 - 9s - loss: 0.3261 - acc: 0.9393 - mDice: 0.7073 - val_loss: 0.7913 - val_acc: 0.9433 - val_mDice: 0.5822

Epoch 00045: val_mDice did not improve from 0.60244
Epoch 46/300
 - 9s - loss: 0.3259 - acc: 0.9395 - mDice: 0.7075 - val_loss: 0.8197 - val_acc: 0.9445 - val_mDice: 0.5625

Epoch 00046: val_mDice did not improve from 0.60244
Epoch 47/300
 - 9s - loss: 0.3242 - acc: 0.9397 - mDice: 0.7087 - val_loss: 0.7910 - val_acc: 0.9452 - val_mDice: 0.5880

Epoch 00047: val_mDice did not improve from 0.60244
Epoch 48/300
 - 9s - loss: 0.3226 - acc: 0.9398 - mDice: 0.7098 - val_loss: 0.7830 - val_acc: 0.9440 - val_mDice: 0.5823

Epoch 00048: val_mDice did not improve from 0.60244
Epoch 49/300
 - 9s - loss: 0.3225 - acc: 0.9397 - mDice: 0.7100 - val_loss: 0.7620 - val_acc: 0.9453 - val_mDice: 0.5863

Epoch 00049: val_mDice did not improve from 0.60244
Epoch 50/300
 - 9s - loss: 0.3193 - acc: 0.9402 - mDice: 0.7123 - val_loss: 0.7688 - val_acc: 0.9471 - val_mDice: 0.5923

Epoch 00050: val_mDice did not improve from 0.60244
Epoch 51/300
 - 9s - loss: 0.3200 - acc: 0.9401 - mDice: 0.7118 - val_loss: 0.7432 - val_acc: 0.9468 - val_mDice: 0.5830

Epoch 00051: val_mDice did not improve from 0.60244
Epoch 52/300
 - 9s - loss: 0.3200 - acc: 0.9400 - mDice: 0.7117 - val_loss: 0.7873 - val_acc: 0.9458 - val_mDice: 0.5630

Epoch 00052: val_mDice did not improve from 0.60244
Epoch 53/300
 - 9s - loss: 0.3187 - acc: 0.9402 - mDice: 0.7128 - val_loss: 0.7763 - val_acc: 0.9468 - val_mDice: 0.5656

Epoch 00053: val_mDice did not improve from 0.60244
Epoch 54/300
 - 9s - loss: 0.3183 - acc: 0.9402 - mDice: 0.7130 - val_loss: 0.7606 - val_acc: 0.9395 - val_mDice: 0.5836

Epoch 00054: val_mDice did not improve from 0.60244
Epoch 55/300
 - 9s - loss: 0.3173 - acc: 0.9404 - mDice: 0.7139 - val_loss: 0.6810 - val_acc: 0.9437 - val_mDice: 0.5891

Epoch 00055: val_mDice did not improve from 0.60244
Epoch 56/300
 - 9s - loss: 0.3163 - acc: 0.9405 - mDice: 0.7145 - val_loss: 0.7452 - val_acc: 0.9427 - val_mDice: 0.5881

Epoch 00056: val_mDice did not improve from 0.60244
Epoch 57/300
 - 9s - loss: 0.3148 - acc: 0.9406 - mDice: 0.7157 - val_loss: 0.7127 - val_acc: 0.9466 - val_mDice: 0.5896

Epoch 00057: val_mDice did not improve from 0.60244
Epoch 58/300
 - 9s - loss: 0.3158 - acc: 0.9406 - mDice: 0.7150 - val_loss: 0.7728 - val_acc: 0.9463 - val_mDice: 0.5582

Epoch 00058: val_mDice did not improve from 0.60244
Epoch 59/300
 - 9s - loss: 0.3151 - acc: 0.9404 - mDice: 0.7155 - val_loss: 0.6482 - val_acc: 0.9476 - val_mDice: 0.5899

Epoch 00059: val_mDice did not improve from 0.60244
Epoch 60/300
 - 9s - loss: 0.3127 - acc: 0.9407 - mDice: 0.7172 - val_loss: 0.7365 - val_acc: 0.9471 - val_mDice: 0.5716

Epoch 00060: val_mDice did not improve from 0.60244
Epoch 61/300
 - 9s - loss: 0.3121 - acc: 0.9408 - mDice: 0.7177 - val_loss: 0.7033 - val_acc: 0.9467 - val_mDice: 0.5964

Epoch 00061: val_mDice did not improve from 0.60244
Epoch 62/300
 - 9s - loss: 0.3122 - acc: 0.9407 - mDice: 0.7176 - val_loss: 0.6437 - val_acc: 0.9462 - val_mDice: 0.5891

Epoch 00062: val_mDice did not improve from 0.60244
Epoch 63/300
 - 9s - loss: 0.3120 - acc: 0.9409 - mDice: 0.7178 - val_loss: 0.6493 - val_acc: 0.9471 - val_mDice: 0.5934

Epoch 00063: val_mDice did not improve from 0.60244
Epoch 64/300
 - 9s - loss: 0.3104 - acc: 0.9408 - mDice: 0.7189 - val_loss: 0.7506 - val_acc: 0.9454 - val_mDice: 0.5618

Epoch 00064: val_mDice did not improve from 0.60244
Epoch 65/300
 - 9s - loss: 0.3095 - acc: 0.9410 - mDice: 0.7196 - val_loss: 0.6516 - val_acc: 0.9465 - val_mDice: 0.5896

Epoch 00065: val_mDice did not improve from 0.60244
Epoch 66/300
 - 9s - loss: 0.3081 - acc: 0.9411 - mDice: 0.7207 - val_loss: 0.6248 - val_acc: 0.9469 - val_mDice: 0.5815

Epoch 00066: val_mDice did not improve from 0.60244
Epoch 67/300
 - 9s - loss: 0.3073 - acc: 0.9414 - mDice: 0.7213 - val_loss: 0.6702 - val_acc: 0.9422 - val_mDice: 0.5793

Epoch 00067: val_mDice did not improve from 0.60244
Epoch 68/300
 - 9s - loss: 0.3091 - acc: 0.9412 - mDice: 0.7200 - val_loss: 0.6736 - val_acc: 0.9390 - val_mDice: 0.5762

Epoch 00068: val_mDice did not improve from 0.60244
Epoch 69/300
 - 9s - loss: 0.3065 - acc: 0.9413 - mDice: 0.7219 - val_loss: 0.6253 - val_acc: 0.9410 - val_mDice: 0.5872

Epoch 00069: val_mDice did not improve from 0.60244
Epoch 70/300
 - 9s - loss: 0.3077 - acc: 0.9414 - mDice: 0.7211 - val_loss: 0.6150 - val_acc: 0.9408 - val_mDice: 0.5895

Epoch 00070: val_mDice did not improve from 0.60244
Restoring model weights from the end of the best epoch
Epoch 00070: early stopping
{'val_loss': [2.3911025410606745, 1.3908696628752208, 1.2793667997632707, 1.135622603552682, 1.0248654513132005, 1.0220136869521368, 0.9766858872913179, 0.9500754276911417, 0.9384634778613136, 0.9400037413551694, 0.9319542646408081, 0.9468969731103807, 0.936937309446789, 0.8791544323875791, 0.9203419060934157, 0.873600511323838, 0.9296091567902338, 0.9013415291195824, 0.888976602327256, 0.8675979943502516, 0.8736826749075026, 0.9098242180688041, 0.8299736238661266, 0.8383970203853789, 0.9213864405949911, 0.8773118995484852, 0.9117519174303327, 0.8994872002374559, 0.7978291908899943, 0.843808787209647, 0.8836969421023414, 0.8941558258874076, 0.9477630683353969, 0.8465401104518345, 0.87647697471437, 0.8218076399394444, 0.8425603253500802, 0.7922081039065406, 0.8111059949511573, 0.8332456861223493, 0.8276711645580473, 0.7569475117183867, 0.8237705855142503, 0.7792469830740065, 0.7912684451966059, 0.8196595509847006, 0.791024298894973, 0.7829638435727074, 0.7619960818971906, 0.7687923908233643, 0.7432090384619576, 0.7872633593423026, 0.7762868631453741, 0.7605862958090646, 0.6810046150570824, 0.7451590242839995, 0.7126532338914418, 0.7728296007428851, 0.6481625466119676, 0.736465124856858, 0.7033059767314366, 0.6437116634278071, 0.6492996329352969, 0.7506377129327684, 0.651577665692284, 0.624822253272647, 0.6701546055930001, 0.6735847734269642, 0.625329505829584, 0.6149830364045643], 'val_acc': [0.8970238310950143, 0.9049130252429417, 0.9056753402664548, 0.9080929415566581, 0.9120787751106989, 0.9150045883087885, 0.9197390221414112, 0.9228067681902931, 0.9310393986247835, 0.9395329526492527, 0.9440109701383681, 0.9440888507025582, 0.9388530055681864, 0.9458676633380708, 0.947518303280785, 0.9427198058082944, 0.9467284963244483, 0.9382257064183553, 0.9449382055373419, 0.9476236019815717, 0.942985353015718, 0.9441277441524324, 0.9466575185457865, 0.9434936160132998, 0.9468772666794913, 0.9394940648760114, 0.9473008201235816, 0.9444780037516639, 0.9464743534723917, 0.9479326861245292, 0.9457348812194097, 0.9465155544735137, 0.9442857305208842, 0.9461103223619007, 0.9462660465921674, 0.9467857309750148, 0.9426373697462536, 0.9446703337487721, 0.946758264587039, 0.9459157586097717, 0.9430105572655088, 0.9438232609203884, 0.9401946238109044, 0.9476831612132844, 0.9432578001703534, 0.9444894847415742, 0.9452495205970037, 0.9440430431138902, 0.9453045044626508, 0.9470878896259126, 0.9467651361510867, 0.9457715295609974, 0.9468177925972712, 0.9394986033439636, 0.943740861756461, 0.9426877356710888, 0.9465979763439724, 0.9463484656243097, 0.9475595042819068, 0.9471085327012199, 0.9467238897369021, 0.9462248399144128, 0.9471130967140198, 0.9454143983977181, 0.9464629320871263, 0.9468864571480524, 0.9422069560913813, 0.9390132512365069, 0.9409798468862262, 0.9408104362941924], 'val_mDice': [0.2142014734092213, 0.4233911794920762, 0.45731494735394207, 0.5167095377331689, 0.5673055176933607, 0.565551620686338, 0.5734658262559346, 0.5779227011260533, 0.5813357755541801, 0.5837109676074415, 0.5771623707952953, 0.5829679011589005, 0.5818543302870932, 0.5955344058928036, 0.588817104342438, 0.5967848370117801, 0.5796763391367027, 0.5656500079092526, 0.5937523714133671, 0.5893776728993371, 0.5969465486705303, 0.5774406038579487, 0.6001145353629476, 0.5944554356946832, 0.5705146739880244, 0.5742493349881399, 0.5844247830765588, 0.5765644088387489, 0.5980173729005314, 0.6024367670927729, 0.5685230979607219, 0.5805353593258631, 0.5462593938268366, 0.5856114852996099, 0.5714393886072295, 0.598821382082644, 0.6000214502924964, 0.5987928545191175, 0.5946010972062746, 0.5747313701680729, 0.5764648836283457, 0.5864668055659249, 0.5746550730296544, 0.5954504924870673, 0.5822114829151404, 0.5624841825947875, 0.5879777896971929, 0.5822503258075032, 0.586277183677469, 0.5922836526518777, 0.583015351777985, 0.5630308836698532, 0.5655686136867318, 0.583582858244578, 0.5890675981839498, 0.5880938738229728, 0.5895828324414435, 0.5581808072470483, 0.5899009945846739, 0.5715814332167307, 0.5964030261550631, 0.589088835531757, 0.593364560178348, 0.5618287530683336, 0.5896301901056653, 0.5815262716440928, 0.5793010113494736, 0.5761529318988323, 0.5871998302283741, 0.5895148861621108], 'loss': [3.1618396608912693, 1.3040634053783515, 0.7418312955183033, 0.6059236092353248, 0.5442006610619762, 0.5075039381934472, 0.4845137787228355, 0.4633042827745566, 0.44914301707033527, 0.43516088043974616, 0.42456434058366266, 0.41668133505718635, 0.4079711770066779, 0.4026662618731956, 0.39588120162015894, 0.3917482998333433, 0.3864074813531317, 0.38121015425245036, 0.3788939970282431, 0.3741551689934312, 0.3721905741844192, 0.3680255193976462, 0.3652987607600534, 0.3623035027384643, 0.3606274912806405, 0.3577202028602632, 0.35394087044264694, 0.35142401023960906, 0.3497115972530688, 0.34892131417777145, 0.3457668150277962, 0.3457610120783887, 0.3429023379451718, 0.340088642146837, 0.33920205417960875, 0.34012276821911436, 0.3359014191320918, 0.3356651340591349, 0.33323831309558843, 0.33287652703018256, 0.3310335663292526, 0.33125301563535237, 0.32978087514265436, 0.3268447681695527, 0.32609455084924827, 0.3259185037620729, 0.32420026138496694, 0.3225713967070406, 0.3225026816870864, 0.31934812645450683, 0.3200196700678043, 0.3200097946974039, 0.31871046355424737, 0.3183364748598547, 0.3173008252711615, 0.3163102190170946, 0.31477030943946294, 0.315798043452041, 0.31505563505265394, 0.31273726763604853, 0.3121174364931578, 0.31220202172379374, 0.3119797066948605, 0.310430442348068, 0.30953835890613496, 0.3080750131551898, 0.30729578895354653, 0.3090861518649161, 0.3064938224830539, 0.30768382047122217], 'acc': [0.6790886222511812, 0.8701240214879559, 0.874012578664452, 0.8769426566110725, 0.8793634638888358, 0.8822799876220244, 0.8868853885681155, 0.8932308353094414, 0.9008456767811949, 0.9096049307076164, 0.9221553800881472, 0.9278918674899039, 0.9304536988401036, 0.931480768479799, 0.9324171421429958, 0.9328439680854779, 0.9334986624010776, 0.9340786542739854, 0.9344249809549015, 0.9348971990806325, 0.9351553828679047, 0.9355296987845577, 0.9357951329649357, 0.9362212152455339, 0.9363621731059087, 0.9365711817282667, 0.9369052000902557, 0.9373118445113465, 0.937393756128355, 0.937321368395903, 0.9375322117772387, 0.937914311690484, 0.9381398221236192, 0.9383630802320198, 0.9381769928648128, 0.9382876118920501, 0.9386704109619182, 0.9387608021698822, 0.9388602542146359, 0.938846608474118, 0.9390418541001657, 0.93900014568391, 0.9391889724975977, 0.9393882004884205, 0.9392521856882358, 0.9395078826966441, 0.9396930265592108, 0.939805042417334, 0.93972892197704, 0.9402370098608409, 0.9401461307842055, 0.9400261253181716, 0.9401756261432472, 0.94016761080663, 0.9404133255711083, 0.9404518345842385, 0.9405723318144469, 0.9405565731599425, 0.9404362197071228, 0.9406777361879373, 0.9407635461693442, 0.9407188017197787, 0.9408832494638456, 0.9408288450284296, 0.9409505423608717, 0.9411198579210157, 0.9413948157561269, 0.9411574653147824, 0.9412678098067259, 0.9413637693548377], 'mDice': [0.0832915468917449, 0.29315266449234956, 0.46139080490086015, 0.5294822344482117, 0.5648880634828181, 0.5870352034879508, 0.6015167083955348, 0.6149230725921049, 0.624189318961575, 0.6333249110304048, 0.6397168906709007, 0.6446068840080175, 0.6501952279664336, 0.6536907156423404, 0.6581475710579259, 0.6610211650944179, 0.6645701082083263, 0.6681170634205732, 0.669771067021048, 0.6730577282209674, 0.674440044485261, 0.6773561046076161, 0.679226048837996, 0.6814905938004537, 0.6825382711226847, 0.6844835608180649, 0.6872574571517935, 0.6890001341812593, 0.6902410384660422, 0.6907771344540642, 0.6930055298831896, 0.6931211173086238, 0.6951776999073128, 0.6971292514573041, 0.6977627595909212, 0.6971061334275362, 0.7001486160126821, 0.7002916891082578, 0.7020543156755851, 0.7023955211028994, 0.7036838016000722, 0.7036029179247446, 0.7046039390706456, 0.706747825018859, 0.7073247899019997, 0.7074824184242507, 0.7087103291262958, 0.7098389070733149, 0.7099695346110446, 0.7123235944886186, 0.7118241323288498, 0.7117484519999681, 0.7127787004851045, 0.7130236404926211, 0.7138648934393736, 0.7145000323294123, 0.7156806373632963, 0.7149933746767936, 0.7155479829573829, 0.7172293665323134, 0.7176939135391128, 0.7176244223602756, 0.7178366128387583, 0.7189270681858706, 0.7195773419787802, 0.7206706940748568, 0.7213371085458715, 0.7199943621930346, 0.721893717023663, 0.7210991790305219]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.21s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  2.00s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:33,  1.81s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:50,  1.67s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:33,  1.61s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:50,  1.68s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:33,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:49,  1.69s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:41,  1.67s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:58,  1.73s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:13,  1.80s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:51,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:10,  1.80s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:58,  1.76s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:59,  1.77s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:10,  1.82s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:16,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:03,  1.80s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:01,  1.80s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:38,  1.73s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:44,  1.75s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:57,  1.81s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:31,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:36,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:23,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:42,  1.78s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:48,  1.81s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:30,  1.74s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:32,  1.76s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:31,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:45,  1.83s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:48,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:21,  1.75s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:26,  1.77s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:32,  1.80s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:13,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:25,  1.79s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:37,  1.85s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:11,  1.76s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:20,  1.80s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<07:09,  1.76s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<06:54,  1.71s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<06:58,  1.73s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<07:04,  1.77s/it]predicting train subjects:  16%|█▌        | 46/285 [01:20<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:53,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<07:06,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:14,  1.84s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:14,  1.85s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:29,  1.92s/it]predicting train subjects:  18%|█▊        | 52/285 [01:31<07:07,  1.84s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:24,  1.92s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<07:05,  1.85s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<07:04,  1.85s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:42,  1.77s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:51,  1.81s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:59,  1.86s/it]predicting train subjects:  21%|██        | 60/285 [01:46<07:04,  1.89s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:46,  1.81s/it]predicting train subjects:  22%|██▏       | 62/285 [01:50<06:49,  1.84s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:46,  1.83s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:30,  1.77s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:33,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:57<06:30,  1.78s/it]predicting train subjects:  24%|██▎       | 67/285 [01:59<06:35,  1.82s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:20,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:20,  1.76s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:28,  1.81s/it]predicting train subjects:  25%|██▍       | 71/285 [02:06<06:32,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:08<06:15,  1.76s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 74/285 [02:11<06:16,  1.79s/it]predicting train subjects:  26%|██▋       | 75/285 [02:13<06:22,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:15<06:25,  1.84s/it]predicting train subjects:  27%|██▋       | 77/285 [02:17<06:08,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:18<05:57,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:20<05:55,  1.73s/it]predicting train subjects:  28%|██▊       | 80/285 [02:22<05:51,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:39,  1.66s/it]predicting train subjects:  29%|██▉       | 82/285 [02:25<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:27<05:35,  1.66s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:32,  1.65s/it]predicting train subjects:  30%|██▉       | 85/285 [02:30<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:32<05:44,  1.73s/it]predicting train subjects:  31%|███       | 87/285 [02:34<05:48,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:35<05:42,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:37<05:38,  1.73s/it]predicting train subjects:  32%|███▏      | 90/285 [02:39<05:45,  1.77s/it]predicting train subjects:  32%|███▏      | 91/285 [02:41<05:36,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:42<05:37,  1.75s/it]predicting train subjects:  33%|███▎      | 93/285 [02:44<05:28,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:46<05:27,  1.72s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<05:29,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<05:33,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<05:37,  1.80s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<05:33,  1.78s/it]predicting train subjects:  35%|███▍      | 99/285 [02:55<05:29,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [02:56<05:30,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:19,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [03:00<05:21,  1.76s/it]predicting train subjects:  36%|███▌      | 103/285 [03:02<05:16,  1.74s/it]predicting train subjects:  36%|███▋      | 104/285 [03:04<05:28,  1.81s/it]predicting train subjects:  37%|███▋      | 105/285 [03:06<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:07<05:23,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:09<05:35,  1.88s/it]predicting train subjects:  38%|███▊      | 108/285 [03:11<05:17,  1.79s/it]predicting train subjects:  38%|███▊      | 109/285 [03:13<05:22,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:15<05:24,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:16<05:07,  1.77s/it]predicting train subjects:  39%|███▉      | 112/285 [03:18<05:07,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:20<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:22<05:03,  1.78s/it]predicting train subjects:  40%|████      | 115/285 [03:24<05:12,  1.84s/it]predicting train subjects:  41%|████      | 116/285 [03:26<05:14,  1.86s/it]predicting train subjects:  41%|████      | 117/285 [03:27<05:01,  1.79s/it]predicting train subjects:  41%|████▏     | 118/285 [03:29<04:50,  1.74s/it]predicting train subjects:  42%|████▏     | 119/285 [03:31<04:56,  1.79s/it]predicting train subjects:  42%|████▏     | 120/285 [03:32<04:49,  1.75s/it]predicting train subjects:  42%|████▏     | 121/285 [03:34<04:44,  1.74s/it]predicting train subjects:  43%|████▎     | 122/285 [03:36<04:30,  1.66s/it]predicting train subjects:  43%|████▎     | 123/285 [03:37<04:18,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:39<04:17,  1.60s/it]predicting train subjects:  44%|████▍     | 125/285 [03:40<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:42<04:09,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:43<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:45<04:02,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:46<04:01,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [03:48<03:58,  1.54s/it]predicting train subjects:  46%|████▌     | 131/285 [03:49<03:48,  1.49s/it]predicting train subjects:  46%|████▋     | 132/285 [03:51<03:52,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [03:52<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [03:54<03:40,  1.46s/it]predicting train subjects:  47%|████▋     | 135/285 [03:55<03:36,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:56<03:36,  1.45s/it]predicting train subjects:  48%|████▊     | 137/285 [03:58<03:45,  1.53s/it]predicting train subjects:  48%|████▊     | 138/285 [04:00<03:47,  1.55s/it]predicting train subjects:  49%|████▉     | 139/285 [04:01<03:50,  1.58s/it]predicting train subjects:  49%|████▉     | 140/285 [04:03<03:50,  1.59s/it]predicting train subjects:  49%|████▉     | 141/285 [04:04<03:41,  1.54s/it]predicting train subjects:  50%|████▉     | 142/285 [04:06<03:42,  1.56s/it]predicting train subjects:  50%|█████     | 143/285 [04:08<03:39,  1.54s/it]predicting train subjects:  51%|█████     | 144/285 [04:09<03:44,  1.59s/it]predicting train subjects:  51%|█████     | 145/285 [04:11<03:40,  1.57s/it]predicting train subjects:  51%|█████     | 146/285 [04:13<03:53,  1.68s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:14<03:44,  1.62s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:16<03:46,  1.66s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:17<03:39,  1.62s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:19<03:33,  1.58s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:21<03:33,  1.60s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:22<03:29,  1.57s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:24<03:23,  1.54s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:25<03:29,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:27<03:24,  1.57s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:28<03:27,  1.60s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:30<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:32<03:18,  1.56s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:33<03:12,  1.53s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:34<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:36<03:13,  1.56s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:38<03:06,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:39<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:41<03:10,  1.57s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:42<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:44<03:07,  1.58s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:46<03:10,  1.62s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:47<03:06,  1.59s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:49<03:02,  1.57s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:50<02:57,  1.54s/it]predicting train subjects:  60%|██████    | 171/285 [04:52<02:54,  1.53s/it]predicting train subjects:  60%|██████    | 172/285 [04:53<02:55,  1.55s/it]predicting train subjects:  61%|██████    | 173/285 [04:55<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [04:56<02:47,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:58<02:54,  1.58s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:00<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:01<02:47,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:03<02:44,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:04<02:39,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:06<02:46,  1.59s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:07<02:45,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:09<02:49,  1.64s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:11<02:41,  1.58s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:12<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:13<02:29,  1.50s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:15<02:39,  1.61s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:17<02:48,  1.72s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:19<02:51,  1.77s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:21<02:38,  1.65s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:22<02:31,  1.60s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:24<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:25<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:27<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:28<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:29<02:10,  1.45s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:31<02:19,  1.57s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:33<02:27,  1.68s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:35<02:31,  1.74s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:36<02:18,  1.62s/it]predicting train subjects:  70%|███████   | 200/285 [05:38<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:40<02:23,  1.70s/it]predicting train subjects:  71%|███████   | 202/285 [05:42<02:21,  1.70s/it]predicting train subjects:  71%|███████   | 203/285 [05:43<02:19,  1.70s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:45<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:46<02:05,  1.56s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:47<01:58,  1.50s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:49<02:05,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:51<02:09,  1.68s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:53<02:12,  1.75s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:55<02:03,  1.65s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:56<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:58<02:00,  1.65s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:59<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:01<01:51,  1.57s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:03<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:04<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:06<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:08<01:57,  1.75s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:10<01:58,  1.79s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:11<01:49,  1.69s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:13<01:44,  1.63s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:14<01:43,  1.64s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:16<01:37,  1.57s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:17<01:33,  1.54s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:19<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:21<01:38,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:23<01:39,  1.71s/it]predicting train subjects:  80%|████████  | 228/285 [06:24<01:39,  1.75s/it]predicting train subjects:  80%|████████  | 229/285 [06:26<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:27<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:29<01:23,  1.54s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:30<01:25,  1.61s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:32<01:20,  1.55s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:34<01:23,  1.64s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:35<01:18,  1.57s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:37<01:21,  1.67s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:39<01:24,  1.75s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:41<01:25,  1.81s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:43<01:22,  1.79s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:44<01:15,  1.67s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:46<01:10,  1.60s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:47<01:05,  1.53s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:48<01:02,  1.50s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:50<01:05,  1.61s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:51<01:01,  1.53s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:53<01:03,  1.64s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:55<01:04,  1.69s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:57<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:58<00:56,  1.57s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:00<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:01<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:02<00:47,  1.45s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:04<00:51,  1.61s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:06<00:52,  1.68s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:08<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:09<00:45,  1.57s/it]predicting train subjects:  90%|█████████ | 257/285 [07:11<00:43,  1.54s/it]predicting train subjects:  91%|█████████ | 258/285 [07:12<00:43,  1.63s/it]predicting train subjects:  91%|█████████ | 259/285 [07:14<00:42,  1.63s/it]predicting train subjects:  91%|█████████ | 260/285 [07:15<00:38,  1.54s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:17<00:36,  1.51s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:18<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:20<00:32,  1.49s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:22<00:33,  1.60s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:24<00:33,  1.66s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:25<00:30,  1.59s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:26<00:28,  1.56s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:28<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:30<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:31<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:33<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:35<00:21,  1.66s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:36<00:18,  1.58s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:38<00:17,  1.58s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:40<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:42<00:15,  1.74s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:43<00:13,  1.65s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:44<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:46<00:09,  1.65s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:48<00:07,  1.58s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:49<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:51<00:04,  1.51s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:52<00:03,  1.62s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:54<00:01,  1.70s/it]predicting train subjects: 100%|██████████| 285/285 [07:56<00:00,  1.79s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:10,  1.94s/it]Loading train:   1%|          | 2/285 [00:03<08:39,  1.84s/it]Loading train:   1%|          | 3/285 [00:05<08:46,  1.87s/it]Loading train:   1%|▏         | 4/285 [00:07<08:50,  1.89s/it]Loading train:   2%|▏         | 5/285 [00:09<09:06,  1.95s/it]Loading train:   2%|▏         | 6/285 [00:11<08:29,  1.83s/it]Loading train:   2%|▏         | 7/285 [00:13<08:47,  1.90s/it]Loading train:   3%|▎         | 8/285 [00:14<08:32,  1.85s/it]Loading train:   3%|▎         | 9/285 [00:17<09:03,  1.97s/it]Loading train:   4%|▎         | 10/285 [00:18<08:30,  1.86s/it]Loading train:   4%|▍         | 11/285 [00:20<07:45,  1.70s/it]Loading train:   4%|▍         | 12/285 [00:21<07:43,  1.70s/it]Loading train:   5%|▍         | 13/285 [00:22<07:02,  1.55s/it]Loading train:   5%|▍         | 14/285 [00:24<06:35,  1.46s/it]Loading train:   5%|▌         | 15/285 [00:26<07:04,  1.57s/it]Loading train:   6%|▌         | 16/285 [00:27<07:20,  1.64s/it]Loading train:   6%|▌         | 17/285 [00:29<06:47,  1.52s/it]Loading train:   6%|▋         | 18/285 [00:30<06:27,  1.45s/it]Loading train:   7%|▋         | 19/285 [00:31<06:04,  1.37s/it]Loading train:   7%|▋         | 20/285 [00:32<05:46,  1.31s/it]Loading train:   7%|▋         | 21/285 [00:34<06:16,  1.42s/it]Loading train:   8%|▊         | 22/285 [00:35<05:54,  1.35s/it]Loading train:   8%|▊         | 23/285 [00:37<06:38,  1.52s/it]Loading train:   8%|▊         | 24/285 [00:38<06:19,  1.45s/it]Loading train:   9%|▉         | 25/285 [00:40<06:20,  1.46s/it]Loading train:   9%|▉         | 26/285 [00:41<06:15,  1.45s/it]Loading train:   9%|▉         | 27/285 [00:42<05:51,  1.36s/it]Loading train:  10%|▉         | 28/285 [00:43<05:34,  1.30s/it]Loading train:  10%|█         | 29/285 [00:45<05:32,  1.30s/it]Loading train:  11%|█         | 30/285 [00:46<05:41,  1.34s/it]Loading train:  11%|█         | 31/285 [00:48<05:40,  1.34s/it]Loading train:  11%|█         | 32/285 [00:48<05:08,  1.22s/it]Loading train:  12%|█▏        | 33/285 [00:50<04:58,  1.19s/it]Loading train:  12%|█▏        | 34/285 [00:51<04:43,  1.13s/it]Loading train:  12%|█▏        | 35/285 [00:52<05:09,  1.24s/it]Loading train:  13%|█▎        | 36/285 [00:53<04:53,  1.18s/it]Loading train:  13%|█▎        | 37/285 [00:54<04:56,  1.19s/it]Loading train:  13%|█▎        | 38/285 [00:56<05:08,  1.25s/it]Loading train:  14%|█▎        | 39/285 [00:57<04:47,  1.17s/it]Loading train:  14%|█▍        | 40/285 [00:58<04:42,  1.15s/it]Loading train:  14%|█▍        | 41/285 [00:59<04:40,  1.15s/it]Loading train:  15%|█▍        | 42/285 [01:00<04:28,  1.10s/it]Loading train:  15%|█▌        | 43/285 [01:01<04:50,  1.20s/it]Loading train:  15%|█▌        | 44/285 [01:03<05:09,  1.28s/it]Loading train:  16%|█▌        | 45/285 [01:04<04:54,  1.23s/it]Loading train:  16%|█▌        | 46/285 [01:05<05:12,  1.31s/it]Loading train:  16%|█▋        | 47/285 [01:06<04:47,  1.21s/it]Loading train:  17%|█▋        | 48/285 [01:08<04:40,  1.18s/it]Loading train:  17%|█▋        | 49/285 [01:09<04:48,  1.22s/it]Loading train:  18%|█▊        | 50/285 [01:10<04:54,  1.25s/it]Loading train:  18%|█▊        | 51/285 [01:11<04:52,  1.25s/it]Loading train:  18%|█▊        | 52/285 [01:13<04:53,  1.26s/it]Loading train:  19%|█▊        | 53/285 [01:14<04:51,  1.25s/it]Loading train:  19%|█▉        | 54/285 [01:15<04:47,  1.24s/it]Loading train:  19%|█▉        | 55/285 [01:16<04:46,  1.25s/it]Loading train:  20%|█▉        | 56/285 [01:18<04:47,  1.25s/it]Loading train:  20%|██        | 57/285 [01:19<04:35,  1.21s/it]Loading train:  20%|██        | 58/285 [01:20<04:44,  1.25s/it]Loading train:  21%|██        | 59/285 [01:22<05:02,  1.34s/it]Loading train:  21%|██        | 60/285 [01:23<04:56,  1.32s/it]Loading train:  21%|██▏       | 61/285 [01:24<04:37,  1.24s/it]Loading train:  22%|██▏       | 62/285 [01:25<04:25,  1.19s/it]Loading train:  22%|██▏       | 63/285 [01:26<04:33,  1.23s/it]Loading train:  22%|██▏       | 64/285 [01:28<04:57,  1.34s/it]Loading train:  23%|██▎       | 65/285 [01:30<05:20,  1.46s/it]Loading train:  23%|██▎       | 66/285 [01:31<05:27,  1.49s/it]Loading train:  24%|██▎       | 67/285 [01:32<04:57,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:34<05:00,  1.39s/it]Loading train:  24%|██▍       | 69/285 [01:35<04:41,  1.30s/it]Loading train:  25%|██▍       | 70/285 [01:37<04:59,  1.39s/it]Loading train:  25%|██▍       | 71/285 [01:38<04:51,  1.36s/it]Loading train:  25%|██▌       | 72/285 [01:39<04:39,  1.31s/it]Loading train:  26%|██▌       | 73/285 [01:40<04:35,  1.30s/it]Loading train:  26%|██▌       | 74/285 [01:42<04:28,  1.27s/it]Loading train:  26%|██▋       | 75/285 [01:43<04:18,  1.23s/it]Loading train:  27%|██▋       | 76/285 [01:44<04:12,  1.21s/it]Loading train:  27%|██▋       | 77/285 [01:45<04:09,  1.20s/it]Loading train:  27%|██▋       | 78/285 [01:46<04:11,  1.21s/it]Loading train:  28%|██▊       | 79/285 [01:47<04:09,  1.21s/it]Loading train:  28%|██▊       | 80/285 [01:49<04:03,  1.19s/it]Loading train:  28%|██▊       | 81/285 [01:50<04:03,  1.19s/it]Loading train:  29%|██▉       | 82/285 [01:51<03:58,  1.18s/it]Loading train:  29%|██▉       | 83/285 [01:52<04:04,  1.21s/it]Loading train:  29%|██▉       | 84/285 [01:53<04:01,  1.20s/it]Loading train:  30%|██▉       | 85/285 [01:55<04:13,  1.27s/it]Loading train:  30%|███       | 86/285 [01:56<04:16,  1.29s/it]Loading train:  31%|███       | 87/285 [01:57<04:15,  1.29s/it]Loading train:  31%|███       | 88/285 [01:59<04:00,  1.22s/it]Loading train:  31%|███       | 89/285 [02:00<04:01,  1.23s/it]Loading train:  32%|███▏      | 90/285 [02:01<04:00,  1.23s/it]Loading train:  32%|███▏      | 91/285 [02:02<03:54,  1.21s/it]Loading train:  32%|███▏      | 92/285 [02:04<04:02,  1.26s/it]Loading train:  33%|███▎      | 93/285 [02:05<03:45,  1.18s/it]Loading train:  33%|███▎      | 94/285 [02:06<03:37,  1.14s/it]Loading train:  33%|███▎      | 95/285 [02:07<03:41,  1.16s/it]Loading train:  34%|███▎      | 96/285 [02:08<03:42,  1.18s/it]Loading train:  34%|███▍      | 97/285 [02:09<03:45,  1.20s/it]Loading train:  34%|███▍      | 98/285 [02:10<03:40,  1.18s/it]Loading train:  35%|███▍      | 99/285 [02:11<03:33,  1.15s/it]Loading train:  35%|███▌      | 100/285 [02:13<03:35,  1.17s/it]Loading train:  35%|███▌      | 101/285 [02:14<03:27,  1.13s/it]Loading train:  36%|███▌      | 102/285 [02:15<03:31,  1.15s/it]Loading train:  36%|███▌      | 103/285 [02:16<03:33,  1.17s/it]Loading train:  36%|███▋      | 104/285 [02:17<03:39,  1.21s/it]Loading train:  37%|███▋      | 105/285 [02:19<03:30,  1.17s/it]Loading train:  37%|███▋      | 106/285 [02:20<03:27,  1.16s/it]Loading train:  38%|███▊      | 107/285 [02:21<03:28,  1.17s/it]Loading train:  38%|███▊      | 108/285 [02:22<03:27,  1.18s/it]Loading train:  38%|███▊      | 109/285 [02:23<03:30,  1.19s/it]Loading train:  39%|███▊      | 110/285 [02:24<03:29,  1.20s/it]Loading train:  39%|███▉      | 111/285 [02:26<03:25,  1.18s/it]Loading train:  39%|███▉      | 112/285 [02:27<03:27,  1.20s/it]Loading train:  40%|███▉      | 113/285 [02:28<03:29,  1.22s/it]Loading train:  40%|████      | 114/285 [02:29<03:27,  1.21s/it]Loading train:  40%|████      | 115/285 [02:30<03:20,  1.18s/it]Loading train:  41%|████      | 116/285 [02:32<03:21,  1.19s/it]Loading train:  41%|████      | 117/285 [02:33<03:18,  1.18s/it]Loading train:  41%|████▏     | 118/285 [02:34<03:15,  1.17s/it]Loading train:  42%|████▏     | 119/285 [02:35<03:28,  1.26s/it]Loading train:  42%|████▏     | 120/285 [02:37<03:22,  1.23s/it]Loading train:  42%|████▏     | 121/285 [02:38<03:39,  1.34s/it]Loading train:  43%|████▎     | 122/285 [02:40<03:39,  1.35s/it]Loading train:  43%|████▎     | 123/285 [02:41<03:32,  1.31s/it]Loading train:  44%|████▎     | 124/285 [02:42<03:13,  1.20s/it]Loading train:  44%|████▍     | 125/285 [02:43<03:04,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:44<02:53,  1.09s/it]Loading train:  45%|████▍     | 127/285 [02:45<02:43,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:46<02:39,  1.02s/it]Loading train:  45%|████▌     | 129/285 [02:47<02:43,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:48<02:36,  1.01s/it]Loading train:  46%|████▌     | 131/285 [02:49<02:44,  1.07s/it]Loading train:  46%|████▋     | 132/285 [02:50<02:33,  1.00s/it]Loading train:  47%|████▋     | 133/285 [02:51<02:44,  1.08s/it]Loading train:  47%|████▋     | 134/285 [02:52<02:41,  1.07s/it]Loading train:  47%|████▋     | 135/285 [02:53<02:44,  1.10s/it]Loading train:  48%|████▊     | 136/285 [02:54<02:37,  1.05s/it]Loading train:  48%|████▊     | 137/285 [02:55<02:39,  1.08s/it]Loading train:  48%|████▊     | 138/285 [02:56<02:28,  1.01s/it]Loading train:  49%|████▉     | 139/285 [02:57<02:27,  1.01s/it]Loading train:  49%|████▉     | 140/285 [02:58<02:27,  1.02s/it]Loading train:  49%|████▉     | 141/285 [02:59<02:25,  1.01s/it]Loading train:  50%|████▉     | 142/285 [03:00<02:39,  1.11s/it]Loading train:  50%|█████     | 143/285 [03:01<02:29,  1.05s/it]Loading train:  51%|█████     | 144/285 [03:02<02:22,  1.01s/it]Loading train:  51%|█████     | 145/285 [03:03<02:13,  1.05it/s]Loading train:  51%|█████     | 146/285 [03:04<02:22,  1.03s/it]Loading train:  52%|█████▏    | 147/285 [03:05<02:23,  1.04s/it]Loading train:  52%|█████▏    | 148/285 [03:07<02:26,  1.07s/it]Loading train:  52%|█████▏    | 149/285 [03:08<02:23,  1.06s/it]Loading train:  53%|█████▎    | 150/285 [03:09<02:19,  1.03s/it]Loading train:  53%|█████▎    | 151/285 [03:10<02:17,  1.03s/it]Loading train:  53%|█████▎    | 152/285 [03:10<02:13,  1.00s/it]Loading train:  54%|█████▎    | 153/285 [03:11<02:11,  1.00it/s]Loading train:  54%|█████▍    | 154/285 [03:13<02:13,  1.02s/it]Loading train:  54%|█████▍    | 155/285 [03:14<02:17,  1.05s/it]Loading train:  55%|█████▍    | 156/285 [03:15<02:14,  1.04s/it]Loading train:  55%|█████▌    | 157/285 [03:16<02:14,  1.05s/it]Loading train:  55%|█████▌    | 158/285 [03:17<02:16,  1.07s/it]Loading train:  56%|█████▌    | 159/285 [03:18<02:15,  1.07s/it]Loading train:  56%|█████▌    | 160/285 [03:19<02:16,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [03:20<02:16,  1.10s/it]Loading train:  57%|█████▋    | 162/285 [03:21<02:06,  1.03s/it]Loading train:  57%|█████▋    | 163/285 [03:22<02:01,  1.00it/s]Loading train:  58%|█████▊    | 164/285 [03:23<02:06,  1.05s/it]Loading train:  58%|█████▊    | 165/285 [03:24<01:57,  1.02it/s]Loading train:  58%|█████▊    | 166/285 [03:25<02:03,  1.04s/it]Loading train:  59%|█████▊    | 167/285 [03:26<02:02,  1.04s/it]Loading train:  59%|█████▉    | 168/285 [03:27<02:04,  1.06s/it]Loading train:  59%|█████▉    | 169/285 [03:28<02:06,  1.09s/it]Loading train:  60%|█████▉    | 170/285 [03:30<02:05,  1.09s/it]Loading train:  60%|██████    | 171/285 [03:31<02:01,  1.06s/it]Loading train:  60%|██████    | 172/285 [03:32<01:57,  1.04s/it]Loading train:  61%|██████    | 173/285 [03:32<01:52,  1.00s/it]Loading train:  61%|██████    | 174/285 [03:34<01:59,  1.07s/it]Loading train:  61%|██████▏   | 175/285 [03:35<01:54,  1.04s/it]Loading train:  62%|██████▏   | 176/285 [03:36<01:52,  1.03s/it]Loading train:  62%|██████▏   | 177/285 [03:37<01:48,  1.00s/it]Loading train:  62%|██████▏   | 178/285 [03:38<01:47,  1.00s/it]Loading train:  63%|██████▎   | 179/285 [03:39<01:50,  1.04s/it]Loading train:  63%|██████▎   | 180/285 [03:40<01:54,  1.09s/it]Loading train:  64%|██████▎   | 181/285 [03:41<01:58,  1.13s/it]Loading train:  64%|██████▍   | 182/285 [03:42<01:52,  1.09s/it]Loading train:  64%|██████▍   | 183/285 [03:43<01:50,  1.08s/it]Loading train:  65%|██████▍   | 184/285 [03:44<01:48,  1.07s/it]Loading train:  65%|██████▍   | 185/285 [03:45<01:43,  1.04s/it]Loading train:  65%|██████▌   | 186/285 [03:47<01:50,  1.11s/it]Loading train:  66%|██████▌   | 187/285 [03:48<01:50,  1.13s/it]Loading train:  66%|██████▌   | 188/285 [03:49<01:48,  1.12s/it]Loading train:  66%|██████▋   | 189/285 [03:50<01:44,  1.09s/it]Loading train:  67%|██████▋   | 190/285 [03:51<01:35,  1.00s/it]Loading train:  67%|██████▋   | 191/285 [03:52<01:33,  1.00it/s]Loading train:  67%|██████▋   | 192/285 [03:53<01:35,  1.03s/it]Loading train:  68%|██████▊   | 193/285 [03:54<01:33,  1.02s/it]Loading train:  68%|██████▊   | 194/285 [03:55<01:29,  1.02it/s]Loading train:  68%|██████▊   | 195/285 [03:55<01:23,  1.08it/s]Loading train:  69%|██████▉   | 196/285 [03:57<01:31,  1.02s/it]Loading train:  69%|██████▉   | 197/285 [03:58<01:33,  1.06s/it]Loading train:  69%|██████▉   | 198/285 [03:59<01:38,  1.14s/it]Loading train:  70%|██████▉   | 199/285 [04:00<01:34,  1.10s/it]Loading train:  70%|███████   | 200/285 [04:01<01:29,  1.06s/it]Loading train:  71%|███████   | 201/285 [04:02<01:29,  1.07s/it]Loading train:  71%|███████   | 202/285 [04:03<01:30,  1.09s/it]Loading train:  71%|███████   | 203/285 [04:04<01:29,  1.09s/it]Loading train:  72%|███████▏  | 204/285 [04:05<01:25,  1.06s/it]Loading train:  72%|███████▏  | 205/285 [04:06<01:22,  1.03s/it]Loading train:  72%|███████▏  | 206/285 [04:07<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [04:09<01:22,  1.06s/it]Loading train:  73%|███████▎  | 208/285 [04:10<01:25,  1.11s/it]Loading train:  73%|███████▎  | 209/285 [04:11<01:28,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [04:12<01:21,  1.09s/it]Loading train:  74%|███████▍  | 211/285 [04:13<01:19,  1.08s/it]Loading train:  74%|███████▍  | 212/285 [04:14<01:19,  1.09s/it]Loading train:  75%|███████▍  | 213/285 [04:15<01:18,  1.10s/it]Loading train:  75%|███████▌  | 214/285 [04:16<01:13,  1.04s/it]Loading train:  75%|███████▌  | 215/285 [04:17<01:17,  1.11s/it]Loading train:  76%|███████▌  | 216/285 [04:19<01:16,  1.11s/it]Loading train:  76%|███████▌  | 217/285 [04:20<01:20,  1.18s/it]Loading train:  76%|███████▋  | 218/285 [04:21<01:19,  1.19s/it]Loading train:  77%|███████▋  | 219/285 [04:22<01:15,  1.15s/it]Loading train:  77%|███████▋  | 220/285 [04:23<01:13,  1.14s/it]Loading train:  78%|███████▊  | 221/285 [04:24<01:07,  1.05s/it]Loading train:  78%|███████▊  | 222/285 [04:25<01:09,  1.10s/it]Loading train:  78%|███████▊  | 223/285 [04:26<01:05,  1.06s/it]Loading train:  79%|███████▊  | 224/285 [04:27<01:04,  1.06s/it]Loading train:  79%|███████▉  | 225/285 [04:28<01:03,  1.06s/it]Loading train:  79%|███████▉  | 226/285 [04:30<01:05,  1.10s/it]Loading train:  80%|███████▉  | 227/285 [04:31<01:06,  1.14s/it]Loading train:  80%|████████  | 228/285 [04:32<01:05,  1.15s/it]Loading train:  80%|████████  | 229/285 [04:33<01:03,  1.14s/it]Loading train:  81%|████████  | 230/285 [04:34<01:02,  1.13s/it]Loading train:  81%|████████  | 231/285 [04:35<00:59,  1.09s/it]Loading train:  81%|████████▏ | 232/285 [04:36<00:55,  1.06s/it]Loading train:  82%|████████▏ | 233/285 [04:37<00:53,  1.02s/it]Loading train:  82%|████████▏ | 234/285 [04:38<00:55,  1.09s/it]Loading train:  82%|████████▏ | 235/285 [04:40<00:55,  1.12s/it]Loading train:  83%|████████▎ | 236/285 [04:41<00:56,  1.15s/it]Loading train:  83%|████████▎ | 237/285 [04:42<00:54,  1.14s/it]Loading train:  84%|████████▎ | 238/285 [04:43<00:56,  1.20s/it]Loading train:  84%|████████▍ | 239/285 [04:44<00:55,  1.20s/it]Loading train:  84%|████████▍ | 240/285 [04:46<00:52,  1.16s/it]Loading train:  85%|████████▍ | 241/285 [04:47<00:52,  1.20s/it]Loading train:  85%|████████▍ | 242/285 [04:48<00:48,  1.12s/it]Loading train:  85%|████████▌ | 243/285 [04:49<00:45,  1.08s/it]Loading train:  86%|████████▌ | 244/285 [04:50<00:44,  1.10s/it]Loading train:  86%|████████▌ | 245/285 [04:51<00:43,  1.08s/it]Loading train:  86%|████████▋ | 246/285 [04:52<00:42,  1.09s/it]Loading train:  87%|████████▋ | 247/285 [04:53<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:54<00:39,  1.06s/it]Loading train:  87%|████████▋ | 249/285 [04:55<00:35,  1.02it/s]Loading train:  88%|████████▊ | 250/285 [04:56<00:32,  1.09it/s]Loading train:  88%|████████▊ | 251/285 [04:57<00:31,  1.09it/s]Loading train:  88%|████████▊ | 252/285 [04:58<00:34,  1.04s/it]Loading train:  89%|████████▉ | 253/285 [04:59<00:35,  1.11s/it]Loading train:  89%|████████▉ | 254/285 [05:01<00:36,  1.18s/it]Loading train:  89%|████████▉ | 255/285 [05:02<00:36,  1.21s/it]Loading train:  90%|████████▉ | 256/285 [05:03<00:32,  1.13s/it]Loading train:  90%|█████████ | 257/285 [05:04<00:31,  1.12s/it]Loading train:  91%|█████████ | 258/285 [05:05<00:30,  1.13s/it]Loading train:  91%|█████████ | 259/285 [05:06<00:29,  1.14s/it]Loading train:  91%|█████████ | 260/285 [05:07<00:27,  1.08s/it]Loading train:  92%|█████████▏| 261/285 [05:08<00:24,  1.04s/it]Loading train:  92%|█████████▏| 262/285 [05:09<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [05:10<00:23,  1.05s/it]Loading train:  93%|█████████▎| 264/285 [05:12<00:24,  1.15s/it]Loading train:  93%|█████████▎| 265/285 [05:13<00:23,  1.15s/it]Loading train:  93%|█████████▎| 266/285 [05:14<00:21,  1.11s/it]Loading train:  94%|█████████▎| 267/285 [05:15<00:19,  1.07s/it]Loading train:  94%|█████████▍| 268/285 [05:16<00:19,  1.15s/it]Loading train:  94%|█████████▍| 269/285 [05:17<00:18,  1.15s/it]Loading train:  95%|█████████▍| 270/285 [05:18<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [05:19<00:15,  1.09s/it]Loading train:  95%|█████████▌| 272/285 [05:20<00:14,  1.11s/it]Loading train:  96%|█████████▌| 273/285 [05:21<00:13,  1.10s/it]Loading train:  96%|█████████▌| 274/285 [05:22<00:11,  1.05s/it]Loading train:  96%|█████████▋| 275/285 [05:24<00:11,  1.14s/it]Loading train:  97%|█████████▋| 276/285 [05:25<00:10,  1.15s/it]Loading train:  97%|█████████▋| 277/285 [05:26<00:08,  1.12s/it]Loading train:  98%|█████████▊| 278/285 [05:27<00:07,  1.07s/it]Loading train:  98%|█████████▊| 279/285 [05:28<00:06,  1.10s/it]Loading train:  98%|█████████▊| 280/285 [05:29<00:05,  1.10s/it]Loading train:  99%|█████████▊| 281/285 [05:30<00:04,  1.09s/it]Loading train:  99%|█████████▉| 282/285 [05:31<00:03,  1.05s/it]Loading train:  99%|█████████▉| 283/285 [05:32<00:02,  1.13s/it]Loading train: 100%|█████████▉| 284/285 [05:34<00:01,  1.11s/it]Loading train: 100%|██████████| 285/285 [05:35<00:00,  1.10s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|▏         | 4/285 [00:00<00:07, 36.28it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:06, 39.54it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:06, 44.78it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:04, 59.69it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:03, 73.22it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:02, 82.22it/s]concatenating: train:  30%|██▉       | 85/285 [00:00<00:02, 91.63it/s]concatenating: train:  34%|███▍      | 98/285 [00:00<00:02, 89.71it/s]concatenating: train:  41%|████      | 117/285 [00:00<00:01, 106.39it/s]concatenating: train:  52%|█████▏    | 149/285 [00:01<00:01, 132.64it/s]concatenating: train:  64%|██████▍   | 182/285 [00:01<00:00, 160.93it/s]concatenating: train:  76%|███████▌  | 216/285 [00:01<00:00, 190.24it/s]concatenating: train:  87%|████████▋ | 248/285 [00:01<00:00, 216.26it/s]concatenating: train:  99%|█████████▉| 283/285 [00:01<00:00, 243.24it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 188.70it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.47s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.45s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.40s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 47.47it/s]2019-07-11 02:31:56.270719: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 02:31:56.270836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 02:31:56.270854: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 02:31:56.270867: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 02:31:56.271393: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.42it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.13it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.08it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.50it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.70it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.36it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.40it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.92it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.45it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.35it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.91it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.32it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.46it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.77it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.40it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.67it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.66it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.48it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.33it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 10)   5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 70)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 232,303
Trainable params: 57,563
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 2.0300 - acc: 0.6101 - mDice: 0.2376 - val_loss: 0.9182 - val_acc: 0.9249 - val_mDice: 0.3936

Epoch 00001: val_mDice improved from -inf to 0.39359, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.5720 - acc: 0.9264 - mDice: 0.5527 - val_loss: 0.5126 - val_acc: 0.9473 - val_mDice: 0.5899

Epoch 00002: val_mDice improved from 0.39359 to 0.58990, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.4564 - acc: 0.9369 - mDice: 0.6201 - val_loss: 0.4917 - val_acc: 0.9533 - val_mDice: 0.6066

Epoch 00003: val_mDice improved from 0.58990 to 0.60656, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.4151 - acc: 0.9417 - mDice: 0.6465 - val_loss: 0.4586 - val_acc: 0.9517 - val_mDice: 0.6234

Epoch 00004: val_mDice improved from 0.60656 to 0.62342, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.3934 - acc: 0.9442 - mDice: 0.6614 - val_loss: 0.4705 - val_acc: 0.9530 - val_mDice: 0.6189

Epoch 00005: val_mDice did not improve from 0.62342
Epoch 6/300
 - 14s - loss: 0.3741 - acc: 0.9459 - mDice: 0.6740 - val_loss: 0.4559 - val_acc: 0.9547 - val_mDice: 0.6296

Epoch 00006: val_mDice improved from 0.62342 to 0.62958, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.3595 - acc: 0.9472 - mDice: 0.6841 - val_loss: 0.4445 - val_acc: 0.9543 - val_mDice: 0.6340

Epoch 00007: val_mDice improved from 0.62958 to 0.63404, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.3475 - acc: 0.9482 - mDice: 0.6925 - val_loss: 0.4595 - val_acc: 0.9556 - val_mDice: 0.6296

Epoch 00008: val_mDice did not improve from 0.63404
Epoch 9/300
 - 14s - loss: 0.3384 - acc: 0.9490 - mDice: 0.6990 - val_loss: 0.4513 - val_acc: 0.9552 - val_mDice: 0.6317

Epoch 00009: val_mDice did not improve from 0.63404
Epoch 10/300
 - 13s - loss: 0.3314 - acc: 0.9496 - mDice: 0.7043 - val_loss: 0.4538 - val_acc: 0.9544 - val_mDice: 0.6288

Epoch 00010: val_mDice did not improve from 0.63404
Epoch 11/300
 - 14s - loss: 0.3232 - acc: 0.9502 - mDice: 0.7100 - val_loss: 0.4498 - val_acc: 0.9539 - val_mDice: 0.6330

Epoch 00011: val_mDice did not improve from 0.63404
Epoch 12/300
 - 13s - loss: 0.3180 - acc: 0.9507 - mDice: 0.7140 - val_loss: 0.4389 - val_acc: 0.9560 - val_mDice: 0.6361

Epoch 00012: val_mDice improved from 0.63404 to 0.63606, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 15s - loss: 0.3137 - acc: 0.9510 - mDice: 0.7172 - val_loss: 0.4376 - val_acc: 0.9557 - val_mDice: 0.6402

Epoch 00013: val_mDice improved from 0.63606 to 0.64017, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 15s - loss: 0.3082 - acc: 0.9515 - mDice: 0.7213 - val_loss: 0.4665 - val_acc: 0.9564 - val_mDice: 0.6306

Epoch 00014: val_mDice did not improve from 0.64017
Epoch 15/300
 - 15s - loss: 0.3034 - acc: 0.9519 - mDice: 0.7250 - val_loss: 0.4469 - val_acc: 0.9551 - val_mDice: 0.6352

Epoch 00015: val_mDice did not improve from 0.64017
Epoch 16/300
 - 15s - loss: 0.2988 - acc: 0.9522 - mDice: 0.7283 - val_loss: 0.4897 - val_acc: 0.9543 - val_mDice: 0.6204

Epoch 00016: val_mDice did not improve from 0.64017
Epoch 17/300
 - 15s - loss: 0.2961 - acc: 0.9525 - mDice: 0.7305 - val_loss: 0.4392 - val_acc: 0.9537 - val_mDice: 0.6380

Epoch 00017: val_mDice did not improve from 0.64017
Epoch 18/300
 - 15s - loss: 0.2930 - acc: 0.9527 - mDice: 0.7328 - val_loss: 0.4644 - val_acc: 0.9537 - val_mDice: 0.6221

Epoch 00018: val_mDice did not improve from 0.64017
Epoch 19/300
 - 16s - loss: 0.2896 - acc: 0.9529 - mDice: 0.7353 - val_loss: 0.4611 - val_acc: 0.9531 - val_mDice: 0.6287

Epoch 00019: val_mDice did not improve from 0.64017
Epoch 20/300
 - 16s - loss: 0.3593 - acc: 0.9480 - mDice: 0.6889 - val_loss: 0.6564 - val_acc: 0.9511 - val_mDice: 0.5568

Epoch 00020: val_mDice did not improve from 0.64017
Epoch 21/300
 - 15s - loss: 0.3142 - acc: 0.9512 - mDice: 0.7166 - val_loss: 0.4618 - val_acc: 0.9560 - val_mDice: 0.6268

Epoch 00021: val_mDice did not improve from 0.64017
Epoch 22/300
 - 16s - loss: 0.2949 - acc: 0.9526 - mDice: 0.7313 - val_loss: 0.4535 - val_acc: 0.9562 - val_mDice: 0.6288

Epoch 00022: val_mDice did not improve from 0.64017
Epoch 23/300
 - 16s - loss: 0.2876 - acc: 0.9531 - mDice: 0.7368 - val_loss: 0.4470 - val_acc: 0.9550 - val_mDice: 0.6322

Epoch 00023: val_mDice did not improve from 0.64017
Epoch 24/300
 - 15s - loss: 0.2843 - acc: 0.9535 - mDice: 0.7394 - val_loss: 0.4498 - val_acc: 0.9543 - val_mDice: 0.6301

Epoch 00024: val_mDice did not improve from 0.64017
Epoch 25/300
 - 16s - loss: 0.2821 - acc: 0.9537 - mDice: 0.7416 - val_loss: 0.4574 - val_acc: 0.9524 - val_mDice: 0.6268

Epoch 00025: val_mDice did not improve from 0.64017
Epoch 26/300
 - 15s - loss: 0.2796 - acc: 0.9537 - mDice: 0.7429 - val_loss: 0.4550 - val_acc: 0.9533 - val_mDice: 0.6271

Epoch 00026: val_mDice did not improve from 0.64017
Epoch 27/300
 - 15s - loss: 0.2749 - acc: 0.9541 - mDice: 0.7465 - val_loss: 0.4700 - val_acc: 0.9555 - val_mDice: 0.6275

Epoch 00027: val_mDice did not improve from 0.64017
Epoch 28/300
 - 15s - loss: 0.2728 - acc: 0.9542 - mDice: 0.7482 - val_loss: 0.4487 - val_acc: 0.9537 - val_mDice: 0.6326

Epoch 00028: val_mDice did not improve from 0.64017
Epoch 29/300
 - 16s - loss: 0.2706 - acc: 0.9543 - mDice: 0.7499 - val_loss: 0.4493 - val_acc: 0.9551 - val_mDice: 0.6349

Epoch 00029: val_mDice did not improve from 0.64017
Epoch 30/300
 - 15s - loss: 0.2714 - acc: 0.9543 - mDice: 0.7493 - val_loss: 0.4625 - val_acc: 0.9535 - val_mDice: 0.6261

Epoch 00030: val_mDice did not improve from 0.64017
Epoch 31/300
 - 14s - loss: 0.2692 - acc: 0.9545 - mDice: 0.7511 - val_loss: 0.4563 - val_acc: 0.9524 - val_mDice: 0.6286

Epoch 00031: val_mDice did not improve from 0.64017
Epoch 32/300
 - 14s - loss: 0.2958 - acc: 0.9530 - mDice: 0.7365 - val_loss: 0.5206 - val_acc: 0.9525 - val_mDice: 0.6038

Epoch 00032: val_mDice did not improve from 0.64017
Epoch 33/300
 - 13s - loss: 0.2794 - acc: 0.9539 - mDice: 0.7430 - val_loss: 0.4447 - val_acc: 0.9556 - val_mDice: 0.6356

Epoch 00033: val_mDice did not improve from 0.64017
Epoch 34/300
 - 13s - loss: 0.2685 - acc: 0.9546 - mDice: 0.7514 - val_loss: 0.4509 - val_acc: 0.9560 - val_mDice: 0.6323

Epoch 00034: val_mDice did not improve from 0.64017
Epoch 35/300
 - 13s - loss: 0.2660 - acc: 0.9547 - mDice: 0.7535 - val_loss: 0.4446 - val_acc: 0.9556 - val_mDice: 0.6347

Epoch 00035: val_mDice did not improve from 0.64017
Epoch 36/300
 - 14s - loss: 0.2624 - acc: 0.9549 - mDice: 0.7563 - val_loss: 0.4563 - val_acc: 0.9556 - val_mDice: 0.6290

Epoch 00036: val_mDice did not improve from 0.64017
Epoch 37/300
 - 13s - loss: 0.2604 - acc: 0.9550 - mDice: 0.7579 - val_loss: 0.4673 - val_acc: 0.9546 - val_mDice: 0.6221

Epoch 00037: val_mDice did not improve from 0.64017
Epoch 38/300
 - 13s - loss: 0.2611 - acc: 0.9550 - mDice: 0.7574 - val_loss: 0.4680 - val_acc: 0.9558 - val_mDice: 0.6258

Epoch 00038: val_mDice did not improve from 0.64017
Epoch 39/300
 - 13s - loss: 0.2583 - acc: 0.9552 - mDice: 0.7595 - val_loss: 0.4430 - val_acc: 0.9561 - val_mDice: 0.6354

Epoch 00039: val_mDice did not improve from 0.64017
Epoch 40/300
 - 13s - loss: 0.2583 - acc: 0.9552 - mDice: 0.7596 - val_loss: 0.4651 - val_acc: 0.9548 - val_mDice: 0.6226

Epoch 00040: val_mDice did not improve from 0.64017
Epoch 41/300
 - 14s - loss: 0.2559 - acc: 0.9553 - mDice: 0.7614 - val_loss: 0.4616 - val_acc: 0.9544 - val_mDice: 0.6270

Epoch 00041: val_mDice did not improve from 0.64017
Epoch 42/300
 - 13s - loss: 0.2548 - acc: 0.9554 - mDice: 0.7623 - val_loss: 0.4360 - val_acc: 0.9565 - val_mDice: 0.6417

Epoch 00042: val_mDice improved from 0.64017 to 0.64165, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 13s - loss: 0.2547 - acc: 0.9554 - mDice: 0.7624 - val_loss: 0.4497 - val_acc: 0.9531 - val_mDice: 0.6319

Epoch 00043: val_mDice did not improve from 0.64165
Epoch 44/300
 - 13s - loss: 0.2517 - acc: 0.9556 - mDice: 0.7648 - val_loss: 0.4928 - val_acc: 0.9560 - val_mDice: 0.6185

Epoch 00044: val_mDice did not improve from 0.64165
Epoch 45/300
 - 13s - loss: 0.2519 - acc: 0.9556 - mDice: 0.7646 - val_loss: 0.4506 - val_acc: 0.9542 - val_mDice: 0.6347

Epoch 00045: val_mDice did not improve from 0.64165
Epoch 46/300
 - 13s - loss: 0.2512 - acc: 0.9556 - mDice: 0.7652 - val_loss: 0.4866 - val_acc: 0.9551 - val_mDice: 0.6271

Epoch 00046: val_mDice did not improve from 0.64165
Epoch 47/300
 - 13s - loss: 0.2522 - acc: 0.9557 - mDice: 0.7645 - val_loss: 0.4703 - val_acc: 0.9555 - val_mDice: 0.6263

Epoch 00047: val_mDice did not improve from 0.64165
Epoch 48/300
 - 13s - loss: 0.2491 - acc: 0.9558 - mDice: 0.7669 - val_loss: 0.4788 - val_acc: 0.9547 - val_mDice: 0.6196

Epoch 00048: val_mDice did not improve from 0.64165
Epoch 49/300
 - 13s - loss: 0.2482 - acc: 0.9559 - mDice: 0.7676 - val_loss: 0.4592 - val_acc: 0.9555 - val_mDice: 0.6264

Epoch 00049: val_mDice did not improve from 0.64165
Epoch 50/300
 - 13s - loss: 0.2484 - acc: 0.9559 - mDice: 0.7674 - val_loss: 0.4908 - val_acc: 0.9564 - val_mDice: 0.6200

Epoch 00050: val_mDice did not improve from 0.64165
Epoch 51/300
 - 13s - loss: 0.2481 - acc: 0.9559 - mDice: 0.7679 - val_loss: 0.5171 - val_acc: 0.9545 - val_mDice: 0.6127

Epoch 00051: val_mDice did not improve from 0.64165
Epoch 52/300
 - 13s - loss: 0.2468 - acc: 0.9560 - mDice: 0.7687 - val_loss: 0.4881 - val_acc: 0.9556 - val_mDice: 0.6227

Epoch 00052: val_mDice did not improve from 0.64165
Epoch 53/300
 - 13s - loss: 0.2461 - acc: 0.9560 - mDice: 0.7693 - val_loss: 0.4536 - val_acc: 0.9530 - val_mDice: 0.6283

Epoch 00053: val_mDice did not improve from 0.64165
Epoch 54/300
 - 13s - loss: 0.2440 - acc: 0.9561 - mDice: 0.7710 - val_loss: 0.4602 - val_acc: 0.9558 - val_mDice: 0.6302

Epoch 00054: val_mDice did not improve from 0.64165
Epoch 55/300
 - 14s - loss: 0.2436 - acc: 0.9562 - mDice: 0.7714 - val_loss: 0.4589 - val_acc: 0.9536 - val_mDice: 0.6280

Epoch 00055: val_mDice did not improve from 0.64165
Epoch 56/300
 - 13s - loss: 0.2432 - acc: 0.9563 - mDice: 0.7716 - val_loss: 0.4685 - val_acc: 0.9522 - val_mDice: 0.6191

Epoch 00056: val_mDice did not improve from 0.64165
Epoch 57/300
 - 13s - loss: 0.2420 - acc: 0.9563 - mDice: 0.7725 - val_loss: 0.4742 - val_acc: 0.9535 - val_mDice: 0.6220

Epoch 00057: val_mDice did not improve from 0.64165
Epoch 58/300
 - 13s - loss: 0.2426 - acc: 0.9562 - mDice: 0.7721 - val_loss: 0.4933 - val_acc: 0.9537 - val_mDice: 0.6155

Epoch 00058: val_mDice did not improve from 0.64165
Epoch 59/300
 - 13s - loss: 0.2399 - acc: 0.9564 - mDice: 0.7742 - val_loss: 0.4471 - val_acc: 0.9559 - val_mDice: 0.6340

Epoch 00059: val_mDice did not improve from 0.64165
Epoch 60/300
 - 13s - loss: 0.2404 - acc: 0.9564 - mDice: 0.7739 - val_loss: 0.4737 - val_acc: 0.9551 - val_mDice: 0.6202

Epoch 00060: val_mDice did not improve from 0.64165
Epoch 61/300
 - 13s - loss: 0.2401 - acc: 0.9565 - mDice: 0.7741 - val_loss: 0.4503 - val_acc: 0.9551 - val_mDice: 0.6298

Epoch 00061: val_mDice did not improve from 0.64165
Epoch 62/300
 - 13s - loss: 0.2399 - acc: 0.9564 - mDice: 0.7743 - val_loss: 0.4637 - val_acc: 0.9553 - val_mDice: 0.6231

Epoch 00062: val_mDice did not improve from 0.64165
Epoch 63/300
 - 13s - loss: 0.2378 - acc: 0.9566 - mDice: 0.7760 - val_loss: 0.4878 - val_acc: 0.9526 - val_mDice: 0.6089

Epoch 00063: val_mDice did not improve from 0.64165
Epoch 64/300
 - 13s - loss: 0.2372 - acc: 0.9566 - mDice: 0.7766 - val_loss: 0.4961 - val_acc: 0.9544 - val_mDice: 0.6120

Epoch 00064: val_mDice did not improve from 0.64165
Epoch 65/300
 - 13s - loss: 0.2377 - acc: 0.9566 - mDice: 0.7761 - val_loss: 0.4595 - val_acc: 0.9548 - val_mDice: 0.6250

Epoch 00065: val_mDice did not improve from 0.64165
Epoch 66/300
 - 13s - loss: 0.2350 - acc: 0.9568 - mDice: 0.7782 - val_loss: 0.4577 - val_acc: 0.9531 - val_mDice: 0.6295

Epoch 00066: val_mDice did not improve from 0.64165
Epoch 67/300
 - 13s - loss: 0.2361 - acc: 0.9567 - mDice: 0.7774 - val_loss: 0.4786 - val_acc: 0.9548 - val_mDice: 0.6159

Epoch 00067: val_mDice did not improve from 0.64165
Epoch 68/300
 - 13s - loss: 0.2342 - acc: 0.9569 - mDice: 0.7789 - val_loss: 0.4479 - val_acc: 0.9544 - val_mDice: 0.6320

Epoch 00068: val_mDice did not improve from 0.64165
Epoch 69/300
 - 13s - loss: 0.2351 - acc: 0.9568 - mDice: 0.7782 - val_loss: 0.4728 - val_acc: 0.9541 - val_mDice: 0.6212

Epoch 00069: val_mDice did not improve from 0.64165
Epoch 70/300
 - 13s - loss: 0.2341 - acc: 0.9568 - mDice: 0.7791 - val_loss: 0.4548 - val_acc: 0.9551 - val_mDice: 0.6296

Epoch 00070: val_mDice did not improve from 0.64165
Epoch 71/300
 - 13s - loss: 0.2337 - acc: 0.9568 - mDice: 0.7793 - val_loss: 0.4568 - val_acc: 0.9522 - val_mDice: 0.6272

Epoch 00071: val_mDice did not improve from 0.64165
Epoch 72/300
 - 13s - loss: 0.2333 - acc: 0.9569 - mDice: 0.7797 - val_loss: 0.4716 - val_acc: 0.9557 - val_mDice: 0.6229

Epoch 00072: val_mDice did not improve from 0.64165
Epoch 73/300
 - 13s - loss: 0.2329 - acc: 0.9569 - mDice: 0.7800 - val_loss: 0.4725 - val_acc: 0.9552 - val_mDice: 0.6218

Epoch 00073: val_mDice did not improve from 0.64165
Epoch 74/300
 - 13s - loss: 0.2321 - acc: 0.9570 - mDice: 0.7807 - val_loss: 0.4662 - val_acc: 0.9538 - val_mDice: 0.6221

Epoch 00074: val_mDice did not improve from 0.64165
Epoch 75/300
 - 13s - loss: 0.2312 - acc: 0.9570 - mDice: 0.7813 - val_loss: 0.4547 - val_acc: 0.9552 - val_mDice: 0.6302

Epoch 00075: val_mDice did not improve from 0.64165
Epoch 76/300
 - 13s - loss: 0.2305 - acc: 0.9571 - mDice: 0.7820 - val_loss: 0.4628 - val_acc: 0.9534 - val_mDice: 0.6220

Epoch 00076: val_mDice did not improve from 0.64165
Epoch 77/300
 - 13s - loss: 0.2306 - acc: 0.9571 - mDice: 0.7818 - val_loss: 0.4748 - val_acc: 0.9537 - val_mDice: 0.6207

Epoch 00077: val_mDice did not improve from 0.64165
Epoch 78/300
 - 13s - loss: 0.2317 - acc: 0.9570 - mDice: 0.7810 - val_loss: 0.4618 - val_acc: 0.9531 - val_mDice: 0.6275

Epoch 00078: val_mDice did not improve from 0.64165
Epoch 79/300
 - 14s - loss: 0.2300 - acc: 0.9571 - mDice: 0.7824 - val_loss: 0.4756 - val_acc: 0.9557 - val_mDice: 0.6175

Epoch 00079: val_mDice did not improve from 0.64165
Epoch 80/300
 - 13s - loss: 0.2296 - acc: 0.9571 - mDice: 0.7827 - val_loss: 0.4882 - val_acc: 0.9545 - val_mDice: 0.6152

Epoch 00080: val_mDice did not improve from 0.64165
Epoch 81/300
 - 13s - loss: 0.2305 - acc: 0.9571 - mDice: 0.7821 - val_loss: 0.4523 - val_acc: 0.9537 - val_mDice: 0.6280

Epoch 00081: val_mDice did not improve from 0.64165
Epoch 82/300
 - 13s - loss: 0.2291 - acc: 0.9573 - mDice: 0.7831 - val_loss: 0.4729 - val_acc: 0.9551 - val_mDice: 0.6248

Epoch 00082: val_mDice did not improve from 0.64165
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
{'val_loss': [0.9181659847664434, 0.5126185357237661, 0.49165148941498227, 0.45863484870122134, 0.4705215422800799, 0.45591015622602493, 0.4444950875623266, 0.45950874336604963, 0.4512883990836543, 0.45384805229123076, 0.44977518200208355, 0.43887092048229454, 0.437631759230651, 0.4664616931084148, 0.44686233298072603, 0.4896964084502705, 0.4392007286322183, 0.46437600904336856, 0.46109837859702507, 0.6564113927287096, 0.46183443502340904, 0.45350533091156175, 0.44704101438628896, 0.4498302473702244, 0.4574069350791377, 0.45501622074809156, 0.4699975015730831, 0.44869355715852877, 0.44931576771443116, 0.4625179447941274, 0.4563054382468069, 0.5206481321563934, 0.44467174773775664, 0.4509224808415887, 0.44457692773648483, 0.45626236506680534, 0.4673211381422075, 0.46802586883140007, 0.4430106452057481, 0.4651275550186967, 0.4615756609586364, 0.43599579920315873, 0.4497227605494707, 0.49280806260401977, 0.45062369907368494, 0.4865650534629822, 0.47026929842027204, 0.47880304891969905, 0.4592486247004077, 0.49077070591836003, 0.5171203266974934, 0.48813389133474683, 0.4535797165092809, 0.4602201757484308, 0.4588830580924476, 0.4684891174625418, 0.47421685477208825, 0.493316779256533, 0.4470769220224306, 0.47365304611248676, 0.4502714466116282, 0.46368990164229323, 0.487818848820372, 0.49610742710156147, 0.4594513311066441, 0.45766615101745006, 0.47859402475410334, 0.4479316446368255, 0.47275907433898756, 0.4548008322049786, 0.4567537570798863, 0.4716469385770446, 0.47249563146569873, 0.46622714050655256, 0.45465743808107, 0.4627910709247909, 0.47478212424496696, 0.46179952168597854, 0.4755544452693875, 0.4881504144748496, 0.4523047115549695, 0.4729079597489128], 'val_acc': [0.9249467013934471, 0.9473323026182932, 0.9532763368590584, 0.9516896235876243, 0.9530222219461836, 0.9546729908975143, 0.9542659674276853, 0.9556089090235407, 0.9551895167574537, 0.9544188460158236, 0.9538817069383972, 0.9560117658290117, 0.9556564369015188, 0.9564187979564986, 0.9550779115554341, 0.9542701137798458, 0.9537143450875522, 0.9537267381918497, 0.9530614621146432, 0.9510697852299866, 0.956017969706871, 0.9562349196252876, 0.9550304023247191, 0.9543073020833831, 0.9523900058016431, 0.9533217829032983, 0.9554870305114618, 0.953704016834664, 0.9551398910623689, 0.9534581683201497, 0.9524044770768235, 0.9524933222951836, 0.9556440487920239, 0.9559560128430414, 0.9556171767538486, 0.9555985624563761, 0.9545593664632829, 0.9557659469503265, 0.9560696422720755, 0.9548362200486593, 0.9544147326293604, 0.9564952360851139, 0.9530676729852261, 0.9559911279704983, 0.9542184488733387, 0.9551130366724963, 0.9554622423049458, 0.9547267119977727, 0.955532475889728, 0.9564064105129775, 0.9545139097634641, 0.955610973541963, 0.9530139412293887, 0.9557638617867198, 0.9535903904025115, 0.9521771879169528, 0.9535098082526436, 0.953693689913723, 0.9559064024653514, 0.9550903203101132, 0.9551006488959882, 0.9552638867047912, 0.9526276098949283, 0.95435067628349, 0.9548134950286183, 0.9530924595268079, 0.9547824719764667, 0.9543796081782719, 0.9541378640595761, 0.9551316533008767, 0.9521854679677739, 0.9556894745240664, 0.9551998170394471, 0.9537887027143767, 0.9552081030840315, 0.9534230245558243, 0.9537432533402682, 0.9531482538031466, 0.9557101363576325, 0.9544829100203913, 0.953704006179085, 0.9550675996189011], 'val_mDice': [0.3935917709126819, 0.5899047928149473, 0.6065603667797324, 0.6234176385336082, 0.618868785863482, 0.6295818143716737, 0.6340352183613698, 0.6295859450734528, 0.6316664708393246, 0.6287871412724756, 0.6329966583731454, 0.63605627933694, 0.6401692592231921, 0.6306489945789955, 0.6352096969188925, 0.6203535192505607, 0.6380338242600084, 0.6221242104162718, 0.6286931877029674, 0.5567826019319077, 0.6268400033759005, 0.6287724485610451, 0.6321882702118857, 0.6301103767070024, 0.62681151002479, 0.6270987977528705, 0.6274956884330878, 0.6325917383811993, 0.6348550223105447, 0.6260938131609443, 0.6286054453370291, 0.6037810574696717, 0.6355581523319862, 0.6322545838755602, 0.6347067479314751, 0.6290457301965638, 0.6220661261894184, 0.6258494487687862, 0.6354492429914421, 0.6226457170933984, 0.626956113223923, 0.6416527512353226, 0.631885507586282, 0.6184522053382916, 0.6347288532630025, 0.6270857999444673, 0.6262722301749544, 0.6195907482887779, 0.6264466606704883, 0.6199652908900597, 0.6126769681216618, 0.6226612149670138, 0.628322557697083, 0.6301959526605446, 0.6280124860102904, 0.6190848383823586, 0.6220021667427191, 0.6154741172017998, 0.6339795932423469, 0.6201907233152976, 0.6297776635798662, 0.6231205902952056, 0.6089169006773879, 0.6119959287803266, 0.6249790704450128, 0.6295393102661857, 0.6158880414909491, 0.6320043259492799, 0.6211775321534226, 0.6296383312294603, 0.6271790509117382, 0.6229074657296335, 0.6217631780901435, 0.6221085287339194, 0.6301729366100034, 0.6220282342846833, 0.62067470603815, 0.6275423388907363, 0.6174666641810753, 0.6151940629468949, 0.6279749510674503, 0.6248496044947448], 'loss': [2.029979884046646, 0.5719799100914446, 0.45637933687280513, 0.4150719386606355, 0.3934399716202635, 0.3740735758000824, 0.3595396109372921, 0.3475103598944431, 0.3383631442722351, 0.33139015530411514, 0.32324891988861426, 0.31804812504090707, 0.31369754809367423, 0.3082386636878792, 0.30335412699181197, 0.2988184237167224, 0.2960864256591256, 0.2929953866018968, 0.2896369756076417, 0.3593295102616514, 0.3142091336755294, 0.2948509405221654, 0.28761161323544454, 0.2843055569650327, 0.28207120077619496, 0.2795988202799471, 0.2749062421148389, 0.27279241581341257, 0.27064427632300214, 0.27141573162297267, 0.2691690839555592, 0.2957625188252796, 0.2794258824575636, 0.2685378170319875, 0.2660160661587742, 0.26241329488109694, 0.26037900089847515, 0.26106213113950116, 0.25830426913455357, 0.25829105314771617, 0.2559179848240687, 0.25476898623281535, 0.25466412464574195, 0.251697531794224, 0.2519203440425352, 0.2511985769271072, 0.2522314534984729, 0.2490674612663143, 0.24822936084793645, 0.24841024097706277, 0.24805943137854963, 0.24680335173795934, 0.24609313250873532, 0.24403864215641694, 0.24355881863459478, 0.2431528850189579, 0.2420340326454546, 0.24260912186264127, 0.23994741080344342, 0.24039393042883098, 0.24007233769556943, 0.2398708595406171, 0.23776575089325527, 0.2371968681643091, 0.2377498989177032, 0.23501360434997212, 0.23608169545568183, 0.23423221006962697, 0.23514319377088072, 0.23405856489778104, 0.23371338732790164, 0.2333305270643537, 0.23289585831355414, 0.23208413989992807, 0.23117916396202315, 0.23049699065618529, 0.2306450503484128, 0.231663048027141, 0.2299739348241417, 0.2296100195801003, 0.23045926625939225, 0.22912288949653983], 'acc': [0.6100658875469127, 0.9264375352825736, 0.9368594722656648, 0.9416525239427913, 0.9442208566298692, 0.9458757190167804, 0.947177018071239, 0.9482391539998228, 0.9489893103780768, 0.9496379758620741, 0.950185652132628, 0.9506814596044115, 0.9510244737620136, 0.9514809432200347, 0.9519244050104422, 0.952204577579756, 0.9524649311615668, 0.9527299547791449, 0.9529441608874135, 0.9480055475973835, 0.9511798665606763, 0.9526446946020071, 0.9531301516903803, 0.9535257960448799, 0.953717625434606, 0.9536509974369926, 0.9540569134789818, 0.9542047755857561, 0.9543174251635658, 0.9543319694143152, 0.9544796866338553, 0.9529735293239558, 0.9538730400838686, 0.954564805952372, 0.9547402812961815, 0.9549353531091135, 0.9550161842303653, 0.9549759826488234, 0.9551599138274275, 0.9552281349515949, 0.955341692048346, 0.955438012303782, 0.9554259279741518, 0.9556293571854292, 0.9556248685865775, 0.9556351193291749, 0.9557302271279041, 0.9558364537558092, 0.9558778075271751, 0.9558535764812222, 0.9559304764260265, 0.9559613762289589, 0.955999163363041, 0.956123132674784, 0.9561709689422667, 0.9562572596619952, 0.9562811245911003, 0.9562312531241417, 0.9563901101696901, 0.9564206669756636, 0.9564698125034315, 0.9564470508981456, 0.9566308865392139, 0.9566176925133493, 0.9566163844704129, 0.9568149593230797, 0.9566613214350066, 0.9568764534036056, 0.9567930456613067, 0.9568057166784069, 0.956831779224045, 0.9569248751314706, 0.9569467885595127, 0.956970576318441, 0.957039765322574, 0.9570818999209544, 0.957051364686402, 0.957002016439215, 0.9571450664439912, 0.9571473802735126, 0.9571184984388892, 0.9572775174827268], 'mDice': [0.23761654446208588, 0.5527087324364605, 0.6201300620643163, 0.646472883321226, 0.6613682484251502, 0.6740399290095954, 0.684087821162284, 0.6924972317686372, 0.6990160956945524, 0.7043124252846996, 0.710033539635353, 0.7140388470687843, 0.7171529309304605, 0.7213012980360408, 0.7250327003313158, 0.7282810041044969, 0.7304500136251549, 0.7328309864365752, 0.7352652468457214, 0.6889146302437303, 0.7166429912886207, 0.7312613115656851, 0.7367586886549715, 0.7393670982995342, 0.7415536210483847, 0.7428656317012436, 0.7465470543315965, 0.748238635393641, 0.7498851051570011, 0.7493009297885794, 0.7511142356340794, 0.7365019203375046, 0.7429972885740679, 0.7513974414633469, 0.7535036070778846, 0.7563209997095526, 0.7578780989710279, 0.7574025033008662, 0.7595483481796353, 0.7596130459521969, 0.761428169263785, 0.7623314728768561, 0.7624331863122168, 0.7648130562770186, 0.7646318066841468, 0.7651814587248299, 0.7645433092161459, 0.7668983340555531, 0.7676349145110075, 0.7673745782382737, 0.7679121837488194, 0.7686977358913832, 0.7692928921519967, 0.770963619918282, 0.7713689982946269, 0.7716365034469468, 0.7724955065675917, 0.772132401599856, 0.7742382749987352, 0.7738666282319002, 0.7741444097041279, 0.7743131093590369, 0.7760237611967795, 0.776556522626385, 0.7761276880644692, 0.7782478723467049, 0.7774265501846007, 0.7788990477020785, 0.7781898753327888, 0.7790778754005622, 0.7793226175711803, 0.7796690124428147, 0.7799730617673716, 0.7806897842769146, 0.7813466293516648, 0.7819862619580464, 0.7818164647479287, 0.7810074931999599, 0.7823964025348265, 0.7826856404736076, 0.7821006559090744, 0.7831110059419661]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.40s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.18s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.96s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:49,  1.86s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:08,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:13,  1.75s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:43,  1.65s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:03,  1.73s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:40,  1.65s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:50,  1.69s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:46,  1.69s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:15,  1.80s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:36,  1.88s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:22,  1.84s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:47,  1.93s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:23,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:17,  1.84s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:31,  1.89s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:47,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:22,  1.88s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:22,  1.88s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:17,  1.87s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:16,  1.88s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:30,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:06,  1.85s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:06,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:46,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:04,  1.86s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:55,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:55,  1.85s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:54,  1.85s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:12,  1.93s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:23,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:58,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<08:02,  1.92s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:58,  1.91s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:13,  1.97s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:50,  1.89s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:51,  1.90s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:01,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:30,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:20,  1.81s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:10,  1.77s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:12,  1.79s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:32,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:21,  1.84s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:39,  1.92s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:20,  1.85s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:19,  1.85s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:36,  1.94s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:28,  1.91s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:38,  1.96s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:30,  1.93s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:27,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:43,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:17,  1.90s/it]predicting train subjects:  20%|█▉        | 56/285 [01:44<07:11,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:50,  1.80s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:53,  1.82s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:09,  1.90s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:21,  1.96s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:57,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<07:02,  1.89s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<06:57,  1.88s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<06:46,  1.84s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<06:51,  1.87s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:48,  1.86s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:47,  1.87s/it]predicting train subjects:  24%|██▍       | 68/285 [02:06<06:34,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:08<06:35,  1.83s/it]predicting train subjects:  25%|██▍       | 70/285 [02:10<06:39,  1.86s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:38,  1.86s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:28,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:28,  1.83s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:30,  1.85s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:33,  1.88s/it]predicting train subjects:  27%|██▋       | 76/285 [02:21<06:37,  1.90s/it]predicting train subjects:  27%|██▋       | 77/285 [02:23<06:26,  1.86s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:14,  1.81s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:13,  1.81s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:14,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:30<06:08,  1.81s/it]predicting train subjects:  29%|██▉       | 82/285 [02:32<06:13,  1.84s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<06:05,  1.81s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:59,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:37<06:03,  1.82s/it]predicting train subjects:  30%|███       | 86/285 [02:39<06:11,  1.87s/it]predicting train subjects:  31%|███       | 87/285 [02:41<06:15,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:43<06:06,  1.86s/it]predicting train subjects:  31%|███       | 89/285 [02:45<06:04,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<06:05,  1.87s/it]predicting train subjects:  32%|███▏      | 91/285 [02:48<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:50<06:02,  1.88s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:55,  1.85s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:59,  1.89s/it]predicting train subjects:  34%|███▎      | 96/285 [02:58<06:01,  1.91s/it]predicting train subjects:  34%|███▍      | 97/285 [03:00<06:02,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [03:02<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:04<05:52,  1.90s/it]predicting train subjects:  35%|███▌      | 100/285 [03:06<05:49,  1.89s/it]predicting train subjects:  35%|███▌      | 101/285 [03:07<05:38,  1.84s/it]predicting train subjects:  36%|███▌      | 102/285 [03:09<05:37,  1.84s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:32,  1.82s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:32,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:31,  1.84s/it]predicting train subjects:  37%|███▋      | 106/285 [03:16<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:18<05:29,  1.85s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:23,  1.83s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:26,  1.86s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:26<05:15,  1.81s/it]predicting train subjects:  39%|███▉      | 112/285 [03:28<05:17,  1.83s/it]predicting train subjects:  40%|███▉      | 113/285 [03:29<05:14,  1.83s/it]predicting train subjects:  40%|████      | 114/285 [03:31<05:11,  1.82s/it]predicting train subjects:  40%|████      | 115/285 [03:33<05:08,  1.81s/it]predicting train subjects:  41%|████      | 116/285 [03:35<05:07,  1.82s/it]predicting train subjects:  41%|████      | 117/285 [03:36<04:59,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:38<04:53,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:40<04:57,  1.79s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<04:55,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:43<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:45<04:36,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:48<04:29,  1.68s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:22,  1.64s/it]predicting train subjects:  44%|████▍     | 126/285 [03:51<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:13,  1.60s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:19,  1.65s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<04:13,  1.62s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<04:12,  1.63s/it]predicting train subjects:  46%|████▌     | 131/285 [04:00<04:05,  1.59s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<04:07,  1.62s/it]predicting train subjects:  47%|████▋     | 133/285 [04:03<04:03,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<03:59,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [04:06<03:54,  1.56s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<03:55,  1.58s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:11<03:53,  1.59s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<03:54,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<03:56,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:16<03:52,  1.62s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:47,  1.59s/it]predicting train subjects:  50%|█████     | 143/285 [04:19<03:44,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:47,  1.62s/it]predicting train subjects:  51%|█████     | 145/285 [04:22<03:46,  1.62s/it]predicting train subjects:  51%|█████     | 146/285 [04:24<03:51,  1.67s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:25<03:48,  1.65s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:50,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:29<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:40,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:32<03:40,  1.64s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:34<03:34,  1.61s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:35<03:29,  1.59s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:37<03:35,  1.65s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:38<03:32,  1.64s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:40<03:34,  1.66s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:42<03:27,  1.62s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:26,  1.62s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:45<03:21,  1.60s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:16,  1.57s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:48<03:19,  1.61s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:50<03:16,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:51<03:20,  1.64s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:53<03:13,  1.60s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:54<03:09,  1.58s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:56<03:09,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:58<03:09,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:59<03:03,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:01<03:02,  1.57s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:02<03:00,  1.57s/it]predicting train subjects:  60%|██████    | 171/285 [05:04<03:02,  1.60s/it]predicting train subjects:  60%|██████    | 172/285 [05:05<02:58,  1.58s/it]predicting train subjects:  61%|██████    | 173/285 [05:07<02:54,  1.56s/it]predicting train subjects:  61%|██████    | 174/285 [05:09<02:53,  1.56s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:10<02:54,  1.59s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:12<02:57,  1.63s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:13<02:52,  1.59s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:15<02:45,  1.54s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:16<02:42,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:18<02:50,  1.62s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:20<02:53,  1.66s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:22<02:56,  1.71s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:23<02:48,  1.65s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:25<02:42,  1.61s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:26<02:37,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:48,  1.70s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:30<02:52,  1.76s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:32<02:53,  1.79s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:34<02:42,  1.70s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:35<02:34,  1.63s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:37<02:36,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:39<02:36,  1.68s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:40<02:29,  1.63s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:42<02:25,  1.59s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:43<02:21,  1.57s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:45<02:28,  1.67s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:47<02:32,  1.74s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:49<02:34,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:50<02:24,  1.69s/it]predicting train subjects:  70%|███████   | 200/285 [05:52<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:53<02:21,  1.69s/it]predicting train subjects:  71%|███████   | 202/285 [05:55<02:21,  1.71s/it]predicting train subjects:  71%|███████   | 203/285 [05:57<02:21,  1.73s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:59<02:15,  1.67s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:00<02:08,  1.61s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:02<02:04,  1.58s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:03<02:12,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:05<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:07<02:14,  1.78s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:09<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:10<02:02,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:12<02:04,  1.70s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:14<02:02,  1.70s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:15<01:56,  1.63s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:17<01:58,  1.70s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:19<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:20<01:56,  1.71s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:22<01:58,  1.76s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:24<01:58,  1.79s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:26<01:52,  1.73s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:27<01:46,  1.66s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:29<01:46,  1.70s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:31<01:44,  1.68s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:32<01:41,  1.67s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:34<01:38,  1.65s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:36<01:42,  1.75s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:38<01:45,  1.82s/it]predicting train subjects:  80%|████████  | 228/285 [06:40<01:46,  1.87s/it]predicting train subjects:  80%|████████  | 229/285 [06:42<01:45,  1.89s/it]predicting train subjects:  81%|████████  | 230/285 [06:43<01:37,  1.77s/it]predicting train subjects:  81%|████████  | 231/285 [06:45<01:32,  1.71s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:47<01:31,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:48<01:27,  1.69s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:50<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:52<01:25,  1.71s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:54<01:28,  1.81s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:56<01:29,  1.85s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:58<01:29,  1.90s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:00<01:25,  1.86s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:01<01:19,  1.77s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:03<01:15,  1.72s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:04<01:12,  1.68s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:06<01:08,  1.64s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:08<01:10,  1.72s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:09<01:05,  1.64s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:11<01:09,  1.79s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:13<01:09,  1.83s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:15<01:07,  1.83s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:17<01:03,  1.77s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:18<01:00,  1.72s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:20<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:22<00:54,  1.66s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:24<00:57,  1.81s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:26<00:56,  1.82s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:27<00:54,  1.83s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:29<00:51,  1.76s/it]predicting train subjects:  90%|█████████ | 257/285 [07:31<00:47,  1.69s/it]predicting train subjects:  91%|█████████ | 258/285 [07:33<00:48,  1.78s/it]predicting train subjects:  91%|█████████ | 259/285 [07:34<00:46,  1.79s/it]predicting train subjects:  91%|█████████ | 260/285 [07:36<00:42,  1.71s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:37<00:40,  1.67s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:39<00:37,  1.63s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:41<00:35,  1.62s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:43<00:36,  1.73s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:44<00:35,  1.78s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:46<00:32,  1.72s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:48<00:30,  1.69s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:50<00:29,  1.74s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:51<00:27,  1.74s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:53<00:25,  1.69s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:54<00:22,  1.64s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:56<00:21,  1.69s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:58<00:19,  1.64s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:59<00:17,  1.62s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:01<00:17,  1.75s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:03<00:16,  1.79s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:05<00:14,  1.75s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:06<00:12,  1.72s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:08<00:10,  1.76s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:10<00:08,  1.71s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:11<00:06,  1.66s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:13<00:04,  1.62s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:15<00:03,  1.74s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:17<00:01,  1.81s/it]predicting train subjects: 100%|██████████| 285/285 [08:19<00:00,  1.86s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:00,  1.90s/it]Loading train:   1%|          | 2/285 [00:03<08:01,  1.70s/it]Loading train:   1%|          | 3/285 [00:04<07:39,  1.63s/it]Loading train:   1%|▏         | 4/285 [00:05<07:02,  1.50s/it]Loading train:   2%|▏         | 5/285 [00:07<07:16,  1.56s/it]Loading train:   2%|▏         | 6/285 [00:08<06:53,  1.48s/it]Loading train:   2%|▏         | 7/285 [00:10<07:16,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<07:07,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:13<07:10,  1.56s/it]Loading train:   4%|▎         | 10/285 [00:14<06:30,  1.42s/it]Loading train:   4%|▍         | 11/285 [00:15<05:50,  1.28s/it]Loading train:   4%|▍         | 12/285 [00:16<05:33,  1.22s/it]Loading train:   5%|▍         | 13/285 [00:17<05:30,  1.22s/it]Loading train:   5%|▍         | 14/285 [00:19<05:23,  1.19s/it]Loading train:   5%|▌         | 15/285 [00:20<05:04,  1.13s/it]Loading train:   6%|▌         | 16/285 [00:21<04:57,  1.11s/it]Loading train:   6%|▌         | 17/285 [00:22<04:50,  1.08s/it]Loading train:   6%|▋         | 18/285 [00:23<04:50,  1.09s/it]Loading train:   7%|▋         | 19/285 [00:24<04:42,  1.06s/it]Loading train:   7%|▋         | 20/285 [00:25<04:53,  1.11s/it]Loading train:   7%|▋         | 21/285 [00:26<04:58,  1.13s/it]Loading train:   8%|▊         | 22/285 [00:27<04:51,  1.11s/it]Loading train:   8%|▊         | 23/285 [00:28<04:56,  1.13s/it]Loading train:   8%|▊         | 24/285 [00:29<04:38,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:31<04:51,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:32<04:51,  1.13s/it]Loading train:   9%|▉         | 27/285 [00:33<04:39,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:34<04:35,  1.07s/it]Loading train:  10%|█         | 29/285 [00:35<04:46,  1.12s/it]Loading train:  11%|█         | 30/285 [00:36<04:51,  1.14s/it]Loading train:  11%|█         | 31/285 [00:37<04:47,  1.13s/it]Loading train:  11%|█         | 32/285 [00:38<04:38,  1.10s/it]Loading train:  12%|█▏        | 33/285 [00:39<04:37,  1.10s/it]Loading train:  12%|█▏        | 34/285 [00:40<04:23,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:35,  1.10s/it]Loading train:  13%|█▎        | 36/285 [00:42<04:19,  1.04s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:21,  1.06s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:22,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:28,  1.09s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:26,  1.09s/it]Loading train:  14%|█▍        | 41/285 [00:48<04:29,  1.11s/it]Loading train:  15%|█▍        | 42/285 [00:49<04:28,  1.10s/it]Loading train:  15%|█▌        | 43/285 [00:50<04:18,  1.07s/it]Loading train:  15%|█▌        | 44/285 [00:51<04:27,  1.11s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:37,  1.16s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:40,  1.17s/it]Loading train:  16%|█▋        | 47/285 [00:55<04:17,  1.08s/it]Loading train:  17%|█▋        | 48/285 [00:56<04:33,  1.15s/it]Loading train:  17%|█▋        | 49/285 [00:57<04:28,  1.14s/it]Loading train:  18%|█▊        | 50/285 [00:58<04:36,  1.18s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:24,  1.13s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:22,  1.12s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:20,  1.12s/it]Loading train:  19%|█▉        | 54/285 [01:03<04:20,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:04<04:17,  1.12s/it]Loading train:  20%|█▉        | 56/285 [01:05<04:13,  1.11s/it]Loading train:  20%|██        | 57/285 [01:06<03:57,  1.04s/it]Loading train:  20%|██        | 58/285 [01:07<03:50,  1.02s/it]Loading train:  21%|██        | 59/285 [01:08<03:58,  1.05s/it]Loading train:  21%|██        | 60/285 [01:09<04:09,  1.11s/it]Loading train:  21%|██▏       | 61/285 [01:10<03:53,  1.04s/it]Loading train:  22%|██▏       | 62/285 [01:11<04:01,  1.08s/it]Loading train:  22%|██▏       | 63/285 [01:12<03:54,  1.05s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:14,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:15<04:38,  1.27s/it]Loading train:  23%|██▎       | 66/285 [01:17<04:48,  1.32s/it]Loading train:  24%|██▎       | 67/285 [01:18<04:23,  1.21s/it]Loading train:  24%|██▍       | 68/285 [01:18<04:01,  1.11s/it]Loading train:  24%|██▍       | 69/285 [01:19<03:41,  1.03s/it]Loading train:  25%|██▍       | 70/285 [01:20<03:39,  1.02s/it]Loading train:  25%|██▍       | 71/285 [01:21<03:33,  1.00it/s]Loading train:  25%|██▌       | 72/285 [01:22<03:27,  1.03it/s]Loading train:  26%|██▌       | 73/285 [01:23<03:20,  1.06it/s]Loading train:  26%|██▌       | 74/285 [01:24<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:26<04:00,  1.15s/it]Loading train:  27%|██▋       | 76/285 [01:27<04:05,  1.18s/it]Loading train:  27%|██▋       | 77/285 [01:28<03:58,  1.15s/it]Loading train:  27%|██▋       | 78/285 [01:29<04:10,  1.21s/it]Loading train:  28%|██▊       | 79/285 [01:30<04:04,  1.19s/it]Loading train:  28%|██▊       | 80/285 [01:32<04:11,  1.23s/it]Loading train:  28%|██▊       | 81/285 [01:33<04:31,  1.33s/it]Loading train:  29%|██▉       | 82/285 [01:34<04:17,  1.27s/it]Loading train:  29%|██▉       | 83/285 [01:36<04:12,  1.25s/it]Loading train:  29%|██▉       | 84/285 [01:37<03:59,  1.19s/it]Loading train:  30%|██▉       | 85/285 [01:38<04:11,  1.26s/it]Loading train:  30%|███       | 86/285 [01:39<04:14,  1.28s/it]Loading train:  31%|███       | 87/285 [01:41<04:16,  1.29s/it]Loading train:  31%|███       | 88/285 [01:42<04:02,  1.23s/it]Loading train:  31%|███       | 89/285 [01:43<04:06,  1.26s/it]Loading train:  32%|███▏      | 90/285 [01:44<04:02,  1.24s/it]Loading train:  32%|███▏      | 91/285 [01:46<04:27,  1.38s/it]Loading train:  32%|███▏      | 92/285 [01:47<04:27,  1.39s/it]Loading train:  33%|███▎      | 93/285 [01:49<04:06,  1.29s/it]Loading train:  33%|███▎      | 94/285 [01:50<04:05,  1.28s/it]Loading train:  33%|███▎      | 95/285 [01:51<04:25,  1.40s/it]Loading train:  34%|███▎      | 96/285 [01:53<04:29,  1.43s/it]Loading train:  34%|███▍      | 97/285 [01:54<04:20,  1.38s/it]Loading train:  34%|███▍      | 98/285 [01:56<04:11,  1.34s/it]Loading train:  35%|███▍      | 99/285 [01:57<04:20,  1.40s/it]Loading train:  35%|███▌      | 100/285 [01:59<04:25,  1.44s/it]Loading train:  35%|███▌      | 101/285 [02:00<04:19,  1.41s/it]Loading train:  36%|███▌      | 102/285 [02:01<04:13,  1.39s/it]Loading train:  36%|███▌      | 103/285 [02:03<04:09,  1.37s/it]Loading train:  36%|███▋      | 104/285 [02:04<04:18,  1.43s/it]Loading train:  37%|███▋      | 105/285 [02:06<04:30,  1.50s/it]Loading train:  37%|███▋      | 106/285 [02:07<04:07,  1.38s/it]Loading train:  38%|███▊      | 107/285 [02:08<03:55,  1.33s/it]Loading train:  38%|███▊      | 108/285 [02:09<03:36,  1.22s/it]Loading train:  38%|███▊      | 109/285 [02:11<03:45,  1.28s/it]Loading train:  39%|███▊      | 110/285 [02:12<03:55,  1.35s/it]Loading train:  39%|███▉      | 111/285 [02:13<03:33,  1.23s/it]Loading train:  39%|███▉      | 112/285 [02:14<03:32,  1.23s/it]Loading train:  40%|███▉      | 113/285 [02:15<03:35,  1.25s/it]Loading train:  40%|████      | 114/285 [02:17<03:48,  1.34s/it]Loading train:  40%|████      | 115/285 [02:19<03:54,  1.38s/it]Loading train:  41%|████      | 116/285 [02:20<03:53,  1.38s/it]Loading train:  41%|████      | 117/285 [02:21<03:53,  1.39s/it]Loading train:  41%|████▏     | 118/285 [02:23<03:43,  1.34s/it]Loading train:  42%|████▏     | 119/285 [02:24<03:40,  1.33s/it]Loading train:  42%|████▏     | 120/285 [02:25<03:20,  1.22s/it]Loading train:  42%|████▏     | 121/285 [02:26<03:34,  1.30s/it]Loading train:  43%|████▎     | 122/285 [02:28<03:38,  1.34s/it]Loading train:  43%|████▎     | 123/285 [02:29<03:56,  1.46s/it]Loading train:  44%|████▎     | 124/285 [02:31<03:42,  1.38s/it]Loading train:  44%|████▍     | 125/285 [02:32<03:32,  1.33s/it]Loading train:  44%|████▍     | 126/285 [02:33<03:16,  1.24s/it]Loading train:  45%|████▍     | 127/285 [02:34<03:12,  1.22s/it]Loading train:  45%|████▍     | 128/285 [02:35<03:03,  1.17s/it]Loading train:  45%|████▌     | 129/285 [02:36<03:05,  1.19s/it]Loading train:  46%|████▌     | 130/285 [02:37<02:59,  1.16s/it]Loading train:  46%|████▌     | 131/285 [02:39<02:58,  1.16s/it]Loading train:  46%|████▋     | 132/285 [02:40<03:04,  1.20s/it]Loading train:  47%|████▋     | 133/285 [02:41<02:56,  1.16s/it]Loading train:  47%|████▋     | 134/285 [02:42<02:58,  1.18s/it]Loading train:  47%|████▋     | 135/285 [02:44<03:02,  1.22s/it]Loading train:  48%|████▊     | 136/285 [02:45<02:54,  1.17s/it]Loading train:  48%|████▊     | 137/285 [02:46<03:05,  1.25s/it]Loading train:  48%|████▊     | 138/285 [02:47<03:00,  1.23s/it]Loading train:  49%|████▉     | 139/285 [02:49<03:07,  1.28s/it]Loading train:  49%|████▉     | 140/285 [02:50<03:17,  1.36s/it]Loading train:  49%|████▉     | 141/285 [02:51<03:15,  1.36s/it]Loading train:  50%|████▉     | 142/285 [02:53<03:09,  1.33s/it]Loading train:  50%|█████     | 143/285 [02:54<03:08,  1.33s/it]Loading train:  51%|█████     | 144/285 [02:55<02:52,  1.22s/it]Loading train:  51%|█████     | 145/285 [02:56<02:44,  1.17s/it]Loading train:  51%|█████     | 146/285 [02:57<02:46,  1.20s/it]Loading train:  52%|█████▏    | 147/285 [02:59<02:45,  1.20s/it]Loading train:  52%|█████▏    | 148/285 [03:00<02:42,  1.19s/it]Loading train:  52%|█████▏    | 149/285 [03:01<02:36,  1.15s/it]Loading train:  53%|█████▎    | 150/285 [03:02<02:29,  1.11s/it]Loading train:  53%|█████▎    | 151/285 [03:03<02:40,  1.20s/it]Loading train:  53%|█████▎    | 152/285 [03:04<02:32,  1.15s/it]Loading train:  54%|█████▎    | 153/285 [03:05<02:32,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:07<02:32,  1.17s/it]Loading train:  54%|█████▍    | 155/285 [03:08<02:33,  1.18s/it]Loading train:  55%|█████▍    | 156/285 [03:09<02:41,  1.25s/it]Loading train:  55%|█████▌    | 157/285 [03:10<02:34,  1.21s/it]Loading train:  55%|█████▌    | 158/285 [03:11<02:30,  1.19s/it]Loading train:  56%|█████▌    | 159/285 [03:13<02:25,  1.16s/it]Loading train:  56%|█████▌    | 160/285 [03:14<02:22,  1.14s/it]Loading train:  56%|█████▋    | 161/285 [03:15<02:26,  1.18s/it]Loading train:  57%|█████▋    | 162/285 [03:16<02:20,  1.14s/it]Loading train:  57%|█████▋    | 163/285 [03:17<02:23,  1.18s/it]Loading train:  58%|█████▊    | 164/285 [03:18<02:14,  1.11s/it]Loading train:  58%|█████▊    | 165/285 [03:19<02:14,  1.12s/it]Loading train:  58%|█████▊    | 166/285 [03:20<02:13,  1.12s/it]Loading train:  59%|█████▊    | 167/285 [03:22<02:19,  1.18s/it]Loading train:  59%|█████▉    | 168/285 [03:23<02:18,  1.18s/it]Loading train:  59%|█████▉    | 169/285 [03:24<02:13,  1.15s/it]Loading train:  60%|█████▉    | 170/285 [03:25<02:15,  1.18s/it]Loading train:  60%|██████    | 171/285 [03:26<02:07,  1.12s/it]Loading train:  60%|██████    | 172/285 [03:27<02:04,  1.10s/it]Loading train:  61%|██████    | 173/285 [03:28<01:59,  1.07s/it]Loading train:  61%|██████    | 174/285 [03:30<02:06,  1.14s/it]Loading train:  61%|██████▏   | 175/285 [03:31<02:07,  1.16s/it]Loading train:  62%|██████▏   | 176/285 [03:32<02:15,  1.25s/it]Loading train:  62%|██████▏   | 177/285 [03:33<02:13,  1.24s/it]Loading train:  62%|██████▏   | 178/285 [03:34<02:03,  1.15s/it]Loading train:  63%|██████▎   | 179/285 [03:36<02:02,  1.16s/it]Loading train:  63%|██████▎   | 180/285 [03:37<02:07,  1.22s/it]Loading train:  64%|██████▎   | 181/285 [03:38<02:07,  1.23s/it]Loading train:  64%|██████▍   | 182/285 [03:40<02:09,  1.26s/it]Loading train:  64%|██████▍   | 183/285 [03:41<02:05,  1.23s/it]Loading train:  65%|██████▍   | 184/285 [03:42<01:59,  1.18s/it]Loading train:  65%|██████▍   | 185/285 [03:43<01:56,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [03:44<02:06,  1.27s/it]Loading train:  66%|██████▌   | 187/285 [03:46<02:09,  1.32s/it]Loading train:  66%|██████▌   | 188/285 [03:47<02:10,  1.34s/it]Loading train:  66%|██████▋   | 189/285 [03:48<02:00,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [03:49<01:52,  1.19s/it]Loading train:  67%|██████▋   | 191/285 [03:50<01:49,  1.17s/it]Loading train:  67%|██████▋   | 192/285 [03:52<01:55,  1.24s/it]Loading train:  68%|██████▊   | 193/285 [03:53<01:49,  1.19s/it]Loading train:  68%|██████▊   | 194/285 [03:54<01:43,  1.14s/it]Loading train:  68%|██████▊   | 195/285 [03:55<01:44,  1.16s/it]Loading train:  69%|██████▉   | 196/285 [03:56<01:44,  1.18s/it]Loading train:  69%|██████▉   | 197/285 [03:58<01:50,  1.25s/it]Loading train:  69%|██████▉   | 198/285 [03:59<01:53,  1.30s/it]Loading train:  70%|██████▉   | 199/285 [04:00<01:43,  1.20s/it]Loading train:  70%|███████   | 200/285 [04:01<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:03<01:54,  1.36s/it]Loading train:  71%|███████   | 202/285 [04:05<01:54,  1.38s/it]Loading train:  71%|███████   | 203/285 [04:06<01:55,  1.41s/it]Loading train:  72%|███████▏  | 204/285 [04:07<01:46,  1.31s/it]Loading train:  72%|███████▏  | 205/285 [04:08<01:39,  1.25s/it]Loading train:  72%|███████▏  | 206/285 [04:09<01:30,  1.15s/it]Loading train:  73%|███████▎  | 207/285 [04:11<01:36,  1.23s/it]Loading train:  73%|███████▎  | 208/285 [04:12<01:35,  1.24s/it]Loading train:  73%|███████▎  | 209/285 [04:13<01:32,  1.21s/it]Loading train:  74%|███████▎  | 210/285 [04:14<01:31,  1.22s/it]Loading train:  74%|███████▍  | 211/285 [04:15<01:28,  1.20s/it]Loading train:  74%|███████▍  | 212/285 [04:17<01:35,  1.30s/it]Loading train:  75%|███████▍  | 213/285 [04:18<01:31,  1.28s/it]Loading train:  75%|███████▌  | 214/285 [04:19<01:25,  1.20s/it]Loading train:  75%|███████▌  | 215/285 [04:20<01:26,  1.24s/it]Loading train:  76%|███████▌  | 216/285 [04:21<01:19,  1.16s/it]Loading train:  76%|███████▌  | 217/285 [04:23<01:23,  1.23s/it]Loading train:  76%|███████▋  | 218/285 [04:24<01:19,  1.19s/it]Loading train:  77%|███████▋  | 219/285 [04:25<01:22,  1.25s/it]Loading train:  77%|███████▋  | 220/285 [04:26<01:16,  1.18s/it]Loading train:  78%|███████▊  | 221/285 [04:28<01:15,  1.18s/it]Loading train:  78%|███████▊  | 222/285 [04:29<01:13,  1.17s/it]Loading train:  78%|███████▊  | 223/285 [04:30<01:09,  1.12s/it]Loading train:  79%|███████▊  | 224/285 [04:31<01:06,  1.10s/it]Loading train:  79%|███████▉  | 225/285 [04:32<01:03,  1.06s/it]Loading train:  79%|███████▉  | 226/285 [04:33<01:05,  1.11s/it]Loading train:  80%|███████▉  | 227/285 [04:34<01:04,  1.11s/it]Loading train:  80%|████████  | 228/285 [04:35<01:04,  1.12s/it]Loading train:  80%|████████  | 229/285 [04:36<01:02,  1.11s/it]Loading train:  81%|████████  | 230/285 [04:37<01:03,  1.15s/it]Loading train:  81%|████████  | 231/285 [04:39<00:59,  1.11s/it]Loading train:  81%|████████▏ | 232/285 [04:39<00:56,  1.06s/it]Loading train:  82%|████████▏ | 233/285 [04:40<00:54,  1.06s/it]Loading train:  82%|████████▏ | 234/285 [04:42<00:58,  1.15s/it]Loading train:  82%|████████▏ | 235/285 [04:43<00:56,  1.13s/it]Loading train:  83%|████████▎ | 236/285 [04:44<00:59,  1.21s/it]Loading train:  83%|████████▎ | 237/285 [04:46<00:57,  1.20s/it]Loading train:  84%|████████▎ | 238/285 [04:47<00:55,  1.18s/it]Loading train:  84%|████████▍ | 239/285 [04:48<00:56,  1.23s/it]Loading train:  84%|████████▍ | 240/285 [04:49<00:55,  1.23s/it]Loading train:  85%|████████▍ | 241/285 [04:50<00:52,  1.19s/it]Loading train:  85%|████████▍ | 242/285 [04:52<00:53,  1.23s/it]Loading train:  85%|████████▌ | 243/285 [04:53<00:48,  1.16s/it]Loading train:  86%|████████▌ | 244/285 [04:54<00:49,  1.21s/it]Loading train:  86%|████████▌ | 245/285 [04:55<00:44,  1.12s/it]Loading train:  86%|████████▋ | 246/285 [04:56<00:48,  1.24s/it]Loading train:  87%|████████▋ | 247/285 [04:58<00:48,  1.28s/it]Loading train:  87%|████████▋ | 248/285 [04:59<00:46,  1.27s/it]Loading train:  87%|████████▋ | 249/285 [05:00<00:45,  1.26s/it]Loading train:  88%|████████▊ | 250/285 [05:02<00:45,  1.31s/it]Loading train:  88%|████████▊ | 251/285 [05:03<00:42,  1.25s/it]Loading train:  88%|████████▊ | 252/285 [05:04<00:42,  1.28s/it]Loading train:  89%|████████▉ | 253/285 [05:05<00:41,  1.28s/it]Loading train:  89%|████████▉ | 254/285 [05:07<00:40,  1.31s/it]Loading train:  89%|████████▉ | 255/285 [05:08<00:39,  1.31s/it]Loading train:  90%|████████▉ | 256/285 [05:09<00:34,  1.20s/it]Loading train:  90%|█████████ | 257/285 [05:10<00:33,  1.18s/it]Loading train:  91%|█████████ | 258/285 [05:12<00:33,  1.23s/it]Loading train:  91%|█████████ | 259/285 [05:13<00:35,  1.37s/it]Loading train:  91%|█████████ | 260/285 [05:14<00:32,  1.30s/it]Loading train:  92%|█████████▏| 261/285 [05:15<00:28,  1.20s/it]Loading train:  92%|█████████▏| 262/285 [05:16<00:25,  1.09s/it]Loading train:  92%|█████████▏| 263/285 [05:17<00:24,  1.09s/it]Loading train:  93%|█████████▎| 264/285 [05:19<00:24,  1.15s/it]Loading train:  93%|█████████▎| 265/285 [05:20<00:25,  1.29s/it]Loading train:  93%|█████████▎| 266/285 [05:21<00:24,  1.28s/it]Loading train:  94%|█████████▎| 267/285 [05:23<00:22,  1.23s/it]Loading train:  94%|█████████▍| 268/285 [05:24<00:21,  1.26s/it]Loading train:  94%|█████████▍| 269/285 [05:25<00:19,  1.23s/it]Loading train:  95%|█████████▍| 270/285 [05:26<00:17,  1.19s/it]Loading train:  95%|█████████▌| 271/285 [05:27<00:15,  1.12s/it]Loading train:  95%|█████████▌| 272/285 [05:29<00:16,  1.24s/it]Loading train:  96%|█████████▌| 273/285 [05:30<00:14,  1.18s/it]Loading train:  96%|█████████▌| 274/285 [05:31<00:12,  1.14s/it]Loading train:  96%|█████████▋| 275/285 [05:32<00:12,  1.24s/it]Loading train:  97%|█████████▋| 276/285 [05:34<00:11,  1.33s/it]Loading train:  97%|█████████▋| 277/285 [05:35<00:10,  1.28s/it]Loading train:  98%|█████████▊| 278/285 [05:36<00:08,  1.27s/it]Loading train:  98%|█████████▊| 279/285 [05:37<00:07,  1.24s/it]Loading train:  98%|█████████▊| 280/285 [05:38<00:05,  1.15s/it]Loading train:  99%|█████████▊| 281/285 [05:39<00:04,  1.13s/it]Loading train:  99%|█████████▉| 282/285 [05:40<00:03,  1.11s/it]Loading train:  99%|█████████▉| 283/285 [05:42<00:02,  1.15s/it]Loading train: 100%|█████████▉| 284/285 [05:43<00:01,  1.21s/it]Loading train: 100%|██████████| 285/285 [05:44<00:00,  1.29s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 45.02it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:05, 46.41it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:05, 49.02it/s]concatenating: train:   8%|▊         | 23/285 [00:00<00:05, 50.31it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:04, 53.43it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:04, 55.87it/s]concatenating: train:  15%|█▌        | 43/285 [00:00<00:05, 41.10it/s]concatenating: train:  17%|█▋        | 48/285 [00:01<00:05, 42.97it/s]concatenating: train:  19%|█▉        | 55/285 [00:01<00:04, 47.81it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:04, 51.43it/s]concatenating: train:  24%|██▍       | 69/285 [00:01<00:03, 54.32it/s]concatenating: train:  27%|██▋       | 76/285 [00:01<00:03, 56.54it/s]concatenating: train:  29%|██▉       | 83/285 [00:01<00:03, 58.20it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:03, 59.43it/s]concatenating: train:  34%|███▍      | 97/285 [00:01<00:03, 60.32it/s]concatenating: train:  36%|███▋      | 104/285 [00:01<00:02, 60.96it/s]concatenating: train:  39%|███▉      | 111/285 [00:02<00:02, 60.77it/s]concatenating: train:  42%|████▏     | 119/285 [00:02<00:02, 64.23it/s]concatenating: train:  44%|████▍     | 126/285 [00:02<00:02, 63.70it/s]concatenating: train:  47%|████▋     | 133/285 [00:02<00:02, 56.58it/s]concatenating: train:  49%|████▉     | 139/285 [00:02<00:02, 51.62it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 52.74it/s]concatenating: train:  53%|█████▎    | 152/285 [00:02<00:02, 55.86it/s]concatenating: train:  55%|█████▌    | 158/285 [00:02<00:02, 55.77it/s]concatenating: train:  58%|█████▊    | 165/285 [00:02<00:02, 57.63it/s]concatenating: train:  60%|██████    | 172/285 [00:03<00:01, 59.01it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:01, 58.61it/s]concatenating: train:  65%|██████▍   | 184/285 [00:03<00:01, 53.35it/s]concatenating: train:  67%|██████▋   | 190/285 [00:03<00:01, 51.23it/s]concatenating: train:  69%|██████▉   | 196/285 [00:03<00:02, 44.12it/s]concatenating: train:  73%|███████▎  | 207/285 [00:03<00:01, 53.75it/s]concatenating: train:  77%|███████▋  | 220/285 [00:03<00:01, 64.83it/s]concatenating: train:  80%|████████  | 229/285 [00:03<00:00, 70.19it/s]concatenating: train:  84%|████████▎ | 238/285 [00:04<00:00, 67.69it/s]concatenating: train:  87%|████████▋ | 248/285 [00:04<00:00, 74.21it/s]concatenating: train:  91%|█████████ | 258/285 [00:04<00:00, 79.68it/s]concatenating: train:  95%|█████████▍| 270/285 [00:04<00:00, 87.14it/s]concatenating: train:  98%|█████████▊| 280/285 [00:04<00:00, 71.26it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 60.50it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.47s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.49s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.48s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 43.25it/s]2019-07-11 03:05:38.288424: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:05:38.288530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:05:38.288545: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:05:38.288553: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:05:38.288954: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.80it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.41it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.87it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.34it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.88it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.59it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.23it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.85it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.48it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.24it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.89it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.84it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.66it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.47it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.11it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.49it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.81it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.00it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.13it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 10)   5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 70)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 232,303
Trainable params: 57,563
Non-trainable params: 174,740
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 18s - loss: 2.8937 - acc: 0.5435 - mDice: 0.1061 - val_loss: 2.1166 - val_acc: 0.8944 - val_mDice: 0.2121

Epoch 00001: val_mDice improved from -inf to 0.21214, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.9914 - acc: 0.8851 - mDice: 0.3652 - val_loss: 1.2276 - val_acc: 0.9042 - val_mDice: 0.3825

Epoch 00002: val_mDice improved from 0.21214 to 0.38254, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.7250 - acc: 0.8959 - mDice: 0.4708 - val_loss: 1.0569 - val_acc: 0.9144 - val_mDice: 0.4456

Epoch 00003: val_mDice improved from 0.38254 to 0.44564, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.6164 - acc: 0.9063 - mDice: 0.5251 - val_loss: 0.9233 - val_acc: 0.9338 - val_mDice: 0.5046

Epoch 00004: val_mDice improved from 0.44564 to 0.50459, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5518 - acc: 0.9159 - mDice: 0.5611 - val_loss: 0.8341 - val_acc: 0.9370 - val_mDice: 0.5376

Epoch 00005: val_mDice improved from 0.50459 to 0.53756, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.5105 - acc: 0.9239 - mDice: 0.5854 - val_loss: 0.8282 - val_acc: 0.9318 - val_mDice: 0.5211

Epoch 00006: val_mDice did not improve from 0.53756
Epoch 7/300
 - 12s - loss: 0.4796 - acc: 0.9295 - mDice: 0.6044 - val_loss: 0.8839 - val_acc: 0.9218 - val_mDice: 0.5225

Epoch 00007: val_mDice did not improve from 0.53756
Epoch 8/300
 - 13s - loss: 0.4600 - acc: 0.9323 - mDice: 0.6165 - val_loss: 0.8586 - val_acc: 0.9362 - val_mDice: 0.5358

Epoch 00008: val_mDice did not improve from 0.53756
Epoch 9/300
 - 12s - loss: 0.4409 - acc: 0.9344 - mDice: 0.6285 - val_loss: 0.8451 - val_acc: 0.9384 - val_mDice: 0.5525

Epoch 00009: val_mDice improved from 0.53756 to 0.55245, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4275 - acc: 0.9358 - mDice: 0.6373 - val_loss: 0.8556 - val_acc: 0.9359 - val_mDice: 0.5581

Epoch 00010: val_mDice improved from 0.55245 to 0.55811, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 12s - loss: 0.4164 - acc: 0.9367 - mDice: 0.6445 - val_loss: 0.8845 - val_acc: 0.9361 - val_mDice: 0.5497

Epoch 00011: val_mDice did not improve from 0.55811
Epoch 12/300
 - 12s - loss: 0.4076 - acc: 0.9376 - mDice: 0.6505 - val_loss: 0.8507 - val_acc: 0.9371 - val_mDice: 0.5550

Epoch 00012: val_mDice did not improve from 0.55811
Epoch 13/300
 - 12s - loss: 0.4016 - acc: 0.9381 - mDice: 0.6545 - val_loss: 0.8486 - val_acc: 0.9372 - val_mDice: 0.5605

Epoch 00013: val_mDice improved from 0.55811 to 0.56049, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 0.3912 - acc: 0.9391 - mDice: 0.6615 - val_loss: 0.8322 - val_acc: 0.9352 - val_mDice: 0.5580

Epoch 00014: val_mDice did not improve from 0.56049
Epoch 15/300
 - 12s - loss: 0.3871 - acc: 0.9393 - mDice: 0.6644 - val_loss: 0.8348 - val_acc: 0.9382 - val_mDice: 0.5622

Epoch 00015: val_mDice improved from 0.56049 to 0.56217, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 12s - loss: 0.3798 - acc: 0.9400 - mDice: 0.6692 - val_loss: 0.8339 - val_acc: 0.9395 - val_mDice: 0.5573

Epoch 00016: val_mDice did not improve from 0.56217
Epoch 17/300
 - 13s - loss: 0.3764 - acc: 0.9404 - mDice: 0.6716 - val_loss: 0.8375 - val_acc: 0.9395 - val_mDice: 0.5545

Epoch 00017: val_mDice did not improve from 0.56217
Epoch 18/300
 - 12s - loss: 0.3713 - acc: 0.9408 - mDice: 0.6753 - val_loss: 0.8247 - val_acc: 0.9349 - val_mDice: 0.5596

Epoch 00018: val_mDice did not improve from 0.56217
Epoch 19/300
 - 13s - loss: 0.3654 - acc: 0.9412 - mDice: 0.6793 - val_loss: 0.8385 - val_acc: 0.9369 - val_mDice: 0.5628

Epoch 00019: val_mDice improved from 0.56217 to 0.56283, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 12s - loss: 0.3613 - acc: 0.9415 - mDice: 0.6823 - val_loss: 0.8340 - val_acc: 0.9386 - val_mDice: 0.5569

Epoch 00020: val_mDice did not improve from 0.56283
Epoch 21/300
 - 13s - loss: 0.3593 - acc: 0.9419 - mDice: 0.6837 - val_loss: 0.8216 - val_acc: 0.9405 - val_mDice: 0.5666

Epoch 00021: val_mDice improved from 0.56283 to 0.56659, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 13s - loss: 0.3535 - acc: 0.9421 - mDice: 0.6878 - val_loss: 0.8059 - val_acc: 0.9363 - val_mDice: 0.5658

Epoch 00022: val_mDice did not improve from 0.56659
Epoch 23/300
 - 12s - loss: 0.3512 - acc: 0.9422 - mDice: 0.6893 - val_loss: 0.8078 - val_acc: 0.9368 - val_mDice: 0.5647

Epoch 00023: val_mDice did not improve from 0.56659
Epoch 24/300
 - 13s - loss: 0.3482 - acc: 0.9427 - mDice: 0.6916 - val_loss: 0.8048 - val_acc: 0.9388 - val_mDice: 0.5640

Epoch 00024: val_mDice did not improve from 0.56659
Epoch 25/300
 - 12s - loss: 0.3440 - acc: 0.9430 - mDice: 0.6945 - val_loss: 0.7937 - val_acc: 0.9402 - val_mDice: 0.5736

Epoch 00025: val_mDice improved from 0.56659 to 0.57361, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 13s - loss: 0.3415 - acc: 0.9432 - mDice: 0.6964 - val_loss: 0.8358 - val_acc: 0.9385 - val_mDice: 0.5550

Epoch 00026: val_mDice did not improve from 0.57361
Epoch 27/300
 - 12s - loss: 0.3382 - acc: 0.9434 - mDice: 0.6987 - val_loss: 0.8025 - val_acc: 0.9392 - val_mDice: 0.5756

Epoch 00027: val_mDice improved from 0.57361 to 0.57555, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 28/300
 - 13s - loss: 0.3362 - acc: 0.9436 - mDice: 0.7002 - val_loss: 0.7917 - val_acc: 0.9395 - val_mDice: 0.5716

Epoch 00028: val_mDice did not improve from 0.57555
Epoch 29/300
 - 11s - loss: 0.3338 - acc: 0.9438 - mDice: 0.7020 - val_loss: 0.8274 - val_acc: 0.9396 - val_mDice: 0.5710

Epoch 00029: val_mDice did not improve from 0.57555
Epoch 30/300
 - 11s - loss: 0.3335 - acc: 0.9438 - mDice: 0.7022 - val_loss: 0.7986 - val_acc: 0.9398 - val_mDice: 0.5679

Epoch 00030: val_mDice did not improve from 0.57555
Epoch 31/300
 - 11s - loss: 0.3295 - acc: 0.9441 - mDice: 0.7050 - val_loss: 0.7999 - val_acc: 0.9407 - val_mDice: 0.5713

Epoch 00031: val_mDice did not improve from 0.57555
Epoch 32/300
 - 11s - loss: 0.3276 - acc: 0.9442 - mDice: 0.7064 - val_loss: 0.8350 - val_acc: 0.9399 - val_mDice: 0.5555

Epoch 00032: val_mDice did not improve from 0.57555
Epoch 33/300
 - 11s - loss: 0.3243 - acc: 0.9445 - mDice: 0.7090 - val_loss: 0.8153 - val_acc: 0.9363 - val_mDice: 0.5601

Epoch 00033: val_mDice did not improve from 0.57555
Epoch 34/300
 - 11s - loss: 0.3228 - acc: 0.9446 - mDice: 0.7100 - val_loss: 0.8276 - val_acc: 0.9391 - val_mDice: 0.5556

Epoch 00034: val_mDice did not improve from 0.57555
Epoch 35/300
 - 11s - loss: 0.3194 - acc: 0.9450 - mDice: 0.7124 - val_loss: 0.7840 - val_acc: 0.9383 - val_mDice: 0.5613

Epoch 00035: val_mDice did not improve from 0.57555
Epoch 36/300
 - 11s - loss: 0.3194 - acc: 0.9449 - mDice: 0.7124 - val_loss: 0.8193 - val_acc: 0.9363 - val_mDice: 0.5622

Epoch 00036: val_mDice did not improve from 0.57555
Epoch 37/300
 - 11s - loss: 0.3177 - acc: 0.9451 - mDice: 0.7137 - val_loss: 0.8199 - val_acc: 0.9359 - val_mDice: 0.5646

Epoch 00037: val_mDice did not improve from 0.57555
Epoch 38/300
 - 11s - loss: 0.3176 - acc: 0.9451 - mDice: 0.7139 - val_loss: 0.8068 - val_acc: 0.9382 - val_mDice: 0.5750

Epoch 00038: val_mDice did not improve from 0.57555
Epoch 39/300
 - 11s - loss: 0.3142 - acc: 0.9453 - mDice: 0.7163 - val_loss: 0.8063 - val_acc: 0.9401 - val_mDice: 0.5758

Epoch 00039: val_mDice improved from 0.57555 to 0.57578, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 40/300
 - 11s - loss: 0.3127 - acc: 0.9455 - mDice: 0.7174 - val_loss: 0.7860 - val_acc: 0.9413 - val_mDice: 0.5828

Epoch 00040: val_mDice improved from 0.57578 to 0.58282, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 11s - loss: 0.3101 - acc: 0.9457 - mDice: 0.7193 - val_loss: 0.8090 - val_acc: 0.9390 - val_mDice: 0.5717

Epoch 00041: val_mDice did not improve from 0.58282
Epoch 42/300
 - 11s - loss: 0.3106 - acc: 0.9458 - mDice: 0.7190 - val_loss: 0.7867 - val_acc: 0.9418 - val_mDice: 0.5719

Epoch 00042: val_mDice did not improve from 0.58282
Epoch 43/300
 - 11s - loss: 0.3084 - acc: 0.9458 - mDice: 0.7207 - val_loss: 0.8239 - val_acc: 0.9403 - val_mDice: 0.5689

Epoch 00043: val_mDice did not improve from 0.58282
Epoch 44/300
 - 11s - loss: 0.3085 - acc: 0.9458 - mDice: 0.7206 - val_loss: 0.7739 - val_acc: 0.9426 - val_mDice: 0.5704

Epoch 00044: val_mDice did not improve from 0.58282
Epoch 45/300
 - 11s - loss: 0.3063 - acc: 0.9461 - mDice: 0.7222 - val_loss: 0.7600 - val_acc: 0.9390 - val_mDice: 0.5830

Epoch 00045: val_mDice improved from 0.58282 to 0.58299, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 11s - loss: 0.3056 - acc: 0.9461 - mDice: 0.7227 - val_loss: 0.7894 - val_acc: 0.9412 - val_mDice: 0.5744

Epoch 00046: val_mDice did not improve from 0.58299
Epoch 47/300
 - 11s - loss: 0.3038 - acc: 0.9462 - mDice: 0.7241 - val_loss: 0.7932 - val_acc: 0.9402 - val_mDice: 0.5730

Epoch 00047: val_mDice did not improve from 0.58299
Epoch 48/300
 - 11s - loss: 0.3022 - acc: 0.9465 - mDice: 0.7254 - val_loss: 0.7815 - val_acc: 0.9405 - val_mDice: 0.5768

Epoch 00048: val_mDice did not improve from 0.58299
Epoch 49/300
 - 11s - loss: 0.2996 - acc: 0.9466 - mDice: 0.7273 - val_loss: 0.7577 - val_acc: 0.9412 - val_mDice: 0.5785

Epoch 00049: val_mDice did not improve from 0.58299
Epoch 50/300
 - 11s - loss: 0.3009 - acc: 0.9464 - mDice: 0.7264 - val_loss: 0.7893 - val_acc: 0.9412 - val_mDice: 0.5626

Epoch 00050: val_mDice did not improve from 0.58299
Epoch 51/300
 - 11s - loss: 0.2992 - acc: 0.9467 - mDice: 0.7276 - val_loss: 0.7882 - val_acc: 0.9387 - val_mDice: 0.5733

Epoch 00051: val_mDice did not improve from 0.58299
Epoch 52/300
 - 11s - loss: 0.2966 - acc: 0.9468 - mDice: 0.7295 - val_loss: 0.7474 - val_acc: 0.9383 - val_mDice: 0.5730

Epoch 00052: val_mDice did not improve from 0.58299
Epoch 53/300
 - 11s - loss: 0.2960 - acc: 0.9468 - mDice: 0.7300 - val_loss: 0.7556 - val_acc: 0.9406 - val_mDice: 0.5733

Epoch 00053: val_mDice did not improve from 0.58299
Epoch 54/300
 - 11s - loss: 0.2957 - acc: 0.9470 - mDice: 0.7303 - val_loss: 0.7344 - val_acc: 0.9407 - val_mDice: 0.5766

Epoch 00054: val_mDice did not improve from 0.58299
Epoch 55/300
 - 11s - loss: 0.2946 - acc: 0.9469 - mDice: 0.7311 - val_loss: 0.7439 - val_acc: 0.9412 - val_mDice: 0.5787

Epoch 00055: val_mDice did not improve from 0.58299
Epoch 56/300
 - 11s - loss: 0.2932 - acc: 0.9470 - mDice: 0.7320 - val_loss: 0.7522 - val_acc: 0.9421 - val_mDice: 0.5690

Epoch 00056: val_mDice did not improve from 0.58299
Epoch 57/300
 - 11s - loss: 0.2936 - acc: 0.9472 - mDice: 0.7319 - val_loss: 0.7703 - val_acc: 0.9400 - val_mDice: 0.5771

Epoch 00057: val_mDice did not improve from 0.58299
Epoch 58/300
 - 11s - loss: 0.2914 - acc: 0.9473 - mDice: 0.7335 - val_loss: 0.7202 - val_acc: 0.9423 - val_mDice: 0.5756

Epoch 00058: val_mDice did not improve from 0.58299
Epoch 59/300
 - 11s - loss: 0.2906 - acc: 0.9473 - mDice: 0.7341 - val_loss: 0.7350 - val_acc: 0.9433 - val_mDice: 0.5707

Epoch 00059: val_mDice did not improve from 0.58299
Epoch 60/300
 - 11s - loss: 0.2894 - acc: 0.9475 - mDice: 0.7350 - val_loss: 0.7406 - val_acc: 0.9421 - val_mDice: 0.5728

Epoch 00060: val_mDice did not improve from 0.58299
Epoch 61/300
 - 11s - loss: 0.2880 - acc: 0.9476 - mDice: 0.7361 - val_loss: 0.7167 - val_acc: 0.9401 - val_mDice: 0.5755

Epoch 00061: val_mDice did not improve from 0.58299
Epoch 62/300
 - 11s - loss: 0.2873 - acc: 0.9476 - mDice: 0.7367 - val_loss: 0.7453 - val_acc: 0.9403 - val_mDice: 0.5742

Epoch 00062: val_mDice did not improve from 0.58299
Epoch 63/300
 - 11s - loss: 0.2878 - acc: 0.9476 - mDice: 0.7364 - val_loss: 0.7051 - val_acc: 0.9393 - val_mDice: 0.5754

Epoch 00063: val_mDice did not improve from 0.58299
Epoch 64/300
 - 11s - loss: 0.2855 - acc: 0.9478 - mDice: 0.7380 - val_loss: 0.7260 - val_acc: 0.9409 - val_mDice: 0.5704

Epoch 00064: val_mDice did not improve from 0.58299
Epoch 65/300
 - 11s - loss: 0.2847 - acc: 0.9478 - mDice: 0.7386 - val_loss: 0.7501 - val_acc: 0.9390 - val_mDice: 0.5737

Epoch 00065: val_mDice did not improve from 0.58299
Epoch 66/300
 - 11s - loss: 0.2847 - acc: 0.9479 - mDice: 0.7386 - val_loss: 0.7329 - val_acc: 0.9409 - val_mDice: 0.5790

Epoch 00066: val_mDice did not improve from 0.58299
Epoch 67/300
 - 11s - loss: 0.2838 - acc: 0.9479 - mDice: 0.7393 - val_loss: 0.7249 - val_acc: 0.9406 - val_mDice: 0.5759

Epoch 00067: val_mDice did not improve from 0.58299
Epoch 68/300
 - 11s - loss: 0.2839 - acc: 0.9479 - mDice: 0.7392 - val_loss: 0.7093 - val_acc: 0.9406 - val_mDice: 0.5730

Epoch 00068: val_mDice did not improve from 0.58299
Epoch 69/300
 - 11s - loss: 0.2824 - acc: 0.9480 - mDice: 0.7403 - val_loss: 0.7406 - val_acc: 0.9432 - val_mDice: 0.5728

Epoch 00069: val_mDice did not improve from 0.58299
Epoch 70/300
 - 11s - loss: 0.2817 - acc: 0.9482 - mDice: 0.7410 - val_loss: 0.6919 - val_acc: 0.9426 - val_mDice: 0.5768

Epoch 00070: val_mDice did not improve from 0.58299
Epoch 71/300
 - 11s - loss: 0.2813 - acc: 0.9481 - mDice: 0.7412 - val_loss: 0.7325 - val_acc: 0.9417 - val_mDice: 0.5706

Epoch 00071: val_mDice did not improve from 0.58299
Epoch 72/300
 - 11s - loss: 0.2798 - acc: 0.9482 - mDice: 0.7424 - val_loss: 0.7318 - val_acc: 0.9353 - val_mDice: 0.5742

Epoch 00072: val_mDice did not improve from 0.58299
Epoch 73/300
 - 11s - loss: 0.2814 - acc: 0.9481 - mDice: 0.7411 - val_loss: 0.6921 - val_acc: 0.9425 - val_mDice: 0.5708

Epoch 00073: val_mDice did not improve from 0.58299
Epoch 74/300
 - 11s - loss: 0.2780 - acc: 0.9483 - mDice: 0.7436 - val_loss: 0.7216 - val_acc: 0.9409 - val_mDice: 0.5780

Epoch 00074: val_mDice did not improve from 0.58299
Epoch 75/300
 - 11s - loss: 0.2789 - acc: 0.9484 - mDice: 0.7431 - val_loss: 0.6970 - val_acc: 0.9390 - val_mDice: 0.5704

Epoch 00075: val_mDice did not improve from 0.58299
Epoch 76/300
 - 11s - loss: 0.2781 - acc: 0.9483 - mDice: 0.7438 - val_loss: 0.7056 - val_acc: 0.9419 - val_mDice: 0.5787

Epoch 00076: val_mDice did not improve from 0.58299
Epoch 77/300
 - 11s - loss: 0.2788 - acc: 0.9484 - mDice: 0.7432 - val_loss: 0.7358 - val_acc: 0.9413 - val_mDice: 0.5731

Epoch 00077: val_mDice did not improve from 0.58299
Epoch 78/300
 - 11s - loss: 0.2778 - acc: 0.9484 - mDice: 0.7440 - val_loss: 0.7113 - val_acc: 0.9400 - val_mDice: 0.5780

Epoch 00078: val_mDice did not improve from 0.58299
Epoch 79/300
 - 11s - loss: 0.2774 - acc: 0.9484 - mDice: 0.7442 - val_loss: 0.7102 - val_acc: 0.9425 - val_mDice: 0.5743

Epoch 00079: val_mDice did not improve from 0.58299
Epoch 80/300
 - 11s - loss: 0.2747 - acc: 0.9486 - mDice: 0.7464 - val_loss: 0.6741 - val_acc: 0.9409 - val_mDice: 0.5800

Epoch 00080: val_mDice did not improve from 0.58299
Epoch 81/300
 - 11s - loss: 0.2746 - acc: 0.9487 - mDice: 0.7464 - val_loss: 0.7047 - val_acc: 0.9426 - val_mDice: 0.5705

Epoch 00081: val_mDice did not improve from 0.58299
Epoch 82/300
 - 11s - loss: 0.2745 - acc: 0.9487 - mDice: 0.7466 - val_loss: 0.7042 - val_acc: 0.9377 - val_mDice: 0.5644

Epoch 00082: val_mDice did not improve from 0.58299
Epoch 83/300
 - 11s - loss: 0.2740 - acc: 0.9487 - mDice: 0.7469 - val_loss: 0.7044 - val_acc: 0.9401 - val_mDice: 0.5738

Epoch 00083: val_mDice did not improve from 0.58299
Epoch 84/300
 - 11s - loss: 0.2732 - acc: 0.9487 - mDice: 0.7475 - val_loss: 0.7130 - val_acc: 0.9404 - val_mDice: 0.5751

Epoch 00084: val_mDice did not improve from 0.58299
Epoch 85/300
 - 11s - loss: 0.2729 - acc: 0.9488 - mDice: 0.7477 - val_loss: 0.6841 - val_acc: 0.9405 - val_mDice: 0.5715

Epoch 00085: val_mDice did not improve from 0.58299
Restoring model weights from the end of the best epoch
Epoch 00085: early stopping
{'val_loss': [2.1165639483011685, 1.227605253458023, 1.0568826702924876, 0.9233230191927689, 0.8341299249575689, 0.828165726019786, 0.8839181615756109, 0.858645634009288, 0.8450820514788995, 0.8555753231048584, 0.8844863818241999, 0.8506985696462485, 0.8486033448806176, 0.8322079961116498, 0.8348337503579947, 0.8339218978698437, 0.8375009688047262, 0.8247124163004068, 0.838501343360314, 0.833981066942215, 0.8216359523626474, 0.8058573924578153, 0.807773986688027, 0.804815228168781, 0.7937354605931503, 0.835797383235051, 0.8025154402622809, 0.7917222586961893, 0.8274023578717158, 0.7986183235278497, 0.799910538471662, 0.8349738740004026, 0.8152630650080167, 0.8276056739000174, 0.7840024187014654, 0.8193034850634061, 0.8198915926309732, 0.8068176702811167, 0.8063479730716119, 0.7860073240903708, 0.8089600939017075, 0.786746974174793, 0.8239290324541239, 0.7739224204650292, 0.760048991212478, 0.7893645717547491, 0.7932425462282621, 0.7815057004873569, 0.7576710134744644, 0.7893045911422143, 0.7882444698076981, 0.7473931175011855, 0.7556121532733624, 0.7344392950718219, 0.7438691476216683, 0.7522009381881127, 0.770291561117539, 0.720195703781568, 0.7349965618206904, 0.7406141391167274, 0.7166931124833914, 0.7452983902050898, 0.7050682375064263, 0.7260123262038598, 0.7501139021836795, 0.7329410692820182, 0.724860471028548, 0.709302883881789, 0.7406251499286065, 0.6918538487874545, 0.7325492203235626, 0.7318379374650809, 0.6921072923220121, 0.7216441619854707, 0.6969556304124686, 0.7056291263837081, 0.7357544532189002, 0.7113193674729421, 0.7101675271987915, 0.6741153059097437, 0.7046602918551519, 0.7042353405402257, 0.7044395208358765, 0.7130261315749242, 0.6841373925025647], 'val_acc': [0.8943856564851907, 0.9041882684597602, 0.9143583637017471, 0.9337833065253037, 0.9370007125230936, 0.9317700335612664, 0.9217709600925446, 0.9361547621396872, 0.938401460647583, 0.9358981893612788, 0.9360692455218389, 0.9371093809604645, 0.9371625643510085, 0.9351793711002057, 0.9382396500844222, 0.9394808663771703, 0.939545560341615, 0.934862726009809, 0.9368597658780905, 0.9386002237980182, 0.9404863440073453, 0.936323493719101, 0.9368088703889114, 0.9388035994309646, 0.9401765717909887, 0.9385424508498266, 0.939221964432643, 0.9395155356480525, 0.9396241513582376, 0.9397859527514532, 0.9406573887054737, 0.9399154209173642, 0.9363234822566693, 0.9391064277062049, 0.9382627377143273, 0.93632350059656, 0.9358912660525396, 0.938198066674746, 0.9400517711272607, 0.9412837739174182, 0.9390047123798957, 0.9417784099395459, 0.9402875556395605, 0.9425619496748998, 0.9389677093579218, 0.9411935806274414, 0.9401719776483682, 0.9404978522887597, 0.9411520132651696, 0.9411542828266437, 0.9387458425301772, 0.9382881774352148, 0.9405810832977295, 0.9406619759706351, 0.9411774438161117, 0.9421320213721349, 0.9400124595715449, 0.942275352202929, 0.9433362392278818, 0.9420811831951141, 0.9401095830477201, 0.9402759785835559, 0.9392890127805563, 0.9409069671080663, 0.9389769687102392, 0.9408630866270798, 0.9405695497989655, 0.9406065138486716, 0.9432438199336712, 0.942610495365583, 0.9417483325187976, 0.9353388272798978, 0.9425341945428115, 0.9409393530625564, 0.9390463278843806, 0.9419216834581815, 0.9412768299763019, 0.9399754955218389, 0.9424833655357361, 0.9408815846993372, 0.9426497771189764, 0.9377034123127277, 0.9400933889242319, 0.940447041621575, 0.9404863394223727], 'val_mDice': [0.21214233023615983, 0.38253598001140815, 0.4456398461300593, 0.5045925854490354, 0.5375576053674405, 0.5211425526784017, 0.5224923560252557, 0.5358346884067242, 0.5524528955037777, 0.5581130884014643, 0.5497038490497149, 0.5550400167703629, 0.5604899749159813, 0.5579907641961024, 0.5621706579740231, 0.5573058936458367, 0.554473394384751, 0.5595788245017712, 0.5628283614149461, 0.5569175063417509, 0.5665914806035849, 0.5658330063407238, 0.56466872130449, 0.5640360678617771, 0.5736143749493819, 0.5550324550041785, 0.5755530698941305, 0.5715604178034343, 0.570994000022228, 0.5679240719630168, 0.57128545240714, 0.5555144995450974, 0.560050813624492, 0.5556011606867497, 0.5612663345841261, 0.5622401839265456, 0.5645523002514472, 0.5749665309603398, 0.57577761893089, 0.5828218546051246, 0.5717233637204537, 0.5719497702442683, 0.5689324111892626, 0.5704145047527093, 0.5829946020474801, 0.5743841311106315, 0.5729535124622859, 0.5767997961777908, 0.5785356622475845, 0.5626311600208282, 0.5733474848362116, 0.573013193332232, 0.5733473507257608, 0.576565829034035, 0.5787175859396274, 0.5690335860619178, 0.5770995055253689, 0.5755741836932989, 0.5707191016811591, 0.5728260685618107, 0.5754833771632268, 0.5741859754690757, 0.5753726672667724, 0.5704497975798754, 0.5736916007903906, 0.5789719378718963, 0.5759289866456618, 0.5730340813214962, 0.5727680245271096, 0.5768423601984978, 0.5705748223341428, 0.5742165572368182, 0.5707850886078981, 0.5780308011632699, 0.5704249086288306, 0.5786653636739805, 0.5731293238126315, 0.5780347367891898, 0.5743284408862774, 0.5800210839280715, 0.5704902175527352, 0.5643757639022974, 0.5737662246594062, 0.57514966909702, 0.5714799366318263], 'loss': [2.8937076575353906, 0.9913748882578317, 0.7249603312712342, 0.616400546460511, 0.5518330705844201, 0.5104651199730188, 0.4795782986265987, 0.46004588955455544, 0.44094364168480576, 0.4275208446335927, 0.4163616834163534, 0.40755026204212447, 0.40155044503123144, 0.3912268528845503, 0.3870957512252172, 0.3798348197558374, 0.37635902502347013, 0.37130357113027884, 0.36535370790748417, 0.361277142145378, 0.3593109057561548, 0.3534511291352979, 0.35119396208463466, 0.3482210600050703, 0.344044196688688, 0.3415371391409978, 0.338235313702386, 0.33615859319701313, 0.33376389744920965, 0.33349422289086567, 0.32954075518299114, 0.32759598352411495, 0.32425639687742813, 0.3227891429487788, 0.31940291925163977, 0.31943651797157324, 0.3177256525293945, 0.31756880813162564, 0.3141574129939112, 0.3127104768665758, 0.31013546392485125, 0.31064369094599376, 0.3083746117836631, 0.3084707555269102, 0.30626721827623027, 0.3055817000482021, 0.30380030002891273, 0.3021918832293782, 0.29959423212968567, 0.30087258229393765, 0.29922285674628235, 0.2965548864993444, 0.295975651334685, 0.29567220556959173, 0.29462923761620397, 0.2932382645443622, 0.29360479520473887, 0.29141805075603056, 0.2905899001632264, 0.289409102081296, 0.28798069384862585, 0.287254199851519, 0.2877536171544448, 0.2855352792426096, 0.2846578727219912, 0.28471847251916543, 0.2837802693708174, 0.2839490736277354, 0.2824006125840777, 0.2816996953781599, 0.2813019504007747, 0.2797553614833242, 0.2813622969812785, 0.27803149385930737, 0.2788867012090946, 0.2780609844075702, 0.2787674640906667, 0.27775336986294774, 0.2774273959951934, 0.2747235733908854, 0.2745940699976858, 0.27445807416182016, 0.27402910691317756, 0.27318998064423555, 0.2729425727166692], 'acc': [0.5434695776339982, 0.8851046900374087, 0.895900557756446, 0.9062651198892964, 0.9158709727947116, 0.9238534338863685, 0.9294963676716408, 0.9322958963994532, 0.9343747346590093, 0.9357618386758866, 0.9366605277762008, 0.9375663538112374, 0.9380835248878012, 0.9390549285379072, 0.9393338654288218, 0.9400109024952887, 0.9404242992137264, 0.9407827372943675, 0.941224773767018, 0.9415371256000846, 0.9418900407494121, 0.9421161907103782, 0.9422450847734795, 0.9426572615399106, 0.942975042370493, 0.9431596451070403, 0.9434181871333268, 0.9435976046285847, 0.9437825417624159, 0.9437674251768539, 0.9441039592624095, 0.94421201334727, 0.9445123866366734, 0.9445645573459559, 0.9449504377557641, 0.9448532233607183, 0.9450691102736882, 0.945123473040943, 0.9452923563566087, 0.9455419619189168, 0.9457029178388157, 0.945766477163544, 0.9458441348035408, 0.9458276662925046, 0.9460775813119258, 0.9461007700309008, 0.9462380900293283, 0.9464731085710526, 0.9465708558513023, 0.9464324082570093, 0.9467191279654594, 0.9468466447671269, 0.9468440969063107, 0.9469611954504324, 0.9468823156156279, 0.9469673817507138, 0.9471701886022178, 0.9473273270268464, 0.9473346170767376, 0.947480050244147, 0.9476087688245336, 0.947642999085445, 0.9475783503474449, 0.9477878752795245, 0.9477923980643583, 0.9479290309190245, 0.9479213154679854, 0.9479007178057409, 0.9480428726462259, 0.9481861523395423, 0.9481097573197482, 0.9481934912473219, 0.9480785860639761, 0.9483141158819528, 0.9483735766906003, 0.9483025854148186, 0.9483851665040174, 0.9484334091995955, 0.9483593179160881, 0.9486420475325109, 0.9487037263177786, 0.9487008397554786, 0.9487088437033329, 0.9487038520960573, 0.9487764858500297], 'mDice': [0.10605920484576577, 0.3651671243843025, 0.47080960630392066, 0.5251123363061616, 0.561116487274286, 0.585425082139618, 0.6044132853086437, 0.6164776629807049, 0.6284755407186229, 0.6372882396678121, 0.644540740205036, 0.650496617483167, 0.6545450555533927, 0.6614815910441029, 0.6643706956583009, 0.6692069556169334, 0.6716144252315962, 0.6752533289621668, 0.6793133314164002, 0.6823131532496679, 0.6837424682996969, 0.6878027871648269, 0.6893083349613756, 0.6916018065673601, 0.6945166823433673, 0.6963541725899344, 0.6986824913426408, 0.7002356538558857, 0.7020282713753221, 0.7021693245880632, 0.7049565417052173, 0.706367638172022, 0.7089701112231612, 0.7099612052948792, 0.7123873561255157, 0.712436018956056, 0.7136967676785075, 0.7139233195186926, 0.716322484848014, 0.7174148373604701, 0.7193165643677153, 0.7190341912137839, 0.7207438449055729, 0.7206084184526551, 0.7222371919836976, 0.7227030055533693, 0.7241243230816096, 0.7253693914672914, 0.7273362138928121, 0.7263756650879211, 0.7275672469490472, 0.7294891436777464, 0.7300289134131381, 0.730297306878402, 0.7310519301890227, 0.7320422794637915, 0.7318993065505189, 0.7334929289692916, 0.7340994218965083, 0.7349973125155645, 0.7361314158471299, 0.7366730282307331, 0.7363620916328054, 0.7379592096059071, 0.7386259675179858, 0.7386287093206513, 0.7392906003098179, 0.7391734973515552, 0.7403341009422696, 0.7410302342693931, 0.7411599984129867, 0.7423627584565228, 0.7411481359068081, 0.7436363015196414, 0.7430776924727687, 0.7437631435294461, 0.7432282658825169, 0.743950651655731, 0.7442201942818352, 0.7463550748040533, 0.7464074747957977, 0.7465516996154989, 0.7468746043676425, 0.7475289332793008, 0.7476849018026738]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.11s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:50,  1.87s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:01,  1.70s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:54,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:23,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:52,  1.69s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:36,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:57,  1.72s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:15,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:22,  1.83s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:50,  1.72s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<07:58,  1.76s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<07:59,  1.77s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:08,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:12,  1.83s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:46,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<07:45,  1.74s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:36,  1.72s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:49,  1.77s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:56,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:40,  1.75s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:44,  1.77s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:30,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:45,  1.79s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<07:58,  1.85s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:36,  1.77s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:33,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:34,  1.78s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:48,  1.84s/it]predicting train subjects:  11%|█         | 31/285 [00:54<07:51,  1.85s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:31,  1.79s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:33,  1.80s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:33,  1.81s/it]predicting train subjects:  12%|█▏        | 35/285 [01:01<07:43,  1.85s/it]predicting train subjects:  13%|█▎        | 36/285 [01:03<07:28,  1.80s/it]predicting train subjects:  13%|█▎        | 37/285 [01:05<07:21,  1.78s/it]predicting train subjects:  13%|█▎        | 38/285 [01:07<07:35,  1.84s/it]predicting train subjects:  14%|█▎        | 39/285 [01:08<07:11,  1.75s/it]predicting train subjects:  14%|█▍        | 40/285 [01:10<07:07,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:12<07:05,  1.74s/it]predicting train subjects:  15%|█▍        | 42/285 [01:13<07:02,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:15<07:11,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:17<07:19,  1.82s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<07:01,  1.76s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:11,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:22<06:58,  1.76s/it]predicting train subjects:  17%|█▋        | 48/285 [01:24<07:02,  1.78s/it]predicting train subjects:  17%|█▋        | 49/285 [01:26<07:16,  1.85s/it]predicting train subjects:  18%|█▊        | 50/285 [01:28<07:11,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:30<07:16,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<06:53,  1.77s/it]predicting train subjects:  19%|█▊        | 53/285 [01:33<06:59,  1.81s/it]predicting train subjects:  19%|█▉        | 54/285 [01:35<07:10,  1.86s/it]predicting train subjects:  19%|█▉        | 55/285 [01:37<06:51,  1.79s/it]predicting train subjects:  20%|█▉        | 56/285 [01:39<06:44,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:40<06:29,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:42<06:29,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:44<06:44,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [01:46<06:54,  1.84s/it]predicting train subjects:  21%|██▏       | 61/285 [01:48<06:31,  1.75s/it]predicting train subjects:  22%|██▏       | 62/285 [01:49<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:51<06:35,  1.78s/it]predicting train subjects:  22%|██▏       | 64/285 [01:53<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:55<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:25,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:58<06:29,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [02:00<06:19,  1.75s/it]predicting train subjects:  24%|██▍       | 69/285 [02:02<06:23,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:04<06:23,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:05<06:25,  1.80s/it]predicting train subjects:  25%|██▌       | 72/285 [02:07<06:10,  1.74s/it]predicting train subjects:  26%|██▌       | 73/285 [02:09<06:10,  1.75s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:10,  1.75s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:11,  1.77s/it]predicting train subjects:  27%|██▋       | 76/285 [02:14<06:10,  1.77s/it]predicting train subjects:  27%|██▋       | 77/285 [02:16<05:58,  1.72s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:51,  1.70s/it]predicting train subjects:  28%|██▊       | 79/285 [02:19<05:57,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:21<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:23<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:54,  1.75s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:46,  1.71s/it]predicting train subjects:  29%|██▉       | 84/285 [02:28<05:35,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:39,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:31<05:52,  1.77s/it]predicting train subjects:  31%|███       | 87/285 [02:33<05:53,  1.78s/it]predicting train subjects:  31%|███       | 88/285 [02:35<05:38,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:38,  1.73s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:44,  1.77s/it]predicting train subjects:  32%|███▏      | 91/285 [02:40<05:40,  1.76s/it]predicting train subjects:  32%|███▏      | 92/285 [02:42<05:46,  1.80s/it]predicting train subjects:  33%|███▎      | 93/285 [02:44<05:33,  1.74s/it]predicting train subjects:  33%|███▎      | 94/285 [02:45<05:34,  1.75s/it]predicting train subjects:  33%|███▎      | 95/285 [02:47<05:36,  1.77s/it]predicting train subjects:  34%|███▎      | 96/285 [02:49<05:37,  1.78s/it]predicting train subjects:  34%|███▍      | 97/285 [02:51<05:42,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [02:53<05:38,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [02:54<05:33,  1.79s/it]predicting train subjects:  35%|███▌      | 100/285 [02:56<05:31,  1.79s/it]predicting train subjects:  35%|███▌      | 101/285 [02:58<05:19,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [03:00<05:21,  1.75s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:10,  1.70s/it]predicting train subjects:  36%|███▋      | 104/285 [03:03<05:18,  1.76s/it]predicting train subjects:  37%|███▋      | 105/285 [03:05<05:16,  1.76s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:08,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:06,  1.72s/it]predicting train subjects:  38%|███▊      | 108/285 [03:10<04:58,  1.69s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<04:58,  1.69s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:00,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<04:55,  1.70s/it]predicting train subjects:  39%|███▉      | 112/285 [03:17<04:57,  1.72s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<04:56,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:20<04:56,  1.74s/it]predicting train subjects:  40%|████      | 115/285 [03:22<04:57,  1.75s/it]predicting train subjects:  41%|████      | 116/285 [03:24<04:59,  1.77s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:51,  1.74s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:45,  1.71s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:49,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:40,  1.70s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:33,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [03:34<04:26,  1.64s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:13,  1.57s/it]predicting train subjects:  44%|████▎     | 124/285 [03:37<04:15,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:05,  1.53s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:04,  1.54s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<04:03,  1.54s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:07,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:44<04:01,  1.55s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<03:55,  1.52s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<03:52,  1.51s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<03:52,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [03:50<03:51,  1.53s/it]predicting train subjects:  47%|████▋     | 134/285 [03:52<03:46,  1.50s/it]predicting train subjects:  47%|████▋     | 135/285 [03:53<03:42,  1.48s/it]predicting train subjects:  48%|████▊     | 136/285 [03:55<03:39,  1.47s/it]predicting train subjects:  48%|████▊     | 137/285 [03:56<03:45,  1.52s/it]predicting train subjects:  48%|████▊     | 138/285 [03:58<03:39,  1.49s/it]predicting train subjects:  49%|████▉     | 139/285 [03:59<03:46,  1.55s/it]predicting train subjects:  49%|████▉     | 140/285 [04:01<03:47,  1.57s/it]predicting train subjects:  49%|████▉     | 141/285 [04:02<03:40,  1.53s/it]predicting train subjects:  50%|████▉     | 142/285 [04:04<03:36,  1.51s/it]predicting train subjects:  50%|█████     | 143/285 [04:05<03:33,  1.50s/it]predicting train subjects:  51%|█████     | 144/285 [04:07<03:35,  1.53s/it]predicting train subjects:  51%|█████     | 145/285 [04:09<03:34,  1.53s/it]predicting train subjects:  51%|█████     | 146/285 [04:10<03:39,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:12<03:35,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:13<03:35,  1.58s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:15<03:28,  1.54s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:16<03:21,  1.49s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:18<03:20,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:19<03:16,  1.48s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:21<03:13,  1.46s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:21,  1.54s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:24<03:18,  1.53s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:21,  1.56s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:27<03:17,  1.54s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:29<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:30<03:15,  1.55s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:32<03:09,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:33<03:08,  1.52s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:35<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:36<03:12,  1.58s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:38<03:06,  1.54s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:39<03:04,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:41<03:05,  1.56s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:42<03:04,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:44<02:58,  1.53s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:45<02:56,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:47<02:51,  1.49s/it]predicting train subjects:  60%|██████    | 171/285 [04:48<02:49,  1.49s/it]predicting train subjects:  60%|██████    | 172/285 [04:50<02:48,  1.49s/it]predicting train subjects:  61%|██████    | 173/285 [04:51<02:43,  1.46s/it]predicting train subjects:  61%|██████    | 174/285 [04:53<02:41,  1.45s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:54<02:46,  1.51s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:56<02:49,  1.55s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:58<02:48,  1.56s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:59<02:41,  1.51s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:00<02:38,  1.50s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:02<02:46,  1.59s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:04<02:46,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:05<02:44,  1.60s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:07<02:38,  1.55s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:08<02:33,  1.52s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:10<02:27,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:11<02:35,  1.57s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:13<02:43,  1.67s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:15<02:46,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:17<02:36,  1.63s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:18<02:29,  1.57s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:20<02:31,  1.61s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:21<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:23<02:21,  1.54s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:24<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:25<02:10,  1.45s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:27<02:19,  1.57s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:29<02:25,  1.65s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:31<02:26,  1.69s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:32<02:16,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:34<02:10,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:36<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:37<02:17,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:39<02:17,  1.67s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:40<02:08,  1.58s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:42<02:04,  1.55s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:43<01:58,  1.50s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:45<02:04,  1.60s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:47<02:07,  1.65s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:49<02:10,  1.71s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:50<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:51<01:53,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:53<01:54,  1.57s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:55<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:56<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:58<01:53,  1.62s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:59<01:45,  1.53s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:01<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:03<01:53,  1.69s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:05<01:54,  1.73s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:06<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:08<01:40,  1.58s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:09<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:11<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:12<01:31,  1.51s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:13<01:27,  1.45s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:15<01:33,  1.58s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:17<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:19<01:36,  1.70s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:34,  1.69s/it]predicting train subjects:  81%|████████  | 230/285 [06:22<01:27,  1.60s/it]predicting train subjects:  81%|████████  | 231/285 [06:23<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:25<01:23,  1.58s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:26<01:18,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:28<01:21,  1.60s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:30<01:17,  1.55s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:32<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:33<01:20,  1.68s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:35<01:19,  1.69s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:37<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:38<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:40<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:41<01:05,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:42<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:44<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:45<00:59,  1.49s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:47<01:01,  1.57s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:49<01:01,  1.63s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:51<01:00,  1.63s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:52<00:55,  1.55s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:53<00:53,  1.53s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:55<00:50,  1.48s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:56<00:47,  1.45s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:58<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:00<00:49,  1.59s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:01<00:49,  1.65s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:03<00:46,  1.60s/it]predicting train subjects:  90%|█████████ | 257/285 [07:05<00:45,  1.63s/it]predicting train subjects:  91%|█████████ | 258/285 [07:07<00:49,  1.83s/it]predicting train subjects:  91%|█████████ | 259/285 [07:09<00:51,  1.99s/it]predicting train subjects:  91%|█████████ | 260/285 [07:11<00:45,  1.84s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:13<00:46,  1.92s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:15<00:45,  1.97s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:17<00:41,  1.89s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:19<00:44,  2.10s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:21<00:41,  2.08s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:23<00:37,  1.98s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:25<00:34,  1.93s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:27<00:34,  2.02s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:29<00:32,  2.03s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:31<00:29,  1.95s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:33<00:27,  1.93s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:35<00:25,  1.95s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:36<00:22,  1.87s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:38<00:20,  1.82s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:40<00:19,  1.95s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:43<00:18,  2.07s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:45<00:17,  2.13s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:47<00:14,  2.07s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:49<00:12,  2.02s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:51<00:09,  1.92s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:52<00:07,  1.89s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:54<00:05,  1.92s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:56<00:03,  1.98s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:59<00:02,  2.11s/it]predicting train subjects: 100%|██████████| 285/285 [08:01<00:00,  2.11s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<11:20,  2.39s/it]Loading train:   1%|          | 2/285 [00:04<11:18,  2.40s/it]Loading train:   1%|          | 3/285 [00:06<10:42,  2.28s/it]Loading train:   1%|▏         | 4/285 [00:09<11:11,  2.39s/it]Loading train:   2%|▏         | 5/285 [00:12<11:31,  2.47s/it]Loading train:   2%|▏         | 6/285 [00:14<11:16,  2.43s/it]Loading train:   2%|▏         | 7/285 [00:17<11:48,  2.55s/it]Loading train:   3%|▎         | 8/285 [00:19<11:14,  2.44s/it]Loading train:   3%|▎         | 9/285 [00:22<11:59,  2.61s/it]Loading train:   4%|▎         | 10/285 [00:23<10:15,  2.24s/it]Loading train:   4%|▍         | 11/285 [00:25<09:12,  2.02s/it]Loading train:   4%|▍         | 12/285 [00:27<08:51,  1.95s/it]Loading train:   5%|▍         | 13/285 [00:28<08:18,  1.83s/it]Loading train:   5%|▍         | 14/285 [00:30<08:43,  1.93s/it]Loading train:   5%|▌         | 15/285 [00:32<08:11,  1.82s/it]Loading train:   6%|▌         | 16/285 [00:34<08:07,  1.81s/it]Loading train:   6%|▌         | 17/285 [00:36<08:23,  1.88s/it]Loading train:   6%|▋         | 18/285 [00:37<07:55,  1.78s/it]Loading train:   7%|▋         | 19/285 [00:39<08:24,  1.90s/it]Loading train:   7%|▋         | 20/285 [00:41<08:14,  1.87s/it]Loading train:   7%|▋         | 21/285 [00:43<08:11,  1.86s/it]Loading train:   8%|▊         | 22/285 [00:45<08:04,  1.84s/it]Loading train:   8%|▊         | 23/285 [00:47<08:26,  1.93s/it]Loading train:   8%|▊         | 24/285 [00:49<08:15,  1.90s/it]Loading train:   9%|▉         | 25/285 [00:51<08:41,  2.01s/it]Loading train:   9%|▉         | 26/285 [00:53<08:53,  2.06s/it]Loading train:   9%|▉         | 27/285 [00:54<07:44,  1.80s/it]Loading train:  10%|▉         | 28/285 [00:57<08:13,  1.92s/it]Loading train:  10%|█         | 29/285 [01:00<09:22,  2.20s/it]Loading train:  11%|█         | 30/285 [01:01<09:01,  2.12s/it]Loading train:  11%|█         | 31/285 [01:03<08:28,  2.00s/it]Loading train:  11%|█         | 32/285 [01:05<08:39,  2.05s/it]Loading train:  12%|█▏        | 33/285 [01:08<09:10,  2.19s/it]Loading train:  12%|█▏        | 34/285 [01:10<08:48,  2.10s/it]Loading train:  12%|█▏        | 35/285 [01:12<09:05,  2.18s/it]Loading train:  13%|█▎        | 36/285 [01:14<08:20,  2.01s/it]Loading train:  13%|█▎        | 37/285 [01:16<08:18,  2.01s/it]Loading train:  13%|█▎        | 38/285 [01:18<08:03,  1.96s/it]Loading train:  14%|█▎        | 39/285 [01:20<08:13,  2.01s/it]Loading train:  14%|█▍        | 40/285 [01:22<08:22,  2.05s/it]Loading train:  14%|█▍        | 41/285 [01:24<08:39,  2.13s/it]Loading train:  15%|█▍        | 42/285 [01:26<08:21,  2.06s/it]Loading train:  15%|█▌        | 43/285 [01:28<07:52,  1.95s/it]Loading train:  15%|█▌        | 44/285 [01:30<08:36,  2.14s/it]Loading train:  16%|█▌        | 45/285 [01:33<08:49,  2.20s/it]Loading train:  16%|█▌        | 46/285 [01:35<09:00,  2.26s/it]Loading train:  16%|█▋        | 47/285 [01:37<08:11,  2.07s/it]Loading train:  17%|█▋        | 48/285 [01:39<08:12,  2.08s/it]Loading train:  17%|█▋        | 49/285 [01:41<07:52,  2.00s/it]Loading train:  18%|█▊        | 50/285 [01:43<08:06,  2.07s/it]Loading train:  18%|█▊        | 51/285 [01:46<08:42,  2.23s/it]Loading train:  18%|█▊        | 52/285 [01:47<08:02,  2.07s/it]Loading train:  19%|█▊        | 53/285 [01:49<08:08,  2.11s/it]Loading train:  19%|█▉        | 54/285 [01:52<08:43,  2.27s/it]Loading train:  19%|█▉        | 55/285 [01:54<08:01,  2.09s/it]Loading train:  20%|█▉        | 56/285 [01:56<07:51,  2.06s/it]Loading train:  20%|██        | 57/285 [01:58<07:52,  2.07s/it]Loading train:  20%|██        | 58/285 [02:00<08:07,  2.15s/it]Loading train:  21%|██        | 59/285 [02:02<07:29,  1.99s/it]Loading train:  21%|██        | 60/285 [02:04<07:30,  2.00s/it]Loading train:  21%|██▏       | 61/285 [02:05<06:56,  1.86s/it]Loading train:  22%|██▏       | 62/285 [02:07<06:33,  1.76s/it]Loading train:  22%|██▏       | 63/285 [02:09<06:29,  1.75s/it]Loading train:  22%|██▏       | 64/285 [02:11<06:46,  1.84s/it]Loading train:  23%|██▎       | 65/285 [02:13<07:21,  2.01s/it]Loading train:  23%|██▎       | 66/285 [02:15<07:34,  2.08s/it]Loading train:  24%|██▎       | 67/285 [02:18<08:00,  2.21s/it]Loading train:  24%|██▍       | 68/285 [02:20<07:40,  2.12s/it]Loading train:  24%|██▍       | 69/285 [02:22<07:28,  2.08s/it]Loading train:  25%|██▍       | 70/285 [02:24<07:26,  2.07s/it]Loading train:  25%|██▍       | 71/285 [02:26<07:42,  2.16s/it]Loading train:  25%|██▌       | 72/285 [02:28<07:16,  2.05s/it]Loading train:  26%|██▌       | 73/285 [02:30<07:01,  1.99s/it]Loading train:  26%|██▌       | 74/285 [02:32<07:28,  2.13s/it]Loading train:  26%|██▋       | 75/285 [02:34<07:01,  2.01s/it]Loading train:  27%|██▋       | 76/285 [02:36<06:48,  1.95s/it]Loading train:  27%|██▋       | 77/285 [02:38<06:40,  1.93s/it]Loading train:  27%|██▋       | 78/285 [02:39<06:34,  1.91s/it]Loading train:  28%|██▊       | 79/285 [02:41<06:35,  1.92s/it]Loading train:  28%|██▊       | 80/285 [02:43<06:36,  1.94s/it]Loading train:  28%|██▊       | 81/285 [02:45<06:27,  1.90s/it]Loading train:  29%|██▉       | 82/285 [02:47<06:41,  1.98s/it]Loading train:  29%|██▉       | 83/285 [02:49<06:35,  1.96s/it]Loading train:  29%|██▉       | 84/285 [02:51<06:32,  1.95s/it]Loading train:  30%|██▉       | 85/285 [02:53<06:11,  1.86s/it]Loading train:  30%|███       | 86/285 [02:55<06:31,  1.97s/it]Loading train:  31%|███       | 87/285 [02:57<06:34,  1.99s/it]Loading train:  31%|███       | 88/285 [02:59<06:16,  1.91s/it]Loading train:  31%|███       | 89/285 [03:00<05:58,  1.83s/it]Loading train:  32%|███▏      | 90/285 [03:02<05:58,  1.84s/it]Loading train:  32%|███▏      | 91/285 [03:04<05:26,  1.68s/it]Loading train:  32%|███▏      | 92/285 [03:06<05:41,  1.77s/it]Loading train:  33%|███▎      | 93/285 [03:07<05:41,  1.78s/it]Loading train:  33%|███▎      | 94/285 [03:09<05:43,  1.80s/it]Loading train:  33%|███▎      | 95/285 [03:12<06:07,  1.94s/it]Loading train:  34%|███▎      | 96/285 [03:14<06:19,  2.01s/it]Loading train:  34%|███▍      | 97/285 [03:16<06:28,  2.07s/it]Loading train:  34%|███▍      | 98/285 [03:18<06:13,  2.00s/it]Loading train:  35%|███▍      | 99/285 [03:20<06:01,  1.95s/it]Loading train:  35%|███▌      | 100/285 [03:21<05:56,  1.92s/it]Loading train:  35%|███▌      | 101/285 [03:23<05:37,  1.83s/it]Loading train:  36%|███▌      | 102/285 [03:25<05:45,  1.89s/it]Loading train:  36%|███▌      | 103/285 [03:27<05:32,  1.83s/it]Loading train:  36%|███▋      | 104/285 [03:29<05:30,  1.83s/it]Loading train:  37%|███▋      | 105/285 [03:31<06:17,  2.10s/it]Loading train:  37%|███▋      | 106/285 [03:33<06:03,  2.03s/it]Loading train:  38%|███▊      | 107/285 [03:35<06:15,  2.11s/it]Loading train:  38%|███▊      | 108/285 [03:38<06:52,  2.33s/it]Loading train:  38%|███▊      | 109/285 [03:40<06:35,  2.25s/it]Loading train:  39%|███▊      | 110/285 [03:42<06:13,  2.14s/it]Loading train:  39%|███▉      | 111/285 [03:44<05:39,  1.95s/it]Loading train:  39%|███▉      | 112/285 [03:46<05:34,  1.94s/it]Loading train:  40%|███▉      | 113/285 [03:47<05:18,  1.85s/it]Loading train:  40%|████      | 114/285 [03:50<05:49,  2.05s/it]Loading train:  40%|████      | 115/285 [03:51<05:08,  1.81s/it]Loading train:  41%|████      | 116/285 [03:53<05:20,  1.90s/it]Loading train:  41%|████      | 117/285 [03:55<05:25,  1.94s/it]Loading train:  41%|████▏     | 118/285 [03:57<05:01,  1.80s/it]Loading train:  42%|████▏     | 119/285 [03:59<05:30,  1.99s/it]Loading train:  42%|████▏     | 120/285 [04:01<05:13,  1.90s/it]Loading train:  42%|████▏     | 121/285 [04:03<05:30,  2.01s/it]Loading train:  43%|████▎     | 122/285 [04:05<05:37,  2.07s/it]Loading train:  43%|████▎     | 123/285 [04:08<05:44,  2.13s/it]Loading train:  44%|████▎     | 124/285 [04:09<05:07,  1.91s/it]Loading train:  44%|████▍     | 125/285 [04:10<04:27,  1.67s/it]Loading train:  44%|████▍     | 126/285 [04:12<04:33,  1.72s/it]Loading train:  45%|████▍     | 127/285 [04:14<04:35,  1.74s/it]Loading train:  45%|████▍     | 128/285 [04:16<04:36,  1.76s/it]Loading train:  45%|████▌     | 129/285 [04:18<05:01,  1.94s/it]Loading train:  46%|████▌     | 130/285 [04:19<04:40,  1.81s/it]Loading train:  46%|████▌     | 131/285 [04:21<04:37,  1.80s/it]Loading train:  46%|████▋     | 132/285 [04:23<04:54,  1.93s/it]Loading train:  47%|████▋     | 133/285 [04:25<04:54,  1.94s/it]Loading train:  47%|████▋     | 134/285 [04:27<04:49,  1.92s/it]Loading train:  47%|████▋     | 135/285 [04:29<04:44,  1.90s/it]Loading train:  48%|████▊     | 136/285 [04:31<04:35,  1.85s/it]Loading train:  48%|████▊     | 137/285 [04:32<04:15,  1.73s/it]Loading train:  48%|████▊     | 138/285 [04:34<04:09,  1.70s/it]Loading train:  49%|████▉     | 139/285 [04:36<04:16,  1.76s/it]Loading train:  49%|████▉     | 140/285 [04:37<04:06,  1.70s/it]Loading train:  49%|████▉     | 141/285 [04:39<04:04,  1.70s/it]Loading train:  50%|████▉     | 142/285 [04:41<04:19,  1.82s/it]Loading train:  50%|█████     | 143/285 [04:43<04:31,  1.91s/it]Loading train:  51%|█████     | 144/285 [04:45<04:16,  1.82s/it]Loading train:  51%|█████     | 145/285 [04:47<04:17,  1.84s/it]Loading train:  51%|█████     | 146/285 [04:49<04:13,  1.82s/it]Loading train:  52%|█████▏    | 147/285 [04:51<04:17,  1.87s/it]Loading train:  52%|█████▏    | 148/285 [04:52<04:03,  1.77s/it]Loading train:  52%|█████▏    | 149/285 [04:53<03:43,  1.65s/it]Loading train:  53%|█████▎    | 150/285 [04:55<03:35,  1.60s/it]Loading train:  53%|█████▎    | 151/285 [04:57<03:44,  1.67s/it]Loading train:  53%|█████▎    | 152/285 [04:59<03:55,  1.77s/it]Loading train:  54%|█████▎    | 153/285 [05:00<03:28,  1.58s/it]Loading train:  54%|█████▍    | 154/285 [05:02<03:34,  1.63s/it]Loading train:  54%|█████▍    | 155/285 [05:03<03:24,  1.57s/it]Loading train:  55%|█████▍    | 156/285 [05:05<03:40,  1.71s/it]Loading train:  55%|█████▌    | 157/285 [05:06<03:23,  1.59s/it]Loading train:  55%|█████▌    | 158/285 [05:08<03:15,  1.54s/it]Loading train:  56%|█████▌    | 159/285 [05:09<03:13,  1.53s/it]Loading train:  56%|█████▌    | 160/285 [05:11<03:18,  1.59s/it]Loading train:  56%|█████▋    | 161/285 [05:13<03:37,  1.75s/it]Loading train:  57%|█████▋    | 162/285 [05:15<03:50,  1.87s/it]Loading train:  57%|█████▋    | 163/285 [05:17<03:47,  1.86s/it]Loading train:  58%|█████▊    | 164/285 [05:19<03:47,  1.88s/it]Loading train:  58%|█████▊    | 165/285 [05:21<03:33,  1.78s/it]Loading train:  58%|█████▊    | 166/285 [05:22<03:23,  1.71s/it]Loading train:  59%|█████▊    | 167/285 [05:24<03:38,  1.85s/it]Loading train:  59%|█████▉    | 168/285 [05:26<03:33,  1.82s/it]Loading train:  59%|█████▉    | 169/285 [05:28<03:21,  1.74s/it]Loading train:  60%|█████▉    | 170/285 [05:30<03:33,  1.86s/it]Loading train:  60%|██████    | 171/285 [05:32<03:36,  1.90s/it]Loading train:  60%|██████    | 172/285 [05:34<03:32,  1.88s/it]Loading train:  61%|██████    | 173/285 [05:35<03:12,  1.72s/it]Loading train:  61%|██████    | 174/285 [05:37<03:27,  1.87s/it]Loading train:  61%|██████▏   | 175/285 [05:39<03:28,  1.90s/it]Loading train:  62%|██████▏   | 176/285 [05:41<03:10,  1.75s/it]Loading train:  62%|██████▏   | 177/285 [05:42<03:13,  1.79s/it]Loading train:  62%|██████▏   | 178/285 [05:45<03:28,  1.95s/it]Loading train:  63%|██████▎   | 179/285 [05:46<03:13,  1.83s/it]Loading train:  63%|██████▎   | 180/285 [05:49<03:22,  1.93s/it]Loading train:  64%|██████▎   | 181/285 [05:50<03:11,  1.84s/it]Loading train:  64%|██████▍   | 182/285 [05:52<03:04,  1.79s/it]Loading train:  64%|██████▍   | 183/285 [05:54<03:07,  1.84s/it]Loading train:  65%|██████▍   | 184/285 [05:55<02:57,  1.75s/it]Loading train:  65%|██████▍   | 185/285 [05:57<02:51,  1.72s/it]Loading train:  65%|██████▌   | 186/285 [05:59<02:52,  1.74s/it]Loading train:  66%|██████▌   | 187/285 [06:01<03:10,  1.94s/it]Loading train:  66%|██████▌   | 188/285 [06:04<03:29,  2.16s/it]Loading train:  66%|██████▋   | 189/285 [06:05<03:10,  1.98s/it]Loading train:  67%|██████▋   | 190/285 [06:07<03:01,  1.91s/it]Loading train:  67%|██████▋   | 191/285 [06:09<02:46,  1.77s/it]Loading train:  67%|██████▋   | 192/285 [06:10<02:44,  1.77s/it]Loading train:  68%|██████▊   | 193/285 [06:13<02:54,  1.89s/it]Loading train:  68%|██████▊   | 194/285 [06:14<02:41,  1.77s/it]Loading train:  68%|██████▊   | 195/285 [06:15<02:20,  1.56s/it]Loading train:  69%|██████▉   | 196/285 [06:17<02:23,  1.62s/it]Loading train:  69%|██████▉   | 197/285 [06:19<02:31,  1.72s/it]Loading train:  69%|██████▉   | 198/285 [06:21<02:36,  1.79s/it]Loading train:  70%|██████▉   | 199/285 [06:22<02:16,  1.58s/it]Loading train:  70%|███████   | 200/285 [06:23<02:02,  1.44s/it]Loading train:  71%|███████   | 201/285 [06:24<01:58,  1.41s/it]Loading train:  71%|███████   | 202/285 [06:26<01:56,  1.41s/it]Loading train:  71%|███████   | 203/285 [06:27<01:49,  1.34s/it]Loading train:  72%|███████▏  | 204/285 [06:28<01:41,  1.25s/it]Loading train:  72%|███████▏  | 205/285 [06:29<01:44,  1.31s/it]Loading train:  72%|███████▏  | 206/285 [06:31<01:43,  1.31s/it]Loading train:  73%|███████▎  | 207/285 [06:33<01:56,  1.49s/it]Loading train:  73%|███████▎  | 208/285 [06:34<01:56,  1.51s/it]Loading train:  73%|███████▎  | 209/285 [06:35<01:48,  1.43s/it]Loading train:  74%|███████▎  | 210/285 [06:36<01:37,  1.29s/it]Loading train:  74%|███████▍  | 211/285 [06:38<01:35,  1.29s/it]Loading train:  74%|███████▍  | 212/285 [06:39<01:31,  1.25s/it]Loading train:  75%|███████▍  | 213/285 [06:40<01:34,  1.31s/it]Loading train:  75%|███████▌  | 214/285 [06:42<01:37,  1.37s/it]Loading train:  75%|███████▌  | 215/285 [06:43<01:40,  1.44s/it]Loading train:  76%|███████▌  | 216/285 [06:44<01:27,  1.26s/it]Loading train:  76%|███████▌  | 217/285 [06:46<01:30,  1.33s/it]Loading train:  76%|███████▋  | 218/285 [06:47<01:31,  1.37s/it]Loading train:  77%|███████▋  | 219/285 [06:49<01:36,  1.47s/it]Loading train:  77%|███████▋  | 220/285 [06:50<01:29,  1.38s/it]Loading train:  78%|███████▊  | 221/285 [06:51<01:19,  1.24s/it]Loading train:  78%|███████▊  | 222/285 [06:53<01:27,  1.39s/it]Loading train:  78%|███████▊  | 223/285 [06:54<01:18,  1.26s/it]Loading train:  79%|███████▊  | 224/285 [06:55<01:17,  1.28s/it]Loading train:  79%|███████▉  | 225/285 [06:56<01:19,  1.32s/it]Loading train:  79%|███████▉  | 226/285 [06:58<01:23,  1.42s/it]Loading train:  80%|███████▉  | 227/285 [06:59<01:22,  1.42s/it]Loading train:  80%|████████  | 228/285 [07:01<01:26,  1.52s/it]Loading train:  80%|████████  | 229/285 [07:03<01:25,  1.53s/it]Loading train:  81%|████████  | 230/285 [07:04<01:17,  1.41s/it]Loading train:  81%|████████  | 231/285 [07:05<01:12,  1.35s/it]Loading train:  81%|████████▏ | 232/285 [07:06<01:10,  1.33s/it]Loading train:  82%|████████▏ | 233/285 [07:08<01:07,  1.30s/it]Loading train:  82%|████████▏ | 234/285 [07:09<01:07,  1.33s/it]Loading train:  82%|████████▏ | 235/285 [07:10<01:02,  1.25s/it]Loading train:  83%|████████▎ | 236/285 [07:11<01:02,  1.27s/it]Loading train:  83%|████████▎ | 237/285 [07:13<01:00,  1.26s/it]Loading train:  84%|████████▎ | 238/285 [07:14<01:00,  1.30s/it]Loading train:  84%|████████▍ | 239/285 [07:16<01:03,  1.38s/it]Loading train:  84%|████████▍ | 240/285 [07:17<01:01,  1.37s/it]Loading train:  85%|████████▍ | 241/285 [07:18<01:00,  1.38s/it]Loading train:  85%|████████▍ | 242/285 [07:20<01:00,  1.40s/it]Loading train:  85%|████████▌ | 243/285 [07:21<00:56,  1.35s/it]Loading train:  86%|████████▌ | 244/285 [07:23<00:58,  1.42s/it]Loading train:  86%|████████▌ | 245/285 [07:24<00:55,  1.39s/it]Loading train:  86%|████████▋ | 246/285 [07:26<00:57,  1.47s/it]Loading train:  87%|████████▋ | 247/285 [07:27<00:56,  1.49s/it]Loading train:  87%|████████▋ | 248/285 [07:28<00:52,  1.41s/it]Loading train:  87%|████████▋ | 249/285 [07:30<00:49,  1.37s/it]Loading train:  88%|████████▊ | 250/285 [07:31<00:50,  1.45s/it]Loading train:  88%|████████▊ | 251/285 [07:32<00:46,  1.36s/it]Loading train:  88%|████████▊ | 252/285 [07:34<00:45,  1.37s/it]Loading train:  89%|████████▉ | 253/285 [07:36<00:47,  1.49s/it]Loading train:  89%|████████▉ | 254/285 [07:38<00:50,  1.62s/it]Loading train:  89%|████████▉ | 255/285 [07:39<00:44,  1.49s/it]Loading train:  90%|████████▉ | 256/285 [07:40<00:40,  1.39s/it]Loading train:  90%|█████████ | 257/285 [07:41<00:39,  1.41s/it]Loading train:  91%|█████████ | 258/285 [07:43<00:41,  1.55s/it]Loading train:  91%|█████████ | 259/285 [07:45<00:42,  1.62s/it]Loading train:  91%|█████████ | 260/285 [07:47<00:40,  1.60s/it]Loading train:  92%|█████████▏| 261/285 [07:49<00:42,  1.78s/it]Loading train:  92%|█████████▏| 262/285 [07:51<00:42,  1.83s/it]Loading train:  92%|█████████▏| 263/285 [07:52<00:33,  1.53s/it]Loading train:  93%|█████████▎| 264/285 [07:53<00:29,  1.39s/it]Loading train:  93%|█████████▎| 265/285 [07:54<00:27,  1.37s/it]Loading train:  93%|█████████▎| 266/285 [07:55<00:24,  1.28s/it]Loading train:  94%|█████████▎| 267/285 [07:56<00:22,  1.25s/it]Loading train:  94%|█████████▍| 268/285 [07:58<00:23,  1.36s/it]Loading train:  94%|█████████▍| 269/285 [07:59<00:23,  1.46s/it]Loading train:  95%|█████████▍| 270/285 [08:00<00:19,  1.29s/it]Loading train:  95%|█████████▌| 271/285 [08:01<00:16,  1.15s/it]Loading train:  95%|█████████▌| 272/285 [08:02<00:14,  1.10s/it]Loading train:  96%|█████████▌| 273/285 [08:03<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [08:04<00:10,  1.07it/s]Loading train:  96%|█████████▋| 275/285 [08:05<00:09,  1.05it/s]Loading train:  97%|█████████▋| 276/285 [08:06<00:08,  1.02it/s]Loading train:  97%|█████████▋| 277/285 [08:07<00:07,  1.08it/s]Loading train:  98%|█████████▊| 278/285 [08:07<00:06,  1.11it/s]Loading train:  98%|█████████▊| 279/285 [08:08<00:05,  1.13it/s]Loading train:  98%|█████████▊| 280/285 [08:09<00:04,  1.18it/s]Loading train:  99%|█████████▊| 281/285 [08:10<00:03,  1.15it/s]Loading train:  99%|█████████▉| 282/285 [08:11<00:02,  1.08it/s]Loading train:  99%|█████████▉| 283/285 [08:12<00:01,  1.06it/s]Loading train: 100%|█████████▉| 284/285 [08:13<00:00,  1.02it/s]Loading train: 100%|██████████| 285/285 [08:14<00:00,  1.01s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:03, 73.29it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:03, 69.69it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:03, 65.84it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:03, 64.80it/s]concatenating: train:  13%|█▎        | 38/285 [00:00<00:03, 70.08it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:03, 76.86it/s]concatenating: train:  29%|██▉       | 84/285 [00:00<00:02, 100.45it/s]concatenating: train:  38%|███▊      | 109/285 [00:00<00:01, 121.37it/s]concatenating: train:  45%|████▍     | 128/285 [00:01<00:01, 122.42it/s]concatenating: train:  51%|█████     | 145/285 [00:01<00:01, 123.20it/s]concatenating: train:  56%|█████▋    | 161/285 [00:01<00:00, 124.88it/s]concatenating: train:  70%|██████▉   | 199/285 [00:01<00:00, 156.12it/s]concatenating: train:  83%|████████▎ | 236/285 [00:01<00:00, 188.18it/s]concatenating: train:  95%|█████████▌| 272/285 [00:01<00:00, 218.65it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 176.66it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 114.84it/s]2019-07-11 03:38:59.531911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 03:38:59.532004: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 03:38:59.532018: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 03:38:59.532026: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 03:38:59.532449: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.87it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.74it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.39it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.94it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.02it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.80it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.94it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.66it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.07it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.74it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.40it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.68it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.72it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.88it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.51it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.89it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.14it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.06it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.96it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 20)   8120        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 65)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   858         concatenate_8[0][0]              
==================================================================================================
Total params: 141,618
Trainable params: 43,038
Non-trainable params: 98,580
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 15s - loss: 2.9286 - acc: 0.6179 - mDice: 0.1019 - val_loss: 3.6772 - val_acc: 0.9033 - val_mDice: 0.0911

Epoch 00001: val_mDice improved from -inf to 0.09112, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.1936 - acc: 0.8840 - mDice: 0.3172 - val_loss: 3.2322 - val_acc: 0.9117 - val_mDice: 0.1597

Epoch 00002: val_mDice improved from 0.09112 to 0.15967, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.8009 - acc: 0.8982 - mDice: 0.4394 - val_loss: 1.4957 - val_acc: 0.9227 - val_mDice: 0.3576

Epoch 00003: val_mDice improved from 0.15967 to 0.35760, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.6653 - acc: 0.9066 - mDice: 0.5013 - val_loss: 1.2421 - val_acc: 0.9301 - val_mDice: 0.4962

Epoch 00004: val_mDice improved from 0.35760 to 0.49619, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.5955 - acc: 0.9127 - mDice: 0.5370 - val_loss: 1.2870 - val_acc: 0.9274 - val_mDice: 0.4645

Epoch 00005: val_mDice did not improve from 0.49619
Epoch 6/300
 - 10s - loss: 0.5533 - acc: 0.9174 - mDice: 0.5603 - val_loss: 1.0915 - val_acc: 0.9395 - val_mDice: 0.5488

Epoch 00006: val_mDice improved from 0.49619 to 0.54883, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 10s - loss: 0.5213 - acc: 0.9216 - mDice: 0.5791 - val_loss: 1.1411 - val_acc: 0.9273 - val_mDice: 0.5321

Epoch 00007: val_mDice did not improve from 0.54883
Epoch 8/300
 - 10s - loss: 0.4971 - acc: 0.9242 - mDice: 0.5935 - val_loss: 1.0424 - val_acc: 0.9395 - val_mDice: 0.5620

Epoch 00008: val_mDice improved from 0.54883 to 0.56196, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.4778 - acc: 0.9261 - mDice: 0.6053 - val_loss: 1.0175 - val_acc: 0.9420 - val_mDice: 0.5721

Epoch 00009: val_mDice improved from 0.56196 to 0.57210, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 10s - loss: 0.4616 - acc: 0.9279 - mDice: 0.6154 - val_loss: 1.0189 - val_acc: 0.9414 - val_mDice: 0.5703

Epoch 00010: val_mDice did not improve from 0.57210
Epoch 11/300
 - 10s - loss: 0.4471 - acc: 0.9290 - mDice: 0.6247 - val_loss: 1.0103 - val_acc: 0.9408 - val_mDice: 0.5720

Epoch 00011: val_mDice did not improve from 0.57210
Epoch 12/300
 - 10s - loss: 0.4379 - acc: 0.9304 - mDice: 0.6310 - val_loss: 1.0440 - val_acc: 0.9373 - val_mDice: 0.5621

Epoch 00012: val_mDice did not improve from 0.57210
Epoch 13/300
 - 9s - loss: 0.4259 - acc: 0.9315 - mDice: 0.6386 - val_loss: 1.0773 - val_acc: 0.9329 - val_mDice: 0.5451

Epoch 00013: val_mDice did not improve from 0.57210
Epoch 14/300
 - 10s - loss: 0.4186 - acc: 0.9321 - mDice: 0.6433 - val_loss: 1.0345 - val_acc: 0.9362 - val_mDice: 0.5538

Epoch 00014: val_mDice did not improve from 0.57210
Epoch 15/300
 - 10s - loss: 0.4105 - acc: 0.9330 - mDice: 0.6486 - val_loss: 1.0221 - val_acc: 0.9408 - val_mDice: 0.5574

Epoch 00015: val_mDice did not improve from 0.57210
Epoch 16/300
 - 10s - loss: 0.4032 - acc: 0.9335 - mDice: 0.6535 - val_loss: 1.0021 - val_acc: 0.9384 - val_mDice: 0.5533

Epoch 00016: val_mDice did not improve from 0.57210
Epoch 17/300
 - 10s - loss: 0.3993 - acc: 0.9339 - mDice: 0.6562 - val_loss: 1.0064 - val_acc: 0.9392 - val_mDice: 0.5614

Epoch 00017: val_mDice did not improve from 0.57210
Epoch 18/300
 - 10s - loss: 0.3958 - acc: 0.9342 - mDice: 0.6585 - val_loss: 0.9823 - val_acc: 0.9412 - val_mDice: 0.5592

Epoch 00018: val_mDice did not improve from 0.57210
Epoch 19/300
 - 10s - loss: 0.3912 - acc: 0.9347 - mDice: 0.6618 - val_loss: 0.9751 - val_acc: 0.9440 - val_mDice: 0.5547

Epoch 00019: val_mDice did not improve from 0.57210
Epoch 20/300
 - 10s - loss: 0.3864 - acc: 0.9352 - mDice: 0.6650 - val_loss: 0.9723 - val_acc: 0.9404 - val_mDice: 0.5738

Epoch 00020: val_mDice improved from 0.57210 to 0.57384, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 9s - loss: 0.3808 - acc: 0.9358 - mDice: 0.6687 - val_loss: 0.9403 - val_acc: 0.9451 - val_mDice: 0.5682

Epoch 00021: val_mDice did not improve from 0.57384
Epoch 22/300
 - 10s - loss: 0.3812 - acc: 0.9360 - mDice: 0.6687 - val_loss: 0.9302 - val_acc: 0.9410 - val_mDice: 0.5586

Epoch 00022: val_mDice did not improve from 0.57384
Epoch 23/300
 - 10s - loss: 0.3764 - acc: 0.9360 - mDice: 0.6718 - val_loss: 0.9564 - val_acc: 0.9429 - val_mDice: 0.5563

Epoch 00023: val_mDice did not improve from 0.57384
Epoch 24/300
 - 10s - loss: 0.3713 - acc: 0.9365 - mDice: 0.6753 - val_loss: 0.9036 - val_acc: 0.9429 - val_mDice: 0.5744

Epoch 00024: val_mDice improved from 0.57384 to 0.57437, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 10s - loss: 0.3676 - acc: 0.9368 - mDice: 0.6778 - val_loss: 0.8859 - val_acc: 0.9432 - val_mDice: 0.5779

Epoch 00025: val_mDice improved from 0.57437 to 0.57787, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 10s - loss: 0.3654 - acc: 0.9371 - mDice: 0.6793 - val_loss: 0.9324 - val_acc: 0.9428 - val_mDice: 0.5464

Epoch 00026: val_mDice did not improve from 0.57787
Epoch 27/300
 - 10s - loss: 0.3637 - acc: 0.9372 - mDice: 0.6806 - val_loss: 0.9068 - val_acc: 0.9441 - val_mDice: 0.5625

Epoch 00027: val_mDice did not improve from 0.57787
Epoch 28/300
 - 10s - loss: 0.3625 - acc: 0.9373 - mDice: 0.6814 - val_loss: 0.9486 - val_acc: 0.9451 - val_mDice: 0.5618

Epoch 00028: val_mDice did not improve from 0.57787
Epoch 29/300
 - 10s - loss: 0.3591 - acc: 0.9376 - mDice: 0.6838 - val_loss: 0.8872 - val_acc: 0.9398 - val_mDice: 0.5683

Epoch 00029: val_mDice did not improve from 0.57787
Epoch 30/300
 - 10s - loss: 0.3567 - acc: 0.9378 - mDice: 0.6855 - val_loss: 0.8650 - val_acc: 0.9446 - val_mDice: 0.5751

Epoch 00030: val_mDice did not improve from 0.57787
Epoch 31/300
 - 10s - loss: 0.3542 - acc: 0.9382 - mDice: 0.6872 - val_loss: 0.8997 - val_acc: 0.9429 - val_mDice: 0.5614

Epoch 00031: val_mDice did not improve from 0.57787
Epoch 32/300
 - 10s - loss: 0.3517 - acc: 0.9387 - mDice: 0.6891 - val_loss: 0.9101 - val_acc: 0.9442 - val_mDice: 0.5450

Epoch 00032: val_mDice did not improve from 0.57787
Epoch 33/300
 - 10s - loss: 0.3489 - acc: 0.9386 - mDice: 0.6910 - val_loss: 0.8670 - val_acc: 0.9413 - val_mDice: 0.5767

Epoch 00033: val_mDice did not improve from 0.57787
Epoch 34/300
 - 10s - loss: 0.3507 - acc: 0.9386 - mDice: 0.6899 - val_loss: 0.8467 - val_acc: 0.9439 - val_mDice: 0.5750

Epoch 00034: val_mDice did not improve from 0.57787
Epoch 35/300
 - 10s - loss: 0.3468 - acc: 0.9389 - mDice: 0.6925 - val_loss: 0.8757 - val_acc: 0.9442 - val_mDice: 0.5735

Epoch 00035: val_mDice did not improve from 0.57787
Epoch 36/300
 - 10s - loss: 0.3451 - acc: 0.9391 - mDice: 0.6938 - val_loss: 0.8556 - val_acc: 0.9456 - val_mDice: 0.5685

Epoch 00036: val_mDice did not improve from 0.57787
Epoch 37/300
 - 10s - loss: 0.3407 - acc: 0.9395 - mDice: 0.6969 - val_loss: 0.8590 - val_acc: 0.9369 - val_mDice: 0.5714

Epoch 00037: val_mDice did not improve from 0.57787
Epoch 38/300
 - 10s - loss: 0.3411 - acc: 0.9395 - mDice: 0.6966 - val_loss: 0.8980 - val_acc: 0.9437 - val_mDice: 0.5608

Epoch 00038: val_mDice did not improve from 0.57787
Epoch 39/300
 - 10s - loss: 0.3392 - acc: 0.9396 - mDice: 0.6979 - val_loss: 0.8775 - val_acc: 0.9400 - val_mDice: 0.5748

Epoch 00039: val_mDice did not improve from 0.57787
Epoch 40/300
 - 10s - loss: 0.3393 - acc: 0.9396 - mDice: 0.6979 - val_loss: 1.0103 - val_acc: 0.9362 - val_mDice: 0.5427

Epoch 00040: val_mDice did not improve from 0.57787
Epoch 41/300
 - 10s - loss: 0.3353 - acc: 0.9400 - mDice: 0.7008 - val_loss: 0.8239 - val_acc: 0.9443 - val_mDice: 0.5753

Epoch 00041: val_mDice did not improve from 0.57787
Epoch 42/300
 - 10s - loss: 0.3338 - acc: 0.9401 - mDice: 0.7019 - val_loss: 0.8419 - val_acc: 0.9454 - val_mDice: 0.5575

Epoch 00042: val_mDice did not improve from 0.57787
Epoch 43/300
 - 10s - loss: 0.3324 - acc: 0.9401 - mDice: 0.7029 - val_loss: 0.8481 - val_acc: 0.9449 - val_mDice: 0.5645

Epoch 00043: val_mDice did not improve from 0.57787
Epoch 44/300
 - 10s - loss: 0.3320 - acc: 0.9403 - mDice: 0.7032 - val_loss: 0.8873 - val_acc: 0.9414 - val_mDice: 0.5674

Epoch 00044: val_mDice did not improve from 0.57787
Epoch 45/300
 - 10s - loss: 0.3309 - acc: 0.9403 - mDice: 0.7040 - val_loss: 0.8717 - val_acc: 0.9393 - val_mDice: 0.5661

Epoch 00045: val_mDice did not improve from 0.57787
Epoch 46/300
 - 10s - loss: 0.3302 - acc: 0.9404 - mDice: 0.7045 - val_loss: 0.8267 - val_acc: 0.9451 - val_mDice: 0.5720

Epoch 00046: val_mDice did not improve from 0.57787
Epoch 47/300
 - 10s - loss: 0.3299 - acc: 0.9404 - mDice: 0.7047 - val_loss: 0.9024 - val_acc: 0.9409 - val_mDice: 0.5634

Epoch 00047: val_mDice did not improve from 0.57787
Epoch 48/300
 - 10s - loss: 0.3253 - acc: 0.9409 - mDice: 0.7082 - val_loss: 0.8790 - val_acc: 0.9422 - val_mDice: 0.5619

Epoch 00048: val_mDice did not improve from 0.57787
Epoch 49/300
 - 10s - loss: 0.3242 - acc: 0.9408 - mDice: 0.7088 - val_loss: 0.8877 - val_acc: 0.9429 - val_mDice: 0.5723

Epoch 00049: val_mDice did not improve from 0.57787
Epoch 50/300
 - 10s - loss: 0.3247 - acc: 0.9409 - mDice: 0.7085 - val_loss: 0.8490 - val_acc: 0.9371 - val_mDice: 0.5658

Epoch 00050: val_mDice did not improve from 0.57787
Epoch 51/300
 - 10s - loss: 0.3242 - acc: 0.9410 - mDice: 0.7088 - val_loss: 0.8184 - val_acc: 0.9388 - val_mDice: 0.5663

Epoch 00051: val_mDice did not improve from 0.57787
Epoch 52/300
 - 10s - loss: 0.3233 - acc: 0.9410 - mDice: 0.7095 - val_loss: 0.7782 - val_acc: 0.9433 - val_mDice: 0.5659

Epoch 00052: val_mDice did not improve from 0.57787
Epoch 53/300
 - 10s - loss: 0.3191 - acc: 0.9414 - mDice: 0.7126 - val_loss: 0.8414 - val_acc: 0.9411 - val_mDice: 0.5710

Epoch 00053: val_mDice did not improve from 0.57787
Epoch 54/300
 - 10s - loss: 0.3198 - acc: 0.9414 - mDice: 0.7122 - val_loss: 0.7916 - val_acc: 0.9438 - val_mDice: 0.5419

Epoch 00054: val_mDice did not improve from 0.57787
Epoch 55/300
 - 10s - loss: 0.3187 - acc: 0.9416 - mDice: 0.7130 - val_loss: 0.8559 - val_acc: 0.9399 - val_mDice: 0.5516

Epoch 00055: val_mDice did not improve from 0.57787
Epoch 56/300
 - 10s - loss: 0.3163 - acc: 0.9417 - mDice: 0.7147 - val_loss: 0.8010 - val_acc: 0.9405 - val_mDice: 0.5743

Epoch 00056: val_mDice did not improve from 0.57787
Epoch 57/300
 - 10s - loss: 0.3164 - acc: 0.9418 - mDice: 0.7146 - val_loss: 0.8687 - val_acc: 0.9462 - val_mDice: 0.5654

Epoch 00057: val_mDice did not improve from 0.57787
Epoch 58/300
 - 10s - loss: 0.3164 - acc: 0.9416 - mDice: 0.7146 - val_loss: 0.7864 - val_acc: 0.9441 - val_mDice: 0.5671

Epoch 00058: val_mDice did not improve from 0.57787
Epoch 59/300
 - 10s - loss: 0.3159 - acc: 0.9417 - mDice: 0.7150 - val_loss: 0.8255 - val_acc: 0.9420 - val_mDice: 0.5666

Epoch 00059: val_mDice did not improve from 0.57787
Epoch 60/300
 - 10s - loss: 0.3138 - acc: 0.9419 - mDice: 0.7165 - val_loss: 0.7796 - val_acc: 0.9437 - val_mDice: 0.5650

Epoch 00060: val_mDice did not improve from 0.57787
Epoch 61/300
 - 10s - loss: 0.3139 - acc: 0.9419 - mDice: 0.7165 - val_loss: 0.8211 - val_acc: 0.9379 - val_mDice: 0.5645

Epoch 00061: val_mDice did not improve from 0.57787
Epoch 62/300
 - 10s - loss: 0.3121 - acc: 0.9421 - mDice: 0.7178 - val_loss: 0.8573 - val_acc: 0.9411 - val_mDice: 0.5647

Epoch 00062: val_mDice did not improve from 0.57787
Epoch 63/300
 - 10s - loss: 0.3120 - acc: 0.9421 - mDice: 0.7178 - val_loss: 0.7962 - val_acc: 0.9461 - val_mDice: 0.5667

Epoch 00063: val_mDice did not improve from 0.57787
Epoch 64/300
 - 10s - loss: 0.3087 - acc: 0.9425 - mDice: 0.7203 - val_loss: 0.8029 - val_acc: 0.9451 - val_mDice: 0.5603

Epoch 00064: val_mDice did not improve from 0.57787
Epoch 65/300
 - 10s - loss: 0.3096 - acc: 0.9423 - mDice: 0.7196 - val_loss: 0.7584 - val_acc: 0.9420 - val_mDice: 0.5578

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.18s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.96s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:42,  1.84s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:04,  1.71s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:54,  1.68s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:26,  1.59s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:44,  1.66s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:22,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:37,  1.65s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:22,  1.60s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:07,  1.77s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:37,  1.67s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:54,  1.74s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:41,  1.70s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:50,  1.74s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:05,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:10,  1.82s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:45,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:47,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:34,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:46,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:23,  1.69s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:32,  1.73s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:12,  1.66s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:26,  1.72s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:38,  1.77s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:15,  1.69s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:23,  1.73s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:26,  1.75s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:36,  1.79s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:42,  1.82s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:17,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:20,  1.75s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:16,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:07,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:11,  1.74s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:20,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<07:04,  1.72s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:08,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:48,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:37,  1.64s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:44,  1.67s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:59,  1.74s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:42,  1.68s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:57,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:40,  1.68s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:48,  1.72s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<07:04,  1.80s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:59,  1.79s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:26,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:57,  1.79s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:55,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<07:00,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:44,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:43,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:38<06:27,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:31,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:43,  1.78s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:49,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:34,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:37,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:20,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:28,  1.77s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:30,  1.79s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:24,  1.76s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:15,  1.73s/it]predicting train subjects:  24%|██▍       | 69/285 [01:59<06:21,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:01<06:24,  1.79s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:28,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:13,  1.75s/it]predicting train subjects:  26%|██▌       | 73/285 [02:06<06:14,  1.77s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:15,  1.78s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<06:16,  1.79s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<06:22,  1.83s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<06:09,  1.77s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:58,  1.73s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<06:07,  1.78s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<06:07,  1.79s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:55,  1.74s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<06:00,  1.77s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:49,  1.73s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:45,  1.72s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:52,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:57,  1.80s/it]predicting train subjects:  31%|███       | 87/285 [02:31<06:00,  1.82s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:50,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:35<05:46,  1.77s/it]predicting train subjects:  32%|███▏      | 90/285 [02:37<05:51,  1.80s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:40,  1.76s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:42,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:42<05:38,  1.77s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:44,  1.80s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:46,  1.82s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:43,  1.82s/it]predicting train subjects:  34%|███▍      | 97/285 [02:49<05:44,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [02:51<05:38,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [02:53<05:31,  1.78s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:38,  1.83s/it]predicting train subjects:  35%|███▌      | 101/285 [02:56<05:27,  1.78s/it]predicting train subjects:  36%|███▌      | 102/285 [02:58<05:33,  1.82s/it]predicting train subjects:  36%|███▌      | 103/285 [03:00<05:24,  1.78s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:27,  1.81s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:32,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:05<05:26,  1.82s/it]predicting train subjects:  38%|███▊      | 107/285 [03:07<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<05:13,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:14,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:18,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:14<05:08,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:06,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:09,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:02,  1.77s/it]predicting train subjects:  40%|████      | 115/285 [03:21<05:01,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:23<05:01,  1.79s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:58,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:51,  1.75s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:57,  1.79s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:49,  1.75s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:42,  1.72s/it]predicting train subjects:  43%|████▎     | 122/285 [03:33<04:27,  1.64s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:21,  1.61s/it]predicting train subjects:  44%|████▎     | 124/285 [03:37<04:20,  1.62s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:11,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:39<04:02,  1.53s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<03:59,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:03,  1.55s/it]predicting train subjects:  45%|████▌     | 129/285 [03:44<03:59,  1.54s/it]predicting train subjects:  46%|████▌     | 130/285 [03:45<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<03:47,  1.48s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<03:53,  1.52s/it]predicting train subjects:  47%|████▋     | 133/285 [03:50<03:51,  1.52s/it]predicting train subjects:  47%|████▋     | 134/285 [03:51<03:47,  1.51s/it]predicting train subjects:  47%|████▋     | 135/285 [03:53<03:43,  1.49s/it]predicting train subjects:  48%|████▊     | 136/285 [03:54<03:37,  1.46s/it]predicting train subjects:  48%|████▊     | 137/285 [03:56<03:42,  1.50s/it]predicting train subjects:  48%|████▊     | 138/285 [03:57<03:37,  1.48s/it]predicting train subjects:  49%|████▉     | 139/285 [03:59<03:42,  1.52s/it]predicting train subjects:  49%|████▉     | 140/285 [04:01<03:43,  1.54s/it]predicting train subjects:  49%|████▉     | 141/285 [04:02<03:36,  1.50s/it]predicting train subjects:  50%|████▉     | 142/285 [04:03<03:32,  1.49s/it]predicting train subjects:  50%|█████     | 143/285 [04:05<03:32,  1.50s/it]predicting train subjects:  51%|█████     | 144/285 [04:06<03:32,  1.51s/it]predicting train subjects:  51%|█████     | 145/285 [04:08<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:10<03:31,  1.52s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:11<03:22,  1.47s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:12<03:26,  1.51s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:14<03:19,  1.47s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:15<03:18,  1.47s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:17<03:21,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:18<03:22,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:20<03:18,  1.50s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:22<03:21,  1.54s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:20,  1.54s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:25<03:24,  1.58s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:26<03:14,  1.52s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:28<03:13,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:29<03:09,  1.50s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:31<03:10,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<03:11,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:34<03:06,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<03:07,  1.54s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:37<03:00,  1.49s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:38<02:56,  1.47s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:40<03:02,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<03:03,  1.56s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:43<02:57,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:44<02:55,  1.51s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:46<02:52,  1.50s/it]predicting train subjects:  60%|██████    | 171/285 [04:47<02:49,  1.49s/it]predicting train subjects:  60%|██████    | 172/285 [04:49<02:46,  1.48s/it]predicting train subjects:  61%|██████    | 173/285 [04:50<02:47,  1.49s/it]predicting train subjects:  61%|██████    | 174/285 [04:52<02:42,  1.46s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:53<02:48,  1.53s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:55<02:47,  1.54s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:56<02:42,  1.50s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:58<02:37,  1.47s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:59<02:34,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:01<02:46,  1.58s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:03<02:46,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:04<02:47,  1.63s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:06<02:41,  1.58s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:07<02:32,  1.51s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:09<02:26,  1.47s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:10<02:33,  1.55s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:12<02:41,  1.65s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:14<02:47,  1.72s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:16<02:38,  1.65s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:17<02:30,  1.58s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:19<02:29,  1.59s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:20<02:31,  1.63s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:22<02:23,  1.56s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:23<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:25<02:14,  1.49s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:26<02:23,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:28<02:30,  1.71s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:30<02:33,  1.77s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:32<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:33<02:17,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:35<02:21,  1.68s/it]predicting train subjects:  71%|███████   | 202/285 [05:37<02:19,  1.68s/it]predicting train subjects:  71%|███████   | 203/285 [05:39<02:20,  1.71s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:40<02:12,  1.63s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:41<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:43<02:00,  1.53s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:45<02:05,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:47<02:10,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:48<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:50<02:04,  1.66s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:51<01:57,  1.59s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:53<01:59,  1.64s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:55<01:57,  1.64s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:56<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:58<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:59<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:01<01:53,  1.67s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:03<01:59,  1.78s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:05<02:00,  1.83s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:07<01:51,  1.71s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:08<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:10<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:11<01:36,  1.56s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:13<01:35,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:14<01:29,  1.49s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:16<01:37,  1.64s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:18<01:40,  1.73s/it]predicting train subjects:  80%|████████  | 228/285 [06:20<01:40,  1.76s/it]predicting train subjects:  80%|████████  | 229/285 [06:21<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:23<01:27,  1.59s/it]predicting train subjects:  81%|████████  | 231/285 [06:24<01:23,  1.55s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:26<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:27<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:29<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:31<01:19,  1.59s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:33<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:35<01:25,  1.78s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:37<01:25,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:38<01:22,  1.80s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:40<01:15,  1.68s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:41<01:11,  1.63s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:43<01:08,  1.58s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:44<01:04,  1.53s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:46<01:05,  1.60s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:47<01:00,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:49<01:02,  1.60s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:51<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:52<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:54<00:57,  1.59s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:55<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:57<00:52,  1.53s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:58<00:49,  1.49s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:00<00:51,  1.59s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:02<00:52,  1.69s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:04<00:51,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:05<00:46,  1.61s/it]predicting train subjects:  90%|█████████ | 257/285 [07:07<00:44,  1.58s/it]predicting train subjects:  91%|█████████ | 258/285 [07:08<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [07:10<00:43,  1.66s/it]predicting train subjects:  91%|█████████ | 260/285 [07:11<00:39,  1.57s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:13<00:36,  1.54s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:14<00:34,  1.51s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:16<00:33,  1.52s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:18<00:34,  1.65s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:20<00:34,  1.73s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:21<00:31,  1.64s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:23<00:28,  1.58s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:24<00:28,  1.65s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:26<00:26,  1.68s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:28<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:29<00:21,  1.57s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:31<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:32<00:18,  1.54s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:34<00:16,  1.50s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:35<00:16,  1.61s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:37<00:15,  1.69s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:39<00:12,  1.62s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:40<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:42<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:43<00:07,  1.58s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:45<00:06,  1.58s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:46<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:48<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:50<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [07:52<00:00,  1.79s/it]
Epoch 00065: val_mDice did not improve from 0.57787
Restoring model weights from the end of the best epoch
Epoch 00065: early stopping
{'val_loss': [3.6771558125813804, 3.2322158813476562, 1.4956513359433128, 1.2420732180277507, 1.286965461004348, 1.0914877709888278, 1.1411222957429432, 1.0423508144560314, 1.0175459214619227, 1.0188732203983126, 1.010250897634597, 1.0440370355333601, 1.0772957234155565, 1.0345354534330822, 1.0221002783094133, 1.0021467662992931, 1.0063868363698323, 0.9822635196504139, 0.9750607240767706, 0.9722565696353004, 0.940264622370402, 0.9302499861944289, 0.9563601244063604, 0.9035732235227313, 0.8858871062596639, 0.9323627040499732, 0.9068074226379395, 0.9485567751384917, 0.8872126908529372, 0.8650022347768148, 0.8997152873447963, 0.9100566591535296, 0.867010548001244, 0.846664621716454, 0.8756783860070365, 0.8556235915138608, 0.8589677243005662, 0.8979703244708833, 0.8774535883040655, 1.010285048257737, 0.8238800196420579, 0.8418671630677723, 0.8480707236698696, 0.8872673511505127, 0.8716579051244826, 0.8267163095020112, 0.9023778438568115, 0.8789624146052769, 0.8876725094658988, 0.8489639418465751, 0.8184059801555815, 0.7781904822304135, 0.8413931926091512, 0.791582221076602, 0.8558798971630278, 0.8010236365454537, 0.8686787968590146, 0.7864291440872919, 0.8255422228858584, 0.7796484629313151, 0.8210920833405995, 0.8572562876201811, 0.7962208361852736, 0.8028623944237119, 0.7584260418301537], 'val_acc': [0.9032989797138032, 0.9117467829159328, 0.9226625306265694, 0.9300572304498582, 0.9273557492664882, 0.9394894440968832, 0.9273213999611991, 0.9394619919004894, 0.9420055207752046, 0.9413599173227946, 0.9408104419708252, 0.9373283159165156, 0.9329029179754711, 0.9362408405258542, 0.9407669504483541, 0.9384363804544721, 0.9392468134562174, 0.9412042044457936, 0.944047592935108, 0.940354877994174, 0.9450732639857701, 0.9409661094347636, 0.9429418331100827, 0.9429029027620951, 0.9432326072738284, 0.9427678670201983, 0.9441300602186293, 0.9451282024383545, 0.9398053941272554, 0.9446130990982056, 0.9428708808762687, 0.9441552133787245, 0.9412751907394046, 0.9439125231334141, 0.9442193139167059, 0.9455929710751488, 0.9369436899820963, 0.9436652660369873, 0.9399702634130206, 0.9361607035001119, 0.9442559537433443, 0.9454052221207392, 0.944940501735324, 0.94138046673366, 0.9393223240261986, 0.945112182980492, 0.9409455373173669, 0.9422230039324079, 0.9429349700609843, 0.9370650194940113, 0.9388415813446045, 0.9433379144895644, 0.9410622545651027, 0.9438393059230986, 0.9399381819225493, 0.9405334364800226, 0.9461859124047416, 0.944072791508266, 0.9419849117596945, 0.9436859091122946, 0.9379166818800426, 0.941078279699598, 0.9461080517087664, 0.9450915540967669, 0.9420100762730553], 'val_mDice': [0.09112374645857406, 0.159666524949855, 0.3575991503894329, 0.4961881036204951, 0.4645449398528962, 0.5488334849831604, 0.5321007885393643, 0.561963157639617, 0.5721018605289006, 0.5702959872072652, 0.5719550377911046, 0.5621300281158516, 0.5451097332295918, 0.5537597357871986, 0.5573909630378088, 0.5532847612741447, 0.5614340759458996, 0.5592471863187495, 0.5546521480594363, 0.5738429212499232, 0.5681569405964443, 0.5586019672808193, 0.5562988129400072, 0.5743656577098937, 0.5778749336798986, 0.546430113769713, 0.5624682988439288, 0.5617855778407483, 0.568322764266105, 0.5750735228260359, 0.5614073223301342, 0.5449954828336125, 0.5767318134506544, 0.5750386782345318, 0.5735320191653002, 0.5685306771525315, 0.5713914796000436, 0.560844346703518, 0.5747579087813696, 0.5426832937768528, 0.5753026860100883, 0.5575199212346759, 0.5644574420792716, 0.5673861368781045, 0.5661358290484974, 0.571951628795692, 0.5634422896518594, 0.56193300620431, 0.5723140450815359, 0.565801332394282, 0.566307753856693, 0.5659239907704648, 0.5709596180490085, 0.5418995047609011, 0.551571096337977, 0.5742760277574971, 0.565356947659027, 0.5671391809980074, 0.566634513437748, 0.5649950438666911, 0.5645303282709349, 0.5647499454872948, 0.5666549581856954, 0.5603327375082743, 0.5578113563713574], 'loss': [2.9285634731726997, 1.1935767511745075, 0.8009272234757465, 0.6652974868546981, 0.5955128810620386, 0.5533458559136641, 0.5213148048876889, 0.4971350358933044, 0.47778336271422434, 0.4615980981631341, 0.4470854607969666, 0.4378770777996229, 0.4258766699002753, 0.41864418173332724, 0.4105006586684872, 0.40315795311905733, 0.3993221358605288, 0.39583824452279226, 0.39115973765252066, 0.38639159087779, 0.38079675730423407, 0.38120266593488533, 0.3764347434560986, 0.37125242450505247, 0.36762394296863254, 0.36544387623687824, 0.3637052429119976, 0.3625334029152188, 0.3591428078252823, 0.356672167588411, 0.35423771084124855, 0.3516666387601558, 0.3488509991689755, 0.350662290561583, 0.346808603010082, 0.3451495744002125, 0.3407062094853245, 0.34110213667642686, 0.3392212638534147, 0.3392851038868082, 0.3352783990085573, 0.33381488624509875, 0.33242883533095724, 0.331980171847348, 0.33090892523751225, 0.3302474849734758, 0.32987001272830885, 0.3252501191087649, 0.32419986578456145, 0.3246559265814973, 0.32422338512584103, 0.32326776338538293, 0.319108799321127, 0.3198433393328457, 0.3186640682157487, 0.31628561697301316, 0.31636112449783704, 0.31641160319116685, 0.31594916170379295, 0.313819413599261, 0.3138664961148485, 0.31214337116127094, 0.31204072718839093, 0.3087329486327891, 0.30959988335596017], 'acc': [0.6179468894575932, 0.8840464931336905, 0.8981895394837303, 0.9065605731674167, 0.9126719584670948, 0.9174222076056389, 0.9215695009609397, 0.9241590229261122, 0.926064815828284, 0.9278738171994078, 0.9290455944946742, 0.9303757743681927, 0.9315079247443598, 0.9320844455171647, 0.9329837407476529, 0.9334950226911902, 0.9338745612709284, 0.9342273522691964, 0.9346821437871178, 0.9352450104423495, 0.935755113887033, 0.935975153516983, 0.9360375790116138, 0.9364810138509893, 0.9367696710788425, 0.937133723896134, 0.9372456441593005, 0.9373159217930999, 0.9376377787161636, 0.9378264444123028, 0.938169550925568, 0.9386974043507831, 0.9386006816058161, 0.9385850444473419, 0.9389019639983397, 0.9391366245430836, 0.9394865209871986, 0.9394750032370689, 0.9395556646503878, 0.9395941102667905, 0.93995725890219, 0.9401315316451591, 0.9401093342870974, 0.940313639819151, 0.9403014521688906, 0.9403684899966473, 0.9404035933748108, 0.9409184011393529, 0.9407809434402234, 0.9409195111623867, 0.9409724846496641, 0.9410214926756622, 0.941421832701869, 0.941391985931676, 0.941564381478815, 0.9416755403032738, 0.9417585201959332, 0.9415584088337083, 0.941718201382624, 0.9419270257442379, 0.9418868921339477, 0.9420546349795172, 0.942107186247118, 0.9424926717432566, 0.9423352194724112], 'mDice': [0.10185000397328159, 0.31716204337676596, 0.43939088269168985, 0.5012671448762922, 0.5370308146877557, 0.5603198265326099, 0.5791085202017799, 0.5935294814070272, 0.6052991406338877, 0.6154270136381634, 0.6246764544740173, 0.6309904976343406, 0.6386125024996305, 0.6433171680696627, 0.6485822165956933, 0.6535395705127661, 0.6561983598204782, 0.6585122616230833, 0.6617514694819497, 0.6650277729413172, 0.668740404463467, 0.6686549900537376, 0.6717828708460778, 0.6753082845352141, 0.6777825375869138, 0.6793494462874989, 0.6806214152674972, 0.6814330776509508, 0.6837671559418192, 0.6854500019047011, 0.6871890517036786, 0.6891202744845597, 0.6909817784697145, 0.6898596918442724, 0.6925280006699004, 0.693777346314551, 0.6968660634309082, 0.696626088477661, 0.6979008258158976, 0.6979354068748933, 0.7008431314479783, 0.7018607207201385, 0.7029342239868762, 0.703194424553094, 0.7039654519554736, 0.7044686802049029, 0.7047228982436168, 0.7081549096962425, 0.7088008029212238, 0.708489897498419, 0.7088214286104065, 0.7095223769806979, 0.7126188543873851, 0.712183295060197, 0.7129774363440357, 0.7146997319978626, 0.7145639706007291, 0.714556578774431, 0.7149718479428053, 0.7164949009775633, 0.7165135182648558, 0.7177721872043812, 0.7178298850291172, 0.7202813377126647, 0.719618912650506]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment:
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:32,  1.80s/it]Loading train:   1%|          | 2/285 [00:03<07:57,  1.69s/it]Loading train:   1%|          | 3/285 [00:04<07:57,  1.69s/it]Loading train:   1%|▏         | 4/285 [00:06<07:21,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:07<07:26,  1.60s/it]Loading train:   2%|▏         | 6/285 [00:09<07:06,  1.53s/it]Loading train:   2%|▏         | 7/285 [00:10<07:17,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<07:17,  1.58s/it]Loading train:   3%|▎         | 9/285 [00:14<07:57,  1.73s/it]Loading train:   4%|▎         | 10/285 [00:16<07:42,  1.68s/it]Loading train:   4%|▍         | 11/285 [00:17<06:58,  1.53s/it]Loading train:   4%|▍         | 12/285 [00:18<06:34,  1.44s/it]Loading train:   5%|▍         | 13/285 [00:19<05:50,  1.29s/it]Loading train:   5%|▍         | 14/285 [00:20<05:49,  1.29s/it]Loading train:   5%|▌         | 15/285 [00:22<06:05,  1.35s/it]Loading train:   6%|▌         | 16/285 [00:23<06:14,  1.39s/it]Loading train:   6%|▌         | 17/285 [00:24<05:39,  1.27s/it]Loading train:   6%|▋         | 18/285 [00:26<05:43,  1.29s/it]Loading train:   7%|▋         | 19/285 [00:27<05:22,  1.21s/it]Loading train:   7%|▋         | 20/285 [00:28<05:23,  1.22s/it]Loading train:   7%|▋         | 21/285 [00:29<05:39,  1.28s/it]Loading train:   8%|▊         | 22/285 [00:30<05:08,  1.17s/it]Loading train:   8%|▊         | 23/285 [00:32<05:24,  1.24s/it]Loading train:   8%|▊         | 24/285 [00:33<05:18,  1.22s/it]Loading train:   9%|▉         | 25/285 [00:34<05:37,  1.30s/it]Loading train:   9%|▉         | 26/285 [00:35<05:32,  1.28s/it]Loading train:   9%|▉         | 27/285 [00:37<05:20,  1.24s/it]Loading train:  10%|▉         | 28/285 [00:38<05:26,  1.27s/it]Loading train:  10%|█         | 29/285 [00:39<05:24,  1.27s/it]Loading train:  11%|█         | 30/285 [00:41<05:43,  1.35s/it]Loading train:  11%|█         | 31/285 [00:42<05:53,  1.39s/it]Loading train:  11%|█         | 32/285 [00:43<05:27,  1.29s/it]Loading train:  12%|█▏        | 33/285 [00:44<05:00,  1.19s/it]Loading train:  12%|█▏        | 34/285 [00:45<04:53,  1.17s/it]Loading train:  12%|█▏        | 35/285 [00:47<05:09,  1.24s/it]Loading train:  13%|█▎        | 36/285 [00:48<05:16,  1.27s/it]Loading train:  13%|█▎        | 37/285 [00:49<05:09,  1.25s/it]Loading train:  13%|█▎        | 38/285 [00:51<05:24,  1.31s/it]Loading train:  14%|█▎        | 39/285 [00:52<05:06,  1.24s/it]Loading train:  14%|█▍        | 40/285 [00:53<05:12,  1.28s/it]Loading train:  14%|█▍        | 41/285 [00:54<05:00,  1.23s/it]Loading train:  15%|█▍        | 42/285 [00:55<04:36,  1.14s/it]Loading train:  15%|█▌        | 43/285 [00:56<04:33,  1.13s/it]Loading train:  15%|█▌        | 44/285 [00:58<04:44,  1.18s/it]Loading train:  16%|█▌        | 45/285 [00:59<04:43,  1.18s/it]Loading train:  16%|█▌        | 46/285 [01:00<04:50,  1.21s/it]Loading train:  16%|█▋        | 47/285 [01:01<04:23,  1.11s/it]Loading train:  17%|█▋        | 48/285 [01:02<04:37,  1.17s/it]Loading train:  17%|█▋        | 49/285 [01:04<04:51,  1.24s/it]Loading train:  18%|█▊        | 50/285 [01:05<04:47,  1.22s/it]Loading train:  18%|█▊        | 51/285 [01:06<04:57,  1.27s/it]Loading train:  18%|█▊        | 52/285 [01:07<04:44,  1.22s/it]Loading train:  19%|█▊        | 53/285 [01:09<04:54,  1.27s/it]Loading train:  19%|█▉        | 54/285 [01:10<04:56,  1.28s/it]Loading train:  19%|█▉        | 55/285 [01:11<04:33,  1.19s/it]Loading train:  20%|█▉        | 56/285 [01:12<04:34,  1.20s/it]Loading train:  20%|██        | 57/285 [01:13<04:22,  1.15s/it]Loading train:  20%|██        | 58/285 [01:15<04:21,  1.15s/it]Loading train:  21%|██        | 59/285 [01:16<04:30,  1.20s/it]Loading train:  21%|██        | 60/285 [01:17<04:49,  1.29s/it]Loading train:  21%|██▏       | 61/285 [01:18<04:33,  1.22s/it]Loading train:  22%|██▏       | 62/285 [01:20<04:28,  1.20s/it]Loading train:  22%|██▏       | 63/285 [01:21<04:20,  1.17s/it]Loading train:  22%|██▏       | 64/285 [01:22<04:39,  1.26s/it]Loading train:  23%|██▎       | 65/285 [01:24<05:14,  1.43s/it]Loading train:  23%|██▎       | 66/285 [01:26<05:32,  1.52s/it]Loading train:  24%|██▎       | 67/285 [01:27<05:08,  1.42s/it]Loading train:  24%|██▍       | 68/285 [01:28<05:03,  1.40s/it]Loading train:  24%|██▍       | 69/285 [01:29<04:50,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:31<04:41,  1.31s/it]Loading train:  25%|██▍       | 71/285 [01:32<04:46,  1.34s/it]Loading train:  25%|██▌       | 72/285 [01:33<04:28,  1.26s/it]Loading train:  26%|██▌       | 73/285 [01:34<04:23,  1.24s/it]Loading train:  26%|██▌       | 74/285 [01:35<04:09,  1.18s/it]Loading train:  26%|██▋       | 75/285 [01:37<04:12,  1.20s/it]Loading train:  27%|██▋       | 76/285 [01:38<04:18,  1.24s/it]Loading train:  27%|██▋       | 77/285 [01:39<04:20,  1.25s/it]Loading train:  27%|██▋       | 78/285 [01:40<04:04,  1.18s/it]Loading train:  28%|██▊       | 79/285 [01:42<04:12,  1.23s/it]Loading train:  28%|██▊       | 80/285 [01:43<04:04,  1.19s/it]Loading train:  28%|██▊       | 81/285 [01:44<04:03,  1.19s/it]Loading train:  29%|██▉       | 82/285 [01:45<04:01,  1.19s/it]Loading train:  29%|██▉       | 83/285 [01:46<03:54,  1.16s/it]Loading train:  29%|██▉       | 84/285 [01:47<04:01,  1.20s/it]Loading train:  30%|██▉       | 85/285 [01:49<04:03,  1.22s/it]Loading train:  30%|███       | 86/285 [01:50<04:17,  1.29s/it]Loading train:  31%|███       | 87/285 [01:52<04:27,  1.35s/it]Loading train:  31%|███       | 88/285 [01:53<04:30,  1.37s/it]Loading train:  31%|███       | 89/285 [01:54<04:29,  1.38s/it]Loading train:  32%|███▏      | 90/285 [01:56<04:25,  1.36s/it]Loading train:  32%|███▏      | 91/285 [01:57<04:13,  1.31s/it]Loading train:  32%|███▏      | 92/285 [01:58<04:15,  1.32s/it]Loading train:  33%|███▎      | 93/285 [01:59<04:03,  1.27s/it]Loading train:  33%|███▎      | 94/285 [02:01<04:10,  1.31s/it]Loading train:  33%|███▎      | 95/285 [02:02<04:12,  1.33s/it]Loading train:  34%|███▎      | 96/285 [02:03<04:03,  1.29s/it]Loading train:  34%|███▍      | 97/285 [02:05<04:04,  1.30s/it]Loading train:  34%|███▍      | 98/285 [02:06<03:57,  1.27s/it]Loading train:  35%|███▍      | 99/285 [02:07<03:52,  1.25s/it]Loading train:  35%|███▌      | 100/285 [02:08<03:53,  1.26s/it]Loading train:  35%|███▌      | 101/285 [02:10<03:41,  1.20s/it]Loading train:  36%|███▌      | 102/285 [02:11<03:40,  1.20s/it]Loading train:  36%|███▌      | 103/285 [02:12<03:46,  1.24s/it]Loading train:  36%|███▋      | 104/285 [02:13<03:45,  1.25s/it]Loading train:  37%|███▋      | 105/285 [02:15<03:42,  1.24s/it]Loading train:  37%|███▋      | 106/285 [02:16<03:34,  1.20s/it]Loading train:  38%|███▊      | 107/285 [02:17<03:26,  1.16s/it]Loading train:  38%|███▊      | 108/285 [02:18<03:22,  1.14s/it]Loading train:  38%|███▊      | 109/285 [02:19<03:24,  1.16s/it]Loading train:  39%|███▊      | 110/285 [02:20<03:25,  1.18s/it]Loading train:  39%|███▉      | 111/285 [02:21<03:20,  1.15s/it]Loading train:  39%|███▉      | 112/285 [02:23<03:28,  1.20s/it]Loading train:  40%|███▉      | 113/285 [02:24<03:32,  1.24s/it]Loading train:  40%|████      | 114/285 [02:25<03:36,  1.27s/it]Loading train:  40%|████      | 115/285 [02:26<03:27,  1.22s/it]Loading train:  41%|████      | 116/285 [02:28<03:19,  1.18s/it]Loading train:  41%|████      | 117/285 [02:29<03:27,  1.23s/it]Loading train:  41%|████▏     | 118/285 [02:30<03:37,  1.30s/it]Loading train:  42%|████▏     | 119/285 [02:32<03:46,  1.36s/it]Loading train:  42%|████▏     | 120/285 [02:33<03:42,  1.35s/it]Loading train:  42%|████▏     | 121/285 [02:35<03:49,  1.40s/it]Loading train:  43%|████▎     | 122/285 [02:36<03:41,  1.36s/it]Loading train:  43%|████▎     | 123/285 [02:37<03:46,  1.40s/it]Loading train:  44%|████▎     | 124/285 [02:39<03:31,  1.31s/it]Loading train:  44%|████▍     | 125/285 [02:40<03:25,  1.29s/it]Loading train:  44%|████▍     | 126/285 [02:41<03:14,  1.23s/it]Loading train:  45%|████▍     | 127/285 [02:42<02:58,  1.13s/it]Loading train:  45%|████▍     | 128/285 [02:43<02:54,  1.11s/it]Loading train:  45%|████▌     | 129/285 [02:44<02:53,  1.11s/it]Loading train:  46%|████▌     | 130/285 [02:45<02:49,  1.09s/it]Loading train:  46%|████▌     | 131/285 [02:46<02:43,  1.06s/it]Loading train:  46%|████▋     | 132/285 [02:47<02:44,  1.08s/it]Loading train:  47%|████▋     | 133/285 [02:48<02:43,  1.08s/it]Loading train:  47%|████▋     | 134/285 [02:49<02:47,  1.11s/it]Loading train:  47%|████▋     | 135/285 [02:50<02:39,  1.06s/it]Loading train:  48%|████▊     | 136/285 [02:51<02:42,  1.09s/it]Loading train:  48%|████▊     | 137/285 [02:53<02:44,  1.11s/it]Loading train:  48%|████▊     | 138/285 [02:54<02:44,  1.12s/it]Loading train:  49%|████▉     | 139/285 [02:55<02:38,  1.09s/it]Loading train:  49%|████▉     | 140/285 [02:56<02:30,  1.04s/it]Loading train:  49%|████▉     | 141/285 [02:57<02:30,  1.05s/it]Loading train:  50%|████▉     | 142/285 [02:58<02:28,  1.04s/it]Loading train:  50%|█████     | 143/285 [02:59<02:25,  1.02s/it]Loading train:  51%|█████     | 144/285 [03:00<02:21,  1.01s/it]Loading train:  51%|█████     | 145/285 [03:01<02:25,  1.04s/it]Loading train:  51%|█████     | 146/285 [03:02<02:32,  1.10s/it]Loading train:  52%|█████▏    | 147/285 [03:03<02:28,  1.08s/it]Loading train:  52%|█████▏    | 148/285 [03:04<02:24,  1.06s/it]Loading train:  52%|█████▏    | 149/285 [03:05<02:22,  1.05s/it]Loading train:  53%|█████▎    | 150/285 [03:06<02:21,  1.05s/it]Loading train:  53%|█████▎    | 151/285 [03:07<02:24,  1.08s/it]Loading train:  53%|█████▎    | 152/285 [03:09<02:27,  1.11s/it]Loading train:  54%|█████▎    | 153/285 [03:10<02:32,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:11<02:32,  1.17s/it]Loading train:  54%|█████▍    | 155/285 [03:13<02:50,  1.31s/it]Loading train:  55%|█████▍    | 156/285 [03:14<02:45,  1.28s/it]Loading train:  55%|█████▌    | 157/285 [03:15<02:44,  1.29s/it]Loading train:  55%|█████▌    | 158/285 [03:17<02:54,  1.37s/it]Loading train:  56%|█████▌    | 159/285 [03:19<03:19,  1.58s/it]Loading train:  56%|█████▌    | 160/285 [03:21<03:23,  1.63s/it]Loading train:  56%|█████▋    | 161/285 [03:22<03:15,  1.58s/it]Loading train:  57%|█████▋    | 162/285 [03:24<03:13,  1.57s/it]Loading train:  57%|█████▋    | 163/285 [03:25<02:58,  1.47s/it]Loading train:  58%|█████▊    | 164/285 [03:27<03:09,  1.57s/it]Loading train:  58%|█████▊    | 165/285 [03:28<03:09,  1.58s/it]Loading train:  58%|█████▊    | 166/285 [03:30<03:00,  1.52s/it]Loading train:  59%|█████▊    | 167/285 [03:31<03:00,  1.53s/it]Loading train:  59%|█████▉    | 168/285 [03:32<02:53,  1.48s/it]Loading train:  59%|█████▉    | 169/285 [03:34<02:59,  1.54s/it]Loading train:  60%|█████▉    | 170/285 [03:36<02:59,  1.56s/it]Loading train:  60%|██████    | 171/285 [03:37<02:59,  1.58s/it]Loading train:  60%|██████    | 172/285 [03:39<03:03,  1.62s/it]Loading train:  61%|██████    | 173/285 [03:41<02:55,  1.57s/it]Loading train:  61%|██████    | 174/285 [03:42<02:43,  1.47s/it]Loading train:  61%|██████▏   | 175/285 [03:44<02:55,  1.60s/it]Loading train:  62%|██████▏   | 176/285 [03:45<02:54,  1.60s/it]Loading train:  62%|██████▏   | 177/285 [03:47<02:51,  1.58s/it]Loading train:  62%|██████▏   | 178/285 [03:48<02:50,  1.59s/it]Loading train:  63%|██████▎   | 179/285 [03:50<02:39,  1.50s/it]Loading train:  63%|██████▎   | 180/285 [03:51<02:28,  1.41s/it]Loading train:  64%|██████▎   | 181/285 [03:52<02:27,  1.42s/it]Loading train:  64%|██████▍   | 182/285 [03:54<02:40,  1.56s/it]Loading train:  64%|██████▍   | 183/285 [03:56<02:36,  1.53s/it]Loading train:  65%|██████▍   | 184/285 [03:57<02:28,  1.47s/it]Loading train:  65%|██████▍   | 185/285 [03:59<02:31,  1.51s/it]Loading train:  65%|██████▌   | 186/285 [04:00<02:29,  1.51s/it]Loading train:  66%|██████▌   | 187/285 [04:02<02:37,  1.60s/it]Loading train:  66%|██████▌   | 188/285 [04:04<02:44,  1.70s/it]Loading train:  66%|██████▋   | 189/285 [04:05<02:31,  1.58s/it]Loading train:  67%|██████▋   | 190/285 [04:07<02:23,  1.52s/it]Loading train:  67%|██████▋   | 191/285 [04:08<02:27,  1.57s/it]Loading train:  67%|██████▋   | 192/285 [04:10<02:37,  1.69s/it]Loading train:  68%|██████▊   | 193/285 [04:12<02:35,  1.69s/it]Loading train:  68%|██████▊   | 194/285 [04:13<02:28,  1.63s/it]Loading train:  68%|██████▊   | 195/285 [04:15<02:22,  1.58s/it]Loading train:  69%|██████▉   | 196/285 [04:16<02:20,  1.58s/it]Loading train:  69%|██████▉   | 197/285 [04:18<02:22,  1.62s/it]Loading train:  69%|██████▉   | 198/285 [04:21<02:39,  1.83s/it]Loading train:  70%|██████▉   | 199/285 [04:22<02:36,  1.82s/it]Loading train:  70%|███████   | 200/285 [04:24<02:23,  1.69s/it]Loading train:  71%|███████   | 201/285 [04:25<02:19,  1.66s/it]Loading train:  71%|███████   | 202/285 [04:27<02:10,  1.57s/it]Loading train:  71%|███████   | 203/285 [04:28<02:02,  1.49s/it]Loading train:  72%|███████▏  | 204/285 [04:29<01:56,  1.44s/it]Loading train:  72%|███████▏  | 205/285 [04:31<01:54,  1.43s/it]Loading train:  72%|███████▏  | 206/285 [04:32<01:49,  1.39s/it]Loading train:  73%|███████▎  | 207/285 [04:34<01:53,  1.45s/it]Loading train:  73%|███████▎  | 208/285 [04:35<02:00,  1.56s/it]Loading train:  73%|███████▎  | 209/285 [04:37<02:03,  1.63s/it]Loading train:  74%|███████▎  | 210/285 [04:39<02:02,  1.63s/it]Loading train:  74%|███████▍  | 211/285 [04:40<01:59,  1.61s/it]Loading train:  74%|███████▍  | 212/285 [04:42<01:52,  1.54s/it]Loading train:  75%|███████▍  | 213/285 [04:43<01:47,  1.49s/it]Loading train:  75%|███████▌  | 214/285 [04:44<01:43,  1.45s/it]Loading train:  75%|███████▌  | 215/285 [04:46<01:49,  1.56s/it]Loading train:  76%|███████▌  | 216/285 [04:48<01:40,  1.46s/it]Loading train:  76%|███████▌  | 217/285 [04:49<01:47,  1.58s/it]Loading train:  76%|███████▋  | 218/285 [04:51<01:46,  1.60s/it]Loading train:  77%|███████▋  | 219/285 [04:52<01:39,  1.51s/it]Loading train:  77%|███████▋  | 220/285 [04:54<01:35,  1.47s/it]Loading train:  78%|███████▊  | 221/285 [04:56<01:42,  1.60s/it]Loading train:  78%|███████▊  | 222/285 [04:57<01:41,  1.61s/it]Loading train:  78%|███████▊  | 223/285 [04:59<01:40,  1.63s/it]Loading train:  79%|███████▊  | 224/285 [05:01<01:40,  1.65s/it]Loading train:  79%|███████▉  | 225/285 [05:02<01:34,  1.58s/it]Loading train:  79%|███████▉  | 226/285 [05:03<01:28,  1.51s/it]Loading train:  80%|███████▉  | 227/285 [05:05<01:30,  1.56s/it]Loading train:  80%|████████  | 228/285 [05:07<01:37,  1.70s/it]Loading train:  80%|████████  | 229/285 [05:09<01:39,  1.78s/it]Loading train:  81%|████████  | 230/285 [05:11<01:35,  1.73s/it]Loading train:  81%|████████  | 231/285 [05:12<01:31,  1.69s/it]Loading train:  81%|████████▏ | 232/285 [05:14<01:30,  1.70s/it]Loading train:  82%|████████▏ | 233/285 [05:16<01:28,  1.69s/it]Loading train:  82%|████████▏ | 234/285 [05:17<01:26,  1.69s/it]Loading train:  82%|████████▏ | 235/285 [05:19<01:19,  1.58s/it]Loading train:  83%|████████▎ | 236/285 [05:20<01:19,  1.63s/it]Loading train:  83%|████████▎ | 237/285 [05:22<01:16,  1.59s/it]Loading train:  84%|████████▎ | 238/285 [05:24<01:23,  1.78s/it]Loading train:  84%|████████▍ | 239/285 [05:26<01:22,  1.79s/it]Loading train:  84%|████████▍ | 240/285 [05:27<01:15,  1.69s/it]Loading train:  85%|████████▍ | 241/285 [05:29<01:15,  1.71s/it]Loading train:  85%|████████▍ | 242/285 [05:31<01:10,  1.64s/it]Loading train:  85%|████████▌ | 243/285 [05:32<01:08,  1.63s/it]Loading train:  86%|████████▌ | 244/285 [05:34<01:06,  1.63s/it]Loading train:  86%|████████▌ | 245/285 [05:36<01:05,  1.64s/it]Loading train:  86%|████████▋ | 246/285 [05:37<01:06,  1.71s/it]Loading train:  87%|████████▋ | 247/285 [05:39<01:08,  1.79s/it]Loading train:  87%|████████▋ | 248/285 [05:41<01:06,  1.81s/it]Loading train:  87%|████████▋ | 249/285 [05:43<01:03,  1.77s/it]Loading train:  88%|████████▊ | 250/285 [05:45<01:00,  1.72s/it]Loading train:  88%|████████▊ | 251/285 [05:46<00:55,  1.64s/it]Loading train:  88%|████████▊ | 252/285 [05:47<00:48,  1.46s/it]Loading train:  89%|████████▉ | 253/285 [05:49<00:52,  1.64s/it]Loading train:  89%|████████▉ | 254/285 [05:52<00:58,  1.89s/it]Loading train:  89%|████████▉ | 255/285 [05:54<01:01,  2.04s/it]Loading train:  90%|████████▉ | 256/285 [05:56<00:55,  1.93s/it]Loading train:  90%|█████████ | 257/285 [05:58<00:53,  1.92s/it]Loading train:  91%|█████████ | 258/285 [06:00<00:54,  2.02s/it]Loading train:  91%|█████████ | 259/285 [06:02<00:56,  2.17s/it]Loading train:  91%|█████████ | 260/285 [06:04<00:49,  1.98s/it]Loading train:  92%|█████████▏| 261/285 [06:05<00:43,  1.82s/it]Loading train:  92%|█████████▏| 262/285 [06:07<00:40,  1.77s/it]Loading train:  92%|█████████▏| 263/285 [06:09<00:41,  1.87s/it]Loading train:  93%|█████████▎| 264/285 [06:11<00:41,  1.98s/it]Loading train:  93%|█████████▎| 265/285 [06:13<00:38,  1.94s/it]Loading train:  93%|█████████▎| 266/285 [06:15<00:36,  1.91s/it]Loading train:  94%|█████████▎| 267/285 [06:17<00:33,  1.88s/it]Loading train:  94%|█████████▍| 268/285 [06:19<00:31,  1.86s/it]Loading train:  94%|█████████▍| 269/285 [06:20<00:28,  1.76s/it]Loading train:  95%|█████████▍| 270/285 [06:22<00:26,  1.77s/it]Loading train:  95%|█████████▌| 271/285 [06:24<00:24,  1.75s/it]Loading train:  95%|█████████▌| 272/285 [06:26<00:25,  1.93s/it]Loading train:  96%|█████████▌| 273/285 [06:28<00:22,  1.92s/it]Loading train:  96%|█████████▌| 274/285 [06:29<00:19,  1.79s/it]Loading train:  96%|█████████▋| 275/285 [06:32<00:19,  1.91s/it]Loading train:  97%|█████████▋| 276/285 [06:33<00:16,  1.84s/it]Loading train:  97%|█████████▋| 277/285 [06:35<00:14,  1.82s/it]Loading train:  98%|█████████▊| 278/285 [06:37<00:12,  1.80s/it]Loading train:  98%|█████████▊| 279/285 [06:38<00:10,  1.70s/it]Loading train:  98%|█████████▊| 280/285 [06:40<00:08,  1.74s/it]Loading train:  99%|█████████▊| 281/285 [06:41<00:06,  1.65s/it]Loading train:  99%|█████████▉| 282/285 [06:43<00:04,  1.62s/it]Loading train:  99%|█████████▉| 283/285 [06:45<00:03,  1.72s/it]Loading train: 100%|█████████▉| 284/285 [06:47<00:01,  1.82s/it]Loading train: 100%|██████████| 285/285 [06:49<00:00,  1.85s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:16, 16.78it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:15, 17.95it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:12, 21.51it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:10, 26.77it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:07, 34.15it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:07, 34.42it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:07, 34.49it/s]concatenating: train:  15%|█▍        | 42/285 [00:01<00:07, 31.19it/s]concatenating: train:  16%|█▌        | 46/285 [00:01<00:07, 30.08it/s]concatenating: train:  18%|█▊        | 50/285 [00:01<00:08, 28.85it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:08, 26.91it/s]concatenating: train:  20%|██        | 58/285 [00:01<00:08, 27.16it/s]concatenating: train:  21%|██▏       | 61/285 [00:01<00:08, 26.47it/s]concatenating: train:  22%|██▏       | 64/285 [00:01<00:09, 23.13it/s]concatenating: train:  24%|██▎       | 67/285 [00:02<00:09, 22.80it/s]concatenating: train:  25%|██▍       | 70/285 [00:02<00:09, 23.86it/s]concatenating: train:  26%|██▌       | 73/285 [00:02<00:09, 22.66it/s]concatenating: train:  27%|██▋       | 76/285 [00:02<00:09, 21.14it/s]concatenating: train:  30%|██▉       | 85/285 [00:02<00:07, 27.14it/s]concatenating: train:  32%|███▏      | 92/285 [00:02<00:05, 32.69it/s]concatenating: train:  35%|███▍      | 99/285 [00:02<00:04, 38.15it/s]concatenating: train:  37%|███▋      | 106/285 [00:03<00:04, 41.96it/s]concatenating: train:  39%|███▉      | 112/285 [00:03<00:04, 35.36it/s]concatenating: train:  41%|████      | 117/285 [00:03<00:05, 31.69it/s]concatenating: train:  42%|████▏     | 121/285 [00:03<00:05, 31.26it/s]concatenating: train:  44%|████▍     | 125/285 [00:03<00:05, 30.68it/s]concatenating: train:  46%|████▌     | 130/285 [00:03<00:04, 34.42it/s]concatenating: train:  48%|████▊     | 137/285 [00:03<00:03, 40.05it/s]concatenating: train:  50%|████▉     | 142/285 [00:04<00:04, 31.14it/s]concatenating: train:  51%|█████     | 146/285 [00:04<00:04, 28.72it/s]concatenating: train:  53%|█████▎    | 152/285 [00:04<00:03, 33.59it/s]concatenating: train:  55%|█████▌    | 158/285 [00:04<00:03, 37.29it/s]concatenating: train:  57%|█████▋    | 163/285 [00:04<00:03, 36.48it/s]concatenating: train:  59%|█████▉    | 168/285 [00:04<00:03, 33.34it/s]concatenating: train:  60%|██████    | 172/285 [00:05<00:03, 32.69it/s]concatenating: train:  62%|██████▏   | 176/285 [00:05<00:03, 32.56it/s]concatenating: train:  63%|██████▎   | 180/285 [00:05<00:03, 28.33it/s]concatenating: train:  65%|██████▍   | 184/285 [00:05<00:04, 24.63it/s]concatenating: train:  66%|██████▌   | 187/285 [00:05<00:04, 23.57it/s]concatenating: train:  67%|██████▋   | 191/285 [00:05<00:03, 26.02it/s]concatenating: train:  68%|██████▊   | 195/285 [00:05<00:03, 28.60it/s]concatenating: train:  70%|██████▉   | 199/285 [00:06<00:03, 26.12it/s]concatenating: train:  71%|███████   | 202/285 [00:06<00:03, 26.89it/s]concatenating: train:  72%|███████▏  | 206/285 [00:06<00:02, 27.60it/s]concatenating: train:  74%|███████▎  | 210/285 [00:06<00:02, 28.12it/s]concatenating: train:  75%|███████▍  | 213/285 [00:06<00:02, 25.19it/s]concatenating: train:  76%|███████▌  | 216/285 [00:06<00:02, 23.70it/s]concatenating: train:  78%|███████▊  | 222/285 [00:06<00:02, 28.95it/s]concatenating: train:  82%|████████▏ | 235/285 [00:06<00:01, 37.50it/s]concatenating: train:  87%|████████▋ | 248/285 [00:07<00:00, 47.24it/s]concatenating: train:  92%|█████████▏| 261/285 [00:07<00:00, 58.08it/s]concatenating: train:  95%|█████████▌| 271/285 [00:07<00:00, 64.38it/s]concatenating: train:  99%|█████████▊| 281/285 [00:07<00:00, 65.41it/s]concatenating: train: 100%|██████████| 285/285 [00:07<00:00, 37.86it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]Loading test:  67%|██████▋   | 2/3 [00:04<00:02,  2.25s/it]Loading test: 100%|██████████| 3/3 [00:06<00:00,  2.19s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 21.56it/s]2019-07-11 04:05:08.397112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:05:08.397206: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:05:08.397220: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:05:08.397229: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:05:08.397664: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.38it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.30it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.28it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  5.13it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.00it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.35it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:08,  3.80it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  5.07it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:04,  5.68it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.00it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:06,  3.70it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:04,  4.52it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:03,  5.36it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  5.20it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.04it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.81it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:05<00:01,  5.66it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  5.54it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.68it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:06<00:00,  5.03it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  3.00it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  6.41it/s] exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 20)   10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 80)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 242,573
Trainable params: 67,773
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 26s - loss: 1.6638 - acc: 0.7938 - mDice: 0.2985 - val_loss: 0.5593 - val_acc: 0.9406 - val_mDice: 0.5620

Epoch 00001: val_mDice improved from -inf to 0.56200, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 0.4958 - acc: 0.9307 - mDice: 0.5956 - val_loss: 0.4404 - val_acc: 0.9518 - val_mDice: 0.6342

Epoch 00002: val_mDice improved from 0.56200 to 0.63417, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 17s - loss: 0.4189 - acc: 0.9419 - mDice: 0.6435 - val_loss: 0.4478 - val_acc: 0.9534 - val_mDice: 0.6285

Epoch 00003: val_mDice did not improve from 0.63417
Epoch 4/300
 - 18s - loss: 0.3879 - acc: 0.9456 - mDice: 0.6643 - val_loss: 0.4503 - val_acc: 0.9533 - val_mDice: 0.6286

Epoch 00004: val_mDice did not improve from 0.63417
Epoch 5/300
 - 17s - loss: 0.3646 - acc: 0.9475 - mDice: 0.6802 - val_loss: 0.4669 - val_acc: 0.9484 - val_mDice: 0.6177

Epoch 00005: val_mDice did not improve from 0.63417
Epoch 6/300
 - 18s - loss: 0.3536 - acc: 0.9484 - mDice: 0.6881 - val_loss: 0.4626 - val_acc: 0.9513 - val_mDice: 0.6232

Epoch 00006: val_mDice did not improve from 0.63417
Epoch 7/300
 - 16s - loss: 0.3402 - acc: 0.9495 - mDice: 0.6976 - val_loss: 0.4622 - val_acc: 0.9536 - val_mDice: 0.6217

Epoch 00007: val_mDice did not improve from 0.63417
Epoch 8/300
 - 16s - loss: 0.3298 - acc: 0.9502 - mDice: 0.7050 - val_loss: 0.4805 - val_acc: 0.9519 - val_mDice: 0.6119

Epoch 00008: val_mDice did not improve from 0.63417
Epoch 9/300
 - 14s - loss: 0.3241 - acc: 0.9506 - mDice: 0.7091 - val_loss: 0.4569 - val_acc: 0.9544 - val_mDice: 0.6311

Epoch 00009: val_mDice did not improve from 0.63417
Epoch 10/300
 - 14s - loss: 0.3182 - acc: 0.9511 - mDice: 0.7136 - val_loss: 0.4674 - val_acc: 0.9530 - val_mDice: 0.6201

Epoch 00010: val_mDice did not improve from 0.63417
Epoch 11/300
 - 15s - loss: 0.3121 - acc: 0.9515 - mDice: 0.7184 - val_loss: 0.4785 - val_acc: 0.9541 - val_mDice: 0.6161

Epoch 00011: val_mDice did not improve from 0.63417
Epoch 12/300
 - 14s - loss: 0.3069 - acc: 0.9519 - mDice: 0.7222 - val_loss: 0.4556 - val_acc: 0.9530 - val_mDice: 0.6242

Epoch 00012: val_mDice did not improve from 0.63417
Epoch 13/300
 - 14s - loss: 0.3008 - acc: 0.9524 - mDice: 0.7265 - val_loss: 0.4644 - val_acc: 0.9531 - val_mDice: 0.6214

Epoch 00013: val_mDice did not improve from 0.63417
Epoch 14/300
 - 14s - loss: 0.2971 - acc: 0.9526 - mDice: 0.7294 - val_loss: 0.4824 - val_acc: 0.9532 - val_mDice: 0.6093

Epoch 00014: val_mDice did not improve from 0.63417
Epoch 15/300
 - 15s - loss: 0.2936 - acc: 0.9528 - mDice: 0.7321 - val_loss: 0.4427 - val_acc: 0.9538 - val_mDice: 0.6333

Epoch 00015: val_mDice did not improve from 0.63417
Epoch 16/300
 - 14s - loss: 0.2913 - acc: 0.9530 - mDice: 0.7339 - val_loss: 0.4875 - val_acc: 0.9516 - val_mDice: 0.6087

Epoch 00016: val_mDice did not improve from 0.63417
Epoch 17/300
 - 14s - loss: 0.2874 - acc: 0.9533 - mDice: 0.7369 - val_loss: 0.4562 - val_acc: 0.9542 - val_mDice: 0.6252

Epoch 00017: val_mDice did not improve from 0.63417
Epoch 18/300
 - 14s - loss: 0.2824 - acc: 0.9536 - mDice: 0.7406 - val_loss: 0.4489 - val_acc: 0.9534 - val_mDice: 0.6293

Epoch 00018: val_mDice did not improve from 0.63417
Epoch 19/300
 - 14s - loss: 0.2806 - acc: 0.9538 - mDice: 0.7420 - val_loss: 0.4623 - val_acc: 0.9525 - val_mDice: 0.6230

Epoch 00019: val_mDice did not improve from 0.63417
Epoch 20/300
 - 14s - loss: 0.2776 - acc: 0.9540 - mDice: 0.7443 - val_loss: 0.4551 - val_acc: 0.9503 - val_mDice: 0.6259

Epoch 00020: val_mDice did not improve from 0.63417
Epoch 21/300
 - 14s - loss: 0.2768 - acc: 0.9541 - mDice: 0.7451 - val_loss: 0.4638 - val_acc: 0.9525 - val_mDice: 0.6235

Epoch 00021: val_mDice did not improve from 0.63417
Epoch 22/300
 - 15s - loss: 0.2729 - acc: 0.9543 - mDice: 0.7481 - val_loss: 0.4548 - val_acc: 0.9514 - val_mDice: 0.6258

Epoch 00022: val_mDice did not improve from 0.63417
Epoch 23/300
 - 14s - loss: 0.2707 - acc: 0.9545 - mDice: 0.7497 - val_loss: 0.4540 - val_acc: 0.9519 - val_mDice: 0.6270

Epoch 00023: val_mDice did not improve from 0.63417
Epoch 24/300
 - 14s - loss: 0.2677 - acc: 0.9547 - mDice: 0.7520 - val_loss: 0.4440 - val_acc: 0.9548 - val_mDice: 0.6327

Epoch 00024: val_mDice did not improve from 0.63417
Epoch 25/300
 - 14s - loss: 0.2661 - acc: 0.9548 - mDice: 0.7533 - val_loss: 0.4652 - val_acc: 0.9540 - val_mDice: 0.6195

Epoch 00025: val_mDice did not improve from 0.63417
Epoch 26/300
 - 14s - loss: 0.2645 - acc: 0.9549 - mDice: 0.7546 - val_loss: 0.4522 - val_acc: 0.9518 - val_mDice: 0.6286

Epoch 00026: val_mDice did not improve from 0.63417
Epoch 27/300
 - 14s - loss: 0.2629 - acc: 0.9551 - mDice: 0.7559 - val_loss: 0.4525 - val_acc: 0.9529 - val_mDice: 0.6278

Epoch 00027: val_mDice did not improve from 0.63417
Epoch 28/300
 - 14s - loss: 0.2613 - acc: 0.9552 - mDice: 0.7571 - val_loss: 0.4658 - val_acc: 0.9492 - val_mDice: 0.6211

Epoch 00028: val_mDice did not improve from 0.63417
Epoch 29/300
 - 14s - loss: 0.2589 - acc: 0.9553 - mDice: 0.7591 - val_loss: 0.4510 - val_acc: 0.9523 - val_mDice: 0.6272

Epoch 00029: val_mDice did not improve from 0.63417
Epoch 30/300
 - 15s - loss: 0.2574 - acc: 0.9555 - mDice: 0.7603 - val_loss: 0.4579 - val_acc: 0.9534 - val_mDice: 0.6260

Epoch 00030: val_mDice did not improve from 0.63417
Epoch 31/300
 - 14s - loss: 0.2554 - acc: 0.9556 - mDice: 0.7617 - val_loss: 0.4584 - val_acc: 0.9529 - val_mDice: 0.6234

Epoch 00031: val_mDice did not improve from 0.63417
Epoch 32/300
 - 14s - loss: 0.2541 - acc: 0.9557 - mDice: 0.7629 - val_loss: 0.4656 - val_acc: 0.9529 - val_mDice: 0.6180

Epoch 00032: val_mDice did not improve from 0.63417
Epoch 33/300
 - 14s - loss: 0.2540 - acc: 0.9557 - mDice: 0.7629 - val_loss: 0.4650 - val_acc: 0.9482 - val_mDice: 0.6186

Epoch 00033: val_mDice did not improve from 0.63417
Epoch 34/300
 - 14s - loss: 0.2517 - acc: 0.9559 - mDice: 0.7648 - val_loss: 0.4582 - val_acc: 0.9528 - val_mDice: 0.6252

Epoch 00034: val_mDice did not improve from 0.63417
Epoch 35/300
 - 14s - loss: 0.2500 - acc: 0.9560 - mDice: 0.7661 - val_loss: 0.4515 - val_acc: 0.9541 - val_mDice: 0.6282

Epoch 00035: val_mDice did not improve from 0.63417
Epoch 36/300
 - 15s - loss: 0.2498 - acc: 0.9560 - mDice: 0.7662 - val_loss: 0.4596 - val_acc: 0.9527 - val_mDice: 0.6228

Epoch 00036: val_mDice did not improve from 0.63417
Epoch 37/300
 - 14s - loss: 0.2483 - acc: 0.9562 - mDice: 0.7674 - val_loss: 0.4548 - val_acc: 0.9542 - val_mDice: 0.6260

Epoch 00037: val_mDice did not improve from 0.63417
Epoch 38/300
 - 14s - loss: 0.2459 - acc: 0.9563 - mDice: 0.7694 - val_loss: 0.4628 - val_acc: 0.9517 - val_mDice: 0.6212

Epoch 00038: val_mDice did not improve from 0.63417
Epoch 39/300
 - 14s - loss: 0.2480 - acc: 0.9562 - mDice: 0.7677 - val_loss: 0.4643 - val_acc: 0.9526 - val_mDice: 0.6199

Epoch 00039: val_mDice did not improve from 0.63417
Epoch 40/300
 - 14s - loss: 0.2440 - acc: 0.9565 - mDice: 0.7711 - val_loss: 0.4543 - val_acc: 0.9528 - val_mDice: 0.6262

Epoch 00040: val_mDice did not improve from 0.63417
Epoch 41/300
 - 14s - loss: 0.2432 - acc: 0.9565 - mDice: 0.7716 - val_loss: 0.4516 - val_acc: 0.9530 - val_mDice: 0.6262

Epoch 00041: val_mDice did not improve from 0.63417
Epoch 42/300
 - 15s - loss: 0.2433 - acc: 0.9565 - mDice: 0.7716 - val_loss: 0.4563 - val_acc: 0.9520 - val_mDice: 0.6259

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.38s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.13s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:47,  1.86s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:12,  1.74s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:09,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:50,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:08,  1.75s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:51,  1.69s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:04,  1.74s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:58,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:30,  1.85s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:48,  1.92s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:30,  1.86s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:50,  1.94s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:24,  1.85s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:22,  1.85s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:39,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:49,  1.97s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:22,  1.87s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:20,  1.87s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<07:58,  1.80s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<07:56,  1.80s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:20,  1.90s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<07:55,  1.81s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:10,  1.87s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:55,  1.82s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:16,  1.91s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:22,  1.94s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:54,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<07:53,  1.84s/it]predicting train subjects:  10%|█         | 29/285 [00:53<07:52,  1.84s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:15,  1.94s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:24,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:56,  1.88s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:54,  1.88s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:46,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:00,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:38,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:42,  1.86s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:55,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:35,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:21,  1.81s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:19,  1.81s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:21,  1.83s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:40,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:17,  1.82s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:27,  1.87s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:09,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:09,  1.81s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:29,  1.91s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:24,  1.89s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:39,  1.96s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:14,  1.86s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:28,  1.94s/it]predicting train subjects:  19%|█▉        | 55/285 [01:42<07:11,  1.88s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:09,  1.87s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:50,  1.80s/it]predicting train subjects:  20%|██        | 58/285 [01:47<07:00,  1.85s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:20,  1.95s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:34,  2.02s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<07:13,  1.94s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<07:16,  1.96s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<07:09,  1.94s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<07:13,  1.97s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<07:19,  2.01s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<07:13,  1.99s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<07:02,  1.94s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:59,  1.94s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:56,  1.94s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:55,  1.94s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:42,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:16<06:42,  1.90s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:51,  1.95s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:51,  1.96s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:50,  1.96s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:37,  1.91s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:25,  1.86s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:23,  1.86s/it]predicting train subjects:  28%|██▊       | 80/285 [02:30<06:22,  1.86s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<06:13,  1.84s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<06:08,  1.83s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:03,  1.81s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:08,  1.84s/it]predicting train subjects:  30%|███       | 86/285 [02:41<06:14,  1.88s/it]predicting train subjects:  31%|███       | 87/285 [02:43<06:20,  1.92s/it]predicting train subjects:  31%|███       | 88/285 [02:44<06:07,  1.87s/it]predicting train subjects:  31%|███       | 89/285 [02:46<06:10,  1.89s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<06:11,  1.91s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<06:03,  1.87s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<06:10,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [02:54<05:58,  1.87s/it]predicting train subjects:  33%|███▎      | 94/285 [02:56<05:54,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:58<06:02,  1.91s/it]predicting train subjects:  34%|███▎      | 96/285 [03:00<06:01,  1.91s/it]predicting train subjects:  34%|███▍      | 97/285 [03:02<06:03,  1.93s/it]predicting train subjects:  34%|███▍      | 98/285 [03:04<06:05,  1.95s/it]predicting train subjects:  35%|███▍      | 99/285 [03:06<06:03,  1.95s/it]predicting train subjects:  35%|███▌      | 100/285 [03:08<06:02,  1.96s/it]predicting train subjects:  35%|███▌      | 101/285 [03:09<05:52,  1.92s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:58,  1.96s/it]predicting train subjects:  36%|███▌      | 103/285 [03:13<05:47,  1.91s/it]predicting train subjects:  36%|███▋      | 104/285 [03:15<05:48,  1.92s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:47,  1.93s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:32,  1.86s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:35,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:23<05:32,  1.88s/it]predicting train subjects:  38%|███▊      | 109/285 [03:25<05:33,  1.89s/it]predicting train subjects:  39%|███▊      | 110/285 [03:27<05:31,  1.90s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:27,  1.88s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:31,  1.92s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:30,  1.92s/it]predicting train subjects:  40%|████      | 114/285 [03:34<05:28,  1.92s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:27,  1.93s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:26,  1.93s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:18,  1.90s/it]predicting train subjects:  41%|████▏     | 118/285 [03:42<05:12,  1.87s/it]predicting train subjects:  42%|████▏     | 119/285 [03:44<05:14,  1.89s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:06,  1.86s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:48,  1.77s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:37,  1.71s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:35,  1.71s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:28,  1.68s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:23,  1.66s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:19,  1.64s/it]predicting train subjects:  45%|████▍     | 128/285 [03:59<04:22,  1.67s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:19,  1.66s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:13,  1.63s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:05,  1.60s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:09,  1.63s/it]predicting train subjects:  47%|████▋     | 133/285 [04:07<04:07,  1.63s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<04:08,  1.65s/it]predicting train subjects:  47%|████▋     | 135/285 [04:10<03:59,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:56,  1.59s/it]predicting train subjects:  48%|████▊     | 137/285 [04:13<04:04,  1.65s/it]predicting train subjects:  48%|████▊     | 138/285 [04:15<03:59,  1.63s/it]predicting train subjects:  49%|████▉     | 139/285 [04:17<04:05,  1.68s/it]predicting train subjects:  49%|████▉     | 140/285 [04:18<04:06,  1.70s/it]predicting train subjects:  49%|████▉     | 141/285 [04:20<03:57,  1.65s/it]predicting train subjects:  50%|████▉     | 142/285 [04:22<03:55,  1.65s/it]predicting train subjects:  50%|█████     | 143/285 [04:23<03:51,  1.63s/it]predicting train subjects:  51%|█████     | 144/285 [04:25<03:56,  1.68s/it]predicting train subjects:  51%|█████     | 145/285 [04:27<03:55,  1.68s/it]predicting train subjects:  51%|█████     | 146/285 [04:28<03:55,  1.70s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:30<03:47,  1.65s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:32<03:54,  1.71s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:33<03:45,  1.66s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:35<03:40,  1.63s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:37<03:44,  1.67s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:38<03:36,  1.63s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:40<03:33,  1.62s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:41<03:35,  1.64s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:43<03:31,  1.63s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:45<03:34,  1.66s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:46<03:29,  1.64s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:48<03:29,  1.65s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:50<03:23,  1.62s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:51<03:20,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:53<03:22,  1.63s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:54<03:18,  1.62s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:56<03:20,  1.64s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:58<03:18,  1.64s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:59<03:12,  1.61s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:01<03:19,  1.67s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:03<03:18,  1.68s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:04<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:06<03:09,  1.63s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:08<03:05,  1.61s/it]predicting train subjects:  60%|██████    | 171/285 [05:09<03:04,  1.62s/it]predicting train subjects:  60%|██████    | 172/285 [05:11<03:05,  1.64s/it]predicting train subjects:  61%|██████    | 173/285 [05:12<03:00,  1.61s/it]predicting train subjects:  61%|██████    | 174/285 [05:14<02:59,  1.61s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:16<03:07,  1.71s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:18<03:07,  1.72s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:19<02:57,  1.65s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:21<02:51,  1.60s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:22<02:49,  1.60s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:24<03:02,  1.74s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:26<03:04,  1.77s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:28<03:02,  1.77s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:30<02:53,  1.70s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:31<02:49,  1.68s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:33<02:44,  1.65s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:35<02:54,  1.77s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:37<03:00,  1.84s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:39<03:03,  1.89s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:40<02:49,  1.77s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:42<02:41,  1.70s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:44<02:43,  1.74s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:46<02:46,  1.79s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:47<02:37,  1.71s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:49<02:32,  1.68s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:50<02:26,  1.63s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:52<02:36,  1.76s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:54<02:41,  1.83s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:56<02:40,  1.84s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:58<02:31,  1.76s/it]predicting train subjects:  70%|███████   | 200/285 [05:59<02:24,  1.70s/it]predicting train subjects:  71%|███████   | 201/285 [06:01<02:26,  1.75s/it]predicting train subjects:  71%|███████   | 202/285 [06:03<02:26,  1.76s/it]predicting train subjects:  71%|███████   | 203/285 [06:05<02:27,  1.80s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:06<02:19,  1.72s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:08<02:12,  1.66s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:09<02:09,  1.64s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:11<02:13,  1.71s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:13<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:15<02:19,  1.84s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:17<02:10,  1.74s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:18<02:04,  1.68s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:20<02:07,  1.75s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:22<02:06,  1.75s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:23<01:59,  1.68s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:25<02:02,  1.75s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:27<01:56,  1.69s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:29<02:03,  1.81s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:31<02:06,  1.88s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:33<02:05,  1.90s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:35<01:57,  1.80s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:36<01:50,  1.72s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:38<01:49,  1.74s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:40<01:46,  1.71s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:41<01:42,  1.67s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:43<01:37,  1.63s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:45<01:44,  1.77s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:47<01:46,  1.84s/it]predicting train subjects:  80%|████████  | 228/285 [06:49<01:47,  1.89s/it]predicting train subjects:  80%|████████  | 229/285 [06:51<01:44,  1.86s/it]predicting train subjects:  81%|████████  | 230/285 [06:52<01:36,  1.76s/it]predicting train subjects:  81%|████████  | 231/285 [06:54<01:30,  1.68s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:55<01:31,  1.72s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:57<01:26,  1.67s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:59<01:29,  1.75s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:00<01:24,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:03<01:28,  1.81s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:04<01:28,  1.85s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:06<01:28,  1.89s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:08<01:24,  1.84s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:10<01:18,  1.75s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:11<01:14,  1.69s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:13<01:10,  1.64s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:14<01:08,  1.62s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:16<01:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:18<01:05,  1.64s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:20<01:07,  1.73s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:22<01:08,  1.81s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:23<01:07,  1.82s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:25<01:02,  1.74s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:27<00:59,  1.69s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:28<00:55,  1.64s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:30<00:52,  1.58s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:32<00:54,  1.69s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:33<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:35<00:52,  1.77s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:37<00:48,  1.69s/it]predicting train subjects:  90%|█████████ | 257/285 [07:38<00:46,  1.65s/it]predicting train subjects:  91%|█████████ | 258/285 [07:40<00:46,  1.72s/it]predicting train subjects:  91%|█████████ | 259/285 [07:42<00:45,  1.74s/it]predicting train subjects:  91%|█████████ | 260/285 [07:44<00:42,  1.69s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:45<00:40,  1.67s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:47<00:37,  1.62s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:48<00:34,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:50<00:35,  1.69s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:52<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:54<00:32,  1.72s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:55<00:30,  1.67s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:57<00:29,  1.75s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:59<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:01<00:26,  1.74s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:02<00:23,  1.68s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:04<00:22,  1.74s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:06<00:20,  1.68s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:07<00:17,  1.62s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:09<00:17,  1.72s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:11<00:15,  1.76s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:12<00:13,  1.68s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:14<00:11,  1.62s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:16<00:09,  1.65s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:17<00:08,  1.65s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:19<00:06,  1.59s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:20<00:04,  1.55s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:22<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:24<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 285/285 [08:26<00:00,  1.86s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:41,  1.63s/it]Loading train:   1%|          | 2/285 [00:02<07:17,  1.55s/it]Loading train:   1%|          | 3/285 [00:04<07:16,  1.55s/it]Loading train:   1%|▏         | 4/285 [00:05<06:45,  1.44s/it]Loading train:   2%|▏         | 5/285 [00:07<06:47,  1.46s/it]Loading train:   2%|▏         | 6/285 [00:08<06:31,  1.40s/it]Loading train:   2%|▏         | 7/285 [00:10<06:40,  1.44s/it]Loading train:   3%|▎         | 8/285 [00:11<06:31,  1.41s/it]Loading train:   3%|▎         | 9/285 [00:13<07:02,  1.53s/it]Loading train:   4%|▎         | 10/285 [00:14<06:39,  1.45s/it]Loading train:   4%|▍         | 11/285 [00:15<06:00,  1.31s/it]Loading train:   4%|▍         | 12/285 [00:16<05:53,  1.30s/it]Loading train:   5%|▍         | 13/285 [00:17<05:36,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:18<05:23,  1.19s/it]Loading train:   5%|▌         | 15/285 [00:20<05:19,  1.18s/it]Loading train:   6%|▌         | 16/285 [00:21<05:23,  1.20s/it]Loading train:   6%|▌         | 17/285 [00:22<04:57,  1.11s/it]Loading train:   6%|▋         | 18/285 [00:23<04:48,  1.08s/it]Loading train:   7%|▋         | 19/285 [00:24<04:51,  1.09s/it]Loading train:   7%|▋         | 20/285 [00:25<04:46,  1.08s/it]Loading train:   7%|▋         | 21/285 [00:26<05:14,  1.19s/it]Loading train:   8%|▊         | 22/285 [00:27<04:55,  1.12s/it]Loading train:   8%|▊         | 23/285 [00:28<04:45,  1.09s/it]Loading train:   8%|▊         | 24/285 [00:29<04:39,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:30<04:36,  1.06s/it]Loading train:   9%|▉         | 26/285 [00:32<04:44,  1.10s/it]Loading train:   9%|▉         | 27/285 [00:33<05:07,  1.19s/it]Loading train:  10%|▉         | 28/285 [00:34<04:53,  1.14s/it]Loading train:  10%|█         | 29/285 [00:35<04:50,  1.14s/it]Loading train:  11%|█         | 30/285 [00:36<04:59,  1.17s/it]Loading train:  11%|█         | 31/285 [00:37<04:46,  1.13s/it]Loading train:  11%|█         | 32/285 [00:39<04:49,  1.14s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:36,  1.10s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:40,  1.12s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:42,  1.13s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:34,  1.10s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:38,  1.12s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:49,  1.17s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:34,  1.12s/it]Loading train:  14%|█▍        | 40/285 [00:47<04:32,  1.11s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:32,  1.12s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:29,  1.11s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:21,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:33,  1.14s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:17,  1.07s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:27,  1.12s/it]Loading train:  16%|█▋        | 47/285 [00:55<04:18,  1.08s/it]Loading train:  17%|█▋        | 48/285 [00:56<04:21,  1.10s/it]Loading train:  17%|█▋        | 49/285 [00:57<04:25,  1.12s/it]Loading train:  18%|█▊        | 50/285 [00:58<04:11,  1.07s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:01,  1.03s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:06,  1.06s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:18,  1.12s/it]Loading train:  19%|█▉        | 54/285 [01:03<04:28,  1.16s/it]Loading train:  19%|█▉        | 55/285 [01:04<04:13,  1.10s/it]Loading train:  20%|█▉        | 56/285 [01:05<04:10,  1.09s/it]Loading train:  20%|██        | 57/285 [01:06<03:50,  1.01s/it]Loading train:  20%|██        | 58/285 [01:07<03:58,  1.05s/it]Loading train:  21%|██        | 59/285 [01:08<03:54,  1.04s/it]Loading train:  21%|██        | 60/285 [01:09<04:20,  1.16s/it]Loading train:  21%|██▏       | 61/285 [01:10<04:12,  1.13s/it]Loading train:  22%|██▏       | 62/285 [01:12<04:09,  1.12s/it]Loading train:  22%|██▏       | 63/285 [01:13<04:11,  1.13s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:31,  1.23s/it]Loading train:  23%|██▎       | 65/285 [01:16<05:05,  1.39s/it]Loading train:  23%|██▎       | 66/285 [01:18<05:17,  1.45s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:57,  1.37s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:32,  1.26s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:11,  1.16s/it]Loading train:  25%|██▍       | 70/285 [01:22<03:57,  1.11s/it]Loading train:  25%|██▍       | 71/285 [01:23<03:55,  1.10s/it]Loading train:  25%|██▌       | 72/285 [01:23<03:32,  1.00it/s]Loading train:  26%|██▌       | 73/285 [01:25<03:33,  1.01s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:42,  1.06s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:35,  1.03s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:41,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:21,  1.03it/s]Loading train:  27%|██▋       | 78/285 [01:29<03:18,  1.04it/s]Loading train:  28%|██▊       | 79/285 [01:30<03:21,  1.02it/s]Loading train:  28%|██▊       | 80/285 [01:32<03:42,  1.09s/it]Loading train:  28%|██▊       | 81/285 [01:33<03:31,  1.04s/it]Loading train:  29%|██▉       | 82/285 [01:34<03:41,  1.09s/it]Loading train:  29%|██▉       | 83/285 [01:35<03:29,  1.03s/it]Loading train:  29%|██▉       | 84/285 [01:36<03:30,  1.05s/it]Loading train:  30%|██▉       | 85/285 [01:37<03:36,  1.08s/it]Loading train:  30%|███       | 86/285 [01:38<03:37,  1.09s/it]Loading train:  31%|███       | 87/285 [01:39<03:37,  1.10s/it]Loading train:  31%|███       | 88/285 [01:40<03:24,  1.04s/it]Loading train:  31%|███       | 89/285 [01:41<03:20,  1.02s/it]Loading train:  32%|███▏      | 90/285 [01:42<03:21,  1.03s/it]Loading train:  32%|███▏      | 91/285 [01:43<03:22,  1.04s/it]Loading train:  32%|███▏      | 92/285 [01:44<03:22,  1.05s/it]Loading train:  33%|███▎      | 93/285 [01:45<03:12,  1.00s/it]Loading train:  33%|███▎      | 94/285 [01:46<03:06,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:47<03:17,  1.04s/it]Loading train:  34%|███▎      | 96/285 [01:48<03:18,  1.05s/it]Loading train:  34%|███▍      | 97/285 [01:50<03:17,  1.05s/it]Loading train:  34%|███▍      | 98/285 [01:51<03:12,  1.03s/it]Loading train:  35%|███▍      | 99/285 [01:52<03:18,  1.07s/it]Loading train:  35%|███▌      | 100/285 [01:53<03:37,  1.18s/it]Loading train:  35%|███▌      | 101/285 [01:55<03:49,  1.25s/it]Loading train:  36%|███▌      | 102/285 [01:56<04:08,  1.36s/it]Loading train:  36%|███▌      | 103/285 [01:58<04:12,  1.39s/it]Loading train:  36%|███▋      | 104/285 [02:00<04:47,  1.59s/it]Loading train:  37%|███▋      | 105/285 [02:01<04:40,  1.56s/it]Loading train:  37%|███▋      | 106/285 [02:02<04:21,  1.46s/it]Loading train:  38%|███▊      | 107/285 [02:04<04:24,  1.49s/it]Loading train:  38%|███▊      | 108/285 [02:05<04:09,  1.41s/it]Loading train:  38%|███▊      | 109/285 [02:07<04:06,  1.40s/it]Loading train:  39%|███▊      | 110/285 [02:08<04:10,  1.43s/it]Loading train:  39%|███▉      | 111/285 [02:10<04:14,  1.46s/it]Loading train:  39%|███▉      | 112/285 [02:11<04:09,  1.44s/it]Loading train:  40%|███▉      | 113/285 [02:12<04:03,  1.41s/it]Loading train:  40%|████      | 114/285 [02:14<04:07,  1.45s/it]Loading train:  40%|████      | 115/285 [02:15<04:07,  1.45s/it]Loading train:  41%|████      | 116/285 [02:17<04:17,  1.52s/it]Loading train:  41%|████      | 117/285 [02:18<04:12,  1.51s/it]Loading train:  41%|████▏     | 118/285 [02:20<04:29,  1.61s/it]Loading train:  42%|████▏     | 119/285 [02:22<04:39,  1.68s/it]Loading train:  42%|████▏     | 120/285 [02:24<04:26,  1.62s/it]Loading train:  42%|████▏     | 121/285 [02:26<04:46,  1.75s/it]Loading train:  43%|████▎     | 122/285 [02:27<04:46,  1.76s/it]Loading train:  43%|████▎     | 123/285 [02:30<05:08,  1.91s/it]Loading train:  44%|████▎     | 124/285 [02:31<04:56,  1.84s/it]Loading train:  44%|████▍     | 125/285 [02:33<04:26,  1.67s/it]Loading train:  44%|████▍     | 126/285 [02:34<04:04,  1.54s/it]Loading train:  45%|████▍     | 127/285 [02:35<04:00,  1.52s/it]Loading train:  45%|████▍     | 128/285 [02:37<04:06,  1.57s/it]Loading train:  45%|████▌     | 129/285 [02:39<04:00,  1.54s/it]Loading train:  46%|████▌     | 130/285 [02:40<03:53,  1.50s/it]Loading train:  46%|████▌     | 131/285 [02:41<03:46,  1.47s/it]Loading train:  46%|████▋     | 132/285 [02:43<03:39,  1.44s/it]Loading train:  47%|████▋     | 133/285 [02:44<03:27,  1.37s/it]Loading train:  47%|████▋     | 134/285 [02:45<03:32,  1.40s/it]Loading train:  47%|████▋     | 135/285 [02:47<03:43,  1.49s/it]Loading train:  48%|████▊     | 136/285 [02:49<03:51,  1.55s/it]Loading train:  48%|████▊     | 137/285 [02:50<03:36,  1.46s/it]Loading train:  48%|████▊     | 138/285 [02:51<03:11,  1.30s/it]Loading train:  49%|████▉     | 139/285 [02:52<03:08,  1.29s/it]Loading train:  49%|████▉     | 140/285 [02:54<03:22,  1.40s/it]Loading train:  49%|████▉     | 141/285 [02:55<03:26,  1.43s/it]Loading train:  50%|████▉     | 142/285 [02:57<03:22,  1.41s/it]Loading train:  50%|█████     | 143/285 [02:58<03:10,  1.34s/it]Loading train:  51%|█████     | 144/285 [02:59<03:15,  1.39s/it]Loading train:  51%|█████     | 145/285 [03:01<03:15,  1.40s/it]Loading train:  51%|█████     | 146/285 [03:02<03:08,  1.36s/it]Loading train:  52%|█████▏    | 147/285 [03:03<03:02,  1.33s/it]Loading train:  52%|█████▏    | 148/285 [03:05<03:04,  1.35s/it]Loading train:  52%|█████▏    | 149/285 [03:06<02:56,  1.29s/it]Loading train:  53%|█████▎    | 150/285 [03:07<03:01,  1.35s/it]Loading train:  53%|█████▎    | 151/285 [03:09<03:13,  1.44s/it]Loading train:  53%|█████▎    | 152/285 [03:10<03:06,  1.40s/it]Loading train:  54%|█████▎    | 153/285 [03:12<03:04,  1.40s/it]Loading train:  54%|█████▍    | 154/285 [03:14<03:29,  1.60s/it]Loading train:  54%|█████▍    | 155/285 [03:15<03:25,  1.58s/it]Loading train:  55%|█████▍    | 156/285 [03:17<03:09,  1.47s/it]Loading train:  55%|█████▌    | 157/285 [03:18<03:06,  1.45s/it]Loading train:  55%|█████▌    | 158/285 [03:20<03:14,  1.53s/it]Loading train:  56%|█████▌    | 159/285 [03:21<03:19,  1.59s/it]Loading train:  56%|█████▌    | 160/285 [03:23<03:10,  1.52s/it]Loading train:  56%|█████▋    | 161/285 [03:25<03:25,  1.66s/it]Loading train:  57%|█████▋    | 162/285 [03:26<03:22,  1.65s/it]Loading train:  57%|█████▋    | 163/285 [03:27<02:57,  1.46s/it]Loading train:  58%|█████▊    | 164/285 [03:29<02:59,  1.49s/it]Loading train:  58%|█████▊    | 165/285 [03:31<03:09,  1.58s/it]Loading train:  58%|█████▊    | 166/285 [03:32<02:59,  1.51s/it]Loading train:  59%|█████▊    | 167/285 [03:33<02:44,  1.40s/it]Loading train:  59%|█████▉    | 168/285 [03:35<02:39,  1.36s/it]Loading train:  59%|█████▉    | 169/285 [03:36<02:44,  1.42s/it]Loading train:  60%|█████▉    | 170/285 [03:38<02:48,  1.47s/it]Loading train:  60%|██████    | 171/285 [03:39<02:54,  1.53s/it]Loading train:  60%|██████    | 172/285 [03:40<02:39,  1.41s/it]Loading train:  61%|██████    | 173/285 [03:42<02:35,  1.39s/it]Loading train:  61%|██████    | 174/285 [03:43<02:36,  1.41s/it]Loading train:  61%|██████▏   | 175/285 [03:44<02:20,  1.28s/it]Loading train:  62%|██████▏   | 176/285 [03:46<02:29,  1.37s/it]Loading train:  62%|██████▏   | 177/285 [03:47<02:34,  1.43s/it]Loading train:  62%|██████▏   | 178/285 [03:48<02:17,  1.29s/it]Loading train:  63%|██████▎   | 179/285 [03:50<02:34,  1.46s/it]Loading train:  63%|██████▎   | 180/285 [03:52<02:43,  1.56s/it]Loading train:  64%|██████▎   | 181/285 [03:54<02:51,  1.65s/it]Loading train:  64%|██████▍   | 182/285 [03:55<02:38,  1.54s/it]Loading train:  64%|██████▍   | 183/285 [03:56<02:21,  1.39s/it]Loading train:  65%|██████▍   | 184/285 [03:58<02:22,  1.41s/it]Loading train:  65%|██████▍   | 185/285 [03:59<02:20,  1.41s/it]Loading train:  65%|██████▌   | 186/285 [04:01<02:29,  1.51s/it]Loading train:  66%|██████▌   | 187/285 [04:02<02:29,  1.52s/it]Loading train:  66%|██████▌   | 188/285 [04:04<02:27,  1.52s/it]Loading train:  66%|██████▋   | 189/285 [04:05<02:23,  1.49s/it]Loading train:  67%|██████▋   | 190/285 [04:07<02:15,  1.43s/it]Loading train:  67%|██████▋   | 191/285 [04:08<02:29,  1.59s/it]Loading train:  67%|██████▋   | 192/285 [04:10<02:26,  1.58s/it]Loading train:  68%|██████▊   | 193/285 [04:11<02:15,  1.47s/it]Loading train:  68%|██████▊   | 194/285 [04:13<02:16,  1.50s/it]Loading train:  68%|██████▊   | 195/285 [04:14<02:15,  1.51s/it]Loading train:  69%|██████▉   | 196/285 [04:16<02:22,  1.60s/it]Loading train:  69%|██████▉   | 197/285 [04:18<02:15,  1.55s/it]Loading train:  69%|██████▉   | 198/285 [04:19<02:17,  1.58s/it]Loading train:  70%|██████▉   | 199/285 [04:21<02:15,  1.58s/it]Loading train:  70%|███████   | 200/285 [04:23<02:23,  1.69s/it]Loading train:  71%|███████   | 201/285 [04:24<02:15,  1.61s/it]Loading train:  71%|███████   | 202/285 [04:26<02:17,  1.66s/it]Loading train:  71%|███████   | 203/285 [04:28<02:13,  1.63s/it]Loading train:  72%|███████▏  | 204/285 [04:29<02:10,  1.61s/it]Loading train:  72%|███████▏  | 205/285 [04:31<02:11,  1.64s/it]Loading train:  72%|███████▏  | 206/285 [04:32<02:05,  1.59s/it]Loading train:  73%|███████▎  | 207/285 [04:34<02:12,  1.70s/it]Loading train:  73%|███████▎  | 208/285 [04:36<02:08,  1.67s/it]Loading train:  73%|███████▎  | 209/285 [04:38<02:11,  1.73s/it]Loading train:  74%|███████▎  | 210/285 [04:39<02:06,  1.69s/it]Loading train:  74%|███████▍  | 211/285 [04:41<02:04,  1.69s/it]Loading train:  74%|███████▍  | 212/285 [04:43<02:05,  1.73s/it]Loading train:  75%|███████▍  | 213/285 [04:45<02:03,  1.72s/it]Loading train:  75%|███████▌  | 214/285 [04:46<01:55,  1.63s/it]Loading train:  75%|███████▌  | 215/285 [04:48<01:58,  1.69s/it]Loading train:  76%|███████▌  | 216/285 [04:50<01:58,  1.71s/it]Loading train:  76%|███████▌  | 217/285 [04:51<01:53,  1.67s/it]Loading train:  76%|███████▋  | 218/285 [04:53<01:54,  1.71s/it]Loading train:  77%|███████▋  | 219/285 [04:55<01:50,  1.68s/it]Loading train:  77%|███████▋  | 220/285 [04:56<01:38,  1.51s/it]Loading train:  78%|███████▊  | 221/285 [04:57<01:36,  1.50s/it]Loading train:  78%|███████▊  | 222/285 [04:58<01:27,  1.38s/it]Loading train:  78%|███████▊  | 223/285 [05:00<01:27,  1.41s/it]Loading train:  79%|███████▊  | 224/285 [05:01<01:28,  1.45s/it]Loading train:  79%|███████▉  | 225/285 [05:02<01:18,  1.30s/it]Loading train:  79%|███████▉  | 226/285 [05:04<01:21,  1.37s/it]Loading train:  80%|███████▉  | 227/285 [05:05<01:24,  1.46s/it]Loading train:  80%|████████  | 228/285 [05:07<01:27,  1.54s/it]Loading train:  80%|████████  | 229/285 [05:09<01:32,  1.66s/it]Loading train:  81%|████████  | 230/285 [05:10<01:26,  1.58s/it]Loading train:  81%|████████  | 231/285 [05:12<01:25,  1.59s/it]Loading train:  81%|████████▏ | 232/285 [05:14<01:22,  1.57s/it]Loading train:  82%|████████▏ | 233/285 [05:15<01:14,  1.43s/it]Loading train:  82%|████████▏ | 234/285 [05:16<01:15,  1.48s/it]Loading train:  82%|████████▏ | 235/285 [05:18<01:18,  1.57s/it]Loading train:  83%|████████▎ | 236/285 [05:20<01:21,  1.66s/it]Loading train:  83%|████████▎ | 237/285 [05:21<01:15,  1.57s/it]Loading train:  84%|████████▎ | 238/285 [05:23<01:21,  1.73s/it]Loading train:  84%|████████▍ | 239/285 [05:25<01:18,  1.71s/it]Loading train:  84%|████████▍ | 240/285 [05:27<01:13,  1.63s/it]Loading train:  85%|████████▍ | 241/285 [05:28<01:10,  1.61s/it]Loading train:  85%|████████▍ | 242/285 [05:29<01:03,  1.48s/it]Loading train:  85%|████████▌ | 243/285 [05:31<01:02,  1.48s/it]Loading train:  86%|████████▌ | 244/285 [05:33<01:07,  1.64s/it]Loading train:  86%|████████▌ | 245/285 [05:34<00:59,  1.50s/it]Loading train:  86%|████████▋ | 246/285 [05:36<01:03,  1.63s/it]Loading train:  87%|████████▋ | 247/285 [05:38<01:02,  1.65s/it]Loading train:  87%|████████▋ | 248/285 [05:39<00:59,  1.60s/it]Loading train:  87%|████████▋ | 249/285 [05:41<00:57,  1.61s/it]Loading train:  88%|████████▊ | 250/285 [05:42<00:52,  1.50s/it]Loading train:  88%|████████▊ | 251/285 [05:43<00:46,  1.38s/it]Loading train:  88%|████████▊ | 252/285 [05:44<00:45,  1.37s/it]Loading train:  89%|████████▉ | 253/285 [05:46<00:48,  1.51s/it]Loading train:  89%|████████▉ | 254/285 [05:48<00:48,  1.55s/it]Loading train:  89%|████████▉ | 255/285 [05:49<00:43,  1.45s/it]Loading train:  90%|████████▉ | 256/285 [05:50<00:38,  1.33s/it]Loading train:  90%|█████████ | 257/285 [05:51<00:37,  1.36s/it]Loading train:  91%|█████████ | 258/285 [05:53<00:41,  1.53s/it]Loading train:  91%|█████████ | 259/285 [05:55<00:41,  1.61s/it]Loading train:  91%|█████████ | 260/285 [05:57<00:39,  1.57s/it]Loading train:  92%|█████████▏| 261/285 [05:58<00:36,  1.51s/it]Loading train:  92%|█████████▏| 262/285 [06:00<00:35,  1.54s/it]Loading train:  92%|█████████▏| 263/285 [06:01<00:34,  1.56s/it]Loading train:  93%|█████████▎| 264/285 [06:03<00:34,  1.64s/it]Loading train:  93%|█████████▎| 265/285 [06:05<00:32,  1.62s/it]Loading train:  93%|█████████▎| 266/285 [06:06<00:27,  1.46s/it]Loading train:  94%|█████████▎| 267/285 [06:07<00:25,  1.44s/it]Loading train:  94%|█████████▍| 268/285 [06:08<00:23,  1.39s/it]Loading train:  94%|█████████▍| 269/285 [06:10<00:21,  1.37s/it]Loading train:  95%|█████████▍| 270/285 [06:11<00:19,  1.27s/it]Loading train:  95%|█████████▌| 271/285 [06:12<00:17,  1.26s/it]Loading train:  95%|█████████▌| 272/285 [06:14<00:17,  1.37s/it]Loading train:  96%|█████████▌| 273/285 [06:15<00:16,  1.37s/it]Loading train:  96%|█████████▌| 274/285 [06:16<00:14,  1.30s/it]Loading train:  96%|█████████▋| 275/285 [06:18<00:13,  1.40s/it]Loading train:  97%|█████████▋| 276/285 [06:19<00:13,  1.48s/it]Loading train:  97%|█████████▋| 277/285 [06:21<00:12,  1.57s/it]Loading train:  98%|█████████▊| 278/285 [06:23<00:10,  1.49s/it]Loading train:  98%|█████████▊| 279/285 [06:24<00:09,  1.62s/it]Loading train:  98%|█████████▊| 280/285 [06:26<00:07,  1.56s/it]Loading train:  99%|█████████▊| 281/285 [06:27<00:06,  1.56s/it]Loading train:  99%|█████████▉| 282/285 [06:29<00:04,  1.48s/it]Loading train:  99%|█████████▉| 283/285 [06:31<00:03,  1.61s/it]Loading train: 100%|█████████▉| 284/285 [06:32<00:01,  1.65s/it]Loading train: 100%|██████████| 285/285 [06:34<00:00,  1.78s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:15, 17.78it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:15, 18.60it/s]concatenating: train:   3%|▎         | 8/285 [00:00<00:13, 20.82it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:13, 20.07it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:15, 17.71it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:13, 19.87it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:13, 19.67it/s]concatenating: train:   7%|▋         | 20/285 [00:00<00:14, 18.25it/s]concatenating: train:   8%|▊         | 23/285 [00:01<00:13, 19.40it/s]concatenating: train:   9%|▉         | 27/285 [00:01<00:11, 22.63it/s]concatenating: train:  11%|█         | 32/285 [00:01<00:09, 26.73it/s]concatenating: train:  14%|█▎        | 39/285 [00:01<00:07, 32.63it/s]concatenating: train:  16%|█▋        | 47/285 [00:01<00:06, 39.66it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:04, 50.50it/s]concatenating: train:  26%|██▌       | 74/285 [00:01<00:03, 60.02it/s]concatenating: train:  29%|██▉       | 83/285 [00:02<00:04, 45.32it/s]concatenating: train:  32%|███▏      | 90/285 [00:02<00:04, 41.64it/s]concatenating: train:  34%|███▎      | 96/285 [00:02<00:05, 35.20it/s]concatenating: train:  35%|███▌      | 101/285 [00:02<00:05, 33.37it/s]concatenating: train:  37%|███▋      | 106/285 [00:02<00:05, 30.77it/s]concatenating: train:  39%|███▊      | 110/285 [00:03<00:06, 25.88it/s]concatenating: train:  40%|████      | 114/285 [00:03<00:05, 28.69it/s]concatenating: train:  42%|████▏     | 119/285 [00:03<00:05, 31.89it/s]concatenating: train:  47%|████▋     | 135/285 [00:03<00:03, 41.92it/s]concatenating: train:  58%|█████▊    | 165/285 [00:03<00:02, 56.48it/s]concatenating: train:  68%|██████▊   | 194/285 [00:03<00:01, 74.43it/s]concatenating: train:  78%|███████▊  | 223/285 [00:03<00:00, 93.08it/s]concatenating: train:  85%|████████▌ | 243/285 [00:04<00:00, 58.64it/s]concatenating: train:  91%|█████████ | 258/285 [00:05<00:00, 37.85it/s]concatenating: train:  94%|█████████▍| 269/285 [00:05<00:00, 38.11it/s]concatenating: train:  98%|█████████▊| 278/285 [00:05<00:00, 39.74it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 49.65it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.62s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.71s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.63s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 16.18it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 15.99it/s]2019-07-11 04:31:31.434195: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 04:31:31.434348: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 04:31:31.434368: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 04:31:31.434381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 04:31:31.434923: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.09it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.98it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.37it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.60it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.98it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.71it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.12it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.41it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:05,  5.19it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.77it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.02it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  6.15it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.05it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:03,  4.69it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.08it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:03,  4.24it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.48it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.21it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  5.53it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.25it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  4.77it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.72it/s]
Epoch 00042: val_mDice did not improve from 0.63417
Restoring model weights from the end of the best epoch
Epoch 00042: early stopping
{'val_loss': [0.5592657311002636, 0.4404157446749383, 0.44778130640530717, 0.4503424397393978, 0.4669297743775991, 0.462613255285018, 0.46217563365424813, 0.48049721837709736, 0.4569195185959672, 0.46735768478009954, 0.4785420211999776, 0.4555903686491471, 0.4644264066019538, 0.4824058546700291, 0.44274862118939445, 0.48747341892572754, 0.45619376678040574, 0.44886354361166503, 0.4622561961578923, 0.4551492643089934, 0.4637794864244301, 0.4547642282933496, 0.454017333478235, 0.4439993737130192, 0.46517073775136936, 0.45224477525529916, 0.45249037069981324, 0.4658119195666393, 0.45098775725124934, 0.4579155468407956, 0.45837887838566105, 0.4656291434218764, 0.46500802073398784, 0.45821701081771427, 0.45153848219184234, 0.4595532460585653, 0.4547744483255141, 0.46283805037343967, 0.46432882480781174, 0.45430476339169723, 0.45158328823537136, 0.4562581997343948], 'val_acc': [0.9406073409751807, 0.9518300887592678, 0.9534188898582032, 0.9532598326992057, 0.948367431843081, 0.9512639998057701, 0.9536316997512093, 0.9518631540197234, 0.9544023312003919, 0.9529561050777329, 0.9540779527339189, 0.9530098218491624, 0.9531317313290175, 0.9532164085510723, 0.9538279768474941, 0.9516462197516884, 0.9541916034741109, 0.9534333851084363, 0.9524602693552412, 0.9502909126894434, 0.9525428877196498, 0.9514024194392412, 0.9518776189681538, 0.9547949017093168, 0.95403251501435, 0.9518073857163584, 0.9528528252127451, 0.9492020999919103, 0.9523362830364505, 0.9534085492848018, 0.9529292303756629, 0.9528920557245862, 0.9481938344806267, 0.9528156002806552, 0.9540800445572624, 0.9527371159478939, 0.9542391216954705, 0.9516627269084227, 0.9525821681795174, 0.9527618974946731, 0.9530036146414347, 0.9519623358156428], 'val_mDice': [0.5620004757822559, 0.6341670232112181, 0.6285325029042846, 0.6285921295261916, 0.6176583570475019, 0.6231890124315657, 0.6217202341090368, 0.611910640860403, 0.6310642671318694, 0.6200951324494858, 0.6160871010252883, 0.6242098954802785, 0.6214384802892887, 0.6092973781031603, 0.6333151492992593, 0.6087025390656967, 0.6252399116921026, 0.6293474575660748, 0.6229920177486356, 0.6258656745516388, 0.6234630296350191, 0.6257993459035565, 0.6269705675167745, 0.6326951794118189, 0.6195478126323423, 0.6286241452121202, 0.6277616876463651, 0.6210803069881887, 0.6272144950301953, 0.6259875131052965, 0.6233523904278292, 0.6179732084274292, 0.6186433324600731, 0.6251809530418012, 0.6282427227696893, 0.6228220502757493, 0.6260023167013457, 0.6212046242959006, 0.6198748057115011, 0.6261713038609681, 0.6261529706043905, 0.6258916368697609], 'loss': [1.6637672912281756, 0.49579654480694074, 0.4189004565361739, 0.3878959286616107, 0.36463232946372504, 0.35357797704200833, 0.34019559958610757, 0.32978777492054795, 0.3240943175357227, 0.31817938670873913, 0.3121159335125714, 0.3068896625469949, 0.30078031793605997, 0.2971278843660382, 0.2935785521583667, 0.29132029877743376, 0.28736791824451763, 0.28237329359881974, 0.28060447554054374, 0.2775963060032353, 0.27678421070084747, 0.2728863492292371, 0.2707399229243796, 0.26773763202704165, 0.26614581860135655, 0.26445407928071846, 0.262882563658292, 0.26127400596795874, 0.2588799855558255, 0.25742645398326885, 0.2554164093652651, 0.25407426487834006, 0.2539775146504294, 0.2517017445304699, 0.24999149256909273, 0.2497560754917486, 0.24829253846507895, 0.24594290524739001, 0.24800519395982198, 0.24398720506119134, 0.2432241841722993, 0.2432800983153594], 'acc': [0.7937589573331677, 0.9306761387302026, 0.9419379731544151, 0.9456123083441951, 0.9475116526812395, 0.9483944229730094, 0.9494524925669634, 0.9501753983839906, 0.9505793834542873, 0.9510562974742721, 0.9515272727829913, 0.9519324017424163, 0.9523804780152828, 0.952627997627303, 0.9527544094212376, 0.9530461581728115, 0.9532743666103337, 0.9535752262764523, 0.9537773271751238, 0.9540121173048375, 0.9540792734208342, 0.9543482441183049, 0.9544581358653905, 0.9547123470004364, 0.9547542403235258, 0.9548953136394801, 0.955090023545968, 0.9551900457397057, 0.9553481786574786, 0.9554682221361238, 0.9556289764733805, 0.9557243055341862, 0.9557210663442589, 0.9559197620131158, 0.9560109831968571, 0.9559930787776773, 0.9561575749238445, 0.9563166562732182, 0.956197117864485, 0.9564603442337043, 0.9564718083679322, 0.9565220996774001], 'mDice': [0.298465286856258, 0.5956474021852202, 0.6435244629555918, 0.6642658501550215, 0.6802092129209905, 0.6881005950570334, 0.6976269953138304, 0.70497785072416, 0.7091251541460452, 0.7136466098658873, 0.7183521830479205, 0.7221544391254111, 0.7265473632639539, 0.7294132091382134, 0.7321140823375425, 0.7339139297457667, 0.7369367421682959, 0.7405806334344243, 0.7420126934319266, 0.7443107997667984, 0.7450967691321368, 0.748061005972185, 0.7496509667244309, 0.7520320646890492, 0.753321548876475, 0.7546010586270242, 0.7559016710740212, 0.7571229713102434, 0.7590502046381788, 0.7602601936716483, 0.7617187729802996, 0.7629186905687992, 0.762943296097221, 0.7647938859936043, 0.7660827223112313, 0.7662498146631536, 0.7674491358611015, 0.7693517134441645, 0.7677207588467759, 0.7711143450217338, 0.7715828114329558, 0.7715602907913195]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 20)   10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 80)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 242,573
Trainable params: 67,773
Non-trainable params: 174,800
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 22s - loss: 2.9957 - acc: 0.5253 - mDice: 0.0812 - val_loss: 2.9804 - val_acc: 0.9039 - val_mDice: 0.1313

Epoch 00001: val_mDice improved from -inf to 0.13134, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 1.3041 - acc: 0.8762 - mDice: 0.2776 - val_loss: 1.4310 - val_acc: 0.9068 - val_mDice: 0.3124

Epoch 00002: val_mDice improved from 0.13134 to 0.31238, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.9393 - acc: 0.8791 - mDice: 0.3807 - val_loss: 1.1530 - val_acc: 0.9066 - val_mDice: 0.3952

Epoch 00003: val_mDice improved from 0.31238 to 0.39522, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.7940 - acc: 0.8813 - mDice: 0.4401 - val_loss: 1.1935 - val_acc: 0.9051 - val_mDice: 0.3795

Epoch 00004: val_mDice did not improve from 0.39522
Epoch 5/300
 - 13s - loss: 0.7048 - acc: 0.8835 - mDice: 0.4818 - val_loss: 0.9545 - val_acc: 0.9109 - val_mDice: 0.4742

Epoch 00005: val_mDice improved from 0.39522 to 0.47420, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.6448 - acc: 0.8857 - mDice: 0.5120 - val_loss: 0.9376 - val_acc: 0.9090 - val_mDice: 0.4842

Epoch 00006: val_mDice improved from 0.47420 to 0.48419, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.5920 - acc: 0.8880 - mDice: 0.5393 - val_loss: 0.8572 - val_acc: 0.9183 - val_mDice: 0.5183

Epoch 00007: val_mDice improved from 0.48419 to 0.51828, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 12s - loss: 0.5557 - acc: 0.8907 - mDice: 0.5598 - val_loss: 0.8690 - val_acc: 0.9180 - val_mDice: 0.5112

Epoch 00008: val_mDice did not improve from 0.51828
Epoch 9/300
 - 12s - loss: 0.5279 - acc: 0.8933 - mDice: 0.5759 - val_loss: 0.8347 - val_acc: 0.9218 - val_mDice: 0.5284

Epoch 00009: val_mDice improved from 0.51828 to 0.52839, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 12s - loss: 0.5064 - acc: 0.8956 - mDice: 0.5888 - val_loss: 0.8082 - val_acc: 0.9268 - val_mDice: 0.5420

Epoch 00010: val_mDice improved from 0.52839 to 0.54198, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 11s - loss: 0.4877 - acc: 0.8981 - mDice: 0.6002 - val_loss: 0.8076 - val_acc: 0.9304 - val_mDice: 0.5437

Epoch 00011: val_mDice improved from 0.54198 to 0.54373, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 11s - loss: 0.4723 - acc: 0.9007 - mDice: 0.6097 - val_loss: 0.8121 - val_acc: 0.9329 - val_mDice: 0.5278

Epoch 00012: val_mDice did not improve from 0.54373
Epoch 13/300
 - 12s - loss: 0.4605 - acc: 0.9030 - mDice: 0.6172 - val_loss: 0.8258 - val_acc: 0.9343 - val_mDice: 0.5492

Epoch 00013: val_mDice improved from 0.54373 to 0.54922, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 12s - loss: 0.4493 - acc: 0.9053 - mDice: 0.6243 - val_loss: 0.8110 - val_acc: 0.9346 - val_mDice: 0.5513

Epoch 00014: val_mDice improved from 0.54922 to 0.55126, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 12s - loss: 0.4402 - acc: 0.9071 - mDice: 0.6303 - val_loss: 0.7937 - val_acc: 0.9359 - val_mDice: 0.5461

Epoch 00015: val_mDice did not improve from 0.55126
Epoch 16/300
 - 12s - loss: 0.4295 - acc: 0.9092 - mDice: 0.6374 - val_loss: 0.7970 - val_acc: 0.9380 - val_mDice: 0.5506

Epoch 00016: val_mDice did not improve from 0.55126
Epoch 17/300
 - 12s - loss: 0.4199 - acc: 0.9114 - mDice: 0.6436 - val_loss: 0.7910 - val_acc: 0.9385 - val_mDice: 0.5469

Epoch 00017: val_mDice did not improve from 0.55126
Epoch 18/300
 - 12s - loss: 0.4151 - acc: 0.9136 - mDice: 0.6467 - val_loss: 0.7961 - val_acc: 0.9400 - val_mDice: 0.5522

Epoch 00018: val_mDice improved from 0.55126 to 0.55217, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 12s - loss: 0.4069 - acc: 0.9165 - mDice: 0.6522 - val_loss: 0.7841 - val_acc: 0.9403 - val_mDice: 0.5559

Epoch 00019: val_mDice improved from 0.55217 to 0.55586, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 12s - loss: 0.4011 - acc: 0.9198 - mDice: 0.6561 - val_loss: 0.7790 - val_acc: 0.9413 - val_mDice: 0.5524

Epoch 00020: val_mDice did not improve from 0.55586
Epoch 21/300
 - 12s - loss: 0.3965 - acc: 0.9242 - mDice: 0.6591 - val_loss: 0.7547 - val_acc: 0.9413 - val_mDice: 0.5627

Epoch 00021: val_mDice improved from 0.55586 to 0.56266, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 22/300
 - 12s - loss: 0.3907 - acc: 0.9278 - mDice: 0.6629 - val_loss: 0.7734 - val_acc: 0.9405 - val_mDice: 0.5533

Epoch 00022: val_mDice did not improve from 0.56266
Epoch 23/300
 - 12s - loss: 0.3864 - acc: 0.9298 - mDice: 0.6657 - val_loss: 0.7574 - val_acc: 0.9431 - val_mDice: 0.5654

Epoch 00023: val_mDice improved from 0.56266 to 0.56536, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 24/300
 - 12s - loss: 0.3817 - acc: 0.9318 - mDice: 0.6688 - val_loss: 0.7625 - val_acc: 0.9396 - val_mDice: 0.5610

Epoch 00024: val_mDice did not improve from 0.56536
Epoch 25/300
 - 12s - loss: 0.3749 - acc: 0.9334 - mDice: 0.6731 - val_loss: 0.7632 - val_acc: 0.9394 - val_mDice: 0.5552

Epoch 00025: val_mDice did not improve from 0.56536
Epoch 26/300
 - 12s - loss: 0.3735 - acc: 0.9342 - mDice: 0.6742 - val_loss: 0.7666 - val_acc: 0.9388 - val_mDice: 0.5553

Epoch 00026: val_mDice did not improve from 0.56536
Epoch 27/300
 - 12s - loss: 0.3680 - acc: 0.9359 - mDice: 0.6779 - val_loss: 0.7499 - val_acc: 0.9381 - val_mDice: 0.5584

Epoch 00027: val_mDice did not improve from 0.56536
Epoch 28/300
 - 12s - loss: 0.3643 - acc: 0.9377 - mDice: 0.6802 - val_loss: 0.7484 - val_acc: 0.9399 - val_mDice: 0.5686

Epoch 00028: val_mDice improved from 0.56536 to 0.56858, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 12s - loss: 0.3611 - acc: 0.9389 - mDice: 0.6821 - val_loss: 0.7622 - val_acc: 0.9370 - val_mDice: 0.5496

Epoch 00029: val_mDice did not improve from 0.56858
Epoch 30/300
 - 12s - loss: 0.3590 - acc: 0.9394 - mDice: 0.6837 - val_loss: 0.7331 - val_acc: 0.9388 - val_mDice: 0.5672

Epoch 00030: val_mDice did not improve from 0.56858
Epoch 31/300
 - 12s - loss: 0.3539 - acc: 0.9399 - mDice: 0.6871 - val_loss: 0.7235 - val_acc: 0.9389 - val_mDice: 0.5660

Epoch 00031: val_mDice did not improve from 0.56858
Epoch 32/300
 - 12s - loss: 0.3510 - acc: 0.9404 - mDice: 0.6892 - val_loss: 0.7051 - val_acc: 0.9365 - val_mDice: 0.5662

Epoch 00032: val_mDice did not improve from 0.56858
Epoch 33/300
 - 12s - loss: 0.3490 - acc: 0.9405 - mDice: 0.6906 - val_loss: 0.7776 - val_acc: 0.9409 - val_mDice: 0.5721

Epoch 00033: val_mDice improved from 0.56858 to 0.57206, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 12s - loss: 0.3470 - acc: 0.9408 - mDice: 0.6920 - val_loss: 0.7148 - val_acc: 0.9382 - val_mDice: 0.5677

Epoch 00034: val_mDice did not improve from 0.57206
Epoch 35/300
 - 12s - loss: 0.3437 - acc: 0.9411 - mDice: 0.6943 - val_loss: 0.7082 - val_acc: 0.9326 - val_mDice: 0.5577

Epoch 00035: val_mDice did not improve from 0.57206
Epoch 36/300
 - 12s - loss: 0.3421 - acc: 0.9414 - mDice: 0.6955 - val_loss: 0.7096 - val_acc: 0.9377 - val_mDice: 0.5667

Epoch 00036: val_mDice did not improve from 0.57206
Epoch 37/300
 - 11s - loss: 0.3407 - acc: 0.9415 - mDice: 0.6964 - val_loss: 0.7024 - val_acc: 0.9335 - val_mDice: 0.5583

Epoch 00037: val_mDice did not improve from 0.57206
Epoch 38/300
 - 12s - loss: 0.3374 - acc: 0.9417 - mDice: 0.6988 - val_loss: 0.7390 - val_acc: 0.9397 - val_mDice: 0.5639

Epoch 00038: val_mDice did not improve from 0.57206
Epoch 39/300
 - 11s - loss: 0.3364 - acc: 0.9418 - mDice: 0.6996 - val_loss: 0.7052 - val_acc: 0.9375 - val_mDice: 0.5595

Epoch 00039: val_mDice did not improve from 0.57206
Epoch 40/300
 - 12s - loss: 0.3350 - acc: 0.9420 - mDice: 0.7007 - val_loss: 0.6954 - val_acc: 0.9375 - val_mDice: 0.5550

Epoch 00040: val_mDice did not improve from 0.57206
Epoch 41/300
 - 12s - loss: 0.3313 - acc: 0.9423 - mDice: 0.7033 - val_loss: 0.7372 - val_acc: 0.9245 - val_mDice: 0.5307

Epoch 00041: val_mDice did not improve from 0.57206
Epoch 42/300
 - 11s - loss: 0.3288 - acc: 0.9425 - mDice: 0.7051 - val_loss: 0.6880 - val_acc: 0.9312 - val_mDice: 0.5558

Epoch 00042: val_mDice did not improve from 0.57206
Epoch 43/300
 - 11s - loss: 0.3274 - acc: 0.9427 - mDice: 0.7061 - val_loss: 0.6773 - val_acc: 0.9383 - val_mDice: 0.5634

Epoch 00043: val_mDice did not improve from 0.57206
Epoch 44/300
 - 11s - loss: 0.3250 - acc: 0.9429 - mDice: 0.7079 - val_loss: 0.6802 - val_acc: 0.9329 - val_mDice: 0.5581

Epoch 00044: val_mDice did not improve from 0.57206
Epoch 45/300
 - 11s - loss: 0.3241 - acc: 0.9430 - mDice: 0.7086 - val_loss: 0.6754 - val_acc: 0.9365 - val_mDice: 0.5668

Epoch 00045: val_mDice did not improve from 0.57206
Epoch 46/300
 - 11s - loss: 0.3225 - acc: 0.9430 - mDice: 0.7097 - val_loss: 0.7012 - val_acc: 0.9357 - val_mDice: 0.5562

Epoch 00046: val_mDice did not improve from 0.57206
Epoch 47/300
 - 11s - loss: 0.3226 - acc: 0.9430 - mDice: 0.7097 - val_loss: 0.7024 - val_acc: 0.9372 - val_mDice: 0.5533

Epoch 00047: val_mDice did not improve from 0.57206
Epoch 48/300
 - 11s - loss: 0.3210 - acc: 0.9432 - mDice: 0.7109 - val_loss: 0.6602 - val_acc: 0.9384 - val_mDice: 0.5720

Epoch 00048: val_mDice did not improve from 0.57206
Epoch 49/300
 - 11s - loss: 0.3212 - acc: 0.9435 - mDice: 0.7109 - val_loss: 0.6595 - val_acc: 0.9335 - val_mDice: 0.5660

Epoch 00049: val_mDice did not improve from 0.57206
Epoch 50/300
 - 12s - loss: 0.3165 - acc: 0.9437 - mDice: 0.7142 - val_loss: 0.6587 - val_acc: 0.9347 - val_mDice: 0.5616

Epoch 00050: val_mDice did not improve from 0.57206
Epoch 51/300
 - 12s - loss: 0.3158 - acc: 0.9438 - mDice: 0.7146 - val_loss: 0.6475 - val_acc: 0.9342 - val_mDice: 0.5639

Epoch 00051: val_mDice did not improve from 0.57206
Epoch 52/300
 - 11s - loss: 0.3149 - acc: 0.9439 - mDice: 0.7153 - val_loss: 0.6562 - val_acc: 0.9342 - val_mDice: 0.5629

Epoch 00052: val_mDice did not improve from 0.57206
Epoch 53/300
 - 11s - loss: 0.3110 - acc: 0.9442 - mDice: 0.7183 - val_loss: 0.6454 - val_acc: 0.9335 - val_mDice: 0.5636

Epoch 00053: val_mDice did not improve from 0.57206
Epoch 54/300
 - 11s - loss: 0.3153 - acc: 0.9437 - mDice: 0.7150 - val_loss: 0.6589 - val_acc: 0.9396 - val_mDice: 0.5600

Epoch 00054: val_mDice did not improve from 0.57206
Epoch 55/300
 - 11s - loss: 0.3106 - acc: 0.9442 - mDice: 0.7186 - val_loss: 0.6915 - val_acc: 0.9298 - val_mDice: 0.5377

Epoch 00055: val_mDice did not improve from 0.57206
Epoch 56/300
 - 11s - loss: 0.3098 - acc: 0.9443 - mDice: 0.7191 - val_loss: 0.6306 - val_acc: 0.9380 - val_mDice: 0.5689

Epoch 00056: val_mDice did not improve from 0.57206
Epoch 57/300
 - 12s - loss: 0.3090 - acc: 0.9443 - mDice: 0.7198 - val_loss: 0.6330 - val_acc: 0.9379 - val_mDice: 0.5667

Epoch 00057: val_mDice did not improve from 0.57206
Epoch 58/300
 - 12s - loss: 0.3068 - acc: 0.9445 - mDice: 0.7214 - val_loss: 0.6347 - val_acc: 0.9372 - val_mDice: 0.5647

Epoch 00058: val_mDice did not improve from 0.57206
Epoch 59/300
 - 11s - loss: 0.3064 - acc: 0.9445 - mDice: 0.7218 - val_loss: 0.6285 - val_acc: 0.9378 - val_mDice: 0.5691

Epoch 00059: val_mDice did not improve from 0.57206
Epoch 60/300
 - 11s - loss: 0.3046 - acc: 0.9448 - mDice: 0.7231 - val_loss: 0.6444 - val_acc: 0.9331 - val_mDice: 0.5550

Epoch 00060: val_mDice did not improve from 0.57206
Epoch 61/300
 - 11s - loss: 0.3022 - acc: 0.9449 - mDice: 0.7249 - val_loss: 0.6309 - val_acc: 0.9353 - val_mDice: 0.5528

Epoch 00061: val_mDice did not improve from 0.57206
Epoch 62/300
 - 11s - loss: 0.3025 - acc: 0.9448 - mDice: 0.7246 - val_loss: 0.6196 - val_acc: 0.9390 - val_mDice: 0.5684

Epoch 00062: val_mDice did not improve from 0.57206
Epoch 63/300
 - 11s - loss: 0.3019 - acc: 0.9449 - mDice: 0.7251 - val_loss: 0.6214 - val_acc: 0.9391 - val_mDice: 0.5605

Epoch 00063: val_mDice did not improve from 0.57206
Epoch 64/300
 - 12s - loss: 0.3018 - acc: 0.9450 - mDice: 0.7252 - val_loss: 0.6070 - val_acc: 0.9374 - val_mDice: 0.5659

Epoch 00064: val_mDice did not improve from 0.57206
Epoch 65/300
 - 12s - loss: 0.3026 - acc: 0.9450 - mDice: 0.7245 - val_loss: 0.6413 - val_acc: 0.9388 - val_mDice: 0.5609

Epoch 00065: val_mDice did not improve from 0.57206
Epoch 66/300
 - 11s - loss: 0.2988 - acc: 0.9453 - mDice: 0.7274 - val_loss: 0.6164 - val_acc: 0.9308 - val_mDice: 0.5555

Epoch 00066: val_mDice did not improve from 0.57206
Epoch 67/300
 - 11s - loss: 0.2970 - acc: 0.9454 - mDice: 0.7289 - val_loss: 0.6539 - val_acc: 0.9398 - val_mDice: 0.5692

Epoch 00067: val_mDice did not improve from 0.57206
Epoch 68/300
 - 11s - loss: 0.2985 - acc: 0.9454 - mDice: 0.7277 - val_loss: 0.6334 - val_acc: 0.9359 - val_mDice: 0.5633

Epoch 00068: val_mDice did not improve from 0.57206
Epoch 69/300
 - 11s - loss: 0.2962 - acc: 0.9455 - mDice: 0.7295 - val_loss: 0.6102 - val_acc: 0.9401 - val_mDice: 0.5669

Epoch 00069: val_mDice did not improve from 0.57206
Epoch 70/300
 - 12s - loss: 0.2954 - acc: 0.9455 - mDice: 0.7301 - val_loss: 0.6027 - val_acc: 0.9359 - val_mDice: 0.5652

Epoch 00070: val_mDice did not improve from 0.57206
Epoch 71/300
 - 12s - loss: 0.2942 - acc: 0.9457 - mDice: 0.7309 - val_loss: 0.6482 - val_acc: 0.9403 - val_mDice: 0.5574

Epoch 00071: val_mDice did not improve from 0.57206
Epoch 72/300
 - 11s - loss: 0.2947 - acc: 0.9457 - mDice: 0.7306 - val_loss: 0.5741 - val_acc: 0.9391 - val_mDice: 0.5765

Epoch 00072: val_mDice improved from 0.57206 to 0.57646, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 73/300
 - 11s - loss: 0.2925 - acc: 0.9459 - mDice: 0.7323 - val_loss: 0.6009 - val_acc: 0.9406 - val_mDice: 0.5732

Epoch 00073: val_mDice did not improve from 0.57646
Epoch 74/300
 - 11s - loss: 0.2919 - acc: 0.9458 - mDice: 0.7326 - val_loss: 0.6023 - val_acc: 0.9350 - val_mDice: 0.5637

Epoch 00074: val_mDice did not improve from 0.57646
Epoch 75/300
 - 11s - loss: 0.2907 - acc: 0.9460 - mDice: 0.7337 - val_loss: 0.5927 - val_acc: 0.9372 - val_mDice: 0.5730

Epoch 00075: val_mDice did not improve from 0.57646
Epoch 76/300
 - 11s - loss: 0.2901 - acc: 0.9461 - mDice: 0.7341 - val_loss: 0.6348 - val_acc: 0.9378 - val_mDice: 0.5613

Epoch 00076: val_mDice did not improve from 0.57646
Epoch 77/300
 - 11s - loss: 0.2907 - acc: 0.9461 - mDice: 0.7337 - val_loss: 0.5980 - val_acc: 0.9366 - val_mDice: 0.5695

Epoch 00077: val_mDice did not improve from 0.57646
Epoch 78/300
 - 11s - loss: 0.2904 - acc: 0.9461 - mDice: 0.7338 - val_loss: 0.6040 - val_acc: 0.9373 - val_mDice: 0.5649

Epoch 00078: val_mDice did not improve from 0.57646
Epoch 79/300
 - 12s - loss: 0.2881 - acc: 0.9462 - mDice: 0.7356 - val_loss: 0.5998 - val_acc: 0.9368 - val_mDice: 0.5688

Epoch 00079: val_mDice did not improve from 0.57646
Epoch 80/300
 - 12s - loss: 0.2870 - acc: 0.9463 - mDice: 0.7364 - val_loss: 0.6002 - val_acc: 0.9359 - val_mDice: 0.5664

Epoch 00080: val_mDice did not improve from 0.57646
Epoch 81/300
 - 11s - loss: 0.2881 - acc: 0.9464 - mDice: 0.7357 - val_loss: 0.6141 - val_acc: 0.9376 - val_mDice: 0.5599

Epoch 00081: val_mDice did not improve from 0.57646
Epoch 82/300
 - 11s - loss: 0.2856 - acc: 0.9465 - mDice: 0.7375 - val_loss: 0.6263 - val_acc: 0.9383 - val_mDice: 0.5700

Epoch 00082: val_mDice did not improve from 0.57646
Epoch 83/300
 - 11s - loss: 0.2861 - acc: 0.9463 - mDice: 0.7371 - val_loss: 0.6028 - val_acc: 0.9391 - val_mDice: 0.5664

Epoch 00083: val_mDice did not improve from 0.57646
Epoch 84/300
 - 11s - loss: 0.2854 - acc: 0.9464 - mDice: 0.7377 - val_loss: 0.6064 - val_acc: 0.9363 - val_mDice: 0.5628

Epoch 00084: val_mDice did not improve from 0.57646
Epoch 85/300
 - 11s - loss: 0.2858 - acc: 0.9465 - mDice: 0.7373 - val_loss: 0.5977 - val_acc: 0.9383 - val_mDice: 0.5744

Epoch 00085: val_mDice did not improve from 0.57646
Epoch 86/300
 - 11s - loss: 0.2847 - acc: 0.9465 - mDice: 0.7383 - val_loss: 0.6134 - val_acc: 0.9377 - val_mDice: 0.5660

Epoch 00086: val_mDice did not improve from 0.57646
Epoch 87/300
 - 11s - loss: 0.2841 - acc: 0.9466 - mDice: 0.7387 - val_loss: 0.5833 - val_acc: 0.9394 - val_mDice: 0.5697

Epoch 00087: val_mDice did not improve from 0.57646
Epoch 88/300
 - 12s - loss: 0.2822 - acc: 0.9468 - mDice: 0.7401 - val_loss: 0.5944 - val_acc: 0.9364 - val_mDice: 0.5661

Epoch 00088: val_mDice did not improve from 0.57646
Epoch 89/300
 - 12s - loss: 0.2815 - acc: 0.9468 - mDice: 0.7407 - val_loss: 0.6332 - val_acc: 0.9333 - val_mDice: 0.5565

Epoch 00089: val_mDice did not improve from 0.57646
Epoch 90/300
 - 11s - loss: 0.2808 - acc: 0.9468 - mDice: 0.7413 - val_loss: 0.5993 - val_acc: 0.9378 - val_mDice: 0.5634

Epoch 00090: val_mDice did not improve from 0.57646
Epoch 91/300
 - 11s - loss: 0.2813 - acc: 0.9468 - mDice: 0.7409 - val_loss: 0.5941 - val_acc: 0.9351 - val_mDice: 0.5641

Epoch 00091: val_mDice did not improve from 0.57646
Epoch 92/300
 - 11s - loss: 0.2817 - acc: 0.9467 - mDice: 0.7406 - val_loss: 0.6333 - val_acc: 0.9343 - val_mDice: 0.5602

Epoch 00092: val_mDice did not improve from 0.57646
Epoch 93/300
 - 12s - loss: 0.2809 - acc: 0.9469 - mDice: 0.7413 - val_loss: 0.6200 - val_acc: 0.9354 - val_mDice: 0.5574

Epoch 00093: val_mDice did not improve from 0.57646
Epoch 94/300
 - 12s - loss: 0.2794 - acc: 0.9470 - mDice: 0.7424 - val_loss: 0.5926 - val_acc: 0.9379 - val_mDice: 0.5649

Epoch 00094: val_mDice did not improve from 0.57646
Epoch 95/300
 - 12s - loss: 0.2808 - acc: 0.9468 - mDice: 0.7413 - val_loss: 0.5724 - val_acc: 0.9372 - val_mDice: 0.5701

Epoch 00095: val_mDice did not improve from 0.57646
Epoch 96/300
 - 12s - loss: 0.2764 - acc: 0.9473 - mDice: 0.7447 - val_loss: 0.5780 - val_acc: 0.9376 - val_mDice: 0.5668

Epoch 00096: val_mDice did not improve from 0.57646
Epoch 97/300
 - 11s - loss: 0.2799 - acc: 0.9470 - mDice: 0.7420 - val_loss: 0.6093 - val_acc: 0.9352 - val_mDice: 0.5608

Epoch 00097: val_mDice did not improve from 0.57646
Epoch 98/300
 - 11s - loss: 0.2774 - acc: 0.9472 - mDice: 0.7440 - val_loss: 0.6180 - val_acc: 0.9305 - val_mDice: 0.5604

Epoch 00098: val_mDice did not improve from 0.57646
Epoch 99/300
 - 12s - loss: 0.2773 - acc: 0.9472 - mDice: 0.7439 - val_loss: 0.6455 - val_acc: 0.9365 - val_mDice: 0.5517

Epoch 00099: val_mDice did not improve from 0.57646
Epoch 100/300
 - 12s - loss: 0.2770 - acc: 0.9472 - mDice: 0.7443 - val_loss: 0.6446 - val_acc: 0.9377 - val_mDice: 0.5762

Epoch 00100: val_mDice did not improve from 0.57646
Epoch 101/300
 - 11s - loss: 0.2763 - acc: 0.9473 - mDice: 0.7448 - val_loss: 0.5874 - val_acc: 0.9388 - val_mDice: 0.5646

Epoch 00101: val_mDice did not improve from 0.57646
Epoch 102/300
 - 12s - loss: 0.2758 - acc: 0.9473 - mDice: 0.7452 - val_loss: 0.6236 - val_acc: 0.9336 - val_mDice: 0.5461

Epoch 00102: val_mDice did not improve from 0.57646
Epoch 103/300
 - 12s - loss: 0.2746 - acc: 0.9473 - mDice: 0.7461 - val_loss: 0.5707 - val_acc: 0.9367 - val_mDice: 0.5693

Epoch 00103: val_mDice did not improve from 0.57646
Epoch 104/300
 - 12s - loss: 0.2746 - acc: 0.9474 - mDice: 0.7462 - val_loss: 0.6319 - val_acc: 0.9377 - val_mDice: 0.5686

Epoch 00104: val_mDice did not improve from 0.57646
Epoch 105/300
 - 12s - loss: 0.2722 - acc: 0.9476 - mDice: 0.7480 - val_loss: 0.6011 - val_acc: 0.9359 - val_mDice: 0.5589

Epoch 00105: val_mDice did not improve from 0.57646
Epoch 106/300
 - 12s - loss: 0.2737 - acc: 0.9475 - mDice: 0.7469 - val_loss: 0.5767 - val_acc: 0.9376 - val_mDice: 0.5693

Epoch 00106: val_mDice did not improve from 0.57646
Epoch 107/300
 - 12s - loss: 0.2731 - acc: 0.9475 - mDice: 0.7473 - val_loss: 0.6072 - val_acc: 0.9332 - val_mDice: 0.5555

Epoch 00107: val_mDice did not improve from 0.57646
Epoch 108/300
 - 12s - loss: 0.2741 - acc: 0.9476 - mDice: 0.7465 - val_loss: 0.5846 - val_acc: 0.9381 - val_mDice: 0.5636

Epoch 00108: val_mDice did not improve from 0.57646
Epoch 109/300
 - 12s - loss: 0.2712 - acc: 0.9478 - mDice: 0.7488 - val_loss: 0.6025 - val_acc: 0.9366 - val_mDice: 0.5608

Epoch 00109: val_mDice did not improve from 0.57646
Epoch 110/300
 - 12s - loss: 0.2729 - acc: 0.9476 - mDice: 0.7475 - val_loss: 0.6009 - val_acc: 0.9396 - val_mDice: 0.5707

Epoch 00110: val_mDice did not improve from 0.57646
Epoch 111/300
 - 13s - loss: 0.2719 - acc: 0.9476 - mDice: 0.7482 - val_loss: 0.5549 - val_acc: 0.9393 - val_mDice: 0.5730

Epoch 00111: val_mDice did not improve from 0.57646
Epoch 112/300
 - 12s - loss: 0.2713 - acc: 0.9478 - mDice: 0.7486 - val_loss: 0.6197 - val_acc: 0.9372 - val_mDice: 0.5632

Epoch 00112: val_mDice did not improve from 0.57646
Restoring model weights from the end of the best epoch
Epoch 00112: early stopping
{'val_loss': [2.9803550976973314, 1.431042831677657, 1.153016475530771, 1.193501311999101, 0.954450751726444, 0.9376218204314892, 0.8571529846925002, 0.8690470113204076, 0.8346685744248904, 0.8081925327961261, 0.807602162544544, 0.8120849270087022, 0.8258291276601645, 0.8110004617617681, 0.7936878502368927, 0.7969830700984368, 0.7910407552352319, 0.7960616739896628, 0.784129608135957, 0.7789997985729804, 0.7546611909682934, 0.7734169409825251, 0.7573582025674673, 0.76247000006529, 0.7632459493783804, 0.7665572831263909, 0.7498573156503531, 0.7484336770497836, 0.7621886867743272, 0.7331302395233741, 0.7235177365633157, 0.7050955799909738, 0.7776271150662348, 0.7147741753321427, 0.7082204199754275, 0.7095604745241312, 0.7023596442662753, 0.7390328554006723, 0.7052107476271116, 0.6953698190358969, 0.7371630301842322, 0.6880161212040827, 0.6772959644977863, 0.6801709945385273, 0.6754226180223318, 0.7011714692299182, 0.7024217821084536, 0.6601927372125479, 0.659522329385464, 0.6587166854968438, 0.647535149867718, 0.6562184141232417, 0.645351760662519, 0.6588535354687617, 0.6914673470533811, 0.6305857209058908, 0.6329767085038699, 0.6346821647423965, 0.6285121532586905, 0.6444003788324503, 0.6308535979344294, 0.6195906538229722, 0.6213624316912431, 0.6069983977537888, 0.6412759904678051, 0.6164342738114871, 0.6539380848407745, 0.6334321636420029, 0.6101886996856103, 0.6026768936560705, 0.6481550060785733, 0.574146914940614, 0.6008960398343893, 0.6022740098146292, 0.5927104330979861, 0.634803288258039, 0.5980291045629061, 0.603967717060676, 0.5998227940155909, 0.6001904538044562, 0.614138506926023, 0.6263384956579942, 0.6027701084430401, 0.6064062210229727, 0.5977075695991516, 0.6134307155242333, 0.5832882431837229, 0.5943909333302424, 0.6331674662920145, 0.5993091532817254, 0.5941051313510308, 0.6333144307136536, 0.6199549253170307, 0.5926363330620986, 0.5724218946236831, 0.5780366063117981, 0.6092897286781898, 0.6179892145670377, 0.6455282018734858, 0.6446445217499366, 0.5873676676016587, 0.6235749308879559, 0.5706818837385911, 0.6319062022062448, 0.6011356803087088, 0.5767278464940878, 0.6072159868020278, 0.5845793623190659, 0.6024636419919821, 0.600909180366076, 0.5548863479724297, 0.6196524042349595], 'val_acc': [0.903857714854754, 0.9068024502350733, 0.9065897648151104, 0.9050526916980743, 0.9109212962480692, 0.9089959309651301, 0.9182507326969733, 0.91798957494589, 0.9217825509034671, 0.926832928107335, 0.9303531761352832, 0.9329326725923098, 0.9343056609997382, 0.9345899820327759, 0.935932879264538, 0.9380038907894721, 0.9384754116718586, 0.9399847457042108, 0.9402991006007562, 0.9412606266828684, 0.9412721601816324, 0.9404863302524273, 0.9430912778927729, 0.9396287821806394, 0.9393583467373481, 0.9388475234691913, 0.9380986530047196, 0.9398645804478571, 0.9370030348117535, 0.9388452378603128, 0.9389191980545337, 0.9365384899652921, 0.9408815434345832, 0.9381633836489457, 0.9325906107058892, 0.9376802788330958, 0.9335452157717484, 0.9396727153888116, 0.9375485204733335, 0.9375230990923368, 0.9245493022295145, 0.9312269137455866, 0.938320517539978, 0.9329396165334262, 0.9365430909853715, 0.9357110032668481, 0.9372133612632751, 0.9383991154340597, 0.9335405987042648, 0.9346893681929662, 0.9342016600645505, 0.9342386309917157, 0.9335105373309209, 0.9395941289571615, 0.9297891740615551, 0.9380408685940963, 0.9378975675656245, 0.937236494742907, 0.9377658069133759, 0.9330528814059037, 0.9352510112982529, 0.9390347416584308, 0.9390578820155218, 0.937407537148549, 0.9388359785079956, 0.9308246832627517, 0.9397535782593948, 0.935863522382883, 0.9401118686565986, 0.9359421248619373, 0.9403222134480109, 0.9391410900996282, 0.940611149256046, 0.9350360288069799, 0.9372457449252789, 0.9377797062580402, 0.9366309298918798, 0.9372919981296246, 0.9368227399312533, 0.9358866306451651, 0.9375785680917593, 0.9383182525634766, 0.9391156870585221, 0.9363373861863062, 0.938295093866495, 0.9377056910441472, 0.9394276715241946, 0.9364414054613847, 0.9332563051810632, 0.9378235729841086, 0.9350892397073599, 0.9342732888001662, 0.9354290068149567, 0.9379090987719022, 0.9372018163020794, 0.9376340531385862, 0.9352348515620599, 0.9305380857907809, 0.9365037771371695, 0.9377010648067181, 0.9388013115295997, 0.933612232024853, 0.9366794732900766, 0.937724225796186, 0.9358750673440787, 0.9375531856830304, 0.9331846283032343, 0.9381148150333991, 0.9366170328397018, 0.9396126086895282, 0.9393075131453, 0.937224940611766], 'val_mDice': [0.1313422815874219, 0.3123805783689022, 0.3952204625193889, 0.3795068487524986, 0.47420378344563335, 0.4841895384284166, 0.5182794286654546, 0.5112166290099804, 0.5283865355528318, 0.541979968547821, 0.5437331348657608, 0.5277554060404117, 0.5492215070586938, 0.5512629414980228, 0.5461448132991791, 0.5505675169137808, 0.5469397570078189, 0.5521746656069388, 0.5558608501003339, 0.5523548395587847, 0.5626626398700935, 0.5532536243016903, 0.5653620511293411, 0.5609563783957408, 0.5552498514835651, 0.5552526380007083, 0.5583925155492929, 0.5685801655054092, 0.5495953370745366, 0.5671689613507345, 0.5660470993472979, 0.5662460911732453, 0.5720580277534631, 0.5676965507177206, 0.5576706253565274, 0.566742887863746, 0.558272585272789, 0.5638624246303852, 0.5594659825930228, 0.554952797981409, 0.530668671314533, 0.5558294350138078, 0.563364663376258, 0.5580819363777454, 0.566764758183406, 0.5562181656177227, 0.5533350402346024, 0.5719945482336558, 0.5659972349038491, 0.5615600571036339, 0.5639292225241661, 0.5628577625522246, 0.5636384911262072, 0.5600231553499515, 0.5377456213419254, 0.5689088461490778, 0.5667078712811837, 0.5647422453531852, 0.5691360487387731, 0.5549569651484489, 0.5527996099912204, 0.5684441133187368, 0.5605184928728983, 0.5658513238796821, 0.5608816834596487, 0.5555052516552118, 0.5691837800236849, 0.5632654411288408, 0.5669393785870992, 0.5652291705975165, 0.5573886128572317, 0.5764624224259303, 0.5731973648071289, 0.5637384068507415, 0.572977361197655, 0.5613073316904215, 0.5695199622557714, 0.564941926071277, 0.5687986629513594, 0.5663532838225365, 0.5599490879819944, 0.5699586037259835, 0.5664450698173963, 0.5628042473242834, 0.5743998151559097, 0.5660157054662704, 0.5696814530170881, 0.5661147328523489, 0.5564519235721002, 0.5633511222325839, 0.5640704310857333, 0.56020176754548, 0.557417671267803, 0.5649157464504242, 0.5700846440516986, 0.5667566794615525, 0.5608390604074185, 0.5604238120409158, 0.5516903646863424, 0.5762112444409957, 0.5645818320604471, 0.5460861199177228, 0.5692727944025626, 0.5686084410318961, 0.5589190274477005, 0.5692585695248383, 0.5554638917629535, 0.563642402107899, 0.5608406783296511, 0.5706681351249034, 0.5730234052126224, 0.5631850080994459], 'loss': [2.995709124728893, 1.3041189074307409, 0.9393430462811889, 0.7940081026483086, 0.7047553781894458, 0.6448485331100852, 0.5920236593604165, 0.5556995015978582, 0.5278748767320756, 0.5064262689990464, 0.4877473113392372, 0.4722959525573301, 0.46046625442591954, 0.4493390642924908, 0.44019127324708635, 0.4295059124350185, 0.41991322266542086, 0.4150767035725305, 0.40689922943828094, 0.4010850384228126, 0.3964919910751497, 0.3907118751660139, 0.3864270839388384, 0.3816772312582787, 0.37492777654949416, 0.3734795814465082, 0.36803977926542847, 0.36430663257949986, 0.36112080564866544, 0.3590165840202973, 0.35392003865861194, 0.3510107649276367, 0.3489715123043546, 0.346968813890968, 0.34372444693687976, 0.34209072463441836, 0.34073670822063695, 0.3374290474444246, 0.33640165645830156, 0.3350207616479637, 0.3312688634358879, 0.32879407583903114, 0.3273792163226082, 0.325001761642954, 0.3240601231001251, 0.3225434108913071, 0.32261626456624454, 0.3210097667691145, 0.3212488647493656, 0.3165342895557858, 0.31582196039664484, 0.3148683405451303, 0.31101937786762995, 0.3153372992644019, 0.3105772858993886, 0.30979098910490743, 0.3089989104812286, 0.30679528897707725, 0.3064055311210391, 0.3046183702410955, 0.30219437402794086, 0.3024670944616912, 0.3018680588682122, 0.3018101488632502, 0.3025762841653793, 0.2987742213143927, 0.29695058459616847, 0.29853468254121984, 0.2961538883495911, 0.29540669136103215, 0.2942470940817527, 0.29470043184901695, 0.29249681745256695, 0.29194841160442647, 0.29068960764910984, 0.29012061333805833, 0.29070071657403396, 0.2904398962216306, 0.2881437279301179, 0.28703154085483495, 0.28814993580636816, 0.28562462899634994, 0.286120136227982, 0.28542994951548795, 0.28584033174674406, 0.2847065993404406, 0.2841398141282539, 0.2822479651327845, 0.28149673842387724, 0.28077478122911276, 0.2812566051709193, 0.28167931511372885, 0.2808806755017676, 0.279394245016875, 0.28078221218794636, 0.27637974995809494, 0.27993767834903677, 0.277404527992689, 0.2773059638599996, 0.27696425443886064, 0.27632645180411614, 0.275754959666508, 0.2746231785798374, 0.2745612614419554, 0.2722327031767545, 0.27366224023938057, 0.2730984294600321, 0.27407690007275654, 0.27119553738344887, 0.2728836036174816, 0.27192548321400095, 0.27134418798407695], 'acc': [0.525311637515884, 0.8761968251843739, 0.8791011900168706, 0.8812592265395499, 0.8835284576461752, 0.8857263473416457, 0.8879948452831051, 0.8906670784330187, 0.8933335241329886, 0.8955944190933004, 0.8981298649430902, 0.9006833550422755, 0.9030317561736155, 0.9052868402939842, 0.9070816055375865, 0.9092263103432952, 0.9113805695762166, 0.9135803218027724, 0.9164859109464457, 0.9197799526962376, 0.9241567580591958, 0.9277610421554525, 0.929791397217465, 0.9318102240771328, 0.9334282282587678, 0.9342455723722581, 0.9358963835979315, 0.9376920309495983, 0.9388590130948453, 0.9393620406977752, 0.9399415334740061, 0.940380336442777, 0.9404843578003962, 0.9407892782376127, 0.94111853987487, 0.9413899638869826, 0.9414903451835033, 0.9416657514945064, 0.941778526181479, 0.9419855882098377, 0.942301910521414, 0.9425075727998579, 0.9426833120844059, 0.9428532404630461, 0.9429939530503317, 0.9430421466406538, 0.9430341674955439, 0.94321693106352, 0.9434844991064243, 0.9437414845845955, 0.9437784847821366, 0.9438825959232717, 0.9442173536881676, 0.9437091386231353, 0.9442262259904368, 0.9442521857509509, 0.9442820506683852, 0.9445095060221946, 0.9444939662123215, 0.9448233612412886, 0.9448899402066943, 0.944836242017761, 0.9448958119925654, 0.9450325315633867, 0.9450004954108516, 0.9452901425687499, 0.945389997268706, 0.9453579798446616, 0.945522102995859, 0.9454701356503903, 0.9457125145549277, 0.9456797484749964, 0.9459014446392585, 0.9457825042824788, 0.945962344666727, 0.9461167341535034, 0.9461140951733852, 0.9461106120644048, 0.9461705174149705, 0.9463167947222362, 0.946389929489446, 0.9464638934445031, 0.9463440826224366, 0.9463921472186985, 0.9464853463836518, 0.9464734646267615, 0.9465947347209318, 0.9467603379121338, 0.9467583653683439, 0.9467949025153586, 0.9468245441256375, 0.9467165067683372, 0.9469129105374172, 0.9469584678631696, 0.9467926599613736, 0.9472600178317061, 0.9470213188089854, 0.9472254771461986, 0.9472128191656549, 0.9472033094515454, 0.9473292556491096, 0.9473190805376164, 0.9473193068516647, 0.9473913297061275, 0.947612335181023, 0.9475349221108178, 0.9475180729117372, 0.9475677544303478, 0.9478041052180639, 0.9476085252662014, 0.9476164400572048, 0.947798341284552], 'mDice': [0.0812140614396255, 0.27756489558676384, 0.3807450425857923, 0.4401354493909488, 0.48179941247510677, 0.5119885034961563, 0.5393308231743303, 0.5597702054028404, 0.5759273150151235, 0.5887977476820541, 0.6002310149884912, 0.6096937033420535, 0.617202996185188, 0.6243447851598192, 0.6303384873047533, 0.6374483466379253, 0.6436348512836084, 0.6467042642689429, 0.6521812886656578, 0.6561491617766801, 0.6590743334951034, 0.6628623670794191, 0.6656841736190336, 0.6688005163211571, 0.6731325753509344, 0.6741994309884909, 0.6778704851060449, 0.6801772643628622, 0.6821353120699609, 0.6836923523537625, 0.6871370060092286, 0.6891896114801883, 0.6905928195089055, 0.6919971252514583, 0.6942773684027845, 0.6955368941223601, 0.696439439769074, 0.6988394397723107, 0.6995790193719221, 0.7006596544401722, 0.7032886716170162, 0.7051342844930092, 0.70608205647637, 0.7079437641621208, 0.708614376218383, 0.7096576732231618, 0.7096787200503537, 0.7108659078128705, 0.7108808858724667, 0.7141911421250474, 0.7145696487152344, 0.7153275903494037, 0.7182688837307335, 0.715030505924793, 0.7185619365440066, 0.7190963811708598, 0.7198064374404783, 0.7213848999678335, 0.7217848839261133, 0.7230900222553952, 0.7248650800694754, 0.724635146414674, 0.7251488002015251, 0.7251627603756219, 0.7245457751124501, 0.7274195301810896, 0.7288592493282323, 0.7276809234510518, 0.7294501910721543, 0.7300591877242752, 0.7308843097904012, 0.7305810100685063, 0.7322805034798757, 0.732627061177892, 0.7336697621417202, 0.7340588609110019, 0.7336868342686588, 0.7337834722912423, 0.7356220116576156, 0.7363957537723448, 0.7356813668786936, 0.7375290012388204, 0.7371462822004425, 0.7376952436064196, 0.7373216759341675, 0.7382674803101004, 0.7386828079925498, 0.7401277426423089, 0.7407073906720658, 0.7412957537661264, 0.7408616081557678, 0.7406173821668899, 0.7412920476743176, 0.7423995152771347, 0.7413036845041071, 0.7446662398388627, 0.7419990446859319, 0.7439642927088795, 0.74393818933212, 0.7443283660368079, 0.7447935257639203, 0.7452263295359138, 0.7460546242644357, 0.7461845795024006, 0.7479693038122994, 0.7468741141946116, 0.7472754410521896, 0.7465062534403429, 0.7487757427164915, 0.7474717863270314, 0.7481653203628253, 0.748639929968526]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.28s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.02s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.82s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:59,  1.90s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:08,  1.73s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:02,  1.71s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:32,  1.61s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:16,  1.56s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:29,  1.62s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:28,  1.62s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:03,  1.76s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:39,  1.68s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:57,  1.75s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:43,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:50,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:07,  1.81s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:14,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:53,  1.77s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:53,  1.77s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:40,  1.73s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:39,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:53,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:36,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:38,  1.75s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:23,  1.70s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:32,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:50,  1.82s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:32,  1.75s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:36,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:32,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:40,  1.81s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:42,  1.82s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:18,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:15,  1.73s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:18,  1.76s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:16,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:27,  1.81s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:08,  1.74s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:13,  1.77s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:56,  1.71s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:51,  1.69s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:57,  1.72s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:55,  1.73s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<06:59,  1.76s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:47,  1.72s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:58,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<06:56,  1.77s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:05,  1.82s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:52,  1.77s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:54,  1.79s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:03,  1.84s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:45,  1.76s/it]predicting train subjects:  20%|█▉        | 56/285 [01:37<06:43,  1.76s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:28,  1.70s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:35,  1.74s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:45,  1.79s/it]predicting train subjects:  21%|██        | 60/285 [01:44<06:51,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:37,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:39,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:51<06:23,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [01:54<06:17,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:19,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<06:11,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<06:21,  1.77s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:16,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:03<06:16,  1.76s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<06:03,  1.71s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<06:02,  1.71s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<06:03,  1.73s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<05:59,  1.72s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<05:49,  1.68s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:46,  1.67s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:52,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:53,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:20<05:43,  1.68s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:41,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:38,  1.68s/it]predicting train subjects:  29%|██▉       | 84/285 [02:25<05:29,  1.64s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:38,  1.70s/it]predicting train subjects:  31%|███       | 87/285 [02:30<05:46,  1.75s/it]predicting train subjects:  31%|███       | 88/285 [02:32<05:29,  1.67s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:27,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:30,  1.70s/it]predicting train subjects:  32%|███▏      | 91/285 [02:37<05:22,  1.66s/it]predicting train subjects:  32%|███▏      | 92/285 [02:39<05:27,  1.70s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:21,  1.67s/it]predicting train subjects:  33%|███▎      | 94/285 [02:42<05:25,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:44<05:28,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:46<05:25,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:47<05:24,  1.73s/it]predicting train subjects:  34%|███▍      | 98/285 [02:49<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:51<05:29,  1.77s/it]predicting train subjects:  35%|███▌      | 100/285 [02:53<05:28,  1.78s/it]predicting train subjects:  35%|███▌      | 101/285 [02:54<05:14,  1.71s/it]predicting train subjects:  36%|███▌      | 102/285 [02:56<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:58<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:59<05:12,  1.73s/it]predicting train subjects:  37%|███▋      | 105/285 [03:01<05:15,  1.75s/it]predicting train subjects:  37%|███▋      | 106/285 [03:03<05:03,  1.69s/it]predicting train subjects:  38%|███▊      | 107/285 [03:05<05:04,  1.71s/it]predicting train subjects:  38%|███▊      | 108/285 [03:06<04:51,  1.65s/it]predicting train subjects:  38%|███▊      | 109/285 [03:08<04:51,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<04:54,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:11<04:46,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:13<04:53,  1.70s/it]predicting train subjects:  40%|███▉      | 113/285 [03:15<04:56,  1.72s/it]predicting train subjects:  40%|████      | 114/285 [03:16<04:58,  1.75s/it]predicting train subjects:  40%|████      | 115/285 [03:18<04:55,  1.74s/it]predicting train subjects:  41%|████      | 116/285 [03:20<04:56,  1.75s/it]predicting train subjects:  41%|████      | 117/285 [03:22<04:46,  1.70s/it]predicting train subjects:  41%|████▏     | 118/285 [03:23<04:35,  1.65s/it]predicting train subjects:  42%|████▏     | 119/285 [03:25<04:39,  1.68s/it]predicting train subjects:  42%|████▏     | 120/285 [03:26<04:28,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:28<04:24,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:16,  1.57s/it]predicting train subjects:  43%|████▎     | 123/285 [03:31<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:04,  1.52s/it]predicting train subjects:  44%|████▍     | 125/285 [03:34<03:57,  1.48s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:53,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:37<03:53,  1.48s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<04:00,  1.53s/it]predicting train subjects:  45%|████▌     | 129/285 [03:40<03:53,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:42<03:41,  1.44s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<03:45,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:45<03:39,  1.44s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<03:39,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:48<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:50<03:34,  1.44s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:39,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:53<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:37,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [03:56<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [03:59<03:30,  1.47s/it]predicting train subjects:  50%|█████     | 143/285 [04:00<03:25,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [04:02<03:35,  1.53s/it]predicting train subjects:  51%|█████     | 145/285 [04:03<03:32,  1.52s/it]predicting train subjects:  51%|█████     | 146/285 [04:05<03:33,  1.54s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:06<03:27,  1.50s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:08<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:09<03:25,  1.51s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:11<03:22,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:12<03:21,  1.50s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:14<03:13,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:15<03:11,  1.45s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:17<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:18<03:11,  1.47s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:20<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:21<03:09,  1.48s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:23<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:24<03:00,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:25<02:58,  1.43s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:27<03:00,  1.46s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:28<02:57,  1.44s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:30<02:59,  1.47s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:31<02:54,  1.44s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:33<02:49,  1.41s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<02:49,  1.43s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:37<02:45,  1.42s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:45,  1.43s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:40<02:44,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:41,  1.42s/it]predicting train subjects:  60%|██████    | 172/285 [04:43<02:39,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:36,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:34,  1.39s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:41,  1.47s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:49<02:45,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:42,  1.51s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:53<02:33,  1.45s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:55<02:41,  1.54s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:39,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:58<02:39,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:31,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:03<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:05<02:38,  1.61s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:07<02:40,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:08<02:31,  1.57s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:10<02:26,  1.54s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:11<02:26,  1.56s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:14<02:16,  1.49s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:16<02:12,  1.46s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:19<02:18,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:21<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:23<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:15,  1.58s/it]predicting train subjects:  70%|███████   | 200/285 [05:25<02:11,  1.54s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:15,  1.62s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:13,  1.61s/it]predicting train subjects:  71%|███████   | 203/285 [05:30<02:13,  1.63s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:04,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:33<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:35<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:36<02:03,  1.58s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:38<02:07,  1.66s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:40<02:07,  1.67s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:41<01:58,  1.58s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:43<01:53,  1.53s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:44<01:53,  1.56s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:46<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:47<01:49,  1.54s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:49<01:54,  1.63s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:51<01:48,  1.58s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:53<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:54<01:51,  1.66s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:56<01:53,  1.71s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:43,  1.60s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:59<01:38,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:01<01:40,  1.60s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:02<01:38,  1.59s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:04<01:41,  1.66s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:05<01:36,  1.61s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:07<01:41,  1.73s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:09<01:44,  1.80s/it]predicting train subjects:  80%|████████  | 228/285 [06:11<01:46,  1.87s/it]predicting train subjects:  80%|████████  | 229/285 [06:13<01:44,  1.86s/it]predicting train subjects:  81%|████████  | 230/285 [06:15<01:35,  1.74s/it]predicting train subjects:  81%|████████  | 231/285 [06:16<01:32,  1.71s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:18<01:34,  1.79s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:20<01:28,  1.70s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:22<01:31,  1.79s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:23<01:25,  1.72s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:25<01:29,  1.83s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:27<01:29,  1.86s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:29<01:26,  1.84s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:31<01:25,  1.86s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:33<01:20,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:34<01:16,  1.73s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:36<01:12,  1.70s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:37<01:09,  1.66s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:39<01:10,  1.72s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:41<01:06,  1.66s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:43<01:08,  1.75s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:45<01:09,  1.82s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:47<01:09,  1.89s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:48<01:03,  1.77s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:50<00:59,  1.71s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:51<00:56,  1.65s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:53<00:54,  1.64s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:55<00:55,  1.74s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:57<00:56,  1.82s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:59<00:55,  1.84s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:00<00:49,  1.71s/it]predicting train subjects:  90%|█████████ | 257/285 [07:02<00:46,  1.67s/it]predicting train subjects:  91%|█████████ | 258/285 [07:04<00:46,  1.71s/it]predicting train subjects:  91%|█████████ | 259/285 [07:06<00:45,  1.74s/it]predicting train subjects:  91%|█████████ | 260/285 [07:07<00:40,  1.64s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:08<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:10<00:36,  1.61s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:12<00:35,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:14<00:36,  1.73s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:16<00:35,  1.78s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:17<00:31,  1.68s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:19<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:21<00:29,  1.75s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:22<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:24<00:24,  1.66s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:25<00:22,  1.63s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:28<00:23,  1.79s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:29<00:19,  1.66s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:31<00:18,  1.68s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:33<00:17,  1.77s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:35<00:16,  1.86s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:36<00:14,  1.76s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:38<00:11,  1.70s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:39<00:10,  1.71s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:41<00:08,  1.66s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:43<00:06,  1.62s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:44<00:04,  1.56s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:46<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:48<00:01,  1.82s/it]predicting train subjects: 100%|██████████| 285/285 [07:50<00:00,  1.87s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:36,  2.03s/it]Loading train:   1%|          | 2/285 [00:03<08:46,  1.86s/it]Loading train:   1%|          | 3/285 [00:05<08:27,  1.80s/it]Loading train:   1%|▏         | 4/285 [00:06<08:00,  1.71s/it]Loading train:   2%|▏         | 5/285 [00:08<07:58,  1.71s/it]Loading train:   2%|▏         | 6/285 [00:09<07:45,  1.67s/it]Loading train:   2%|▏         | 7/285 [00:12<08:26,  1.82s/it]Loading train:   3%|▎         | 8/285 [00:13<08:21,  1.81s/it]Loading train:   3%|▎         | 9/285 [00:16<08:50,  1.92s/it]Loading train:   4%|▎         | 10/285 [00:17<08:26,  1.84s/it]Loading train:   4%|▍         | 11/285 [00:19<07:54,  1.73s/it]Loading train:   4%|▍         | 12/285 [00:20<07:50,  1.72s/it]Loading train:   5%|▍         | 13/285 [00:22<07:05,  1.56s/it]Loading train:   5%|▍         | 14/285 [00:23<06:57,  1.54s/it]Loading train:   5%|▌         | 15/285 [00:24<06:28,  1.44s/it]Loading train:   6%|▌         | 16/285 [00:26<06:18,  1.41s/it]Loading train:   6%|▌         | 17/285 [00:27<06:27,  1.44s/it]Loading train:   6%|▋         | 18/285 [00:29<06:30,  1.46s/it]Loading train:   7%|▋         | 19/285 [00:30<05:51,  1.32s/it]Loading train:   7%|▋         | 20/285 [00:31<05:55,  1.34s/it]Loading train:   7%|▋         | 21/285 [00:33<06:17,  1.43s/it]Loading train:   8%|▊         | 22/285 [00:34<05:54,  1.35s/it]Loading train:   8%|▊         | 23/285 [00:35<06:15,  1.43s/it]Loading train:   8%|▊         | 24/285 [00:37<06:00,  1.38s/it]Loading train:   9%|▉         | 25/285 [00:38<06:20,  1.46s/it]Loading train:   9%|▉         | 26/285 [00:40<06:03,  1.40s/it]Loading train:   9%|▉         | 27/285 [00:41<05:38,  1.31s/it]Loading train:  10%|▉         | 28/285 [00:42<05:50,  1.36s/it]Loading train:  10%|█         | 29/285 [00:44<05:43,  1.34s/it]Loading train:  11%|█         | 30/285 [00:45<05:44,  1.35s/it]Loading train:  11%|█         | 31/285 [00:47<06:04,  1.43s/it]Loading train:  11%|█         | 32/285 [00:48<06:13,  1.48s/it]Loading train:  12%|█▏        | 33/285 [00:50<06:34,  1.57s/it]Loading train:  12%|█▏        | 34/285 [00:51<06:17,  1.50s/it]Loading train:  12%|█▏        | 35/285 [00:52<05:54,  1.42s/it]Loading train:  13%|█▎        | 36/285 [00:54<05:33,  1.34s/it]Loading train:  13%|█▎        | 37/285 [00:55<05:26,  1.32s/it]Loading train:  13%|█▎        | 38/285 [00:56<05:16,  1.28s/it]Loading train:  14%|█▎        | 39/285 [00:57<05:04,  1.24s/it]Loading train:  14%|█▍        | 40/285 [00:59<05:12,  1.27s/it]Loading train:  14%|█▍        | 41/285 [01:00<04:53,  1.20s/it]Loading train:  15%|█▍        | 42/285 [01:01<04:32,  1.12s/it]Loading train:  15%|█▌        | 43/285 [01:02<04:50,  1.20s/it]Loading train:  15%|█▌        | 44/285 [01:03<05:16,  1.31s/it]Loading train:  16%|█▌        | 45/285 [01:05<05:15,  1.32s/it]Loading train:  16%|█▌        | 46/285 [01:06<05:39,  1.42s/it]Loading train:  16%|█▋        | 47/285 [01:08<05:22,  1.36s/it]Loading train:  17%|█▋        | 48/285 [01:09<05:37,  1.42s/it]Loading train:  17%|█▋        | 49/285 [01:11<05:28,  1.39s/it]Loading train:  18%|█▊        | 50/285 [01:12<05:10,  1.32s/it]Loading train:  18%|█▊        | 51/285 [01:13<05:14,  1.34s/it]Loading train:  18%|█▊        | 52/285 [01:14<05:07,  1.32s/it]Loading train:  19%|█▊        | 53/285 [01:16<04:57,  1.28s/it]Loading train:  19%|█▉        | 54/285 [01:17<04:44,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:18<04:35,  1.20s/it]Loading train:  20%|█▉        | 56/285 [01:19<04:50,  1.27s/it]Loading train:  20%|██        | 57/285 [01:21<04:49,  1.27s/it]Loading train:  20%|██        | 58/285 [01:22<04:53,  1.29s/it]Loading train:  21%|██        | 59/285 [01:23<05:08,  1.36s/it]Loading train:  21%|██        | 60/285 [01:25<05:03,  1.35s/it]Loading train:  21%|██▏       | 61/285 [01:26<05:00,  1.34s/it]Loading train:  22%|██▏       | 62/285 [01:27<04:52,  1.31s/it]Loading train:  22%|██▏       | 63/285 [01:28<04:40,  1.27s/it]Loading train:  22%|██▏       | 64/285 [01:30<04:57,  1.35s/it]Loading train:  23%|██▎       | 65/285 [01:32<05:36,  1.53s/it]Loading train:  23%|██▎       | 66/285 [01:34<06:17,  1.72s/it]Loading train:  24%|██▎       | 67/285 [01:36<06:15,  1.72s/it]Loading train:  24%|██▍       | 68/285 [01:37<05:56,  1.64s/it]Loading train:  24%|██▍       | 69/285 [01:39<05:39,  1.57s/it]Loading train:  25%|██▍       | 70/285 [01:41<05:54,  1.65s/it]Loading train:  25%|██▍       | 71/285 [01:42<05:45,  1.61s/it]Loading train:  25%|██▌       | 72/285 [01:43<05:06,  1.44s/it]Loading train:  26%|██▌       | 73/285 [01:44<04:41,  1.33s/it]Loading train:  26%|██▌       | 74/285 [01:45<04:39,  1.32s/it]Loading train:  26%|██▋       | 75/285 [01:47<05:07,  1.47s/it]Loading train:  27%|██▋       | 76/285 [01:49<05:05,  1.46s/it]Loading train:  27%|██▋       | 77/285 [01:50<04:48,  1.39s/it]Loading train:  27%|██▋       | 78/285 [01:51<04:26,  1.29s/it]Loading train:  28%|██▊       | 79/285 [01:52<04:34,  1.33s/it]Loading train:  28%|██▊       | 80/285 [01:54<04:24,  1.29s/it]Loading train:  28%|██▊       | 81/285 [01:55<04:21,  1.28s/it]Loading train:  29%|██▉       | 82/285 [01:56<04:20,  1.28s/it]Loading train:  29%|██▉       | 83/285 [01:58<04:29,  1.33s/it]Loading train:  29%|██▉       | 84/285 [01:59<04:23,  1.31s/it]Loading train:  30%|██▉       | 85/285 [02:00<04:27,  1.34s/it]Loading train:  30%|███       | 86/285 [02:02<04:36,  1.39s/it]Loading train:  31%|███       | 87/285 [02:03<04:38,  1.41s/it]Loading train:  31%|███       | 88/285 [02:04<04:20,  1.32s/it]Loading train:  31%|███       | 89/285 [02:05<04:05,  1.25s/it]Loading train:  32%|███▏      | 90/285 [02:07<04:03,  1.25s/it]Loading train:  32%|███▏      | 91/285 [02:08<03:57,  1.23s/it]Loading train:  32%|███▏      | 92/285 [02:09<03:59,  1.24s/it]Loading train:  33%|███▎      | 93/285 [02:11<04:07,  1.29s/it]Loading train:  33%|███▎      | 94/285 [02:12<04:18,  1.35s/it]Loading train:  33%|███▎      | 95/285 [02:14<04:26,  1.40s/it]Loading train:  34%|███▎      | 96/285 [02:15<04:13,  1.34s/it]Loading train:  34%|███▍      | 97/285 [02:16<04:16,  1.37s/it]Loading train:  34%|███▍      | 98/285 [02:17<04:06,  1.32s/it]Loading train:  35%|███▍      | 99/285 [02:19<04:13,  1.36s/it]Loading train:  35%|███▌      | 100/285 [02:20<04:11,  1.36s/it]Loading train:  35%|███▌      | 101/285 [02:21<03:46,  1.23s/it]Loading train:  36%|███▌      | 102/285 [02:22<03:44,  1.22s/it]Loading train:  36%|███▌      | 103/285 [02:24<03:40,  1.21s/it]Loading train:  36%|███▋      | 104/285 [02:25<04:02,  1.34s/it]Loading train:  37%|███▋      | 105/285 [02:27<04:19,  1.44s/it]Loading train:  37%|███▋      | 106/285 [02:28<03:54,  1.31s/it]Loading train:  38%|███▊      | 107/285 [02:29<03:50,  1.29s/it]Loading train:  38%|███▊      | 108/285 [02:31<03:54,  1.33s/it]Loading train:  38%|███▊      | 109/285 [02:32<03:46,  1.29s/it]Loading train:  39%|███▊      | 110/285 [02:33<03:49,  1.31s/it]Loading train:  39%|███▉      | 111/285 [02:34<03:42,  1.28s/it]Loading train:  39%|███▉      | 112/285 [02:36<03:58,  1.38s/it]Loading train:  40%|███▉      | 113/285 [02:38<04:14,  1.48s/it]Loading train:  40%|████      | 114/285 [02:39<04:28,  1.57s/it]Loading train:  40%|████      | 115/285 [02:41<04:23,  1.55s/it]Loading train:  41%|████      | 116/285 [02:42<04:13,  1.50s/it]Loading train:  41%|████      | 117/285 [02:43<03:48,  1.36s/it]Loading train:  41%|████▏     | 118/285 [02:44<03:28,  1.25s/it]Loading train:  42%|████▏     | 119/285 [02:46<03:42,  1.34s/it]Loading train:  42%|████▏     | 120/285 [02:47<03:35,  1.30s/it]Loading train:  42%|████▏     | 121/285 [02:49<03:50,  1.40s/it]Loading train:  43%|████▎     | 122/285 [02:50<03:43,  1.37s/it]Loading train:  43%|████▎     | 123/285 [02:51<03:42,  1.37s/it]Loading train:  44%|████▎     | 124/285 [02:53<03:41,  1.37s/it]Loading train:  44%|████▍     | 125/285 [02:54<03:24,  1.28s/it]Loading train:  44%|████▍     | 126/285 [02:55<03:12,  1.21s/it]Loading train:  45%|████▍     | 127/285 [02:56<03:12,  1.22s/it]Loading train:  45%|████▍     | 128/285 [02:58<03:21,  1.28s/it]Loading train:  45%|████▌     | 129/285 [02:59<03:22,  1.30s/it]Loading train:  46%|████▌     | 130/285 [03:00<03:00,  1.17s/it]Loading train:  46%|████▌     | 131/285 [03:01<03:07,  1.22s/it]Loading train:  46%|████▋     | 132/285 [03:03<03:30,  1.37s/it]Loading train:  47%|████▋     | 133/285 [03:04<03:17,  1.30s/it]Loading train:  47%|████▋     | 134/285 [03:05<03:04,  1.22s/it]Loading train:  47%|████▋     | 135/285 [03:06<02:57,  1.18s/it]Loading train:  48%|████▊     | 136/285 [03:07<03:00,  1.21s/it]Loading train:  48%|████▊     | 137/285 [03:09<03:07,  1.26s/it]Loading train:  48%|████▊     | 138/285 [03:10<02:48,  1.14s/it]Loading train:  49%|████▉     | 139/285 [03:11<02:54,  1.20s/it]Loading train:  49%|████▉     | 140/285 [03:12<02:51,  1.18s/it]Loading train:  49%|████▉     | 141/285 [03:13<02:47,  1.16s/it]Loading train:  50%|████▉     | 142/285 [03:14<02:40,  1.12s/it]Loading train:  50%|█████     | 143/285 [03:15<02:27,  1.04s/it]Loading train:  51%|█████     | 144/285 [03:16<02:26,  1.04s/it]Loading train:  51%|█████     | 145/285 [03:17<02:23,  1.02s/it]Loading train:  51%|█████     | 146/285 [03:18<02:17,  1.01it/s]Loading train:  52%|█████▏    | 147/285 [03:19<02:20,  1.02s/it]Loading train:  52%|█████▏    | 148/285 [03:20<02:27,  1.08s/it]Loading train:  52%|█████▏    | 149/285 [03:21<02:22,  1.05s/it]Loading train:  53%|█████▎    | 150/285 [03:22<02:13,  1.01it/s]Loading train:  53%|█████▎    | 151/285 [03:24<02:40,  1.20s/it]Loading train:  53%|█████▎    | 152/285 [03:25<02:47,  1.26s/it]Loading train:  54%|█████▎    | 153/285 [03:26<02:36,  1.19s/it]Loading train:  54%|█████▍    | 154/285 [03:27<02:32,  1.16s/it]Loading train:  54%|█████▍    | 155/285 [03:28<02:30,  1.16s/it]Loading train:  55%|█████▍    | 156/285 [03:30<02:32,  1.18s/it]Loading train:  55%|█████▌    | 157/285 [03:31<02:32,  1.19s/it]Loading train:  55%|█████▌    | 158/285 [03:32<02:25,  1.14s/it]Loading train:  56%|█████▌    | 159/285 [03:33<02:23,  1.14s/it]Loading train:  56%|█████▌    | 160/285 [03:34<02:26,  1.17s/it]Loading train:  56%|█████▋    | 161/285 [03:35<02:25,  1.17s/it]Loading train:  57%|█████▋    | 162/285 [03:37<02:26,  1.19s/it]Loading train:  57%|█████▋    | 163/285 [03:38<02:28,  1.21s/it]Loading train:  58%|█████▊    | 164/285 [03:39<02:13,  1.10s/it]Loading train:  58%|█████▊    | 165/285 [03:40<02:05,  1.05s/it]Loading train:  58%|█████▊    | 166/285 [03:41<02:15,  1.14s/it]Loading train:  59%|█████▊    | 167/285 [03:43<02:23,  1.22s/it]Loading train:  59%|█████▉    | 168/285 [03:43<02:12,  1.14s/it]Loading train:  59%|█████▉    | 169/285 [03:45<02:14,  1.16s/it]Loading train:  60%|█████▉    | 170/285 [03:46<02:20,  1.22s/it]Loading train:  60%|██████    | 171/285 [03:47<02:16,  1.19s/it]Loading train:  60%|██████    | 172/285 [03:48<02:04,  1.10s/it]Loading train:  61%|██████    | 173/285 [03:49<01:59,  1.07s/it]Loading train:  61%|██████    | 174/285 [03:50<01:59,  1.08s/it]Loading train:  61%|██████▏   | 175/285 [03:51<01:59,  1.09s/it]Loading train:  62%|██████▏   | 176/285 [03:52<02:02,  1.12s/it]Loading train:  62%|██████▏   | 177/285 [03:54<02:04,  1.15s/it]Loading train:  62%|██████▏   | 178/285 [03:55<02:07,  1.20s/it]Loading train:  63%|██████▎   | 179/285 [03:56<02:04,  1.17s/it]Loading train:  63%|██████▎   | 180/285 [03:57<02:08,  1.22s/it]Loading train:  64%|██████▎   | 181/285 [03:58<01:57,  1.13s/it]Loading train:  64%|██████▍   | 182/285 [04:00<02:00,  1.17s/it]Loading train:  64%|██████▍   | 183/285 [04:01<02:03,  1.21s/it]Loading train:  65%|██████▍   | 184/285 [04:02<02:03,  1.22s/it]Loading train:  65%|██████▍   | 185/285 [04:03<02:02,  1.22s/it]Loading train:  65%|██████▌   | 186/285 [04:05<02:01,  1.23s/it]Loading train:  66%|██████▌   | 187/285 [04:06<01:58,  1.21s/it]Loading train:  66%|██████▌   | 188/285 [04:07<02:02,  1.26s/it]Loading train:  66%|██████▋   | 189/285 [04:08<01:48,  1.13s/it]Loading train:  67%|██████▋   | 190/285 [04:09<01:52,  1.18s/it]Loading train:  67%|██████▋   | 191/285 [04:11<01:51,  1.19s/it]Loading train:  67%|██████▋   | 192/285 [04:12<01:58,  1.27s/it]Loading train:  68%|██████▊   | 193/285 [04:13<01:50,  1.20s/it]Loading train:  68%|██████▊   | 194/285 [04:14<01:43,  1.14s/it]Loading train:  68%|██████▊   | 195/285 [04:15<01:43,  1.15s/it]Loading train:  69%|██████▉   | 196/285 [04:17<02:06,  1.42s/it]Loading train:  69%|██████▉   | 197/285 [04:19<02:09,  1.47s/it]Loading train:  69%|██████▉   | 198/285 [04:21<02:16,  1.57s/it]Loading train:  70%|██████▉   | 199/285 [04:21<01:54,  1.33s/it]Loading train:  70%|███████   | 200/285 [04:22<01:42,  1.20s/it]Loading train:  71%|███████   | 201/285 [04:23<01:39,  1.18s/it]Loading train:  71%|███████   | 202/285 [04:25<01:40,  1.21s/it]Loading train:  71%|███████   | 203/285 [04:26<01:37,  1.19s/it]Loading train:  72%|███████▏  | 204/285 [04:27<01:29,  1.11s/it]Loading train:  72%|███████▏  | 205/285 [04:28<01:28,  1.10s/it]Loading train:  72%|███████▏  | 206/285 [04:29<01:16,  1.03it/s]Loading train:  73%|███████▎  | 207/285 [04:29<01:13,  1.07it/s]Loading train:  73%|███████▎  | 208/285 [04:30<01:09,  1.10it/s]Loading train:  73%|███████▎  | 209/285 [04:31<01:08,  1.11it/s]Loading train:  74%|███████▎  | 210/285 [04:32<01:00,  1.23it/s]Loading train:  74%|███████▍  | 211/285 [04:32<00:57,  1.28it/s]Loading train:  74%|███████▍  | 212/285 [04:33<00:58,  1.25it/s]Loading train:  75%|███████▍  | 213/285 [04:34<00:58,  1.24it/s]Loading train:  75%|███████▌  | 214/285 [04:35<00:57,  1.22it/s]Loading train:  75%|███████▌  | 215/285 [04:36<01:02,  1.13it/s]Loading train:  76%|███████▌  | 216/285 [04:37<00:57,  1.19it/s]Loading train:  76%|███████▌  | 217/285 [04:38<01:00,  1.11it/s]Loading train:  76%|███████▋  | 218/285 [04:39<01:01,  1.09it/s]Loading train:  77%|███████▋  | 219/285 [04:40<01:01,  1.07it/s]Loading train:  77%|███████▋  | 220/285 [04:40<00:57,  1.13it/s]Loading train:  78%|███████▊  | 221/285 [04:41<00:56,  1.13it/s]Loading train:  78%|███████▊  | 222/285 [04:42<00:56,  1.12it/s]Loading train:  78%|███████▊  | 223/285 [04:43<00:55,  1.12it/s]Loading train:  79%|███████▊  | 224/285 [04:44<00:52,  1.16it/s]Loading train:  79%|███████▉  | 225/285 [04:45<00:51,  1.16it/s]Loading train:  79%|███████▉  | 226/285 [04:46<00:52,  1.12it/s]Loading train:  80%|███████▉  | 227/285 [04:47<00:53,  1.08it/s]Loading train:  80%|████████  | 228/285 [04:48<00:55,  1.02it/s]Loading train:  80%|████████  | 229/285 [04:49<00:52,  1.06it/s]Loading train:  81%|████████  | 230/285 [04:49<00:48,  1.14it/s]Loading train:  81%|████████  | 231/285 [04:50<00:45,  1.20it/s]Loading train:  81%|████████▏ | 232/285 [04:51<00:44,  1.19it/s]Loading train:  82%|████████▏ | 233/285 [04:52<00:41,  1.26it/s]Loading train:  82%|████████▏ | 234/285 [04:53<00:44,  1.15it/s]Loading train:  82%|████████▏ | 235/285 [04:53<00:41,  1.22it/s]Loading train:  83%|████████▎ | 236/285 [04:54<00:42,  1.14it/s]Loading train:  83%|████████▎ | 237/285 [04:55<00:42,  1.13it/s]Loading train:  84%|████████▎ | 238/285 [04:56<00:41,  1.13it/s]Loading train:  84%|████████▍ | 239/285 [04:57<00:38,  1.18it/s]Loading train:  84%|████████▍ | 240/285 [04:58<00:34,  1.30it/s]Loading train:  85%|████████▍ | 241/285 [04:58<00:32,  1.36it/s]Loading train:  85%|████████▍ | 242/285 [04:59<00:30,  1.42it/s]Loading train:  85%|████████▌ | 243/285 [05:00<00:29,  1.45it/s]Loading train:  86%|████████▌ | 244/285 [05:00<00:31,  1.32it/s]Loading train:  86%|████████▌ | 245/285 [05:01<00:30,  1.32it/s]Loading train:  86%|████████▋ | 246/285 [05:02<00:32,  1.22it/s]Loading train:  87%|████████▋ | 247/285 [05:03<00:32,  1.18it/s]Loading train:  87%|████████▋ | 248/285 [05:04<00:30,  1.20it/s]Loading train:  87%|████████▋ | 249/285 [05:05<00:28,  1.25it/s]Loading train:  88%|████████▊ | 250/285 [05:05<00:27,  1.27it/s]Loading train:  88%|████████▊ | 251/285 [05:06<00:27,  1.25it/s]Loading train:  88%|████████▊ | 252/285 [05:07<00:28,  1.16it/s]Loading train:  89%|████████▉ | 253/285 [05:08<00:29,  1.08it/s]Loading train:  89%|████████▉ | 254/285 [05:09<00:30,  1.01it/s]Loading train:  89%|████████▉ | 255/285 [05:10<00:29,  1.01it/s]Loading train:  90%|████████▉ | 256/285 [05:11<00:27,  1.07it/s]Loading train:  90%|█████████ | 257/285 [05:12<00:26,  1.08it/s]Loading train:  91%|█████████ | 258/285 [05:13<00:26,  1.03it/s]Loading train:  91%|█████████ | 259/285 [05:14<00:25,  1.00it/s]Loading train:  91%|█████████ | 260/285 [05:15<00:23,  1.08it/s]Loading train:  92%|█████████▏| 261/285 [05:16<00:24,  1.03s/it]Loading train:  92%|█████████▏| 262/285 [05:17<00:22,  1.02it/s]Loading train:  92%|█████████▏| 263/285 [05:18<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [05:19<00:22,  1.05s/it]Loading train:  93%|█████████▎| 265/285 [05:21<00:22,  1.10s/it]Loading train:  93%|█████████▎| 266/285 [05:21<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [05:22<00:18,  1.00s/it]Loading train:  94%|█████████▍| 268/285 [05:23<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [05:24<00:16,  1.03s/it]Loading train:  95%|█████████▍| 270/285 [05:26<00:15,  1.06s/it]Loading train:  95%|█████████▌| 271/285 [05:27<00:14,  1.02s/it]Loading train:  95%|█████████▌| 272/285 [05:27<00:12,  1.01it/s]Loading train:  96%|█████████▌| 273/285 [05:28<00:11,  1.02it/s]Loading train:  96%|█████████▌| 274/285 [05:29<00:10,  1.07it/s]Loading train:  96%|█████████▋| 275/285 [05:30<00:09,  1.00it/s]Loading train:  97%|█████████▋| 276/285 [05:32<00:09,  1.08s/it]Loading train:  97%|█████████▋| 277/285 [05:32<00:08,  1.02s/it]Loading train:  98%|█████████▊| 278/285 [05:33<00:06,  1.03it/s]Loading train:  98%|█████████▊| 279/285 [05:34<00:05,  1.03it/s]Loading train:  98%|█████████▊| 280/285 [05:35<00:04,  1.03it/s]Loading train:  99%|█████████▊| 281/285 [05:37<00:04,  1.06s/it]Loading train:  99%|█████████▉| 282/285 [05:37<00:02,  1.00it/s]Loading train:  99%|█████████▉| 283/285 [05:39<00:02,  1.05s/it]Loading train: 100%|█████████▉| 284/285 [05:40<00:01,  1.10s/it]Loading train: 100%|██████████| 285/285 [05:41<00:00,  1.16s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 11/285 [00:00<00:02, 106.12it/s]concatenating: train:   6%|▋         | 18/285 [00:00<00:02, 89.09it/s] concatenating: train:   9%|▉         | 25/285 [00:00<00:03, 79.01it/s]concatenating: train:  11%|█         | 32/285 [00:00<00:03, 73.21it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:03, 69.63it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:03, 67.33it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:03, 60.99it/s]concatenating: train:  20%|██        | 58/285 [00:00<00:03, 57.21it/s]concatenating: train:  23%|██▎       | 65/285 [00:01<00:03, 58.70it/s]concatenating: train:  25%|██▌       | 72/285 [00:01<00:03, 59.79it/s]concatenating: train:  27%|██▋       | 78/285 [00:01<00:03, 55.22it/s]concatenating: train:  30%|██▉       | 85/285 [00:01<00:03, 57.23it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:03, 58.71it/s]concatenating: train:  35%|███▍      | 99/285 [00:01<00:03, 59.80it/s]concatenating: train:  37%|███▋      | 105/285 [00:01<00:03, 59.15it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:03, 52.54it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:03, 51.75it/s]concatenating: train:  44%|████▎     | 124/285 [00:02<00:02, 54.57it/s]concatenating: train:  46%|████▌     | 131/285 [00:02<00:02, 56.73it/s]concatenating: train:  48%|████▊     | 138/285 [00:02<00:02, 58.34it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 59.53it/s]concatenating: train:  53%|█████▎    | 152/285 [00:02<00:02, 60.39it/s]concatenating: train:  56%|█████▌    | 159/285 [00:02<00:02, 61.01it/s]concatenating: train:  58%|█████▊    | 166/285 [00:02<00:01, 61.45it/s]concatenating: train:  61%|██████    | 173/285 [00:02<00:01, 61.76it/s]concatenating: train:  63%|██████▎   | 180/285 [00:02<00:01, 61.98it/s]concatenating: train:  66%|██████▌   | 187/285 [00:03<00:01, 62.13it/s]concatenating: train:  68%|██████▊   | 194/285 [00:03<00:01, 54.15it/s]concatenating: train:  70%|███████   | 200/285 [00:03<00:01, 46.89it/s]concatenating: train:  76%|███████▋  | 218/285 [00:03<00:01, 60.16it/s]concatenating: train:  86%|████████▌ | 244/285 [00:03<00:00, 78.07it/s]concatenating: train:  91%|█████████ | 259/285 [00:03<00:00, 91.07it/s]concatenating: train:  96%|█████████▌| 274/285 [00:03<00:00, 98.67it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 72.11it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.41s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 117.19it/s]2019-07-11 05:08:12.281456: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:08:12.281599: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:08:12.281614: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:08:12.281622: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:08:12.282085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.60it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.50it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.34it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.71it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.13it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.96it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.58it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.27it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.63it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.47it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.12it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  8.64it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  8.91it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.05it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.52it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.78it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  9.02it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.03it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.83it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 30)   12180       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 75)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   988         concatenate_8[0][0]              
==================================================================================================
Total params: 151,888
Trainable params: 53,248
Non-trainable params: 98,640
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 17s - loss: 2.6234 - acc: 0.6284 - mDice: 0.1389 - val_loss: 1.6649 - val_acc: 0.9194 - val_mDice: 0.3649

Epoch 00001: val_mDice improved from -inf to 0.36488, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 0.7057 - acc: 0.9042 - mDice: 0.4875 - val_loss: 1.1614 - val_acc: 0.9385 - val_mDice: 0.5244

Epoch 00002: val_mDice improved from 0.36488 to 0.52441, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.5023 - acc: 0.9200 - mDice: 0.5896 - val_loss: 1.0887 - val_acc: 0.9426 - val_mDice: 0.5521

Epoch 00003: val_mDice improved from 0.52441 to 0.55214, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.4566 - acc: 0.9263 - mDice: 0.6182 - val_loss: 1.0320 - val_acc: 0.9400 - val_mDice: 0.5662

Epoch 00004: val_mDice improved from 0.55214 to 0.56624, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.4352 - acc: 0.9294 - mDice: 0.6320 - val_loss: 0.9884 - val_acc: 0.9431 - val_mDice: 0.5826

Epoch 00005: val_mDice improved from 0.56624 to 0.58265, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 10s - loss: 0.4177 - acc: 0.9314 - mDice: 0.6434 - val_loss: 1.0100 - val_acc: 0.9445 - val_mDice: 0.5596

Epoch 00006: val_mDice did not improve from 0.58265
Epoch 7/300
 - 10s - loss: 0.4053 - acc: 0.9329 - mDice: 0.6517 - val_loss: 0.9733 - val_acc: 0.9347 - val_mDice: 0.5706

Epoch 00007: val_mDice did not improve from 0.58265
Epoch 8/300
 - 10s - loss: 0.3978 - acc: 0.9338 - mDice: 0.6568 - val_loss: 1.0957 - val_acc: 0.9379 - val_mDice: 0.4997

Epoch 00008: val_mDice did not improve from 0.58265
Epoch 9/300
 - 11s - loss: 0.3880 - acc: 0.9350 - mDice: 0.6635 - val_loss: 0.9615 - val_acc: 0.9390 - val_mDice: 0.5774

Epoch 00009: val_mDice did not improve from 0.58265
Epoch 10/300
 - 11s - loss: 0.3808 - acc: 0.9358 - mDice: 0.6686 - val_loss: 0.9791 - val_acc: 0.9462 - val_mDice: 0.5667

Epoch 00010: val_mDice did not improve from 0.58265
Epoch 11/300
 - 10s - loss: 0.3770 - acc: 0.9361 - mDice: 0.6710 - val_loss: 0.9860 - val_acc: 0.9454 - val_mDice: 0.5631

Epoch 00011: val_mDice did not improve from 0.58265
Epoch 12/300
 - 10s - loss: 0.3723 - acc: 0.9366 - mDice: 0.6743 - val_loss: 0.9310 - val_acc: 0.9464 - val_mDice: 0.5881

Epoch 00012: val_mDice improved from 0.58265 to 0.58809, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 10s - loss: 0.3658 - acc: 0.9373 - mDice: 0.6788 - val_loss: 0.9955 - val_acc: 0.9430 - val_mDice: 0.5436

Epoch 00013: val_mDice did not improve from 0.58809
Epoch 14/300
 - 10s - loss: 0.3612 - acc: 0.9377 - mDice: 0.6821 - val_loss: 0.9557 - val_acc: 0.9423 - val_mDice: 0.5713

Epoch 00014: val_mDice did not improve from 0.58809
Epoch 15/300
 - 10s - loss: 0.3604 - acc: 0.9379 - mDice: 0.6830 - val_loss: 0.9724 - val_acc: 0.9458 - val_mDice: 0.5586

Epoch 00015: val_mDice did not improve from 0.58809
Epoch 16/300
 - 10s - loss: 0.3538 - acc: 0.9383 - mDice: 0.6873 - val_loss: 0.9540 - val_acc: 0.9456 - val_mDice: 0.5531

Epoch 00016: val_mDice did not improve from 0.58809
Epoch 17/300
 - 10s - loss: 0.3498 - acc: 0.9390 - mDice: 0.6902 - val_loss: 0.9575 - val_acc: 0.9432 - val_mDice: 0.5627

Epoch 00017: val_mDice did not improve from 0.58809
Epoch 18/300
 - 11s - loss: 0.3468 - acc: 0.9392 - mDice: 0.6923 - val_loss: 0.9139 - val_acc: 0.9454 - val_mDice: 0.5763

Epoch 00018: val_mDice did not improve from 0.58809
Epoch 19/300
 - 10s - loss: 0.3458 - acc: 0.9394 - mDice: 0.6930 - val_loss: 0.9262 - val_acc: 0.9462 - val_mDice: 0.5760

Epoch 00019: val_mDice did not improve from 0.58809
Epoch 20/300
 - 10s - loss: 0.3403 - acc: 0.9399 - mDice: 0.6970 - val_loss: 0.9229 - val_acc: 0.9431 - val_mDice: 0.5794

Epoch 00020: val_mDice did not improve from 0.58809
Epoch 21/300
 - 10s - loss: 0.3389 - acc: 0.9401 - mDice: 0.6980 - val_loss: 0.9007 - val_acc: 0.9462 - val_mDice: 0.5751

Epoch 00021: val_mDice did not improve from 0.58809
Epoch 22/300
 - 10s - loss: 0.3384 - acc: 0.9401 - mDice: 0.6983 - val_loss: 0.8917 - val_acc: 0.9467 - val_mDice: 0.5852

Epoch 00022: val_mDice did not improve from 0.58809
Epoch 23/300
 - 10s - loss: 0.3341 - acc: 0.9404 - mDice: 0.7014 - val_loss: 0.9526 - val_acc: 0.9445 - val_mDice: 0.5523

Epoch 00023: val_mDice did not improve from 0.58809
Epoch 24/300
 - 10s - loss: 0.3336 - acc: 0.9405 - mDice: 0.7018 - val_loss: 0.9102 - val_acc: 0.9444 - val_mDice: 0.5746

Epoch 00024: val_mDice did not improve from 0.58809
Epoch 25/300
 - 11s - loss: 0.3317 - acc: 0.9408 - mDice: 0.7033 - val_loss: 0.9252 - val_acc: 0.9453 - val_mDice: 0.5644

Epoch 00025: val_mDice did not improve from 0.58809
Epoch 26/300
 - 10s - loss: 0.3286 - acc: 0.9411 - mDice: 0.7054 - val_loss: 0.9280 - val_acc: 0.9446 - val_mDice: 0.5660

Epoch 00026: val_mDice did not improve from 0.58809
Epoch 27/300
 - 10s - loss: 0.3258 - acc: 0.9414 - mDice: 0.7075 - val_loss: 0.9047 - val_acc: 0.9461 - val_mDice: 0.5714

Epoch 00027: val_mDice did not improve from 0.58809
Epoch 28/300
 - 11s - loss: 0.3245 - acc: 0.9414 - mDice: 0.7085 - val_loss: 0.8853 - val_acc: 0.9412 - val_mDice: 0.5765

Epoch 00028: val_mDice did not improve from 0.58809
Epoch 29/300
 - 11s - loss: 0.3222 - acc: 0.9416 - mDice: 0.7100 - val_loss: 0.8827 - val_acc: 0.9459 - val_mDice: 0.5800

Epoch 00029: val_mDice did not improve from 0.58809
Epoch 30/300
 - 11s - loss: 0.3205 - acc: 0.9418 - mDice: 0.7114 - val_loss: 0.9194 - val_acc: 0.9471 - val_mDice: 0.5573

Epoch 00030: val_mDice did not improve from 0.58809
Epoch 31/300
 - 10s - loss: 0.3197 - acc: 0.9420 - mDice: 0.7120 - val_loss: 0.9177 - val_acc: 0.9353 - val_mDice: 0.5512

Epoch 00031: val_mDice did not improve from 0.58809
Epoch 32/300
 - 10s - loss: 0.3193 - acc: 0.9419 - mDice: 0.7123 - val_loss: 0.8769 - val_acc: 0.9447 - val_mDice: 0.5790

Epoch 00032: val_mDice did not improve from 0.58809
Epoch 33/300
 - 11s - loss: 0.3170 - acc: 0.9422 - mDice: 0.7140 - val_loss: 0.8688 - val_acc: 0.9479 - val_mDice: 0.5767

Epoch 00033: val_mDice did not improve from 0.58809
Epoch 34/300
 - 10s - loss: 0.3165 - acc: 0.9422 - mDice: 0.7144 - val_loss: 0.9315 - val_acc: 0.9438 - val_mDice: 0.5226

Epoch 00034: val_mDice did not improve from 0.58809
Epoch 35/300
 - 11s - loss: 0.3145 - acc: 0.9423 - mDice: 0.7158 - val_loss: 0.9328 - val_acc: 0.9432 - val_mDice: 0.5382

Epoch 00035: val_mDice did not improve from 0.58809
Epoch 36/300
 - 10s - loss: 0.3134 - acc: 0.9424 - mDice: 0.7166 - val_loss: 0.8353 - val_acc: 0.9451 - val_mDice: 0.5737

Epoch 00036: val_mDice did not improve from 0.58809
Epoch 37/300
 - 10s - loss: 0.3105 - acc: 0.9427 - mDice: 0.7187 - val_loss: 0.8508 - val_acc: 0.9450 - val_mDice: 0.5724

Epoch 00037: val_mDice did not improve from 0.58809
Epoch 38/300
 - 10s - loss: 0.3110 - acc: 0.9427 - mDice: 0.7184 - val_loss: 0.8684 - val_acc: 0.9472 - val_mDice: 0.5638

Epoch 00038: val_mDice did not improve from 0.58809
Epoch 39/300
 - 11s - loss: 0.3080 - acc: 0.9430 - mDice: 0.7207 - val_loss: 0.8448 - val_acc: 0.9455 - val_mDice: 0.5734

Epoch 00039: val_mDice did not improve from 0.58809
Epoch 40/300
 - 10s - loss: 0.3088 - acc: 0.9430 - mDice: 0.7201 - val_loss: 0.8072 - val_acc: 0.9453 - val_mDice: 0.5735

Epoch 00040: val_mDice did not improve from 0.58809
Epoch 41/300
 - 10s - loss: 0.3068 - acc: 0.9432 - mDice: 0.7216 - val_loss: 0.8573 - val_acc: 0.9438 - val_mDice: 0.5695

Epoch 00041: val_mDice did not improve from 0.58809
Epoch 42/300
 - 10s - loss: 0.3065 - acc: 0.9431 - mDice: 0.7219 - val_loss: 0.8240 - val_acc: 0.9465 - val_mDice: 0.5711

Epoch 00042: val_mDice did not improve from 0.58809
Epoch 43/300
 - 10s - loss: 0.3044 - acc: 0.9433 - mDice: 0.7234 - val_loss: 0.8021 - val_acc: 0.9472 - val_mDice: 0.5766

Epoch 00043: val_mDice did not improve from 0.58809
Epoch 44/300
 - 11s - loss: 0.3042 - acc: 0.9433 - mDice: 0.7235 - val_loss: 0.8222 - val_acc: 0.9451 - val_mDice: 0.5807

Epoch 00044: val_mDice did not improve from 0.58809
Epoch 45/300
 - 11s - loss: 0.3017 - acc: 0.9436 - mDice: 0.7254 - val_loss: 0.8086 - val_acc: 0.9463 - val_mDice: 0.5737

Epoch 00045: val_mDice did not improve from 0.58809
Epoch 46/300
 - 10s - loss: 0.3014 - acc: 0.9437 - mDice: 0.7257 - val_loss: 0.8748 - val_acc: 0.9445 - val_mDice: 0.5407

Epoch 00046: val_mDice did not improve from 0.58809
Epoch 47/300
 - 10s - loss: 0.3013 - acc: 0.9436 - mDice: 0.7256 - val_loss: 0.8269 - val_acc: 0.9427 - val_mDice: 0.5685

Epoch 00047: val_mDice did not improve from 0.58809
Epoch 48/300
 - 10s - loss: 0.2992 - acc: 0.9438 - mDice: 0.7274 - val_loss: 0.8012 - val_acc: 0.9469 - val_mDice: 0.5624

Epoch 00048: val_mDice did not improve from 0.58809
Epoch 49/300
 - 10s - loss: 0.2992 - acc: 0.9439 - mDice: 0.7272 - val_loss: 0.7558 - val_acc: 0.9463 - val_mDice: 0.5803

Epoch 00049: val_mDice did not improve from 0.58809
Epoch 50/300
 - 10s - loss: 0.2976 - acc: 0.9440 - mDice: 0.7285 - val_loss: 0.7836 - val_acc: 0.9455 - val_mDice: 0.5715

Epoch 00050: val_mDice did not improve from 0.58809
Epoch 51/300
 - 10s - loss: 0.2990 - acc: 0.9438 - mDice: 0.7274 - val_loss: 0.7904 - val_acc: 0.9396 - val_mDice: 0.5679

Epoch 00051: val_mDice did not improve from 0.58809
Epoch 52/300
 - 11s - loss: 0.2974 - acc: 0.9440 - mDice: 0.7286 - val_loss: 0.7638 - val_acc: 0.9448 - val_mDice: 0.5650

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.35s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.08s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:24,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:46,  1.65s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:24,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:42,  1.65s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:21,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:42,  1.66s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:37,  1.65s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:00,  1.74s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:17,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:49,  1.71s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:09,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:45,  1.71s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:54,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:05,  1.80s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:14,  1.84s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<07:46,  1.74s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:50,  1.76s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:25,  1.68s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:33,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:52,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:32,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:40,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:25,  1.71s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:43,  1.78s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:54,  1.83s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:25,  1.73s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:35,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:50<07:32,  1.77s/it]predicting train subjects:  11%|█         | 30/285 [00:52<07:42,  1.81s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:46,  1.84s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:18,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:57<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:59<07:23,  1.77s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:34,  1.82s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:10,  1.73s/it]predicting train subjects:  13%|█▎        | 37/285 [01:04<07:19,  1.77s/it]predicting train subjects:  13%|█▎        | 38/285 [01:06<07:30,  1.82s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:04,  1.73s/it]predicting train subjects:  14%|█▍        | 41/285 [01:11<06:49,  1.68s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:38,  1.64s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:53,  1.71s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:11,  1.79s/it]predicting train subjects:  16%|█▌        | 45/285 [01:18<06:50,  1.71s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<07:02,  1.77s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:44,  1.70s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:48,  1.72s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<06:58,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:27<07:04,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:29<07:17,  1.87s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:54,  1.78s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:56,  1.80s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:11,  1.87s/it]predicting train subjects:  19%|█▉        | 55/285 [01:36<06:47,  1.77s/it]predicting train subjects:  20%|█▉        | 56/285 [01:37<06:54,  1.81s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:35,  1.73s/it]predicting train subjects:  20%|██        | 58/285 [01:41<06:40,  1.76s/it]predicting train subjects:  21%|██        | 59/285 [01:43<06:54,  1.83s/it]predicting train subjects:  21%|██        | 60/285 [01:45<07:02,  1.88s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:47,  1.82s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:50,  1.84s/it]predicting train subjects:  22%|██▏       | 63/285 [01:50<06:51,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [01:52<06:37,  1.80s/it]predicting train subjects:  23%|██▎       | 65/285 [01:54<06:37,  1.81s/it]predicting train subjects:  23%|██▎       | 66/285 [01:56<06:34,  1.80s/it]predicting train subjects:  24%|██▎       | 67/285 [01:57<06:34,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [01:59<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 69/285 [02:01<06:16,  1.74s/it]predicting train subjects:  25%|██▍       | 70/285 [02:03<06:21,  1.78s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:29,  1.82s/it]predicting train subjects:  25%|██▌       | 72/285 [02:06<06:23,  1.80s/it]predicting train subjects:  26%|██▌       | 73/285 [02:08<06:25,  1.82s/it]predicting train subjects:  26%|██▌       | 74/285 [02:10<06:23,  1.82s/it]predicting train subjects:  26%|██▋       | 75/285 [02:12<06:24,  1.83s/it]predicting train subjects:  27%|██▋       | 76/285 [02:14<06:25,  1.85s/it]predicting train subjects:  27%|██▋       | 77/285 [02:15<06:15,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:17<05:59,  1.74s/it]predicting train subjects:  28%|██▊       | 79/285 [02:19<05:56,  1.73s/it]predicting train subjects:  28%|██▊       | 80/285 [02:20<05:55,  1.73s/it]predicting train subjects:  28%|██▊       | 81/285 [02:22<05:49,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:24<05:52,  1.74s/it]predicting train subjects:  29%|██▉       | 83/285 [02:26<05:48,  1.72s/it]predicting train subjects:  29%|██▉       | 84/285 [02:27<05:39,  1.69s/it]predicting train subjects:  30%|██▉       | 85/285 [02:29<05:39,  1.70s/it]predicting train subjects:  30%|███       | 86/285 [02:31<05:47,  1.75s/it]predicting train subjects:  31%|███       | 87/285 [02:33<05:49,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:34<05:36,  1.71s/it]predicting train subjects:  31%|███       | 89/285 [02:36<05:35,  1.71s/it]predicting train subjects:  32%|███▏      | 90/285 [02:38<05:39,  1.74s/it]predicting train subjects:  32%|███▏      | 91/285 [02:39<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:41<05:36,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:43<05:27,  1.70s/it]predicting train subjects:  33%|███▎      | 94/285 [02:44<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:46<05:32,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:48<05:34,  1.77s/it]predicting train subjects:  34%|███▍      | 97/285 [02:50<05:37,  1.79s/it]predicting train subjects:  34%|███▍      | 98/285 [02:52<05:38,  1.81s/it]predicting train subjects:  35%|███▍      | 99/285 [02:54<05:36,  1.81s/it]predicting train subjects:  35%|███▌      | 100/285 [02:55<05:38,  1.83s/it]predicting train subjects:  35%|███▌      | 101/285 [02:57<05:25,  1.77s/it]predicting train subjects:  36%|███▌      | 102/285 [02:59<05:32,  1.82s/it]predicting train subjects:  36%|███▌      | 103/285 [03:01<05:18,  1.75s/it]predicting train subjects:  36%|███▋      | 104/285 [03:02<05:16,  1.75s/it]predicting train subjects:  37%|███▋      | 105/285 [03:04<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:06<05:14,  1.76s/it]predicting train subjects:  38%|███▊      | 107/285 [03:08<05:11,  1.75s/it]predicting train subjects:  38%|███▊      | 108/285 [03:09<05:04,  1.72s/it]predicting train subjects:  38%|███▊      | 109/285 [03:11<05:04,  1.73s/it]predicting train subjects:  39%|███▊      | 110/285 [03:13<05:09,  1.77s/it]predicting train subjects:  39%|███▉      | 111/285 [03:15<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:16<05:05,  1.77s/it]predicting train subjects:  40%|███▉      | 113/285 [03:18<05:08,  1.79s/it]predicting train subjects:  40%|████      | 114/285 [03:20<05:02,  1.77s/it]predicting train subjects:  40%|████      | 115/285 [03:22<05:02,  1.78s/it]predicting train subjects:  41%|████      | 116/285 [03:24<05:02,  1.79s/it]predicting train subjects:  41%|████      | 117/285 [03:25<04:50,  1.73s/it]predicting train subjects:  41%|████▏     | 118/285 [03:27<04:44,  1.70s/it]predicting train subjects:  42%|████▏     | 119/285 [03:29<04:49,  1.74s/it]predicting train subjects:  42%|████▏     | 120/285 [03:30<04:41,  1.71s/it]predicting train subjects:  42%|████▏     | 121/285 [03:32<04:38,  1.70s/it]predicting train subjects:  43%|████▎     | 122/285 [03:34<04:31,  1.66s/it]predicting train subjects:  43%|████▎     | 123/285 [03:35<04:18,  1.59s/it]predicting train subjects:  44%|████▎     | 124/285 [03:37<04:16,  1.59s/it]predicting train subjects:  44%|████▍     | 125/285 [03:38<04:11,  1.57s/it]predicting train subjects:  44%|████▍     | 126/285 [03:40<04:05,  1.55s/it]predicting train subjects:  45%|████▍     | 127/285 [03:41<03:58,  1.51s/it]predicting train subjects:  45%|████▍     | 128/285 [03:43<04:01,  1.54s/it]predicting train subjects:  45%|████▌     | 129/285 [03:44<03:59,  1.54s/it]predicting train subjects:  46%|████▌     | 130/285 [03:46<03:53,  1.50s/it]predicting train subjects:  46%|████▌     | 131/285 [03:47<03:44,  1.46s/it]predicting train subjects:  46%|████▋     | 132/285 [03:49<03:51,  1.51s/it]predicting train subjects:  47%|████▋     | 133/285 [03:50<03:48,  1.50s/it]predicting train subjects:  47%|████▋     | 134/285 [03:51<03:43,  1.48s/it]predicting train subjects:  47%|████▋     | 135/285 [03:53<03:40,  1.47s/it]predicting train subjects:  48%|████▊     | 136/285 [03:54<03:38,  1.47s/it]predicting train subjects:  48%|████▊     | 137/285 [03:56<03:42,  1.51s/it]predicting train subjects:  48%|████▊     | 138/285 [03:57<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:59<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 140/285 [04:01<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [04:02<03:31,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [04:03<03:28,  1.46s/it]predicting train subjects:  50%|█████     | 143/285 [04:05<03:25,  1.45s/it]predicting train subjects:  51%|█████     | 144/285 [04:06<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:08<03:23,  1.45s/it]predicting train subjects:  51%|█████     | 146/285 [04:09<03:28,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:11<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:12<03:29,  1.53s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:14<03:26,  1.52s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:15<03:23,  1.50s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:17<03:22,  1.51s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:18<03:14,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:20<03:09,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:21<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:23<03:12,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:24<03:15,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:26<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:27<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:28<03:02,  1.44s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:30<03:00,  1.44s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:32<03:06,  1.51s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:33<03:02,  1.48s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:35<03:03,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:36<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:37<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:39<02:59,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:41<02:58,  1.51s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:42<02:52,  1.48s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:43<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:45<02:46,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:46<02:44,  1.44s/it]predicting train subjects:  60%|██████    | 172/285 [04:48<02:40,  1.42s/it]predicting train subjects:  61%|██████    | 173/285 [04:49<02:40,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:50<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:52<02:40,  1.46s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:54<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:55<02:40,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:56<02:36,  1.46s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:58<02:34,  1.46s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:00<02:42,  1.55s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:01<02:46,  1.60s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:03<02:47,  1.63s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:05<02:40,  1.57s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:06<02:33,  1.52s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:07<02:28,  1.49s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:09<02:37,  1.59s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:11<02:42,  1.66s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:13<02:47,  1.73s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:14<02:34,  1.61s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:16<02:27,  1.55s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:17<02:27,  1.57s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:19<02:27,  1.59s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:20<02:20,  1.53s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:22<02:16,  1.50s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:23<02:12,  1.47s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:25<02:23,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:27<02:29,  1.70s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:29<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:30<02:20,  1.64s/it]predicting train subjects:  70%|███████   | 200/285 [05:32<02:15,  1.60s/it]predicting train subjects:  71%|███████   | 201/285 [05:34<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:35<02:18,  1.66s/it]predicting train subjects:  71%|███████   | 203/285 [05:37<02:16,  1.66s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:38<02:08,  1.59s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:40<02:02,  1.53s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:41<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:43<02:04,  1.59s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:45<02:08,  1.67s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:47<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:48<02:02,  1.63s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:49<01:57,  1.58s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:51<01:56,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:53<01:58,  1.65s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:54<01:52,  1.59s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:56<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:57<01:47,  1.56s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:59<01:52,  1.66s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:01<01:53,  1.70s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:03<01:54,  1.73s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:04<01:44,  1.61s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:06<01:38,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:07<01:38,  1.56s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:09<01:32,  1.49s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:10<01:30,  1.48s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:11<01:26,  1.44s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:13<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:15<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:17<01:37,  1.72s/it]predicting train subjects:  80%|████████  | 229/285 [06:19<01:35,  1.71s/it]predicting train subjects:  81%|████████  | 230/285 [06:20<01:28,  1.62s/it]predicting train subjects:  81%|████████  | 231/285 [06:21<01:24,  1.56s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:23<01:24,  1.59s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:24<01:18,  1.52s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:26<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:28<01:17,  1.55s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:30<01:20,  1.64s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:31<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:33<01:22,  1.75s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:35<01:18,  1.71s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:36<01:11,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:38<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:39<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:40<01:00,  1.45s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:42<01:03,  1.55s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:43<00:58,  1.47s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:45<01:02,  1.61s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:47<01:03,  1.67s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:49<01:01,  1.66s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:50<00:57,  1.59s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:52<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:53<00:51,  1.51s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:54<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:56<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:58<00:50,  1.63s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:00<00:48,  1.63s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:01<00:43,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [07:02<00:41,  1.50s/it]predicting train subjects:  91%|█████████ | 258/285 [07:04<00:43,  1.59s/it]predicting train subjects:  91%|█████████ | 259/285 [07:06<00:41,  1.60s/it]predicting train subjects:  91%|█████████ | 260/285 [07:07<00:37,  1.52s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:09<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:10<00:33,  1.45s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:11<00:31,  1.44s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:13<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:15<00:32,  1.63s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:16<00:29,  1.55s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:18<00:27,  1.51s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:20<00:27,  1.60s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:21<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:23<00:23,  1.56s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:24<00:21,  1.52s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:26<00:20,  1.54s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:27<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:28<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:30<00:15,  1.55s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:32<00:14,  1.64s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:33<00:12,  1.56s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:35<00:10,  1.52s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:36<00:09,  1.56s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:38<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:39<00:05,  1.48s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:41<00:04,  1.44s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:42<00:03,  1.55s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:44<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 285/285 [07:46<00:00,  1.67s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:52,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<07:12,  1.53s/it]Loading train:   1%|          | 3/285 [00:04<07:26,  1.58s/it]Loading train:   1%|▏         | 4/285 [00:06<07:11,  1.54s/it]Loading train:   2%|▏         | 5/285 [00:07<07:18,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:09<06:59,  1.50s/it]Loading train:   2%|▏         | 7/285 [00:10<07:02,  1.52s/it]Loading train:   3%|▎         | 8/285 [00:11<06:52,  1.49s/it]Loading train:   3%|▎         | 9/285 [00:13<07:17,  1.58s/it]Loading train:   4%|▎         | 10/285 [00:15<06:51,  1.50s/it]Loading train:   4%|▍         | 11/285 [00:16<06:05,  1.34s/it]Loading train:   4%|▍         | 12/285 [00:17<05:58,  1.31s/it]Loading train:   5%|▍         | 13/285 [00:18<05:36,  1.24s/it]Loading train:   5%|▍         | 14/285 [00:19<05:25,  1.20s/it]Loading train:   5%|▌         | 15/285 [00:20<05:29,  1.22s/it]Loading train:   6%|▌         | 16/285 [00:21<05:14,  1.17s/it]Loading train:   6%|▌         | 17/285 [00:22<04:54,  1.10s/it]Loading train:   6%|▋         | 18/285 [00:23<04:45,  1.07s/it]Loading train:   7%|▋         | 19/285 [00:24<04:32,  1.02s/it]Loading train:   7%|▋         | 20/285 [00:25<04:26,  1.01s/it]Loading train:   7%|▋         | 21/285 [00:26<04:41,  1.07s/it]Loading train:   8%|▊         | 22/285 [00:27<04:22,  1.00it/s]Loading train:   8%|▊         | 23/285 [00:28<04:43,  1.08s/it]Loading train:   8%|▊         | 24/285 [00:30<04:43,  1.08s/it]Loading train:   9%|▉         | 25/285 [00:31<04:56,  1.14s/it]Loading train:   9%|▉         | 26/285 [00:32<05:12,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:33<05:15,  1.22s/it]Loading train:  10%|▉         | 28/285 [00:34<05:00,  1.17s/it]Loading train:  10%|█         | 29/285 [00:36<05:06,  1.20s/it]Loading train:  11%|█         | 30/285 [00:37<05:09,  1.21s/it]Loading train:  11%|█         | 31/285 [00:38<05:08,  1.22s/it]Loading train:  11%|█         | 32/285 [00:39<05:02,  1.20s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:55,  1.17s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:38,  1.11s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:37,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:22,  1.05s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:13,  1.02s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:22,  1.06s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:04,  1.01it/s]Loading train:  14%|█▍        | 40/285 [00:47<04:02,  1.01it/s]Loading train:  14%|█▍        | 41/285 [00:48<03:56,  1.03it/s]Loading train:  15%|█▍        | 42/285 [00:49<03:48,  1.06it/s]Loading train:  15%|█▌        | 43/285 [00:50<03:55,  1.03it/s]Loading train:  15%|█▌        | 44/285 [00:51<04:03,  1.01s/it]Loading train:  16%|█▌        | 45/285 [00:52<03:56,  1.01it/s]Loading train:  16%|█▌        | 46/285 [00:53<04:06,  1.03s/it]Loading train:  16%|█▋        | 47/285 [00:54<04:03,  1.02s/it]Loading train:  17%|█▋        | 48/285 [00:55<04:02,  1.02s/it]Loading train:  17%|█▋        | 49/285 [00:57<04:17,  1.09s/it]Loading train:  18%|█▊        | 50/285 [00:58<04:09,  1.06s/it]Loading train:  18%|█▊        | 51/285 [00:59<04:16,  1.10s/it]Loading train:  18%|█▊        | 52/285 [01:00<04:24,  1.14s/it]Loading train:  19%|█▊        | 53/285 [01:01<04:14,  1.10s/it]Loading train:  19%|█▉        | 54/285 [01:02<04:20,  1.13s/it]Loading train:  19%|█▉        | 55/285 [01:03<04:08,  1.08s/it]Loading train:  20%|█▉        | 56/285 [01:04<04:07,  1.08s/it]Loading train:  20%|██        | 57/285 [01:05<04:07,  1.09s/it]Loading train:  20%|██        | 58/285 [01:06<04:05,  1.08s/it]Loading train:  21%|██        | 59/285 [01:08<04:13,  1.12s/it]Loading train:  21%|██        | 60/285 [01:09<04:15,  1.14s/it]Loading train:  21%|██▏       | 61/285 [01:10<04:07,  1.11s/it]Loading train:  22%|██▏       | 62/285 [01:11<04:13,  1.14s/it]Loading train:  22%|██▏       | 63/285 [01:12<04:05,  1.11s/it]Loading train:  22%|██▏       | 64/285 [01:14<04:28,  1.21s/it]Loading train:  23%|██▎       | 65/285 [01:15<04:59,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:17<05:21,  1.47s/it]Loading train:  24%|██▎       | 67/285 [01:18<05:01,  1.38s/it]Loading train:  24%|██▍       | 68/285 [01:19<04:50,  1.34s/it]Loading train:  24%|██▍       | 69/285 [01:20<04:29,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:22<04:21,  1.21s/it]Loading train:  25%|██▍       | 71/285 [01:23<04:07,  1.16s/it]Loading train:  25%|██▌       | 72/285 [01:24<04:01,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:25<03:57,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:26<03:54,  1.11s/it]Loading train:  26%|██▋       | 75/285 [01:27<03:59,  1.14s/it]Loading train:  27%|██▋       | 76/285 [01:28<03:54,  1.12s/it]Loading train:  27%|██▋       | 77/285 [01:29<03:43,  1.08s/it]Loading train:  27%|██▋       | 78/285 [01:30<03:43,  1.08s/it]Loading train:  28%|██▊       | 79/285 [01:32<03:55,  1.15s/it]Loading train:  28%|██▊       | 80/285 [01:33<03:45,  1.10s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:43,  1.09s/it]Loading train:  29%|██▉       | 82/285 [01:35<03:42,  1.10s/it]Loading train:  29%|██▉       | 83/285 [01:36<03:45,  1.11s/it]Loading train:  29%|██▉       | 84/285 [01:37<03:29,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:38<03:36,  1.08s/it]Loading train:  30%|███       | 86/285 [01:39<03:40,  1.11s/it]Loading train:  31%|███       | 87/285 [01:40<03:39,  1.11s/it]Loading train:  31%|███       | 88/285 [01:41<03:32,  1.08s/it]Loading train:  31%|███       | 89/285 [01:42<03:32,  1.09s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:37,  1.12s/it]Loading train:  32%|███▏      | 91/285 [01:45<03:31,  1.09s/it]Loading train:  32%|███▏      | 92/285 [01:46<03:34,  1.11s/it]Loading train:  33%|███▎      | 93/285 [01:47<03:40,  1.15s/it]Loading train:  33%|███▎      | 94/285 [01:48<03:42,  1.16s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:32,  1.12s/it]Loading train:  34%|███▎      | 96/285 [01:50<03:35,  1.14s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:41,  1.18s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:38,  1.17s/it]Loading train:  35%|███▍      | 99/285 [01:54<03:32,  1.14s/it]Loading train:  35%|███▌      | 100/285 [01:55<03:34,  1.16s/it]Loading train:  35%|███▌      | 101/285 [01:56<03:37,  1.18s/it]Loading train:  36%|███▌      | 102/285 [01:57<03:31,  1.16s/it]Loading train:  36%|███▌      | 103/285 [01:58<03:26,  1.13s/it]Loading train:  36%|███▋      | 104/285 [02:00<03:30,  1.16s/it]Loading train:  37%|███▋      | 105/285 [02:01<03:26,  1.15s/it]Loading train:  37%|███▋      | 106/285 [02:02<03:28,  1.16s/it]Loading train:  38%|███▊      | 107/285 [02:03<03:27,  1.16s/it]Loading train:  38%|███▊      | 108/285 [02:04<03:17,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:05<03:10,  1.08s/it]Loading train:  39%|███▊      | 110/285 [02:06<03:12,  1.10s/it]Loading train:  39%|███▉      | 111/285 [02:07<03:05,  1.06s/it]Loading train:  39%|███▉      | 112/285 [02:08<03:01,  1.05s/it]Loading train:  40%|███▉      | 113/285 [02:09<02:56,  1.03s/it]Loading train:  40%|████      | 114/285 [02:10<02:59,  1.05s/it]Loading train:  40%|████      | 115/285 [02:11<02:54,  1.03s/it]Loading train:  41%|████      | 116/285 [02:13<03:03,  1.09s/it]Loading train:  41%|████      | 117/285 [02:14<02:57,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:15<02:59,  1.08s/it]Loading train:  42%|████▏     | 119/285 [02:16<03:01,  1.10s/it]Loading train:  42%|████▏     | 120/285 [02:17<03:02,  1.11s/it]Loading train:  42%|████▏     | 121/285 [02:19<03:23,  1.24s/it]Loading train:  43%|████▎     | 122/285 [02:20<03:31,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:21<03:29,  1.29s/it]Loading train:  44%|████▎     | 124/285 [02:22<03:20,  1.25s/it]Loading train:  44%|████▍     | 125/285 [02:23<03:07,  1.17s/it]Loading train:  44%|████▍     | 126/285 [02:24<02:59,  1.13s/it]Loading train:  45%|████▍     | 127/285 [02:25<02:49,  1.07s/it]Loading train:  45%|████▍     | 128/285 [02:26<02:45,  1.05s/it]Loading train:  45%|████▌     | 129/285 [02:27<02:39,  1.02s/it]Loading train:  46%|████▌     | 130/285 [02:28<02:34,  1.00it/s]Loading train:  46%|████▌     | 131/285 [02:29<02:33,  1.01it/s]Loading train:  46%|████▋     | 132/285 [02:30<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:31<02:26,  1.04it/s]Loading train:  47%|████▋     | 134/285 [02:32<02:26,  1.03it/s]Loading train:  47%|████▋     | 135/285 [02:33<02:21,  1.06it/s]Loading train:  48%|████▊     | 136/285 [02:34<02:20,  1.06it/s]Loading train:  48%|████▊     | 137/285 [02:35<02:22,  1.04it/s]Loading train:  48%|████▊     | 138/285 [02:36<02:22,  1.03it/s]Loading train:  49%|████▉     | 139/285 [02:37<02:21,  1.03it/s]Loading train:  49%|████▉     | 140/285 [02:38<02:18,  1.05it/s]Loading train:  49%|████▉     | 141/285 [02:39<02:14,  1.07it/s]Loading train:  50%|████▉     | 142/285 [02:40<02:18,  1.03it/s]Loading train:  50%|█████     | 143/285 [02:41<02:17,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:42<02:16,  1.03it/s]Loading train:  51%|█████     | 145/285 [02:43<02:16,  1.02it/s]Loading train:  51%|█████     | 146/285 [02:44<02:14,  1.03it/s]Loading train:  52%|█████▏    | 147/285 [02:44<02:11,  1.05it/s]Loading train:  52%|█████▏    | 148/285 [02:45<02:11,  1.04it/s]Loading train:  52%|█████▏    | 149/285 [02:46<02:08,  1.06it/s]Loading train:  53%|█████▎    | 150/285 [02:47<02:09,  1.04it/s]Loading train:  53%|█████▎    | 151/285 [02:48<02:05,  1.07it/s]Loading train:  53%|█████▎    | 152/285 [02:49<02:06,  1.05it/s]Loading train:  54%|█████▎    | 153/285 [02:50<02:00,  1.10it/s]Loading train:  54%|█████▍    | 154/285 [02:51<01:57,  1.11it/s]Loading train:  54%|█████▍    | 155/285 [02:52<01:55,  1.12it/s]Loading train:  55%|█████▍    | 156/285 [02:53<02:11,  1.02s/it]Loading train:  55%|█████▌    | 157/285 [02:54<02:22,  1.11s/it]Loading train:  55%|█████▌    | 158/285 [02:56<02:37,  1.24s/it]Loading train:  56%|█████▌    | 159/285 [02:57<02:43,  1.30s/it]Loading train:  56%|█████▌    | 160/285 [02:59<02:48,  1.34s/it]Loading train:  56%|█████▋    | 161/285 [03:01<03:04,  1.49s/it]Loading train:  57%|█████▋    | 162/285 [03:02<03:04,  1.50s/it]Loading train:  57%|█████▋    | 163/285 [03:04<02:57,  1.45s/it]Loading train:  58%|█████▊    | 164/285 [03:05<02:40,  1.33s/it]Loading train:  58%|█████▊    | 165/285 [03:06<02:41,  1.35s/it]Loading train:  58%|█████▊    | 166/285 [03:07<02:39,  1.34s/it]Loading train:  59%|█████▊    | 167/285 [03:09<02:39,  1.35s/it]Loading train:  59%|█████▉    | 168/285 [03:10<02:38,  1.35s/it]Loading train:  59%|█████▉    | 169/285 [03:11<02:32,  1.32s/it]Loading train:  60%|█████▉    | 170/285 [03:13<02:28,  1.29s/it]Loading train:  60%|██████    | 171/285 [03:14<02:32,  1.33s/it]Loading train:  60%|██████    | 172/285 [03:15<02:21,  1.25s/it]Loading train:  61%|██████    | 173/285 [03:16<02:17,  1.23s/it]Loading train:  61%|██████    | 174/285 [03:18<02:26,  1.32s/it]Loading train:  61%|██████▏   | 175/285 [03:19<02:27,  1.34s/it]Loading train:  62%|██████▏   | 176/285 [03:21<02:28,  1.36s/it]Loading train:  62%|██████▏   | 177/285 [03:22<02:35,  1.44s/it]Loading train:  62%|██████▏   | 178/285 [03:24<02:37,  1.47s/it]Loading train:  63%|██████▎   | 179/285 [03:25<02:26,  1.38s/it]Loading train:  63%|██████▎   | 180/285 [03:27<02:34,  1.47s/it]Loading train:  64%|██████▎   | 181/285 [03:28<02:43,  1.57s/it]Loading train:  64%|██████▍   | 182/285 [03:30<02:54,  1.69s/it]Loading train:  64%|██████▍   | 183/285 [03:32<02:57,  1.74s/it]Loading train:  65%|██████▍   | 184/285 [03:34<03:02,  1.81s/it]Loading train:  65%|██████▍   | 185/285 [03:36<03:03,  1.83s/it]Loading train:  65%|██████▌   | 186/285 [03:38<02:57,  1.80s/it]Loading train:  66%|██████▌   | 187/285 [03:39<02:47,  1.71s/it]Loading train:  66%|██████▌   | 188/285 [03:41<02:53,  1.79s/it]Loading train:  66%|██████▋   | 189/285 [03:43<02:47,  1.75s/it]Loading train:  67%|██████▋   | 190/285 [03:45<02:54,  1.84s/it]Loading train:  67%|██████▋   | 191/285 [03:47<02:50,  1.81s/it]Loading train:  67%|██████▋   | 192/285 [03:48<02:45,  1.78s/it]Loading train:  68%|██████▊   | 193/285 [03:50<02:36,  1.70s/it]Loading train:  68%|██████▊   | 194/285 [03:51<02:24,  1.59s/it]Loading train:  68%|██████▊   | 195/285 [03:53<02:19,  1.55s/it]Loading train:  69%|██████▉   | 196/285 [03:54<02:19,  1.57s/it]Loading train:  69%|██████▉   | 197/285 [03:56<02:19,  1.59s/it]Loading train:  69%|██████▉   | 198/285 [03:58<02:20,  1.62s/it]Loading train:  70%|██████▉   | 199/285 [03:59<02:10,  1.51s/it]Loading train:  70%|███████   | 200/285 [04:00<01:59,  1.41s/it]Loading train:  71%|███████   | 201/285 [04:01<01:59,  1.42s/it]Loading train:  71%|███████   | 202/285 [04:03<01:58,  1.42s/it]Loading train:  71%|███████   | 203/285 [04:04<01:51,  1.36s/it]Loading train:  72%|███████▏  | 204/285 [04:05<01:46,  1.32s/it]Loading train:  72%|███████▏  | 205/285 [04:07<01:43,  1.30s/it]Loading train:  72%|███████▏  | 206/285 [04:08<01:50,  1.40s/it]Loading train:  73%|███████▎  | 207/285 [04:10<02:02,  1.57s/it]Loading train:  73%|███████▎  | 208/285 [04:12<02:07,  1.66s/it]Loading train:  73%|███████▎  | 209/285 [04:14<02:14,  1.77s/it]Loading train:  74%|███████▎  | 210/285 [04:16<02:14,  1.79s/it]Loading train:  74%|███████▍  | 211/285 [04:18<02:08,  1.74s/it]Loading train:  74%|███████▍  | 212/285 [04:19<01:56,  1.60s/it]Loading train:  75%|███████▍  | 213/285 [04:20<01:45,  1.47s/it]Loading train:  75%|███████▌  | 214/285 [04:21<01:36,  1.36s/it]Loading train:  75%|███████▌  | 215/285 [04:23<01:38,  1.41s/it]Loading train:  76%|███████▌  | 216/285 [04:24<01:37,  1.41s/it]Loading train:  76%|███████▌  | 217/285 [04:26<01:48,  1.59s/it]Loading train:  76%|███████▋  | 218/285 [04:28<01:51,  1.67s/it]Loading train:  77%|███████▋  | 219/285 [04:30<01:54,  1.74s/it]Loading train:  77%|███████▋  | 220/285 [04:31<01:51,  1.72s/it]Loading train:  78%|███████▊  | 221/285 [04:33<01:54,  1.79s/it]Loading train:  78%|███████▊  | 222/285 [04:35<01:43,  1.64s/it]Loading train:  78%|███████▊  | 223/285 [04:36<01:37,  1.57s/it]Loading train:  79%|███████▊  | 224/285 [04:37<01:28,  1.45s/it]Loading train:  79%|███████▉  | 225/285 [04:39<01:23,  1.39s/it]Loading train:  79%|███████▉  | 226/285 [04:40<01:22,  1.39s/it]Loading train:  80%|███████▉  | 227/285 [04:42<01:27,  1.50s/it]Loading train:  80%|████████  | 228/285 [04:44<01:34,  1.65s/it]Loading train:  80%|████████  | 229/285 [04:46<01:35,  1.70s/it]Loading train:  81%|████████  | 230/285 [04:47<01:35,  1.74s/it]Loading train:  81%|████████  | 231/285 [04:49<01:27,  1.61s/it]Loading train:  81%|████████▏ | 232/285 [04:50<01:25,  1.60s/it]Loading train:  82%|████████▏ | 233/285 [04:51<01:17,  1.50s/it]Loading train:  82%|████████▏ | 234/285 [04:53<01:13,  1.45s/it]Loading train:  82%|████████▏ | 235/285 [04:54<01:10,  1.41s/it]Loading train:  83%|████████▎ | 236/285 [04:56<01:12,  1.47s/it]Loading train:  83%|████████▎ | 237/285 [04:58<01:17,  1.62s/it]Loading train:  84%|████████▎ | 238/285 [04:59<01:17,  1.66s/it]Loading train:  84%|████████▍ | 239/285 [05:01<01:17,  1.70s/it]Loading train:  84%|████████▍ | 240/285 [05:03<01:15,  1.68s/it]Loading train:  85%|████████▍ | 241/285 [05:04<01:09,  1.58s/it]Loading train:  85%|████████▍ | 242/285 [05:05<01:03,  1.48s/it]Loading train:  85%|████████▌ | 243/285 [05:07<00:59,  1.41s/it]Loading train:  86%|████████▌ | 244/285 [05:08<00:57,  1.40s/it]Loading train:  86%|████████▌ | 245/285 [05:09<00:51,  1.29s/it]Loading train:  86%|████████▋ | 246/285 [05:11<00:53,  1.37s/it]Loading train:  87%|████████▋ | 247/285 [05:12<00:54,  1.44s/it]Loading train:  87%|████████▋ | 248/285 [05:14<00:53,  1.43s/it]Loading train:  87%|████████▋ | 249/285 [05:15<00:46,  1.29s/it]Loading train:  88%|████████▊ | 250/285 [05:16<00:44,  1.26s/it]Loading train:  88%|████████▊ | 251/285 [05:17<00:42,  1.24s/it]Loading train:  88%|████████▊ | 252/285 [05:18<00:40,  1.22s/it]Loading train:  89%|████████▉ | 253/285 [05:20<00:42,  1.32s/it]Loading train:  89%|████████▉ | 254/285 [05:21<00:43,  1.40s/it]Loading train:  89%|████████▉ | 255/285 [05:23<00:44,  1.50s/it]Loading train:  90%|████████▉ | 256/285 [05:25<00:45,  1.56s/it]Loading train:  90%|█████████ | 257/285 [05:26<00:42,  1.54s/it]Loading train:  91%|█████████ | 258/285 [05:28<00:43,  1.61s/it]Loading train:  91%|█████████ | 259/285 [05:29<00:39,  1.53s/it]Loading train:  91%|█████████ | 260/285 [05:31<00:36,  1.47s/it]Loading train:  92%|█████████▏| 261/285 [05:32<00:32,  1.37s/it]Loading train:  92%|█████████▏| 262/285 [05:33<00:30,  1.33s/it]Loading train:  92%|█████████▏| 263/285 [05:34<00:27,  1.23s/it]Loading train:  93%|█████████▎| 264/285 [05:36<00:29,  1.42s/it]Loading train:  93%|█████████▎| 265/285 [05:38<00:32,  1.63s/it]Loading train:  93%|█████████▎| 266/285 [05:39<00:29,  1.55s/it]Loading train:  94%|█████████▎| 267/285 [05:41<00:26,  1.47s/it]Loading train:  94%|█████████▍| 268/285 [05:42<00:25,  1.49s/it]Loading train:  94%|█████████▍| 269/285 [05:43<00:21,  1.37s/it]Loading train:  95%|█████████▍| 270/285 [05:45<00:21,  1.40s/it]Loading train:  95%|█████████▌| 271/285 [05:46<00:20,  1.43s/it]Loading train:  95%|█████████▌| 272/285 [05:48<00:18,  1.44s/it]Loading train:  96%|█████████▌| 273/285 [05:49<00:16,  1.38s/it]Loading train:  96%|█████████▌| 274/285 [05:50<00:15,  1.39s/it]Loading train:  96%|█████████▋| 275/285 [05:52<00:15,  1.52s/it]Loading train:  97%|█████████▋| 276/285 [05:54<00:13,  1.50s/it]Loading train:  97%|█████████▋| 277/285 [05:55<00:11,  1.46s/it]Loading train:  98%|█████████▊| 278/285 [05:56<00:09,  1.35s/it]Loading train:  98%|█████████▊| 279/285 [05:58<00:08,  1.44s/it]Loading train:  98%|█████████▊| 280/285 [06:00<00:08,  1.60s/it]Loading train:  99%|█████████▊| 281/285 [06:02<00:06,  1.64s/it]Loading train:  99%|█████████▉| 282/285 [06:03<00:04,  1.65s/it]Loading train:  99%|█████████▉| 283/285 [06:05<00:03,  1.70s/it]Loading train: 100%|█████████▉| 284/285 [06:07<00:01,  1.77s/it]Loading train: 100%|██████████| 285/285 [06:09<00:00,  1.72s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   1%|          | 2/285 [00:00<00:15, 18.78it/s]concatenating: train:   1%|          | 3/285 [00:00<00:19, 14.13it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:20, 13.71it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:19, 14.48it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:14, 19.04it/s]concatenating: train:  10%|█         | 29/285 [00:00<00:10, 25.53it/s]concatenating: train:  13%|█▎        | 37/285 [00:00<00:07, 31.91it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:06, 36.92it/s]concatenating: train:  18%|█▊        | 51/285 [00:01<00:06, 37.25it/s]concatenating: train:  20%|██        | 57/285 [00:01<00:05, 38.52it/s]concatenating: train:  22%|██▏       | 64/285 [00:01<00:05, 43.86it/s]concatenating: train:  25%|██▍       | 71/285 [00:01<00:04, 46.63it/s]concatenating: train:  27%|██▋       | 77/285 [00:01<00:05, 39.32it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:06, 30.62it/s]concatenating: train:  30%|███       | 86/285 [00:02<00:07, 25.40it/s]concatenating: train:  32%|███▏      | 91/285 [00:02<00:06, 29.59it/s]concatenating: train:  37%|███▋      | 105/285 [00:02<00:04, 38.73it/s]concatenating: train:  47%|████▋     | 134/285 [00:02<00:02, 52.30it/s]concatenating: train:  58%|█████▊    | 164/285 [00:02<00:01, 69.52it/s]concatenating: train:  67%|██████▋   | 190/285 [00:02<00:01, 88.89it/s]concatenating: train:  74%|███████▍  | 211/285 [00:03<00:01, 62.12it/s]concatenating: train:  80%|███████▉  | 227/285 [00:03<00:01, 42.98it/s]concatenating: train:  84%|████████▍ | 239/285 [00:04<00:01, 42.39it/s]concatenating: train:  87%|████████▋ | 249/285 [00:04<00:00, 40.75it/s]concatenating: train:  97%|█████████▋| 277/285 [00:04<00:00, 54.79it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 62.04it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.13s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:02,  2.03s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.95s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation:  67%|██████▋   | 2/3 [00:00<00:00, 14.50it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 16.46it/s]2019-07-11 05:32:05.199985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 05:32:05.200120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 05:32:05.200136: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 05:32:05.200145: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 05:32:05.200562: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.66it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.48it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.16it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.57it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.57it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.21it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.49it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.44it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.01it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.35it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.47it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.94it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.34it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  4.86it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.11it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.48it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.59it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.30it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.50it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.65it/s]
Epoch 00052: val_mDice did not improve from 0.58809
Restoring model weights from the end of the best epoch
Epoch 00052: early stopping
{'val_loss': [1.6648759387788319, 1.161389396304176, 1.0887367384774345, 1.0319500877743675, 0.9884040809813, 1.0100401015508742, 0.9732785849344163, 1.0957392624446325, 0.9615171125956944, 0.9791301545642671, 0.9859876859755743, 0.9310267709550404, 0.9954578876495361, 0.9556882722037179, 0.9724355538686117, 0.9539795603070941, 0.9574768316178095, 0.9139137608664376, 0.9262337230500721, 0.9228881143388294, 0.9006820349466234, 0.891736314410255, 0.9526218005589077, 0.9102228312265306, 0.925205253419422, 0.9280058315822056, 0.9046652317047119, 0.8852537473042806, 0.8826927344004313, 0.9193625563666934, 0.9177090894608271, 0.8769364186695644, 0.8688333375113351, 0.9315255937122163, 0.9328205699012393, 0.8353445416405088, 0.850839478628976, 0.868441763378325, 0.8448456525802612, 0.8071973777952648, 0.8572634061177572, 0.8240074714024862, 0.802122814314706, 0.8221754346575055, 0.8086088044302804, 0.874849625996181, 0.8269467637652442, 0.8012010710580009, 0.7557904379708427, 0.7835894368943714, 0.7904241652715773, 0.7637523923601423], 'val_acc': [0.9194345417476836, 0.938459228901636, 0.9425640929312933, 0.940032076267969, 0.9430837744758243, 0.9445031881332397, 0.9346817930539449, 0.9379121036756606, 0.9390453554335094, 0.9461584034420195, 0.9454235434532166, 0.9464216856729417, 0.9430494762602306, 0.9423168585413978, 0.945787543342227, 0.9456204005650112, 0.9431982863517034, 0.9453663258325486, 0.9461629816464016, 0.9431112891151792, 0.946238534791129, 0.9466941470191592, 0.9444551524661836, 0.9443933112280709, 0.9453159088180179, 0.9445672943478539, 0.9461240967114767, 0.9412339868999663, 0.945892836366381, 0.9470627222742353, 0.9353388547897339, 0.9446886692728315, 0.9478891832487923, 0.9437523143632072, 0.9432165764627003, 0.9451144678252084, 0.9450320431164333, 0.9471840716543651, 0.9454807468823024, 0.9452541129929679, 0.9438255769865853, 0.9464949908710661, 0.9471566137813386, 0.9451099180039906, 0.9462522750809079, 0.9445490184284392, 0.9427014589309692, 0.9468841751416525, 0.9462660011791048, 0.945496800399962, 0.939578754561288, 0.9447962584949675], 'val_mDice': [0.36488412019042743, 0.5244084039614314, 0.5521437117741221, 0.566238418753658, 0.5826483645609447, 0.5595546322209495, 0.5706454604154542, 0.4996658421698071, 0.577443048003174, 0.5666621930542446, 0.5631062406159583, 0.588090316880317, 0.5436190201767853, 0.571331337094307, 0.5586151814176923, 0.5531128834755648, 0.562665124556848, 0.5763289995846295, 0.5759790028844561, 0.5793695703503632, 0.5751264673613367, 0.5852070115506649, 0.552289377011004, 0.5745589197391555, 0.5644495426898911, 0.5659518743909541, 0.5714350745436692, 0.5764526495976108, 0.5800032360213143, 0.5572765207006818, 0.5512282773852348, 0.579047027088347, 0.5767415178318819, 0.5226100016207922, 0.5381605098290103, 0.5737346529605842, 0.5724055561281386, 0.5638012790254184, 0.5733623171136493, 0.5735096205912885, 0.5694885266323885, 0.5711326859891415, 0.5766216253950482, 0.5806521152456602, 0.5737370845107805, 0.5407135451123828, 0.5685144875730787, 0.5624441500930559, 0.5802998819521495, 0.5714979984221005, 0.5679355033096813, 0.5649618187120983], 'loss': [2.623435117409182, 0.705738983242549, 0.5023396038264467, 0.45657607680321294, 0.4351735886108078, 0.4177396856384836, 0.4053329699573109, 0.39776619633360594, 0.38796127568165506, 0.3807518997701671, 0.3769886080518218, 0.3722997515192835, 0.3657867252045292, 0.361224023994049, 0.36035125832326015, 0.35376891077242767, 0.3498237197261705, 0.34677802548257747, 0.3458120920983541, 0.34028805496721615, 0.3388684829501304, 0.33836790700971864, 0.3340895158869466, 0.3335842232392063, 0.33168754575683224, 0.3285820639924045, 0.32576143214738, 0.3244590714978924, 0.3222348261929809, 0.3205042367200298, 0.3196892470196076, 0.31930881118140103, 0.3170210022457032, 0.31650692308962586, 0.31451558915089156, 0.3134153001922529, 0.31053164025618896, 0.31104967603109834, 0.30801834047403737, 0.3087835647029318, 0.3067920705774328, 0.3064509497480354, 0.30440251472048246, 0.304164038903915, 0.3016681842820502, 0.30142590575924216, 0.3013486578810622, 0.2991665432637933, 0.29921315339504695, 0.2975890950899674, 0.2990068710617921, 0.2974177440949803], 'acc': [0.6284000749518606, 0.9042025588141118, 0.9199876069723812, 0.9262662466973819, 0.9293581349601032, 0.9314216100482415, 0.9329268271945588, 0.9337620846058147, 0.935019846984778, 0.9357874170189904, 0.9361477388521139, 0.9365872142630688, 0.9372793110390952, 0.9377356552654823, 0.9379156111912482, 0.9383426419406675, 0.9389592038084368, 0.939162949180934, 0.9393576381062643, 0.9399259519043837, 0.9401069243496177, 0.9401030782240306, 0.9404226644594866, 0.9405182667474469, 0.9407860215445211, 0.9410502018785118, 0.94138378678247, 0.9414152757427884, 0.9416188422668778, 0.941795664955615, 0.9420201269928054, 0.9419149279778279, 0.9422307181087146, 0.9421579125232267, 0.9422937200114013, 0.942396557328787, 0.9427118121784778, 0.9426868979310815, 0.9430263673774258, 0.9429890604659912, 0.9431526529000678, 0.9431081595668127, 0.9432751383536901, 0.9433315853312315, 0.9435538485120527, 0.9436915612344868, 0.9435777394831789, 0.9438158537419012, 0.9438901919263255, 0.9439770863859185, 0.9438466017407582, 0.9439540529540675], 'mDice': [0.13893685616942092, 0.4875315220594544, 0.5895511748497946, 0.618241702129047, 0.6319777620581043, 0.6434329550046095, 0.6517379778944185, 0.656804787117506, 0.6635003357878627, 0.6685784920024486, 0.6709996153215739, 0.6742928146005986, 0.6787616965488958, 0.6821078512970598, 0.682972191235958, 0.6873150280451806, 0.6901811819120665, 0.6922838857276421, 0.6929967140034488, 0.6969608485825103, 0.6979947900850234, 0.6983325024066643, 0.7013585015668882, 0.7018130003475191, 0.7032772221499977, 0.7053942074430042, 0.7074775003573328, 0.7084575877245713, 0.7099572460339297, 0.7113574603423461, 0.7119705814236916, 0.7122645305029018, 0.7139621186697669, 0.7143816638709908, 0.7158095679785076, 0.716596687302002, 0.7187176989364513, 0.7184260743924228, 0.7207020715364537, 0.7200696276450906, 0.7215950997987648, 0.7219199947775824, 0.7233516198145027, 0.7235354307025573, 0.7254005578618209, 0.7256748433836582, 0.7256486302904939, 0.7273603203624389, 0.727220852227484, 0.7285464944144492, 0.7273942356006659, 0.7286160268695318]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 30)   16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 90)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 254,643
Trainable params: 79,783
Non-trainable params: 174,860
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 24s - loss: 1.9605 - acc: 0.6992 - mDice: 0.2304 - val_loss: 0.9146 - val_acc: 0.9262 - val_mDice: 0.3895

Epoch 00001: val_mDice improved from -inf to 0.38946, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 17s - loss: 0.6326 - acc: 0.9162 - mDice: 0.5184 - val_loss: 0.5927 - val_acc: 0.9386 - val_mDice: 0.5404

Epoch 00002: val_mDice improved from 0.38946 to 0.54036, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.4855 - acc: 0.9324 - mDice: 0.6016 - val_loss: 0.4890 - val_acc: 0.9504 - val_mDice: 0.6036

Epoch 00003: val_mDice improved from 0.54036 to 0.60359, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 16s - loss: 0.4327 - acc: 0.9405 - mDice: 0.6350 - val_loss: 0.5106 - val_acc: 0.9454 - val_mDice: 0.5900

Epoch 00004: val_mDice did not improve from 0.60359
Epoch 5/300
 - 17s - loss: 0.4040 - acc: 0.9438 - mDice: 0.6538 - val_loss: 0.5056 - val_acc: 0.9531 - val_mDice: 0.5987

Epoch 00005: val_mDice did not improve from 0.60359
Epoch 6/300
 - 15s - loss: 0.3838 - acc: 0.9457 - mDice: 0.6674 - val_loss: 0.4827 - val_acc: 0.9534 - val_mDice: 0.6083

Epoch 00006: val_mDice improved from 0.60359 to 0.60833, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 16s - loss: 0.3689 - acc: 0.9470 - mDice: 0.6777 - val_loss: 0.4693 - val_acc: 0.9536 - val_mDice: 0.6173

Epoch 00007: val_mDice improved from 0.60833 to 0.61726, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 15s - loss: 0.3549 - acc: 0.9482 - mDice: 0.6872 - val_loss: 0.4850 - val_acc: 0.9529 - val_mDice: 0.6099

Epoch 00008: val_mDice did not improve from 0.61726
Epoch 9/300
 - 15s - loss: 0.3452 - acc: 0.9489 - mDice: 0.6942 - val_loss: 0.4786 - val_acc: 0.9533 - val_mDice: 0.6138

Epoch 00009: val_mDice did not improve from 0.61726
Epoch 10/300
 - 15s - loss: 0.3365 - acc: 0.9496 - mDice: 0.7004 - val_loss: 0.4793 - val_acc: 0.9557 - val_mDice: 0.6154

Epoch 00010: val_mDice did not improve from 0.61726
Epoch 11/300
 - 15s - loss: 0.3292 - acc: 0.9501 - mDice: 0.7058 - val_loss: 0.4757 - val_acc: 0.9531 - val_mDice: 0.6162

Epoch 00011: val_mDice did not improve from 0.61726
Epoch 12/300
 - 15s - loss: 0.3218 - acc: 0.9506 - mDice: 0.7111 - val_loss: 0.4678 - val_acc: 0.9540 - val_mDice: 0.6191

Epoch 00012: val_mDice improved from 0.61726 to 0.61910, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 15s - loss: 0.3162 - acc: 0.9511 - mDice: 0.7153 - val_loss: 0.4971 - val_acc: 0.9514 - val_mDice: 0.6003

Epoch 00013: val_mDice did not improve from 0.61910
Epoch 14/300
 - 15s - loss: 0.3107 - acc: 0.9516 - mDice: 0.7194 - val_loss: 0.4636 - val_acc: 0.9537 - val_mDice: 0.6195

Epoch 00014: val_mDice improved from 0.61910 to 0.61954, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 15s - loss: 0.3057 - acc: 0.9519 - mDice: 0.7230 - val_loss: 0.4571 - val_acc: 0.9541 - val_mDice: 0.6246

Epoch 00015: val_mDice improved from 0.61954 to 0.62456, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 15s - loss: 0.3010 - acc: 0.9523 - mDice: 0.7266 - val_loss: 0.4893 - val_acc: 0.9512 - val_mDice: 0.6085

Epoch 00016: val_mDice did not improve from 0.62456
Epoch 17/300
 - 15s - loss: 0.2977 - acc: 0.9526 - mDice: 0.7291 - val_loss: 0.4713 - val_acc: 0.9555 - val_mDice: 0.6174

Epoch 00017: val_mDice did not improve from 0.62456
Epoch 18/300
 - 15s - loss: 0.2918 - acc: 0.9530 - mDice: 0.7335 - val_loss: 0.4627 - val_acc: 0.9557 - val_mDice: 0.6226

Epoch 00018: val_mDice did not improve from 0.62456
Epoch 19/300
 - 15s - loss: 0.2903 - acc: 0.9532 - mDice: 0.7346 - val_loss: 0.4808 - val_acc: 0.9556 - val_mDice: 0.6156

Epoch 00019: val_mDice did not improve from 0.62456
Epoch 20/300
 - 15s - loss: 0.2878 - acc: 0.9533 - mDice: 0.7367 - val_loss: 0.4759 - val_acc: 0.9538 - val_mDice: 0.6148

Epoch 00020: val_mDice did not improve from 0.62456
Epoch 21/300
 - 15s - loss: 0.2846 - acc: 0.9535 - mDice: 0.7391 - val_loss: 0.4626 - val_acc: 0.9561 - val_mDice: 0.6216

Epoch 00021: val_mDice did not improve from 0.62456
Epoch 22/300
 - 15s - loss: 0.2826 - acc: 0.9536 - mDice: 0.7406 - val_loss: 0.4566 - val_acc: 0.9520 - val_mDice: 0.6240

Epoch 00022: val_mDice did not improve from 0.62456
Epoch 23/300
 - 15s - loss: 0.2784 - acc: 0.9540 - mDice: 0.7438 - val_loss: 0.4753 - val_acc: 0.9539 - val_mDice: 0.6164

Epoch 00023: val_mDice did not improve from 0.62456
Epoch 24/300
 - 15s - loss: 0.2747 - acc: 0.9542 - mDice: 0.7466 - val_loss: 0.4704 - val_acc: 0.9557 - val_mDice: 0.6253

Epoch 00024: val_mDice improved from 0.62456 to 0.62529, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 25/300
 - 15s - loss: 0.2730 - acc: 0.9544 - mDice: 0.7480 - val_loss: 0.4619 - val_acc: 0.9540 - val_mDice: 0.6210

Epoch 00025: val_mDice did not improve from 0.62529
Epoch 26/300
 - 15s - loss: 0.2737 - acc: 0.9544 - mDice: 0.7476 - val_loss: 0.4547 - val_acc: 0.9534 - val_mDice: 0.6252

Epoch 00026: val_mDice did not improve from 0.62529
Epoch 27/300
 - 15s - loss: 0.2690 - acc: 0.9547 - mDice: 0.7511 - val_loss: 0.4580 - val_acc: 0.9529 - val_mDice: 0.6246

Epoch 00027: val_mDice did not improve from 0.62529
Epoch 28/300
 - 15s - loss: 0.2668 - acc: 0.9548 - mDice: 0.7528 - val_loss: 0.4499 - val_acc: 0.9561 - val_mDice: 0.6306

Epoch 00028: val_mDice improved from 0.62529 to 0.63061, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 15s - loss: 0.2648 - acc: 0.9551 - mDice: 0.7545 - val_loss: 0.4653 - val_acc: 0.9539 - val_mDice: 0.6213

Epoch 00029: val_mDice did not improve from 0.63061
Epoch 30/300
 - 15s - loss: 0.2638 - acc: 0.9551 - mDice: 0.7552 - val_loss: 0.4784 - val_acc: 0.9557 - val_mDice: 0.6195

Epoch 00030: val_mDice did not improve from 0.63061
Epoch 31/300
 - 15s - loss: 0.3114 - acc: 0.9519 - mDice: 0.7244 - val_loss: 0.4772 - val_acc: 0.9554 - val_mDice: 0.6136

Epoch 00031: val_mDice did not improve from 0.63061
Epoch 32/300
 - 15s - loss: 0.2707 - acc: 0.9546 - mDice: 0.7497 - val_loss: 0.4445 - val_acc: 0.9530 - val_mDice: 0.6321

Epoch 00032: val_mDice improved from 0.63061 to 0.63208, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 33/300
 - 15s - loss: 0.2648 - acc: 0.9550 - mDice: 0.7543 - val_loss: 0.4582 - val_acc: 0.9547 - val_mDice: 0.6259

Epoch 00033: val_mDice did not improve from 0.63208
Epoch 34/300
 - 15s - loss: 0.2611 - acc: 0.9553 - mDice: 0.7573 - val_loss: 0.4930 - val_acc: 0.9548 - val_mDice: 0.6115

Epoch 00034: val_mDice did not improve from 0.63208
Epoch 35/300
 - 15s - loss: 0.2585 - acc: 0.9555 - mDice: 0.7593 - val_loss: 0.4596 - val_acc: 0.9550 - val_mDice: 0.6300

Epoch 00035: val_mDice did not improve from 0.63208
Epoch 36/300
 - 15s - loss: 0.2561 - acc: 0.9556 - mDice: 0.7613 - val_loss: 0.4573 - val_acc: 0.9553 - val_mDice: 0.6251

Epoch 00036: val_mDice did not improve from 0.63208
Epoch 37/300
 - 15s - loss: 0.2548 - acc: 0.9556 - mDice: 0.7623 - val_loss: 0.4562 - val_acc: 0.9533 - val_mDice: 0.6265

Epoch 00037: val_mDice did not improve from 0.63208
Epoch 38/300
 - 15s - loss: 0.2535 - acc: 0.9557 - mDice: 0.7633 - val_loss: 0.5135 - val_acc: 0.9540 - val_mDice: 0.6042

Epoch 00038: val_mDice did not improve from 0.63208
Epoch 39/300
 - 15s - loss: 0.2517 - acc: 0.9559 - mDice: 0.7649 - val_loss: 0.4699 - val_acc: 0.9555 - val_mDice: 0.6237

Epoch 00039: val_mDice did not improve from 0.63208
Epoch 40/300
 - 15s - loss: 0.2515 - acc: 0.9560 - mDice: 0.7650 - val_loss: 0.4516 - val_acc: 0.9552 - val_mDice: 0.6291

Epoch 00040: val_mDice did not improve from 0.63208
Epoch 41/300
 - 16s - loss: 0.2493 - acc: 0.9561 - mDice: 0.7666 - val_loss: 0.4553 - val_acc: 0.9552 - val_mDice: 0.6319

Epoch 00041: val_mDice did not improve from 0.63208
Epoch 42/300
 - 15s - loss: 0.2497 - acc: 0.9561 - mDice: 0.7664 - val_loss: 0.4342 - val_acc: 0.9540 - val_mDice: 0.6388

Epoch 00042: val_mDice improved from 0.63208 to 0.63882, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 15s - loss: 0.2472 - acc: 0.9562 - mDice: 0.7684 - val_loss: 0.4574 - val_acc: 0.9533 - val_mDice: 0.6264

Epoch 00043: val_mDice did not improve from 0.63882
Epoch 44/300
 - 15s - loss: 0.2469 - acc: 0.9564 - mDice: 0.7687 - val_loss: 0.4544 - val_acc: 0.9540 - val_mDice: 0.6298

Epoch 00044: val_mDice did not improve from 0.63882
Epoch 45/300
 - 15s - loss: 0.2459 - acc: 0.9564 - mDice: 0.7695 - val_loss: 0.4699 - val_acc: 0.9550 - val_mDice: 0.6181

Epoch 00045: val_mDice did not improve from 0.63882
Epoch 46/300
 - 15s - loss: 0.2446 - acc: 0.9565 - mDice: 0.7704 - val_loss: 0.4651 - val_acc: 0.9550 - val_mDice: 0.6236

Epoch 00046: val_mDice did not improve from 0.63882
Epoch 47/300
 - 15s - loss: 0.2439 - acc: 0.9565 - mDice: 0.7710 - val_loss: 0.4881 - val_acc: 0.9535 - val_mDice: 0.6079

Epoch 00047: val_mDice did not improve from 0.63882
Epoch 48/300
 - 15s - loss: 0.2436 - acc: 0.9566 - mDice: 0.7713 - val_loss: 0.4795 - val_acc: 0.9550 - val_mDice: 0.6217

Epoch 00048: val_mDice did not improve from 0.63882
Epoch 49/300
 - 15s - loss: 0.2417 - acc: 0.9567 - mDice: 0.7728 - val_loss: 0.4883 - val_acc: 0.9546 - val_mDice: 0.6110

Epoch 00049: val_mDice did not improve from 0.63882
Epoch 50/300
 - 15s - loss: 0.2413 - acc: 0.9567 - mDice: 0.7731 - val_loss: 0.4646 - val_acc: 0.9539 - val_mDice: 0.6247

Epoch 00050: val_mDice did not improve from 0.63882
Epoch 51/300
 - 15s - loss: 0.2397 - acc: 0.9568 - mDice: 0.7744 - val_loss: 0.4594 - val_acc: 0.9547 - val_mDice: 0.6281

Epoch 00051: val_mDice did not improve from 0.63882
Epoch 52/300
 - 15s - loss: 0.2394 - acc: 0.9569 - mDice: 0.7747 - val_loss: 0.5097 - val_acc: 0.9536 - val_mDice: 0.6118

Epoch 00052: val_mDice did not improve from 0.63882
Epoch 53/300
 - 15s - loss: 0.2396 - acc: 0.9569 - mDice: 0.7746 - val_loss: 0.4507 - val_acc: 0.9556 - val_mDice: 0.6292

Epoch 00053: val_mDice did not improve from 0.63882
Epoch 54/300
 - 15s - loss: 0.2387 - acc: 0.9569 - mDice: 0.7752 - val_loss: 0.4466 - val_acc: 0.9549 - val_mDice: 0.6333

Epoch 00054: val_mDice did not improve from 0.63882
Epoch 55/300
 - 15s - loss: 0.2362 - acc: 0.9571 - mDice: 0.7773 - val_loss: 0.4947 - val_acc: 0.9550 - val_mDice: 0.6070

Epoch 00055: val_mDice did not improve from 0.63882
Epoch 56/300
 - 15s - loss: 0.2383 - acc: 0.9570 - mDice: 0.7758 - val_loss: 0.4638 - val_acc: 0.9538 - val_mDice: 0.6209

Epoch 00056: val_mDice did not improve from 0.63882
Epoch 57/300
 - 15s - loss: 0.2354 - acc: 0.9571 - mDice: 0.7779 - val_loss: 0.4471 - val_acc: 0.9550 - val_mDice: 0.6329

Epoch 00057: val_mDice did not improve from 0.63882
Epoch 58/300
 - 15s - loss: 0.2348 - acc: 0.9572 - mDice: 0.7785 - val_loss: 0.4495 - val_acc: 0.9541 - val_mDice: 0.6309

Epoch 00058: val_mDice did not improve from 0.63882
Epoch 59/300
 - 15s - loss: 0.2348 - acc: 0.9572 - mDice: 0.7785 - val_loss: 0.4656 - val_acc: 0.9535 - val_mDice: 0.6196

Epoch 00059: val_mDice did not improve from 0.63882
Epoch 60/300
 - 15s - loss: 0.2330 - acc: 0.9574 - mDice: 0.7799 - val_loss: 0.4504 - val_acc: 0.9547 - val_mDice: 0.6299

Epoch 00060: val_mDice did not improve from 0.63882
Epoch 61/300
 - 15s - loss: 0.2333 - acc: 0.9574 - mDice: 0.7797 - val_loss: 0.4631 - val_acc: 0.9543 - val_mDice: 0.6247

Epoch 00061: val_mDice did not improve from 0.63882
Epoch 62/300
 - 15s - loss: 0.2326 - acc: 0.9575 - mDice: 0.7803 - val_loss: 0.4699 - val_acc: 0.9555 - val_mDice: 0.6234

Epoch 00062: val_mDice did not improve from 0.63882
Epoch 63/300
 - 15s - loss: 0.2378 - acc: 0.9575 - mDice: 0.7812 - val_loss: 0.4692 - val_acc: 0.9536 - val_mDice: 0.6231

Epoch 00063: val_mDice did not improve from 0.63882
Epoch 64/300
 - 15s - loss: 0.2316 - acc: 0.9575 - mDice: 0.7811 - val_loss: 0.4514 - val_acc: 0.9541 - val_mDice: 0.6295

Epoch 00064: val_mDice did not improve from 0.63882
Epoch 65/300
 - 15s - loss: 0.2304 - acc: 0.9576 - mDice: 0.7820 - val_loss: 0.4433 - val_acc: 0.9539 - val_mDice: 0.6327

Epoch 00065: val_mDice did not improve from 0.63882
Epoch 66/300
 - 15s - loss: 0.2297 - acc: 0.9576 - mDice: 0.7827 - val_loss: 0.4557 - val_acc: 0.9550 - val_mDice: 0.6283

Epoch 00066: val_mDice did not improve from 0.63882
Epoch 67/300
 - 15s - loss: 0.2288 - acc: 0.9576 - mDice: 0.7833 - val_loss: 0.4368 - val_acc: 0.9535 - val_mDice: 0.6379

Epoch 00067: val_mDice did not improve from 0.63882
Epoch 68/300
 - 16s - loss: 0.2286 - acc: 0.9577 - mDice: 0.7835 - val_loss: 0.4540 - val_acc: 0.9546 - val_mDice: 0.6288

Epoch 00068: val_mDice did not improve from 0.63882
Epoch 69/300
 - 15s - loss: 0.2287 - acc: 0.9578 - mDice: 0.7835 - val_loss: 0.4736 - val_acc: 0.9543 - val_mDice: 0.6169

Epoch 00069: val_mDice did not improve from 0.63882
Epoch 70/300
 - 15s - loss: 0.2277 - acc: 0.9577 - mDice: 0.7843 - val_loss: 0.4489 - val_acc: 0.9547 - val_mDice: 0.6310

Epoch 00070: val_mDice did not improve from 0.63882
Epoch 71/300
 - 15s - loss: 0.2269 - acc: 0.9578 - mDice: 0.7850 - val_loss: 0.4436 - val_acc: 0.9556 - val_mDice: 0.6339

Epoch 00071: val_mDice did not improve from 0.63882
Epoch 72/300
 - 15s - loss: 0.2264 - acc: 0.9579 - mDice: 0.7854 - val_loss: 0.4733 - val_acc: 0.9539 - val_mDice: 0.6203

Epoch 00072: val_mDice did not improve from 0.63882
Epoch 73/300
 - 15s - loss: 0.2262 - acc: 0.9579 - mDice: 0.7855 - val_loss: 0.4374 - val_acc: 0.9540 - val_mDice: 0.6384

Epoch 00073: val_mDice did not improve from 0.63882
Epoch 74/300
 - 15s - loss: 0.2245 - acc: 0.9580 - mDice: 0.7869 - val_loss: 0.4448 - val_acc: 0.9565 - val_mDice: 0.6343

Epoch 00074: val_mDice did not improve from 0.63882
Epoch 75/300
 - 15s - loss: 0.2258 - acc: 0.9579 - mDice: 0.7859 - val_loss: 0.4542 - val_acc: 0.9548 - val_mDice: 0.6278

Epoch 00075: val_mDice did not improve from 0.63882
Epoch 76/300
 - 15s - loss: 0.2233 - acc: 0.9581 - mDice: 0.7879 - val_loss: 0.4804 - val_acc: 0.9542 - val_mDice: 0.6153

Epoch 00076: val_mDice did not improve from 0.63882
Epoch 77/300
 - 15s - loss: 0.2237 - acc: 0.9580 - mDice: 0.7875 - val_loss: 0.4396 - val_acc: 0.9554 - val_mDice: 0.6368

Epoch 00077: val_mDice did not improve from 0.63882
Epoch 78/300
 - 15s - loss: 0.2235 - acc: 0.9581 - mDice: 0.7878 - val_loss: 0.4372 - val_acc: 0.9534 - val_mDice: 0.6363

Epoch 00078: val_mDice did not improve from 0.63882
Epoch 79/300
 - 15s - loss: 0.2232 - acc: 0.9580 - mDice: 0.7879 - val_loss: 0.4560 - val_acc: 0.9561 - val_mDice: 0.6296

Epoch 00079: val_mDice did not improve from 0.63882
Epoch 80/300
 - 15s - loss: 0.2228 - acc: 0.9581 - mDice: 0.7883 - val_loss: 0.4614 - val_acc: 0.9550 - val_mDice: 0.6244

Epoch 00080: val_mDice did not improve from 0.63882
Epoch 81/300
 - 15s - loss: 0.2221 - acc: 0.9582 - mDice: 0.7889 - val_loss: 0.4647 - val_acc: 0.9523 - val_mDice: 0.6214

Epoch 00081: val_mDice did not improve from 0.63882
Epoch 82/300
 - 15s - loss: 0.2214 - acc: 0.9582 - mDice: 0.7895 - val_loss: 0.4575 - val_acc: 0.9544 - val_mDice: 0.6265

Epoch 00082: val_mDice did not improve from 0.63882
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
{'val_loss': [0.9146104558220123, 0.5927425942607432, 0.4890393927776614, 0.5105989142503152, 0.5055884359269168, 0.4827081088247246, 0.4692767262458801, 0.4849955296383224, 0.47857426598085373, 0.47929524642795157, 0.4757118041954893, 0.4678039960355066, 0.4970694447362889, 0.46357285044046753, 0.45706628421165424, 0.48926216863387123, 0.47132247486594003, 0.46265346544414926, 0.4807728728768546, 0.4758667373124448, 0.46263516482028216, 0.4565559662254163, 0.4752510596254018, 0.4704008815008835, 0.4618526440758945, 0.4547256101443115, 0.45798254246152315, 0.44986904799605215, 0.4653331500857902, 0.4784449735167306, 0.4771504698518934, 0.4444571027542626, 0.4581658523841943, 0.4930111006651511, 0.45957857836558164, 0.45734115719129254, 0.4561880513942441, 0.5134652373511032, 0.46987636861854426, 0.4516089099079537, 0.45526701178630635, 0.4341621808499597, 0.4573960384177096, 0.4543905178261869, 0.4698610409012054, 0.4650938927128328, 0.48809763039956544, 0.4794802412640449, 0.48827444508089035, 0.46461698562739284, 0.45937971462750565, 0.5097288033149762, 0.4507454267427242, 0.4466218645346231, 0.4947144099453974, 0.4637547181971246, 0.44712673851897594, 0.4495228335844072, 0.4655839704268471, 0.45043324125545653, 0.46307488360218496, 0.46988377491189115, 0.46921241882793063, 0.4513941174112885, 0.4433459972536098, 0.45565257525310837, 0.4368331645454108, 0.4539525765280484, 0.4736081451677077, 0.448859763545031, 0.4435624247156708, 0.47331487333308386, 0.43743535360144503, 0.44477059588086004, 0.4542308832680047, 0.480391876324595, 0.4396223259371752, 0.4371637508855852, 0.4560486154849303, 0.4613548700369936, 0.464724699545173, 0.4574683738154406], 'val_acc': [0.9262090401942503, 0.9385536902443656, 0.9503735503670889, 0.945386100414745, 0.9530552865406654, 0.9534044442230096, 0.9536482139006673, 0.9529106423841508, 0.9532866507935125, 0.9556647036328662, 0.9531420292801032, 0.9539746429001152, 0.9513590449061473, 0.9536998971214508, 0.9540924090246915, 0.9511503567242755, 0.9555159331034015, 0.9556502210361332, 0.9556192126354026, 0.9538259279794533, 0.9560654889271912, 0.9519664588587244, 0.9538878878401644, 0.9556791472701387, 0.9539684776487297, 0.9533796273796252, 0.9528651866832925, 0.9560593133532135, 0.9539312910101267, 0.9557018749540744, 0.955387856041253, 0.9530180679353256, 0.9546750567478841, 0.9548093310281551, 0.9549642814604263, 0.9553093237583864, 0.9532556926737951, 0.9540448947991739, 0.9554539725767167, 0.9551915456462838, 0.9551502186492835, 0.9540407764179081, 0.95331145465041, 0.9540386992459856, 0.9549766922130265, 0.9549952725458412, 0.9535449280419164, 0.9550097667971137, 0.9546048218311545, 0.9538693058424156, 0.954730829380078, 0.9536234210323355, 0.9556378469120856, 0.9548713471636426, 0.9550345296966297, 0.9537597994564632, 0.9549952828684333, 0.9541151470312194, 0.9534767293397275, 0.9546584976452023, 0.9542783828421012, 0.9555200674680359, 0.9535903804129062, 0.9541275338087668, 0.9539292138382043, 0.9550263029237033, 0.9534747054456999, 0.9546337091056994, 0.9543114301212673, 0.9546543935823707, 0.9556316330446212, 0.9539292098423622, 0.953999482386605, 0.9564745672588242, 0.954778332284043, 0.954166810605779, 0.9554126385869927, 0.953447826081814, 0.9561481222760078, 0.955028345797981, 0.9522577830533075, 0.9543733963087284], 'val_mDice': [0.3894564449454153, 0.540362849581841, 0.6035912882682332, 0.5900157889840323, 0.5987367540098435, 0.6083342932456033, 0.6172566240726236, 0.6099065322449754, 0.6138036777187326, 0.615418063195724, 0.6161920821200536, 0.6191026498485543, 0.6002628593471463, 0.6195365423596771, 0.6245579886036878, 0.608464065876753, 0.6174342042906991, 0.6225852560064646, 0.6155566909459717, 0.614826101164578, 0.6216026018451712, 0.6240196124801423, 0.6164415408779123, 0.6252873430038963, 0.6209909905934466, 0.6252350687314678, 0.6245636343955994, 0.6306128681704984, 0.6213299575464686, 0.6195300980653177, 0.6135889628080017, 0.6320783555840647, 0.6259072119963236, 0.611450279891158, 0.6300487671484495, 0.6250532086335081, 0.6265177360460079, 0.6041939378450703, 0.6237427938583843, 0.6290713245642252, 0.6319392793005405, 0.638817491811081, 0.626409417424122, 0.6298128979166127, 0.6181366253831533, 0.6235701578289436, 0.6078600423962044, 0.6216639766480003, 0.6110476864782791, 0.6247403648312532, 0.628053816670146, 0.6118087681978108, 0.6292360168595553, 0.6333081922051627, 0.6070173499304489, 0.6208998334474404, 0.6329302308279708, 0.6309406890549474, 0.6196054366713796, 0.629851171424269, 0.6246818996674521, 0.6234275701991673, 0.6230656960823017, 0.6294873260252969, 0.6327176663462676, 0.6282592758786079, 0.6379287059746641, 0.6287784523138121, 0.6169242083027376, 0.6310210880620519, 0.6338787032239264, 0.6202851713702665, 0.6383944813099653, 0.6343086904653624, 0.6278446140236029, 0.6153022517039123, 0.6367599208261714, 0.6363002141760714, 0.6295798777201989, 0.6243829853707852, 0.6214459188823593, 0.6265040353023806], 'loss': [1.9605435574926664, 0.6326074111040274, 0.48546112861114415, 0.4326902687513882, 0.4039716704869139, 0.3838066587319049, 0.3689202328249232, 0.35494243945277376, 0.3452348918912458, 0.336508959728183, 0.3291755471280974, 0.32184387666617764, 0.31617605886482203, 0.31065357159596957, 0.30574260730381386, 0.3009844767077349, 0.2976808300267494, 0.29177764672630785, 0.29032999053609626, 0.28784715353121365, 0.2845887505932186, 0.2825533357244919, 0.2784069088505709, 0.27473667051354417, 0.2730307284214873, 0.27374488167413197, 0.26900556367191963, 0.2667894635651212, 0.26475003702397326, 0.26383635160041446, 0.31138395309532646, 0.2706665056709189, 0.26483732543897476, 0.2611306781219791, 0.25849633718632864, 0.25605044663228355, 0.25477400817166523, 0.2535238316421915, 0.251682187720949, 0.2515056996256962, 0.24933451096623702, 0.2497216102607655, 0.24716274609824657, 0.24686480931262877, 0.2459262046352476, 0.2446358656116797, 0.24389188986761198, 0.243604087417639, 0.24168884917224495, 0.2412611354290741, 0.23973950035827468, 0.23936967700874032, 0.2396484016146667, 0.23873736100235535, 0.23618151201729057, 0.2382764039209846, 0.23536146403797104, 0.2347585660239644, 0.2347581683258418, 0.23295130006115614, 0.2332990546059254, 0.2326438909836905, 0.23781320784945198, 0.23156409207028467, 0.23036673584782827, 0.22965133372757354, 0.22881371695782635, 0.22859082880375803, 0.22873277206883427, 0.2277227630121023, 0.22687944492303783, 0.22636689726878248, 0.22615236968628222, 0.22452209503664558, 0.22579072538293996, 0.22332435272795126, 0.22371696808078334, 0.2235486110470782, 0.2232205490080803, 0.22282345739787884, 0.22212267428576496, 0.22139122227500918], 'acc': [0.6992362700765913, 0.9162176735072242, 0.9323888915626904, 0.9404908657580392, 0.9438070040546168, 0.945730862200153, 0.9470415639855245, 0.9481575171429765, 0.9489102348036823, 0.9495550523259516, 0.9500911851171042, 0.9506446211876014, 0.9510588559487061, 0.9515552696050184, 0.9519277900127886, 0.9522536828473634, 0.952595549392373, 0.9529549175764142, 0.9531914014960678, 0.953277648089336, 0.9534994702499927, 0.9536061811392607, 0.954011470645895, 0.9542180259894795, 0.9543989988189073, 0.9543851632274877, 0.9546891818618691, 0.9548179673204547, 0.955068047640338, 0.9550944550073353, 0.9519498234097458, 0.9545631941630491, 0.9549955387052111, 0.9552838057287703, 0.9554699177731876, 0.9556235575830486, 0.9556018272280388, 0.9557316183628363, 0.9559334381026229, 0.955998475567447, 0.9560810366712308, 0.9560980365450467, 0.9562080494783963, 0.956365135365806, 0.9564014906347217, 0.9564575477724443, 0.9565221416840503, 0.9565561975141307, 0.9567133459765162, 0.9566893153451352, 0.9567663996419994, 0.9568569781272398, 0.9569365985187971, 0.9568761944134545, 0.9570861082179348, 0.9569974248461601, 0.9571054461513832, 0.9572268394783466, 0.9572223697727487, 0.9573762713028685, 0.9573502285172364, 0.9574523266770275, 0.9574602410740195, 0.9575053614849658, 0.9575630458739646, 0.957599785071976, 0.9576385389303539, 0.9576862312455263, 0.9577698223367898, 0.9577280459278816, 0.9577994523734791, 0.9578687988863188, 0.9578566709853396, 0.958002317062774, 0.9579169760179652, 0.9580797215580882, 0.9579894060818732, 0.9580765999121172, 0.9580242507637317, 0.9580926136489814, 0.9581658272310563, 0.9581755978253067], 'mDice': [0.23040483102716136, 0.5184396571254984, 0.6015654615337608, 0.6350104116768912, 0.6538296541671115, 0.667448323258361, 0.6776583408434195, 0.687232788744903, 0.6942257016100244, 0.7003672614147458, 0.7057706234885044, 0.7110732969430841, 0.7152929488015807, 0.7193593394781638, 0.7229514321135082, 0.7266234058380958, 0.7291285520895563, 0.73346190725976, 0.7346466323024509, 0.7366599113838221, 0.7390890308834293, 0.7406250234425675, 0.7438303395058035, 0.7465684812908163, 0.7479502520954145, 0.7475580395478892, 0.7511321709804121, 0.7527998371403706, 0.7545086860812559, 0.7551836314190188, 0.7243617720758725, 0.7496607853893517, 0.7543092801169524, 0.757262137426893, 0.7593031852250914, 0.7612994439422315, 0.7622946553822144, 0.7633357915273972, 0.7648746029210437, 0.7649978939065434, 0.7666105673558689, 0.766408906530421, 0.7684342674288145, 0.7686648620323485, 0.7695340407056348, 0.770427480420349, 0.7710445107772754, 0.7713160333008322, 0.7728066949126027, 0.7731496089099896, 0.7743816170438715, 0.7746910212197197, 0.7745519973381069, 0.7752348555308867, 0.7772797629091904, 0.7757706442505672, 0.777940496770679, 0.7784894819346904, 0.7785116430201774, 0.7799369575125376, 0.7797350392518989, 0.780290503782629, 0.7812114123275912, 0.7811226362977164, 0.7820465634067972, 0.7826860512850117, 0.7833067429597442, 0.7835297048250955, 0.7835056255874107, 0.7842703575753197, 0.7849501456890249, 0.7854214785996426, 0.7855449933013939, 0.7868712002347675, 0.7858836887890552, 0.7879030262292273, 0.7875185250021859, 0.7877655584083313, 0.7879233332080497, 0.7882775286107364, 0.7889148273224418, 0.7894766000346755]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.31s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.07s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.86s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:31,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:58,  1.69s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:56,  1.69s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:37,  1.63s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:57,  1.70s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:38,  1.64s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:56,  1.71s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:45,  1.68s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:16,  1.80s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:37,  1.88s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:20,  1.83s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:37,  1.89s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:13,  1.81s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:10,  1.81s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:45,  1.94s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:57,  2.00s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:30,  1.91s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:21,  1.88s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:03,  1.82s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<08:02,  1.82s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:25,  1.91s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:59,  1.82s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:01,  1.84s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:43,  1.78s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:05,  1.87s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:16,  1.92s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:55,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:55,  1.85s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:56,  1.86s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:16,  1.95s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:25,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:58,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:59,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:52,  1.88s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:05,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<08:01,  1.95s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:42,  1.88s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:18,  1.80s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:05,  1.75s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:10,  1.78s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:34,  1.89s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:18,  1.83s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:30,  1.88s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:11,  1.81s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:15,  1.84s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:36,  1.93s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:29,  1.91s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:33,  1.94s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:13,  1.86s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:24,  1.92s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:03,  1.84s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:04,  1.85s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:53,  1.81s/it]predicting train subjects:  20%|██        | 58/285 [01:46<06:52,  1.82s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:05,  1.88s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:12,  1.92s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<06:54,  1.85s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<06:51,  1.84s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<06:47,  1.83s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:34,  1.79s/it]predicting train subjects:  23%|██▎       | 65/285 [01:59<06:36,  1.80s/it]predicting train subjects:  23%|██▎       | 66/285 [02:01<06:39,  1.82s/it]predicting train subjects:  24%|██▎       | 67/285 [02:03<06:40,  1.84s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:28,  1.79s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:29,  1.80s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:34,  1.84s/it]predicting train subjects:  25%|██▍       | 71/285 [02:10<06:31,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:12<06:22,  1.80s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:23,  1.81s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:20,  1.80s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:27,  1.84s/it]predicting train subjects:  27%|██▋       | 76/285 [02:19<06:24,  1.84s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<06:17,  1.82s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<06:08,  1.78s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<06:12,  1.81s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<06:15,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:28<06:12,  1.82s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<06:12,  1.84s/it]predicting train subjects:  29%|██▉       | 83/285 [02:32<06:06,  1.81s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:56,  1.77s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:07,  1.84s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:08,  1.86s/it]predicting train subjects:  31%|███       | 88/285 [02:41<05:54,  1.80s/it]predicting train subjects:  31%|███       | 89/285 [02:43<06:01,  1.84s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<06:06,  1.88s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<05:55,  1.83s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<05:56,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<05:47,  1.81s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<05:46,  1.81s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<05:49,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:48,  1.85s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<05:49,  1.86s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:47,  1.87s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<05:44,  1.86s/it]predicting train subjects:  35%|███▌      | 101/285 [03:05<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:07<05:33,  1.82s/it]predicting train subjects:  36%|███▌      | 103/285 [03:09<05:26,  1.79s/it]predicting train subjects:  36%|███▋      | 104/285 [03:11<05:24,  1.79s/it]predicting train subjects:  37%|███▋      | 105/285 [03:12<05:25,  1.81s/it]predicting train subjects:  37%|███▋      | 106/285 [03:14<05:14,  1.76s/it]predicting train subjects:  38%|███▊      | 107/285 [03:16<05:15,  1.77s/it]predicting train subjects:  38%|███▊      | 108/285 [03:18<05:13,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:19<05:14,  1.79s/it]predicting train subjects:  39%|███▊      | 110/285 [03:21<05:14,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:23<05:09,  1.78s/it]predicting train subjects:  39%|███▉      | 112/285 [03:25<05:08,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:27<05:10,  1.81s/it]predicting train subjects:  40%|████      | 114/285 [03:29<05:14,  1.84s/it]predicting train subjects:  40%|████      | 115/285 [03:30<05:11,  1.83s/it]predicting train subjects:  41%|████      | 116/285 [03:32<05:09,  1.83s/it]predicting train subjects:  41%|████      | 117/285 [03:34<04:59,  1.78s/it]predicting train subjects:  41%|████▏     | 118/285 [03:36<04:54,  1.77s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<04:59,  1.81s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<04:55,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:41<04:47,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:43<04:37,  1.70s/it]predicting train subjects:  43%|████▎     | 123/285 [03:44<04:27,  1.65s/it]predicting train subjects:  44%|████▎     | 124/285 [03:46<04:25,  1.65s/it]predicting train subjects:  44%|████▍     | 125/285 [03:47<04:17,  1.61s/it]predicting train subjects:  44%|████▍     | 126/285 [03:49<04:13,  1.59s/it]predicting train subjects:  45%|████▍     | 127/285 [03:50<04:05,  1.55s/it]predicting train subjects:  45%|████▍     | 128/285 [03:52<04:07,  1.58s/it]predicting train subjects:  45%|████▌     | 129/285 [03:53<04:03,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:55<03:59,  1.55s/it]predicting train subjects:  46%|████▌     | 131/285 [03:56<03:56,  1.54s/it]predicting train subjects:  46%|████▋     | 132/285 [03:58<04:01,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:00<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:01<03:56,  1.57s/it]predicting train subjects:  47%|████▋     | 135/285 [04:03<03:59,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:04<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 137/285 [04:06<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:08<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:09<03:55,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:11<03:57,  1.64s/it]predicting train subjects:  49%|████▉     | 141/285 [04:13<03:49,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:14<03:48,  1.60s/it]predicting train subjects:  50%|█████     | 143/285 [04:16<03:41,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:17<03:50,  1.64s/it]predicting train subjects:  51%|█████     | 145/285 [04:19<03:45,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:21<03:44,  1.61s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:22<03:35,  1.56s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:24<03:37,  1.59s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:25<03:34,  1.58s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:31,  1.57s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:28<03:33,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:28,  1.57s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:31<03:25,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:33<03:31,  1.62s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:35<03:28,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:37<03:32,  1.65s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:38<03:24,  1.60s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:40<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:17,  1.57s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:43<03:19,  1.60s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:21,  1.62s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<03:12,  1.58s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<03:10,  1.57s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:51<03:06,  1.56s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:06,  1.57s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:56<03:09,  1.62s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:59<03:01,  1.58s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [05:02<02:56,  1.56s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:53,  1.55s/it]predicting train subjects:  61%|██████    | 174/285 [05:05<02:50,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:53,  1.58s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:55,  1.61s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:10<02:49,  1.57s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:11<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:40,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:16<02:51,  1.64s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:18<02:54,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:19<02:47,  1.64s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:21<02:42,  1.60s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:35,  1.55s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:24<02:43,  1.66s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:50,  1.74s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:53,  1.79s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:30<02:43,  1.70s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:33,  1.62s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:33<02:33,  1.64s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:35,  1.67s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:36<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:38<02:26,  1.61s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:39<02:21,  1.57s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:41<02:28,  1.67s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:43<02:33,  1.74s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:45<02:35,  1.78s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:46<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:48<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [05:50<02:25,  1.73s/it]predicting train subjects:  71%|███████   | 202/285 [05:51<02:25,  1.75s/it]predicting train subjects:  71%|███████   | 203/285 [05:53<02:25,  1.78s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:55<02:16,  1.69s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:56<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:58<02:06,  1.60s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:00<02:12,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:02<02:14,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:03<02:16,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:05<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:06<02:01,  1.64s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:08<02:01,  1.66s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:10<02:00,  1.67s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:11<01:55,  1.62s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:13<01:58,  1.69s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:15<01:52,  1.63s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:17<01:56,  1.71s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:18<01:57,  1.76s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:20<01:59,  1.81s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:22<01:51,  1.72s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:23<01:45,  1.66s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:25<01:46,  1.69s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:27<01:39,  1.61s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:35,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:30<01:33,  1.55s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:32<01:38,  1.67s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:41,  1.76s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:43,  1.81s/it]predicting train subjects:  80%|████████  | 229/285 [06:37<01:39,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:39<01:32,  1.69s/it]predicting train subjects:  81%|████████  | 231/285 [06:40<01:28,  1.64s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:42<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:43<01:25,  1.65s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:45<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:47<01:23,  1.66s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:49<01:26,  1.76s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:51<01:26,  1.80s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:53<01:25,  1.82s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:54<01:23,  1.81s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:56<01:17,  1.71s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:57<01:13,  1.66s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:59<01:08,  1.59s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:00<01:04,  1.55s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:02<01:07,  1.64s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:04<01:03,  1.58s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:06<01:05,  1.67s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:05,  1.73s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:09<01:03,  1.72s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:11<00:59,  1.66s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:12<00:57,  1.63s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:14<00:54,  1.60s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:15<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:17<00:52,  1.65s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:19<00:52,  1.69s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:21<00:50,  1.70s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:22<00:47,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [07:23<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [07:25<00:45,  1.69s/it]predicting train subjects:  91%|█████████ | 259/285 [07:27<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [07:29<00:41,  1.68s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:30<00:39,  1.64s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:32<00:36,  1.61s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:33<00:34,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:35<00:35,  1.70s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:37<00:35,  1.76s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:39<00:32,  1.71s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:40<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:42<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:44<00:27,  1.69s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:45<00:24,  1.61s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:47<00:22,  1.58s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:48<00:20,  1.61s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:50<00:18,  1.57s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:51<00:16,  1.54s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:53<00:16,  1.67s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:55<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:57<00:13,  1.64s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:58<00:11,  1.59s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:00<00:09,  1.64s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:01<00:07,  1.59s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:03<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:04<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:06<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:08<00:01,  1.73s/it]predicting train subjects: 100%|██████████| 285/285 [08:10<00:00,  1.79s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:51,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<07:07,  1.51s/it]Loading train:   1%|          | 3/285 [00:04<07:05,  1.51s/it]Loading train:   1%|▏         | 4/285 [00:05<06:30,  1.39s/it]Loading train:   2%|▏         | 5/285 [00:06<06:42,  1.44s/it]Loading train:   2%|▏         | 6/285 [00:08<06:12,  1.34s/it]Loading train:   2%|▏         | 7/285 [00:09<06:17,  1.36s/it]Loading train:   3%|▎         | 8/285 [00:10<06:14,  1.35s/it]Loading train:   3%|▎         | 9/285 [00:12<06:32,  1.42s/it]Loading train:   4%|▎         | 10/285 [00:13<05:54,  1.29s/it]Loading train:   4%|▍         | 11/285 [00:14<05:04,  1.11s/it]Loading train:   4%|▍         | 12/285 [00:15<04:53,  1.07s/it]Loading train:   5%|▍         | 13/285 [00:15<04:32,  1.00s/it]Loading train:   5%|▍         | 14/285 [00:16<04:23,  1.03it/s]Loading train:   5%|▌         | 15/285 [00:17<04:28,  1.01it/s]Loading train:   6%|▌         | 16/285 [00:18<04:23,  1.02it/s]Loading train:   6%|▌         | 17/285 [00:19<04:13,  1.06it/s]Loading train:   6%|▋         | 18/285 [00:20<04:22,  1.02it/s]Loading train:   7%|▋         | 19/285 [00:21<04:11,  1.06it/s]Loading train:   7%|▋         | 20/285 [00:22<03:59,  1.11it/s]Loading train:   7%|▋         | 21/285 [00:23<04:09,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:24<03:54,  1.12it/s]Loading train:   8%|▊         | 23/285 [00:25<04:08,  1.06it/s]Loading train:   8%|▊         | 24/285 [00:26<03:51,  1.13it/s]Loading train:   9%|▉         | 25/285 [00:27<03:58,  1.09it/s]Loading train:   9%|▉         | 26/285 [00:27<03:55,  1.10it/s]Loading train:   9%|▉         | 27/285 [00:28<03:47,  1.13it/s]Loading train:  10%|▉         | 28/285 [00:29<03:59,  1.07it/s]Loading train:  10%|█         | 29/285 [00:30<04:02,  1.05it/s]Loading train:  11%|█         | 30/285 [00:31<04:09,  1.02it/s]Loading train:  11%|█         | 31/285 [00:32<04:16,  1.01s/it]Loading train:  11%|█         | 32/285 [00:33<03:56,  1.07it/s]Loading train:  12%|█▏        | 33/285 [00:34<03:57,  1.06it/s]Loading train:  12%|█▏        | 34/285 [00:35<03:55,  1.07it/s]Loading train:  12%|█▏        | 35/285 [00:36<03:58,  1.05it/s]Loading train:  13%|█▎        | 36/285 [00:37<03:53,  1.07it/s]Loading train:  13%|█▎        | 37/285 [00:38<03:48,  1.08it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:56,  1.05it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:47,  1.08it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:53,  1.05it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:43,  1.09it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:49,  1.06it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:50,  1.05it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:52,  1.04it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:55,  1.02it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:51,  1.03it/s]Loading train:  16%|█▋        | 47/285 [00:47<03:47,  1.05it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:44,  1.06it/s]Loading train:  17%|█▋        | 49/285 [00:49<03:53,  1.01it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:52,  1.01it/s]Loading train:  18%|█▊        | 51/285 [00:51<03:52,  1.00it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:43,  1.04it/s]Loading train:  19%|█▊        | 53/285 [00:53<03:47,  1.02it/s]Loading train:  19%|█▉        | 54/285 [00:54<03:50,  1.00it/s]Loading train:  19%|█▉        | 55/285 [00:55<03:42,  1.03it/s]Loading train:  20%|█▉        | 56/285 [00:56<03:36,  1.06it/s]Loading train:  20%|██        | 57/285 [00:57<03:34,  1.07it/s]Loading train:  20%|██        | 58/285 [00:58<03:32,  1.07it/s]Loading train:  21%|██        | 59/285 [00:59<03:42,  1.02it/s]Loading train:  21%|██        | 60/285 [01:00<03:36,  1.04it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:36,  1.03it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:45,  1.01s/it]Loading train:  22%|██▏       | 63/285 [01:03<03:37,  1.02it/s]Loading train:  22%|██▏       | 64/285 [01:04<04:02,  1.10s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:30,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:32,  1.24s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:12,  1.16s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:47,  1.05s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:39,  1.02s/it]Loading train:  25%|██▍       | 70/285 [01:11<03:34,  1.00it/s]Loading train:  25%|██▍       | 71/285 [01:12<03:25,  1.04it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:30,  1.01it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:28,  1.02it/s]Loading train:  26%|██▌       | 74/285 [01:15<03:19,  1.06it/s]Loading train:  26%|██▋       | 75/285 [01:16<03:18,  1.06it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:13,  1.08it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:07,  1.11it/s]Loading train:  27%|██▋       | 78/285 [01:18<02:57,  1.17it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:02,  1.13it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:04,  1.11it/s]Loading train:  28%|██▊       | 81/285 [01:21<03:04,  1.10it/s]Loading train:  29%|██▉       | 82/285 [01:22<03:04,  1.10it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:08,  1.07it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:56,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:25<03:03,  1.09it/s]Loading train:  30%|███       | 86/285 [01:26<03:09,  1.05it/s]Loading train:  31%|███       | 87/285 [01:26<03:07,  1.06it/s]Loading train:  31%|███       | 88/285 [01:27<02:57,  1.11it/s]Loading train:  31%|███       | 89/285 [01:28<02:57,  1.10it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:04,  1.06it/s]Loading train:  32%|███▏      | 91/285 [01:30<03:00,  1.07it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:07,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:32<02:58,  1.07it/s]Loading train:  33%|███▎      | 94/285 [01:33<03:05,  1.03it/s]Loading train:  33%|███▎      | 95/285 [01:34<03:07,  1.01it/s]Loading train:  34%|███▎      | 96/285 [01:35<03:10,  1.01s/it]Loading train:  34%|███▍      | 97/285 [01:36<02:58,  1.05it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:58,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:57,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:58,  1.04it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:47,  1.10it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:48,  1.09it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:35,  1.17it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:44,  1.10it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:47,  1.08it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:38,  1.13it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:38,  1.13it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:36,  1.13it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:45,  1.07it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:38,  1.10it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:31,  1.15it/s]Loading train:  39%|███▉      | 112/285 [01:49<02:30,  1.15it/s]Loading train:  40%|███▉      | 113/285 [01:50<02:29,  1.15it/s]Loading train:  40%|████      | 114/285 [01:51<02:27,  1.16it/s]Loading train:  40%|████      | 115/285 [01:52<02:34,  1.10it/s]Loading train:  41%|████      | 116/285 [01:53<02:32,  1.11it/s]Loading train:  41%|████      | 117/285 [01:54<02:27,  1.14it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:19,  1.19it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:28,  1.12it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:31,  1.09it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:46,  1.02s/it]Loading train:  43%|████▎     | 122/285 [01:59<02:51,  1.05s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:55,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:48,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:38,  1.01it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:34,  1.03it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:26,  1.08it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:23,  1.09it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:20,  1.11it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:15,  1.14it/s]Loading train:  46%|████▌     | 131/285 [02:07<02:06,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:05,  1.21it/s]Loading train:  47%|████▋     | 133/285 [02:08<01:56,  1.30it/s]Loading train:  47%|████▋     | 134/285 [02:09<01:56,  1.29it/s]Loading train:  47%|████▋     | 135/285 [02:10<01:52,  1.33it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:53,  1.31it/s]Loading train:  48%|████▊     | 137/285 [02:12<01:54,  1.29it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:56,  1.26it/s]Loading train:  49%|████▉     | 139/285 [02:13<01:52,  1.29it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:57,  1.24it/s]Loading train:  49%|████▉     | 141/285 [02:15<01:49,  1.32it/s]Loading train:  50%|████▉     | 142/285 [02:16<01:53,  1.27it/s]Loading train:  50%|█████     | 143/285 [02:16<01:51,  1.28it/s]Loading train:  51%|█████     | 144/285 [02:17<01:50,  1.27it/s]Loading train:  51%|█████     | 145/285 [02:18<01:49,  1.27it/s]Loading train:  51%|█████     | 146/285 [02:19<01:47,  1.30it/s]Loading train:  52%|█████▏    | 147/285 [02:19<01:50,  1.25it/s]Loading train:  52%|█████▏    | 148/285 [02:20<01:47,  1.27it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:51,  1.22it/s]Loading train:  53%|█████▎    | 150/285 [02:22<01:46,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:23<01:49,  1.22it/s]Loading train:  53%|█████▎    | 152/285 [02:24<01:48,  1.23it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:40,  1.31it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:42,  1.28it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:42,  1.27it/s]Loading train:  55%|█████▍    | 156/285 [02:27<01:44,  1.23it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:42,  1.25it/s]Loading train:  55%|█████▌    | 158/285 [02:28<01:44,  1.22it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:43,  1.21it/s]Loading train:  56%|█████▌    | 160/285 [02:30<01:43,  1.21it/s]Loading train:  56%|█████▋    | 161/285 [02:31<01:38,  1.25it/s]Loading train:  57%|█████▋    | 162/285 [02:31<01:37,  1.26it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:35,  1.27it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:37,  1.24it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:32,  1.30it/s]Loading train:  58%|█████▊    | 166/285 [02:35<01:31,  1.30it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:29,  1.32it/s]Loading train:  59%|█████▉    | 168/285 [02:36<01:25,  1.37it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:28,  1.31it/s]Loading train:  60%|█████▉    | 170/285 [02:37<01:25,  1.34it/s]Loading train:  60%|██████    | 171/285 [02:38<01:27,  1.31it/s]Loading train:  60%|██████    | 172/285 [02:39<01:23,  1.35it/s]Loading train:  61%|██████    | 173/285 [02:40<01:23,  1.35it/s]Loading train:  61%|██████    | 174/285 [02:40<01:20,  1.38it/s]Loading train:  61%|██████▏   | 175/285 [02:41<01:26,  1.28it/s]Loading train:  62%|██████▏   | 176/285 [02:42<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [02:43<01:30,  1.20it/s]Loading train:  62%|██████▏   | 178/285 [02:44<01:27,  1.23it/s]Loading train:  63%|██████▎   | 179/285 [02:45<01:25,  1.24it/s]Loading train:  63%|██████▎   | 180/285 [02:46<01:32,  1.14it/s]Loading train:  64%|██████▎   | 181/285 [02:47<01:31,  1.14it/s]Loading train:  64%|██████▍   | 182/285 [02:48<01:33,  1.11it/s]Loading train:  64%|██████▍   | 183/285 [02:48<01:29,  1.13it/s]Loading train:  65%|██████▍   | 184/285 [02:49<01:27,  1.15it/s]Loading train:  65%|██████▍   | 185/285 [02:50<01:21,  1.23it/s]Loading train:  65%|██████▌   | 186/285 [02:51<01:28,  1.12it/s]Loading train:  66%|██████▌   | 187/285 [02:52<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [02:53<01:31,  1.06it/s]Loading train:  66%|██████▋   | 189/285 [02:54<01:26,  1.10it/s]Loading train:  67%|██████▋   | 190/285 [02:55<01:25,  1.11it/s]Loading train:  67%|██████▋   | 191/285 [02:56<01:24,  1.12it/s]Loading train:  67%|██████▋   | 192/285 [02:56<01:24,  1.10it/s]Loading train:  68%|██████▊   | 193/285 [02:57<01:17,  1.19it/s]Loading train:  68%|██████▊   | 194/285 [02:58<01:13,  1.24it/s]Loading train:  68%|██████▊   | 195/285 [02:59<01:11,  1.26it/s]Loading train:  69%|██████▉   | 196/285 [03:00<01:16,  1.17it/s]Loading train:  69%|██████▉   | 197/285 [03:00<01:15,  1.17it/s]Loading train:  69%|██████▉   | 198/285 [03:02<01:21,  1.06it/s]Loading train:  70%|██████▉   | 199/285 [03:02<01:13,  1.17it/s]Loading train:  70%|███████   | 200/285 [03:03<01:11,  1.18it/s]Loading train:  71%|███████   | 201/285 [03:04<01:17,  1.09it/s]Loading train:  71%|███████   | 202/285 [03:05<01:15,  1.10it/s]Loading train:  71%|███████   | 203/285 [03:06<01:11,  1.14it/s]Loading train:  72%|███████▏  | 204/285 [03:07<01:07,  1.20it/s]Loading train:  72%|███████▏  | 205/285 [03:07<01:04,  1.23it/s]Loading train:  72%|███████▏  | 206/285 [03:08<01:03,  1.25it/s]Loading train:  73%|███████▎  | 207/285 [03:09<01:09,  1.12it/s]Loading train:  73%|███████▎  | 208/285 [03:10<01:06,  1.15it/s]Loading train:  73%|███████▎  | 209/285 [03:11<01:07,  1.13it/s]Loading train:  74%|███████▎  | 210/285 [03:12<01:01,  1.23it/s]Loading train:  74%|███████▍  | 211/285 [03:12<01:00,  1.22it/s]Loading train:  74%|███████▍  | 212/285 [03:13<00:59,  1.22it/s]Loading train:  75%|███████▍  | 213/285 [03:14<01:02,  1.15it/s]Loading train:  75%|███████▌  | 214/285 [03:15<00:59,  1.20it/s]Loading train:  75%|███████▌  | 215/285 [03:16<01:04,  1.08it/s]Loading train:  76%|███████▌  | 216/285 [03:17<00:58,  1.17it/s]Loading train:  76%|███████▌  | 217/285 [03:18<00:58,  1.15it/s]Loading train:  76%|███████▋  | 218/285 [03:19<00:57,  1.17it/s]Loading train:  77%|███████▋  | 219/285 [03:19<00:57,  1.15it/s]Loading train:  77%|███████▋  | 220/285 [03:20<00:52,  1.23it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:49,  1.30it/s]Loading train:  78%|███████▊  | 222/285 [03:22<00:51,  1.21it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:47,  1.30it/s]Loading train:  79%|███████▊  | 224/285 [03:23<00:49,  1.24it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:47,  1.25it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:48,  1.21it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:51,  1.12it/s]Loading train:  80%|████████  | 228/285 [03:27<00:55,  1.03it/s]Loading train:  80%|████████  | 229/285 [03:28<00:52,  1.06it/s]Loading train:  81%|████████  | 230/285 [03:29<00:49,  1.12it/s]Loading train:  81%|████████  | 231/285 [03:30<00:45,  1.19it/s]Loading train:  81%|████████▏ | 232/285 [03:30<00:45,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [03:31<00:44,  1.18it/s]Loading train:  82%|████████▏ | 234/285 [03:32<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:33<00:43,  1.15it/s]Loading train:  83%|████████▎ | 236/285 [03:34<00:44,  1.09it/s]Loading train:  83%|████████▎ | 237/285 [03:35<00:43,  1.10it/s]Loading train:  84%|████████▎ | 238/285 [03:36<00:41,  1.12it/s]Loading train:  84%|████████▍ | 239/285 [03:37<00:40,  1.13it/s]Loading train:  84%|████████▍ | 240/285 [03:37<00:38,  1.18it/s]Loading train:  85%|████████▍ | 241/285 [03:38<00:35,  1.24it/s]Loading train:  85%|████████▍ | 242/285 [03:39<00:34,  1.25it/s]Loading train:  85%|████████▌ | 243/285 [03:40<00:31,  1.33it/s]Loading train:  86%|████████▌ | 244/285 [03:40<00:32,  1.27it/s]Loading train:  86%|████████▌ | 245/285 [03:41<00:31,  1.29it/s]Loading train:  86%|████████▋ | 246/285 [03:42<00:31,  1.25it/s]Loading train:  87%|████████▋ | 247/285 [03:43<00:32,  1.16it/s]Loading train:  87%|████████▋ | 248/285 [03:44<00:32,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [03:45<00:30,  1.16it/s]Loading train:  88%|████████▊ | 250/285 [03:46<00:30,  1.15it/s]Loading train:  88%|████████▊ | 251/285 [03:46<00:28,  1.20it/s]Loading train:  88%|████████▊ | 252/285 [03:47<00:26,  1.25it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:28,  1.13it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:28,  1.09it/s]Loading train:  89%|████████▉ | 255/285 [03:50<00:26,  1.12it/s]Loading train:  90%|████████▉ | 256/285 [03:51<00:24,  1.19it/s]Loading train:  90%|█████████ | 257/285 [03:52<00:22,  1.25it/s]Loading train:  91%|█████████ | 258/285 [03:52<00:22,  1.18it/s]Loading train:  91%|█████████ | 259/285 [03:53<00:22,  1.15it/s]Loading train:  91%|█████████ | 260/285 [03:54<00:20,  1.25it/s]Loading train:  92%|█████████▏| 261/285 [03:55<00:18,  1.30it/s]Loading train:  92%|█████████▏| 262/285 [03:55<00:16,  1.36it/s]Loading train:  92%|█████████▏| 263/285 [03:56<00:15,  1.42it/s]Loading train:  93%|█████████▎| 264/285 [03:57<00:16,  1.25it/s]Loading train:  93%|█████████▎| 265/285 [03:58<00:16,  1.21it/s]Loading train:  93%|█████████▎| 266/285 [03:59<00:15,  1.24it/s]Loading train:  94%|█████████▎| 267/285 [03:59<00:14,  1.28it/s]Loading train:  94%|█████████▍| 268/285 [04:00<00:13,  1.24it/s]Loading train:  94%|█████████▍| 269/285 [04:01<00:12,  1.25it/s]Loading train:  95%|█████████▍| 270/285 [04:02<00:11,  1.26it/s]Loading train:  95%|█████████▌| 271/285 [04:03<00:10,  1.28it/s]Loading train:  95%|█████████▌| 272/285 [04:03<00:10,  1.26it/s]Loading train:  96%|█████████▌| 273/285 [04:04<00:09,  1.30it/s]Loading train:  96%|█████████▌| 274/285 [04:05<00:08,  1.37it/s]Loading train:  96%|█████████▋| 275/285 [04:06<00:07,  1.27it/s]Loading train:  97%|█████████▋| 276/285 [04:07<00:07,  1.18it/s]Loading train:  97%|█████████▋| 277/285 [04:07<00:06,  1.28it/s]Loading train:  98%|█████████▊| 278/285 [04:08<00:05,  1.33it/s]Loading train:  98%|█████████▊| 279/285 [04:09<00:04,  1.27it/s]Loading train:  98%|█████████▊| 280/285 [04:10<00:03,  1.31it/s]Loading train:  99%|█████████▊| 281/285 [04:10<00:03,  1.25it/s]Loading train:  99%|█████████▉| 282/285 [04:11<00:02,  1.28it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.17it/s]Loading train: 100%|█████████▉| 284/285 [04:13<00:00,  1.11it/s]Loading train: 100%|██████████| 285/285 [04:14<00:00,  1.12it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 64.26it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:03, 74.54it/s]concatenating: train:  15%|█▌        | 44/285 [00:00<00:02, 94.16it/s]concatenating: train:  25%|██▍       | 71/285 [00:00<00:01, 116.96it/s]concatenating: train:  36%|███▌      | 102/285 [00:00<00:01, 143.41it/s]concatenating: train:  47%|████▋     | 134/285 [00:00<00:00, 171.63it/s]concatenating: train:  57%|█████▋    | 163/285 [00:00<00:00, 194.57it/s]concatenating: train:  68%|██████▊   | 193/285 [00:00<00:00, 216.88it/s]concatenating: train:  79%|███████▊  | 224/285 [00:00<00:00, 237.65it/s]concatenating: train:  90%|████████▉ | 256/285 [00:01<00:00, 256.44it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 257.51it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.17s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.18s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 781.01it/s]2019-07-11 06:05:56.022907: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:05:56.023055: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:05:56.023074: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:05:56.023084: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:05:56.024953: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.78it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.69it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.35it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.83it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.22it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.96it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.13it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.89it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  8.31it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.85it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.63it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.06it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.15it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.84it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.14it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.22it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.35it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.91it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 30)   16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 90)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 254,643
Trainable params: 79,783
Non-trainable params: 174,860
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 19s - loss: 2.6065 - acc: 0.5761 - mDice: 0.1306 - val_loss: 1.5072 - val_acc: 0.8891 - val_mDice: 0.3066

Epoch 00001: val_mDice improved from -inf to 0.30658, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.9037 - acc: 0.8878 - mDice: 0.4008 - val_loss: 1.2199 - val_acc: 0.9053 - val_mDice: 0.3742

Epoch 00002: val_mDice improved from 0.30658 to 0.37422, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6652 - acc: 0.8999 - mDice: 0.5014 - val_loss: 0.9121 - val_acc: 0.9116 - val_mDice: 0.5010

Epoch 00003: val_mDice improved from 0.37422 to 0.50096, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.5546 - acc: 0.9109 - mDice: 0.5603 - val_loss: 0.8756 - val_acc: 0.9195 - val_mDice: 0.5220

Epoch 00004: val_mDice improved from 0.50096 to 0.52204, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.5046 - acc: 0.9191 - mDice: 0.5896 - val_loss: 0.8120 - val_acc: 0.9398 - val_mDice: 0.5520

Epoch 00005: val_mDice improved from 0.52204 to 0.55195, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4713 - acc: 0.9257 - mDice: 0.6097 - val_loss: 0.8115 - val_acc: 0.9400 - val_mDice: 0.5484

Epoch 00006: val_mDice did not improve from 0.55195
Epoch 7/300
 - 13s - loss: 0.4512 - acc: 0.9314 - mDice: 0.6226 - val_loss: 0.8539 - val_acc: 0.9376 - val_mDice: 0.5480

Epoch 00007: val_mDice did not improve from 0.55195
Epoch 8/300
 - 13s - loss: 0.4334 - acc: 0.9353 - mDice: 0.6335 - val_loss: 0.8279 - val_acc: 0.9372 - val_mDice: 0.5530

Epoch 00008: val_mDice improved from 0.55195 to 0.55302, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.4191 - acc: 0.9369 - mDice: 0.6427 - val_loss: 0.8309 - val_acc: 0.9339 - val_mDice: 0.5602

Epoch 00009: val_mDice improved from 0.55302 to 0.56017, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.4118 - acc: 0.9378 - mDice: 0.6478 - val_loss: 0.8082 - val_acc: 0.9388 - val_mDice: 0.5646

Epoch 00010: val_mDice improved from 0.56017 to 0.56461, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.3981 - acc: 0.9389 - mDice: 0.6568 - val_loss: 0.8642 - val_acc: 0.9360 - val_mDice: 0.5427

Epoch 00011: val_mDice did not improve from 0.56461
Epoch 12/300
 - 13s - loss: 0.3910 - acc: 0.9395 - mDice: 0.6616 - val_loss: 0.8317 - val_acc: 0.9381 - val_mDice: 0.5652

Epoch 00012: val_mDice improved from 0.56461 to 0.56521, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 14s - loss: 0.3845 - acc: 0.9400 - mDice: 0.6659 - val_loss: 0.8260 - val_acc: 0.9393 - val_mDice: 0.5695

Epoch 00013: val_mDice improved from 0.56521 to 0.56950, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 13s - loss: 0.3750 - acc: 0.9408 - mDice: 0.6725 - val_loss: 0.8248 - val_acc: 0.9393 - val_mDice: 0.5723

Epoch 00014: val_mDice improved from 0.56950 to 0.57233, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 13s - loss: 0.3706 - acc: 0.9411 - mDice: 0.6756 - val_loss: 0.8425 - val_acc: 0.9382 - val_mDice: 0.5655

Epoch 00015: val_mDice did not improve from 0.57233
Epoch 16/300
 - 14s - loss: 0.3642 - acc: 0.9416 - mDice: 0.6800 - val_loss: 0.8309 - val_acc: 0.9383 - val_mDice: 0.5614

Epoch 00016: val_mDice did not improve from 0.57233
Epoch 17/300
 - 13s - loss: 0.3590 - acc: 0.9421 - mDice: 0.6837 - val_loss: 0.8244 - val_acc: 0.9411 - val_mDice: 0.5776

Epoch 00017: val_mDice improved from 0.57233 to 0.57760, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 13s - loss: 0.3541 - acc: 0.9425 - mDice: 0.6871 - val_loss: 0.8562 - val_acc: 0.9380 - val_mDice: 0.5604

Epoch 00018: val_mDice did not improve from 0.57760
Epoch 19/300
 - 14s - loss: 0.3489 - acc: 0.9429 - mDice: 0.6909 - val_loss: 0.8484 - val_acc: 0.9378 - val_mDice: 0.5609

Epoch 00019: val_mDice did not improve from 0.57760
Epoch 20/300
 - 13s - loss: 0.3458 - acc: 0.9431 - mDice: 0.6930 - val_loss: 0.8308 - val_acc: 0.9317 - val_mDice: 0.5499

Epoch 00020: val_mDice did not improve from 0.57760
Epoch 21/300
 - 13s - loss: 0.3435 - acc: 0.9433 - mDice: 0.6947 - val_loss: 0.8225 - val_acc: 0.9409 - val_mDice: 0.5730

Epoch 00021: val_mDice did not improve from 0.57760
Epoch 22/300
 - 13s - loss: 0.3380 - acc: 0.9437 - mDice: 0.6985 - val_loss: 0.8136 - val_acc: 0.9401 - val_mDice: 0.5769

Epoch 00022: val_mDice did not improve from 0.57760
Epoch 23/300
 - 13s - loss: 0.3391 - acc: 0.9438 - mDice: 0.6979 - val_loss: 0.8244 - val_acc: 0.9363 - val_mDice: 0.5535

Epoch 00023: val_mDice did not improve from 0.57760
Epoch 24/300
 - 13s - loss: 0.3336 - acc: 0.9442 - mDice: 0.7018 - val_loss: 0.8114 - val_acc: 0.9366 - val_mDice: 0.5542

Epoch 00024: val_mDice did not improve from 0.57760
Epoch 25/300
 - 13s - loss: 0.3299 - acc: 0.9446 - mDice: 0.7046 - val_loss: 0.8274 - val_acc: 0.9384 - val_mDice: 0.5722

Epoch 00025: val_mDice did not improve from 0.57760
Epoch 26/300
 - 12s - loss: 0.3282 - acc: 0.9448 - mDice: 0.7059 - val_loss: 0.7994 - val_acc: 0.9403 - val_mDice: 0.5686

Epoch 00026: val_mDice did not improve from 0.57760
Epoch 27/300
 - 12s - loss: 0.3249 - acc: 0.9450 - mDice: 0.7083 - val_loss: 0.8128 - val_acc: 0.9388 - val_mDice: 0.5709

Epoch 00027: val_mDice did not improve from 0.57760
Epoch 28/300
 - 13s - loss: 0.3218 - acc: 0.9451 - mDice: 0.7104 - val_loss: 0.8001 - val_acc: 0.9382 - val_mDice: 0.5748

Epoch 00028: val_mDice did not improve from 0.57760
Epoch 29/300
 - 12s - loss: 0.3205 - acc: 0.9454 - mDice: 0.7114 - val_loss: 0.8256 - val_acc: 0.9383 - val_mDice: 0.5664

Epoch 00029: val_mDice did not improve from 0.57760
Epoch 30/300
 - 12s - loss: 0.3162 - acc: 0.9456 - mDice: 0.7145 - val_loss: 0.8165 - val_acc: 0.9385 - val_mDice: 0.5582

Epoch 00030: val_mDice did not improve from 0.57760
Epoch 31/300
 - 12s - loss: 0.3148 - acc: 0.9458 - mDice: 0.7156 - val_loss: 0.7956 - val_acc: 0.9395 - val_mDice: 0.5770

Epoch 00031: val_mDice did not improve from 0.57760
Epoch 32/300
 - 12s - loss: 0.3140 - acc: 0.9457 - mDice: 0.7162 - val_loss: 0.8254 - val_acc: 0.9406 - val_mDice: 0.5709

Epoch 00032: val_mDice did not improve from 0.57760
Epoch 33/300
 - 13s - loss: 0.3108 - acc: 0.9461 - mDice: 0.7186 - val_loss: 0.8060 - val_acc: 0.9409 - val_mDice: 0.5694

Epoch 00033: val_mDice did not improve from 0.57760
Epoch 34/300
 - 13s - loss: 0.3093 - acc: 0.9463 - mDice: 0.7198 - val_loss: 0.7891 - val_acc: 0.9394 - val_mDice: 0.5636

Epoch 00034: val_mDice did not improve from 0.57760
Epoch 35/300
 - 13s - loss: 0.3077 - acc: 0.9463 - mDice: 0.7209 - val_loss: 0.8009 - val_acc: 0.9389 - val_mDice: 0.5675

Epoch 00035: val_mDice did not improve from 0.57760
Epoch 36/300
 - 13s - loss: 0.3042 - acc: 0.9466 - mDice: 0.7235 - val_loss: 0.8085 - val_acc: 0.9398 - val_mDice: 0.5666

Epoch 00036: val_mDice did not improve from 0.57760
Epoch 37/300
 - 12s - loss: 0.3034 - acc: 0.9466 - mDice: 0.7242 - val_loss: 0.8302 - val_acc: 0.9385 - val_mDice: 0.5567

Epoch 00037: val_mDice did not improve from 0.57760
Epoch 38/300
 - 12s - loss: 0.3016 - acc: 0.9469 - mDice: 0.7256 - val_loss: 0.7968 - val_acc: 0.9400 - val_mDice: 0.5767

Epoch 00038: val_mDice did not improve from 0.57760
Epoch 39/300
 - 13s - loss: 0.3013 - acc: 0.9469 - mDice: 0.7257 - val_loss: 0.8092 - val_acc: 0.9381 - val_mDice: 0.5684

Epoch 00039: val_mDice did not improve from 0.57760
Epoch 40/300
 - 12s - loss: 0.3000 - acc: 0.9469 - mDice: 0.7267 - val_loss: 0.7910 - val_acc: 0.9409 - val_mDice: 0.5732

Epoch 00040: val_mDice did not improve from 0.57760
Epoch 41/300
 - 12s - loss: 0.2980 - acc: 0.9470 - mDice: 0.7282 - val_loss: 0.7944 - val_acc: 0.9401 - val_mDice: 0.5723

Epoch 00041: val_mDice did not improve from 0.57760
Epoch 42/300
 - 12s - loss: 0.2962 - acc: 0.9473 - mDice: 0.7297 - val_loss: 0.8267 - val_acc: 0.9371 - val_mDice: 0.5624

Epoch 00042: val_mDice did not improve from 0.57760
Epoch 43/300
 - 12s - loss: 0.2952 - acc: 0.9473 - mDice: 0.7303 - val_loss: 0.8044 - val_acc: 0.9410 - val_mDice: 0.5697

Epoch 00043: val_mDice did not improve from 0.57760
Epoch 44/300
 - 12s - loss: 0.2925 - acc: 0.9475 - mDice: 0.7324 - val_loss: 0.8084 - val_acc: 0.9410 - val_mDice: 0.5669

Epoch 00044: val_mDice did not improve from 0.57760
Epoch 45/300
 - 13s - loss: 0.2919 - acc: 0.9476 - mDice: 0.7329 - val_loss: 0.7904 - val_acc: 0.9384 - val_mDice: 0.5716

Epoch 00045: val_mDice did not improve from 0.57760
Epoch 46/300
 - 12s - loss: 0.2895 - acc: 0.9477 - mDice: 0.7347 - val_loss: 0.7866 - val_acc: 0.9402 - val_mDice: 0.5730

Epoch 00046: val_mDice did not improve from 0.57760
Epoch 47/300
 - 12s - loss: 0.2897 - acc: 0.9477 - mDice: 0.7345 - val_loss: 0.7865 - val_acc: 0.9398 - val_mDice: 0.5691

Epoch 00047: val_mDice did not improve from 0.57760
Epoch 48/300
 - 12s - loss: 0.2888 - acc: 0.9477 - mDice: 0.7352 - val_loss: 0.7922 - val_acc: 0.9397 - val_mDice: 0.5638

Epoch 00048: val_mDice did not improve from 0.57760
Epoch 49/300
 - 12s - loss: 0.2878 - acc: 0.9478 - mDice: 0.7360 - val_loss: 0.7894 - val_acc: 0.9390 - val_mDice: 0.5698

Epoch 00049: val_mDice did not improve from 0.57760
Epoch 50/300
 - 12s - loss: 0.2870 - acc: 0.9480 - mDice: 0.7366 - val_loss: 0.7852 - val_acc: 0.9396 - val_mDice: 0.5671

Epoch 00050: val_mDice did not improve from 0.57760
Epoch 51/300
 - 12s - loss: 0.2836 - acc: 0.9481 - mDice: 0.7391 - val_loss: 0.7830 - val_acc: 0.9390 - val_mDice: 0.5743

Epoch 00051: val_mDice did not improve from 0.57760
Epoch 52/300
 - 12s - loss: 0.2835 - acc: 0.9483 - mDice: 0.7393 - val_loss: 0.8144 - val_acc: 0.9352 - val_mDice: 0.5419

Epoch 00052: val_mDice did not improve from 0.57760
Epoch 53/300
 - 12s - loss: 0.2827 - acc: 0.9482 - mDice: 0.7399 - val_loss: 0.8296 - val_acc: 0.9356 - val_mDice: 0.5580

Epoch 00053: val_mDice did not improve from 0.57760
Epoch 54/300
 - 12s - loss: 0.2808 - acc: 0.9485 - mDice: 0.7414 - val_loss: 0.8061 - val_acc: 0.9364 - val_mDice: 0.5576

Epoch 00054: val_mDice did not improve from 0.57760
Epoch 55/300
 - 13s - loss: 0.2812 - acc: 0.9484 - mDice: 0.7411 - val_loss: 0.7993 - val_acc: 0.9380 - val_mDice: 0.5666

Epoch 00055: val_mDice did not improve from 0.57760
Epoch 56/300
 - 12s - loss: 0.2792 - acc: 0.9485 - mDice: 0.7426 - val_loss: 0.7698 - val_acc: 0.9382 - val_mDice: 0.5642

Epoch 00056: val_mDice did not improve from 0.57760
Epoch 57/300
 - 12s - loss: 0.2788 - acc: 0.9486 - mDice: 0.7429 - val_loss: 0.7847 - val_acc: 0.9391 - val_mDice: 0.5664

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.23s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  2.00s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.80s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:28,  1.79s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:44,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:40,  1.63s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:10,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:03,  1.52s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:16,  1.57s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:24,  1.61s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:48,  1.70s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:02,  1.75s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:34,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:52,  1.73s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:36,  1.68s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:43,  1.71s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:58,  1.77s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:02,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:39,  1.72s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:38,  1.72s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:37,  1.73s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:55,  1.80s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:38,  1.74s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:41,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:29,  1.72s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:39,  1.77s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:52,  1.82s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:32,  1.75s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:30,  1.75s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:26,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:35,  1.79s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:39,  1.81s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:18,  1.73s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:14,  1.73s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:26,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:15,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:16,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:22,  1.79s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<07:05,  1.73s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<07:03,  1.73s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:51,  1.69s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:43,  1.66s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:50,  1.70s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<07:02,  1.75s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:52,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:57,  1.75s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:39,  1.68s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:54,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:48,  1.74s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<06:55,  1.78s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:41,  1.72s/it]predicting train subjects:  19%|█▊        | 53/285 [01:30<06:40,  1.73s/it]predicting train subjects:  19%|█▉        | 54/285 [01:32<06:54,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:43,  1.75s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:39,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:31,  1.72s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:37,  1.75s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:45,  1.80s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:52,  1.83s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:35,  1.76s/it]predicting train subjects:  22%|██▏       | 62/285 [01:47<06:38,  1.79s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:19,  1.72s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:21,  1.74s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:21,  1.74s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:18,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:05,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:11,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:13,  1.74s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:13,  1.75s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<06:01,  1.70s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:01,  1.71s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:01,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<05:59,  1.72s/it]predicting train subjects:  27%|██▋       | 77/285 [02:12<05:48,  1.67s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:42,  1.65s/it]predicting train subjects:  28%|██▊       | 79/285 [02:15<05:46,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:17<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:32,  1.63s/it]predicting train subjects:  29%|██▉       | 82/285 [02:20<05:33,  1.64s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:26,  1.62s/it]predicting train subjects:  29%|██▉       | 84/285 [02:23<05:18,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:25<05:28,  1.64s/it]predicting train subjects:  30%|███       | 86/285 [02:27<05:32,  1.67s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:35,  1.70s/it]predicting train subjects:  31%|███       | 88/285 [02:30<05:23,  1.64s/it]predicting train subjects:  31%|███       | 89/285 [02:32<05:28,  1.68s/it]predicting train subjects:  32%|███▏      | 90/285 [02:34<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 91/285 [02:35<05:18,  1.64s/it]predicting train subjects:  32%|███▏      | 92/285 [02:37<05:19,  1.66s/it]predicting train subjects:  33%|███▎      | 93/285 [02:38<05:13,  1.63s/it]predicting train subjects:  33%|███▎      | 94/285 [02:40<05:17,  1.66s/it]predicting train subjects:  33%|███▎      | 95/285 [02:42<05:15,  1.66s/it]predicting train subjects:  34%|███▎      | 96/285 [02:44<05:21,  1.70s/it]predicting train subjects:  34%|███▍      | 97/285 [02:45<05:21,  1.71s/it]predicting train subjects:  34%|███▍      | 98/285 [02:47<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:49<05:24,  1.74s/it]predicting train subjects:  35%|███▌      | 100/285 [02:51<05:27,  1.77s/it]predicting train subjects:  35%|███▌      | 101/285 [02:52<05:16,  1.72s/it]predicting train subjects:  36%|███▌      | 102/285 [02:54<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:56<05:02,  1.66s/it]predicting train subjects:  36%|███▋      | 104/285 [02:57<05:04,  1.68s/it]predicting train subjects:  37%|███▋      | 105/285 [02:59<05:05,  1.70s/it]predicting train subjects:  37%|███▋      | 106/285 [03:01<04:54,  1.64s/it]predicting train subjects:  38%|███▊      | 107/285 [03:02<04:59,  1.68s/it]predicting train subjects:  38%|███▊      | 108/285 [03:04<04:50,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:06<04:52,  1.66s/it]predicting train subjects:  39%|███▊      | 110/285 [03:07<04:54,  1.68s/it]predicting train subjects:  39%|███▉      | 111/285 [03:09<04:49,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:11<04:49,  1.67s/it]predicting train subjects:  40%|███▉      | 113/285 [03:12<04:50,  1.69s/it]predicting train subjects:  40%|████      | 114/285 [03:14<04:50,  1.70s/it]predicting train subjects:  40%|████      | 115/285 [03:16<04:51,  1.72s/it]predicting train subjects:  41%|████      | 116/285 [03:18<04:50,  1.72s/it]predicting train subjects:  41%|████      | 117/285 [03:19<04:39,  1.66s/it]predicting train subjects:  41%|████▏     | 118/285 [03:21<04:33,  1.64s/it]predicting train subjects:  42%|████▏     | 119/285 [03:22<04:36,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:24<04:30,  1.64s/it]predicting train subjects:  42%|████▏     | 121/285 [03:26<04:23,  1.61s/it]predicting train subjects:  43%|████▎     | 122/285 [03:27<04:14,  1.56s/it]predicting train subjects:  43%|████▎     | 123/285 [03:28<04:04,  1.51s/it]predicting train subjects:  44%|████▎     | 124/285 [03:30<04:04,  1.52s/it]predicting train subjects:  44%|████▍     | 125/285 [03:31<03:58,  1.49s/it]predicting train subjects:  44%|████▍     | 126/285 [03:33<03:54,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:34<03:48,  1.45s/it]predicting train subjects:  45%|████▍     | 128/285 [03:36<03:50,  1.47s/it]predicting train subjects:  45%|████▌     | 129/285 [03:37<03:48,  1.47s/it]predicting train subjects:  46%|████▌     | 130/285 [03:39<03:44,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:40<03:39,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [03:41<03:44,  1.47s/it]predicting train subjects:  47%|████▋     | 133/285 [03:43<03:43,  1.47s/it]predicting train subjects:  47%|████▋     | 134/285 [03:44<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:46<03:34,  1.43s/it]predicting train subjects:  48%|████▊     | 136/285 [03:47<03:30,  1.41s/it]predicting train subjects:  48%|████▊     | 137/285 [03:49<03:39,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:50<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:52<03:38,  1.50s/it]predicting train subjects:  49%|████▉     | 140/285 [03:53<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:55<03:32,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [03:56<03:27,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [03:57<03:23,  1.43s/it]predicting train subjects:  51%|█████     | 144/285 [03:59<03:24,  1.45s/it]predicting train subjects:  51%|█████     | 145/285 [04:01<03:28,  1.49s/it]predicting train subjects:  51%|█████     | 146/285 [04:02<03:29,  1.50s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:03<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:05<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:06<03:18,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:08<03:13,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:09<03:16,  1.46s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:11<03:13,  1.46s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:12<03:10,  1.44s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:14<03:13,  1.48s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:15<03:11,  1.48s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:17<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:18<03:08,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:20<03:05,  1.46s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:21<03:03,  1.46s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:22<03:02,  1.46s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:24<03:04,  1.49s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:25<03:00,  1.47s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:27<03:02,  1.50s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:28<02:57,  1.47s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:30<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:31<02:57,  1.49s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:33<02:56,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:34<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:36<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:37<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 171/285 [04:39<02:46,  1.46s/it]predicting train subjects:  60%|██████    | 172/285 [04:40<02:42,  1.44s/it]predicting train subjects:  61%|██████    | 173/285 [04:41<02:39,  1.43s/it]predicting train subjects:  61%|██████    | 174/285 [04:43<02:36,  1.41s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:44<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:46<02:44,  1.51s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:47<02:38,  1.47s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:49<02:33,  1.43s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:50<02:29,  1.41s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:52<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:53<02:39,  1.53s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:55<02:40,  1.55s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:56<02:32,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:58<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:59<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:01<02:31,  1.53s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:03<02:35,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:04<02:37,  1.63s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:06<02:27,  1.54s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:07<02:22,  1.50s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:09<02:26,  1.56s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:10<02:27,  1.59s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:12<02:18,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:13<02:13,  1.47s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:14<02:08,  1.43s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:16<02:14,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:18<02:19,  1.58s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:20<02:19,  1.61s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:21<02:10,  1.52s/it]predicting train subjects:  70%|███████   | 200/285 [05:22<02:05,  1.47s/it]predicting train subjects:  71%|███████   | 201/285 [05:24<02:10,  1.56s/it]predicting train subjects:  71%|███████   | 202/285 [05:26<02:11,  1.58s/it]predicting train subjects:  71%|███████   | 203/285 [05:27<02:13,  1.62s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:29<02:05,  1.54s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:30<02:00,  1.51s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:32<01:57,  1.49s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:33<02:04,  1.60s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:35<02:11,  1.71s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:37<02:12,  1.74s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:39<02:01,  1.62s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:40<01:56,  1.57s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:42<01:57,  1.60s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:43<01:57,  1.63s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:45<01:50,  1.56s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:47<01:54,  1.64s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:48<01:48,  1.57s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:50<01:52,  1.65s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:52<01:54,  1.71s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:54<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:55<01:46,  1.64s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:56<01:39,  1.56s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:58<01:40,  1.59s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:59<01:34,  1.53s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:01<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:02<01:27,  1.46s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:04<01:37,  1.66s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:06<01:38,  1.71s/it]predicting train subjects:  80%|████████  | 228/285 [06:08<01:40,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [06:10<01:38,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:11<01:29,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:13<01:27,  1.62s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:14<01:26,  1.63s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:16<01:20,  1.56s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:17<01:22,  1.63s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:19<01:17,  1.56s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:21<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:22<01:20,  1.68s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:24<01:19,  1.70s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:26<01:17,  1.68s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:27<01:11,  1.59s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:29<01:08,  1.56s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:30<01:05,  1.51s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:31<01:01,  1.47s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:33<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:35<01:00,  1.51s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:36<01:01,  1.58s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:38<01:01,  1.62s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:40<01:00,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:41<00:56,  1.58s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:43<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:44<00:51,  1.51s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:46<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:47<00:50,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:49<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:51<00:49,  1.66s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:52<00:46,  1.60s/it]predicting train subjects:  90%|█████████ | 257/285 [06:54<00:44,  1.59s/it]predicting train subjects:  91%|█████████ | 258/285 [06:56<00:44,  1.66s/it]predicting train subjects:  91%|█████████ | 259/285 [06:57<00:43,  1.68s/it]predicting train subjects:  91%|█████████ | 260/285 [06:59<00:39,  1.60s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:00<00:36,  1.54s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:02<00:34,  1.50s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:03<00:32,  1.47s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:05<00:33,  1.58s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:07<00:32,  1.64s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:08<00:29,  1.57s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:10<00:27,  1.55s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:11<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:13<00:26,  1.67s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:14<00:23,  1.57s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:16<00:21,  1.54s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:18<00:20,  1.58s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:19<00:18,  1.52s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:20<00:16,  1.46s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:22<00:15,  1.56s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:24<00:14,  1.66s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:25<00:12,  1.58s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:27<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:28<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:30<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:31<00:06,  1.50s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:33<00:04,  1.47s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:34<00:03,  1.55s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:36<00:01,  1.61s/it]predicting train subjects: 100%|██████████| 285/285 [07:38<00:00,  1.65s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a’: File exists

Epoch 00057: val_mDice did not improve from 0.57760
Restoring model weights from the end of the best epoch
Epoch 00057: early stopping
{'val_loss': [1.5071879900418794, 1.2199016075867872, 0.9120889810415415, 0.8756158306048467, 0.8120015080158527, 0.8114807972541223, 0.8538911778193253, 0.8278944446490362, 0.8309111686853262, 0.8081987546040461, 0.8642170612628644, 0.8316806577719175, 0.8259992530712714, 0.824759996854342, 0.8425373412095584, 0.8308960543229029, 0.8243835832063968, 0.8561959862709045, 0.848408790735098, 0.8307811778325301, 0.8224762999094449, 0.8136070210200089, 0.8244407314520615, 0.8113639446405264, 0.8274160119203421, 0.7993589777212876, 0.812780533845608, 0.8000659575829139, 0.825620738359598, 0.816483158331651, 0.7955831690476491, 0.8254166795657232, 0.8060418825883132, 0.7890735887564145, 0.8009267541078421, 0.8085423249464768, 0.8302015455869528, 0.7968236517447692, 0.8092263409724603, 0.7910414704909692, 0.7944467870088724, 0.8267364822901212, 0.8044054187261142, 0.8084148741685427, 0.7903912984407865, 0.7866489382890555, 0.7865095184399531, 0.7922126008914068, 0.7894443686191852, 0.7851756856991694, 0.7829841581674722, 0.8144410298420832, 0.8295707473388085, 0.8061420413163992, 0.7992994899933155, 0.7698421776294708, 0.7846993781053103], 'val_acc': [0.8890763612893912, 0.9053462697909429, 0.9115523283298199, 0.9194827217322129, 0.9397906064987183, 0.940000946705158, 0.9376363754272461, 0.9372041661005753, 0.9338849645394546, 0.9387620389461517, 0.9359837013941544, 0.9381194687806643, 0.9392797946929932, 0.9392566382884979, 0.938165701352633, 0.9382928220125345, 0.9411242879354037, 0.9379946268521823, 0.9378397854474875, 0.9317215062104739, 0.9408700282757099, 0.9401003282803756, 0.9363489494873927, 0.9366216797095078, 0.9383991544063275, 0.940294488118245, 0.9387527681314028, 0.938198066674746, 0.9383459710157834, 0.9385031301241654, 0.9394831909583166, 0.9406342323009784, 0.9408561403934772, 0.9394022891154656, 0.9389307407232431, 0.9397651690703172, 0.9385401216837076, 0.9400494557160598, 0.9380755126476288, 0.9408653905758491, 0.9401234457126031, 0.9371232711351835, 0.9409624567398658, 0.9409693938035232, 0.9383944914891169, 0.940169659944681, 0.9397674684341137, 0.939677343918727, 0.939039409160614, 0.9396473008852738, 0.9390463049595172, 0.9352278915735391, 0.9355769363733438, 0.9363650885912088, 0.9379530342725607, 0.9382003568685972, 0.9390578797230353], 'val_mDice': [0.3065784226816434, 0.37421960555590117, 0.5009629623248026, 0.5220447830282725, 0.5519504965497897, 0.5484182869012539, 0.5479925544216082, 0.5530160682705733, 0.5601680404864825, 0.5646120802714274, 0.5426512750295492, 0.5652058021380351, 0.5694984466983721, 0.5723311178959333, 0.5654727530020934, 0.5614400368470412, 0.5776018156455114, 0.5603524904984695, 0.5609156695696024, 0.5498747390050155, 0.5730179364864643, 0.5769393724890856, 0.5534547177644876, 0.5541692857558911, 0.5722162700616397, 0.5685866211469357, 0.5709034158633306, 0.5748098160211856, 0.5664186775684357, 0.5582018276819816, 0.5770436198665545, 0.5709420614517652, 0.5693982037214133, 0.5636180960215055, 0.5675005993017783, 0.5665751179823508, 0.556745742376034, 0.5767287892790941, 0.5684279661912185, 0.5731843841763643, 0.5723192198918416, 0.5624428827029008, 0.5697495748217289, 0.5668549789832189, 0.5715957708083667, 0.5729800823789376, 0.5691162577042213, 0.5638114941807894, 0.5698384780150193, 0.567106677362552, 0.5743072594587619, 0.5418661508995753, 0.5579991111388574, 0.5575607699843553, 0.5665891176232924, 0.5641923672877825, 0.5663583966401907], 'loss': [2.6064746565652994, 0.9036666204939686, 0.6651764829847235, 0.5545644659755481, 0.5045816042673255, 0.4713171882860491, 0.4511516156681875, 0.43342984674503077, 0.4191454672196645, 0.41178259529454414, 0.39805084230010823, 0.3910186684055763, 0.384548646260548, 0.37504923782049154, 0.37057094844210187, 0.36418205896536937, 0.3590200234523704, 0.354077951712746, 0.34889562705736654, 0.34584690148206165, 0.3435414243088562, 0.3380253382365906, 0.3390809940388092, 0.33362911197572553, 0.329857242843448, 0.32820195847965744, 0.3248730346108345, 0.32177367962276343, 0.32052941093319054, 0.31620920292348054, 0.31484498563622415, 0.31395810431058935, 0.31082678952142784, 0.30934031962809677, 0.30772614277597615, 0.304215805818924, 0.3033765802428059, 0.30155961010318216, 0.3013028367099139, 0.29999631773025953, 0.29798621261657454, 0.29616763767562404, 0.2951765790462142, 0.29247378778283933, 0.2918727377387174, 0.28947903447998613, 0.2896698386419812, 0.28875638921795366, 0.28784287350760235, 0.28696952102358664, 0.28364611941818424, 0.28352320457278807, 0.2826808023626466, 0.2807773234609373, 0.2812050063210111, 0.27917513773800384, 0.2787803140203748], 'acc': [0.5761441926113807, 0.8877604248217416, 0.8998560078423544, 0.9108620921778061, 0.9190996165624308, 0.9256712318643107, 0.9313576103993847, 0.9352868555448135, 0.9369410599640218, 0.9378346955216613, 0.9388696818095362, 0.9394665262328186, 0.9400158016749615, 0.9407983866936714, 0.9411027737014751, 0.9416106357836563, 0.9421034206117551, 0.9424909261400317, 0.9428531756581805, 0.9431403822194361, 0.9433400423601744, 0.9437369195548391, 0.9438229144405618, 0.9441792921453541, 0.9446342107467542, 0.9447746337762917, 0.9449691911866434, 0.9451006574350607, 0.9453750511855203, 0.9455500796944367, 0.9458113029347699, 0.9456887936323846, 0.9461040783552933, 0.9462820745741409, 0.9463070372830213, 0.9466348558095375, 0.946627520342919, 0.9468823146646361, 0.9468624083678968, 0.9468925597867127, 0.9470178358209405, 0.947310541626669, 0.9473044688462178, 0.9474619602427033, 0.9475899035779135, 0.947738925452867, 0.94773114233849, 0.9477452658358001, 0.9478134380751932, 0.9479673808597061, 0.9481150097681194, 0.9483120331275642, 0.9482448790375293, 0.9484664440803683, 0.9484259155055402, 0.9485463616835459, 0.9485938948568224], 'mDice': [0.13062108425164282, 0.4007629338532678, 0.5014445581944525, 0.5603203858098321, 0.5895632792693337, 0.6096685445089902, 0.6225747656670486, 0.6334936116923159, 0.6426925134210253, 0.6478084356464012, 0.6567941186536472, 0.6616000446855038, 0.6659381970657388, 0.672452209532992, 0.6755507611858991, 0.680041050631699, 0.6836782444076411, 0.6871083024945919, 0.6908549911298842, 0.692956376353896, 0.694656544875958, 0.6985375568851998, 0.6979394549319943, 0.7018069082065932, 0.704609413599051, 0.7058546728922038, 0.7082733511045214, 0.7104351362992529, 0.7113905756453532, 0.7144655419772461, 0.7155788266316866, 0.716217792865305, 0.7185668938496143, 0.7197775980164773, 0.72091483218879, 0.7235435090315229, 0.7241545458193097, 0.7255902551619602, 0.7256805629217019, 0.7267205827374482, 0.7282213565993878, 0.7296502594247269, 0.7303103653254197, 0.7323845508331018, 0.7328769505535183, 0.7347044839274561, 0.7345094537532694, 0.7352208542799604, 0.7359825352576675, 0.73662095931055, 0.7391209345808067, 0.7393087326551313, 0.7399217374626258, 0.7413783448984579, 0.7411088570835603, 0.7426051314132389, 0.7429380022840703]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:43,  1.63s/it]Loading train:   1%|          | 2/285 [00:02<07:02,  1.49s/it]Loading train:   1%|          | 3/285 [00:04<06:52,  1.46s/it]Loading train:   1%|▏         | 4/285 [00:05<06:19,  1.35s/it]Loading train:   2%|▏         | 5/285 [00:06<06:27,  1.39s/it]Loading train:   2%|▏         | 6/285 [00:08<06:38,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:09<06:59,  1.51s/it]Loading train:   3%|▎         | 8/285 [00:11<06:32,  1.42s/it]Loading train:   3%|▎         | 9/285 [00:12<06:44,  1.47s/it]Loading train:   4%|▎         | 10/285 [00:13<06:03,  1.32s/it]Loading train:   4%|▍         | 11/285 [00:14<05:13,  1.14s/it]Loading train:   4%|▍         | 12/285 [00:15<05:02,  1.11s/it]Loading train:   5%|▍         | 13/285 [00:16<04:36,  1.02s/it]Loading train:   5%|▍         | 14/285 [00:17<04:46,  1.06s/it]Loading train:   5%|▌         | 15/285 [00:18<04:38,  1.03s/it]Loading train:   6%|▌         | 16/285 [00:19<04:33,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:20<04:06,  1.09it/s]Loading train:   6%|▋         | 18/285 [00:20<03:59,  1.12it/s]Loading train:   7%|▋         | 19/285 [00:21<03:44,  1.18it/s]Loading train:   7%|▋         | 20/285 [00:22<03:44,  1.18it/s]Loading train:   7%|▋         | 21/285 [00:23<03:59,  1.10it/s]Loading train:   8%|▊         | 22/285 [00:24<03:41,  1.19it/s]Loading train:   8%|▊         | 23/285 [00:25<03:49,  1.14it/s]Loading train:   8%|▊         | 24/285 [00:25<03:41,  1.18it/s]Loading train:   9%|▉         | 25/285 [00:27<04:00,  1.08it/s]Loading train:   9%|▉         | 26/285 [00:28<04:05,  1.06it/s]Loading train:   9%|▉         | 27/285 [00:29<04:05,  1.05it/s]Loading train:  10%|▉         | 28/285 [00:30<04:44,  1.11s/it]Loading train:  10%|█         | 29/285 [00:31<04:42,  1.10s/it]Loading train:  11%|█         | 30/285 [00:32<04:37,  1.09s/it]Loading train:  11%|█         | 31/285 [00:33<04:24,  1.04s/it]Loading train:  11%|█         | 32/285 [00:34<03:59,  1.06it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:06,  1.02it/s]Loading train:  12%|█▏        | 34/285 [00:36<04:05,  1.02it/s]Loading train:  12%|█▏        | 35/285 [00:37<04:13,  1.01s/it]Loading train:  13%|█▎        | 36/285 [00:38<04:08,  1.00it/s]Loading train:  13%|█▎        | 37/285 [00:39<04:04,  1.02it/s]Loading train:  13%|█▎        | 38/285 [00:40<03:54,  1.05it/s]Loading train:  14%|█▎        | 39/285 [00:41<03:50,  1.07it/s]Loading train:  14%|█▍        | 40/285 [00:42<03:49,  1.07it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:36,  1.12it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:30,  1.15it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:29,  1.15it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:33,  1.13it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:26,  1.16it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:28,  1.15it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:25,  1.16it/s]Loading train:  17%|█▋        | 48/285 [00:48<03:26,  1.15it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:46,  1.04it/s]Loading train:  18%|█▊        | 50/285 [00:50<03:41,  1.06it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:49,  1.02it/s]Loading train:  18%|█▊        | 52/285 [00:52<03:37,  1.07it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:55,  1.02s/it]Loading train:  19%|█▉        | 54/285 [00:55<03:59,  1.03s/it]Loading train:  19%|█▉        | 55/285 [00:56<03:52,  1.01s/it]Loading train:  20%|█▉        | 56/285 [00:56<03:41,  1.03it/s]Loading train:  20%|██        | 57/285 [00:57<03:31,  1.08it/s]Loading train:  20%|██        | 58/285 [00:58<03:37,  1.04it/s]Loading train:  21%|██        | 59/285 [00:59<03:47,  1.01s/it]Loading train:  21%|██        | 60/285 [01:00<03:47,  1.01s/it]Loading train:  21%|██▏       | 61/285 [01:02<03:54,  1.05s/it]Loading train:  22%|██▏       | 62/285 [01:03<03:59,  1.07s/it]Loading train:  22%|██▏       | 63/285 [01:04<03:50,  1.04s/it]Loading train:  22%|██▏       | 64/285 [01:05<04:13,  1.15s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:30,  1.23s/it]Loading train:  23%|██▎       | 66/285 [01:08<04:32,  1.24s/it]Loading train:  24%|██▎       | 67/285 [01:09<04:14,  1.17s/it]Loading train:  24%|██▍       | 68/285 [01:10<03:55,  1.09s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:36,  1.00s/it]Loading train:  25%|██▍       | 70/285 [01:12<03:40,  1.03s/it]Loading train:  25%|██▍       | 71/285 [01:12<03:32,  1.01it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:23,  1.05it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:27,  1.02it/s]Loading train:  26%|██▌       | 74/285 [01:15<03:24,  1.03it/s]Loading train:  26%|██▋       | 75/285 [01:16<03:26,  1.02it/s]Loading train:  27%|██▋       | 76/285 [01:17<03:26,  1.01it/s]Loading train:  27%|██▋       | 77/285 [01:18<03:26,  1.01it/s]Loading train:  27%|██▋       | 78/285 [01:19<03:12,  1.07it/s]Loading train:  28%|██▊       | 79/285 [01:20<03:17,  1.04it/s]Loading train:  28%|██▊       | 80/285 [01:21<03:15,  1.05it/s]Loading train:  28%|██▊       | 81/285 [01:22<03:08,  1.08it/s]Loading train:  29%|██▉       | 82/285 [01:23<03:06,  1.09it/s]Loading train:  29%|██▉       | 83/285 [01:24<03:01,  1.12it/s]Loading train:  29%|██▉       | 84/285 [01:24<02:52,  1.17it/s]Loading train:  30%|██▉       | 85/285 [01:26<03:02,  1.10it/s]Loading train:  30%|███       | 86/285 [01:27<03:09,  1.05it/s]Loading train:  31%|███       | 87/285 [01:27<03:03,  1.08it/s]Loading train:  31%|███       | 88/285 [01:28<02:55,  1.12it/s]Loading train:  31%|███       | 89/285 [01:29<02:55,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:30<02:57,  1.10it/s]Loading train:  32%|███▏      | 91/285 [01:31<02:51,  1.13it/s]Loading train:  32%|███▏      | 92/285 [01:32<02:56,  1.09it/s]Loading train:  33%|███▎      | 93/285 [01:33<02:44,  1.17it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:44,  1.16it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:47,  1.14it/s]Loading train:  34%|███▎      | 96/285 [01:35<02:43,  1.16it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:49,  1.11it/s]Loading train:  34%|███▍      | 98/285 [01:37<02:49,  1.10it/s]Loading train:  35%|███▍      | 99/285 [01:38<02:43,  1.14it/s]Loading train:  35%|███▌      | 100/285 [01:39<02:43,  1.13it/s]Loading train:  35%|███▌      | 101/285 [01:40<02:39,  1.15it/s]Loading train:  36%|███▌      | 102/285 [01:41<02:47,  1.09it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:37,  1.16it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:36,  1.16it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:46,  1.08it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:42,  1.10it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:38,  1.13it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:32,  1.16it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:31,  1.16it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:43,  1.07it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:34,  1.13it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:35,  1.11it/s]Loading train:  40%|███▉      | 113/285 [01:50<02:36,  1.10it/s]Loading train:  40%|████      | 114/285 [01:51<02:34,  1.11it/s]Loading train:  40%|████      | 115/285 [01:52<02:32,  1.11it/s]Loading train:  41%|████      | 116/285 [01:53<02:34,  1.09it/s]Loading train:  41%|████      | 117/285 [01:54<02:31,  1.11it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:24,  1.16it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:26,  1.14it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:23,  1.15it/s]Loading train:  42%|████▏     | 121/285 [01:58<02:42,  1.01it/s]Loading train:  43%|████▎     | 122/285 [01:59<02:47,  1.03s/it]Loading train:  43%|████▎     | 123/285 [02:00<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [02:01<02:34,  1.04it/s]Loading train:  44%|████▍     | 125/285 [02:02<02:17,  1.16it/s]Loading train:  44%|████▍     | 126/285 [02:02<02:09,  1.22it/s]Loading train:  45%|████▍     | 127/285 [02:03<02:08,  1.23it/s]Loading train:  45%|████▍     | 128/285 [02:04<02:08,  1.22it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:10,  1.19it/s]Loading train:  46%|████▌     | 130/285 [02:06<02:04,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:06<02:06,  1.22it/s]Loading train:  46%|████▋     | 132/285 [02:07<02:02,  1.25it/s]Loading train:  47%|████▋     | 133/285 [02:08<01:56,  1.31it/s]Loading train:  47%|████▋     | 134/285 [02:09<01:54,  1.32it/s]Loading train:  47%|████▋     | 135/285 [02:09<01:50,  1.35it/s]Loading train:  48%|████▊     | 136/285 [02:10<01:52,  1.33it/s]Loading train:  48%|████▊     | 137/285 [02:11<01:54,  1.29it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:54,  1.28it/s]Loading train:  49%|████▉     | 139/285 [02:12<01:49,  1.33it/s]Loading train:  49%|████▉     | 140/285 [02:13<01:51,  1.30it/s]Loading train:  49%|████▉     | 141/285 [02:14<01:53,  1.27it/s]Loading train:  50%|████▉     | 142/285 [02:15<01:46,  1.34it/s]Loading train:  50%|█████     | 143/285 [02:15<01:51,  1.28it/s]Loading train:  51%|█████     | 144/285 [02:16<01:49,  1.29it/s]Loading train:  51%|█████     | 145/285 [02:17<01:52,  1.24it/s]Loading train:  51%|█████     | 146/285 [02:18<01:53,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:19<01:51,  1.23it/s]Loading train:  52%|█████▏    | 148/285 [02:20<01:50,  1.24it/s]Loading train:  52%|█████▏    | 149/285 [02:20<01:47,  1.27it/s]Loading train:  53%|█████▎    | 150/285 [02:21<01:47,  1.25it/s]Loading train:  53%|█████▎    | 151/285 [02:22<01:44,  1.28it/s]Loading train:  53%|█████▎    | 152/285 [02:23<01:45,  1.27it/s]Loading train:  54%|█████▎    | 153/285 [02:23<01:44,  1.26it/s]Loading train:  54%|█████▍    | 154/285 [02:24<01:48,  1.21it/s]Loading train:  54%|█████▍    | 155/285 [02:25<01:42,  1.27it/s]Loading train:  55%|█████▍    | 156/285 [02:26<01:42,  1.26it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:36,  1.32it/s]Loading train:  55%|█████▌    | 158/285 [02:27<01:40,  1.26it/s]Loading train:  56%|█████▌    | 159/285 [02:28<01:38,  1.28it/s]Loading train:  56%|█████▌    | 160/285 [02:29<01:40,  1.24it/s]Loading train:  56%|█████▋    | 161/285 [02:30<01:40,  1.24it/s]Loading train:  57%|█████▋    | 162/285 [02:31<01:38,  1.25it/s]Loading train:  57%|█████▋    | 163/285 [02:31<01:36,  1.26it/s]Loading train:  58%|█████▊    | 164/285 [02:32<01:36,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [02:33<01:37,  1.23it/s]Loading train:  58%|█████▊    | 166/285 [02:34<01:37,  1.22it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:36,  1.22it/s]Loading train:  59%|█████▉    | 168/285 [02:35<01:31,  1.28it/s]Loading train:  59%|█████▉    | 169/285 [02:36<01:28,  1.31it/s]Loading train:  60%|█████▉    | 170/285 [02:37<01:25,  1.35it/s]Loading train:  60%|██████    | 171/285 [02:38<01:25,  1.33it/s]Loading train:  60%|██████    | 172/285 [02:38<01:23,  1.35it/s]Loading train:  61%|██████    | 173/285 [02:39<01:23,  1.34it/s]Loading train:  61%|██████    | 174/285 [02:40<01:26,  1.29it/s]Loading train:  61%|██████▏   | 175/285 [02:41<01:24,  1.30it/s]Loading train:  62%|██████▏   | 176/285 [02:41<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:42<01:23,  1.29it/s]Loading train:  62%|██████▏   | 178/285 [02:43<01:27,  1.23it/s]Loading train:  63%|██████▎   | 179/285 [02:44<01:26,  1.23it/s]Loading train:  63%|██████▎   | 180/285 [02:45<01:34,  1.11it/s]Loading train:  64%|██████▎   | 181/285 [02:46<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [02:47<01:27,  1.17it/s]Loading train:  64%|██████▍   | 183/285 [02:47<01:21,  1.25it/s]Loading train:  65%|██████▍   | 184/285 [02:48<01:17,  1.30it/s]Loading train:  65%|██████▍   | 185/285 [02:49<01:17,  1.29it/s]Loading train:  65%|██████▌   | 186/285 [02:50<01:23,  1.18it/s]Loading train:  66%|██████▌   | 187/285 [02:51<01:24,  1.16it/s]Loading train:  66%|██████▌   | 188/285 [02:52<01:29,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [02:52<01:22,  1.17it/s]Loading train:  67%|██████▋   | 190/285 [02:53<01:20,  1.18it/s]Loading train:  67%|██████▋   | 191/285 [02:54<01:17,  1.21it/s]Loading train:  67%|██████▋   | 192/285 [02:55<01:26,  1.08it/s]Loading train:  68%|██████▊   | 193/285 [02:56<01:20,  1.15it/s]Loading train:  68%|██████▊   | 194/285 [02:57<01:17,  1.17it/s]Loading train:  68%|██████▊   | 195/285 [02:58<01:15,  1.20it/s]Loading train:  69%|██████▉   | 196/285 [02:59<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:00<01:22,  1.07it/s]Loading train:  69%|██████▉   | 198/285 [03:01<01:23,  1.04it/s]Loading train:  70%|██████▉   | 199/285 [03:01<01:14,  1.16it/s]Loading train:  70%|███████   | 200/285 [03:02<01:08,  1.24it/s]Loading train:  71%|███████   | 201/285 [03:03<01:12,  1.16it/s]Loading train:  71%|███████   | 202/285 [03:04<01:14,  1.12it/s]Loading train:  71%|███████   | 203/285 [03:05<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:06<01:07,  1.20it/s]Loading train:  72%|███████▏  | 205/285 [03:06<01:03,  1.26it/s]Loading train:  72%|███████▏  | 206/285 [03:07<01:00,  1.30it/s]Loading train:  73%|███████▎  | 207/285 [03:08<01:04,  1.22it/s]Loading train:  73%|███████▎  | 208/285 [03:09<01:06,  1.16it/s]Loading train:  73%|███████▎  | 209/285 [03:10<01:06,  1.15it/s]Loading train:  74%|███████▎  | 210/285 [03:11<01:03,  1.18it/s]Loading train:  74%|███████▍  | 211/285 [03:11<01:00,  1.22it/s]Loading train:  74%|███████▍  | 212/285 [03:12<00:59,  1.23it/s]Loading train:  75%|███████▍  | 213/285 [03:13<00:56,  1.27it/s]Loading train:  75%|███████▌  | 214/285 [03:14<00:55,  1.28it/s]Loading train:  75%|███████▌  | 215/285 [03:15<00:58,  1.20it/s]Loading train:  76%|███████▌  | 216/285 [03:15<00:55,  1.24it/s]Loading train:  76%|███████▌  | 217/285 [03:16<00:57,  1.18it/s]Loading train:  76%|███████▋  | 218/285 [03:17<00:58,  1.14it/s]Loading train:  77%|███████▋  | 219/285 [03:18<01:01,  1.08it/s]Loading train:  77%|███████▋  | 220/285 [03:19<00:56,  1.15it/s]Loading train:  78%|███████▊  | 221/285 [03:20<00:51,  1.23it/s]Loading train:  78%|███████▊  | 222/285 [03:20<00:50,  1.25it/s]Loading train:  78%|███████▊  | 223/285 [03:21<00:48,  1.28it/s]Loading train:  79%|███████▊  | 224/285 [03:22<00:47,  1.30it/s]Loading train:  79%|███████▉  | 225/285 [03:23<00:45,  1.33it/s]Loading train:  79%|███████▉  | 226/285 [03:24<00:49,  1.20it/s]Loading train:  80%|███████▉  | 227/285 [03:24<00:48,  1.19it/s]Loading train:  80%|████████  | 228/285 [03:25<00:48,  1.17it/s]Loading train:  80%|████████  | 229/285 [03:26<00:47,  1.19it/s]Loading train:  81%|████████  | 230/285 [03:27<00:45,  1.20it/s]Loading train:  81%|████████  | 231/285 [03:28<00:43,  1.25it/s]Loading train:  81%|████████▏ | 232/285 [03:28<00:40,  1.31it/s]Loading train:  82%|████████▏ | 233/285 [03:29<00:38,  1.34it/s]Loading train:  82%|████████▏ | 234/285 [03:30<00:40,  1.25it/s]Loading train:  82%|████████▏ | 235/285 [03:31<00:41,  1.21it/s]Loading train:  83%|████████▎ | 236/285 [03:32<00:40,  1.20it/s]Loading train:  83%|████████▎ | 237/285 [03:33<00:42,  1.13it/s]Loading train:  84%|████████▎ | 238/285 [03:34<00:42,  1.12it/s]Loading train:  84%|████████▍ | 239/285 [03:35<00:41,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:35<00:38,  1.17it/s]Loading train:  85%|████████▍ | 241/285 [03:36<00:38,  1.13it/s]Loading train:  85%|████████▍ | 242/285 [03:37<00:36,  1.18it/s]Loading train:  85%|████████▌ | 243/285 [03:38<00:36,  1.16it/s]Loading train:  86%|████████▌ | 244/285 [03:39<00:37,  1.09it/s]Loading train:  86%|████████▌ | 245/285 [03:40<00:34,  1.16it/s]Loading train:  86%|████████▋ | 246/285 [03:41<00:35,  1.10it/s]Loading train:  87%|████████▋ | 247/285 [03:42<00:35,  1.06it/s]Loading train:  87%|████████▋ | 248/285 [03:43<00:33,  1.12it/s]Loading train:  87%|████████▋ | 249/285 [03:43<00:30,  1.19it/s]Loading train:  88%|████████▊ | 250/285 [03:44<00:28,  1.22it/s]Loading train:  88%|████████▊ | 251/285 [03:45<00:26,  1.29it/s]Loading train:  88%|████████▊ | 252/285 [03:45<00:25,  1.30it/s]Loading train:  89%|████████▉ | 253/285 [03:46<00:26,  1.21it/s]Loading train:  89%|████████▉ | 254/285 [03:47<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [03:48<00:27,  1.10it/s]Loading train:  90%|████████▉ | 256/285 [03:49<00:25,  1.12it/s]Loading train:  90%|█████████ | 257/285 [03:50<00:23,  1.19it/s]Loading train:  91%|█████████ | 258/285 [03:51<00:23,  1.14it/s]Loading train:  91%|█████████ | 259/285 [03:52<00:22,  1.17it/s]Loading train:  91%|█████████ | 260/285 [03:52<00:20,  1.22it/s]Loading train:  92%|█████████▏| 261/285 [03:53<00:19,  1.24it/s]Loading train:  92%|█████████▏| 262/285 [03:54<00:17,  1.30it/s]Loading train:  92%|█████████▏| 263/285 [03:55<00:16,  1.30it/s]Loading train:  93%|█████████▎| 264/285 [03:56<00:17,  1.20it/s]Loading train:  93%|█████████▎| 265/285 [03:57<00:17,  1.14it/s]Loading train:  93%|█████████▎| 266/285 [03:57<00:16,  1.18it/s]Loading train:  94%|█████████▎| 267/285 [03:58<00:14,  1.23it/s]Loading train:  94%|█████████▍| 268/285 [03:59<00:14,  1.20it/s]Loading train:  94%|█████████▍| 269/285 [04:00<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [04:01<00:12,  1.24it/s]Loading train:  95%|█████████▌| 271/285 [04:01<00:10,  1.28it/s]Loading train:  95%|█████████▌| 272/285 [04:02<00:10,  1.19it/s]Loading train:  96%|█████████▌| 273/285 [04:03<00:09,  1.20it/s]Loading train:  96%|█████████▌| 274/285 [04:04<00:08,  1.27it/s]Loading train:  96%|█████████▋| 275/285 [04:05<00:08,  1.23it/s]Loading train:  97%|█████████▋| 276/285 [04:06<00:07,  1.13it/s]Loading train:  97%|█████████▋| 277/285 [04:06<00:06,  1.19it/s]Loading train:  98%|█████████▊| 278/285 [04:07<00:05,  1.20it/s]Loading train:  98%|█████████▊| 279/285 [04:08<00:05,  1.17it/s]Loading train:  98%|█████████▊| 280/285 [04:09<00:04,  1.21it/s]Loading train:  99%|█████████▊| 281/285 [04:10<00:03,  1.20it/s]Loading train:  99%|█████████▉| 282/285 [04:11<00:02,  1.24it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.16it/s]Loading train: 100%|█████████▉| 284/285 [04:12<00:00,  1.15it/s]Loading train: 100%|██████████| 285/285 [04:13<00:00,  1.13it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 116.13it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:01, 140.31it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:01, 163.38it/s]concatenating: train:  35%|███▍      | 99/285 [00:00<00:00, 189.90it/s]concatenating: train:  43%|████▎     | 123/285 [00:00<00:00, 202.22it/s]concatenating: train:  56%|█████▌    | 159/285 [00:00<00:00, 232.70it/s]concatenating: train:  68%|██████▊   | 195/285 [00:00<00:00, 259.66it/s]concatenating: train:  81%|████████▏ | 232/285 [00:00<00:00, 284.49it/s]concatenating: train:  94%|█████████▍| 269/285 [00:00<00:00, 302.99it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 296.06it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.19s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.20s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.12s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 706.27it/s]2019-07-11 06:30:53.226277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:30:53.226374: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:30:53.226390: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:30:53.226400: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:30:53.226833: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.53it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.37it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.03it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.49it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.69it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.43it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.74it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.46it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.42it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.14it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.73it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.12it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.40it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.64it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.18it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.37it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.55it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.70it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.43it/s] False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 40)   16240       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 85)   0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_8[0][0]              
==================================================================================================
Total params: 163,958
Trainable params: 65,258
Non-trainable params: 98,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 19s - loss: 2.5438 - acc: 0.5906 - mDice: 0.1429 - val_loss: 1.7371 - val_acc: 0.9181 - val_mDice: 0.3319

Epoch 00001: val_mDice improved from -inf to 0.33187, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.6963 - acc: 0.8899 - mDice: 0.4884 - val_loss: 1.2609 - val_acc: 0.9172 - val_mDice: 0.4506

Epoch 00002: val_mDice improved from 0.33187 to 0.45061, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.5134 - acc: 0.8978 - mDice: 0.5838 - val_loss: 1.2731 - val_acc: 0.9192 - val_mDice: 0.4263

Epoch 00003: val_mDice did not improve from 0.45061
Epoch 4/300
 - 12s - loss: 0.4630 - acc: 0.9049 - mDice: 0.6153 - val_loss: 0.9671 - val_acc: 0.9427 - val_mDice: 0.5918

Epoch 00004: val_mDice improved from 0.45061 to 0.59179, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 12s - loss: 0.4391 - acc: 0.9100 - mDice: 0.6309 - val_loss: 1.0133 - val_acc: 0.9409 - val_mDice: 0.5623

Epoch 00005: val_mDice did not improve from 0.59179
Epoch 6/300
 - 12s - loss: 0.4243 - acc: 0.9170 - mDice: 0.6407 - val_loss: 1.0113 - val_acc: 0.9438 - val_mDice: 0.5607

Epoch 00006: val_mDice did not improve from 0.59179
Epoch 7/300
 - 12s - loss: 0.4119 - acc: 0.9245 - mDice: 0.6489 - val_loss: 1.0081 - val_acc: 0.9445 - val_mDice: 0.5609

Epoch 00007: val_mDice did not improve from 0.59179
Epoch 8/300
 - 13s - loss: 0.4023 - acc: 0.9307 - mDice: 0.6546 - val_loss: 0.9563 - val_acc: 0.9369 - val_mDice: 0.5830

Epoch 00008: val_mDice did not improve from 0.59179
Epoch 9/300
 - 12s - loss: 0.3910 - acc: 0.9336 - mDice: 0.6619 - val_loss: 0.9634 - val_acc: 0.9443 - val_mDice: 0.5836

Epoch 00009: val_mDice did not improve from 0.59179
Epoch 10/300
 - 13s - loss: 0.3818 - acc: 0.9350 - mDice: 0.6683 - val_loss: 0.9637 - val_acc: 0.9430 - val_mDice: 0.5753

Epoch 00010: val_mDice did not improve from 0.59179
Epoch 11/300
 - 13s - loss: 0.3771 - acc: 0.9356 - mDice: 0.6713 - val_loss: 0.9301 - val_acc: 0.9453 - val_mDice: 0.5939

Epoch 00011: val_mDice improved from 0.59179 to 0.59388, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 12s - loss: 0.3736 - acc: 0.9363 - mDice: 0.6738 - val_loss: 0.9611 - val_acc: 0.9387 - val_mDice: 0.5749

Epoch 00012: val_mDice did not improve from 0.59388
Epoch 13/300
 - 13s - loss: 0.3658 - acc: 0.9375 - mDice: 0.6792 - val_loss: 0.9552 - val_acc: 0.9485 - val_mDice: 0.5857

Epoch 00013: val_mDice did not improve from 0.59388
Epoch 14/300
 - 12s - loss: 0.3611 - acc: 0.9380 - mDice: 0.6825 - val_loss: 0.9673 - val_acc: 0.9391 - val_mDice: 0.5666

Epoch 00014: val_mDice did not improve from 0.59388
Epoch 15/300
 - 13s - loss: 0.3577 - acc: 0.9382 - mDice: 0.6848 - val_loss: 0.9069 - val_acc: 0.9438 - val_mDice: 0.5922

Epoch 00015: val_mDice did not improve from 0.59388
Epoch 16/300
 - 13s - loss: 0.3531 - acc: 0.9387 - mDice: 0.6880 - val_loss: 0.9397 - val_acc: 0.9403 - val_mDice: 0.5837

Epoch 00016: val_mDice did not improve from 0.59388
Epoch 17/300
 - 13s - loss: 0.3515 - acc: 0.9389 - mDice: 0.6892 - val_loss: 0.9782 - val_acc: 0.9471 - val_mDice: 0.5587

Epoch 00017: val_mDice did not improve from 0.59388
Epoch 18/300
 - 13s - loss: 0.3457 - acc: 0.9396 - mDice: 0.6933 - val_loss: 0.9082 - val_acc: 0.9459 - val_mDice: 0.5933

Epoch 00018: val_mDice did not improve from 0.59388
Epoch 19/300
 - 13s - loss: 0.3440 - acc: 0.9398 - mDice: 0.6944 - val_loss: 0.9299 - val_acc: 0.9414 - val_mDice: 0.5814

Epoch 00019: val_mDice did not improve from 0.59388
Epoch 20/300
 - 13s - loss: 0.3402 - acc: 0.9402 - mDice: 0.6973 - val_loss: 0.9305 - val_acc: 0.9479 - val_mDice: 0.5864

Epoch 00020: val_mDice did not improve from 0.59388
Epoch 21/300
 - 13s - loss: 0.3371 - acc: 0.9403 - mDice: 0.6994 - val_loss: 0.9149 - val_acc: 0.9465 - val_mDice: 0.5822

Epoch 00021: val_mDice did not improve from 0.59388
Epoch 22/300
 - 13s - loss: 0.3348 - acc: 0.9407 - mDice: 0.7010 - val_loss: 0.9630 - val_acc: 0.9446 - val_mDice: 0.5364

Epoch 00022: val_mDice did not improve from 0.59388
Epoch 23/300
 - 13s - loss: 0.3321 - acc: 0.9408 - mDice: 0.7029 - val_loss: 0.9307 - val_acc: 0.9460 - val_mDice: 0.5773

Epoch 00023: val_mDice did not improve from 0.59388
Epoch 24/300
 - 13s - loss: 0.3305 - acc: 0.9410 - mDice: 0.7042 - val_loss: 0.9123 - val_acc: 0.9456 - val_mDice: 0.5757

Epoch 00024: val_mDice did not improve from 0.59388
Epoch 25/300
 - 13s - loss: 0.3311 - acc: 0.9410 - mDice: 0.7038 - val_loss: 0.8985 - val_acc: 0.9378 - val_mDice: 0.5685

Epoch 00025: val_mDice did not improve from 0.59388
Epoch 26/300
 - 13s - loss: 0.3259 - acc: 0.9415 - mDice: 0.7074 - val_loss: 0.8822 - val_acc: 0.9475 - val_mDice: 0.5874

Epoch 00026: val_mDice did not improve from 0.59388
Epoch 27/300
 - 13s - loss: 0.3243 - acc: 0.9418 - mDice: 0.7087 - val_loss: 0.8811 - val_acc: 0.9433 - val_mDice: 0.5751

Epoch 00027: val_mDice did not improve from 0.59388
Epoch 28/300
 - 13s - loss: 0.3236 - acc: 0.9417 - mDice: 0.7092 - val_loss: 0.9396 - val_acc: 0.9454 - val_mDice: 0.5707

Epoch 00028: val_mDice did not improve from 0.59388
Epoch 29/300
 - 12s - loss: 0.3224 - acc: 0.9416 - mDice: 0.7100 - val_loss: 0.9471 - val_acc: 0.9458 - val_mDice: 0.5542

Epoch 00029: val_mDice did not improve from 0.59388
Epoch 30/300
 - 12s - loss: 0.3197 - acc: 0.9421 - mDice: 0.7121 - val_loss: 0.9522 - val_acc: 0.9464 - val_mDice: 0.5456

Epoch 00030: val_mDice did not improve from 0.59388
Epoch 31/300
 - 13s - loss: 0.3193 - acc: 0.9422 - mDice: 0.7123 - val_loss: 0.8820 - val_acc: 0.9482 - val_mDice: 0.5862

Epoch 00031: val_mDice did not improve from 0.59388
Epoch 32/300
 - 12s - loss: 0.3172 - acc: 0.9425 - mDice: 0.7139 - val_loss: 0.8793 - val_acc: 0.9443 - val_mDice: 0.5751

Epoch 00032: val_mDice did not improve from 0.59388
Epoch 33/300
 - 12s - loss: 0.3152 - acc: 0.9426 - mDice: 0.7154 - val_loss: 0.8925 - val_acc: 0.9468 - val_mDice: 0.5750

Epoch 00033: val_mDice did not improve from 0.59388
Epoch 34/300
 - 12s - loss: 0.3126 - acc: 0.9429 - mDice: 0.7173 - val_loss: 0.8785 - val_acc: 0.9460 - val_mDice: 0.5741

Epoch 00034: val_mDice did not improve from 0.59388
Epoch 35/300
 - 12s - loss: 0.3116 - acc: 0.9429 - mDice: 0.7180 - val_loss: 0.9262 - val_acc: 0.9459 - val_mDice: 0.5607

Epoch 00035: val_mDice did not improve from 0.59388
Epoch 36/300
 - 12s - loss: 0.3108 - acc: 0.9431 - mDice: 0.7187 - val_loss: 0.8527 - val_acc: 0.9445 - val_mDice: 0.5798

Epoch 00036: val_mDice did not improve from 0.59388
Epoch 37/300
 - 12s - loss: 0.3085 - acc: 0.9431 - mDice: 0.7203 - val_loss: 0.8614 - val_acc: 0.9462 - val_mDice: 0.5770

Epoch 00037: val_mDice did not improve from 0.59388
Epoch 38/300
 - 12s - loss: 0.3091 - acc: 0.9430 - mDice: 0.7198 - val_loss: 0.8991 - val_acc: 0.9458 - val_mDice: 0.5451

Epoch 00038: val_mDice did not improve from 0.59388
Epoch 39/300
 - 12s - loss: 0.3085 - acc: 0.9432 - mDice: 0.7203 - val_loss: 0.8609 - val_acc: 0.9475 - val_mDice: 0.5723

Epoch 00039: val_mDice did not improve from 0.59388
Epoch 40/300
 - 12s - loss: 0.3059 - acc: 0.9435 - mDice: 0.7223 - val_loss: 0.8334 - val_acc: 0.9480 - val_mDice: 0.5928

Epoch 00040: val_mDice did not improve from 0.59388
Epoch 41/300
 - 12s - loss: 0.3043 - acc: 0.9435 - mDice: 0.7235 - val_loss: 0.8441 - val_acc: 0.9461 - val_mDice: 0.5808

Epoch 00041: val_mDice did not improve from 0.59388
Epoch 42/300
 - 12s - loss: 0.3025 - acc: 0.9438 - mDice: 0.7248 - val_loss: 0.8346 - val_acc: 0.9468 - val_mDice: 0.5769

Epoch 00042: val_mDice did not improve from 0.59388
Epoch 43/300
 - 12s - loss: 0.3046 - acc: 0.9436 - mDice: 0.7233 - val_loss: 0.8181 - val_acc: 0.9453 - val_mDice: 0.5864

Epoch 00043: val_mDice did not improve from 0.59388
Epoch 44/300
 - 12s - loss: 0.3002 - acc: 0.9438 - mDice: 0.7266 - val_loss: 0.8451 - val_acc: 0.9467 - val_mDice: 0.5547

Epoch 00044: val_mDice did not improve from 0.59388
Epoch 45/300
 - 12s - loss: 0.3017 - acc: 0.9438 - mDice: 0.7255 - val_loss: 0.8208 - val_acc: 0.9457 - val_mDice: 0.5779

Epoch 00045: val_mDice did not improve from 0.59388
Epoch 46/300
 - 12s - loss: 0.2994 - acc: 0.9440 - mDice: 0.7271 - val_loss: 0.8495 - val_acc: 0.9439 - val_mDice: 0.5768

Epoch 00046: val_mDice did not improve from 0.59388
Epoch 47/300
 - 12s - loss: 0.2967 - acc: 0.9442 - mDice: 0.7293 - val_loss: 0.7881 - val_acc: 0.9473 - val_mDice: 0.5922

Epoch 00047: val_mDice did not improve from 0.59388
Epoch 48/300
 - 13s - loss: 0.2971 - acc: 0.9443 - mDice: 0.7289 - val_loss: 0.8341 - val_acc: 0.9426 - val_mDice: 0.5712

Epoch 00048: val_mDice did not improve from 0.59388
Epoch 49/300
 - 12s - loss: 0.2958 - acc: 0.9444 - mDice: 0.7298 - val_loss: 0.7540 - val_acc: 0.9469 - val_mDice: 0.5876

Epoch 00049: val_mDice did not improve from 0.59388
Epoch 50/300
 - 12s - loss: 0.2947 - acc: 0.9443 - mDice: 0.7308 - val_loss: 0.8271 - val_acc: 0.9472 - val_mDice: 0.5701

Epoch 00050: val_mDice did not improve from 0.59388
Epoch 51/300
 - 12s - loss: 0.2944 - acc: 0.9445 - mDice: 0.7310 - val_loss: 0.7584 - val_acc: 0.9465 - val_mDice: 0.5838

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.39s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.10s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.88s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:23,  1.77s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:44,  1.64s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:41,  1.64s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:15,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:21,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:48,  1.69s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:40,  1.66s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<08:13,  1.79s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:17,  1.81s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:52,  1.73s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:08,  1.79s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:40,  1.69s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:49,  1.73s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<08:03,  1.79s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:10,  1.83s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:44,  1.73s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:47,  1.75s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:34,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<07:51,  1.79s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:27,  1.70s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:35,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:19,  1.68s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:33,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:45,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:20,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:48<07:26,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:26,  1.74s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:34,  1.78s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:42,  1.82s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:15,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:22,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:28,  1.79s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:31,  1.81s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:13,  1.74s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:13,  1.75s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:20,  1.78s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<07:03,  1.72s/it]predicting train subjects:  14%|█▍        | 40/285 [01:09<07:09,  1.75s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:53,  1.70s/it]predicting train subjects:  15%|█▍        | 42/285 [01:12<06:49,  1.68s/it]predicting train subjects:  15%|█▌        | 43/285 [01:14<06:57,  1.73s/it]predicting train subjects:  15%|█▌        | 44/285 [01:16<07:12,  1.79s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:52,  1.72s/it]predicting train subjects:  16%|█▌        | 46/285 [01:19<07:05,  1.78s/it]predicting train subjects:  16%|█▋        | 47/285 [01:21<06:49,  1.72s/it]predicting train subjects:  17%|█▋        | 48/285 [01:23<06:56,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:25<07:09,  1.82s/it]predicting train subjects:  18%|█▊        | 50/285 [01:26<07:05,  1.81s/it]predicting train subjects:  18%|█▊        | 51/285 [01:28<07:15,  1.86s/it]predicting train subjects:  18%|█▊        | 52/285 [01:30<06:50,  1.76s/it]predicting train subjects:  19%|█▊        | 53/285 [01:32<06:48,  1.76s/it]predicting train subjects:  19%|█▉        | 54/285 [01:34<07:00,  1.82s/it]predicting train subjects:  19%|█▉        | 55/285 [01:35<06:40,  1.74s/it]predicting train subjects:  20%|█▉        | 56/285 [01:37<06:48,  1.78s/it]predicting train subjects:  20%|██        | 57/285 [01:39<06:30,  1.71s/it]predicting train subjects:  20%|██        | 58/285 [01:40<06:29,  1.72s/it]predicting train subjects:  21%|██        | 59/285 [01:42<06:48,  1.81s/it]predicting train subjects:  21%|██        | 60/285 [01:44<06:57,  1.86s/it]predicting train subjects:  21%|██▏       | 61/285 [01:46<06:36,  1.77s/it]predicting train subjects:  22%|██▏       | 62/285 [01:48<06:37,  1.78s/it]predicting train subjects:  22%|██▏       | 63/285 [01:49<06:36,  1.79s/it]predicting train subjects:  22%|██▏       | 64/285 [01:51<06:24,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:53<06:26,  1.76s/it]predicting train subjects:  23%|██▎       | 66/285 [01:55<06:26,  1.76s/it]predicting train subjects:  24%|██▎       | 67/285 [01:56<06:27,  1.78s/it]predicting train subjects:  24%|██▍       | 68/285 [01:58<06:10,  1.71s/it]predicting train subjects:  24%|██▍       | 69/285 [02:00<06:10,  1.72s/it]predicting train subjects:  25%|██▍       | 70/285 [02:02<06:16,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:04<06:24,  1.80s/it]predicting train subjects:  25%|██▌       | 72/285 [02:05<06:05,  1.72s/it]predicting train subjects:  26%|██▌       | 73/285 [02:07<06:04,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:08<06:02,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:10<06:07,  1.75s/it]predicting train subjects:  27%|██▋       | 76/285 [02:12<06:12,  1.78s/it]predicting train subjects:  27%|██▋       | 77/285 [02:14<05:58,  1.72s/it]predicting train subjects:  27%|██▋       | 78/285 [02:15<05:47,  1.68s/it]predicting train subjects:  28%|██▊       | 79/285 [02:17<05:51,  1.71s/it]predicting train subjects:  28%|██▊       | 80/285 [02:19<05:51,  1.72s/it]predicting train subjects:  28%|██▊       | 81/285 [02:21<05:48,  1.71s/it]predicting train subjects:  29%|██▉       | 82/285 [02:22<05:51,  1.73s/it]predicting train subjects:  29%|██▉       | 83/285 [02:24<05:42,  1.70s/it]predicting train subjects:  29%|██▉       | 84/285 [02:26<05:34,  1.67s/it]predicting train subjects:  30%|██▉       | 85/285 [02:27<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:29<05:43,  1.73s/it]predicting train subjects:  31%|███       | 87/285 [02:31<05:49,  1.76s/it]predicting train subjects:  31%|███       | 88/285 [02:33<05:38,  1.72s/it]predicting train subjects:  31%|███       | 89/285 [02:34<05:38,  1.72s/it]predicting train subjects:  32%|███▏      | 90/285 [02:36<05:41,  1.75s/it]predicting train subjects:  32%|███▏      | 91/285 [02:38<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:40<05:35,  1.74s/it]predicting train subjects:  33%|███▎      | 93/285 [02:41<05:28,  1.71s/it]predicting train subjects:  33%|███▎      | 94/285 [02:43<05:28,  1.72s/it]predicting train subjects:  33%|███▎      | 95/285 [02:45<05:33,  1.75s/it]predicting train subjects:  34%|███▎      | 96/285 [02:47<05:32,  1.76s/it]predicting train subjects:  34%|███▍      | 97/285 [02:48<05:27,  1.74s/it]predicting train subjects:  34%|███▍      | 98/285 [02:50<05:26,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:52<05:25,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:54<05:31,  1.79s/it]predicting train subjects:  35%|███▌      | 101/285 [02:55<05:20,  1.74s/it]predicting train subjects:  36%|███▌      | 102/285 [02:57<05:25,  1.78s/it]predicting train subjects:  36%|███▌      | 103/285 [02:59<05:12,  1.72s/it]predicting train subjects:  36%|███▋      | 104/285 [03:00<05:07,  1.70s/it]predicting train subjects:  37%|███▋      | 105/285 [03:02<05:13,  1.74s/it]predicting train subjects:  37%|███▋      | 106/285 [03:04<05:07,  1.72s/it]predicting train subjects:  38%|███▊      | 107/285 [03:06<05:09,  1.74s/it]predicting train subjects:  38%|███▊      | 108/285 [03:07<05:00,  1.70s/it]predicting train subjects:  38%|███▊      | 109/285 [03:09<04:59,  1.70s/it]predicting train subjects:  39%|███▊      | 110/285 [03:11<05:07,  1.76s/it]predicting train subjects:  39%|███▉      | 111/285 [03:12<05:00,  1.73s/it]predicting train subjects:  39%|███▉      | 112/285 [03:14<04:58,  1.73s/it]predicting train subjects:  40%|███▉      | 113/285 [03:16<05:00,  1.75s/it]predicting train subjects:  40%|████      | 114/285 [03:18<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:20<05:00,  1.77s/it]predicting train subjects:  41%|████      | 116/285 [03:21<04:59,  1.77s/it]predicting train subjects:  41%|████      | 117/285 [03:23<04:47,  1.71s/it]predicting train subjects:  41%|████▏     | 118/285 [03:24<04:37,  1.66s/it]predicting train subjects:  42%|████▏     | 119/285 [03:26<04:44,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:28<04:38,  1.69s/it]predicting train subjects:  42%|████▏     | 121/285 [03:29<04:28,  1.64s/it]predicting train subjects:  43%|████▎     | 122/285 [03:31<04:18,  1.59s/it]predicting train subjects:  43%|████▎     | 123/285 [03:32<04:06,  1.52s/it]predicting train subjects:  44%|████▎     | 124/285 [03:34<04:07,  1.53s/it]predicting train subjects:  44%|████▍     | 125/285 [03:35<04:01,  1.51s/it]predicting train subjects:  44%|████▍     | 126/285 [03:37<03:54,  1.47s/it]predicting train subjects:  45%|████▍     | 127/285 [03:38<03:48,  1.44s/it]predicting train subjects:  45%|████▍     | 128/285 [03:40<03:54,  1.49s/it]predicting train subjects:  45%|████▌     | 129/285 [03:41<03:48,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:42<03:41,  1.43s/it]predicting train subjects:  46%|████▌     | 131/285 [03:44<03:39,  1.42s/it]predicting train subjects:  46%|████▋     | 132/285 [03:45<03:48,  1.49s/it]predicting train subjects:  47%|████▋     | 133/285 [03:47<03:43,  1.47s/it]predicting train subjects:  47%|████▋     | 134/285 [03:48<03:38,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:50<03:35,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:51<03:33,  1.43s/it]predicting train subjects:  48%|████▊     | 137/285 [03:53<03:38,  1.47s/it]predicting train subjects:  48%|████▊     | 138/285 [03:54<03:31,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [03:56<03:34,  1.47s/it]predicting train subjects:  49%|████▉     | 140/285 [03:57<03:37,  1.50s/it]predicting train subjects:  49%|████▉     | 141/285 [03:59<03:30,  1.46s/it]predicting train subjects:  50%|████▉     | 142/285 [04:00<03:26,  1.44s/it]predicting train subjects:  50%|█████     | 143/285 [04:01<03:22,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [04:03<03:25,  1.46s/it]predicting train subjects:  51%|█████     | 145/285 [04:04<03:22,  1.44s/it]predicting train subjects:  51%|█████     | 146/285 [04:06<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:07<03:17,  1.43s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:09<03:19,  1.46s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:10<03:13,  1.43s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:11<03:08,  1.40s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:13<03:14,  1.45s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:14<03:08,  1.42s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:16<03:05,  1.41s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:17<03:09,  1.44s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:19<03:04,  1.42s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:20<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:22<03:05,  1.45s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:23<03:02,  1.44s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:24<02:55,  1.40s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:26<02:54,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:27<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:29<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:30<02:58,  1.46s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:32<02:54,  1.44s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:33<02:51,  1.43s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:34<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:36<02:54,  1.48s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:37<02:47,  1.43s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:39<02:44,  1.42s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:40<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [04:42<02:43,  1.43s/it]predicting train subjects:  60%|██████    | 172/285 [04:43<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 174/285 [04:46<02:34,  1.40s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:38,  1.44s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:49<02:39,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:37,  1.46s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:30,  1.40s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:53<02:27,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:55<02:38,  1.51s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:40,  1.54s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:58<02:38,  1.54s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:29,  1.47s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:27,  1.46s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:22,  1.43s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:04<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:06<02:40,  1.63s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:07<02:42,  1.67s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:09<02:30,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:10<02:25,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:12<02:25,  1.54s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:25,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:15<02:16,  1.48s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:16<02:11,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:05,  1.39s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:19<02:14,  1.51s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:21<02:19,  1.59s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:23<02:24,  1.66s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:14,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:25<02:09,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:14,  1.60s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:11,  1.59s/it]predicting train subjects:  71%|███████   | 203/285 [05:30<02:10,  1.59s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:02,  1.52s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:33<01:58,  1.48s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:34<01:52,  1.42s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:36<02:00,  1.54s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:38<02:06,  1.64s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:40<02:08,  1.70s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:41<01:59,  1.59s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:43<01:53,  1.54s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:44<01:53,  1.55s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:46<01:54,  1.59s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:47<01:48,  1.53s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:49<01:51,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:50<01:44,  1.51s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:52<01:47,  1.59s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:54<01:50,  1.64s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:56<01:51,  1.69s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:42,  1.58s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:58<01:38,  1.53s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:00<01:39,  1.58s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:01<01:33,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:03<01:31,  1.50s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:04<01:27,  1.45s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:06<01:32,  1.57s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:08<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:10<01:35,  1.67s/it]predicting train subjects:  80%|████████  | 229/285 [06:11<01:32,  1.65s/it]predicting train subjects:  81%|████████  | 230/285 [06:13<01:25,  1.56s/it]predicting train subjects:  81%|████████  | 231/285 [06:14<01:21,  1.51s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:16<01:22,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:17<01:18,  1.50s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:19<01:22,  1.61s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:20<01:16,  1.54s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:22<01:19,  1.63s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:24<01:21,  1.70s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:26<01:21,  1.74s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:27<01:17,  1.69s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:29<01:11,  1.58s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:30<01:06,  1.52s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:31<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:33<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:35<01:04,  1.57s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:36<01:00,  1.50s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:38<01:01,  1.58s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:40<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:41<01:00,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:43<00:56,  1.58s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:44<00:54,  1.55s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:46<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:47<00:48,  1.47s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:49<00:50,  1.58s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:51<00:51,  1.65s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:52<00:48,  1.62s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:53<00:44,  1.54s/it]predicting train subjects:  90%|█████████ | 257/285 [06:55<00:41,  1.49s/it]predicting train subjects:  91%|█████████ | 258/285 [06:57<00:43,  1.60s/it]predicting train subjects:  91%|█████████ | 259/285 [06:58<00:41,  1.60s/it]predicting train subjects:  91%|█████████ | 260/285 [07:00<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:01<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:02<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:04<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:05<00:32,  1.54s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:07<00:32,  1.61s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:09<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:10<00:27,  1.53s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:12<00:27,  1.63s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:14<00:26,  1.64s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:15<00:23,  1.56s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:16<00:21,  1.51s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:18<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:19<00:17,  1.48s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:21<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:22<00:15,  1.53s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:24<00:14,  1.59s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:26<00:12,  1.53s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:27<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:29<00:09,  1.53s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:30<00:07,  1.50s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:31<00:05,  1.46s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:33<00:04,  1.42s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:35<00:03,  1.52s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:36<00:01,  1.63s/it]predicting train subjects: 100%|██████████| 285/285 [07:38<00:00,  1.67s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:27,  1.79s/it]Loading train:   1%|          | 2/285 [00:03<07:44,  1.64s/it]Loading train:   1%|          | 3/285 [00:04<07:35,  1.62s/it]Loading train:   1%|▏         | 4/285 [00:05<07:06,  1.52s/it]Loading train:   2%|▏         | 5/285 [00:07<07:19,  1.57s/it]Loading train:   2%|▏         | 6/285 [00:08<06:53,  1.48s/it]Loading train:   2%|▏         | 7/285 [00:10<07:15,  1.57s/it]Loading train:   3%|▎         | 8/285 [00:12<07:05,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:13<07:27,  1.62s/it]Loading train:   4%|▎         | 10/285 [00:15<06:52,  1.50s/it]Loading train:   4%|▍         | 11/285 [00:16<06:20,  1.39s/it]Loading train:   4%|▍         | 12/285 [00:17<06:05,  1.34s/it]Loading train:   5%|▍         | 13/285 [00:18<05:41,  1.25s/it]Loading train:   5%|▍         | 14/285 [00:19<05:25,  1.20s/it]Loading train:   5%|▌         | 15/285 [00:20<05:24,  1.20s/it]Loading train:   6%|▌         | 16/285 [00:22<05:42,  1.27s/it]Loading train:   6%|▌         | 17/285 [00:23<05:24,  1.21s/it]Loading train:   6%|▋         | 18/285 [00:24<05:20,  1.20s/it]Loading train:   7%|▋         | 19/285 [00:25<05:07,  1.15s/it]Loading train:   7%|▋         | 20/285 [00:26<05:08,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:27<05:08,  1.17s/it]Loading train:   8%|▊         | 22/285 [00:28<04:42,  1.08s/it]Loading train:   8%|▊         | 23/285 [00:30<04:52,  1.12s/it]Loading train:   8%|▊         | 24/285 [00:31<04:43,  1.09s/it]Loading train:   9%|▉         | 25/285 [00:32<04:52,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:33<05:01,  1.16s/it]Loading train:   9%|▉         | 27/285 [00:34<04:37,  1.08s/it]Loading train:  10%|▉         | 28/285 [00:35<04:33,  1.06s/it]Loading train:  10%|█         | 29/285 [00:36<04:22,  1.03s/it]Loading train:  11%|█         | 30/285 [00:37<04:32,  1.07s/it]Loading train:  11%|█         | 31/285 [00:38<04:50,  1.14s/it]Loading train:  11%|█         | 32/285 [00:39<04:28,  1.06s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:21,  1.04s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:18,  1.03s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:24,  1.06s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:07,  1.01it/s]Loading train:  13%|█▎        | 37/285 [00:44<04:03,  1.02it/s]Loading train:  13%|█▎        | 38/285 [00:45<04:23,  1.07s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:30,  1.10s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:35,  1.12s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:27,  1.10s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:23,  1.08s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:21,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:52<04:28,  1.12s/it]Loading train:  16%|█▌        | 45/285 [00:53<04:22,  1.09s/it]Loading train:  16%|█▌        | 46/285 [00:54<04:31,  1.14s/it]Loading train:  16%|█▋        | 47/285 [00:55<04:18,  1.09s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:40,  1.18s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:45,  1.21s/it]Loading train:  18%|█▊        | 50/285 [00:59<04:38,  1.18s/it]Loading train:  18%|█▊        | 51/285 [01:00<04:33,  1.17s/it]Loading train:  18%|█▊        | 52/285 [01:01<04:23,  1.13s/it]Loading train:  19%|█▊        | 53/285 [01:02<04:19,  1.12s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:25,  1.15s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:21,  1.14s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:14,  1.11s/it]Loading train:  20%|██        | 57/285 [01:07<03:55,  1.03s/it]Loading train:  20%|██        | 58/285 [01:08<03:59,  1.05s/it]Loading train:  21%|██        | 59/285 [01:09<04:03,  1.08s/it]Loading train:  21%|██        | 60/285 [01:10<04:05,  1.09s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:05,  1.10s/it]Loading train:  22%|██▏       | 62/285 [01:12<04:05,  1.10s/it]Loading train:  22%|██▏       | 63/285 [01:13<04:01,  1.09s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:31,  1.23s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:59,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:18<04:58,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:35,  1.26s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:08,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:22,  1.22s/it]Loading train:  25%|██▍       | 70/285 [01:22<04:29,  1.25s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:12,  1.18s/it]Loading train:  25%|██▌       | 72/285 [01:25<04:03,  1.14s/it]Loading train:  26%|██▌       | 73/285 [01:26<04:06,  1.16s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:56,  1.12s/it]Loading train:  26%|██▋       | 75/285 [01:28<04:04,  1.16s/it]Loading train:  27%|██▋       | 76/285 [01:29<04:11,  1.20s/it]Loading train:  27%|██▋       | 77/285 [01:30<04:02,  1.17s/it]Loading train:  27%|██▋       | 78/285 [01:32<04:00,  1.16s/it]Loading train:  28%|██▊       | 79/285 [01:33<03:50,  1.12s/it]Loading train:  28%|██▊       | 80/285 [01:34<03:51,  1.13s/it]Loading train:  28%|██▊       | 81/285 [01:35<03:55,  1.15s/it]Loading train:  29%|██▉       | 82/285 [01:36<03:50,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:37<03:35,  1.07s/it]Loading train:  29%|██▉       | 84/285 [01:38<03:30,  1.05s/it]Loading train:  30%|██▉       | 85/285 [01:39<03:38,  1.09s/it]Loading train:  30%|███       | 86/285 [01:40<03:37,  1.10s/it]Loading train:  31%|███       | 87/285 [01:41<03:37,  1.10s/it]Loading train:  31%|███       | 88/285 [01:42<03:21,  1.02s/it]Loading train:  31%|███       | 89/285 [01:43<03:26,  1.06s/it]Loading train:  32%|███▏      | 90/285 [01:45<03:33,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:46<03:25,  1.06s/it]Loading train:  32%|███▏      | 92/285 [01:47<03:35,  1.12s/it]Loading train:  33%|███▎      | 93/285 [01:48<03:36,  1.13s/it]Loading train:  33%|███▎      | 94/285 [01:49<03:26,  1.08s/it]Loading train:  33%|███▎      | 95/285 [01:50<03:34,  1.13s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:29,  1.11s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:27,  1.10s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:22,  1.08s/it]Loading train:  35%|███▍      | 99/285 [01:54<03:20,  1.08s/it]Loading train:  35%|███▌      | 100/285 [01:55<03:15,  1.06s/it]Loading train:  35%|███▌      | 101/285 [01:56<03:12,  1.05s/it]Loading train:  36%|███▌      | 102/285 [01:58<03:14,  1.06s/it]Loading train:  36%|███▌      | 103/285 [01:59<03:13,  1.06s/it]Loading train:  36%|███▋      | 104/285 [02:00<03:10,  1.05s/it]Loading train:  37%|███▋      | 105/285 [02:01<03:31,  1.18s/it]Loading train:  37%|███▋      | 106/285 [02:02<03:24,  1.14s/it]Loading train:  38%|███▊      | 107/285 [02:03<03:24,  1.15s/it]Loading train:  38%|███▊      | 108/285 [02:04<03:12,  1.09s/it]Loading train:  38%|███▊      | 109/285 [02:05<03:14,  1.10s/it]Loading train:  39%|███▊      | 110/285 [02:07<03:21,  1.15s/it]Loading train:  39%|███▉      | 111/285 [02:08<03:08,  1.08s/it]Loading train:  39%|███▉      | 112/285 [02:09<03:09,  1.09s/it]Loading train:  40%|███▉      | 113/285 [02:10<03:09,  1.10s/it]Loading train:  40%|████      | 114/285 [02:11<03:12,  1.13s/it]Loading train:  40%|████      | 115/285 [02:12<03:02,  1.07s/it]Loading train:  41%|████      | 116/285 [02:13<03:05,  1.10s/it]Loading train:  41%|████      | 117/285 [02:14<03:00,  1.07s/it]Loading train:  41%|████▏     | 118/285 [02:15<03:04,  1.11s/it]Loading train:  42%|████▏     | 119/285 [02:17<03:10,  1.15s/it]Loading train:  42%|████▏     | 120/285 [02:18<03:03,  1.11s/it]Loading train:  42%|████▏     | 121/285 [02:19<03:19,  1.22s/it]Loading train:  43%|████▎     | 122/285 [02:20<03:19,  1.22s/it]Loading train:  43%|████▎     | 123/285 [02:22<03:29,  1.30s/it]Loading train:  44%|████▎     | 124/285 [02:23<03:15,  1.21s/it]Loading train:  44%|████▍     | 125/285 [02:24<03:03,  1.15s/it]Loading train:  44%|████▍     | 126/285 [02:25<03:02,  1.15s/it]Loading train:  45%|████▍     | 127/285 [02:26<02:48,  1.07s/it]Loading train:  45%|████▍     | 128/285 [02:27<02:50,  1.08s/it]Loading train:  45%|████▌     | 129/285 [02:28<02:40,  1.03s/it]Loading train:  46%|████▌     | 130/285 [02:29<02:40,  1.03s/it]Loading train:  46%|████▌     | 131/285 [02:30<02:41,  1.05s/it]Loading train:  46%|████▋     | 132/285 [02:31<02:38,  1.03s/it]Loading train:  47%|████▋     | 133/285 [02:32<02:35,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:33<02:26,  1.03it/s]Loading train:  47%|████▋     | 135/285 [02:34<02:25,  1.03it/s]Loading train:  48%|████▊     | 136/285 [02:35<02:19,  1.07it/s]Loading train:  48%|████▊     | 137/285 [02:36<02:30,  1.02s/it]Loading train:  48%|████▊     | 138/285 [02:37<02:24,  1.02it/s]Loading train:  49%|████▉     | 139/285 [02:38<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:39<02:24,  1.00it/s]Loading train:  49%|████▉     | 141/285 [02:39<02:12,  1.09it/s]Loading train:  50%|████▉     | 142/285 [02:40<02:14,  1.06it/s]Loading train:  50%|█████     | 143/285 [02:41<02:10,  1.09it/s]Loading train:  51%|█████     | 144/285 [02:42<02:18,  1.02it/s]Loading train:  51%|█████     | 145/285 [02:44<02:23,  1.02s/it]Loading train:  51%|█████     | 146/285 [02:44<02:18,  1.00it/s]Loading train:  52%|█████▏    | 147/285 [02:46<02:20,  1.02s/it]Loading train:  52%|█████▏    | 148/285 [02:47<02:30,  1.10s/it]Loading train:  52%|█████▏    | 149/285 [02:48<02:31,  1.11s/it]Loading train:  53%|█████▎    | 150/285 [02:49<02:37,  1.17s/it]Loading train:  53%|█████▎    | 151/285 [02:50<02:32,  1.14s/it]Loading train:  53%|█████▎    | 152/285 [02:51<02:28,  1.12s/it]Loading train:  54%|█████▎    | 153/285 [02:52<02:17,  1.04s/it]Loading train:  54%|█████▍    | 154/285 [02:54<02:29,  1.14s/it]Loading train:  54%|█████▍    | 155/285 [02:55<02:25,  1.12s/it]Loading train:  55%|█████▍    | 156/285 [02:56<02:16,  1.06s/it]Loading train:  55%|█████▌    | 157/285 [02:56<02:03,  1.03it/s]Loading train:  55%|█████▌    | 158/285 [02:57<02:06,  1.00it/s]Loading train:  56%|█████▌    | 159/285 [02:58<02:02,  1.03it/s]Loading train:  56%|█████▌    | 160/285 [02:59<02:00,  1.04it/s]Loading train:  56%|█████▋    | 161/285 [03:00<02:03,  1.00it/s]Loading train:  57%|█████▋    | 162/285 [03:01<01:56,  1.05it/s]Loading train:  57%|█████▋    | 163/285 [03:02<02:06,  1.03s/it]Loading train:  58%|█████▊    | 164/285 [03:04<02:06,  1.04s/it]Loading train:  58%|█████▊    | 165/285 [03:05<02:06,  1.05s/it]Loading train:  58%|█████▊    | 166/285 [03:05<01:57,  1.01it/s]Loading train:  59%|█████▊    | 167/285 [03:07<02:00,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [03:07<01:52,  1.04it/s]Loading train:  59%|█████▉    | 169/285 [03:08<01:46,  1.09it/s]Loading train:  60%|█████▉    | 170/285 [03:09<01:50,  1.04it/s]Loading train:  60%|██████    | 171/285 [03:10<01:49,  1.04it/s]Loading train:  60%|██████    | 172/285 [03:11<01:52,  1.01it/s]Loading train:  61%|██████    | 173/285 [03:12<01:52,  1.01s/it]Loading train:  61%|██████    | 174/285 [03:13<01:51,  1.01s/it]Loading train:  61%|██████▏   | 175/285 [03:14<01:48,  1.01it/s]Loading train:  62%|██████▏   | 176/285 [03:15<01:51,  1.03s/it]Loading train:  62%|██████▏   | 177/285 [03:16<01:46,  1.01it/s]Loading train:  62%|██████▏   | 178/285 [03:17<01:43,  1.03it/s]Loading train:  63%|██████▎   | 179/285 [03:18<01:50,  1.04s/it]Loading train:  63%|██████▎   | 180/285 [03:20<01:59,  1.14s/it]Loading train:  64%|██████▎   | 181/285 [03:21<02:00,  1.16s/it]Loading train:  64%|██████▍   | 182/285 [03:22<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [03:23<01:49,  1.08s/it]Loading train:  65%|██████▍   | 184/285 [03:24<01:40,  1.00it/s]Loading train:  65%|██████▍   | 185/285 [03:25<01:39,  1.00it/s]Loading train:  65%|██████▌   | 186/285 [03:26<01:42,  1.04s/it]Loading train:  66%|██████▌   | 187/285 [03:27<01:45,  1.08s/it]Loading train:  66%|██████▌   | 188/285 [03:28<01:49,  1.13s/it]Loading train:  66%|██████▋   | 189/285 [03:29<01:40,  1.05s/it]Loading train:  67%|██████▋   | 190/285 [03:30<01:36,  1.01s/it]Loading train:  67%|██████▋   | 191/285 [03:31<01:36,  1.03s/it]Loading train:  67%|██████▋   | 192/285 [03:32<01:36,  1.04s/it]Loading train:  68%|██████▊   | 193/285 [03:33<01:33,  1.01s/it]Loading train:  68%|██████▊   | 194/285 [03:34<01:28,  1.02it/s]Loading train:  68%|██████▊   | 195/285 [03:35<01:26,  1.04it/s]Loading train:  69%|██████▉   | 196/285 [03:36<01:28,  1.00it/s]Loading train:  69%|██████▉   | 197/285 [03:37<01:27,  1.01it/s]Loading train:  69%|██████▉   | 198/285 [03:38<01:32,  1.07s/it]Loading train:  70%|██████▉   | 199/285 [03:39<01:26,  1.01s/it]Loading train:  70%|███████   | 200/285 [03:40<01:24,  1.00it/s]Loading train:  71%|███████   | 201/285 [03:41<01:25,  1.02s/it]Loading train:  71%|███████   | 202/285 [03:42<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:43<01:22,  1.00s/it]Loading train:  72%|███████▏  | 204/285 [03:44<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:45<01:19,  1.01it/s]Loading train:  72%|███████▏  | 206/285 [03:46<01:13,  1.07it/s]Loading train:  73%|███████▎  | 207/285 [03:47<01:15,  1.04it/s]Loading train:  73%|███████▎  | 208/285 [03:48<01:13,  1.04it/s]Loading train:  73%|███████▎  | 209/285 [03:49<01:14,  1.02it/s]Loading train:  74%|███████▎  | 210/285 [03:50<01:09,  1.08it/s]Loading train:  74%|███████▍  | 211/285 [03:51<01:08,  1.08it/s]Loading train:  74%|███████▍  | 212/285 [03:52<01:14,  1.01s/it]Loading train:  75%|███████▍  | 213/285 [03:53<01:14,  1.03s/it]Loading train:  75%|███████▌  | 214/285 [03:54<01:08,  1.04it/s]Loading train:  75%|███████▌  | 215/285 [03:55<01:14,  1.06s/it]Loading train:  76%|███████▌  | 216/285 [03:56<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [03:57<01:13,  1.08s/it]Loading train:  76%|███████▋  | 218/285 [03:59<01:15,  1.13s/it]Loading train:  77%|███████▋  | 219/285 [04:00<01:16,  1.16s/it]Loading train:  77%|███████▋  | 220/285 [04:01<01:10,  1.09s/it]Loading train:  78%|███████▊  | 221/285 [04:02<01:07,  1.05s/it]Loading train:  78%|███████▊  | 222/285 [04:03<01:06,  1.05s/it]Loading train:  78%|███████▊  | 223/285 [04:04<01:03,  1.03s/it]Loading train:  79%|███████▊  | 224/285 [04:05<01:02,  1.02s/it]Loading train:  79%|███████▉  | 225/285 [04:05<00:57,  1.04it/s]Loading train:  79%|███████▉  | 226/285 [04:07<00:59,  1.01s/it]Loading train:  80%|███████▉  | 227/285 [04:08<01:02,  1.08s/it]Loading train:  80%|████████  | 228/285 [04:09<01:03,  1.12s/it]Loading train:  80%|████████  | 229/285 [04:10<01:01,  1.09s/it]Loading train:  81%|████████  | 230/285 [04:11<00:56,  1.02s/it]Loading train:  81%|████████  | 231/285 [04:12<00:51,  1.04it/s]Loading train:  81%|████████▏ | 232/285 [04:13<00:53,  1.00s/it]Loading train:  82%|████████▏ | 233/285 [04:14<00:52,  1.01s/it]Loading train:  82%|████████▏ | 234/285 [04:15<00:51,  1.01s/it]Loading train:  82%|████████▏ | 235/285 [04:16<00:47,  1.05it/s]Loading train:  83%|████████▎ | 236/285 [04:17<00:50,  1.03s/it]Loading train:  83%|████████▎ | 237/285 [04:18<00:48,  1.02s/it]Loading train:  84%|████████▎ | 238/285 [04:19<00:48,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [04:20<00:50,  1.10s/it]Loading train:  84%|████████▍ | 240/285 [04:21<00:45,  1.02s/it]Loading train:  85%|████████▍ | 241/285 [04:22<00:45,  1.04s/it]Loading train:  85%|████████▍ | 242/285 [04:23<00:41,  1.03it/s]Loading train:  85%|████████▌ | 243/285 [04:24<00:38,  1.08it/s]Loading train:  86%|████████▌ | 244/285 [04:25<00:42,  1.05s/it]Loading train:  86%|████████▌ | 245/285 [04:26<00:41,  1.05s/it]Loading train:  86%|████████▋ | 246/285 [04:27<00:40,  1.03s/it]Loading train:  87%|████████▋ | 247/285 [04:28<00:39,  1.05s/it]Loading train:  87%|████████▋ | 248/285 [04:29<00:40,  1.08s/it]Loading train:  87%|████████▋ | 249/285 [04:30<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:31<00:36,  1.04s/it]Loading train:  88%|████████▊ | 251/285 [04:33<00:36,  1.06s/it]Loading train:  88%|████████▊ | 252/285 [04:33<00:33,  1.02s/it]Loading train:  89%|████████▉ | 253/285 [04:34<00:31,  1.00it/s]Loading train:  89%|████████▉ | 254/285 [04:36<00:33,  1.07s/it]Loading train:  89%|████████▉ | 255/285 [04:37<00:31,  1.05s/it]Loading train:  90%|████████▉ | 256/285 [04:38<00:29,  1.03s/it]Loading train:  90%|█████████ | 257/285 [04:39<00:28,  1.01s/it]Loading train:  91%|█████████ | 258/285 [04:40<00:29,  1.11s/it]Loading train:  91%|█████████ | 259/285 [04:41<00:27,  1.05s/it]Loading train:  91%|█████████ | 260/285 [04:42<00:26,  1.05s/it]Loading train:  92%|█████████▏| 261/285 [04:43<00:24,  1.02s/it]Loading train:  92%|█████████▏| 262/285 [04:44<00:23,  1.01s/it]Loading train:  92%|█████████▏| 263/285 [04:45<00:21,  1.01it/s]Loading train:  93%|█████████▎| 264/285 [04:46<00:22,  1.07s/it]Loading train:  93%|█████████▎| 265/285 [04:47<00:20,  1.04s/it]Loading train:  93%|█████████▎| 266/285 [04:48<00:19,  1.03s/it]Loading train:  94%|█████████▎| 267/285 [04:49<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [04:50<00:17,  1.03s/it]Loading train:  94%|█████████▍| 269/285 [04:51<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:52<00:14,  1.05it/s]Loading train:  95%|█████████▌| 271/285 [04:53<00:13,  1.02it/s]Loading train:  95%|█████████▌| 272/285 [04:54<00:12,  1.05it/s]Loading train:  96%|█████████▌| 273/285 [04:55<00:12,  1.02s/it]Loading train:  96%|█████████▌| 274/285 [04:56<00:11,  1.03s/it]Loading train:  96%|█████████▋| 275/285 [04:57<00:11,  1.17s/it]Loading train:  97%|█████████▋| 276/285 [04:59<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:00<00:09,  1.13s/it]Loading train:  98%|█████████▊| 278/285 [05:01<00:07,  1.09s/it]Loading train:  98%|█████████▊| 279/285 [05:02<00:06,  1.06s/it]Loading train:  98%|█████████▊| 280/285 [05:03<00:05,  1.03s/it]Loading train:  99%|█████████▊| 281/285 [05:04<00:04,  1.00s/it]Loading train:  99%|█████████▉| 282/285 [05:04<00:02,  1.05it/s]Loading train:  99%|█████████▉| 283/285 [05:06<00:02,  1.01s/it]Loading train: 100%|█████████▉| 284/285 [05:07<00:01,  1.14s/it]Loading train: 100%|██████████| 285/285 [05:08<00:00,  1.18s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:05, 54.92it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:04, 60.93it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:03, 71.22it/s]concatenating: train:  19%|█▉        | 54/285 [00:00<00:02, 91.09it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:01, 114.04it/s]concatenating: train:  39%|███▉      | 111/285 [00:00<00:01, 139.11it/s]concatenating: train:  49%|████▉     | 141/285 [00:00<00:00, 165.33it/s]concatenating: train:  58%|█████▊    | 165/285 [00:00<00:00, 179.17it/s]concatenating: train:  66%|██████▌   | 188/285 [00:01<00:00, 162.26it/s]concatenating: train:  77%|███████▋  | 219/285 [00:01<00:00, 188.57it/s]concatenating: train:  87%|████████▋ | 249/285 [00:01<00:00, 211.98it/s]concatenating: train:  99%|█████████▉| 282/285 [00:01<00:00, 237.31it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 215.66it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.37s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 149.73it/s]2019-07-11 06:55:05.136258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 06:55:05.136381: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 06:55:05.136396: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 06:55:05.136405: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 06:55:05.136835: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.30it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.06it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.77it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.16it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.68it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.46it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.53it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.29it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.25it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.78it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  7.96it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.51it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.76it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.15it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.27it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.03it/s]
Epoch 00051: val_mDice did not improve from 0.59388
Restoring model weights from the end of the best epoch
Epoch 00051: early stopping
{'val_loss': [1.7370654968988328, 1.2608573209671747, 1.2731465612139021, 0.9670523632140386, 1.0133215472811745, 1.011251653943743, 1.0080830029078893, 0.9562841369992211, 0.9634182396389189, 0.9636919498443604, 0.9301315943400065, 0.961067347299485, 0.955244813646589, 0.967303542863755, 0.9068740095411029, 0.939654202688308, 0.9781635034651983, 0.9082036302203224, 0.9299139579137167, 0.9304718346822829, 0.9149045887447539, 0.9629976068224225, 0.9307020902633667, 0.9123028687068394, 0.8985338267825899, 0.8822309062594459, 0.8810787144161406, 0.9395521822429839, 0.9471271719251361, 0.9521863801138741, 0.8820259968439738, 0.8793446733838036, 0.8924573716663179, 0.8784735883985247, 0.9262200877780006, 0.8526988540376935, 0.8614018701371693, 0.8991313434782482, 0.8608797902152652, 0.833427661941165, 0.8440953606650943, 0.83464553242638, 0.8181216716766357, 0.84508026213873, 0.8207677886599586, 0.8494831380389986, 0.7881043865567162, 0.834058091754005, 0.7539635272253127, 0.827062691961016, 0.7583537896474203], 'val_acc': [0.9180791974067688, 0.9171749325025649, 0.9192376477377755, 0.9426900063242231, 0.9409432297661191, 0.9437935068493798, 0.9445192274593172, 0.936927664847601, 0.9443383983203343, 0.9430059450013297, 0.9453434092657906, 0.9387133717536926, 0.9485073288281759, 0.9391071512585595, 0.9437568954059056, 0.9403319585890997, 0.9470856388409933, 0.9459203141076225, 0.9414034173602149, 0.9478846419425238, 0.9465224515824091, 0.9445993644850594, 0.9460371136665344, 0.9455998114177159, 0.9378159613836379, 0.9474542084194365, 0.9433402021725973, 0.9453868922733125, 0.9458379319735936, 0.9463507504690261, 0.9482188622156779, 0.9443086300577436, 0.9468429230508351, 0.9459638368515741, 0.9458699368295216, 0.9444826216924758, 0.946243132863726, 0.9457944092296419, 0.9475252003896804, 0.9479693060829526, 0.9461378001031422, 0.9468063456671578, 0.9453434035891578, 0.9466620967501685, 0.9457394622621083, 0.943940003712972, 0.9472573200861613, 0.9426304754756746, 0.9468933003289359, 0.9472206774212065, 0.946540755884988], 'val_mDice': [0.33187067082950045, 0.45061236016807105, 0.42629059670226915, 0.5917938058929784, 0.5622877576166675, 0.560701118161281, 0.560895315770592, 0.5830267735180401, 0.5836213099814597, 0.5753458741874922, 0.5938824718551976, 0.5749411607782046, 0.5856756033996741, 0.5666216808770385, 0.5922239000598589, 0.5836810150316784, 0.5586585125752858, 0.5933077186346054, 0.5813739313965752, 0.5863501589213099, 0.5822053824861845, 0.5364327292357173, 0.5772847027650901, 0.575674631411121, 0.5684827998990104, 0.5873594672552177, 0.575051649695351, 0.5706776541968187, 0.5541833433366957, 0.5456246190837452, 0.586195962414855, 0.5750607548370248, 0.5750235806973207, 0.574129389687663, 0.5607321471685455, 0.5797756319599492, 0.5770009172459444, 0.5451160270188536, 0.5723345723180544, 0.5928302930579299, 0.5808147672741186, 0.5768999751834643, 0.5864456918622766, 0.5546521285460109, 0.5779002468500819, 0.5767929082115492, 0.5922154461344084, 0.5711574646688643, 0.587563574668907, 0.5700519822892689, 0.5837510437482879], 'loss': [2.543766997856558, 0.6963422768764559, 0.5134062259636657, 0.4630163597398717, 0.4390967202388829, 0.4242845814777795, 0.4118776344738187, 0.40231115032717835, 0.3910048828778617, 0.3817688322421188, 0.3770828037988664, 0.37359854341679416, 0.36578738536015626, 0.36111125834925406, 0.35771455778789724, 0.35305071784302244, 0.35145684649816983, 0.34571804623624963, 0.3439693866390609, 0.3401649689855938, 0.33706049645523906, 0.3348432230839087, 0.3320611618848488, 0.3304644167561142, 0.3310652119830231, 0.3258837676356242, 0.3242765472922133, 0.32355813631230934, 0.3223663969653085, 0.3196628750094518, 0.31932842376399, 0.31723508867358846, 0.3151778307049771, 0.31259150256971785, 0.3116437373695425, 0.31078195108805684, 0.3085058062826252, 0.30912933732035164, 0.3085403628711965, 0.30588343247687955, 0.3043298111937284, 0.30249514306513176, 0.30456947227169695, 0.300200889651569, 0.30166302548108453, 0.29942290475999594, 0.2966595452622869, 0.29714847452750387, 0.29584609921529664, 0.294704134946433, 0.29435199036611076], 'acc': [0.5905834052073248, 0.8898808842153937, 0.8977722146043617, 0.9048709730111911, 0.9100090720094144, 0.9169816425454761, 0.9245259712053582, 0.9306504305718559, 0.9335802995862128, 0.9349575628429013, 0.9356317949566235, 0.9362529599875734, 0.9374842898726624, 0.9379641798642506, 0.9382358897690694, 0.9386900799661008, 0.9388548584372317, 0.9395527002759492, 0.939844388630387, 0.94015655920688, 0.9403059216324295, 0.9406962059976877, 0.9408490007291852, 0.941027956338018, 0.9410055756614873, 0.9415162121810641, 0.941767279182943, 0.9416906048342836, 0.9416217401994316, 0.9420672833333475, 0.9421940583334232, 0.9425047245907237, 0.9426018346682067, 0.942918221557993, 0.9428766514263517, 0.9430604297714424, 0.9430839689637003, 0.9430071834725453, 0.9431800649233675, 0.9434699718033346, 0.9435348267704162, 0.9437661289892975, 0.9435703736498839, 0.9438178490438695, 0.9438282991733444, 0.9439525005213898, 0.944243811816408, 0.9442612425840174, 0.9443657689065126, 0.9443263525858949, 0.9445242194029001], 'mDice': [0.1429282753427226, 0.4883692803722093, 0.5838354595920496, 0.6152743675907798, 0.6308863429359464, 0.640740006110653, 0.6488698542244475, 0.654604974511457, 0.6619110543741205, 0.6682506781541844, 0.6713359407751643, 0.673834004061103, 0.6792174394199194, 0.6824758351136431, 0.6847731656184287, 0.6879692568539056, 0.6891821203651008, 0.6932616435840269, 0.6944341756416373, 0.6972956515493847, 0.6993573748676998, 0.7009976814311204, 0.7029069333561864, 0.7042257071161905, 0.703786600548476, 0.7074118029618507, 0.7086813283467628, 0.7091928331498492, 0.7100435949162479, 0.7120905070146752, 0.7123092959697982, 0.7138796850783254, 0.7153813906871493, 0.7172828651081281, 0.7179576538191472, 0.7186595099910459, 0.7202913429044404, 0.7197665732468119, 0.7202591928806934, 0.7222888835344743, 0.7234555136750653, 0.7247879437589453, 0.7232694534844508, 0.7265574165867867, 0.7255021105939675, 0.7271303549446259, 0.7292593121758448, 0.7288729390221017, 0.7298351342631646, 0.7307549938430257, 0.7309690348118837]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 40)   21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 100)  0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 268,513
Trainable params: 93,593
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 24s - loss: 1.5452 - acc: 0.8196 - mDice: 0.3590 - val_loss: 0.6452 - val_acc: 0.9407 - val_mDice: 0.5258

Epoch 00001: val_mDice improved from -inf to 0.52584, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 18s - loss: 0.4277 - acc: 0.9414 - mDice: 0.6382 - val_loss: 0.4824 - val_acc: 0.9530 - val_mDice: 0.6126

Epoch 00002: val_mDice improved from 0.52584 to 0.61255, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 18s - loss: 0.3790 - acc: 0.9464 - mDice: 0.6705 - val_loss: 0.4494 - val_acc: 0.9533 - val_mDice: 0.6286

Epoch 00003: val_mDice improved from 0.61255 to 0.62862, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 17s - loss: 0.3557 - acc: 0.9484 - mDice: 0.6867 - val_loss: 0.4531 - val_acc: 0.9534 - val_mDice: 0.6275

Epoch 00004: val_mDice did not improve from 0.62862
Epoch 5/300
 - 18s - loss: 0.3387 - acc: 0.9496 - mDice: 0.6986 - val_loss: 0.4509 - val_acc: 0.9498 - val_mDice: 0.6266

Epoch 00005: val_mDice did not improve from 0.62862
Epoch 6/300
 - 17s - loss: 0.3281 - acc: 0.9506 - mDice: 0.7065 - val_loss: 0.4664 - val_acc: 0.9528 - val_mDice: 0.6222

Epoch 00006: val_mDice did not improve from 0.62862
Epoch 7/300
 - 17s - loss: 0.3186 - acc: 0.9512 - mDice: 0.7133 - val_loss: 0.4532 - val_acc: 0.9542 - val_mDice: 0.6297

Epoch 00007: val_mDice improved from 0.62862 to 0.62968, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 17s - loss: 0.3098 - acc: 0.9518 - mDice: 0.7198 - val_loss: 0.4405 - val_acc: 0.9523 - val_mDice: 0.6354

Epoch 00008: val_mDice improved from 0.62968 to 0.63535, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 18s - loss: 0.3030 - acc: 0.9524 - mDice: 0.7250 - val_loss: 0.4728 - val_acc: 0.9527 - val_mDice: 0.6221

Epoch 00009: val_mDice did not improve from 0.63535
Epoch 10/300
 - 17s - loss: 0.2974 - acc: 0.9528 - mDice: 0.7293 - val_loss: 0.4491 - val_acc: 0.9520 - val_mDice: 0.6301

Epoch 00010: val_mDice did not improve from 0.63535
Epoch 11/300
 - 17s - loss: 0.2929 - acc: 0.9532 - mDice: 0.7326 - val_loss: 0.4914 - val_acc: 0.9544 - val_mDice: 0.6097

Epoch 00011: val_mDice did not improve from 0.63535
Epoch 12/300
 - 17s - loss: 0.2873 - acc: 0.9536 - mDice: 0.7369 - val_loss: 0.4664 - val_acc: 0.9493 - val_mDice: 0.6203

Epoch 00012: val_mDice did not improve from 0.63535
Epoch 13/300
 - 17s - loss: 0.2833 - acc: 0.9538 - mDice: 0.7400 - val_loss: 0.4435 - val_acc: 0.9558 - val_mDice: 0.6365

Epoch 00013: val_mDice improved from 0.63535 to 0.63654, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 18s - loss: 0.2818 - acc: 0.9540 - mDice: 0.7412 - val_loss: 0.4600 - val_acc: 0.9528 - val_mDice: 0.6253

Epoch 00014: val_mDice did not improve from 0.63654
Epoch 15/300
 - 17s - loss: 0.2771 - acc: 0.9544 - mDice: 0.7448 - val_loss: 0.4729 - val_acc: 0.9523 - val_mDice: 0.6180

Epoch 00015: val_mDice did not improve from 0.63654
Epoch 16/300
 - 19s - loss: 0.2750 - acc: 0.9544 - mDice: 0.7464 - val_loss: 0.4547 - val_acc: 0.9540 - val_mDice: 0.6256

Epoch 00016: val_mDice did not improve from 0.63654
Epoch 17/300
 - 18s - loss: 0.2700 - acc: 0.9548 - mDice: 0.7502 - val_loss: 0.4489 - val_acc: 0.9527 - val_mDice: 0.6300

Epoch 00017: val_mDice did not improve from 0.63654
Epoch 18/300
 - 18s - loss: 0.2674 - acc: 0.9550 - mDice: 0.7523 - val_loss: 0.4756 - val_acc: 0.9518 - val_mDice: 0.6201

Epoch 00018: val_mDice did not improve from 0.63654
Epoch 19/300
 - 18s - loss: 0.2656 - acc: 0.9551 - mDice: 0.7537 - val_loss: 0.4493 - val_acc: 0.9550 - val_mDice: 0.6319

Epoch 00019: val_mDice did not improve from 0.63654
Epoch 20/300
 - 18s - loss: 0.2627 - acc: 0.9554 - mDice: 0.7561 - val_loss: 0.4491 - val_acc: 0.9518 - val_mDice: 0.6327

Epoch 00020: val_mDice did not improve from 0.63654
Epoch 21/300
 - 18s - loss: 0.2615 - acc: 0.9555 - mDice: 0.7570 - val_loss: 0.4480 - val_acc: 0.9526 - val_mDice: 0.6337

Epoch 00021: val_mDice did not improve from 0.63654
Epoch 22/300
 - 18s - loss: 0.2575 - acc: 0.9557 - mDice: 0.7601 - val_loss: 0.4682 - val_acc: 0.9561 - val_mDice: 0.6238

Epoch 00022: val_mDice did not improve from 0.63654
Epoch 23/300
 - 18s - loss: 0.2564 - acc: 0.9558 - mDice: 0.7610 - val_loss: 0.4514 - val_acc: 0.9520 - val_mDice: 0.6300

Epoch 00023: val_mDice did not improve from 0.63654
Epoch 24/300
 - 18s - loss: 0.2540 - acc: 0.9560 - mDice: 0.7630 - val_loss: 0.5078 - val_acc: 0.9534 - val_mDice: 0.6042

Epoch 00024: val_mDice did not improve from 0.63654
Epoch 25/300
 - 18s - loss: 0.2529 - acc: 0.9561 - mDice: 0.7638 - val_loss: 0.4497 - val_acc: 0.9546 - val_mDice: 0.6302

Epoch 00025: val_mDice did not improve from 0.63654
Epoch 26/300
 - 18s - loss: 0.2515 - acc: 0.9563 - mDice: 0.7650 - val_loss: 0.4825 - val_acc: 0.9531 - val_mDice: 0.6168

Epoch 00026: val_mDice did not improve from 0.63654
Epoch 27/300
 - 18s - loss: 0.2511 - acc: 0.9562 - mDice: 0.7653 - val_loss: 0.4701 - val_acc: 0.9537 - val_mDice: 0.6278

Epoch 00027: val_mDice did not improve from 0.63654
Epoch 28/300
 - 18s - loss: 0.2488 - acc: 0.9565 - mDice: 0.7672 - val_loss: 0.4600 - val_acc: 0.9530 - val_mDice: 0.6248

Epoch 00028: val_mDice did not improve from 0.63654
Epoch 29/300
 - 18s - loss: 0.2486 - acc: 0.9564 - mDice: 0.7673 - val_loss: 0.4464 - val_acc: 0.9546 - val_mDice: 0.6334

Epoch 00029: val_mDice did not improve from 0.63654
Epoch 30/300
 - 18s - loss: 0.2445 - acc: 0.9567 - mDice: 0.7705 - val_loss: 0.4434 - val_acc: 0.9546 - val_mDice: 0.6355

Epoch 00030: val_mDice did not improve from 0.63654
Epoch 31/300
 - 18s - loss: 0.2437 - acc: 0.9567 - mDice: 0.7712 - val_loss: 0.4693 - val_acc: 0.9533 - val_mDice: 0.6219

Epoch 00031: val_mDice did not improve from 0.63654
Epoch 32/300
 - 17s - loss: 0.2432 - acc: 0.9568 - mDice: 0.7716 - val_loss: 0.4505 - val_acc: 0.9550 - val_mDice: 0.6283

Epoch 00032: val_mDice did not improve from 0.63654
Epoch 33/300
 - 17s - loss: 0.2404 - acc: 0.9570 - mDice: 0.7739 - val_loss: 0.4763 - val_acc: 0.9548 - val_mDice: 0.6158

Epoch 00033: val_mDice did not improve from 0.63654
Epoch 34/300
 - 17s - loss: 0.2409 - acc: 0.9569 - mDice: 0.7734 - val_loss: 0.4891 - val_acc: 0.9540 - val_mDice: 0.6162

Epoch 00034: val_mDice did not improve from 0.63654
Epoch 35/300
 - 17s - loss: 0.2390 - acc: 0.9571 - mDice: 0.7750 - val_loss: 0.4649 - val_acc: 0.9536 - val_mDice: 0.6234

Epoch 00035: val_mDice did not improve from 0.63654
Epoch 36/300
 - 16s - loss: 0.2373 - acc: 0.9572 - mDice: 0.7763 - val_loss: 0.4709 - val_acc: 0.9532 - val_mDice: 0.6216

Epoch 00036: val_mDice did not improve from 0.63654
Epoch 37/300
 - 17s - loss: 0.2365 - acc: 0.9573 - mDice: 0.7771 - val_loss: 0.4508 - val_acc: 0.9524 - val_mDice: 0.6299

Epoch 00037: val_mDice did not improve from 0.63654
Epoch 38/300
 - 17s - loss: 0.2351 - acc: 0.9573 - mDice: 0.7781 - val_loss: 0.4592 - val_acc: 0.9542 - val_mDice: 0.6251

Epoch 00038: val_mDice did not improve from 0.63654
Epoch 39/300
 - 16s - loss: 0.2342 - acc: 0.9575 - mDice: 0.7789 - val_loss: 0.4671 - val_acc: 0.9505 - val_mDice: 0.6177

Epoch 00039: val_mDice did not improve from 0.63654
Epoch 40/300
 - 16s - loss: 0.2345 - acc: 0.9575 - mDice: 0.7786 - val_loss: 0.4580 - val_acc: 0.9552 - val_mDice: 0.6279

Epoch 00040: val_mDice did not improve from 0.63654
Epoch 41/300
 - 16s - loss: 0.2320 - acc: 0.9575 - mDice: 0.7807 - val_loss: 0.4625 - val_acc: 0.9536 - val_mDice: 0.6234

Epoch 00041: val_mDice did not improve from 0.63654
Epoch 42/300
 - 16s - loss: 0.2315 - acc: 0.9577 - mDice: 0.7811 - val_loss: 0.4618 - val_acc: 0.9535 - val_mDice: 0.6257

Epoch 00042: val_mDice did not improve from 0.63654
Epoch 43/300
 - 17s - loss: 0.2307 - acc: 0.9577 - mDice: 0.7818 - val_loss: 0.4407 - val_acc: 0.9543 - val_mDice: 0.6337

Epoch 00043: val_mDice did not improve from 0.63654
Epoch 44/300
 - 17s - loss: 0.2303 - acc: 0.9577 - mDice: 0.7821 - val_loss: 0.4845 - val_acc: 0.9554 - val_mDice: 0.6190

Epoch 00044: val_mDice did not improve from 0.63654
Epoch 45/300
 - 17s - loss: 0.2286 - acc: 0.9578 - mDice: 0.7835 - val_loss: 0.4450 - val_acc: 0.9544 - val_mDice: 0.6319

Epoch 00045: val_mDice did not improve from 0.63654
Epoch 46/300
 - 16s - loss: 0.2291 - acc: 0.9578 - mDice: 0.7830 - val_loss: 0.4412 - val_acc: 0.9547 - val_mDice: 0.6335

Epoch 00046: val_mDice did not improve from 0.63654
Epoch 47/300
 - 17s - loss: 0.2275 - acc: 0.9579 - mDice: 0.7844 - val_loss: 0.4383 - val_acc: 0.9522 - val_mDice: 0.6355

Epoch 00047: val_mDice did not improve from 0.63654
Epoch 48/300
 - 16s - loss: 0.2269 - acc: 0.9580 - mDice: 0.7849 - val_loss: 0.4528 - val_acc: 0.9544 - val_mDice: 0.6277

Epoch 00048: val_mDice did not improve from 0.63654
Epoch 49/300
 - 17s - loss: 0.2270 - acc: 0.9580 - mDice: 0.7850 - val_loss: 0.4554 - val_acc: 0.9549 - val_mDice: 0.6250

Epoch 00049: val_mDice did not improve from 0.63654
Epoch 50/300
 - 17s - loss: 0.2679 - acc: 0.9548 - mDice: 0.7555 - val_loss: 0.4551 - val_acc: 0.9551 - val_mDice: 0.6267

Epoch 00050: val_mDice did not improve from 0.63654
Epoch 51/300
 - 16s - loss: 0.2340 - acc: 0.9575 - mDice: 0.7791 - val_loss: 0.4388 - val_acc: 0.9539 - val_mDice: 0.6360

Epoch 00051: val_mDice did not improve from 0.63654
Epoch 52/300
 - 16s - loss: 0.2287 - acc: 0.9578 - mDice: 0.7834 - val_loss: 0.4496 - val_acc: 0.9558 - val_mDice: 0.6328

Epoch 00052: val_mDice did not improve from 0.63654
Epoch 53/300
 - 16s - loss: 0.2278 - acc: 0.9579 - mDice: 0.7842 - val_loss: 0.4701 - val_acc: 0.9538 - val_mDice: 0.6207

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.36s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.10s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.92s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:10,  1.94s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:27,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:22,  1.78s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:57,  1.70s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:16,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:56,  1.71s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:12,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:56,  1.72s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:28,  1.84s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:42,  1.90s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:22,  1.83s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:37,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:17,  1.83s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:18,  1.84s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:43,  1.94s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:53,  1.98s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:30,  1.90s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:24,  1.89s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:05,  1.82s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:10,  1.85s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:30,  1.93s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:13,  1.88s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:07,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:47,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:07,  1.88s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:18,  1.93s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<07:53,  1.83s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:00,  1.87s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:01,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:10,  1.92s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:17,  1.96s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:50,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:48,  1.87s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:46,  1.88s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:55,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:41,  1.87s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:44,  1.90s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:25,  1.82s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:15,  1.79s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:19,  1.82s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:39,  1.91s/it]predicting train subjects:  16%|█▌        | 45/285 [01:23<07:25,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:25<07:47,  1.96s/it]predicting train subjects:  16%|█▋        | 47/285 [01:27<07:29,  1.89s/it]predicting train subjects:  17%|█▋        | 48/285 [01:29<07:33,  1.91s/it]predicting train subjects:  17%|█▋        | 49/285 [01:31<07:58,  2.03s/it]predicting train subjects:  18%|█▊        | 50/285 [01:33<07:53,  2.02s/it]predicting train subjects:  18%|█▊        | 51/285 [01:35<07:57,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:37<07:31,  1.94s/it]predicting train subjects:  19%|█▊        | 53/285 [01:39<07:27,  1.93s/it]predicting train subjects:  19%|█▉        | 54/285 [01:41<07:42,  2.00s/it]predicting train subjects:  19%|█▉        | 55/285 [01:43<07:18,  1.90s/it]predicting train subjects:  20%|█▉        | 56/285 [01:45<07:17,  1.91s/it]predicting train subjects:  20%|██        | 57/285 [01:46<07:05,  1.87s/it]predicting train subjects:  20%|██        | 58/285 [01:48<07:04,  1.87s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:22,  1.96s/it]predicting train subjects:  21%|██        | 60/285 [01:53<07:32,  2.01s/it]predicting train subjects:  21%|██▏       | 61/285 [01:54<07:09,  1.92s/it]predicting train subjects:  22%|██▏       | 62/285 [01:56<07:03,  1.90s/it]predicting train subjects:  22%|██▏       | 63/285 [01:58<06:59,  1.89s/it]predicting train subjects:  22%|██▏       | 64/285 [02:00<06:54,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:02<06:53,  1.88s/it]predicting train subjects:  23%|██▎       | 66/285 [02:04<06:50,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<06:54,  1.90s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:46,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:43,  1.87s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:38,  1.85s/it]predicting train subjects:  25%|██▍       | 71/285 [02:13<06:42,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:15<06:29,  1.83s/it]predicting train subjects:  26%|██▌       | 73/285 [02:17<06:32,  1.85s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:25,  1.83s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:33,  1.87s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:32,  1.88s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:22,  1.84s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:15,  1.82s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:18,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:22,  1.87s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<06:16,  1.85s/it]predicting train subjects:  29%|██▉       | 83/285 [02:35<06:13,  1.85s/it]predicting train subjects:  29%|██▉       | 84/285 [02:37<06:00,  1.79s/it]predicting train subjects:  30%|██▉       | 85/285 [02:39<06:04,  1.82s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:09,  1.85s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:06,  1.85s/it]predicting train subjects:  31%|███       | 88/285 [02:44<05:57,  1.81s/it]predicting train subjects:  31%|███       | 89/285 [02:46<06:04,  1.86s/it]predicting train subjects:  32%|███▏      | 90/285 [02:48<06:06,  1.88s/it]predicting train subjects:  32%|███▏      | 91/285 [02:50<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:52<05:58,  1.86s/it]predicting train subjects:  33%|███▎      | 93/285 [02:53<05:50,  1.83s/it]predicting train subjects:  33%|███▎      | 94/285 [02:55<05:55,  1.86s/it]predicting train subjects:  33%|███▎      | 95/285 [02:57<05:55,  1.87s/it]predicting train subjects:  34%|███▎      | 96/285 [02:59<05:53,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [03:01<05:55,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [03:03<05:55,  1.90s/it]predicting train subjects:  35%|███▍      | 99/285 [03:05<05:50,  1.88s/it]predicting train subjects:  35%|███▌      | 100/285 [03:07<05:52,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:08<05:43,  1.87s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:48,  1.90s/it]predicting train subjects:  36%|███▌      | 103/285 [03:12<05:35,  1.84s/it]predicting train subjects:  36%|███▋      | 104/285 [03:14<05:33,  1.84s/it]predicting train subjects:  37%|███▋      | 105/285 [03:16<05:33,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:18<05:22,  1.80s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:24,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:21<05:19,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:23<05:21,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:25<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:27<05:19,  1.83s/it]predicting train subjects:  39%|███▉      | 112/285 [03:29<05:18,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:31<05:21,  1.87s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:10,  1.83s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:10,  1.84s/it]predicting train subjects:  41%|████      | 117/285 [03:38<05:04,  1.81s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<04:58,  1.79s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<05:01,  1.82s/it]predicting train subjects:  42%|████▏     | 120/285 [03:43<04:55,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:45<04:47,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:34,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:48<04:25,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:22,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:51<04:16,  1.60s/it]predicting train subjects:  44%|████▍     | 126/285 [03:53<04:16,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:54<04:09,  1.58s/it]predicting train subjects:  45%|████▍     | 128/285 [03:56<04:12,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [03:57<04:09,  1.60s/it]predicting train subjects:  46%|████▌     | 130/285 [03:59<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [04:01<04:06,  1.60s/it]predicting train subjects:  46%|████▋     | 132/285 [04:02<04:10,  1.64s/it]predicting train subjects:  47%|████▋     | 133/285 [04:04<04:08,  1.64s/it]predicting train subjects:  47%|████▋     | 134/285 [04:06<04:06,  1.63s/it]predicting train subjects:  47%|████▋     | 135/285 [04:07<04:02,  1.61s/it]predicting train subjects:  48%|████▊     | 136/285 [04:09<03:55,  1.58s/it]predicting train subjects:  48%|████▊     | 137/285 [04:10<04:01,  1.63s/it]predicting train subjects:  48%|████▊     | 138/285 [04:12<03:56,  1.61s/it]predicting train subjects:  49%|████▉     | 139/285 [04:14<03:55,  1.62s/it]predicting train subjects:  49%|████▉     | 140/285 [04:15<04:00,  1.66s/it]predicting train subjects:  49%|████▉     | 141/285 [04:17<03:50,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:18<03:51,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:20<03:45,  1.59s/it]predicting train subjects:  51%|█████     | 144/285 [04:22<03:47,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:23<03:44,  1.61s/it]predicting train subjects:  51%|█████     | 146/285 [04:25<03:50,  1.66s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:27<03:42,  1.61s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:28<03:49,  1.68s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:30<03:44,  1.65s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:32<03:40,  1.64s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:33<03:43,  1.66s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:35<03:37,  1.64s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:36<03:31,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:38<03:30,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:40<03:26,  1.59s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:41<03:29,  1.62s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:43<03:27,  1.62s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:44<03:24,  1.61s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:46<03:19,  1.58s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:48<03:17,  1.58s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:49<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:51<03:15,  1.59s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:52<03:19,  1.63s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:54<03:17,  1.63s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:56<03:16,  1.63s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:57<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:59<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:01<03:08,  1.61s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:02<03:06,  1.61s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:04<02:59,  1.56s/it]predicting train subjects:  60%|██████    | 171/285 [05:05<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [05:07<02:54,  1.55s/it]predicting train subjects:  61%|██████    | 173/285 [05:08<02:52,  1.54s/it]predicting train subjects:  61%|██████    | 174/285 [05:10<02:53,  1.57s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<02:55,  1.60s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:13<02:55,  1.61s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<02:52,  1.60s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:16<02:49,  1.59s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:45,  1.56s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:20<02:55,  1.67s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:21<02:55,  1.69s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:23<02:54,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:25<02:44,  1.62s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:26<02:41,  1.60s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:28<02:34,  1.55s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:29<02:44,  1.66s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:32<02:53,  1.77s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:33<02:55,  1.81s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:35<02:44,  1.71s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:36<02:37,  1.66s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:38<02:39,  1.70s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:40<02:41,  1.73s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:42<02:33,  1.67s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:43<02:29,  1.65s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:45<02:22,  1.59s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:47<02:30,  1.69s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:49<02:38,  1.80s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:50<02:38,  1.83s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:52<02:27,  1.71s/it]predicting train subjects:  70%|███████   | 200/285 [05:53<02:19,  1.64s/it]predicting train subjects:  71%|███████   | 201/285 [05:55<02:23,  1.71s/it]predicting train subjects:  71%|███████   | 202/285 [05:57<02:23,  1.73s/it]predicting train subjects:  71%|███████   | 203/285 [05:59<02:23,  1.76s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:00<02:16,  1.69s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:02<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:03<02:03,  1.56s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:05<02:09,  1.67s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:07<02:12,  1.72s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:09<02:13,  1.76s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:10<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:12<02:02,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:14<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:15<02:01,  1.69s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:17<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:19<02:00,  1.72s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:20<01:54,  1.66s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:22<01:59,  1.76s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:24<02:01,  1.81s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:26<01:59,  1.82s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:28<01:52,  1.73s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:29<01:46,  1.67s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:31<01:47,  1.70s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:32<01:41,  1.63s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:34<01:36,  1.59s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:35<01:32,  1.54s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:37<01:40,  1.70s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:39<01:41,  1.76s/it]predicting train subjects:  80%|████████  | 228/285 [06:41<01:41,  1.78s/it]predicting train subjects:  80%|████████  | 229/285 [06:43<01:39,  1.77s/it]predicting train subjects:  81%|████████  | 230/285 [06:44<01:32,  1.68s/it]predicting train subjects:  81%|████████  | 231/285 [06:46<01:28,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:48<01:28,  1.66s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:49<01:23,  1.61s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:51<01:26,  1.70s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:53<01:21,  1.64s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:54<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:56<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:58<01:24,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:00<01:21,  1.77s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:01<01:15,  1.68s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:03<01:12,  1.64s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:04<01:09,  1.61s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:06<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:08<01:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:09<01:04,  1.60s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:11<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:13<01:06,  1.76s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:15<01:04,  1.75s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:16<01:01,  1.70s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:18<00:58,  1.67s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:20<00:56,  1.66s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:21<00:53,  1.62s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:23<00:55,  1.75s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:25<00:54,  1.77s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:27<00:52,  1.76s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:28<00:48,  1.66s/it]predicting train subjects:  90%|█████████ | 257/285 [07:30<00:46,  1.65s/it]predicting train subjects:  91%|█████████ | 258/285 [07:32<00:46,  1.71s/it]predicting train subjects:  91%|█████████ | 259/285 [07:33<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [07:35<00:40,  1.63s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:36<00:38,  1.61s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:38<00:36,  1.59s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:39<00:34,  1.56s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:41<00:35,  1.68s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:43<00:34,  1.74s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:45<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:46<00:28,  1.61s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:48<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:50<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:51<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:53<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:55<00:21,  1.64s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:56<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:58<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:00<00:16,  1.69s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:01<00:15,  1.72s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:03<00:13,  1.65s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:04<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:06<00:09,  1.63s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:08<00:07,  1.58s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:09<00:06,  1.55s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:11<00:04,  1.53s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:13<00:03,  1.67s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:14<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:16<00:00,  1.77s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:02,  1.70s/it]Loading train:   1%|          | 2/285 [00:02<07:21,  1.56s/it]Loading train:   1%|          | 3/285 [00:04<07:09,  1.52s/it]Loading train:   1%|▏         | 4/285 [00:05<06:39,  1.42s/it]Loading train:   2%|▏         | 5/285 [00:07<06:50,  1.47s/it]Loading train:   2%|▏         | 6/285 [00:08<06:39,  1.43s/it]Loading train:   2%|▏         | 7/285 [00:10<06:59,  1.51s/it]Loading train:   3%|▎         | 8/285 [00:11<06:52,  1.49s/it]Loading train:   3%|▎         | 9/285 [00:13<07:10,  1.56s/it]Loading train:   4%|▎         | 10/285 [00:14<06:42,  1.46s/it]Loading train:   4%|▍         | 11/285 [00:15<06:20,  1.39s/it]Loading train:   4%|▍         | 12/285 [00:17<06:04,  1.34s/it]Loading train:   5%|▍         | 13/285 [00:17<05:34,  1.23s/it]Loading train:   5%|▍         | 14/285 [00:19<05:30,  1.22s/it]Loading train:   5%|▌         | 15/285 [00:20<05:33,  1.23s/it]Loading train:   6%|▌         | 16/285 [00:21<05:31,  1.23s/it]Loading train:   6%|▌         | 17/285 [00:22<05:26,  1.22s/it]Loading train:   6%|▋         | 18/285 [00:24<05:30,  1.24s/it]Loading train:   7%|▋         | 19/285 [00:25<05:11,  1.17s/it]Loading train:   7%|▋         | 20/285 [00:27<06:09,  1.39s/it]Loading train:   7%|▋         | 21/285 [00:28<06:05,  1.39s/it]Loading train:   8%|▊         | 22/285 [00:29<05:41,  1.30s/it]Loading train:   8%|▊         | 23/285 [00:30<05:36,  1.28s/it]Loading train:   8%|▊         | 24/285 [00:31<05:07,  1.18s/it]Loading train:   9%|▉         | 25/285 [00:32<04:59,  1.15s/it]Loading train:   9%|▉         | 26/285 [00:34<05:02,  1.17s/it]Loading train:   9%|▉         | 27/285 [00:34<04:46,  1.11s/it]Loading train:  10%|▉         | 28/285 [00:36<04:42,  1.10s/it]Loading train:  10%|█         | 29/285 [00:37<04:47,  1.12s/it]Loading train:  11%|█         | 30/285 [00:38<04:51,  1.14s/it]Loading train:  11%|█         | 31/285 [00:39<04:58,  1.17s/it]Loading train:  11%|█         | 32/285 [00:40<04:49,  1.15s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:51,  1.15s/it]Loading train:  12%|█▏        | 34/285 [00:43<04:44,  1.13s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:50,  1.16s/it]Loading train:  13%|█▎        | 36/285 [00:45<04:57,  1.19s/it]Loading train:  13%|█▎        | 37/285 [00:46<05:07,  1.24s/it]Loading train:  13%|█▎        | 38/285 [00:48<05:02,  1.23s/it]Loading train:  14%|█▎        | 39/285 [00:49<04:53,  1.19s/it]Loading train:  14%|█▍        | 40/285 [00:50<04:50,  1.19s/it]Loading train:  14%|█▍        | 41/285 [00:51<04:48,  1.18s/it]Loading train:  15%|█▍        | 42/285 [00:52<04:36,  1.14s/it]Loading train:  15%|█▌        | 43/285 [00:53<04:39,  1.15s/it]Loading train:  15%|█▌        | 44/285 [00:54<04:38,  1.15s/it]Loading train:  16%|█▌        | 45/285 [00:56<04:39,  1.16s/it]Loading train:  16%|█▌        | 46/285 [00:57<04:42,  1.18s/it]Loading train:  16%|█▋        | 47/285 [00:58<04:47,  1.21s/it]Loading train:  17%|█▋        | 48/285 [00:59<04:43,  1.20s/it]Loading train:  17%|█▋        | 49/285 [01:00<04:44,  1.20s/it]Loading train:  18%|█▊        | 50/285 [01:02<04:38,  1.18s/it]Loading train:  18%|█▊        | 51/285 [01:03<04:50,  1.24s/it]Loading train:  18%|█▊        | 52/285 [01:04<04:41,  1.21s/it]Loading train:  19%|█▊        | 53/285 [01:05<04:46,  1.24s/it]Loading train:  19%|█▉        | 54/285 [01:07<04:43,  1.23s/it]Loading train:  19%|█▉        | 55/285 [01:08<04:37,  1.21s/it]Loading train:  20%|█▉        | 56/285 [01:09<04:31,  1.19s/it]Loading train:  20%|██        | 57/285 [01:10<04:23,  1.16s/it]Loading train:  20%|██        | 58/285 [01:11<04:18,  1.14s/it]Loading train:  21%|██        | 59/285 [01:12<04:17,  1.14s/it]Loading train:  21%|██        | 60/285 [01:13<04:21,  1.16s/it]Loading train:  21%|██▏       | 61/285 [01:15<04:22,  1.17s/it]Loading train:  22%|██▏       | 62/285 [01:16<04:22,  1.18s/it]Loading train:  22%|██▏       | 63/285 [01:17<04:18,  1.17s/it]Loading train:  22%|██▏       | 64/285 [01:18<04:37,  1.26s/it]Loading train:  23%|██▎       | 65/285 [01:20<04:52,  1.33s/it]Loading train:  23%|██▎       | 66/285 [01:21<04:59,  1.37s/it]Loading train:  24%|██▎       | 67/285 [01:22<04:39,  1.28s/it]Loading train:  24%|██▍       | 68/285 [01:24<04:28,  1.24s/it]Loading train:  24%|██▍       | 69/285 [01:25<04:23,  1.22s/it]Loading train:  25%|██▍       | 70/285 [01:26<04:29,  1.25s/it]Loading train:  25%|██▍       | 71/285 [01:28<04:42,  1.32s/it]Loading train:  25%|██▌       | 72/285 [01:29<04:21,  1.23s/it]Loading train:  26%|██▌       | 73/285 [01:30<04:16,  1.21s/it]Loading train:  26%|██▌       | 74/285 [01:31<04:06,  1.17s/it]Loading train:  26%|██▋       | 75/285 [01:32<04:05,  1.17s/it]Loading train:  27%|██▋       | 76/285 [01:33<03:59,  1.14s/it]Loading train:  27%|██▋       | 77/285 [01:34<03:55,  1.13s/it]Loading train:  27%|██▋       | 78/285 [01:35<03:45,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:37<03:59,  1.16s/it]Loading train:  28%|██▊       | 80/285 [01:38<03:56,  1.15s/it]Loading train:  28%|██▊       | 81/285 [01:39<03:51,  1.14s/it]Loading train:  29%|██▉       | 82/285 [01:40<03:48,  1.12s/it]Loading train:  29%|██▉       | 83/285 [01:41<03:36,  1.07s/it]Loading train:  29%|██▉       | 84/285 [01:42<03:25,  1.02s/it]Loading train:  30%|██▉       | 85/285 [01:43<03:35,  1.08s/it]Loading train:  30%|███       | 86/285 [01:44<03:44,  1.13s/it]Loading train:  31%|███       | 87/285 [01:45<03:47,  1.15s/it]Loading train:  31%|███       | 88/285 [01:47<03:45,  1.14s/it]Loading train:  31%|███       | 89/285 [01:48<03:48,  1.17s/it]Loading train:  32%|███▏      | 90/285 [01:49<03:44,  1.15s/it]Loading train:  32%|███▏      | 91/285 [01:50<03:37,  1.12s/it]Loading train:  32%|███▏      | 92/285 [01:51<03:40,  1.14s/it]Loading train:  33%|███▎      | 93/285 [01:52<03:34,  1.12s/it]Loading train:  33%|███▎      | 94/285 [01:53<03:41,  1.16s/it]Loading train:  33%|███▎      | 95/285 [01:55<03:46,  1.19s/it]Loading train:  34%|███▎      | 96/285 [01:56<03:44,  1.19s/it]Loading train:  34%|███▍      | 97/285 [01:57<03:47,  1.21s/it]Loading train:  34%|███▍      | 98/285 [01:58<03:52,  1.24s/it]Loading train:  35%|███▍      | 99/285 [01:59<03:39,  1.18s/it]Loading train:  35%|███▌      | 100/285 [02:01<03:33,  1.15s/it]Loading train:  35%|███▌      | 101/285 [02:02<03:31,  1.15s/it]Loading train:  36%|███▌      | 102/285 [02:03<03:30,  1.15s/it]Loading train:  36%|███▌      | 103/285 [02:04<03:24,  1.12s/it]Loading train:  36%|███▋      | 104/285 [02:05<03:21,  1.11s/it]Loading train:  37%|███▋      | 105/285 [02:06<03:19,  1.11s/it]Loading train:  37%|███▋      | 106/285 [02:07<03:11,  1.07s/it]Loading train:  38%|███▊      | 107/285 [02:08<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:09<03:07,  1.06s/it]Loading train:  38%|███▊      | 109/285 [02:11<03:20,  1.14s/it]Loading train:  39%|███▊      | 110/285 [02:12<03:21,  1.15s/it]Loading train:  39%|███▉      | 111/285 [02:13<03:15,  1.13s/it]Loading train:  39%|███▉      | 112/285 [02:14<03:16,  1.13s/it]Loading train:  40%|███▉      | 113/285 [02:15<03:16,  1.14s/it]Loading train:  40%|████      | 114/285 [02:16<03:15,  1.14s/it]Loading train:  40%|████      | 115/285 [02:17<03:08,  1.11s/it]Loading train:  41%|████      | 116/285 [02:18<03:07,  1.11s/it]Loading train:  41%|████      | 117/285 [02:19<03:03,  1.09s/it]Loading train:  41%|████▏     | 118/285 [02:21<03:03,  1.10s/it]Loading train:  42%|████▏     | 119/285 [02:22<03:09,  1.14s/it]Loading train:  42%|████▏     | 120/285 [02:23<03:01,  1.10s/it]Loading train:  42%|████▏     | 121/285 [02:24<03:14,  1.19s/it]Loading train:  43%|████▎     | 122/285 [02:26<03:23,  1.25s/it]Loading train:  43%|████▎     | 123/285 [02:27<03:18,  1.23s/it]Loading train:  44%|████▎     | 124/285 [02:28<03:12,  1.19s/it]Loading train:  44%|████▍     | 125/285 [02:29<03:03,  1.14s/it]Loading train:  44%|████▍     | 126/285 [02:30<02:47,  1.05s/it]Loading train:  45%|████▍     | 127/285 [02:31<02:44,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:32<02:41,  1.03s/it]Loading train:  45%|████▌     | 129/285 [02:33<02:47,  1.08s/it]Loading train:  46%|████▌     | 130/285 [02:34<02:48,  1.08s/it]Loading train:  46%|████▌     | 131/285 [02:35<02:41,  1.05s/it]Loading train:  46%|████▋     | 132/285 [02:36<02:41,  1.06s/it]Loading train:  47%|████▋     | 133/285 [02:37<02:43,  1.08s/it]Loading train:  47%|████▋     | 134/285 [02:38<02:43,  1.08s/it]Loading train:  47%|████▋     | 135/285 [02:40<02:50,  1.14s/it]Loading train:  48%|████▊     | 136/285 [02:41<02:45,  1.11s/it]Loading train:  48%|████▊     | 137/285 [02:42<02:45,  1.12s/it]Loading train:  48%|████▊     | 138/285 [02:43<02:34,  1.05s/it]Loading train:  49%|████▉     | 139/285 [02:44<02:30,  1.03s/it]Loading train:  49%|████▉     | 140/285 [02:45<02:30,  1.04s/it]Loading train:  49%|████▉     | 141/285 [02:46<02:26,  1.02s/it]Loading train:  50%|████▉     | 142/285 [02:47<02:26,  1.02s/it]Loading train:  50%|█████     | 143/285 [02:48<02:30,  1.06s/it]Loading train:  51%|█████     | 144/285 [02:49<02:29,  1.06s/it]Loading train:  51%|█████     | 145/285 [02:50<02:23,  1.02s/it]Loading train:  51%|█████     | 146/285 [02:51<02:27,  1.06s/it]Loading train:  52%|█████▏    | 147/285 [02:52<02:24,  1.04s/it]Loading train:  52%|█████▏    | 148/285 [02:53<02:23,  1.05s/it]Loading train:  52%|█████▏    | 149/285 [02:54<02:19,  1.03s/it]Loading train:  53%|█████▎    | 150/285 [02:55<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:56<02:21,  1.06s/it]Loading train:  53%|█████▎    | 152/285 [02:57<02:19,  1.05s/it]Loading train:  54%|█████▎    | 153/285 [02:58<02:13,  1.01s/it]Loading train:  54%|█████▍    | 154/285 [02:59<02:15,  1.03s/it]Loading train:  54%|█████▍    | 155/285 [03:00<02:15,  1.05s/it]Loading train:  55%|█████▍    | 156/285 [03:01<02:08,  1.00it/s]Loading train:  55%|█████▌    | 157/285 [03:02<02:00,  1.06it/s]Loading train:  55%|█████▌    | 158/285 [03:03<02:02,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [03:04<02:02,  1.03it/s]Loading train:  56%|█████▌    | 160/285 [03:05<02:11,  1.05s/it]Loading train:  56%|█████▋    | 161/285 [03:07<02:19,  1.13s/it]Loading train:  57%|█████▋    | 162/285 [03:07<02:05,  1.02s/it]Loading train:  57%|█████▋    | 163/285 [03:08<01:53,  1.07it/s]Loading train:  58%|█████▊    | 164/285 [03:09<01:44,  1.16it/s]Loading train:  58%|█████▊    | 165/285 [03:09<01:35,  1.25it/s]Loading train:  58%|█████▊    | 166/285 [03:10<01:35,  1.24it/s]Loading train:  59%|█████▊    | 167/285 [03:11<01:34,  1.25it/s]Loading train:  59%|█████▉    | 168/285 [03:12<01:30,  1.29it/s]Loading train:  59%|█████▉    | 169/285 [03:13<01:32,  1.25it/s]Loading train:  60%|█████▉    | 170/285 [03:13<01:31,  1.26it/s]Loading train:  60%|██████    | 171/285 [03:14<01:29,  1.28it/s]Loading train:  60%|██████    | 172/285 [03:15<01:29,  1.26it/s]Loading train:  61%|██████    | 173/285 [03:16<01:31,  1.22it/s]Loading train:  61%|██████    | 174/285 [03:17<01:32,  1.20it/s]Loading train:  61%|██████▏   | 175/285 [03:17<01:30,  1.22it/s]Loading train:  62%|██████▏   | 176/285 [03:18<01:26,  1.26it/s]Loading train:  62%|██████▏   | 177/285 [03:19<01:21,  1.33it/s]Loading train:  62%|██████▏   | 178/285 [03:20<01:21,  1.32it/s]Loading train:  63%|██████▎   | 179/285 [03:20<01:20,  1.32it/s]Loading train:  63%|██████▎   | 180/285 [03:21<01:25,  1.22it/s]Loading train:  64%|██████▎   | 181/285 [03:22<01:27,  1.19it/s]Loading train:  64%|██████▍   | 182/285 [03:23<01:23,  1.24it/s]Loading train:  64%|██████▍   | 183/285 [03:24<01:23,  1.22it/s]Loading train:  65%|██████▍   | 184/285 [03:25<01:23,  1.22it/s]Loading train:  65%|██████▍   | 185/285 [03:25<01:19,  1.26it/s]Loading train:  65%|██████▌   | 186/285 [03:26<01:23,  1.19it/s]Loading train:  66%|██████▌   | 187/285 [03:27<01:24,  1.16it/s]Loading train:  66%|██████▌   | 188/285 [03:28<01:25,  1.14it/s]Loading train:  66%|██████▋   | 189/285 [03:29<01:19,  1.21it/s]Loading train:  67%|██████▋   | 190/285 [03:30<01:15,  1.26it/s]Loading train:  67%|██████▋   | 191/285 [03:30<01:15,  1.24it/s]Loading train:  67%|██████▋   | 192/285 [03:31<01:16,  1.22it/s]Loading train:  68%|██████▊   | 193/285 [03:32<01:08,  1.34it/s]Loading train:  68%|██████▊   | 194/285 [03:33<01:06,  1.37it/s]Loading train:  68%|██████▊   | 195/285 [03:33<01:01,  1.46it/s]Loading train:  69%|██████▉   | 196/285 [03:34<01:05,  1.36it/s]Loading train:  69%|██████▉   | 197/285 [03:35<01:05,  1.35it/s]Loading train:  69%|██████▉   | 198/285 [03:36<01:09,  1.25it/s]Loading train:  70%|██████▉   | 199/285 [03:36<01:04,  1.33it/s]Loading train:  70%|███████   | 200/285 [03:37<01:01,  1.38it/s]Loading train:  71%|███████   | 201/285 [03:38<01:03,  1.33it/s]Loading train:  71%|███████   | 202/285 [03:38<01:01,  1.35it/s]Loading train:  71%|███████   | 203/285 [03:39<01:01,  1.34it/s]Loading train:  72%|███████▏  | 204/285 [03:40<00:57,  1.41it/s]Loading train:  72%|███████▏  | 205/285 [03:40<00:54,  1.46it/s]Loading train:  72%|███████▏  | 206/285 [03:41<00:52,  1.51it/s]Loading train:  73%|███████▎  | 207/285 [03:42<00:55,  1.41it/s]Loading train:  73%|███████▎  | 208/285 [03:43<00:57,  1.35it/s]Loading train:  73%|███████▎  | 209/285 [03:44<00:59,  1.28it/s]Loading train:  74%|███████▎  | 210/285 [03:44<00:54,  1.37it/s]Loading train:  74%|███████▍  | 211/285 [03:45<00:52,  1.40it/s]Loading train:  74%|███████▍  | 212/285 [03:46<00:52,  1.39it/s]Loading train:  75%|███████▍  | 213/285 [03:46<00:52,  1.38it/s]Loading train:  75%|███████▌  | 214/285 [03:47<00:48,  1.47it/s]Loading train:  75%|███████▌  | 215/285 [03:48<00:51,  1.36it/s]Loading train:  76%|███████▌  | 216/285 [03:48<00:48,  1.41it/s]Loading train:  76%|███████▌  | 217/285 [03:49<00:51,  1.32it/s]Loading train:  76%|███████▋  | 218/285 [03:50<00:50,  1.32it/s]Loading train:  77%|███████▋  | 219/285 [03:51<00:50,  1.30it/s]Loading train:  77%|███████▋  | 220/285 [03:52<00:47,  1.37it/s]Loading train:  78%|███████▊  | 221/285 [03:52<00:45,  1.42it/s]Loading train:  78%|███████▊  | 222/285 [03:53<00:44,  1.41it/s]Loading train:  78%|███████▊  | 223/285 [03:53<00:41,  1.51it/s]Loading train:  79%|███████▊  | 224/285 [03:54<00:40,  1.51it/s]Loading train:  79%|███████▉  | 225/285 [03:55<00:39,  1.53it/s]Loading train:  79%|███████▉  | 226/285 [03:56<00:42,  1.38it/s]Loading train:  80%|███████▉  | 227/285 [03:56<00:42,  1.36it/s]Loading train:  80%|████████  | 228/285 [03:57<00:43,  1.32it/s]Loading train:  80%|████████  | 229/285 [03:58<00:41,  1.35it/s]Loading train:  81%|████████  | 230/285 [03:59<00:40,  1.37it/s]Loading train:  81%|████████  | 231/285 [03:59<00:38,  1.42it/s]Loading train:  81%|████████▏ | 232/285 [04:00<00:38,  1.38it/s]Loading train:  82%|████████▏ | 233/285 [04:01<00:37,  1.38it/s]Loading train:  82%|████████▏ | 234/285 [04:02<00:39,  1.28it/s]Loading train:  82%|████████▏ | 235/285 [04:02<00:36,  1.37it/s]Loading train:  83%|████████▎ | 236/285 [04:03<00:37,  1.30it/s]Loading train:  83%|████████▎ | 237/285 [04:04<00:37,  1.28it/s]Loading train:  84%|████████▎ | 238/285 [04:05<00:37,  1.24it/s]Loading train:  84%|████████▍ | 239/285 [04:06<00:36,  1.27it/s]Loading train:  84%|████████▍ | 240/285 [04:06<00:33,  1.36it/s]Loading train:  85%|████████▍ | 241/285 [04:07<00:31,  1.39it/s]Loading train:  85%|████████▍ | 242/285 [04:07<00:29,  1.45it/s]Loading train:  85%|████████▌ | 243/285 [04:08<00:28,  1.45it/s]Loading train:  86%|████████▌ | 244/285 [04:09<00:29,  1.38it/s]Loading train:  86%|████████▌ | 245/285 [04:10<00:27,  1.43it/s]Loading train:  86%|████████▋ | 246/285 [04:10<00:28,  1.36it/s]Loading train:  87%|████████▋ | 247/285 [04:11<00:28,  1.33it/s]Loading train:  87%|████████▋ | 248/285 [04:12<00:27,  1.33it/s]Loading train:  87%|████████▋ | 249/285 [04:13<00:25,  1.39it/s]Loading train:  88%|████████▊ | 250/285 [04:13<00:24,  1.41it/s]Loading train:  88%|████████▊ | 251/285 [04:14<00:23,  1.45it/s]Loading train:  88%|████████▊ | 252/285 [04:15<00:22,  1.46it/s]Loading train:  89%|████████▉ | 253/285 [04:15<00:23,  1.37it/s]Loading train:  89%|████████▉ | 254/285 [04:16<00:23,  1.33it/s]Loading train:  89%|████████▉ | 255/285 [04:17<00:22,  1.32it/s]Loading train:  90%|████████▉ | 256/285 [04:18<00:21,  1.38it/s]Loading train:  90%|█████████ | 257/285 [04:18<00:19,  1.43it/s]Loading train:  91%|█████████ | 258/285 [04:19<00:19,  1.35it/s]Loading train:  91%|█████████ | 259/285 [04:20<00:18,  1.37it/s]Loading train:  91%|█████████ | 260/285 [04:20<00:17,  1.44it/s]Loading train:  92%|█████████▏| 261/285 [04:21<00:16,  1.49it/s]Loading train:  92%|█████████▏| 262/285 [04:22<00:15,  1.53it/s]Loading train:  92%|█████████▏| 263/285 [04:22<00:14,  1.56it/s]Loading train:  93%|█████████▎| 264/285 [04:23<00:14,  1.44it/s]Loading train:  93%|█████████▎| 265/285 [04:24<00:14,  1.35it/s]Loading train:  93%|█████████▎| 266/285 [04:25<00:13,  1.46it/s]Loading train:  94%|█████████▎| 267/285 [04:25<00:11,  1.52it/s]Loading train:  94%|█████████▍| 268/285 [04:26<00:12,  1.40it/s]Loading train:  94%|█████████▍| 269/285 [04:27<00:11,  1.35it/s]Loading train:  95%|█████████▍| 270/285 [04:27<00:10,  1.42it/s]Loading train:  95%|█████████▌| 271/285 [04:28<00:09,  1.43it/s]Loading train:  95%|█████████▌| 272/285 [04:29<00:09,  1.40it/s]Loading train:  96%|█████████▌| 273/285 [04:29<00:08,  1.44it/s]Loading train:  96%|█████████▌| 274/285 [04:30<00:07,  1.47it/s]Loading train:  96%|█████████▋| 275/285 [04:31<00:07,  1.35it/s]Loading train:  97%|█████████▋| 276/285 [04:32<00:06,  1.31it/s]Loading train:  97%|█████████▋| 277/285 [04:32<00:05,  1.39it/s]Loading train:  98%|█████████▊| 278/285 [04:33<00:05,  1.37it/s]Loading train:  98%|█████████▊| 279/285 [04:34<00:04,  1.32it/s]Loading train:  98%|█████████▊| 280/285 [04:35<00:03,  1.37it/s]Loading train:  99%|█████████▊| 281/285 [04:35<00:02,  1.42it/s]Loading train:  99%|█████████▉| 282/285 [04:36<00:02,  1.40it/s]Loading train:  99%|█████████▉| 283/285 [04:37<00:01,  1.29it/s]Loading train: 100%|█████████▉| 284/285 [04:38<00:00,  1.28it/s]Loading train: 100%|██████████| 285/285 [04:39<00:00,  1.22it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   5%|▍         | 13/285 [00:00<00:02, 127.17it/s]concatenating: train:   9%|▉         | 27/285 [00:00<00:01, 129.31it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:01, 141.13it/s]concatenating: train:  27%|██▋       | 77/285 [00:00<00:01, 169.54it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 199.56it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:00, 225.09it/s]concatenating: train:  63%|██████▎   | 179/285 [00:00<00:00, 249.33it/s]concatenating: train:  75%|███████▌  | 214/285 [00:00<00:00, 271.43it/s]concatenating: train:  88%|████████▊ | 250/285 [00:00<00:00, 292.61it/s]concatenating: train: 100%|██████████| 285/285 [00:00<00:00, 285.61it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.24s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.22s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.17s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 130.75it/s]2019-07-11 07:24:06.071060: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:24:06.071215: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:24:06.071234: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:24:06.071244: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:24:06.071693: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  4.96it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.82it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.41it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.88it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  5.89it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.58it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.70it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.35it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.77it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.33it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.81it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.21it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.58it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.10it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.43it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.52it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.57it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.40it/s]
Epoch 00053: val_mDice did not improve from 0.63654
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [0.6452403411518928, 0.4824064690307532, 0.44942210606356575, 0.45314906695701557, 0.45090071748754834, 0.4664111164029084, 0.4532417828144308, 0.4405111254260527, 0.47276036832585683, 0.4491291831991526, 0.4914450652106514, 0.4663698360240659, 0.44350819614346465, 0.4599633812904358, 0.4729291180658607, 0.45466364995061354, 0.4489066684046271, 0.47557049889804265, 0.4493492958265976, 0.44912263101705624, 0.44801484206535297, 0.4682375665483528, 0.4513694157813514, 0.5078099569794852, 0.44969638899051945, 0.48252238907627554, 0.4700528276699215, 0.4599630209986724, 0.4463967238058591, 0.44341245576656063, 0.46931908783299964, 0.4505431082661591, 0.47629131518262724, 0.48908618974952056, 0.464871773506676, 0.4708959064004142, 0.45077125819701724, 0.459229738352685, 0.4670891958242022, 0.45799900699594165, 0.4625119477010972, 0.46180303636209924, 0.44070251827133433, 0.484545624788913, 0.44504734224447323, 0.44120972782539924, 0.438312680694644, 0.45281597156098435, 0.4554315455798996, 0.4551085340244144, 0.4388345230225078, 0.44955405909255897, 0.4701169689274367], 'val_acc': [0.9406796660503196, 0.9530263406604362, 0.9532556667008214, 0.9533775655250976, 0.949774393489241, 0.9528362904181028, 0.9542205337039585, 0.952274302863542, 0.952704034371083, 0.9520222284940368, 0.9543940488186629, 0.949328107207847, 0.9557555963873198, 0.9528383402851041, 0.9522928945179092, 0.954040774419987, 0.9527474265524795, 0.9517887750817411, 0.9550428224009508, 0.9518466288816996, 0.9526337987883797, 0.9561088970919561, 0.9520036458303143, 0.9534230235568638, 0.9545593654643224, 0.9530635179754076, 0.9536730370708018, 0.9529746734230212, 0.9545779434662292, 0.9546089325537229, 0.9533383033795064, 0.954962214944083, 0.9547576954244902, 0.9540118531807841, 0.9536089707353261, 0.9532288133099093, 0.9523755325285416, 0.9541936799800596, 0.9504685644996899, 0.9551585016969862, 0.9536151476412512, 0.9535056752199568, 0.9542721636468472, 0.9553898812672279, 0.9544085424039617, 0.9547184509272016, 0.9522123053753176, 0.9544374456618752, 0.954925030303401, 0.9551233845716082, 0.9538920235367461, 0.9557535551779763, 0.9538052658129005], 'val_mDice': [0.5258380584210657, 0.6125527993260815, 0.6286161062437728, 0.6275482857027533, 0.6265948844355578, 0.6221674534195628, 0.6296816308405147, 0.6353537290455908, 0.6220567785827807, 0.6301193017533372, 0.6097047205743843, 0.6203099296079667, 0.6365392038276075, 0.6252795278027071, 0.6180411444029994, 0.6256442592796667, 0.6299568134979163, 0.6200647540598608, 0.6318794339062781, 0.632713549629936, 0.6337095678851591, 0.6237646444549774, 0.6300317894813069, 0.604246336321591, 0.6302128900362792, 0.6167863773900037, 0.6278146172368992, 0.6247808583621872, 0.6333831775121849, 0.6354902559818503, 0.6219337772390696, 0.6282735963107487, 0.6157551484400999, 0.6161563323196753, 0.6234056400187189, 0.621616823047233, 0.6299472967339628, 0.62506919932765, 0.6177113009564703, 0.627850533197712, 0.6234489059981021, 0.6257122132365264, 0.6336572156938095, 0.6190433522176476, 0.6318817774676744, 0.6335463530524483, 0.6354903901755476, 0.6276694469611738, 0.624960268675948, 0.6267360898369517, 0.6359763751482831, 0.6328063227610881, 0.6206934901589122], 'loss': [1.5452475817133013, 0.4277147749745958, 0.3790098185499901, 0.3557347025732207, 0.3387140560533855, 0.3281077112574235, 0.3185570033087683, 0.3097975470454765, 0.3029697873848702, 0.2973540233121797, 0.29288845404639274, 0.2872859744372227, 0.28334869658542505, 0.28177238023753104, 0.2770650883845713, 0.27502182245994666, 0.2700001586464572, 0.26737087937256043, 0.2656358887859565, 0.2626533334739301, 0.26146091306451735, 0.2574684973794984, 0.25635800449412266, 0.253974023750097, 0.2529433769154189, 0.25149941472152526, 0.2510560557224296, 0.24876663970808324, 0.2485968491065464, 0.24454061173027972, 0.24371702947730067, 0.2432016668597063, 0.24039644156381537, 0.24093894044007425, 0.23897038902613627, 0.23733791275488889, 0.23649517099852527, 0.23513449867185532, 0.23418830947466687, 0.2345307808399629, 0.23202692786986698, 0.2314916456232961, 0.2306996990094861, 0.2302815930921004, 0.22862931581196927, 0.22914873815885875, 0.22749621769382208, 0.2268697065942123, 0.22695741565923117, 0.2679410952737691, 0.23400658913462727, 0.2287043252124239, 0.22779455379095545], 'acc': [0.8195564782102995, 0.941362177752363, 0.9463988205627071, 0.9483683230628778, 0.9495621802669083, 0.9506417212451986, 0.9512140260309664, 0.9518313321287638, 0.9523609374111095, 0.9528205309075979, 0.9532140624412141, 0.953597117331246, 0.9538033697627337, 0.9539829923348141, 0.954382401728486, 0.9544027682145653, 0.9548372230357863, 0.954989154785133, 0.955095059971269, 0.9553562561467507, 0.9555027075604893, 0.9557010842287672, 0.9557972825805149, 0.9559888891467121, 0.956111208616431, 0.9562772766358647, 0.9562460585367926, 0.9564743225373614, 0.9564395618071244, 0.9566740911385182, 0.9566716141907466, 0.9567863998359328, 0.9570109402164058, 0.9569262442236391, 0.9571410156102698, 0.9571801509013669, 0.9573001158593897, 0.957300256967973, 0.9574848749617997, 0.957486105681985, 0.9575361974890809, 0.9576546904905826, 0.9577425295416744, 0.9576907257558239, 0.9578191494183385, 0.9578232978736969, 0.9579336739665484, 0.9580157127497756, 0.9579912394449138, 0.9548225187702146, 0.9574510567419786, 0.9577685520121892, 0.9578548394369603], 'mDice': [0.35903449945915084, 0.638214909740149, 0.6704809075217057, 0.6866784499015016, 0.6986252486618131, 0.7065274576613355, 0.7133450926236419, 0.7197919013544233, 0.7249623042105797, 0.729253473465469, 0.7326011516891932, 0.7368967816705154, 0.7399649311758504, 0.7411748919213794, 0.7447927183045598, 0.7463510123403443, 0.7502205064857547, 0.7523321135391707, 0.7536986673730734, 0.7560798228095413, 0.7570377940556614, 0.7601291104363146, 0.7610012055657462, 0.7630361737031627, 0.7637781345125546, 0.7649787556669966, 0.7653374012554985, 0.7672402223635133, 0.7672802611287075, 0.770517083257315, 0.771155193580352, 0.7716135555093802, 0.7738620629076098, 0.7734058158770735, 0.7749807864068854, 0.7763104913645168, 0.7770565289225521, 0.7781216032877317, 0.7789202005727756, 0.7786472554845972, 0.7806794280697075, 0.7811273432564848, 0.7817898870722075, 0.782085700308041, 0.7835307319948184, 0.7830208809207866, 0.7843976412117595, 0.7849209061648538, 0.7849804131944846, 0.7554871760924315, 0.77905936694588, 0.7833636425840108, 0.7841812762733145]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 40)   21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 100)  0           dropout_7[0][0]                  
                                                                 dropout_8[0][0]                  
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 268,513
Trainable params: 93,593
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2.6774 - acc: 0.5629 - mDice: 0.1090 - val_loss: 1.9223 - val_acc: 0.9024 - val_mDice: 0.2173

Epoch 00001: val_mDice improved from -inf to 0.21729, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.9929 - acc: 0.8774 - mDice: 0.3605 - val_loss: 1.2498 - val_acc: 0.9057 - val_mDice: 0.3756

Epoch 00002: val_mDice improved from 0.21729 to 0.37559, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.7398 - acc: 0.8843 - mDice: 0.4631 - val_loss: 1.0838 - val_acc: 0.9068 - val_mDice: 0.4356

Epoch 00003: val_mDice improved from 0.37559 to 0.43555, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.6448 - acc: 0.8891 - mDice: 0.5108 - val_loss: 0.9599 - val_acc: 0.9135 - val_mDice: 0.4792

Epoch 00004: val_mDice improved from 0.43555 to 0.47922, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.5869 - acc: 0.8926 - mDice: 0.5418 - val_loss: 0.8931 - val_acc: 0.9186 - val_mDice: 0.5114

Epoch 00005: val_mDice improved from 0.47922 to 0.51138, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 14s - loss: 0.5406 - acc: 0.8961 - mDice: 0.5673 - val_loss: 0.8894 - val_acc: 0.9185 - val_mDice: 0.5155

Epoch 00006: val_mDice improved from 0.51138 to 0.51550, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.5072 - acc: 0.9012 - mDice: 0.5870 - val_loss: 0.8654 - val_acc: 0.9271 - val_mDice: 0.5329

Epoch 00007: val_mDice improved from 0.51550 to 0.53287, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.4817 - acc: 0.9072 - mDice: 0.6028 - val_loss: 0.8876 - val_acc: 0.9336 - val_mDice: 0.5272

Epoch 00008: val_mDice did not improve from 0.53287
Epoch 9/300
 - 15s - loss: 0.4613 - acc: 0.9168 - mDice: 0.6156 - val_loss: 0.8727 - val_acc: 0.9379 - val_mDice: 0.5332

Epoch 00009: val_mDice improved from 0.53287 to 0.53323, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 14s - loss: 0.4464 - acc: 0.9272 - mDice: 0.6248 - val_loss: 0.8176 - val_acc: 0.9353 - val_mDice: 0.5460

Epoch 00010: val_mDice improved from 0.53323 to 0.54596, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.4302 - acc: 0.9315 - mDice: 0.6347 - val_loss: 0.8338 - val_acc: 0.9356 - val_mDice: 0.5473

Epoch 00011: val_mDice improved from 0.54596 to 0.54726, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 14s - loss: 0.4205 - acc: 0.9331 - mDice: 0.6411 - val_loss: 0.8392 - val_acc: 0.9359 - val_mDice: 0.5428

Epoch 00012: val_mDice did not improve from 0.54726
Epoch 13/300
 - 14s - loss: 0.4090 - acc: 0.9344 - mDice: 0.6487 - val_loss: 0.8176 - val_acc: 0.9296 - val_mDice: 0.5457

Epoch 00013: val_mDice did not improve from 0.54726
Epoch 14/300
 - 14s - loss: 0.4017 - acc: 0.9353 - mDice: 0.6535 - val_loss: 0.8096 - val_acc: 0.9330 - val_mDice: 0.5622

Epoch 00014: val_mDice improved from 0.54726 to 0.56223, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 14s - loss: 0.3935 - acc: 0.9362 - mDice: 0.6590 - val_loss: 0.8031 - val_acc: 0.9275 - val_mDice: 0.5436

Epoch 00015: val_mDice did not improve from 0.56223
Epoch 16/300
 - 14s - loss: 0.3868 - acc: 0.9369 - mDice: 0.6637 - val_loss: 0.7951 - val_acc: 0.9356 - val_mDice: 0.5715

Epoch 00016: val_mDice improved from 0.56223 to 0.57148, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB1_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 14s - loss: 0.3809 - acc: 0.9375 - mDice: 0.6677 - val_loss: 0.8012 - val_acc: 0.9362 - val_mDice: 0.5629

Epoch 00017: val_mDice did not improve from 0.57148
Epoch 18/300
 - 14s - loss: 0.3769 - acc: 0.9379 - mDice: 0.6707 - val_loss: 0.7929 - val_acc: 0.9340 - val_mDice: 0.5654

Epoch 00018: val_mDice did not improve from 0.57148
Epoch 19/300
 - 14s - loss: 0.3670 - acc: 0.9389 - mDice: 0.6774 - val_loss: 0.8041 - val_acc: 0.9337 - val_mDice: 0.5622

Epoch 00019: val_mDice did not improve from 0.57148
Epoch 20/300
 - 14s - loss: 0.3632 - acc: 0.9394 - mDice: 0.6803 - val_loss: 0.7948 - val_acc: 0.9370 - val_mDice: 0.5612

Epoch 00020: val_mDice did not improve from 0.57148
Epoch 21/300
 - 14s - loss: 0.3594 - acc: 0.9397 - mDice: 0.6827 - val_loss: 0.7971 - val_acc: 0.9367 - val_mDice: 0.5587

Epoch 00021: val_mDice did not improve from 0.57148
Epoch 22/300
 - 14s - loss: 0.3559 - acc: 0.9402 - mDice: 0.6853 - val_loss: 0.7802 - val_acc: 0.9370 - val_mDice: 0.5683

Epoch 00022: val_mDice did not improve from 0.57148
Epoch 23/300
 - 14s - loss: 0.3561 - acc: 0.9403 - mDice: 0.6854 - val_loss: 0.8024 - val_acc: 0.9294 - val_mDice: 0.5535

Epoch 00023: val_mDice did not improve from 0.57148
Epoch 24/300
 - 14s - loss: 0.3510 - acc: 0.9408 - mDice: 0.6890 - val_loss: 0.8230 - val_acc: 0.9356 - val_mDice: 0.5488

Epoch 00024: val_mDice did not improve from 0.57148
Epoch 25/300
 - 14s - loss: 0.3459 - acc: 0.9412 - mDice: 0.6926 - val_loss: 0.8285 - val_acc: 0.9361 - val_mDice: 0.5458

Epoch 00025: val_mDice did not improve from 0.57148
Epoch 26/300
 - 14s - loss: 0.3407 - acc: 0.9418 - mDice: 0.6964 - val_loss: 0.7839 - val_acc: 0.9390 - val_mDice: 0.5666

Epoch 00026: val_mDice did not improve from 0.57148
Epoch 27/300
 - 15s - loss: 0.3406 - acc: 0.9418 - mDice: 0.6964 - val_loss: 0.7900 - val_acc: 0.9372 - val_mDice: 0.5595

Epoch 00027: val_mDice did not improve from 0.57148
Epoch 28/300
 - 14s - loss: 0.3361 - acc: 0.9422 - mDice: 0.6997 - val_loss: 0.7909 - val_acc: 0.9391 - val_mDice: 0.5618

Epoch 00028: val_mDice did not improve from 0.57148
Epoch 29/300
 - 15s - loss: 0.3334 - acc: 0.9424 - mDice: 0.7016 - val_loss: 0.8074 - val_acc: 0.9266 - val_mDice: 0.5484

Epoch 00029: val_mDice did not improve from 0.57148
Epoch 30/300
 - 14s - loss: 0.3314 - acc: 0.9427 - mDice: 0.7031 - val_loss: 0.8176 - val_acc: 0.9343 - val_mDice: 0.5512

Epoch 00030: val_mDice did not improve from 0.57148
Epoch 31/300
 - 14s - loss: 0.3281 - acc: 0.9430 - mDice: 0.7056 - val_loss: 0.7890 - val_acc: 0.9323 - val_mDice: 0.5590

Epoch 00031: val_mDice did not improve from 0.57148
Epoch 32/300
 - 14s - loss: 0.3246 - acc: 0.9432 - mDice: 0.7081 - val_loss: 0.8011 - val_acc: 0.9388 - val_mDice: 0.5527

Epoch 00032: val_mDice did not improve from 0.57148
Epoch 33/300
 - 14s - loss: 0.3228 - acc: 0.9434 - mDice: 0.7095 - val_loss: 0.8008 - val_acc: 0.9373 - val_mDice: 0.5600

Epoch 00033: val_mDice did not improve from 0.57148
Epoch 34/300
 - 14s - loss: 0.3215 - acc: 0.9435 - mDice: 0.7105 - val_loss: 0.7940 - val_acc: 0.9389 - val_mDice: 0.5562

Epoch 00034: val_mDice did not improve from 0.57148
Epoch 35/300
 - 14s - loss: 0.3177 - acc: 0.9438 - mDice: 0.7133 - val_loss: 0.8109 - val_acc: 0.9369 - val_mDice: 0.5525

Epoch 00035: val_mDice did not improve from 0.57148
Epoch 36/300
 - 14s - loss: 0.3144 - acc: 0.9441 - mDice: 0.7157 - val_loss: 0.8275 - val_acc: 0.9371 - val_mDice: 0.5395

Epoch 00036: val_mDice did not improve from 0.57148
Epoch 37/300
 - 15s - loss: 0.3140 - acc: 0.9444 - mDice: 0.7161 - val_loss: 0.8059 - val_acc: 0.9311 - val_mDice: 0.5609

Epoch 00037: val_mDice did not improve from 0.57148
Epoch 38/300
 - 14s - loss: 0.3121 - acc: 0.9445 - mDice: 0.7175 - val_loss: 0.7969 - val_acc: 0.9341 - val_mDice: 0.5515

Epoch 00038: val_mDice did not improve from 0.57148
Epoch 39/300
 - 14s - loss: 0.3121 - acc: 0.9444 - mDice: 0.7175 - val_loss: 0.8129 - val_acc: 0.9407 - val_mDice: 0.5465

Epoch 00039: val_mDice did not improve from 0.57148
Epoch 40/300
 - 15s - loss: 0.3108 - acc: 0.9444 - mDice: 0.7185 - val_loss: 0.7924 - val_acc: 0.9374 - val_mDice: 0.5515

Epoch 00040: val_mDice did not improve from 0.57148
Epoch 41/300
 - 15s - loss: 0.3077 - acc: 0.9448 - mDice: 0.7208 - val_loss: 0.7805 - val_acc: 0.9364 - val_mDice: 0.5636

Epoch 00041: val_mDice did not improve from 0.57148
Epoch 42/300
 - 14s - loss: 0.3070 - acc: 0.9448 - mDice: 0.7213 - val_loss: 0.7943 - val_acc: 0.9365 - val_mDice: 0.5545

Epoch 00042: val_mDice did not improve from 0.57148
Epoch 43/300
 - 15s - loss: 0.3043 - acc: 0.9452 - mDice: 0.7233 - val_loss: 0.7970 - val_acc: 0.9357 - val_mDice: 0.5511

Epoch 00043: val_mDice did not improve from 0.57148
Epoch 44/300
 - 14s - loss: 0.3034 - acc: 0.9452 - mDice: 0.7240 - val_loss: 0.7844 - val_acc: 0.9308 - val_mDice: 0.5574

Epoch 00044: val_mDice did not improve from 0.57148
Epoch 45/300
 - 15s - loss: 0.3027 - acc: 0.9453 - mDice: 0.7245 - val_loss: 0.7817 - val_acc: 0.9388 - val_mDice: 0.5590

Epoch 00045: val_mDice did not improve from 0.57148
Epoch 46/300
 - 15s - loss: 0.3011 - acc: 0.9455 - mDice: 0.7258 - val_loss: 0.8152 - val_acc: 0.9364 - val_mDice: 0.5449

Epoch 00046: val_mDice did not improve from 0.57148
Epoch 47/300
 - 14s - loss: 0.2995 - acc: 0.9456 - mDice: 0.7270 - val_loss: 0.7863 - val_acc: 0.9400 - val_mDice: 0.5587

Epoch 00047: val_mDice did not improve from 0.57148
Epoch 48/300
 - 15s - loss: 0.2989 - acc: 0.9458 - mDice: 0.7274 - val_loss: 0.7934 - val_acc: 0.9375 - val_mDice: 0.5370

Epoch 00048: val_mDice did not improve from 0.57148
Epoch 49/300
 - 15s - loss: 0.2963 - acc: 0.9459 - mDice: 0.7293 - val_loss: 0.8004 - val_acc: 0.9390 - val_mDice: 0.5548

Epoch 00049: val_mDice did not improve from 0.57148
Epoch 50/300
 - 14s - loss: 0.2957 - acc: 0.9460 - mDice: 0.7298 - val_loss: 0.7895 - val_acc: 0.9350 - val_mDice: 0.5485

Epoch 00050: val_mDice did not improve from 0.57148
Epoch 51/300
 - 14s - loss: 0.2951 - acc: 0.9461 - mDice: 0.7303 - val_loss: 0.7767 - val_acc: 0.9389 - val_mDice: 0.5566

Epoch 00051: val_mDice did not improve from 0.57148
Epoch 52/300
 - 14s - loss: 0.2948 - acc: 0.9461 - mDice: 0.7305 - val_loss: 0.7966 - val_acc: 0.9371 - val_mDice: 0.5509

Epoch 00052: val_mDice did not improve from 0.57148
Epoch 53/300
 - 14s - loss: 0.2939 - acc: 0.9462 - mDice: 0.7313 - val_loss: 0.7982 - val_acc: 0.9329 - val_mDice: 0.5559

Epoch 00053: val_mDice did not improve from 0.57148
Epoch 54/300
 - 14s - loss: 0.2899 - acc: 0.9464 - mDice: 0.7342 - val_loss: 0.8042 - val_acc: 0.9365 - val_mDice: 0.5517

Epoch 00054: val_mDice did not improve from 0.57148
Epoch 55/300
 - 15s - loss: 0.2875 - acc: 0.9466 - mDice: 0.7361 - val_loss: 0.8050 - val_acc: 0.9396 - val_mDice: 0.5438

Epoch 00055: val_mDice did not improve from 0.57148
Epoch 56/300
 - 14s - loss: 0.2895 - acc: 0.9464 - mDice: 0.7344 - val_loss: 0.7947 - val_acc: 0.9373 - val_mDice: 0.5536

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.56s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.27s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.02s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:54,  2.09s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:52,  1.88s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:40,  1.84s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:03,  1.72s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:28,  1.82s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:08,  1.75s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:27,  1.83s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:22,  1.81s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:45,  1.91s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:07,  1.99s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:45,  1.92s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:45,  1.92s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:46,  1.94s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:37,  1.91s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:37,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:48,  1.96s/it]predicting train subjects:   6%|▌         | 17/285 [00:31<08:35,  1.92s/it]predicting train subjects:   6%|▋         | 18/285 [00:33<08:47,  1.98s/it]predicting train subjects:   7%|▋         | 19/285 [00:35<08:32,  1.93s/it]predicting train subjects:   7%|▋         | 20/285 [00:37<08:38,  1.96s/it]predicting train subjects:   7%|▋         | 21/285 [00:39<08:54,  2.02s/it]predicting train subjects:   8%|▊         | 22/285 [00:41<08:43,  1.99s/it]predicting train subjects:   8%|▊         | 23/285 [00:43<08:34,  1.97s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<08:19,  1.91s/it]predicting train subjects:   9%|▉         | 25/285 [00:47<08:29,  1.96s/it]predicting train subjects:   9%|▉         | 26/285 [00:49<08:58,  2.08s/it]predicting train subjects:   9%|▉         | 27/285 [00:51<08:51,  2.06s/it]predicting train subjects:  10%|▉         | 28/285 [00:53<08:44,  2.04s/it]predicting train subjects:  10%|█         | 29/285 [00:55<08:31,  2.00s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:49,  2.08s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:44,  2.07s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:40,  2.06s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:45,  2.08s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:34,  2.05s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:38,  2.07s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<08:14,  1.99s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<08:10,  1.98s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<08:23,  2.04s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:08,  1.99s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:02,  1.97s/it]predicting train subjects:  14%|█▍        | 41/285 [01:19<07:45,  1.91s/it]predicting train subjects:  15%|█▍        | 42/285 [01:21<07:46,  1.92s/it]predicting train subjects:  15%|█▌        | 43/285 [01:23<07:42,  1.91s/it]predicting train subjects:  15%|█▌        | 44/285 [01:25<07:56,  1.98s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:39,  1.91s/it]predicting train subjects:  16%|█▌        | 46/285 [01:29<07:42,  1.94s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:37,  1.92s/it]predicting train subjects:  17%|█▋        | 48/285 [01:33<07:32,  1.91s/it]predicting train subjects:  17%|█▋        | 49/285 [01:35<07:53,  2.00s/it]predicting train subjects:  18%|█▊        | 50/285 [01:37<07:50,  2.00s/it]predicting train subjects:  18%|█▊        | 51/285 [01:39<07:53,  2.02s/it]predicting train subjects:  18%|█▊        | 52/285 [01:41<07:34,  1.95s/it]predicting train subjects:  19%|█▊        | 53/285 [01:43<07:43,  2.00s/it]predicting train subjects:  19%|█▉        | 54/285 [01:45<07:57,  2.07s/it]predicting train subjects:  19%|█▉        | 55/285 [01:47<07:32,  1.97s/it]predicting train subjects:  20%|█▉        | 56/285 [01:49<07:27,  1.95s/it]predicting train subjects:  20%|██        | 57/285 [01:51<07:24,  1.95s/it]predicting train subjects:  20%|██        | 58/285 [01:53<07:23,  1.96s/it]predicting train subjects:  21%|██        | 59/285 [01:55<07:59,  2.12s/it]predicting train subjects:  21%|██        | 60/285 [01:58<08:05,  2.16s/it]predicting train subjects:  21%|██▏       | 61/285 [01:59<07:29,  2.01s/it]predicting train subjects:  22%|██▏       | 62/285 [02:01<07:29,  2.02s/it]predicting train subjects:  22%|██▏       | 63/285 [02:03<07:29,  2.03s/it]predicting train subjects:  22%|██▏       | 64/285 [02:05<07:16,  1.98s/it]predicting train subjects:  23%|██▎       | 65/285 [02:07<07:22,  2.01s/it]predicting train subjects:  23%|██▎       | 66/285 [02:09<07:13,  1.98s/it]predicting train subjects:  24%|██▎       | 67/285 [02:11<07:16,  2.00s/it]predicting train subjects:  24%|██▍       | 68/285 [02:13<07:01,  1.94s/it]predicting train subjects:  24%|██▍       | 69/285 [02:15<07:09,  1.99s/it]predicting train subjects:  25%|██▍       | 70/285 [02:17<07:05,  1.98s/it]predicting train subjects:  25%|██▍       | 71/285 [02:19<07:00,  1.96s/it]predicting train subjects:  25%|██▌       | 72/285 [02:21<06:53,  1.94s/it]predicting train subjects:  26%|██▌       | 73/285 [02:23<06:54,  1.95s/it]predicting train subjects:  26%|██▌       | 74/285 [02:25<06:55,  1.97s/it]predicting train subjects:  26%|██▋       | 75/285 [02:27<06:52,  1.97s/it]predicting train subjects:  27%|██▋       | 76/285 [02:29<06:54,  1.98s/it]predicting train subjects:  27%|██▋       | 77/285 [02:31<06:47,  1.96s/it]predicting train subjects:  27%|██▋       | 78/285 [02:33<06:38,  1.92s/it]predicting train subjects:  28%|██▊       | 79/285 [02:35<06:45,  1.97s/it]predicting train subjects:  28%|██▊       | 80/285 [02:37<06:53,  2.02s/it]predicting train subjects:  28%|██▊       | 81/285 [02:39<06:38,  1.95s/it]predicting train subjects:  29%|██▉       | 82/285 [02:41<06:45,  2.00s/it]predicting train subjects:  29%|██▉       | 83/285 [02:43<06:32,  1.94s/it]predicting train subjects:  29%|██▉       | 84/285 [02:44<06:21,  1.90s/it]predicting train subjects:  30%|██▉       | 85/285 [02:46<06:28,  1.94s/it]predicting train subjects:  30%|███       | 86/285 [02:48<06:29,  1.96s/it]predicting train subjects:  31%|███       | 87/285 [02:50<06:14,  1.89s/it]predicting train subjects:  31%|███       | 88/285 [02:52<06:05,  1.85s/it]predicting train subjects:  31%|███       | 89/285 [02:54<06:21,  1.95s/it]predicting train subjects:  32%|███▏      | 90/285 [02:56<06:36,  2.03s/it]predicting train subjects:  32%|███▏      | 91/285 [02:58<06:19,  1.96s/it]predicting train subjects:  32%|███▏      | 92/285 [03:00<06:26,  2.00s/it]predicting train subjects:  33%|███▎      | 93/285 [03:02<06:15,  1.95s/it]predicting train subjects:  33%|███▎      | 94/285 [03:04<06:13,  1.96s/it]predicting train subjects:  33%|███▎      | 95/285 [03:06<06:15,  1.97s/it]predicting train subjects:  34%|███▎      | 96/285 [03:08<06:12,  1.97s/it]predicting train subjects:  34%|███▍      | 97/285 [03:10<06:12,  1.98s/it]predicting train subjects:  34%|███▍      | 98/285 [03:12<06:13,  2.00s/it]predicting train subjects:  35%|███▍      | 99/285 [03:14<06:04,  1.96s/it]predicting train subjects:  35%|███▌      | 100/285 [03:16<06:03,  1.97s/it]predicting train subjects:  35%|███▌      | 101/285 [03:18<05:50,  1.91s/it]predicting train subjects:  36%|███▌      | 102/285 [03:20<06:01,  1.97s/it]predicting train subjects:  36%|███▌      | 103/285 [03:22<05:54,  1.95s/it]predicting train subjects:  36%|███▋      | 104/285 [03:24<05:54,  1.96s/it]predicting train subjects:  37%|███▋      | 105/285 [03:25<05:47,  1.93s/it]predicting train subjects:  37%|███▋      | 106/285 [03:27<05:34,  1.87s/it]predicting train subjects:  38%|███▊      | 107/285 [03:29<05:35,  1.89s/it]predicting train subjects:  38%|███▊      | 108/285 [03:31<05:26,  1.84s/it]predicting train subjects:  38%|███▊      | 109/285 [03:33<05:21,  1.83s/it]predicting train subjects:  39%|███▊      | 110/285 [03:35<05:23,  1.85s/it]predicting train subjects:  39%|███▉      | 111/285 [03:36<05:17,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:38<05:23,  1.87s/it]predicting train subjects:  40%|███▉      | 113/285 [03:40<05:32,  1.93s/it]predicting train subjects:  40%|████      | 114/285 [03:42<05:29,  1.93s/it]predicting train subjects:  40%|████      | 115/285 [03:44<05:31,  1.95s/it]predicting train subjects:  41%|████      | 116/285 [03:46<05:26,  1.93s/it]predicting train subjects:  41%|████      | 117/285 [03:48<05:17,  1.89s/it]predicting train subjects:  41%|████▏     | 118/285 [03:50<05:10,  1.86s/it]predicting train subjects:  42%|████▏     | 119/285 [03:52<05:17,  1.91s/it]predicting train subjects:  42%|████▏     | 120/285 [03:54<05:12,  1.89s/it]predicting train subjects:  42%|████▏     | 121/285 [03:56<05:11,  1.90s/it]predicting train subjects:  43%|████▎     | 122/285 [03:57<05:01,  1.85s/it]predicting train subjects:  43%|████▎     | 123/285 [03:59<04:44,  1.76s/it]predicting train subjects:  44%|████▎     | 124/285 [04:01<04:45,  1.78s/it]predicting train subjects:  44%|████▍     | 125/285 [04:02<04:36,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [04:04<04:28,  1.69s/it]predicting train subjects:  45%|████▍     | 127/285 [04:05<04:21,  1.65s/it]predicting train subjects:  45%|████▍     | 128/285 [04:07<04:28,  1.71s/it]predicting train subjects:  45%|████▌     | 129/285 [04:09<04:18,  1.65s/it]predicting train subjects:  46%|████▌     | 130/285 [04:10<04:13,  1.64s/it]predicting train subjects:  46%|████▌     | 131/285 [04:12<04:04,  1.59s/it]predicting train subjects:  46%|████▋     | 132/285 [04:13<04:01,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:15<03:56,  1.56s/it]predicting train subjects:  47%|████▋     | 134/285 [04:16<03:49,  1.52s/it]predicting train subjects:  47%|████▋     | 135/285 [04:18<03:43,  1.49s/it]predicting train subjects:  48%|████▊     | 136/285 [04:19<03:35,  1.45s/it]predicting train subjects:  48%|████▊     | 137/285 [04:21<03:37,  1.47s/it]predicting train subjects:  48%|████▊     | 138/285 [04:22<03:33,  1.45s/it]predicting train subjects:  49%|████▉     | 139/285 [04:24<03:37,  1.49s/it]predicting train subjects:  49%|████▉     | 140/285 [04:25<03:39,  1.51s/it]predicting train subjects:  49%|████▉     | 141/285 [04:27<03:31,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [04:28<03:26,  1.45s/it]predicting train subjects:  50%|█████     | 143/285 [04:29<03:22,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [04:31<03:26,  1.47s/it]predicting train subjects:  51%|█████     | 145/285 [04:32<03:24,  1.46s/it]predicting train subjects:  51%|█████     | 146/285 [04:34<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:35<03:16,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:37<03:18,  1.45s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:38<03:12,  1.42s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:39<03:07,  1.39s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:41<03:13,  1.44s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:42<03:09,  1.42s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:44<03:09,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:45<03:10,  1.46s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:47<03:06,  1.43s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:48<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:50<03:05,  1.45s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:51<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:52<02:56,  1.40s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:54<02:53,  1.39s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:55<02:55,  1.42s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:57<02:51,  1.39s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:58<02:53,  1.42s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:59<02:49,  1.40s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:01<02:47,  1.40s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:02<02:50,  1.43s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:04<02:49,  1.44s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:05<02:43,  1.40s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:06<02:44,  1.42s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:08<02:43,  1.42s/it]predicting train subjects:  60%|██████    | 171/285 [05:09<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 172/285 [05:11<02:39,  1.41s/it]predicting train subjects:  61%|██████    | 173/285 [05:12<02:35,  1.38s/it]predicting train subjects:  61%|██████    | 174/285 [05:13<02:31,  1.37s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:15<02:37,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:17<02:41,  1.48s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:18<02:36,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:19<02:30,  1.40s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:21<02:26,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:22<02:34,  1.47s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:24<02:36,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:25<02:35,  1.51s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:27<02:28,  1.46s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:28<02:23,  1.42s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:29<02:19,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:31<02:25,  1.47s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:33<02:32,  1.56s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:34<02:34,  1.59s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:36<02:24,  1.51s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:37<02:19,  1.47s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:39<02:20,  1.49s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:40<02:21,  1.52s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:41<02:12,  1.45s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:43<02:09,  1.42s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:44<02:06,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:46<02:15,  1.52s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:48<02:17,  1.56s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:49<02:19,  1.60s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:51<02:10,  1.52s/it]predicting train subjects:  70%|███████   | 200/285 [05:52<02:04,  1.46s/it]predicting train subjects:  71%|███████   | 201/285 [05:54<02:09,  1.54s/it]predicting train subjects:  71%|███████   | 202/285 [05:55<02:07,  1.54s/it]predicting train subjects:  71%|███████   | 203/285 [05:57<02:06,  1.54s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:58<01:57,  1.45s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<01:54,  1.43s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:01<01:49,  1.38s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<01:56,  1.49s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<01:59,  1.56s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<01:53,  1.51s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<01:48,  1.46s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:10<01:49,  1.50s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<01:48,  1.51s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:13<01:42,  1.45s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<01:46,  1.52s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:16<01:39,  1.44s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:18<01:43,  1.53s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:19<01:46,  1.59s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:21<01:47,  1.63s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:22<01:40,  1.54s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:24<01:33,  1.47s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:25<01:35,  1.51s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:27<01:28,  1.43s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:26,  1.42s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:29<01:23,  1.39s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:28,  1.50s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:31,  1.58s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:32,  1.63s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:30,  1.61s/it]predicting train subjects:  81%|████████  | 230/285 [06:37<01:23,  1.52s/it]predicting train subjects:  81%|████████  | 231/285 [06:39<01:20,  1.48s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:41<01:21,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:42<01:16,  1.48s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:44<01:19,  1.56s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:45<01:15,  1.50s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:47<01:17,  1.57s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:48<01:18,  1.63s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:50<01:17,  1.66s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:52<01:14,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:53<01:10,  1.56s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:55<01:07,  1.52s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:56<01:03,  1.48s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:57<01:00,  1.43s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:59<01:01,  1.51s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:00<00:58,  1.45s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:02<00:59,  1.54s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:04<01:00,  1.58s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:05<00:59,  1.60s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:07<00:55,  1.53s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:08<00:51,  1.48s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:09<00:49,  1.44s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:11<00:45,  1.38s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:13<00:48,  1.52s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:14<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:16<00:47,  1.57s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:17<00:43,  1.49s/it]predicting train subjects:  90%|█████████ | 257/285 [07:18<00:40,  1.45s/it]predicting train subjects:  91%|█████████ | 258/285 [07:20<00:40,  1.52s/it]predicting train subjects:  91%|█████████ | 259/285 [07:22<00:40,  1.56s/it]predicting train subjects:  91%|█████████ | 260/285 [07:23<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:24<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:26<00:32,  1.42s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:27<00:30,  1.39s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:29<00:31,  1.49s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:31<00:31,  1.56s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:32<00:28,  1.50s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:33<00:26,  1.46s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:35<00:26,  1.55s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:37<00:24,  1.56s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:38<00:22,  1.48s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:39<00:20,  1.44s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:41<00:19,  1.49s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:42<00:17,  1.42s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:44<00:15,  1.43s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:45<00:15,  1.56s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:47<00:14,  1.60s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:49<00:12,  1.53s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:50<00:10,  1.47s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:51<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:53<00:07,  1.48s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:54<00:05,  1.46s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:56<00:04,  1.42s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:57<00:03,  1.51s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:59<00:01,  1.60s/it]predicting train subjects: 100%|██████████| 285/285 [08:01<00:00,  1.64s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a’: File exists

Epoch 00056: val_mDice did not improve from 0.57148
Restoring model weights from the end of the best epoch
Epoch 00056: early stopping
{'val_loss': [1.9223226125423725, 1.2498087264024293, 1.0837596563192515, 0.9598548297698681, 0.8930872357808627, 0.8893781969180474, 0.8653950553673965, 0.8875628136671506, 0.8727329992330991, 0.8175874535854046, 0.833782067665687, 0.8392455348601708, 0.8175674653970278, 0.8095836135057303, 0.8030882638234359, 0.7951394869731023, 0.8012455128706418, 0.7928860668952649, 0.8040775198202866, 0.7947915746615484, 0.797144169990833, 0.7801558558757489, 0.8023563440029438, 0.8229988973874313, 0.8284775339640104, 0.7838646311026353, 0.7899504785354321, 0.7909282170809232, 0.8073734663999997, 0.8176212242016425, 0.788980055313844, 0.8010862721846654, 0.8007619885297922, 0.7940358129831461, 0.8108658309166248, 0.8275105288395515, 0.8059374690055847, 0.7968510985374451, 0.8128906396719126, 0.7924369160945599, 0.7804749149542588, 0.7943035730948815, 0.7969759473433862, 0.7843774786362281, 0.7816986877184647, 0.8151985498575064, 0.7862778030909024, 0.7934100123552176, 0.8004203255359943, 0.7894547512898078, 0.7767065419600561, 0.7965793174046737, 0.7982499851630285, 0.8041523603292612, 0.8050064444541931, 0.7947212343032544], 'val_acc': [0.9023853402871352, 0.9056629034189078, 0.9067677282370054, 0.9134846604787387, 0.9186390477877396, 0.9185350353901203, 0.9271288078564864, 0.9335729273465964, 0.9378582514249362, 0.9352625677218804, 0.935572278041106, 0.9358820548424354, 0.9295834623850309, 0.9330136134074285, 0.9275101652512183, 0.9355977406868567, 0.9362495449873117, 0.9340328872203827, 0.9336977440577287, 0.9370377040826358, 0.9367118225647852, 0.9370238345402938, 0.9294378619927627, 0.9355561160124265, 0.9361339922134693, 0.9390486203707181, 0.9372064448319949, 0.9391456888272212, 0.9266064350421612, 0.9342825183501611, 0.9322739541530609, 0.9387666170413678, 0.9373151132693658, 0.9389168918132782, 0.936868993135599, 0.9371301875664637, 0.9311344233842996, 0.9341276975778433, 0.9407151226813977, 0.9373705730988429, 0.9364437025326949, 0.9365083942046533, 0.9356948274832505, 0.9308223701440371, 0.9388313637329981, 0.9364228661243732, 0.9400309874461248, 0.9375115289137914, 0.9390301475158105, 0.9350060293307672, 0.9389307613556201, 0.9371116619843703, 0.9329049449700576, 0.9365222797943995, 0.9396265011567336, 0.9373474396192111], 'val_mDice': [0.21728783903213647, 0.3755919509209119, 0.43555252024760616, 0.47922011522146374, 0.5113829391507002, 0.5155043063255457, 0.5328747355020963, 0.5272146807267115, 0.5332274448413116, 0.5459626431648548, 0.5472602076255358, 0.5428404028599079, 0.5457333658750241, 0.5622335844315015, 0.5436169264408258, 0.5714848259320626, 0.5629048708539742, 0.5654352525105844, 0.5622418631727879, 0.561200984968589, 0.5587376975096189, 0.5683191177936701, 0.5535197487244239, 0.5487996024581102, 0.5457874192641332, 0.5666281007803403, 0.5594687249798042, 0.5617625610186503, 0.5483773281941047, 0.5512371281018624, 0.5589609363904366, 0.5527028578978318, 0.5599620846601633, 0.5561700159540544, 0.5524875716521189, 0.539451362995001, 0.560880687374335, 0.5514846346699275, 0.5464857730727929, 0.551518596135653, 0.5635878856365497, 0.5544888990429732, 0.5510763445725808, 0.557396568931066, 0.5589785363811713, 0.5448697524575087, 0.5586517229676247, 0.5369794483368213, 0.5548134835866781, 0.5485270751210359, 0.5566164157711543, 0.5509324623988225, 0.5559207762663181, 0.5516539800625581, 0.5437923772976949, 0.5535548380934275], 'loss': [2.677433770564631, 0.9928754887479286, 0.7397761089076396, 0.6448343767458405, 0.5868610592991358, 0.5406301921829795, 0.5072103908808921, 0.481674712288372, 0.46128365837218277, 0.44636197827799695, 0.43016293507478537, 0.42050963803750613, 0.4089700042470337, 0.4016915538632473, 0.39352180680632315, 0.3867504434601843, 0.3809350890574789, 0.37687450356284685, 0.36696857678200895, 0.3631662685641567, 0.3594026521547775, 0.3559104537602161, 0.35605350654855006, 0.35099147564588873, 0.3458975657352077, 0.34071333123003217, 0.3406412207056739, 0.3360894455561655, 0.33338637915108793, 0.3314311457886353, 0.3281377924881573, 0.32460559935496325, 0.3227508336258893, 0.3215049435008796, 0.31768275955270203, 0.3143731867416114, 0.31400875476061235, 0.31214932979038257, 0.31207050881262227, 0.3107654374238146, 0.30765993153104526, 0.3070137104204877, 0.3042619529766954, 0.3034210868738437, 0.3026888237979748, 0.30105209244217784, 0.2995167876382733, 0.2989377603010422, 0.2963441275180425, 0.2957238256848849, 0.29513515082219643, 0.2948223309802534, 0.2939161633687695, 0.28994695775889057, 0.2874673119382226, 0.2895431020026122], 'acc': [0.5628695219609501, 0.8773689295086134, 0.8842736887039101, 0.889073616841793, 0.8926223678847449, 0.896095406697991, 0.9012381680763967, 0.9071650289965877, 0.9168301589878395, 0.9272468870475284, 0.9314771936265874, 0.933127007355365, 0.9344326605229957, 0.93529951518547, 0.9361908229791644, 0.9369207291346705, 0.937535472607949, 0.9379291600168691, 0.9389259441965545, 0.9394347842830492, 0.9397377285813973, 0.9401812097314516, 0.9403296324156378, 0.9407912712359707, 0.9412351081284014, 0.9417754471505424, 0.9418154852719893, 0.9422197222467785, 0.9423513893303611, 0.9426971895826882, 0.9429553099623204, 0.9432431159617111, 0.9434224664367874, 0.9435201465154524, 0.9438272147153144, 0.9440578005580591, 0.9444219379212643, 0.9445140979600702, 0.9444443496195117, 0.944425083048876, 0.9447963361611261, 0.9448389709792893, 0.9451605156867979, 0.9452194673795382, 0.945283534698773, 0.9455043661311842, 0.9456233257441726, 0.9457643044827159, 0.945881580697383, 0.946040249756976, 0.9460718175927992, 0.9461263319690278, 0.9461742844417131, 0.9464483897503282, 0.9466398938614912, 0.9464133420542884], 'mDice': [0.1089828847171822, 0.360536540171916, 0.46314003413578664, 0.5108352920495198, 0.541784160753727, 0.5673320222899206, 0.5869856217817155, 0.6027619430117971, 0.6156203933475884, 0.624835189083873, 0.6347430479611175, 0.6411017706327571, 0.648654688842664, 0.653477100915688, 0.6590000671796403, 0.6637010725070264, 0.6676591169259144, 0.6707267842806871, 0.6774184302816221, 0.680331236782037, 0.6827253934192139, 0.685342946423493, 0.6853600727019907, 0.6889774096822382, 0.692557390870989, 0.6963649877518577, 0.6964326852374793, 0.699697115088613, 0.7015997718854396, 0.7031379474723272, 0.7055511669974963, 0.7080540877915413, 0.7094538089457907, 0.7104813594401658, 0.7132636743377718, 0.7157150570684216, 0.7161124585783702, 0.7174602457488208, 0.7174980342690491, 0.7184516415982561, 0.7207714597105617, 0.7212538947525208, 0.7233112511089078, 0.7240208863145606, 0.724529425695265, 0.7258071488453697, 0.726986091130116, 0.7273777232974435, 0.7293377669328343, 0.7297983956570051, 0.7302995316328998, 0.730474966957397, 0.7312839659423743, 0.7341856751551457, 0.7361092213103222, 0.7344252293613205]}
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU:
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:47,  1.65s/it]Loading train:   1%|          | 2/285 [00:02<07:05,  1.51s/it]Loading train:   1%|          | 3/285 [00:04<07:00,  1.49s/it]Loading train:   1%|▏         | 4/285 [00:05<06:23,  1.36s/it]Loading train:   2%|▏         | 5/285 [00:06<06:32,  1.40s/it]Loading train:   2%|▏         | 6/285 [00:08<06:15,  1.34s/it]Loading train:   2%|▏         | 7/285 [00:09<06:26,  1.39s/it]Loading train:   3%|▎         | 8/285 [00:10<06:15,  1.36s/it]Loading train:   3%|▎         | 9/285 [00:12<06:33,  1.43s/it]Loading train:   4%|▎         | 10/285 [00:13<05:52,  1.28s/it]Loading train:   4%|▍         | 11/285 [00:14<05:05,  1.11s/it]Loading train:   4%|▍         | 12/285 [00:15<04:59,  1.10s/it]Loading train:   5%|▍         | 13/285 [00:16<04:43,  1.04s/it]Loading train:   5%|▍         | 14/285 [00:17<04:38,  1.03s/it]Loading train:   5%|▌         | 15/285 [00:18<04:43,  1.05s/it]Loading train:   6%|▌         | 16/285 [00:19<04:35,  1.02s/it]Loading train:   6%|▌         | 17/285 [00:19<04:19,  1.03it/s]Loading train:   6%|▋         | 18/285 [00:20<04:23,  1.01it/s]Loading train:   7%|▋         | 19/285 [00:21<04:23,  1.01it/s]Loading train:   7%|▋         | 20/285 [00:22<04:17,  1.03it/s]Loading train:   7%|▋         | 21/285 [00:23<04:23,  1.00it/s]Loading train:   8%|▊         | 22/285 [00:24<04:09,  1.05it/s]Loading train:   8%|▊         | 23/285 [00:25<04:17,  1.02it/s]Loading train:   8%|▊         | 24/285 [00:26<03:56,  1.10it/s]Loading train:   9%|▉         | 25/285 [00:27<04:17,  1.01it/s]Loading train:   9%|▉         | 26/285 [00:28<04:17,  1.00it/s]Loading train:   9%|▉         | 27/285 [00:29<03:54,  1.10it/s]Loading train:  10%|▉         | 28/285 [00:30<04:09,  1.03it/s]Loading train:  10%|█         | 29/285 [00:31<04:26,  1.04s/it]Loading train:  11%|█         | 30/285 [00:32<04:33,  1.07s/it]Loading train:  11%|█         | 31/285 [00:33<04:29,  1.06s/it]Loading train:  11%|█         | 32/285 [00:35<04:25,  1.05s/it]Loading train:  12%|█▏        | 33/285 [00:36<04:25,  1.05s/it]Loading train:  12%|█▏        | 34/285 [00:37<04:24,  1.05s/it]Loading train:  12%|█▏        | 35/285 [00:38<04:15,  1.02s/it]Loading train:  13%|█▎        | 36/285 [00:39<04:09,  1.00s/it]Loading train:  13%|█▎        | 37/285 [00:39<04:00,  1.03it/s]Loading train:  13%|█▎        | 38/285 [00:41<04:15,  1.03s/it]Loading train:  14%|█▎        | 39/285 [00:42<04:17,  1.05s/it]Loading train:  14%|█▍        | 40/285 [00:43<04:04,  1.00it/s]Loading train:  14%|█▍        | 41/285 [00:43<03:47,  1.07it/s]Loading train:  15%|█▍        | 42/285 [00:44<03:45,  1.08it/s]Loading train:  15%|█▌        | 43/285 [00:45<03:39,  1.10it/s]Loading train:  15%|█▌        | 44/285 [00:46<03:37,  1.11it/s]Loading train:  16%|█▌        | 45/285 [00:47<03:22,  1.19it/s]Loading train:  16%|█▌        | 46/285 [00:48<03:28,  1.15it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:22,  1.17it/s]Loading train:  17%|█▋        | 48/285 [00:50<03:35,  1.10it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:38,  1.08it/s]Loading train:  18%|█▊        | 50/285 [00:51<03:43,  1.05it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:43,  1.05it/s]Loading train:  18%|█▊        | 52/285 [00:53<03:32,  1.10it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:39,  1.06it/s]Loading train:  19%|█▉        | 54/285 [00:55<03:51,  1.00s/it]Loading train:  19%|█▉        | 55/285 [00:56<03:37,  1.06it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:52,  1.01s/it]Loading train:  20%|██        | 57/285 [00:58<03:47,  1.00it/s]Loading train:  20%|██        | 58/285 [00:59<03:48,  1.00s/it]Loading train:  21%|██        | 59/285 [01:00<03:47,  1.01s/it]Loading train:  21%|██        | 60/285 [01:02<03:58,  1.06s/it]Loading train:  21%|██▏       | 61/285 [01:03<03:54,  1.05s/it]Loading train:  22%|██▏       | 62/285 [01:04<03:46,  1.01s/it]Loading train:  22%|██▏       | 63/285 [01:04<03:38,  1.02it/s]Loading train:  22%|██▏       | 64/285 [01:06<03:57,  1.08s/it]Loading train:  23%|██▎       | 65/285 [01:07<04:33,  1.24s/it]Loading train:  23%|██▎       | 66/285 [01:09<04:42,  1.29s/it]Loading train:  24%|██▎       | 67/285 [01:10<04:30,  1.24s/it]Loading train:  24%|██▍       | 68/285 [01:11<04:08,  1.14s/it]Loading train:  24%|██▍       | 69/285 [01:12<03:48,  1.06s/it]Loading train:  25%|██▍       | 70/285 [01:13<03:49,  1.07s/it]Loading train:  25%|██▍       | 71/285 [01:14<03:47,  1.06s/it]Loading train:  25%|██▌       | 72/285 [01:15<03:35,  1.01s/it]Loading train:  26%|██▌       | 73/285 [01:16<03:47,  1.07s/it]Loading train:  26%|██▌       | 74/285 [01:17<03:35,  1.02s/it]Loading train:  26%|██▋       | 75/285 [01:18<03:43,  1.07s/it]Loading train:  27%|██▋       | 76/285 [01:19<03:42,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:20<03:23,  1.02it/s]Loading train:  27%|██▋       | 78/285 [01:21<03:14,  1.07it/s]Loading train:  28%|██▊       | 79/285 [01:22<03:11,  1.08it/s]Loading train:  28%|██▊       | 80/285 [01:22<03:06,  1.10it/s]Loading train:  28%|██▊       | 81/285 [01:23<03:01,  1.13it/s]Loading train:  29%|██▉       | 82/285 [01:24<02:55,  1.16it/s]Loading train:  29%|██▉       | 83/285 [01:25<02:57,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:26<02:52,  1.16it/s]Loading train:  30%|██▉       | 85/285 [01:27<02:56,  1.13it/s]Loading train:  30%|███       | 86/285 [01:28<03:05,  1.07it/s]Loading train:  31%|███       | 87/285 [01:29<03:12,  1.03it/s]Loading train:  31%|███       | 88/285 [01:30<02:57,  1.11it/s]Loading train:  31%|███       | 89/285 [01:30<02:49,  1.15it/s]Loading train:  32%|███▏      | 90/285 [01:31<02:59,  1.09it/s]Loading train:  32%|███▏      | 91/285 [01:32<02:52,  1.12it/s]Loading train:  32%|███▏      | 92/285 [01:33<03:07,  1.03it/s]Loading train:  33%|███▎      | 93/285 [01:34<02:51,  1.12it/s]Loading train:  33%|███▎      | 94/285 [01:35<02:52,  1.11it/s]Loading train:  33%|███▎      | 95/285 [01:36<02:53,  1.10it/s]Loading train:  34%|███▎      | 96/285 [01:37<02:57,  1.06it/s]Loading train:  34%|███▍      | 97/285 [01:38<02:55,  1.07it/s]Loading train:  34%|███▍      | 98/285 [01:39<02:54,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:40<02:48,  1.11it/s]Loading train:  35%|███▌      | 100/285 [01:41<02:51,  1.08it/s]Loading train:  35%|███▌      | 101/285 [01:42<02:48,  1.09it/s]Loading train:  36%|███▌      | 102/285 [01:43<02:49,  1.08it/s]Loading train:  36%|███▌      | 103/285 [01:43<02:42,  1.12it/s]Loading train:  36%|███▋      | 104/285 [01:44<02:45,  1.09it/s]Loading train:  37%|███▋      | 105/285 [01:45<02:48,  1.07it/s]Loading train:  37%|███▋      | 106/285 [01:46<02:44,  1.09it/s]Loading train:  38%|███▊      | 107/285 [01:47<02:40,  1.11it/s]Loading train:  38%|███▊      | 108/285 [01:48<02:38,  1.12it/s]Loading train:  38%|███▊      | 109/285 [01:49<02:40,  1.10it/s]Loading train:  39%|███▊      | 110/285 [01:50<02:41,  1.08it/s]Loading train:  39%|███▉      | 111/285 [01:51<02:32,  1.14it/s]Loading train:  39%|███▉      | 112/285 [01:51<02:29,  1.16it/s]Loading train:  40%|███▉      | 113/285 [01:53<02:40,  1.07it/s]Loading train:  40%|████      | 114/285 [01:53<02:36,  1.09it/s]Loading train:  40%|████      | 115/285 [01:54<02:43,  1.04it/s]Loading train:  41%|████      | 116/285 [01:55<02:42,  1.04it/s]Loading train:  41%|████      | 117/285 [01:56<02:41,  1.04it/s]Loading train:  41%|████▏     | 118/285 [01:57<02:31,  1.10it/s]Loading train:  42%|████▏     | 119/285 [01:58<02:38,  1.05it/s]Loading train:  42%|████▏     | 120/285 [01:59<02:29,  1.11it/s]Loading train:  42%|████▏     | 121/285 [02:00<02:49,  1.03s/it]Loading train:  43%|████▎     | 122/285 [02:01<02:51,  1.05s/it]Loading train:  43%|████▎     | 123/285 [02:02<02:51,  1.06s/it]Loading train:  44%|████▎     | 124/285 [02:03<02:45,  1.03s/it]Loading train:  44%|████▍     | 125/285 [02:04<02:33,  1.04it/s]Loading train:  44%|████▍     | 126/285 [02:05<02:21,  1.12it/s]Loading train:  45%|████▍     | 127/285 [02:06<02:18,  1.14it/s]Loading train:  45%|████▍     | 128/285 [02:07<02:13,  1.17it/s]Loading train:  45%|████▌     | 129/285 [02:07<02:09,  1.20it/s]Loading train:  46%|████▌     | 130/285 [02:08<02:04,  1.24it/s]Loading train:  46%|████▌     | 131/285 [02:09<02:07,  1.20it/s]Loading train:  46%|████▋     | 132/285 [02:10<02:07,  1.20it/s]Loading train:  47%|████▋     | 133/285 [02:11<02:04,  1.22it/s]Loading train:  47%|████▋     | 134/285 [02:11<01:58,  1.27it/s]Loading train:  47%|████▋     | 135/285 [02:12<02:01,  1.23it/s]Loading train:  48%|████▊     | 136/285 [02:13<01:59,  1.25it/s]Loading train:  48%|████▊     | 137/285 [02:14<01:58,  1.25it/s]Loading train:  48%|████▊     | 138/285 [02:15<01:59,  1.23it/s]Loading train:  49%|████▉     | 139/285 [02:15<01:55,  1.26it/s]Loading train:  49%|████▉     | 140/285 [02:16<02:01,  1.20it/s]Loading train:  49%|████▉     | 141/285 [02:17<01:56,  1.23it/s]Loading train:  50%|████▉     | 142/285 [02:18<01:56,  1.23it/s]Loading train:  50%|█████     | 143/285 [02:19<01:54,  1.24it/s]Loading train:  51%|█████     | 144/285 [02:20<01:55,  1.22it/s]Loading train:  51%|█████     | 145/285 [02:20<01:54,  1.22it/s]Loading train:  51%|█████     | 146/285 [02:21<01:52,  1.23it/s]Loading train:  52%|█████▏    | 147/285 [02:22<01:51,  1.24it/s]Loading train:  52%|█████▏    | 148/285 [02:23<01:46,  1.29it/s]Loading train:  52%|█████▏    | 149/285 [02:23<01:42,  1.33it/s]Loading train:  53%|█████▎    | 150/285 [02:24<01:40,  1.35it/s]Loading train:  53%|█████▎    | 151/285 [02:25<01:41,  1.32it/s]Loading train:  53%|█████▎    | 152/285 [02:26<01:47,  1.24it/s]Loading train:  54%|█████▎    | 153/285 [02:26<01:40,  1.32it/s]Loading train:  54%|█████▍    | 154/285 [02:27<01:44,  1.25it/s]Loading train:  54%|█████▍    | 155/285 [02:28<01:39,  1.30it/s]Loading train:  55%|█████▍    | 156/285 [02:29<01:41,  1.27it/s]Loading train:  55%|█████▌    | 157/285 [02:30<01:40,  1.27it/s]Loading train:  55%|█████▌    | 158/285 [02:30<01:39,  1.27it/s]Loading train:  56%|█████▌    | 159/285 [02:31<01:40,  1.26it/s]Loading train:  56%|█████▌    | 160/285 [02:32<01:34,  1.33it/s]Loading train:  56%|█████▋    | 161/285 [02:33<01:35,  1.30it/s]Loading train:  57%|█████▋    | 162/285 [02:33<01:33,  1.32it/s]Loading train:  57%|█████▋    | 163/285 [02:34<01:34,  1.29it/s]Loading train:  58%|█████▊    | 164/285 [02:35<01:31,  1.33it/s]Loading train:  58%|█████▊    | 165/285 [02:36<01:25,  1.40it/s]Loading train:  58%|█████▊    | 166/285 [02:37<01:34,  1.26it/s]Loading train:  59%|█████▊    | 167/285 [02:37<01:33,  1.26it/s]Loading train:  59%|█████▉    | 168/285 [02:38<01:39,  1.18it/s]Loading train:  59%|█████▉    | 169/285 [02:39<01:33,  1.25it/s]Loading train:  60%|█████▉    | 170/285 [02:40<01:26,  1.32it/s]Loading train:  60%|██████    | 171/285 [02:40<01:22,  1.37it/s]Loading train:  60%|██████    | 172/285 [02:41<01:21,  1.38it/s]Loading train:  61%|██████    | 173/285 [02:42<01:26,  1.30it/s]Loading train:  61%|██████    | 174/285 [02:43<01:23,  1.32it/s]Loading train:  61%|██████▏   | 175/285 [02:44<01:26,  1.28it/s]Loading train:  62%|██████▏   | 176/285 [02:44<01:23,  1.30it/s]Loading train:  62%|██████▏   | 177/285 [02:45<01:20,  1.35it/s]Loading train:  62%|██████▏   | 178/285 [02:46<01:22,  1.30it/s]Loading train:  63%|██████▎   | 179/285 [02:46<01:17,  1.37it/s]Loading train:  63%|██████▎   | 180/285 [02:48<01:29,  1.17it/s]Loading train:  64%|██████▎   | 181/285 [02:48<01:26,  1.20it/s]Loading train:  64%|██████▍   | 182/285 [02:49<01:26,  1.19it/s]Loading train:  64%|██████▍   | 183/285 [02:50<01:25,  1.19it/s]Loading train:  65%|██████▍   | 184/285 [02:51<01:20,  1.26it/s]Loading train:  65%|██████▍   | 185/285 [02:51<01:17,  1.29it/s]Loading train:  65%|██████▌   | 186/285 [02:52<01:22,  1.20it/s]Loading train:  66%|██████▌   | 187/285 [02:53<01:28,  1.11it/s]Loading train:  66%|██████▌   | 188/285 [02:54<01:29,  1.08it/s]Loading train:  66%|██████▋   | 189/285 [02:55<01:25,  1.12it/s]Loading train:  67%|██████▋   | 190/285 [02:56<01:19,  1.20it/s]Loading train:  67%|██████▋   | 191/285 [02:57<01:18,  1.20it/s]Loading train:  67%|██████▋   | 192/285 [02:58<01:15,  1.23it/s]Loading train:  68%|██████▊   | 193/285 [02:58<01:14,  1.23it/s]Loading train:  68%|██████▊   | 194/285 [02:59<01:11,  1.28it/s]Loading train:  68%|██████▊   | 195/285 [03:00<01:10,  1.27it/s]Loading train:  69%|██████▉   | 196/285 [03:01<01:15,  1.18it/s]Loading train:  69%|██████▉   | 197/285 [03:02<01:18,  1.13it/s]Loading train:  69%|██████▉   | 198/285 [03:03<01:21,  1.07it/s]Loading train:  70%|██████▉   | 199/285 [03:04<01:14,  1.15it/s]Loading train:  70%|███████   | 200/285 [03:04<01:09,  1.22it/s]Loading train:  71%|███████   | 201/285 [03:05<01:10,  1.19it/s]Loading train:  71%|███████   | 202/285 [03:06<01:11,  1.15it/s]Loading train:  71%|███████   | 203/285 [03:07<01:07,  1.22it/s]Loading train:  72%|███████▏  | 204/285 [03:08<01:04,  1.25it/s]Loading train:  72%|███████▏  | 205/285 [03:08<01:00,  1.32it/s]Loading train:  72%|███████▏  | 206/285 [03:09<00:56,  1.39it/s]Loading train:  73%|███████▎  | 207/285 [03:10<01:00,  1.29it/s]Loading train:  73%|███████▎  | 208/285 [03:11<01:03,  1.21it/s]Loading train:  73%|███████▎  | 209/285 [03:12<01:06,  1.14it/s]Loading train:  74%|███████▎  | 210/285 [03:12<01:01,  1.22it/s]Loading train:  74%|███████▍  | 211/285 [03:13<01:02,  1.18it/s]Loading train:  74%|███████▍  | 212/285 [03:14<01:00,  1.20it/s]Loading train:  75%|███████▍  | 213/285 [03:15<01:03,  1.14it/s]Loading train:  75%|███████▌  | 214/285 [03:16<00:57,  1.24it/s]Loading train:  75%|███████▌  | 215/285 [03:17<01:03,  1.11it/s]Loading train:  76%|███████▌  | 216/285 [03:18<00:58,  1.18it/s]Loading train:  76%|███████▌  | 217/285 [03:19<01:01,  1.11it/s]Loading train:  76%|███████▋  | 218/285 [03:20<01:00,  1.11it/s]Loading train:  77%|███████▋  | 219/285 [03:20<01:00,  1.09it/s]Loading train:  77%|███████▋  | 220/285 [03:21<00:55,  1.18it/s]Loading train:  78%|███████▊  | 221/285 [03:22<00:54,  1.18it/s]Loading train:  78%|███████▊  | 222/285 [03:23<00:51,  1.22it/s]Loading train:  78%|███████▊  | 223/285 [03:23<00:47,  1.30it/s]Loading train:  79%|███████▊  | 224/285 [03:24<00:47,  1.27it/s]Loading train:  79%|███████▉  | 225/285 [03:25<00:46,  1.30it/s]Loading train:  79%|███████▉  | 226/285 [03:26<00:51,  1.15it/s]Loading train:  80%|███████▉  | 227/285 [03:27<00:51,  1.12it/s]Loading train:  80%|████████  | 228/285 [03:28<00:51,  1.11it/s]Loading train:  80%|████████  | 229/285 [03:29<00:48,  1.15it/s]Loading train:  81%|████████  | 230/285 [03:29<00:45,  1.20it/s]Loading train:  81%|████████  | 231/285 [03:30<00:45,  1.20it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:44,  1.18it/s]Loading train:  82%|████████▏ | 233/285 [03:32<00:41,  1.25it/s]Loading train:  82%|████████▏ | 234/285 [03:33<00:46,  1.10it/s]Loading train:  82%|████████▏ | 235/285 [03:34<00:40,  1.24it/s]Loading train:  83%|████████▎ | 236/285 [03:34<00:39,  1.25it/s]Loading train:  83%|████████▎ | 237/285 [03:35<00:39,  1.22it/s]Loading train:  84%|████████▎ | 238/285 [03:36<00:39,  1.19it/s]Loading train:  84%|████████▍ | 239/285 [03:37<00:38,  1.19it/s]Loading train:  84%|████████▍ | 240/285 [03:38<00:38,  1.18it/s]Loading train:  85%|████████▍ | 241/285 [03:39<00:37,  1.16it/s]Loading train:  85%|████████▍ | 242/285 [03:39<00:35,  1.23it/s]Loading train:  85%|████████▌ | 243/285 [03:40<00:35,  1.18it/s]Loading train:  86%|████████▌ | 244/285 [03:41<00:35,  1.15it/s]Loading train:  86%|████████▌ | 245/285 [03:42<00:34,  1.17it/s]Loading train:  86%|████████▋ | 246/285 [03:43<00:33,  1.16it/s]Loading train:  87%|████████▋ | 247/285 [03:44<00:34,  1.11it/s]Loading train:  87%|████████▋ | 248/285 [03:45<00:31,  1.16it/s]Loading train:  87%|████████▋ | 249/285 [03:46<00:32,  1.12it/s]Loading train:  88%|████████▊ | 250/285 [03:47<00:31,  1.12it/s]Loading train:  88%|████████▊ | 251/285 [03:47<00:28,  1.18it/s]Loading train:  88%|████████▊ | 252/285 [03:48<00:26,  1.24it/s]Loading train:  89%|████████▉ | 253/285 [03:49<00:26,  1.20it/s]Loading train:  89%|████████▉ | 254/285 [03:50<00:26,  1.16it/s]Loading train:  89%|████████▉ | 255/285 [03:51<00:24,  1.22it/s]Loading train:  90%|████████▉ | 256/285 [03:51<00:22,  1.30it/s]Loading train:  90%|█████████ | 257/285 [03:52<00:22,  1.23it/s]Loading train:  91%|█████████ | 258/285 [03:53<00:23,  1.13it/s]Loading train:  91%|█████████ | 259/285 [03:54<00:22,  1.16it/s]Loading train:  91%|█████████ | 260/285 [03:55<00:21,  1.18it/s]Loading train:  92%|█████████▏| 261/285 [03:56<00:19,  1.25it/s]Loading train:  92%|█████████▏| 262/285 [03:56<00:18,  1.24it/s]Loading train:  92%|█████████▏| 263/285 [03:57<00:17,  1.27it/s]Loading train:  93%|█████████▎| 264/285 [03:58<00:17,  1.18it/s]Loading train:  93%|█████████▎| 265/285 [03:59<00:17,  1.15it/s]Loading train:  93%|█████████▎| 266/285 [04:00<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [04:00<00:14,  1.25it/s]Loading train:  94%|█████████▍| 268/285 [04:01<00:14,  1.17it/s]Loading train:  94%|█████████▍| 269/285 [04:02<00:13,  1.17it/s]Loading train:  95%|█████████▍| 270/285 [04:03<00:11,  1.26it/s]Loading train:  95%|█████████▌| 271/285 [04:04<00:10,  1.33it/s]Loading train:  95%|█████████▌| 272/285 [04:04<00:09,  1.30it/s]Loading train:  96%|█████████▌| 273/285 [04:05<00:09,  1.32it/s]Loading train:  96%|█████████▌| 274/285 [04:06<00:08,  1.28it/s]Loading train:  96%|█████████▋| 275/285 [04:07<00:08,  1.21it/s]Loading train:  97%|█████████▋| 276/285 [04:08<00:07,  1.19it/s]Loading train:  97%|█████████▋| 277/285 [04:09<00:06,  1.18it/s]Loading train:  98%|█████████▊| 278/285 [04:10<00:06,  1.16it/s]Loading train:  98%|█████████▊| 279/285 [04:10<00:05,  1.17it/s]Loading train:  98%|█████████▊| 280/285 [04:11<00:03,  1.27it/s]Loading train:  99%|█████████▊| 281/285 [04:12<00:03,  1.24it/s]Loading train:  99%|█████████▉| 282/285 [04:13<00:02,  1.26it/s]Loading train:  99%|█████████▉| 283/285 [04:14<00:01,  1.13it/s]Loading train: 100%|█████████▉| 284/285 [04:15<00:00,  1.15it/s]Loading train: 100%|██████████| 285/285 [04:16<00:00,  1.10it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:01, 258.53it/s]concatenating: train:  20%|██        | 57/285 [00:00<00:00, 270.13it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:00, 278.37it/s]concatenating: train:  40%|████      | 114/285 [00:00<00:00, 270.81it/s]concatenating: train:  48%|████▊     | 136/285 [00:00<00:00, 180.80it/s]concatenating: train:  54%|█████▍    | 154/285 [00:00<00:00, 159.45it/s]concatenating: train:  65%|██████▍   | 185/285 [00:00<00:00, 186.49it/s]concatenating: train:  78%|███████▊  | 221/285 [00:00<00:00, 216.98it/s]concatenating: train:  90%|████████▉ | 256/285 [00:01<00:00, 243.82it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 248.67it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.31s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.23s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 213.86it/s]2019-07-11 07:50:46.276765: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 07:50:46.276895: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 07:50:46.276911: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 07:50:46.276920: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 07:50:46.277335: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.15it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  5.02it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.63it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.93it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.19it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.84it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.29it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  6.91it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.25it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.89it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.29it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.48it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.63it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.31it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.44it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.85it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.27it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.77it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.51it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.82it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  8.87it/s] 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   1500        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 10)   4060        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 80, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 80, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 80, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 55)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 80, 13)   728         concatenate_8[0][0]              
==================================================================================================
Total params: 134,098
Trainable params: 35,558
Non-trainable params: 98,540
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 16s - loss: 3.4978 - acc: 0.1158 - mDice: 0.0415 - val_loss: 3.1362 - val_acc: 0.1284 - val_mDice: 0.0973

Epoch 00001: val_mDice improved from -inf to 0.09725, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 10s - loss: 1.8168 - acc: 0.7278 - mDice: 0.1778 - val_loss: 2.1798 - val_acc: 0.8967 - val_mDice: 0.2038

Epoch 00002: val_mDice improved from 0.09725 to 0.20379, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 9s - loss: 1.2314 - acc: 0.8713 - mDice: 0.2863 - val_loss: 1.7291 - val_acc: 0.9076 - val_mDice: 0.2924

Epoch 00003: val_mDice improved from 0.20379 to 0.29244, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 1.0266 - acc: 0.8752 - mDice: 0.3461 - val_loss: 1.4166 - val_acc: 0.9112 - val_mDice: 0.3877

Epoch 00004: val_mDice improved from 0.29244 to 0.38773, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 9s - loss: 0.8950 - acc: 0.8790 - mDice: 0.3941 - val_loss: 1.3304 - val_acc: 0.9181 - val_mDice: 0.4076

Epoch 00005: val_mDice improved from 0.38773 to 0.40762, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 9s - loss: 0.7975 - acc: 0.8831 - mDice: 0.4350 - val_loss: 1.2567 - val_acc: 0.9212 - val_mDice: 0.4394

Epoch 00006: val_mDice improved from 0.40762 to 0.43936, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 9s - loss: 0.7278 - acc: 0.8864 - mDice: 0.4671 - val_loss: 1.2290 - val_acc: 0.9221 - val_mDice: 0.4600

Epoch 00007: val_mDice improved from 0.43936 to 0.45996, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.6811 - acc: 0.8905 - mDice: 0.4898 - val_loss: 1.1342 - val_acc: 0.9254 - val_mDice: 0.4857

Epoch 00008: val_mDice improved from 0.45996 to 0.48571, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 10s - loss: 0.6437 - acc: 0.8946 - mDice: 0.5087 - val_loss: 1.1611 - val_acc: 0.9236 - val_mDice: 0.4801

Epoch 00009: val_mDice did not improve from 0.48571
Epoch 10/300
 - 9s - loss: 0.6181 - acc: 0.8980 - mDice: 0.5226 - val_loss: 1.1365 - val_acc: 0.9267 - val_mDice: 0.4891

Epoch 00010: val_mDice improved from 0.48571 to 0.48905, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 9s - loss: 0.5933 - acc: 0.9011 - mDice: 0.5360 - val_loss: 1.1335 - val_acc: 0.9307 - val_mDice: 0.4791

Epoch 00011: val_mDice did not improve from 0.48905
Epoch 12/300
 - 10s - loss: 0.5727 - acc: 0.9039 - mDice: 0.5475 - val_loss: 1.0793 - val_acc: 0.9308 - val_mDice: 0.4991

Epoch 00012: val_mDice improved from 0.48905 to 0.49910, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 10s - loss: 0.5575 - acc: 0.9066 - mDice: 0.5561 - val_loss: 1.0855 - val_acc: 0.9316 - val_mDice: 0.4916

Epoch 00013: val_mDice did not improve from 0.49910
Epoch 14/300
 - 9s - loss: 0.5406 - acc: 0.9089 - mDice: 0.5658 - val_loss: 1.0636 - val_acc: 0.9314 - val_mDice: 0.5073

Epoch 00014: val_mDice improved from 0.49910 to 0.50725, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 10s - loss: 0.5313 - acc: 0.9110 - mDice: 0.5713 - val_loss: 1.0764 - val_acc: 0.9307 - val_mDice: 0.4682

Epoch 00015: val_mDice did not improve from 0.50725
Epoch 16/300
 - 10s - loss: 0.5198 - acc: 0.9131 - mDice: 0.5782 - val_loss: 1.0511 - val_acc: 0.9198 - val_mDice: 0.5020

Epoch 00016: val_mDice did not improve from 0.50725
Epoch 17/300
 - 10s - loss: 0.5100 - acc: 0.9146 - mDice: 0.5840 - val_loss: 0.9976 - val_acc: 0.9329 - val_mDice: 0.5158

Epoch 00017: val_mDice improved from 0.50725 to 0.51582, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 9s - loss: 0.4997 - acc: 0.9158 - mDice: 0.5903 - val_loss: 1.0229 - val_acc: 0.9325 - val_mDice: 0.5230

Epoch 00018: val_mDice improved from 0.51582 to 0.52298, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 19/300
 - 9s - loss: 0.4936 - acc: 0.9170 - mDice: 0.5940 - val_loss: 0.9546 - val_acc: 0.9320 - val_mDice: 0.5309

Epoch 00019: val_mDice improved from 0.52298 to 0.53088, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 10s - loss: 0.4834 - acc: 0.9180 - mDice: 0.6004 - val_loss: 1.1606 - val_acc: 0.9132 - val_mDice: 0.4908

Epoch 00020: val_mDice did not improve from 0.53088
Epoch 21/300
 - 10s - loss: 0.4768 - acc: 0.9186 - mDice: 0.6044 - val_loss: 0.9979 - val_acc: 0.9306 - val_mDice: 0.5192

Epoch 00021: val_mDice did not improve from 0.53088
Epoch 22/300
 - 10s - loss: 0.4706 - acc: 0.9194 - mDice: 0.6085 - val_loss: 0.9455 - val_acc: 0.9312 - val_mDice: 0.5224

Epoch 00022: val_mDice did not improve from 0.53088
Epoch 23/300
 - 10s - loss: 0.4644 - acc: 0.9202 - mDice: 0.6123 - val_loss: 0.9453 - val_acc: 0.9291 - val_mDice: 0.5243

Epoch 00023: val_mDice did not improve from 0.53088
Epoch 24/300
 - 10s - loss: 0.4574 - acc: 0.9208 - mDice: 0.6168 - val_loss: 0.9065 - val_acc: 0.9285 - val_mDice: 0.5262

Epoch 00024: val_mDice did not improve from 0.53088
Epoch 25/300
 - 10s - loss: 0.4559 - acc: 0.9213 - mDice: 0.6177 - val_loss: 0.9055 - val_acc: 0.9340 - val_mDice: 0.5274

Epoch 00025: val_mDice did not improve from 0.53088
Epoch 26/300
 - 10s - loss: 0.4509 - acc: 0.9217 - mDice: 0.6210 - val_loss: 0.9587 - val_acc: 0.9218 - val_mDice: 0.5122

Epoch 00026: val_mDice did not improve from 0.53088
Epoch 27/300
 - 10s - loss: 0.4453 - acc: 0.9226 - mDice: 0.6245 - val_loss: 0.9112 - val_acc: 0.9278 - val_mDice: 0.5134

Epoch 00027: val_mDice did not improve from 0.53088
Epoch 28/300
 - 9s - loss: 0.4410 - acc: 0.9232 - mDice: 0.6274 - val_loss: 0.9146 - val_acc: 0.9368 - val_mDice: 0.5320

Epoch 00028: val_mDice improved from 0.53088 to 0.53199, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 29/300
 - 9s - loss: 0.4392 - acc: 0.9235 - mDice: 0.6287 - val_loss: 0.8626 - val_acc: 0.9331 - val_mDice: 0.5397

Epoch 00029: val_mDice improved from 0.53199 to 0.53972, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 10s - loss: 0.4342 - acc: 0.9240 - mDice: 0.6320 - val_loss: 0.8853 - val_acc: 0.9331 - val_mDice: 0.5305

Epoch 00030: val_mDice did not improve from 0.53972
Epoch 31/300
 - 10s - loss: 0.4312 - acc: 0.9245 - mDice: 0.6340 - val_loss: 0.8499 - val_acc: 0.9298 - val_mDice: 0.5268

Epoch 00031: val_mDice did not improve from 0.53972
Epoch 32/300
 - 10s - loss: 0.4318 - acc: 0.9247 - mDice: 0.6337 - val_loss: 0.8813 - val_acc: 0.9302 - val_mDice: 0.5310

Epoch 00032: val_mDice did not improve from 0.53972
Epoch 33/300
 - 10s - loss: 0.4234 - acc: 0.9256 - mDice: 0.6391 - val_loss: 0.8599 - val_acc: 0.9353 - val_mDice: 0.5271

Epoch 00033: val_mDice did not improve from 0.53972
Epoch 34/300
 - 10s - loss: 0.4229 - acc: 0.9259 - mDice: 0.6394 - val_loss: 0.8490 - val_acc: 0.9369 - val_mDice: 0.5284

Epoch 00034: val_mDice did not improve from 0.53972
Epoch 35/300
 - 9s - loss: 0.4191 - acc: 0.9264 - mDice: 0.6419 - val_loss: 0.9467 - val_acc: 0.9372 - val_mDice: 0.5180

Epoch 00035: val_mDice did not improve from 0.53972
Epoch 36/300
 - 9s - loss: 0.4148 - acc: 0.9267 - mDice: 0.6449 - val_loss: 0.8276 - val_acc: 0.9314 - val_mDice: 0.5380

Epoch 00036: val_mDice did not improve from 0.53972
Epoch 37/300
 - 10s - loss: 0.4129 - acc: 0.9271 - mDice: 0.6461 - val_loss: 0.8245 - val_acc: 0.9386 - val_mDice: 0.5358

Epoch 00037: val_mDice did not improve from 0.53972
Epoch 38/300
 - 10s - loss: 0.4109 - acc: 0.9275 - mDice: 0.6475 - val_loss: 0.8019 - val_acc: 0.9364 - val_mDice: 0.5198

Epoch 00038: val_mDice did not improve from 0.53972
Epoch 39/300
 - 10s - loss: 0.4086 - acc: 0.9279 - mDice: 0.6491 - val_loss: 0.8494 - val_acc: 0.9362 - val_mDice: 0.5334

Epoch 00039: val_mDice did not improve from 0.53972
Epoch 40/300
 - 10s - loss: 0.4059 - acc: 0.9282 - mDice: 0.6508 - val_loss: 0.8238 - val_acc: 0.9372 - val_mDice: 0.5327

Epoch 00040: val_mDice did not improve from 0.53972
Epoch 41/300
 - 10s - loss: 0.4033 - acc: 0.9285 - mDice: 0.6526 - val_loss: 0.7909 - val_acc: 0.9414 - val_mDice: 0.5372

Epoch 00041: val_mDice did not improve from 0.53972
Epoch 42/300
 - 9s - loss: 0.4017 - acc: 0.9288 - mDice: 0.6536 - val_loss: 0.8760 - val_acc: 0.9270 - val_mDice: 0.5287

Epoch 00042: val_mDice did not improve from 0.53972
Epoch 43/300
 - 10s - loss: 0.4001 - acc: 0.9290 - mDice: 0.6548 - val_loss: 0.8715 - val_acc: 0.9389 - val_mDice: 0.5047

Epoch 00043: val_mDice did not improve from 0.53972
Epoch 44/300
 - 10s - loss: 0.3994 - acc: 0.9293 - mDice: 0.6553 - val_loss: 0.7882 - val_acc: 0.9362 - val_mDice: 0.5353

Epoch 00044: val_mDice did not improve from 0.53972
Epoch 45/300
 - 9s - loss: 0.3987 - acc: 0.9294 - mDice: 0.6559 - val_loss: 0.8168 - val_acc: 0.9309 - val_mDice: 0.5227

Epoch 00045: val_mDice did not improve from 0.53972
Epoch 46/300
 - 10s - loss: 0.3950 - acc: 0.9297 - mDice: 0.6583 - val_loss: 0.7929 - val_acc: 0.9293 - val_mDice: 0.5321

Epoch 00046: val_mDice did not improve from 0.53972
Epoch 47/300
 - 10s - loss: 0.3922 - acc: 0.9302 - mDice: 0.6601 - val_loss: 0.7652 - val_acc: 0.9329 - val_mDice: 0.5311

Epoch 00047: val_mDice did not improve from 0.53972
Epoch 48/300
 - 10s - loss: 0.3905 - acc: 0.9306 - mDice: 0.6614 - val_loss: 0.7744 - val_acc: 0.9385 - val_mDice: 0.5372

Epoch 00048: val_mDice did not improve from 0.53972
Epoch 49/300
 - 10s - loss: 0.3890 - acc: 0.9307 - mDice: 0.6624 - val_loss: 0.7802 - val_acc: 0.9410 - val_mDice: 0.5307

Epoch 00049: val_mDice did not improve from 0.53972
Epoch 50/300
 - 11s - loss: 0.3880 - acc: 0.9308 - mDice: 0.6632 - val_loss: 0.8419 - val_acc: 0.9246 - val_mDice: 0.5087

Epoch 00050: val_mDice did not improve from 0.53972
Epoch 51/300
 - 10s - loss: 0.3854 - acc: 0.9311 - mDice: 0.6649 - val_loss: 0.7619 - val_acc: 0.9368 - val_mDice: 0.5359

Epoch 00051: val_mDice did not improve from 0.53972
Epoch 52/300
 - 10s - loss: 0.3856 - acc: 0.9310 - mDice: 0.6648 - val_loss: 0.7804 - val_acc: 0.9372 - val_mDice: 0.5369

Epoch 00052: val_mDice did not improve from 0.53972
Epoch 53/300
 - 10s - loss: 0.3842 - acc: 0.9314 - mDice: 0.6658 - val_loss: 0.8373 - val_acc: 0.9390 - val_mDice: 0.5423

Epoch 00053: val_mDice improved from 0.53972 to 0.54231, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 54/300
 - 10s - loss: 0.3817 - acc: 0.9317 - mDice: 0.6675 - val_loss: 0.8072 - val_acc: 0.9369 - val_mDice: 0.5289

Epoch 00054: val_mDice did not improve from 0.54231
Epoch 55/300
 - 10s - loss: 0.3820 - acc: 0.9316 - mDice: 0.6673 - val_loss: 0.7484 - val_acc: 0.9298 - val_mDice: 0.5278

Epoch 00055: val_mDice did not improve from 0.54231
Epoch 56/300
 - 10s - loss: 0.3781 - acc: 0.9319 - mDice: 0.6699 - val_loss: 0.7562 - val_acc: 0.9345 - val_mDice: 0.5355

Epoch 00056: val_mDice did not improve from 0.54231
Epoch 57/300
 - 10s - loss: 0.3774 - acc: 0.9322 - mDice: 0.6706 - val_loss: 0.7357 - val_acc: 0.9349 - val_mDice: 0.5372

Epoch 00057: val_mDice did not improve from 0.54231
Epoch 58/300
 - 10s - loss: 0.3772 - acc: 0.9321 - mDice: 0.6706 - val_loss: 0.7264 - val_acc: 0.9358 - val_mDice: 0.5439

Epoch 00058: val_mDice improved from 0.54231 to 0.54390, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 59/300
 - 11s - loss: 0.3776 - acc: 0.9322 - mDice: 0.6703 - val_loss: 0.7255 - val_acc: 0.9392 - val_mDice: 0.5426

Epoch 00059: val_mDice did not improve from 0.54390
Epoch 60/300
 - 10s - loss: 0.3767 - acc: 0.9324 - mDice: 0.6710 - val_loss: 0.7158 - val_acc: 0.9334 - val_mDice: 0.5394

Epoch 00060: val_mDice did not improve from 0.54390
Epoch 61/300
 - 10s - loss: 0.3729 - acc: 0.9327 - mDice: 0.6736 - val_loss: 0.7318 - val_acc: 0.9359 - val_mDice: 0.5389

Epoch 00061: val_mDice did not improve from 0.54390
Epoch 62/300
 - 10s - loss: 0.3727 - acc: 0.9326 - mDice: 0.6738 - val_loss: 0.7163 - val_acc: 0.9388 - val_mDice: 0.5490

Epoch 00062: val_mDice improved from 0.54390 to 0.54901, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 63/300
 - 10s - loss: 0.3711 - acc: 0.9329 - mDice: 0.6748 - val_loss: 0.7602 - val_acc: 0.9408 - val_mDice: 0.5298

Epoch 00063: val_mDice did not improve from 0.54901
Epoch 64/300
 - 10s - loss: 0.3733 - acc: 0.9329 - mDice: 0.6735 - val_loss: 0.7268 - val_acc: 0.9363 - val_mDice: 0.5465

Epoch 00064: val_mDice did not improve from 0.54901
Epoch 65/300
 - 10s - loss: 0.3713 - acc: 0.9330 - mDice: 0.6749 - val_loss: 0.7649 - val_acc: 0.9340 - val_mDice: 0.5316

Epoch 00065: val_mDice did not improve from 0.54901
Epoch 66/300
 - 10s - loss: 0.3679 - acc: 0.9333 - mDice: 0.6771 - val_loss: 0.7710 - val_acc: 0.9334 - val_mDice: 0.5128

Epoch 00066: val_mDice did not improve from 0.54901
Epoch 67/300
 - 10s - loss: 0.3671 - acc: 0.9335 - mDice: 0.6778 - val_loss: 0.6454 - val_acc: 0.9376 - val_mDice: 0.5489

Epoch 00067: val_mDice did not improve from 0.54901
Epoch 68/300
 - 10s - loss: 0.3650 - acc: 0.9337 - mDice: 0.6792 - val_loss: 0.6619 - val_acc: 0.9386 - val_mDice: 0.5424

Epoch 00068: val_mDice did not improve from 0.54901
Epoch 69/300
 - 10s - loss: 0.3669 - acc: 0.9337 - mDice: 0.6779 - val_loss: 0.7046 - val_acc: 0.9332 - val_mDice: 0.5268

Epoch 00069: val_mDice did not improve from 0.54901
Epoch 70/300
 - 10s - loss: 0.3632 - acc: 0.9339 - mDice: 0.6804 - val_loss: 0.6955 - val_acc: 0.9361 - val_mDice: 0.5457

Epoch 00070: val_mDice did not improve from 0.54901
Epoch 71/300
 - 10s - loss: 0.3656 - acc: 0.9339 - mDice: 0.6788 - val_loss: 0.6410 - val_acc: 0.9400 - val_mDice: 0.5486

Epoch 00071: val_mDice did not improve from 0.54901
Epoch 72/300
 - 10s - loss: 0.3618 - acc: 0.9340 - mDice: 0.6814 - val_loss: 0.6599 - val_acc: 0.9415 - val_mDice: 0.5235

Epoch 00072: val_mDice did not improve from 0.54901
Epoch 73/300
 - 10s - loss: 0.3630 - acc: 0.9341 - mDice: 0.6806 - val_loss: 0.7197 - val_acc: 0.9363 - val_mDice: 0.5331

Epoch 00073: val_mDice did not improve from 0.54901
Epoch 74/300
 - 10s - loss: 0.3606 - acc: 0.9343 - mDice: 0.6823 - val_loss: 0.6744 - val_acc: 0.9373 - val_mDice: 0.5393

Epoch 00074: val_mDice did not improve from 0.54901
Epoch 75/300
 - 10s - loss: 0.3588 - acc: 0.9344 - mDice: 0.6836 - val_loss: 0.6797 - val_acc: 0.9411 - val_mDice: 0.5431

Epoch 00075: val_mDice did not improve from 0.54901
Epoch 76/300
 - 10s - loss: 0.3621 - acc: 0.9343 - mDice: 0.6813 - val_loss: 0.6399 - val_acc: 0.9396 - val_mDice: 0.5459

Epoch 00076: val_mDice did not improve from 0.54901
Epoch 77/300
 - 10s - loss: 0.3598 - acc: 0.9345 - mDice: 0.6830 - val_loss: 0.7027 - val_acc: 0.9396 - val_mDice: 0.5425

Epoch 00077: val_mDice did not improve from 0.54901
Epoch 78/300
 - 10s - loss: 0.3559 - acc: 0.9348 - mDice: 0.6856 - val_loss: 0.7173 - val_acc: 0.9388 - val_mDice: 0.5349

Epoch 00078: val_mDice did not improve from 0.54901
Epoch 79/300
 - 10s - loss: 0.3565 - acc: 0.9348 - mDice: 0.6852 - val_loss: 0.6765 - val_acc: 0.9402 - val_mDice: 0.5468

Epoch 00079: val_mDice did not improve from 0.54901
Epoch 80/300
 - 10s - loss: 0.3548 - acc: 0.9349 - mDice: 0.6864 - val_loss: 0.7049 - val_acc: 0.9334 - val_mDice: 0.5395

Epoch 00080: val_mDice did not improve from 0.54901
Epoch 81/300
 - 11s - loss: 0.3551 - acc: 0.9350 - mDice: 0.6863 - val_loss: 0.6494 - val_acc: 0.9396 - val_mDice: 0.5488

Epoch 00081: val_mDice did not improve from 0.54901
Epoch 82/300
 - 10s - loss: 0.3548 - acc: 0.9351 - mDice: 0.6865 - val_loss: 0.6823 - val_acc: 0.9385 - val_mDice: 0.5404

Epoch 00082: val_mDice did not improve from 0.54901
Epoch 83/300
 - 10s - loss: 0.3526 - acc: 0.9354 - mDice: 0.6881 - val_loss: 0.6752 - val_acc: 0.9411 - val_mDice: 0.5424

Epoch 00083: val_mDice did not improve from 0.54901
Epoch 84/300
 - 10s - loss: 0.3531 - acc: 0.9352 - mDice: 0.6876 - val_loss: 0.7003 - val_acc: 0.9324 - val_mDice: 0.5293

Epoch 00084: val_mDice did not improve from 0.54901
Epoch 85/300
 - 10s - loss: 0.3525 - acc: 0.9354 - mDice: 0.6881 - val_loss: 0.6643 - val_acc: 0.9308 - val_mDice: 0.5289

Epoch 00085: val_mDice did not improve from 0.54901
Epoch 86/300
 - 10s - loss: 0.3507 - acc: 0.9354 - mDice: 0.6894 - val_loss: 0.6578 - val_acc: 0.9424 - val_mDice: 0.5375

Epoch 00086: val_mDice did not improve from 0.54901
Epoch 87/300
 - 9s - loss: 0.3499 - acc: 0.9357 - mDice: 0.6900 - val_loss: 0.6378 - val_acc: 0.9346 - val_mDice: 0.5370

Epoch 00087: val_mDice did not improve from 0.54901
Epoch 88/300
 - 9s - loss: 0.3504 - acc: 0.9354 - mDice: 0.6896 - val_loss: 0.7180 - val_acc: 0.9405 - val_mDice: 0.5373

Epoch 00088: val_mDice did not improve from 0.54901
Epoch 89/300
 - 10s - loss: 0.3481 - acc: 0.9356 - mDice: 0.6912 - val_loss: 0.6568 - val_acc: 0.9327 - val_mDice: 0.5136

Epoch 00089: val_mDice did not improve from 0.54901
Epoch 90/300
 - 10s - loss: 0.3493 - acc: 0.9358 - mDice: 0.6905 - val_loss: 0.6991 - val_acc: 0.9405 - val_mDice: 0.5493

Epoch 00090: val_mDice improved from 0.54901 to 0.54928, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 91/300
 - 9s - loss: 0.3463 - acc: 0.9361 - mDice: 0.6925 - val_loss: 0.7343 - val_acc: 0.9300 - val_mDice: 0.5256

Epoch 00091: val_mDice did not improve from 0.54928
Epoch 92/300
 - 9s - loss: 0.3467 - acc: 0.9361 - mDice: 0.6923 - val_loss: 0.6783 - val_acc: 0.9418 - val_mDice: 0.5519

Epoch 00092: val_mDice improved from 0.54928 to 0.55186, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 93/300
 - 9s - loss: 0.3478 - acc: 0.9359 - mDice: 0.6915 - val_loss: 0.6640 - val_acc: 0.9377 - val_mDice: 0.5430

Epoch 00093: val_mDice did not improve from 0.55186
Epoch 94/300
 - 9s - loss: 0.3452 - acc: 0.9362 - mDice: 0.6934 - val_loss: 0.6481 - val_acc: 0.9354 - val_mDice: 0.5369

Epoch 00094: val_mDice did not improve from 0.55186
Epoch 95/300
 - 10s - loss: 0.3449 - acc: 0.9363 - mDice: 0.6935 - val_loss: 0.6778 - val_acc: 0.9407 - val_mDice: 0.5394

Epoch 00095: val_mDice did not improve from 0.55186
Epoch 96/300
 - 10s - loss: 0.3456 - acc: 0.9363 - mDice: 0.6931 - val_loss: 0.6300 - val_acc: 0.9373 - val_mDice: 0.5452

Epoch 00096: val_mDice did not improve from 0.55186
Epoch 97/300
 - 9s - loss: 0.3457 - acc: 0.9362 - mDice: 0.6929 - val_loss: 0.7147 - val_acc: 0.9394 - val_mDice: 0.5385

Epoch 00097: val_mDice did not improve from 0.55186
Epoch 98/300
 - 9s - loss: 0.3445 - acc: 0.9362 - mDice: 0.6939 - val_loss: 0.6900 - val_acc: 0.9385 - val_mDice: 0.5402

Epoch 00098: val_mDice did not improve from 0.55186
Epoch 99/300
 - 9s - loss: 0.3431 - acc: 0.9363 - mDice: 0.6948 - val_loss: 0.7151 - val_acc: 0.9321 - val_mDice: 0.5385

Epoch 00099: val_mDice did not improve from 0.55186
Epoch 100/300
 - 10s - loss: 0.3435 - acc: 0.9364 - mDice: 0.6945 - val_loss: 0.6081 - val_acc: 0.9366 - val_mDice: 0.5395

Epoch 00100: val_mDice did not improve from 0.55186
Epoch 101/300
 - 9s - loss: 0.3430 - acc: 0.9364 - mDice: 0.6949 - val_loss: 0.6437 - val_acc: 0.9413 - val_mDice: 0.5381

Epoch 00101: val_mDice did not improve from 0.55186
Epoch 102/300
 - 9s - loss: 0.3402 - acc: 0.9369 - mDice: 0.6970 - val_loss: 0.6791 - val_acc: 0.9428 - val_mDice: 0.5496

Epoch 00102: val_mDice did not improve from 0.55186
Epoch 103/300
 - 9s - loss: 0.3388 - acc: 0.9368 - mDice: 0.6981 - val_loss: 0.7274 - val_acc: 0.9323 - val_mDice: 0.5260

Epoch 00103: val_mDice did not improve from 0.55186
Epoch 104/300
 - 9s - loss: 0.3427 - acc: 0.9365 - mDice: 0.6951 - val_loss: 0.7417 - val_acc: 0.9270 - val_mDice: 0.5144

Epoch 00104: val_mDice did not improve from 0.55186
Epoch 105/300
 - 9s - loss: 0.3412 - acc: 0.9368 - mDice: 0.6962 - val_loss: 0.6893 - val_acc: 0.9404 - val_mDice: 0.5449

Epoch 00105: val_mDice did not improve from 0.55186
Epoch 106/300
 - 10s - loss: 0.3402 - acc: 0.9368 - mDice: 0.6970 - val_loss: 0.6941 - val_acc: 0.9378 - val_mDice: 0.5348

Epoch 00106: val_mDice did not improve from 0.55186
Epoch 107/300
 - 9s - loss: 0.3394 - acc: 0.9369 - mDice: 0.6976 - val_loss: 0.7201 - val_acc: 0.9396 - val_mDice: 0.5305

Epoch 00107: val_mDice did not improve from 0.55186
Epoch 108/300
 - 9s - loss: 0.3400 - acc: 0.9366 - mDice: 0.6972 - val_loss: 0.6984 - val_acc: 0.9350 - val_mDice: 0.5109

Epoch 00108: val_mDice did not improve from 0.55186
Epoch 109/300
 - 9s - loss: 0.3393 - acc: 0.9367 - mDice: 0.6976 - val_loss: 0.6988 - val_acc: 0.9381 - val_mDice: 0.5484

Epoch 00109: val_mDice did not improve from 0.55186
Epoch 110/300
 - 10s - loss: 0.3392 - acc: 0.9369 - mDice: 0.6977 - val_loss: 0.7416 - val_acc: 0.9373 - val_mDice: 0.5251

Epoch 00110: val_mDice did not improve from 0.55186
Epoch 111/300
 - 10s - loss: 0.3381 - acc: 0.9371 - mDice: 0.6985 - val_loss: 0.6617 - val_acc: 0.9390 - val_mDice: 0.5459

Epoch 00111: val_mDice did not improve from 0.55186
Epoch 112/300
 - 9s - loss: 0.3368 - acc: 0.9373 - mDice: 0.6995 - val_loss: 0.7095 - val_acc: 0.9371 - val_mDice: 0.5363

Epoch 00112: val_mDice did not improve from 0.55186
Epoch 113/300
 - 9s - loss: 0.3358 - acc: 0.9372 - mDice: 0.7002 - val_loss: 0.7292 - val_acc: 0.9363 - val_mDice: 0.5303

Epoch 00113: val_mDice did not improve from 0.55186
Epoch 114/300
 - 10s - loss: 0.3348 - acc: 0.9374 - mDice: 0.7008 - val_loss: 0.6861 - val_acc: 0.9410 - val_mDice: 0.5479

Epoch 00114: val_mDice did not improve from 0.55186
Epoch 115/300
 - 9s - loss: 0.3368 - acc: 0.9373 - mDice: 0.6995 - val_loss: 0.6557 - val_acc: 0.9367 - val_mDice: 0.5319

Epoch 00115: val_mDice did not improve from 0.55186
Epoch 116/300
 - 9s - loss: 0.3358 - acc: 0.9374 - mDice: 0.7001 - val_loss: 0.6503 - val_acc: 0.9365 - val_mDice: 0.5418

Epoch 00116: val_mDice did not improve from 0.55186
Epoch 117/300
 - 9s - loss: 0.3334 - acc: 0.9376 - mDice: 0.7019 - val_loss: 0.6809 - val_acc: 0.9397 - val_mDice: 0.5523

Epoch 00117: val_mDice improved from 0.55186 to 0.55226, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 118/300
 - 9s - loss: 0.3346 - acc: 0.9374 - mDice: 0.7010 - val_loss: 0.6762 - val_acc: 0.9342 - val_mDice: 0.5316

Epoch 00118: val_mDice did not improve from 0.55226
Epoch 119/300
 - 9s - loss: 0.3340 - acc: 0.9376 - mDice: 0.7015 - val_loss: 0.6573 - val_acc: 0.9355 - val_mDice: 0.5288

Epoch 00119: val_mDice did not improve from 0.55226
Epoch 120/300
 - 10s - loss: 0.3319 - acc: 0.9376 - mDice: 0.7030 - val_loss: 0.6165 - val_acc: 0.9407 - val_mDice: 0.5321

Epoch 00120: val_mDice did not improve from 0.55226
Epoch 121/300
 - 10s - loss: 0.3329 - acc: 0.9377 - mDice: 0.7023 - val_loss: 0.6801 - val_acc: 0.9337 - val_mDice: 0.5174

Epoch 00121: val_mDice did not improve from 0.55226
Epoch 122/300
 - 9s - loss: 0.3332 - acc: 0.9378 - mDice: 0.7021 - val_loss: 0.6918 - val_acc: 0.9389 - val_mDice: 0.5420

Epoch 00122: val_mDice did not improve from 0.55226
Epoch 123/300
 - 9s - loss: 0.3317 - acc: 0.9378 - mDice: 0.7031 - val_loss: 0.6501 - val_acc: 0.9426 - val_mDice: 0.5448

Epoch 00123: val_mDice did not improve from 0.55226
Epoch 124/300
 - 9s - loss: 0.3316 - acc: 0.9378 - mDice: 0.7033 - val_loss: 0.6242 - val_acc: 0.9444 - val_mDice: 0.5440

Epoch 00124: val_mDice did not improve from 0.55226
Epoch 125/300
 - 9s - loss: 0.3314 - acc: 0.9377 - mDice: 0.7034 - val_loss: 0.6674 - val_acc: 0.9342 - val_mDice: 0.5256

Epoch 00125: val_mDice did not improve from 0.55226
Epoch 126/300
 - 9s - loss: 0.3328 - acc: 0.9376 - mDice: 0.7024 - val_loss: 0.6772 - val_acc: 0.9410 - val_mDice: 0.5501

Epoch 00126: val_mDice did not improve from 0.55226
Epoch 127/300
 - 9s - loss: 0.3306 - acc: 0.9379 - mDice: 0.7040 - val_loss: 0.6167 - val_acc: 0.9422 - val_mDice: 0.5446

Epoch 00127: val_mDice did not improve from 0.55226
Epoch 128/300
 - 9s - loss: 0.3303 - acc: 0.9380 - mDice: 0.7043 - val_loss: 0.6941 - val_acc: 0.9362 - val_mDice: 0.5426

Epoch 00128: val_mDice did not improve from 0.55226
Epoch 129/300
 - 9s - loss: 0.3294 - acc: 0.9380 - mDice: 0.7048 - val_loss: 0.7398 - val_acc: 0.9354 - val_mDice: 0.5202

Epoch 00129: val_mDice did not improve from 0.55226
Epoch 130/300
 - 10s - loss: 0.3283 - acc: 0.9381 - mDice: 0.7057 - val_loss: 0.6439 - val_acc: 0.9451 - val_mDice: 0.5354

Epoch 00130: val_mDice did not improve from 0.55226
Epoch 131/300
 - 10s - loss: 0.3292 - acc: 0.9381 - mDice: 0.7050 - val_loss: 0.7054 - val_acc: 0.9359 - val_mDice: 0.5373

Epoch 00131: val_mDice did not improve from 0.55226
Epoch 132/300
 - 9s - loss: 0.3272 - acc: 0.9383 - mDice: 0.7064 - val_loss: 0.6271 - val_acc: 0.9426 - val_mDice: 0.5478

Epoch 00132: val_mDice did not improve from 0.55226
Epoch 133/300
 - 9s - loss: 0.3295 - acc: 0.9380 - mDice: 0.7047 - val_loss: 0.7000 - val_acc: 0.9407 - val_mDice: 0.5362

Epoch 00133: val_mDice did not improve from 0.55226
Epoch 134/300
 - 9s - loss: 0.3280 - acc: 0.9383 - mDice: 0.7058 - val_loss: 0.6575 - val_acc: 0.9412 - val_mDice: 0.5337

Epoch 00134: val_mDice did not improve from 0.55226
Epoch 135/300
 - 9s - loss: 0.3274 - acc: 0.9384 - mDice: 0.7063 - val_loss: 0.6904 - val_acc: 0.9426 - val_mDice: 0.5370

Epoch 00135: val_mDice did not improve from 0.55226
Epoch 136/300
 - 9s - loss: 0.3269 - acc: 0.9382 - mDice: 0.7067 - val_loss: 0.7309 - val_acc: 0.9412 - val_mDice: 0.5255

Epoch 00136: val_mDice did not improve from 0.55226
Epoch 137/300
 - 9s - loss: 0.3274 - acc: 0.9382 - mDice: 0.7063 - val_loss: 0.6800 - val_acc: 0.9414 - val_mDice: 0.5219

Epoch 00137: val_mDice did not improve from 0.55226
Epoch 138/300
 - 9s - loss: 0.3264 - acc: 0.9385 - mDice: 0.7070 - val_loss: 0.6186 - val_acc: 0.9403 - val_mDice: 0.5362

Epoch 00138: val_mDice did not improve from 0.55226
Epoch 139/300
 - 10s - loss: 0.3262 - acc: 0.9385 - mDice: 0.7072 - val_loss: 0.7207 - val_acc: 0.9345 - val_mDice: 0.5002

Epoch 00139: val_mDice did not improve from 0.55226
Epoch 140/300
 - 10s - loss: 0.3251 - acc: 0.9386 - mDice: 0.7081 - val_loss: 0.6146 - val_acc: 0.9407 - val_mDice: 0.5486

Epoch 00140: val_mDice did not improve from 0.55226
Epoch 141/300
 - 9s - loss: 0.3249 - acc: 0.9386 - mDice: 0.7081 - val_loss: 0.6581 - val_acc: 0.9344 - val_mDice: 0.5356

Epoch 00141: val_mDice did not improve from 0.55226
Epoch 142/300
 - 9s - loss: 0.3241 - acc: 0.9385 - mDice: 0.7086 - val_loss: 0.6611 - val_acc: 0.9385 - val_mDice: 0.5434

Epoch 00142: val_mDice did not improve from 0.55226
Epoch 143/300
 - 9s - loss: 0.3237 - acc: 0.9387 - mDice: 0.7090 - val_loss: 0.7125 - val_acc: 0.9400 - val_mDice: 0.5354

Epoch 00143: val_mDice did not improve from 0.55226
Epoch 144/300
 - 10s - loss: 0.3240 - acc: 0.9387 - mDice: 0.7088 - val_loss: 0.6361 - val_acc: 0.9346 - val_mDice: 0.5419

Epoch 00144: val_mDice did not improve from 0.55226
Epoch 145/300
 - 9s - loss: 0.3234 - acc: 0.9386 - mDice: 0.7093 - val_loss: 0.6594 - val_acc: 0.9428 - val_mDice: 0.5261

Epoch 00145: val_mDice did not improve from 0.55226
Epoch 146/300
 - 9s - loss: 0.3236 - acc: 0.9387 - mDice: 0.7092 - val_loss: 0.6262 - val_acc: 0.9431 - val_mDice: 0.5438

Epoch 00146: val_mDice did not improve from 0.55226
Epoch 147/300
 - 9s - loss: 0.3224 - acc: 0.9388 - mDice: 0.7099 - val_loss: 0.6386 - val_acc: 0.9430 - val_mDice: 0.5402

Epoch 00147: val_mDice did not improve from 0.55226
Epoch 148/300
 - 9s - loss: 0.3222 - acc: 0.9389 - mDice: 0.7101 - val_loss: 0.7065 - val_acc: 0.9411 - val_mDice: 0.5408

Epoch 00148: val_mDice did not improve from 0.55226
Epoch 149/300
 - 9s - loss: 0.3222 - acc: 0.9389 - mDice: 0.7101 - val_loss: 0.5695 - val_acc: 0.9426 - val_mDice: 0.5400

Epoch 00149: val_mDice did not improve from 0.55226
Epoch 150/300
 - 10s - loss: 0.3230 - acc: 0.9387 - mDice: 0.7095 - val_loss: 0.6507 - val_acc: 0.9384 - val_mDice: 0.5365

Epoch 00150: val_mDice did not improve from 0.55226
Epoch 151/300
 - 9s - loss: 0.3234 - acc: 0.9386 - mDice: 0.7093 - val_loss: 0.6447 - val_acc: 0.9351 - val_mDice: 0.5353

Epoch 00151: val_mDice did not improve from 0.55226
Epoch 152/300
 - 9s - loss: 0.3218 - acc: 0.9389 - mDice: 0.7105 - val_loss: 0.6509 - val_acc: 0.9390 - val_mDice: 0.5340

Epoch 00152: val_mDice did not improve from 0.55226
Epoch 153/300
 - 9s - loss: 0.3218 - acc: 0.9390 - mDice: 0.7105 - val_loss: 0.7507 - val_acc: 0.9257 - val_mDice: 0.5126

Epoch 00153: val_mDice did not improve from 0.55226
Epoch 154/300
 - 9s - loss: 0.3201 - acc: 0.9391 - mDice: 0.7116 - val_loss: 0.6340 - val_acc: 0.9414 - val_mDice: 0.5431

Epoch 00154: val_mDice did not improve from 0.55226
Epoch 155/300
 - 9s - loss: 0.3206 - acc: 0.9390 - mDice: 0.7113 - val_loss: 0.7034 - val_acc: 0.9375 - val_mDice: 0.5391

Epoch 00155: val_mDice did not improve from 0.55226
Epoch 156/300
 - 9s - loss: 0.3213 - acc: 0.9389 - mDice: 0.7108 - val_loss: 0.7271 - val_acc: 0.9318 - val_mDice: 0.5047

Epoch 00156: val_mDice did not improve from 0.55226
Epoch 157/300
 - 9s - loss: 0.3210 - acc: 0.9389 - mDice: 0.7110 - val_loss: 0.6480 - val_acc: 0.9347 - val_mDice: 0.5280

Epoch 00157: val_mDice did not improve from 0.55226
Restoring model weights from the end of the best epoch
Epoch 00157: early stopping
{'val_loss': [3.136152539934431, 2.179772694905599, 1.729077974955241, 1.4166192327226912, 1.330415135338193, 1.2567077931903659, 1.2290145442599343, 1.1342182954152424, 1.1611466521308536, 1.136526834397089, 1.1334707055773054, 1.0793309325263614, 1.0855406579517184, 1.0636353265671503, 1.076437132699149, 1.0510759807768322, 0.9976240566798619, 1.0228875705174036, 0.9546494483947754, 1.1605702014196486, 0.997922590800694, 0.9454758848462786, 0.9453148160661969, 0.906530811673119, 0.9055385930197579, 0.9586923008873349, 0.9112472420647031, 0.9145817643120175, 0.862624792825608, 0.8852641128358387, 0.8499307745978946, 0.8812699544997442, 0.8599092733292353, 0.8490459010714576, 0.946731238138108, 0.8275518190293085, 0.8245226542154948, 0.8018558138892764, 0.8494157677605039, 0.8238384269532704, 0.7909323715028309, 0.8760473614647275, 0.8715081896100726, 0.7881705874488467, 0.8167701448713031, 0.7928851899646577, 0.7651702222369966, 0.7743510291689918, 0.7802258219037738, 0.8419075239272344, 0.7619332926613944, 0.780400934673491, 0.8373199644542876, 0.8072420983087449, 0.7483783222380138, 0.7562294687543597, 0.7357036840348017, 0.726429507845924, 0.7254557609558105, 0.7158458346412295, 0.7317721730186826, 0.7162919839223226, 0.7601821309044248, 0.7268438452766055, 0.764857428414481, 0.7709832532065255, 0.6454390571230934, 0.6618749981834775, 0.7046149458203997, 0.6954824810936338, 0.6409578209831601, 0.6598639034089588, 0.7196628933861142, 0.6744395778292701, 0.6796751930600121, 0.639916011265346, 0.7027463231767926, 0.7173065798623222, 0.6765284878867013, 0.7048915794917515, 0.6494452272142682, 0.6823055062975202, 0.675227823711577, 0.7003360362279982, 0.6643194698152088, 0.6578078837621779, 0.6377606505439395, 0.7180098124912807, 0.6567825646627516, 0.6990807169959659, 0.7343245687938872, 0.678327412832351, 0.6639526458013625, 0.648101840700422, 0.6777536074320475, 0.6299876599084764, 0.7146687280564081, 0.6899827661968413, 0.7151007198152088, 0.6080660082045055, 0.6436779044923329, 0.6791350955054873, 0.7274146307082403, 0.7417208921341669, 0.6893378325871059, 0.6941006524222237, 0.7200783774966285, 0.6983804248628163, 0.6988177072434199, 0.7415861288706461, 0.6617099103473482, 0.7095200220743815, 0.7291739668164935, 0.6860963844117665, 0.6557261035555885, 0.6502814406440371, 0.6808664685203916, 0.6761543069566999, 0.6572704088120234, 0.6165443658828735, 0.6801334335690453, 0.6917928286961147, 0.6501175449008033, 0.6242418743315197, 0.6674409480321974, 0.6771600927625384, 0.6166841416131883, 0.6941441808428083, 0.7398059368133545, 0.6439308211916969, 0.7054317338126046, 0.627092304683867, 0.6999829610188802, 0.6574999945504325, 0.6904269286564418, 0.7309231985182989, 0.6800311633518764, 0.6186406101499285, 0.7206619012923468, 0.6145990576062884, 0.6581305662790934, 0.6611164410909017, 0.7124972002846854, 0.6361415953863234, 0.6594361918313163, 0.6262495177132743, 0.6385895638238817, 0.70647170430138, 0.5694803737458729, 0.6506741046905518, 0.6446719396682012, 0.6508951981862386, 0.7507310821896508, 0.6339969067346483, 0.7033531325204032, 0.7270865099770683, 0.6479919524419875], 'val_acc': [0.12844094101871764, 0.8966597857929411, 0.9076373690650577, 0.9111881937299456, 0.9180860576175508, 0.9211835804439726, 0.9220512537729173, 0.9254486929802668, 0.9235622826076689, 0.926664392153422, 0.9306776665505909, 0.9308493705022902, 0.9315911134084066, 0.9314217113313221, 0.9307028339022682, 0.9198030999728611, 0.9328823231515431, 0.9324587980906168, 0.932016963050479, 0.9132120070003328, 0.9305631972494579, 0.9311744230134147, 0.9290979674884251, 0.9284546488807315, 0.9339583090373448, 0.9217742823419117, 0.9277701491401309, 0.936817779427483, 0.9331158314432416, 0.9330677475248065, 0.9298397671608698, 0.9301625405039106, 0.9352770078749884, 0.9368726923352196, 0.9372481646991911, 0.9313621549379258, 0.9385531090554737, 0.9364194273948669, 0.9361813011623564, 0.937243572303227, 0.941394221215021, 0.9269505767595201, 0.9388965169588724, 0.9361561281340463, 0.9309020184335255, 0.9292513784908113, 0.932909817922683, 0.9385485450426737, 0.9409569870857966, 0.9246222348440261, 0.9367673907961164, 0.9371726030395144, 0.9390270142328172, 0.9369368297713143, 0.9298237221581596, 0.9345146616299947, 0.934894689491817, 0.9358402235167367, 0.9391735621861049, 0.9334134714944022, 0.9359088994207836, 0.9387522765568325, 0.9408081656410581, 0.9362660532905942, 0.9339789123762221, 0.9334454933802286, 0.9376213295119149, 0.9385599777812049, 0.9331936722710019, 0.9361263598714556, 0.9400160142353603, 0.9415384502637953, 0.9362843632698059, 0.9372595974377224, 0.9410622943015325, 0.9395650398163569, 0.9395673133078075, 0.9388026680265155, 0.9402403973397755, 0.9334363454864139, 0.9396405447097051, 0.9385279161589486, 0.9411423773992629, 0.932413018885113, 0.9307898538453239, 0.9424221373739696, 0.9346314328057426, 0.9405265393711272, 0.9327014713060289, 0.9405151094709124, 0.9300206161680675, 0.9418383638064066, 0.9377083352633885, 0.9353571477390471, 0.9406867907160804, 0.9372779130935669, 0.9394208136058989, 0.9385119307608831, 0.9321176750319344, 0.9365682147798085, 0.9412568694069272, 0.9427953135399592, 0.9323374714170184, 0.9269872080712092, 0.940366288026174, 0.9378159613836379, 0.9395512626284644, 0.9349931052752903, 0.9381456148056757, 0.9372756396021161, 0.9390109919366383, 0.9370535612106323, 0.9362637570926121, 0.94104855685007, 0.9367353518803915, 0.9364857787177676, 0.9397230063165937, 0.9341987059229896, 0.9354899213427589, 0.9406661930538359, 0.9337087869644165, 0.938896499928974, 0.9425732862381708, 0.9444070401645842, 0.9342353514262608, 0.9409501098451161, 0.942184050877889, 0.9362408632323855, 0.9354372648965745, 0.9450641104153225, 0.9358562372979664, 0.9426419337590536, 0.940659347034636, 0.9412477073215303, 0.942637338524773, 0.9411675873256865, 0.9413781989188421, 0.9402953244390941, 0.9344894602185204, 0.9406890925906953, 0.9344139099121094, 0.9384523772058033, 0.939967964376722, 0.9346062257176354, 0.9428456993330092, 0.9431318839391073, 0.9429807776496524, 0.9410828493890309, 0.9425892886661348, 0.9384271701176962, 0.9350893071719578, 0.9389537260645912, 0.9257096960431054, 0.941362182299296, 0.9374794051760719, 0.9318291942278544, 0.9346657537278675], 'val_mDice': [0.0972501086736364, 0.20379253521206833, 0.29244277963326093, 0.387734150602704, 0.4076170940839109, 0.43935663288547877, 0.45996428422984625, 0.48571087632860455, 0.48014636444193975, 0.4890505128673145, 0.47914352267980576, 0.499096178937526, 0.49157225766352247, 0.5072501284025964, 0.46823069808028994, 0.5019666103734857, 0.5158176830127126, 0.522976142132566, 0.5308785883798486, 0.4908325342195375, 0.5192170870446023, 0.5223706822310176, 0.524325950159913, 0.5261764276240554, 0.5273968902017389, 0.5122461232046286, 0.5134417315324148, 0.5319906590240342, 0.5397159301099324, 0.5304675449927648, 0.5267988471757798, 0.5309705127562795, 0.5270684168097519, 0.5283533476647877, 0.5180225526647908, 0.5380085470775763, 0.5357887892141229, 0.5197750207568917, 0.5334429675269694, 0.5327292595590863, 0.5371618309900874, 0.5287025854701087, 0.5046973872397628, 0.5352512321301869, 0.5227315017864818, 0.5321499336333502, 0.5310607172903561, 0.5371561963998136, 0.5307335177702563, 0.5086810324518454, 0.5359144164692788, 0.5369334103805679, 0.5423069752397991, 0.5289369495142073, 0.5278391595042887, 0.5354646682029679, 0.5371630493374098, 0.5438950698645342, 0.54259746397535, 0.5394333828063238, 0.5388963880638281, 0.5490138307213783, 0.5298275404742786, 0.5465474068408921, 0.5316105406908762, 0.5127678533040342, 0.5489062899280162, 0.5424354443592685, 0.5268344769165629, 0.5457389111674967, 0.5486336213847002, 0.5235055372828529, 0.5330530978029683, 0.5393089552720388, 0.5430677320275988, 0.5459036596474194, 0.5425362741308553, 0.5349458860499519, 0.5467953921428749, 0.5394523369059676, 0.5488149953030405, 0.5403778340135302, 0.5424142322015195, 0.5292797235860711, 0.5289157774476778, 0.5374941717655886, 0.5369733932117621, 0.5373224286096436, 0.5135724115229788, 0.5492757824914796, 0.5255623479329404, 0.551859660340207, 0.5429609446298509, 0.5368960632809571, 0.5393930650537923, 0.5451668662329515, 0.5384991798727286, 0.5402374159367311, 0.5384614950134641, 0.5395011082291603, 0.5380777095754942, 0.5495876889853251, 0.525953233951614, 0.5144480890816167, 0.5448502635671979, 0.5347635479910033, 0.530525401057232, 0.5109315337169738, 0.5484351714452108, 0.5250984165994894, 0.5459064752573058, 0.5362928431658518, 0.5303354465535709, 0.5478746420925572, 0.5318834921788602, 0.5418125382136731, 0.5522605421997252, 0.5315894842857406, 0.528784172520751, 0.5321249387093953, 0.5173627074275698, 0.541994380809012, 0.5447807494728338, 0.5440453205789838, 0.5255995100097997, 0.550077016154925, 0.5445718037940207, 0.5426010296103501, 0.5202278061991646, 0.5354408983673368, 0.5373354202934674, 0.5478210811104093, 0.5362276397645473, 0.5336642009871346, 0.5370061752342042, 0.5254504189250016, 0.5219427808409646, 0.5362315679944697, 0.5002051070332527, 0.5486385488793963, 0.5356377673645815, 0.5434347252760615, 0.5353505574166775, 0.5419149051109949, 0.5261474329800833, 0.5437514632940292, 0.5401980138960338, 0.5407681323233104, 0.5399942225998356, 0.5364510798383326, 0.5353448665922597, 0.5339720206601279, 0.512558696170648, 0.5430807824290934, 0.539114682979527, 0.5046561065883863, 0.5279801793041683], 'loss': [3.49784174957371, 1.8168095245236304, 1.2314314444400176, 1.0266386746601812, 0.894952119040264, 0.7974670554761002, 0.7278152953482143, 0.6811484336416364, 0.6436681973237809, 0.6180623257484238, 0.5933009437887752, 0.5727092950174476, 0.5574662085440845, 0.5405716788614787, 0.531268653254622, 0.5197526928154471, 0.5099706882016609, 0.4996916499927551, 0.4935621892771602, 0.4833922915567156, 0.47682882152197564, 0.4705661693726152, 0.46439687812031866, 0.4573865853363502, 0.45585647344888003, 0.4508542082708236, 0.44534154972038176, 0.44096625900944236, 0.43915348403343973, 0.43423205504349394, 0.43118441222673304, 0.4317967243189524, 0.4234358168921536, 0.42294858261894025, 0.41911295956100875, 0.4147740859378159, 0.4129277865896341, 0.4108522403428659, 0.4086343065631029, 0.4059004229756479, 0.403290366900089, 0.40170968515992006, 0.4000605649862626, 0.39944481657193487, 0.39871291426971556, 0.39495612942623176, 0.39223491371034175, 0.39047893609457307, 0.3890401179652143, 0.387957876424282, 0.38540432775827277, 0.3856243529668175, 0.3841848722399603, 0.38174182708630655, 0.3819608401190414, 0.3780733965048561, 0.3773854944559796, 0.37722515630680675, 0.3775873816217879, 0.37670062679143135, 0.37287482846235986, 0.37270658237869303, 0.371138577260607, 0.37329632245508354, 0.37127105378337005, 0.3678842964706932, 0.36708225778400816, 0.3649581713163487, 0.36688939756756, 0.36324406005707877, 0.36555200172270425, 0.36179814341901606, 0.3630148564227082, 0.36059232182830936, 0.35883604956771775, 0.36212807431808436, 0.3597555187526686, 0.3559359038280618, 0.35649854350416377, 0.3548389075692734, 0.35505129627025905, 0.3547939167779743, 0.3525840447993322, 0.3531464814783545, 0.35248973156092644, 0.35067759185069924, 0.34986627539711374, 0.3503958240441557, 0.3480856325358859, 0.34925562629976414, 0.3463415501835674, 0.34668879379581713, 0.3478204321891144, 0.3451594845600985, 0.3449079376759041, 0.3455814977751225, 0.3457141229015613, 0.3445152490555447, 0.34312286360520766, 0.34345333916225806, 0.3429864862417012, 0.340153867215441, 0.3387965585986888, 0.3427190619878326, 0.3412340751486246, 0.34016161242362414, 0.33944715075417475, 0.3400021196330975, 0.3393497673020051, 0.3391754732084614, 0.3381195851884091, 0.3368030112557773, 0.3357850463605925, 0.33482579297129533, 0.336813180690697, 0.3357875944275559, 0.3334464957908511, 0.3345562827731916, 0.3339923410108146, 0.33192846220951217, 0.33294322096775186, 0.3331601784905878, 0.33172364883140626, 0.3315897566380013, 0.3314011606127627, 0.3327584429951975, 0.3306083764980725, 0.33029427424616176, 0.32935634740910735, 0.328270076998677, 0.3291814400725956, 0.3272182425541158, 0.3294685578642724, 0.32800380259620127, 0.32738521808324944, 0.32693318915500424, 0.3273673395740979, 0.3263586537730425, 0.3262078975043086, 0.32505056058048215, 0.32488627965932454, 0.32408745324586385, 0.3237013006017276, 0.3240111611276457, 0.3233814258979469, 0.32358948108155716, 0.3224394206357687, 0.3222323437060652, 0.3221885043117199, 0.323025635293345, 0.323403779754111, 0.3218074125811064, 0.3217642568245728, 0.3201304735109161, 0.3206244630633877, 0.3213230625946949, 0.32102533315380394], 'acc': [0.11581948162897694, 0.7277989466916119, 0.871298506468138, 0.8752128821543607, 0.8790332436768425, 0.8830622714885471, 0.8864289063673753, 0.8905196622867264, 0.8945627748472097, 0.8980367178859016, 0.9010675491132051, 0.9038952546173009, 0.9065735021123819, 0.90894497942782, 0.911046570416519, 0.9131040229304622, 0.9145570104927002, 0.9158148702362587, 0.9169525123180303, 0.9179906327530946, 0.9185685449789226, 0.9194214951332442, 0.9201881833933258, 0.9207807549603854, 0.9213381092603987, 0.9217074439202473, 0.9225759500480006, 0.9232264274872404, 0.9234823865975078, 0.9240383000784764, 0.9244903118389293, 0.924696797508253, 0.9255596937897901, 0.9259389911011416, 0.9263929530033055, 0.9267489415431313, 0.927125946069375, 0.9274778365744133, 0.927899815637711, 0.9281977603080209, 0.9284554775542139, 0.9287676946584121, 0.9290411458990812, 0.9293240503766574, 0.9294197744019624, 0.929685597891336, 0.9301510760153054, 0.9305577872919627, 0.9306686400608771, 0.9308257227185743, 0.9311252189252518, 0.9309963855597241, 0.9314354898406978, 0.9317087112466839, 0.931582258883896, 0.9319467533179416, 0.93223102555377, 0.9321005448615687, 0.9322042632751067, 0.9324250658031418, 0.9326918204441589, 0.9326499974265686, 0.9328853079802456, 0.932874345919611, 0.9330269539082742, 0.9333271910879041, 0.9335259136515637, 0.9337377267603656, 0.933714858100252, 0.9338929780145038, 0.9338519642733185, 0.9339816331840421, 0.9340850525286608, 0.9342704023932454, 0.9344226161891701, 0.9342650244271385, 0.9345301294202678, 0.9348468734897675, 0.9347908623259444, 0.9349372396699859, 0.9349592297964756, 0.9350815061569582, 0.9354295952255288, 0.9351812412864283, 0.935378780364071, 0.9354334413855895, 0.9356976472184634, 0.9354134937782428, 0.935640578546206, 0.9358423572986692, 0.936116874286934, 0.9361319122503827, 0.9358577866395222, 0.9362441840970679, 0.9362822510337977, 0.9362819482991983, 0.9362205453568946, 0.936231571273903, 0.9363416856209024, 0.9364182234086212, 0.9364486216510539, 0.9368959332169745, 0.936840620324955, 0.936536700033328, 0.9367791457237801, 0.9367903861347733, 0.9368890731555776, 0.9365908279569709, 0.9367379462509825, 0.9369103454063457, 0.9371032520643153, 0.9373107072772469, 0.9372395706792684, 0.9374042293780429, 0.9372599180755483, 0.9373681502280632, 0.9376155370941552, 0.9374127326063139, 0.9376000323942776, 0.9376026976193585, 0.9376869276007959, 0.9377620945276496, 0.93778709929091, 0.9378351812213745, 0.9377443483392007, 0.937562031209963, 0.9379147282220367, 0.9380068135371851, 0.9380206008028245, 0.93813949778564, 0.9381237196651111, 0.9383350899850608, 0.938029983633397, 0.9383176857045742, 0.9383593043174178, 0.9382426817108722, 0.9382441650931721, 0.9384553047051107, 0.9385411348879763, 0.9385740834209118, 0.9385883808710545, 0.9385240562209877, 0.938653056828852, 0.9386599826656464, 0.9386242279111018, 0.9387382577558187, 0.9388221127922097, 0.938926710762085, 0.9389464104246813, 0.938733093088616, 0.9386067773097508, 0.9389230516781024, 0.9389972485787197, 0.9390619881745591, 0.9390448876743673, 0.9388782147821582, 0.9389274563315012], 'mDice': [0.04145562995088015, 0.17784731351779975, 0.28632435010696206, 0.34614674391626093, 0.39408248978955496, 0.43502870363515306, 0.4671043380391099, 0.489841864222572, 0.5087426867309461, 0.5226084360479734, 0.5360155192808722, 0.5475268230655186, 0.5560757715117847, 0.5658438444850025, 0.571301101443164, 0.5781703198693817, 0.5839533356427916, 0.5903112783192072, 0.5940012986751473, 0.6003864585652341, 0.6043885216814994, 0.608450462426527, 0.6122692758025337, 0.6168236144365362, 0.6177245373782887, 0.6210188796944487, 0.6244899958504264, 0.6273861225799993, 0.628651635769086, 0.6320068771402018, 0.6340018091161334, 0.6336827025101873, 0.6390734467865852, 0.6394257398843995, 0.6419299810935197, 0.6449007477308942, 0.64613033506207, 0.6474725434332885, 0.6490903059158891, 0.6508465259663971, 0.6526277840470726, 0.6536409479587644, 0.6548388915322111, 0.6552783906494282, 0.6559180647554208, 0.6583252206275245, 0.6601413613871524, 0.661397434174957, 0.6623730089063702, 0.6631996162897915, 0.6648988395797188, 0.66475833643602, 0.6658156435453343, 0.6675453376328759, 0.6673440012440921, 0.6699380418319842, 0.6705847399437476, 0.6706069439666819, 0.6702652641842998, 0.6710086245056014, 0.6735513719125177, 0.673784310104807, 0.6748466913424775, 0.6734962810182102, 0.6748523732842291, 0.6771006035004964, 0.6777818539203742, 0.6792341602407073, 0.677933275308916, 0.6803778469941739, 0.6788277277051081, 0.6814111666410949, 0.6806081151810597, 0.6822925784557063, 0.6836110292566703, 0.68127729897557, 0.6830469593965918, 0.6856256460945845, 0.685229593316599, 0.6864351222389623, 0.6862512544696676, 0.6864825880594145, 0.6880787172849775, 0.6876290513872986, 0.6880734187917303, 0.6893565454118993, 0.6900444177159092, 0.6896398428756423, 0.691249615026389, 0.690488769205085, 0.6925293721053236, 0.6922963777787198, 0.6915484664755932, 0.6933932925594412, 0.6934946650642408, 0.6930828583201439, 0.692914283698479, 0.6938822593145663, 0.6948013864594065, 0.6945447149202271, 0.6948959403054572, 0.6969935637644681, 0.698060618709548, 0.6951226209753024, 0.6961761442870792, 0.696974112391357, 0.6975738306782805, 0.6971577292971467, 0.6976345195139629, 0.6977171461913589, 0.6984641893258875, 0.6994560075353192, 0.7001944307833249, 0.7007620136862388, 0.6995053996763088, 0.700102785384239, 0.7018526210958659, 0.7010337001261097, 0.7014867848620976, 0.7030117400399931, 0.7022722250513886, 0.7020703397184203, 0.7030911599254479, 0.7032810160712468, 0.7034151885972355, 0.7024466327925006, 0.7040303075200954, 0.7042566508439687, 0.7048360888774579, 0.7056943309061188, 0.7049827451234335, 0.7063805926436746, 0.7047158976798116, 0.705843497671694, 0.7062795861208165, 0.7066580040367072, 0.7063293401414038, 0.7070142022672131, 0.7072094197169374, 0.7080691954936507, 0.7080881234329515, 0.7086132801358171, 0.7090076385882863, 0.7088389344497616, 0.7092523759262213, 0.7091581469007786, 0.7099497080630642, 0.7101425783859873, 0.7101002195126431, 0.7094971315465912, 0.7093097203748177, 0.7104500140416639, 0.7104758319883234, 0.7116439734117498, 0.7113233993962157, 0.7107932446709436, 0.7109846009761354]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.19s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.98s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.78s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:36,  1.82s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:54,  1.68s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:47,  1.66s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:16,  1.55s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:26,  1.60s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:46,  1.68s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:33,  1.64s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:51,  1.71s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<08:10,  1.79s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<07:42,  1.69s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<07:59,  1.76s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:50,  1.73s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:53,  1.75s/it]predicting train subjects:   5%|▌         | 15/285 [00:25<07:56,  1.76s/it]predicting train subjects:   6%|▌         | 16/285 [00:27<08:02,  1.79s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:39,  1.71s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:42,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:32<07:31,  1.70s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:33,  1.71s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:50,  1.78s/it]predicting train subjects:   8%|▊         | 22/285 [00:37<07:30,  1.71s/it]predicting train subjects:   8%|▊         | 23/285 [00:39<07:40,  1.76s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:15,  1.67s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:30,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:44,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:46<07:23,  1.72s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:35,  1.77s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:37,  1.79s/it]predicting train subjects:  11%|█         | 30/285 [00:51<07:47,  1.83s/it]predicting train subjects:  11%|█         | 31/285 [00:53<07:55,  1.87s/it]predicting train subjects:  11%|█         | 32/285 [00:55<07:25,  1.76s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:58<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [01:00<07:27,  1.79s/it]predicting train subjects:  13%|█▎        | 36/285 [01:02<07:06,  1.71s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:11,  1.74s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:17,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:07<06:57,  1.70s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<06:56,  1.70s/it]predicting train subjects:  14%|█▍        | 41/285 [01:10<06:42,  1.65s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:29,  1.60s/it]predicting train subjects:  15%|█▌        | 43/285 [01:13<06:40,  1.66s/it]predicting train subjects:  15%|█▌        | 44/285 [01:15<06:53,  1.72s/it]predicting train subjects:  16%|█▌        | 45/285 [01:17<06:37,  1.66s/it]predicting train subjects:  16%|█▌        | 46/285 [01:18<06:51,  1.72s/it]predicting train subjects:  16%|█▋        | 47/285 [01:20<06:37,  1.67s/it]predicting train subjects:  17%|█▋        | 48/285 [01:22<06:43,  1.70s/it]predicting train subjects:  17%|█▋        | 49/285 [01:24<06:58,  1.77s/it]predicting train subjects:  18%|█▊        | 50/285 [01:25<06:53,  1.76s/it]predicting train subjects:  18%|█▊        | 51/285 [01:27<07:01,  1.80s/it]predicting train subjects:  18%|█▊        | 52/285 [01:29<06:37,  1.71s/it]predicting train subjects:  19%|█▊        | 53/285 [01:31<06:43,  1.74s/it]predicting train subjects:  19%|█▉        | 54/285 [01:33<06:53,  1.79s/it]predicting train subjects:  19%|█▉        | 55/285 [01:34<06:34,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:36<06:38,  1.74s/it]predicting train subjects:  20%|██        | 57/285 [01:37<06:21,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:39<06:28,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:41<06:38,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:43<06:48,  1.82s/it]predicting train subjects:  21%|██▏       | 61/285 [01:45<06:30,  1.74s/it]predicting train subjects:  22%|██▏       | 62/285 [01:46<06:34,  1.77s/it]predicting train subjects:  22%|██▏       | 63/285 [01:48<06:39,  1.80s/it]predicting train subjects:  22%|██▏       | 64/285 [01:50<06:25,  1.74s/it]predicting train subjects:  23%|██▎       | 65/285 [01:52<06:21,  1.73s/it]predicting train subjects:  23%|██▎       | 66/285 [01:53<06:16,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:55<06:20,  1.74s/it]predicting train subjects:  24%|██▍       | 68/285 [01:57<06:06,  1.69s/it]predicting train subjects:  24%|██▍       | 69/285 [01:58<06:09,  1.71s/it]predicting train subjects:  25%|██▍       | 70/285 [02:00<06:15,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:02<06:18,  1.77s/it]predicting train subjects:  25%|██▌       | 72/285 [02:04<06:05,  1.71s/it]predicting train subjects:  26%|██▌       | 73/285 [02:05<06:08,  1.74s/it]predicting train subjects:  26%|██▌       | 74/285 [02:07<06:05,  1.73s/it]predicting train subjects:  26%|██▋       | 75/285 [02:09<06:13,  1.78s/it]predicting train subjects:  27%|██▋       | 76/285 [02:11<06:14,  1.79s/it]predicting train subjects:  27%|██▋       | 77/285 [02:13<06:01,  1.74s/it]predicting train subjects:  27%|██▋       | 78/285 [02:14<05:50,  1.70s/it]predicting train subjects:  28%|██▊       | 79/285 [02:16<05:45,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:18<05:48,  1.70s/it]predicting train subjects:  28%|██▊       | 81/285 [02:19<05:40,  1.67s/it]predicting train subjects:  29%|██▉       | 82/285 [02:21<05:40,  1.68s/it]predicting train subjects:  29%|██▉       | 83/285 [02:22<05:32,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:24<05:28,  1.64s/it]predicting train subjects:  30%|██▉       | 85/285 [02:26<05:36,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:28<05:41,  1.72s/it]predicting train subjects:  31%|███       | 87/285 [02:29<05:47,  1.75s/it]predicting train subjects:  31%|███       | 88/285 [02:31<05:37,  1.71s/it]predicting train subjects:  31%|███       | 89/285 [02:33<05:35,  1.71s/it]predicting train subjects:  32%|███▏      | 90/285 [02:35<05:39,  1.74s/it]predicting train subjects:  32%|███▏      | 91/285 [02:36<05:29,  1.70s/it]predicting train subjects:  32%|███▏      | 92/285 [02:38<05:27,  1.70s/it]predicting train subjects:  33%|███▎      | 93/285 [02:40<05:24,  1.69s/it]predicting train subjects:  33%|███▎      | 94/285 [02:41<05:26,  1.71s/it]predicting train subjects:  33%|███▎      | 95/285 [02:43<05:29,  1.73s/it]predicting train subjects:  34%|███▎      | 96/285 [02:45<05:24,  1.72s/it]predicting train subjects:  34%|███▍      | 97/285 [02:47<05:26,  1.74s/it]predicting train subjects:  34%|███▍      | 98/285 [02:48<05:23,  1.73s/it]predicting train subjects:  35%|███▍      | 99/285 [02:50<05:16,  1.70s/it]predicting train subjects:  35%|███▌      | 100/285 [02:52<05:22,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:53<05:11,  1.70s/it]predicting train subjects:  36%|███▌      | 102/285 [02:55<05:18,  1.74s/it]predicting train subjects:  36%|███▌      | 103/285 [02:57<05:07,  1.69s/it]predicting train subjects:  36%|███▋      | 104/285 [02:58<05:08,  1.70s/it]predicting train subjects:  37%|███▋      | 105/285 [03:00<05:11,  1.73s/it]predicting train subjects:  37%|███▋      | 106/285 [03:02<05:01,  1.68s/it]predicting train subjects:  38%|███▊      | 107/285 [03:04<05:05,  1.71s/it]predicting train subjects:  38%|███▊      | 108/285 [03:05<04:59,  1.69s/it]predicting train subjects:  38%|███▊      | 109/285 [03:07<05:01,  1.71s/it]predicting train subjects:  39%|███▊      | 110/285 [03:09<05:02,  1.73s/it]predicting train subjects:  39%|███▉      | 111/285 [03:10<04:54,  1.69s/it]predicting train subjects:  39%|███▉      | 112/285 [03:12<04:53,  1.70s/it]predicting train subjects:  40%|███▉      | 113/285 [03:14<05:02,  1.76s/it]predicting train subjects:  40%|████      | 114/285 [03:16<04:57,  1.74s/it]predicting train subjects:  40%|████      | 115/285 [03:17<04:54,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:19<04:54,  1.74s/it]predicting train subjects:  41%|████      | 117/285 [03:21<04:47,  1.71s/it]predicting train subjects:  41%|████▏     | 118/285 [03:22<04:41,  1.69s/it]predicting train subjects:  42%|████▏     | 119/285 [03:24<04:43,  1.71s/it]predicting train subjects:  42%|████▏     | 120/285 [03:26<04:36,  1.67s/it]predicting train subjects:  42%|████▏     | 121/285 [03:27<04:33,  1.67s/it]predicting train subjects:  43%|████▎     | 122/285 [03:29<04:25,  1.63s/it]predicting train subjects:  43%|████▎     | 123/285 [03:30<04:12,  1.56s/it]predicting train subjects:  44%|████▎     | 124/285 [03:32<04:10,  1.56s/it]predicting train subjects:  44%|████▍     | 125/285 [03:33<04:02,  1.52s/it]predicting train subjects:  44%|████▍     | 126/285 [03:35<03:59,  1.51s/it]predicting train subjects:  45%|████▍     | 127/285 [03:36<03:56,  1.50s/it]predicting train subjects:  45%|████▍     | 128/285 [03:38<03:57,  1.51s/it]predicting train subjects:  45%|████▌     | 129/285 [03:39<03:51,  1.48s/it]predicting train subjects:  46%|████▌     | 130/285 [03:41<03:46,  1.46s/it]predicting train subjects:  46%|████▌     | 131/285 [03:42<03:43,  1.45s/it]predicting train subjects:  46%|████▋     | 132/285 [03:44<03:49,  1.50s/it]predicting train subjects:  47%|████▋     | 133/285 [03:45<03:44,  1.48s/it]predicting train subjects:  47%|████▋     | 134/285 [03:47<03:39,  1.45s/it]predicting train subjects:  47%|████▋     | 135/285 [03:48<03:35,  1.44s/it]predicting train subjects:  48%|████▊     | 136/285 [03:49<03:31,  1.42s/it]predicting train subjects:  48%|████▊     | 137/285 [03:51<03:36,  1.46s/it]predicting train subjects:  48%|████▊     | 138/285 [03:52<03:31,  1.44s/it]predicting train subjects:  49%|████▉     | 139/285 [03:54<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:55<03:39,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:57<03:34,  1.49s/it]predicting train subjects:  50%|████▉     | 142/285 [03:58<03:32,  1.48s/it]predicting train subjects:  50%|█████     | 143/285 [04:00<03:27,  1.46s/it]predicting train subjects:  51%|█████     | 144/285 [04:01<03:30,  1.49s/it]predicting train subjects:  51%|█████     | 145/285 [04:03<03:26,  1.48s/it]predicting train subjects:  51%|█████     | 146/285 [04:04<03:27,  1.49s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:06<03:21,  1.46s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:07<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:09<03:18,  1.46s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:10<03:13,  1.44s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:12<03:17,  1.47s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:13<03:12,  1.45s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:14<03:07,  1.42s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:16<03:13,  1.47s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:17<03:10,  1.46s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:19<03:10,  1.48s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:20<03:04,  1.44s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:22<03:01,  1.43s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:23<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:24<02:57,  1.42s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:26<03:00,  1.46s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:27<02:58,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:29<03:02,  1.49s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:30<02:56,  1.46s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:32<02:55,  1.46s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:33<02:58,  1.50s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:35<03:01,  1.54s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:36<02:54,  1.49s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:38<02:50,  1.47s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:39<02:47,  1.45s/it]predicting train subjects:  60%|██████    | 171/285 [04:41<02:45,  1.45s/it]predicting train subjects:  60%|██████    | 172/285 [04:42<02:41,  1.43s/it]predicting train subjects:  61%|██████    | 173/285 [04:44<02:41,  1.45s/it]predicting train subjects:  61%|██████    | 174/285 [04:45<02:41,  1.45s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:47<02:46,  1.52s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:48<02:46,  1.53s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:50<02:41,  1.49s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:51<02:34,  1.44s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:52<02:32,  1.44s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:54<02:44,  1.56s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:56<02:42,  1.57s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:58<02:43,  1.59s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:59<02:33,  1.50s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:00<02:29,  1.48s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:02<02:24,  1.45s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:03<02:32,  1.54s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:05<02:38,  1.62s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:07<02:42,  1.68s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:08<02:32,  1.59s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:10<02:25,  1.53s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:11<02:26,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:13<02:25,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:14<02:19,  1.51s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:16<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:17<02:11,  1.46s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:19<02:19,  1.56s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:21<02:24,  1.64s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:23<02:25,  1.67s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:24<02:14,  1.56s/it]predicting train subjects:  70%|███████   | 200/285 [05:25<02:07,  1.51s/it]predicting train subjects:  71%|███████   | 201/285 [05:27<02:12,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:29<02:13,  1.61s/it]predicting train subjects:  71%|███████   | 203/285 [05:30<02:11,  1.60s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:32<02:02,  1.52s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:33<01:59,  1.49s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:34<01:56,  1.47s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:36<02:06,  1.62s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:38<02:10,  1.69s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:40<02:10,  1.72s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:41<02:01,  1.61s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:43<01:55,  1.56s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:44<01:54,  1.57s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:46<01:54,  1.58s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:47<01:48,  1.52s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:49<01:51,  1.60s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:50<01:43,  1.50s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:52<01:47,  1.58s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:54<01:50,  1.64s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:56<01:53,  1.72s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:57<01:44,  1.60s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:59<01:39,  1.55s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:00<01:37,  1.55s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:02<01:33,  1.51s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:03<01:29,  1.47s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:04<01:26,  1.43s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:06<01:30,  1.54s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:08<01:34,  1.63s/it]predicting train subjects:  80%|████████  | 228/285 [06:10<01:34,  1.66s/it]predicting train subjects:  80%|████████  | 229/285 [06:11<01:32,  1.66s/it]predicting train subjects:  81%|████████  | 230/285 [06:13<01:25,  1.55s/it]predicting train subjects:  81%|████████  | 231/285 [06:14<01:21,  1.52s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:16<01:22,  1.55s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:17<01:17,  1.49s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:19<01:21,  1.60s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:20<01:15,  1.52s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:22<01:19,  1.62s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:24<01:20,  1.69s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:26<01:20,  1.72s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:27<01:18,  1.70s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:29<01:12,  1.60s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:30<01:08,  1.55s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:31<01:02,  1.46s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:33<01:01,  1.46s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:35<01:03,  1.54s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:36<00:58,  1.46s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:38<01:00,  1.55s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:40<01:02,  1.64s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:41<01:01,  1.65s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:43<00:56,  1.58s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:44<00:54,  1.56s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:46<00:51,  1.50s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:47<00:48,  1.46s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:49<00:49,  1.56s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:50<00:49,  1.61s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:52<00:48,  1.62s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:53<00:44,  1.55s/it]predicting train subjects:  90%|█████████ | 257/285 [06:55<00:42,  1.51s/it]predicting train subjects:  91%|█████████ | 258/285 [06:57<00:43,  1.62s/it]predicting train subjects:  91%|█████████ | 259/285 [06:58<00:42,  1.64s/it]predicting train subjects:  91%|█████████ | 260/285 [07:00<00:38,  1.54s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:01<00:35,  1.49s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:02<00:33,  1.46s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:04<00:31,  1.42s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:06<00:32,  1.56s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:07<00:32,  1.61s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:09<00:29,  1.56s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:10<00:27,  1.52s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:12<00:27,  1.62s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:14<00:26,  1.63s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:15<00:23,  1.55s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:17<00:21,  1.50s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:18<00:20,  1.55s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:20<00:17,  1.49s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:21<00:15,  1.45s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:23<00:15,  1.56s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:24<00:14,  1.62s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:26<00:12,  1.55s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:27<00:10,  1.54s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:29<00:09,  1.57s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:30<00:07,  1.51s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:32<00:05,  1.47s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:33<00:04,  1.44s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:35<00:03,  1.56s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:37<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 285/285 [07:39<00:00,  1.68s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:22,  1.77s/it]Loading train:   1%|          | 2/285 [00:03<07:59,  1.69s/it]Loading train:   1%|          | 3/285 [00:04<07:43,  1.64s/it]Loading train:   1%|▏         | 4/285 [00:06<07:20,  1.57s/it]Loading train:   2%|▏         | 5/285 [00:08<07:47,  1.67s/it]Loading train:   2%|▏         | 6/285 [00:09<07:15,  1.56s/it]Loading train:   2%|▏         | 7/285 [00:11<07:29,  1.62s/it]Loading train:   3%|▎         | 8/285 [00:12<07:14,  1.57s/it]Loading train:   3%|▎         | 9/285 [00:14<07:36,  1.65s/it]Loading train:   4%|▎         | 10/285 [00:15<07:19,  1.60s/it]Loading train:   4%|▍         | 11/285 [00:17<06:35,  1.44s/it]Loading train:   4%|▍         | 12/285 [00:18<06:23,  1.41s/it]Loading train:   5%|▍         | 13/285 [00:19<06:02,  1.33s/it]Loading train:   5%|▍         | 14/285 [00:20<06:05,  1.35s/it]Loading train:   5%|▌         | 15/285 [00:22<05:50,  1.30s/it]Loading train:   6%|▌         | 16/285 [00:23<05:40,  1.26s/it]Loading train:   6%|▌         | 17/285 [00:24<05:32,  1.24s/it]Loading train:   6%|▋         | 18/285 [00:25<05:18,  1.19s/it]Loading train:   7%|▋         | 19/285 [00:26<04:51,  1.09s/it]Loading train:   7%|▋         | 20/285 [00:27<04:54,  1.11s/it]Loading train:   7%|▋         | 21/285 [00:28<05:04,  1.15s/it]Loading train:   8%|▊         | 22/285 [00:29<04:42,  1.07s/it]Loading train:   8%|▊         | 23/285 [00:30<04:47,  1.10s/it]Loading train:   8%|▊         | 24/285 [00:31<04:39,  1.07s/it]Loading train:   9%|▉         | 25/285 [00:32<04:45,  1.10s/it]Loading train:   9%|▉         | 26/285 [00:34<04:46,  1.11s/it]Loading train:   9%|▉         | 27/285 [00:35<04:47,  1.12s/it]Loading train:  10%|▉         | 28/285 [00:36<04:41,  1.09s/it]Loading train:  10%|█         | 29/285 [00:37<04:30,  1.05s/it]Loading train:  11%|█         | 30/285 [00:38<04:42,  1.11s/it]Loading train:  11%|█         | 31/285 [00:39<04:53,  1.16s/it]Loading train:  11%|█         | 32/285 [00:40<04:35,  1.09s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:24,  1.05s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:29,  1.07s/it]Loading train:  12%|█▏        | 35/285 [00:44<04:39,  1.12s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:28,  1.08s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:36,  1.12s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:54,  1.19s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:53,  1.19s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:43,  1.16s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:17,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:15,  1.05s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:07,  1.02s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:28,  1.11s/it]Loading train:  16%|█▌        | 45/285 [00:55<04:24,  1.10s/it]Loading train:  16%|█▌        | 46/285 [00:56<04:28,  1.12s/it]Loading train:  16%|█▋        | 47/285 [00:57<04:20,  1.09s/it]Loading train:  17%|█▋        | 48/285 [00:58<04:12,  1.07s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:26,  1.13s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:16,  1.09s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:21,  1.12s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:11,  1.08s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:12,  1.09s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:17,  1.11s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:04,  1.06s/it]Loading train:  20%|█▉        | 56/285 [01:06<03:56,  1.03s/it]Loading train:  20%|██        | 57/285 [01:07<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:08<03:39,  1.04it/s]Loading train:  21%|██        | 59/285 [01:09<03:58,  1.06s/it]Loading train:  21%|██        | 60/285 [01:11<04:02,  1.08s/it]Loading train:  21%|██▏       | 61/285 [01:12<03:58,  1.06s/it]Loading train:  22%|██▏       | 62/285 [01:13<03:56,  1.06s/it]Loading train:  22%|██▏       | 63/285 [01:14<03:54,  1.05s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:19,  1.17s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:51,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:18<04:49,  1.32s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:46,  1.31s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:25,  1.22s/it]Loading train:  24%|██▍       | 69/285 [01:21<04:09,  1.15s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:06,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:03,  1.14s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:50,  1.08s/it]Loading train:  26%|██▌       | 73/285 [01:26<03:56,  1.12s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:52,  1.10s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:52,  1.11s/it]Loading train:  27%|██▋       | 76/285 [01:29<03:49,  1.10s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:52,  1.12s/it]Loading train:  27%|██▋       | 78/285 [01:31<03:45,  1.09s/it]Loading train:  28%|██▊       | 79/285 [01:32<03:44,  1.09s/it]Loading train:  28%|██▊       | 80/285 [01:33<03:41,  1.08s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:36,  1.06s/it]Loading train:  29%|██▉       | 82/285 [01:36<03:38,  1.07s/it]Loading train:  29%|██▉       | 83/285 [01:37<03:40,  1.09s/it]Loading train:  29%|██▉       | 84/285 [01:38<03:35,  1.07s/it]Loading train:  30%|██▉       | 85/285 [01:39<03:34,  1.07s/it]Loading train:  30%|███       | 86/285 [01:40<03:33,  1.07s/it]Loading train:  31%|███       | 87/285 [01:41<03:35,  1.09s/it]Loading train:  31%|███       | 88/285 [01:42<03:27,  1.05s/it]Loading train:  31%|███       | 89/285 [01:43<03:25,  1.05s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:33,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:45<03:28,  1.07s/it]Loading train:  32%|███▏      | 92/285 [01:46<03:24,  1.06s/it]Loading train:  33%|███▎      | 93/285 [01:47<03:23,  1.06s/it]Loading train:  33%|███▎      | 94/285 [01:48<03:19,  1.04s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:22,  1.07s/it]Loading train:  34%|███▎      | 96/285 [01:51<03:22,  1.07s/it]Loading train:  34%|███▍      | 97/285 [01:52<03:31,  1.12s/it]Loading train:  34%|███▍      | 98/285 [01:53<03:25,  1.10s/it]Loading train:  35%|███▍      | 99/285 [01:54<03:17,  1.06s/it]Loading train:  35%|███▌      | 100/285 [01:55<03:16,  1.06s/it]Loading train:  35%|███▌      | 101/285 [01:56<03:16,  1.07s/it]Loading train:  36%|███▌      | 102/285 [01:57<03:19,  1.09s/it]Loading train:  36%|███▌      | 103/285 [01:58<03:12,  1.06s/it]Loading train:  36%|███▋      | 104/285 [01:59<03:14,  1.08s/it]Loading train:  37%|███▋      | 105/285 [02:00<03:12,  1.07s/it]Loading train:  37%|███▋      | 106/285 [02:01<03:13,  1.08s/it]Loading train:  38%|███▊      | 107/285 [02:03<03:25,  1.15s/it]Loading train:  38%|███▊      | 108/285 [02:04<03:18,  1.12s/it]Loading train:  38%|███▊      | 109/285 [02:05<03:17,  1.12s/it]Loading train:  39%|███▊      | 110/285 [02:06<03:13,  1.11s/it]Loading train:  39%|███▉      | 111/285 [02:07<03:11,  1.10s/it]Loading train:  39%|███▉      | 112/285 [02:08<03:13,  1.12s/it]Loading train:  40%|███▉      | 113/285 [02:09<03:09,  1.10s/it]Loading train:  40%|████      | 114/285 [02:10<03:04,  1.08s/it]Loading train:  40%|████      | 115/285 [02:11<03:07,  1.10s/it]Loading train:  41%|████      | 116/285 [02:12<03:02,  1.08s/it]Loading train:  41%|████      | 117/285 [02:13<03:02,  1.08s/it]Loading train:  41%|████▏     | 118/285 [02:15<03:02,  1.09s/it]Loading train:  42%|████▏     | 119/285 [02:16<03:07,  1.13s/it]Loading train:  42%|████▏     | 120/285 [02:17<02:54,  1.06s/it]Loading train:  42%|████▏     | 121/285 [02:18<03:09,  1.15s/it]Loading train:  43%|████▎     | 122/285 [02:19<03:17,  1.21s/it]Loading train:  43%|████▎     | 123/285 [02:21<03:20,  1.24s/it]Loading train:  44%|████▎     | 124/285 [02:22<03:16,  1.22s/it]Loading train:  44%|████▍     | 125/285 [02:23<03:02,  1.14s/it]Loading train:  44%|████▍     | 126/285 [02:24<02:52,  1.08s/it]Loading train:  45%|████▍     | 127/285 [02:25<02:44,  1.04s/it]Loading train:  45%|████▍     | 128/285 [02:26<02:39,  1.02s/it]Loading train:  45%|████▌     | 129/285 [02:27<02:33,  1.02it/s]Loading train:  46%|████▌     | 130/285 [02:28<02:32,  1.02it/s]Loading train:  46%|████▌     | 131/285 [02:29<02:29,  1.03it/s]Loading train:  46%|████▋     | 132/285 [02:29<02:25,  1.05it/s]Loading train:  47%|████▋     | 133/285 [02:30<02:27,  1.03it/s]Loading train:  47%|████▋     | 134/285 [02:31<02:21,  1.07it/s]Loading train:  47%|████▋     | 135/285 [02:32<02:25,  1.03it/s]Loading train:  48%|████▊     | 136/285 [02:33<02:18,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:34<02:16,  1.08it/s]Loading train:  48%|████▊     | 138/285 [02:35<02:19,  1.05it/s]Loading train:  49%|████▉     | 139/285 [02:36<02:19,  1.05it/s]Loading train:  49%|████▉     | 140/285 [02:37<02:18,  1.05it/s]Loading train:  49%|████▉     | 141/285 [02:38<02:15,  1.06it/s]Loading train:  50%|████▉     | 142/285 [02:39<02:14,  1.06it/s]Loading train:  50%|█████     | 143/285 [02:40<02:18,  1.03it/s]Loading train:  51%|█████     | 144/285 [02:41<02:18,  1.02it/s]Loading train:  51%|█████     | 145/285 [02:42<02:14,  1.04it/s]Loading train:  51%|█████     | 146/285 [02:43<02:14,  1.04it/s]Loading train:  52%|█████▏    | 147/285 [02:44<02:12,  1.04it/s]Loading train:  52%|█████▏    | 148/285 [02:45<02:13,  1.03it/s]Loading train:  52%|█████▏    | 149/285 [02:46<02:12,  1.03it/s]Loading train:  53%|█████▎    | 150/285 [02:47<02:20,  1.04s/it]Loading train:  53%|█████▎    | 151/285 [02:48<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:49<02:16,  1.03s/it]Loading train:  54%|█████▎    | 153/285 [02:50<02:15,  1.03s/it]Loading train:  54%|█████▍    | 154/285 [02:51<02:11,  1.01s/it]Loading train:  54%|█████▍    | 155/285 [02:52<02:07,  1.02it/s]Loading train:  55%|█████▍    | 156/285 [02:53<02:05,  1.02it/s]Loading train:  55%|█████▌    | 157/285 [02:54<02:05,  1.02it/s]Loading train:  55%|█████▌    | 158/285 [02:55<02:04,  1.02it/s]Loading train:  56%|█████▌    | 159/285 [02:56<02:00,  1.04it/s]Loading train:  56%|█████▌    | 160/285 [02:57<01:58,  1.06it/s]Loading train:  56%|█████▋    | 161/285 [02:58<01:56,  1.06it/s]Loading train:  57%|█████▋    | 162/285 [02:59<01:55,  1.06it/s]Loading train:  57%|█████▋    | 163/285 [02:59<01:53,  1.08it/s]Loading train:  58%|█████▊    | 164/285 [03:00<01:50,  1.09it/s]Loading train:  58%|█████▊    | 165/285 [03:01<01:45,  1.14it/s]Loading train:  58%|█████▊    | 166/285 [03:02<01:45,  1.13it/s]Loading train:  59%|█████▊    | 167/285 [03:03<01:43,  1.14it/s]Loading train:  59%|█████▉    | 168/285 [03:04<01:44,  1.12it/s]Loading train:  59%|█████▉    | 169/285 [03:05<01:45,  1.10it/s]Loading train:  60%|█████▉    | 170/285 [03:06<01:41,  1.13it/s]Loading train:  60%|██████    | 171/285 [03:06<01:36,  1.18it/s]Loading train:  60%|██████    | 172/285 [03:07<01:35,  1.18it/s]Loading train:  61%|██████    | 173/285 [03:08<01:33,  1.19it/s]Loading train:  61%|██████    | 174/285 [03:09<01:32,  1.20it/s]Loading train:  61%|██████▏   | 175/285 [03:10<01:33,  1.18it/s]Loading train:  62%|██████▏   | 176/285 [03:11<01:37,  1.12it/s]Loading train:  62%|██████▏   | 177/285 [03:12<01:41,  1.07it/s]Loading train:  62%|██████▏   | 178/285 [03:13<01:46,  1.01it/s]Loading train:  63%|██████▎   | 179/285 [03:14<01:51,  1.06s/it]Loading train:  63%|██████▎   | 180/285 [03:15<02:03,  1.18s/it]Loading train:  64%|██████▎   | 181/285 [03:17<02:14,  1.29s/it]Loading train:  64%|██████▍   | 182/285 [03:18<02:08,  1.25s/it]Loading train:  64%|██████▍   | 183/285 [03:19<02:08,  1.26s/it]Loading train:  65%|██████▍   | 184/285 [03:21<02:04,  1.24s/it]Loading train:  65%|██████▍   | 185/285 [03:22<01:55,  1.16s/it]Loading train:  65%|██████▌   | 186/285 [03:23<02:00,  1.22s/it]Loading train:  66%|██████▌   | 187/285 [03:25<02:08,  1.31s/it]Loading train:  66%|██████▌   | 188/285 [03:26<02:17,  1.41s/it]Loading train:  66%|██████▋   | 189/285 [03:27<02:02,  1.27s/it]Loading train:  67%|██████▋   | 190/285 [03:28<01:53,  1.20s/it]Loading train:  67%|██████▋   | 191/285 [03:30<02:00,  1.28s/it]Loading train:  67%|██████▋   | 192/285 [03:31<02:05,  1.35s/it]Loading train:  68%|██████▊   | 193/285 [03:32<01:59,  1.30s/it]Loading train:  68%|██████▊   | 194/285 [03:33<01:53,  1.25s/it]Loading train:  68%|██████▊   | 195/285 [03:35<01:48,  1.21s/it]Loading train:  69%|██████▉   | 196/285 [03:36<01:56,  1.31s/it]Loading train:  69%|██████▉   | 197/285 [03:38<01:58,  1.35s/it]Loading train:  69%|██████▉   | 198/285 [03:39<01:58,  1.36s/it]Loading train:  70%|██████▉   | 199/285 [03:40<01:48,  1.26s/it]Loading train:  70%|███████   | 200/285 [03:41<01:42,  1.21s/it]Loading train:  71%|███████   | 201/285 [03:42<01:42,  1.22s/it]Loading train:  71%|███████   | 202/285 [03:44<01:42,  1.24s/it]Loading train:  71%|███████   | 203/285 [03:45<01:45,  1.28s/it]Loading train:  72%|███████▏  | 204/285 [03:46<01:40,  1.24s/it]Loading train:  72%|███████▏  | 205/285 [03:47<01:37,  1.22s/it]Loading train:  72%|███████▏  | 206/285 [03:49<01:37,  1.24s/it]Loading train:  73%|███████▎  | 207/285 [03:50<01:45,  1.35s/it]Loading train:  73%|███████▎  | 208/285 [03:52<01:44,  1.36s/it]Loading train:  73%|███████▎  | 209/285 [03:53<01:45,  1.38s/it]Loading train:  74%|███████▎  | 210/285 [03:54<01:42,  1.37s/it]Loading train:  74%|███████▍  | 211/285 [03:56<01:38,  1.33s/it]Loading train:  74%|███████▍  | 212/285 [03:57<01:37,  1.34s/it]Loading train:  75%|███████▍  | 213/285 [03:58<01:33,  1.30s/it]Loading train:  75%|███████▌  | 214/285 [03:59<01:29,  1.26s/it]Loading train:  75%|███████▌  | 215/285 [04:01<01:31,  1.30s/it]Loading train:  76%|███████▌  | 216/285 [04:02<01:29,  1.30s/it]Loading train:  76%|███████▌  | 217/285 [04:03<01:29,  1.31s/it]Loading train:  76%|███████▋  | 218/285 [04:05<01:27,  1.30s/it]Loading train:  77%|███████▋  | 219/285 [04:06<01:24,  1.27s/it]Loading train:  77%|███████▋  | 220/285 [04:07<01:23,  1.28s/it]Loading train:  78%|███████▊  | 221/285 [04:08<01:21,  1.28s/it]Loading train:  78%|███████▊  | 222/285 [04:10<01:20,  1.28s/it]Loading train:  78%|███████▊  | 223/285 [04:11<01:16,  1.23s/it]Loading train:  79%|███████▊  | 224/285 [04:12<01:14,  1.23s/it]Loading train:  79%|███████▉  | 225/285 [04:13<01:14,  1.24s/it]Loading train:  79%|███████▉  | 226/285 [04:15<01:14,  1.26s/it]Loading train:  80%|███████▉  | 227/285 [04:16<01:15,  1.30s/it]Loading train:  80%|████████  | 228/285 [04:17<01:15,  1.32s/it]Loading train:  80%|████████  | 229/285 [04:19<01:11,  1.28s/it]Loading train:  81%|████████  | 230/285 [04:20<01:09,  1.27s/it]Loading train:  81%|████████  | 231/285 [04:21<01:05,  1.22s/it]Loading train:  81%|████████▏ | 232/285 [04:22<01:03,  1.20s/it]Loading train:  82%|████████▏ | 233/285 [04:23<01:01,  1.19s/it]Loading train:  82%|████████▏ | 234/285 [04:25<01:05,  1.28s/it]Loading train:  82%|████████▏ | 235/285 [04:26<01:01,  1.22s/it]Loading train:  83%|████████▎ | 236/285 [04:27<01:06,  1.36s/it]Loading train:  83%|████████▎ | 237/285 [04:29<01:08,  1.42s/it]Loading train:  84%|████████▎ | 238/285 [04:30<01:06,  1.41s/it]Loading train:  84%|████████▍ | 239/285 [04:32<01:01,  1.33s/it]Loading train:  84%|████████▍ | 240/285 [04:33<00:59,  1.32s/it]Loading train:  85%|████████▍ | 241/285 [04:34<00:56,  1.29s/it]Loading train:  85%|████████▍ | 242/285 [04:35<00:55,  1.28s/it]Loading train:  85%|████████▌ | 243/285 [04:37<00:52,  1.25s/it]Loading train:  86%|████████▌ | 244/285 [04:38<00:52,  1.29s/it]Loading train:  86%|████████▌ | 245/285 [04:39<00:50,  1.26s/it]Loading train:  86%|████████▋ | 246/285 [04:40<00:48,  1.25s/it]Loading train:  87%|████████▋ | 247/285 [04:42<00:48,  1.27s/it]Loading train:  87%|████████▋ | 248/285 [04:43<00:46,  1.25s/it]Loading train:  87%|████████▋ | 249/285 [04:44<00:45,  1.25s/it]Loading train:  88%|████████▊ | 250/285 [04:45<00:43,  1.24s/it]Loading train:  88%|████████▊ | 251/285 [04:47<00:42,  1.24s/it]Loading train:  88%|████████▊ | 252/285 [04:48<00:42,  1.27s/it]Loading train:  89%|████████▉ | 253/285 [04:49<00:42,  1.31s/it]Loading train:  89%|████████▉ | 254/285 [04:51<00:40,  1.31s/it]Loading train:  89%|████████▉ | 255/285 [04:52<00:38,  1.29s/it]Loading train:  90%|████████▉ | 256/285 [04:53<00:36,  1.24s/it]Loading train:  90%|█████████ | 257/285 [04:54<00:33,  1.19s/it]Loading train:  91%|█████████ | 258/285 [04:56<00:34,  1.28s/it]Loading train:  91%|█████████ | 259/285 [04:57<00:33,  1.27s/it]Loading train:  91%|█████████ | 260/285 [04:58<00:31,  1.25s/it]Loading train:  92%|█████████▏| 261/285 [04:59<00:29,  1.21s/it]Loading train:  92%|█████████▏| 262/285 [05:00<00:26,  1.14s/it]Loading train:  92%|█████████▏| 263/285 [05:01<00:24,  1.11s/it]Loading train:  93%|█████████▎| 264/285 [05:03<00:25,  1.22s/it]Loading train:  93%|█████████▎| 265/285 [05:04<00:23,  1.20s/it]Loading train:  93%|█████████▎| 266/285 [05:05<00:22,  1.18s/it]Loading train:  94%|█████████▎| 267/285 [05:06<00:20,  1.11s/it]Loading train:  94%|█████████▍| 268/285 [05:07<00:20,  1.19s/it]Loading train:  94%|█████████▍| 269/285 [05:09<00:19,  1.22s/it]Loading train:  95%|█████████▍| 270/285 [05:10<00:17,  1.19s/it]Loading train:  95%|█████████▌| 271/285 [05:11<00:17,  1.21s/it]Loading train:  95%|█████████▌| 272/285 [05:12<00:16,  1.30s/it]Loading train:  96%|█████████▌| 273/285 [05:13<00:14,  1.23s/it]Loading train:  96%|█████████▌| 274/285 [05:15<00:13,  1.25s/it]Loading train:  96%|█████████▋| 275/285 [05:16<00:13,  1.31s/it]Loading train:  97%|█████████▋| 276/285 [05:18<00:11,  1.32s/it]Loading train:  97%|█████████▋| 277/285 [05:19<00:10,  1.27s/it]Loading train:  98%|█████████▊| 278/285 [05:20<00:08,  1.26s/it]Loading train:  98%|█████████▊| 279/285 [05:21<00:07,  1.26s/it]Loading train:  98%|█████████▊| 280/285 [05:22<00:06,  1.24s/it]Loading train:  99%|█████████▊| 281/285 [05:24<00:04,  1.22s/it]Loading train:  99%|█████████▉| 282/285 [05:25<00:03,  1.19s/it]Loading train:  99%|█████████▉| 283/285 [05:26<00:02,  1.29s/it]Loading train: 100%|█████████▉| 284/285 [05:28<00:01,  1.32s/it]Loading train: 100%|██████████| 285/285 [05:29<00:00,  1.36s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 45.11it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:06, 42.86it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:05, 45.98it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:04, 56.48it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:04, 58.75it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:04, 57.45it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:04, 58.90it/s]concatenating: train:  19%|█▉        | 55/285 [00:00<00:04, 57.19it/s]concatenating: train:  22%|██▏       | 64/285 [00:00<00:03, 63.60it/s]concatenating: train:  26%|██▌       | 73/285 [00:01<00:03, 69.10it/s]concatenating: train:  29%|██▉       | 82/285 [00:01<00:02, 72.08it/s]concatenating: train:  32%|███▏      | 90/285 [00:01<00:03, 63.10it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 69.83it/s]concatenating: train:  38%|███▊      | 108/285 [00:01<00:02, 68.76it/s]concatenating: train:  42%|████▏     | 119/285 [00:01<00:02, 76.20it/s]concatenating: train:  45%|████▍     | 128/285 [00:01<00:02, 74.41it/s]concatenating: train:  48%|████▊     | 138/285 [00:01<00:01, 79.07it/s]concatenating: train:  52%|█████▏    | 147/285 [00:02<00:01, 77.71it/s]concatenating: train:  55%|█████▍    | 156/285 [00:02<00:01, 80.27it/s]concatenating: train:  59%|█████▉    | 168/285 [00:02<00:01, 87.50it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 83.68it/s]concatenating: train:  66%|██████▌   | 188/285 [00:02<00:01, 85.28it/s]concatenating: train:  69%|██████▉   | 197/285 [00:02<00:01, 68.46it/s]concatenating: train:  72%|███████▏  | 205/285 [00:02<00:01, 69.32it/s]concatenating: train:  75%|███████▍  | 213/285 [00:02<00:01, 68.50it/s]concatenating: train:  78%|███████▊  | 221/285 [00:03<00:00, 66.59it/s]concatenating: train:  80%|████████  | 228/285 [00:03<00:00, 65.30it/s]concatenating: train:  84%|████████▎ | 238/285 [00:03<00:00, 71.03it/s]concatenating: train:  86%|████████▋ | 246/285 [00:03<00:00, 69.57it/s]concatenating: train:  90%|█████████ | 257/285 [00:03<00:00, 76.64it/s]concatenating: train:  93%|█████████▎| 266/285 [00:03<00:00, 79.75it/s]concatenating: train:  98%|█████████▊| 278/285 [00:03<00:00, 87.85it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 74.32it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:03,  1.73s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.64s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.53s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 42.33it/s]2019-07-11 08:30:11.300541: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 08:30:11.300671: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 08:30:11.300686: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 08:30:11.300694: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 08:30:11.301054: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:13,  3.22it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:10,  3.86it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.10it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.39it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.18it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.01it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.44it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.10it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.65it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.42it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.05it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.10it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.26it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.76it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.38it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.65it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.79it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.99it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.47it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 10)   5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 52, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 52, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 52, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 70)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 233,253
Trainable params: 58,493
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 20s - loss: 2.1958 - acc: 0.7865 - mDice: 0.1692 - val_loss: 0.9853 - val_acc: 0.9148 - val_mDice: 0.3667

Epoch 00001: val_mDice improved from -inf to 0.36668, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.8674 - acc: 0.8990 - mDice: 0.4052 - val_loss: 0.7739 - val_acc: 0.9251 - val_mDice: 0.4651

Epoch 00002: val_mDice improved from 0.36668 to 0.46514, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.6848 - acc: 0.9142 - mDice: 0.4883 - val_loss: 1.2510 - val_acc: 0.9287 - val_mDice: 0.3891

Epoch 00003: val_mDice did not improve from 0.46514
Epoch 4/300
 - 14s - loss: 0.5964 - acc: 0.9235 - mDice: 0.5347 - val_loss: 0.6151 - val_acc: 0.9415 - val_mDice: 0.5332

Epoch 00004: val_mDice improved from 0.46514 to 0.53323, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.5427 - acc: 0.9286 - mDice: 0.5653 - val_loss: 0.6136 - val_acc: 0.9423 - val_mDice: 0.5368

Epoch 00005: val_mDice improved from 0.53323 to 0.53679, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 14s - loss: 0.5028 - acc: 0.9323 - mDice: 0.5889 - val_loss: 0.5671 - val_acc: 0.9447 - val_mDice: 0.5601

Epoch 00006: val_mDice improved from 0.53679 to 0.56011, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 14s - loss: 0.4717 - acc: 0.9351 - mDice: 0.6079 - val_loss: 0.5516 - val_acc: 0.9440 - val_mDice: 0.5660

Epoch 00007: val_mDice improved from 0.56011 to 0.56605, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.4484 - acc: 0.9372 - mDice: 0.6230 - val_loss: 0.5727 - val_acc: 0.9457 - val_mDice: 0.5555

Epoch 00008: val_mDice did not improve from 0.56605
Epoch 9/300
 - 14s - loss: 0.4328 - acc: 0.9388 - mDice: 0.6335 - val_loss: 0.5170 - val_acc: 0.9470 - val_mDice: 0.5845

Epoch 00009: val_mDice improved from 0.56605 to 0.58452, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 15s - loss: 0.4187 - acc: 0.9401 - mDice: 0.6429 - val_loss: 0.5616 - val_acc: 0.9477 - val_mDice: 0.5651

Epoch 00010: val_mDice did not improve from 0.58452
Epoch 11/300
 - 15s - loss: 0.4037 - acc: 0.9412 - mDice: 0.6527 - val_loss: 0.5654 - val_acc: 0.9466 - val_mDice: 0.5640

Epoch 00011: val_mDice did not improve from 0.58452
Epoch 12/300
 - 15s - loss: 0.3956 - acc: 0.9419 - mDice: 0.6583 - val_loss: 0.5155 - val_acc: 0.9489 - val_mDice: 0.5898

Epoch 00012: val_mDice improved from 0.58452 to 0.58984, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 15s - loss: 0.3824 - acc: 0.9430 - mDice: 0.6675 - val_loss: 0.5372 - val_acc: 0.9488 - val_mDice: 0.5777

Epoch 00013: val_mDice did not improve from 0.58984
Epoch 14/300
 - 15s - loss: 0.3763 - acc: 0.9437 - mDice: 0.6717 - val_loss: 0.5479 - val_acc: 0.9426 - val_mDice: 0.5683

Epoch 00014: val_mDice did not improve from 0.58984
Epoch 15/300
 - 14s - loss: 0.3651 - acc: 0.9444 - mDice: 0.6793 - val_loss: 0.5521 - val_acc: 0.9468 - val_mDice: 0.5705

Epoch 00015: val_mDice did not improve from 0.58984
Epoch 16/300
 - 14s - loss: 0.3639 - acc: 0.9446 - mDice: 0.6804 - val_loss: 0.5560 - val_acc: 0.9475 - val_mDice: 0.5688

Epoch 00016: val_mDice did not improve from 0.58984
Epoch 17/300
 - 15s - loss: 0.3565 - acc: 0.9451 - mDice: 0.6856 - val_loss: 0.5038 - val_acc: 0.9471 - val_mDice: 0.5943

Epoch 00017: val_mDice improved from 0.58984 to 0.59432, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 14s - loss: 0.3495 - acc: 0.9458 - mDice: 0.6905 - val_loss: 0.5615 - val_acc: 0.9441 - val_mDice: 0.5663

Epoch 00018: val_mDice did not improve from 0.59432
Epoch 19/300
 - 15s - loss: 0.3446 - acc: 0.9462 - mDice: 0.6941 - val_loss: 0.5338 - val_acc: 0.9491 - val_mDice: 0.5815

Epoch 00019: val_mDice did not improve from 0.59432
Epoch 20/300
 - 14s - loss: 0.3403 - acc: 0.9466 - mDice: 0.6974 - val_loss: 0.5458 - val_acc: 0.9473 - val_mDice: 0.5735

Epoch 00020: val_mDice did not improve from 0.59432
Epoch 21/300
 - 15s - loss: 0.3350 - acc: 0.9469 - mDice: 0.7010 - val_loss: 0.5396 - val_acc: 0.9489 - val_mDice: 0.5791

Epoch 00021: val_mDice did not improve from 0.59432
Epoch 22/300
 - 14s - loss: 0.3318 - acc: 0.9472 - mDice: 0.7034 - val_loss: 0.5404 - val_acc: 0.9459 - val_mDice: 0.5746

Epoch 00022: val_mDice did not improve from 0.59432
Epoch 23/300
 - 15s - loss: 0.3283 - acc: 0.9474 - mDice: 0.7059 - val_loss: 0.5157 - val_acc: 0.9485 - val_mDice: 0.5887

Epoch 00023: val_mDice did not improve from 0.59432
Epoch 24/300
 - 14s - loss: 0.3239 - acc: 0.9477 - mDice: 0.7092 - val_loss: 0.5101 - val_acc: 0.9480 - val_mDice: 0.5906

Epoch 00024: val_mDice did not improve from 0.59432
Epoch 25/300
 - 15s - loss: 0.3211 - acc: 0.9480 - mDice: 0.7112 - val_loss: 0.5642 - val_acc: 0.9487 - val_mDice: 0.5729

Epoch 00025: val_mDice did not improve from 0.59432
Epoch 26/300
 - 15s - loss: 0.3176 - acc: 0.9483 - mDice: 0.7139 - val_loss: 0.5261 - val_acc: 0.9492 - val_mDice: 0.5884

Epoch 00026: val_mDice did not improve from 0.59432
Epoch 27/300
 - 15s - loss: 0.3156 - acc: 0.9484 - mDice: 0.7152 - val_loss: 0.5422 - val_acc: 0.9445 - val_mDice: 0.5742

Epoch 00027: val_mDice did not improve from 0.59432
Epoch 28/300
 - 14s - loss: 0.3115 - acc: 0.9488 - mDice: 0.7184 - val_loss: 0.5129 - val_acc: 0.9499 - val_mDice: 0.5924

Epoch 00028: val_mDice did not improve from 0.59432
Epoch 29/300
 - 15s - loss: 0.3082 - acc: 0.9491 - mDice: 0.7209 - val_loss: 0.4978 - val_acc: 0.9515 - val_mDice: 0.6012

Epoch 00029: val_mDice improved from 0.59432 to 0.60123, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 14s - loss: 0.3070 - acc: 0.9492 - mDice: 0.7218 - val_loss: 0.5134 - val_acc: 0.9506 - val_mDice: 0.5927

Epoch 00030: val_mDice did not improve from 0.60123
Epoch 31/300
 - 14s - loss: 0.3058 - acc: 0.9493 - mDice: 0.7227 - val_loss: 0.5311 - val_acc: 0.9472 - val_mDice: 0.5815

Epoch 00031: val_mDice did not improve from 0.60123
Epoch 32/300
 - 14s - loss: 0.3025 - acc: 0.9495 - mDice: 0.7253 - val_loss: 0.5421 - val_acc: 0.9474 - val_mDice: 0.5781

Epoch 00032: val_mDice did not improve from 0.60123
Epoch 33/300
 - 14s - loss: 0.2996 - acc: 0.9497 - mDice: 0.7273 - val_loss: 0.5148 - val_acc: 0.9480 - val_mDice: 0.5888

Epoch 00033: val_mDice did not improve from 0.60123
Epoch 34/300
 - 14s - loss: 0.2987 - acc: 0.9499 - mDice: 0.7280 - val_loss: 0.5171 - val_acc: 0.9476 - val_mDice: 0.5873

Epoch 00034: val_mDice did not improve from 0.60123
Epoch 35/300
 - 14s - loss: 0.2960 - acc: 0.9501 - mDice: 0.7301 - val_loss: 0.5737 - val_acc: 0.9486 - val_mDice: 0.5682

Epoch 00035: val_mDice did not improve from 0.60123
Epoch 36/300
 - 14s - loss: 0.2962 - acc: 0.9501 - mDice: 0.7301 - val_loss: 0.5697 - val_acc: 0.9441 - val_mDice: 0.5605

Epoch 00036: val_mDice did not improve from 0.60123
Epoch 37/300
 - 15s - loss: 0.2921 - acc: 0.9504 - mDice: 0.7331 - val_loss: 0.5452 - val_acc: 0.9468 - val_mDice: 0.5779

Epoch 00037: val_mDice did not improve from 0.60123
Epoch 38/300
 - 14s - loss: 0.2892 - acc: 0.9505 - mDice: 0.7352 - val_loss: 0.5272 - val_acc: 0.9504 - val_mDice: 0.5852

Epoch 00038: val_mDice did not improve from 0.60123
Epoch 39/300
 - 15s - loss: 0.2904 - acc: 0.9505 - mDice: 0.7345 - val_loss: 0.5456 - val_acc: 0.9471 - val_mDice: 0.5787

Epoch 00039: val_mDice did not improve from 0.60123
Epoch 40/300
 - 14s - loss: 0.2887 - acc: 0.9508 - mDice: 0.7357 - val_loss: 0.5368 - val_acc: 0.9463 - val_mDice: 0.5764

Epoch 00040: val_mDice did not improve from 0.60123
Epoch 41/300
 - 14s - loss: 0.2867 - acc: 0.9511 - mDice: 0.7372 - val_loss: 0.5213 - val_acc: 0.9475 - val_mDice: 0.5883

Epoch 00041: val_mDice did not improve from 0.60123
Epoch 42/300
 - 15s - loss: 0.2878 - acc: 0.9509 - mDice: 0.7365 - val_loss: 0.5389 - val_acc: 0.9468 - val_mDice: 0.5791

Epoch 00042: val_mDice did not improve from 0.60123
Epoch 43/300
 - 14s - loss: 0.2834 - acc: 0.9511 - mDice: 0.7398 - val_loss: 0.5217 - val_acc: 0.9490 - val_mDice: 0.5890

Epoch 00043: val_mDice did not improve from 0.60123
Epoch 44/300
 - 15s - loss: 0.2833 - acc: 0.9512 - mDice: 0.7399 - val_loss: 0.5033 - val_acc: 0.9485 - val_mDice: 0.5960

Epoch 00044: val_mDice did not improve from 0.60123
Epoch 45/300
 - 15s - loss: 0.2808 - acc: 0.9514 - mDice: 0.7417 - val_loss: 0.5141 - val_acc: 0.9503 - val_mDice: 0.5940

Epoch 00045: val_mDice did not improve from 0.60123
Epoch 46/300
 - 15s - loss: 0.2791 - acc: 0.9516 - mDice: 0.7430 - val_loss: 0.5344 - val_acc: 0.9509 - val_mDice: 0.5850

Epoch 00046: val_mDice did not improve from 0.60123
Epoch 47/300
 - 15s - loss: 0.2784 - acc: 0.9517 - mDice: 0.7437 - val_loss: 0.5280 - val_acc: 0.9489 - val_mDice: 0.5866

Epoch 00047: val_mDice did not improve from 0.60123
Epoch 48/300
 - 15s - loss: 0.2754 - acc: 0.9519 - mDice: 0.7459 - val_loss: 0.5501 - val_acc: 0.9486 - val_mDice: 0.5759

Epoch 00048: val_mDice did not improve from 0.60123
Epoch 49/300
 - 15s - loss: 0.2793 - acc: 0.9519 - mDice: 0.7436 - val_loss: 1.7026 - val_acc: 0.9337 - val_mDice: 0.4349

Epoch 00049: val_mDice did not improve from 0.60123
Epoch 50/300
 - 15s - loss: 0.3525 - acc: 0.9465 - mDice: 0.6925 - val_loss: 0.5216 - val_acc: 0.9481 - val_mDice: 0.5865

Epoch 00050: val_mDice did not improve from 0.60123
Epoch 51/300
 - 15s - loss: 0.2897 - acc: 0.9508 - mDice: 0.7348 - val_loss: 0.5302 - val_acc: 0.9488 - val_mDice: 0.5843

Epoch 00051: val_mDice did not improve from 0.60123
Epoch 52/300
 - 15s - loss: 0.2808 - acc: 0.9515 - mDice: 0.7417 - val_loss: 0.5263 - val_acc: 0.9489 - val_mDice: 0.5853

Epoch 00052: val_mDice did not improve from 0.60123
Epoch 53/300
 - 15s - loss: 0.2781 - acc: 0.9518 - mDice: 0.7439 - val_loss: 0.5508 - val_acc: 0.9463 - val_mDice: 0.5758

Epoch 00053: val_mDice did not improve from 0.60123
Epoch 54/300
 - 15s - loss: 0.2741 - acc: 0.9522 - mDice: 0.7469 - val_loss: 0.5252 - val_acc: 0.9492 - val_mDice: 0.5897

Epoch 00054: val_mDice did not improve from 0.60123
Epoch 55/300
 - 15s - loss: 0.2722 - acc: 0.9524 - mDice: 0.7486 - val_loss: 0.5209 - val_acc: 0.9481 - val_mDice: 0.5875

Epoch 00055: val_mDice did not improve from 0.60123
Epoch 56/300
 - 15s - loss: 0.2721 - acc: 0.9524 - mDice: 0.7486 - val_loss: 0.6296 - val_acc: 0.9498 - val_mDice: 0.5517

Epoch 00056: val_mDice did not improve from 0.60123
Epoch 57/300
 - 15s - loss: 0.2709 - acc: 0.9524 - mDice: 0.7496 - val_loss: 0.5390 - val_acc: 0.9484 - val_mDice: 0.5814

Epoch 00057: val_mDice did not improve from 0.60123
Epoch 58/300
 - 15s - loss: 0.2691 - acc: 0.9526 - mDice: 0.7510 - val_loss: 0.5588 - val_acc: 0.9470 - val_mDice: 0.5709

Epoch 00058: val_mDice did not improve from 0.60123
Epoch 59/300
 - 15s - loss: 0.2692 - acc: 0.9526 - mDice: 0.7509 - val_loss: 0.5385 - val_acc: 0.9493 - val_mDice: 0.5824

Epoch 00059: val_mDice did not improve from 0.60123
Epoch 60/300
 - 15s - loss: 0.2701 - acc: 0.9526 - mDice: 0.7504 - val_loss: 0.5885 - val_acc: 0.9451 - val_mDice: 0.5579

Epoch 00060: val_mDice did not improve from 0.60123
Epoch 61/300
 - 15s - loss: 0.2682 - acc: 0.9526 - mDice: 0.7516 - val_loss: 0.5487 - val_acc: 0.9498 - val_mDice: 0.5790

Epoch 00061: val_mDice did not improve from 0.60123
Epoch 62/300
 - 14s - loss: 0.2652 - acc: 0.9529 - mDice: 0.7540 - val_loss: 0.5537 - val_acc: 0.9512 - val_mDice: 0.5761

Epoch 00062: val_mDice did not improve from 0.60123
Epoch 63/300
 - 14s - loss: 0.2656 - acc: 0.9530 - mDice: 0.7537 - val_loss: 0.5178 - val_acc: 0.9498 - val_mDice: 0.5913

Epoch 00063: val_mDice did not improve from 0.60123
Epoch 64/300
 - 14s - loss: 0.2641 - acc: 0.9531 - mDice: 0.7549 - val_loss: 0.5429 - val_acc: 0.9495 - val_mDice: 0.5804

Epoch 00064: val_mDice did not improve from 0.60123
Epoch 65/300
 - 14s - loss: 0.2637 - acc: 0.9531 - mDice: 0.7553 - val_loss: 0.5058 - val_acc: 0.9474 - val_mDice: 0.5944

Epoch 00065: val_mDice did not improve from 0.60123
Epoch 66/300
 - 14s - loss: 0.2628 - acc: 0.9532 - mDice: 0.7559 - val_loss: 0.5377 - val_acc: 0.9493 - val_mDice: 0.5832

Epoch 00066: val_mDice did not improve from 0.60123
Epoch 67/300
 - 14s - loss: 0.2613 - acc: 0.9533 - mDice: 0.7571 - val_loss: 0.5606 - val_acc: 0.9499 - val_mDice: 0.5811

Epoch 00067: val_mDice did not improve from 0.60123
Epoch 68/300
 - 14s - loss: 0.2615 - acc: 0.9533 - mDice: 0.7570 - val_loss: 0.5445 - val_acc: 0.9491 - val_mDice: 0.5802

Epoch 00068: val_mDice did not improve from 0.60123
Epoch 69/300
 - 14s - loss: 0.2605 - acc: 0.9534 - mDice: 0.7577 - val_loss: 0.5408 - val_acc: 0.9496 - val_mDice: 0.5824

Epoch 00069: val_mDice did not improve from 0.60123
Restoring model weights from the end of the best epoch
Epoch 00069: early stopping
{'val_loss': [0.9852903861573289, 0.7739307910370428, 1.2510321060372465, 0.6151030599737967, 0.6135752387552954, 0.5670763064363149, 0.5515678481682719, 0.5727279995406807, 0.5169891838254875, 0.5615715950560969, 0.5653808246777711, 0.5154552742755613, 0.537194518403634, 0.5478714061848944, 0.5520948854238628, 0.5560315900674745, 0.5038309723305303, 0.5615267294079231, 0.5337507085427226, 0.5457843495480841, 0.5396127467714874, 0.5403766582132051, 0.5156636377952618, 0.5101036695794686, 0.5641980257780193, 0.5261244420898693, 0.5422229107531755, 0.5129443373760032, 0.4977757064989825, 0.513427786986921, 0.5311132120020563, 0.5421450001567436, 0.5147897221522624, 0.5170900771737764, 0.5736576618429002, 0.5696691204715707, 0.5452153642750319, 0.5272168730224311, 0.5456309052153007, 0.536791076540281, 0.521294262489127, 0.5389425784515935, 0.5216695662983303, 0.5032861412570463, 0.5140798158485796, 0.5343517817598481, 0.5280341878949597, 0.5501383313253605, 1.7025633690743474, 0.52159346615136, 0.53018550233468, 0.5262917210269906, 0.5507665116693721, 0.5252329620569112, 0.5208744186928819, 0.6295999581587381, 0.5390322354918752, 0.5587514722147467, 0.538527457074746, 0.5885494434633735, 0.5487397749330745, 0.5536584357975581, 0.517756920287063, 0.5429135554329643, 0.5057860532952421, 0.5377294131497431, 0.5605545972978603, 0.5444889984317332, 0.5407502867656047], 'val_acc': [0.9147879388079297, 0.9251409206310464, 0.9286635334931272, 0.9414502738574364, 0.9422560583945759, 0.9446774358189972, 0.9439687885385651, 0.9457063505103468, 0.9469914216569016, 0.9477434644485985, 0.946555484606567, 0.9488736008132637, 0.9488467450914436, 0.9426485986016983, 0.9468075300062169, 0.9475017483007975, 0.9471463684263176, 0.9440906817020651, 0.9490574691548693, 0.9473157941296114, 0.9488818622168216, 0.9458530152310206, 0.9484789824352584, 0.9479624522464901, 0.9487206992490331, 0.9491628398442401, 0.9445348658375234, 0.9499231543620872, 0.9514685492941787, 0.9505574033913, 0.9472455339058817, 0.947433559255227, 0.9479913788134825, 0.9475905848614996, 0.9486049893182084, 0.9440679586799451, 0.9468013314561471, 0.9504458501352279, 0.9471215775559069, 0.9463075485975383, 0.9474542024415299, 0.9467682648637441, 0.9489851527373884, 0.9484934503805704, 0.9503280953322043, 0.9509231151815233, 0.9488508661366042, 0.9486194715819545, 0.9336798827075425, 0.9480512901391397, 0.9487558190383059, 0.9489087016222864, 0.9462538594640167, 0.9491648927081231, 0.9481256887233457, 0.949828113257552, 0.9484128602390183, 0.9470348304876403, 0.9493033393135284, 0.9450658786230247, 0.9498218970591795, 0.9512206219428079, 0.9498177796768743, 0.9494582894128129, 0.9473963612950714, 0.9492619979980937, 0.94992932727217, 0.9491153093023673, 0.9496318438199646], 'val_mDice': [0.36667993964429674, 0.46514350891779255, 0.3891189779316247, 0.5332347537552178, 0.5367945820592636, 0.5601054077041882, 0.5660459332625959, 0.5555111729232959, 0.5845234843605723, 0.5651367476532579, 0.564046777160474, 0.5898388091412337, 0.5776739207059978, 0.5683277775455453, 0.5705106238413123, 0.5687589931754427, 0.5943168494954455, 0.5663447153634865, 0.5815090220733727, 0.5734695888764365, 0.5790844979232916, 0.5745706098705696, 0.5886775428356406, 0.5906096976562585, 0.5729245090617814, 0.5883985644612233, 0.5742165209860776, 0.5924146964563338, 0.6012305131171669, 0.592747834141694, 0.5815300555202548, 0.5781253443083949, 0.5887747230476508, 0.5872589139964993, 0.5682075596388492, 0.5605134281366231, 0.5779440899135014, 0.585240412690786, 0.5786633028664403, 0.5764144765598148, 0.5882877544317832, 0.5790947958743772, 0.5890267175003137, 0.595992417974845, 0.5940371122440147, 0.584951998135231, 0.5865858240500509, 0.5758945249312417, 0.4349464248012564, 0.5865167692386904, 0.5842802604483492, 0.5852643194811304, 0.5758249606500124, 0.5896686961530974, 0.5874732386466511, 0.5516806427992922, 0.5813932581986795, 0.5709300387505046, 0.5823630946974515, 0.5578630433402247, 0.5790348156204437, 0.5760834580027191, 0.5913424561809562, 0.5804429240732886, 0.594402374169014, 0.58322028874019, 0.5810542659386576, 0.580199842679434, 0.5823986057462639], 'loss': [2.195826388958408, 0.8673567639756232, 0.6847555476539724, 0.5963877019692101, 0.5427364744292671, 0.5028094305081096, 0.4717490574508625, 0.44842416762227905, 0.43282281904463143, 0.4186589838788307, 0.40374664649108444, 0.39564716035709047, 0.3824207641857524, 0.37626782948658766, 0.365056144836376, 0.36389017413497576, 0.3564813204122248, 0.3495382932797671, 0.34464880994680197, 0.34030329683956567, 0.3350390501677045, 0.3317537720939912, 0.3283216939902982, 0.32394347441436017, 0.3211103634898955, 0.31758396634673264, 0.31564432481270027, 0.31147208053960135, 0.30820549094698396, 0.3070120543564504, 0.30580224536887235, 0.3024936492267397, 0.2996204512716346, 0.29871151652427536, 0.296038923829828, 0.29618734919091894, 0.29213303847124905, 0.28923446474028053, 0.2903768277870765, 0.28874845601109844, 0.28669963470699156, 0.28777743964359903, 0.28339174915246923, 0.28332131290466955, 0.28076226424887823, 0.27914745618650244, 0.27837665959722785, 0.27539643722223006, 0.27926105007640445, 0.35253966324703734, 0.2897035932853833, 0.28076379180253186, 0.27811354086599177, 0.2741004116401051, 0.2721863785676139, 0.27206117388541307, 0.27091608326631555, 0.2690634239775625, 0.26921949326508343, 0.2701337814451166, 0.2681983725972428, 0.2652495868127075, 0.2656278149763241, 0.2640964264369376, 0.2636756664377874, 0.2628380520921875, 0.26127467772863405, 0.2614573713423062, 0.26051807505821756], 'acc': [0.7864532877524871, 0.899016869616115, 0.9142276890091787, 0.9235462048663909, 0.928607883367538, 0.9323162831328324, 0.9350628498125022, 0.9372272622311961, 0.9388406532248746, 0.940116352069794, 0.9412050930660708, 0.9419494917284825, 0.9430373453294054, 0.943663110816656, 0.9443579815966417, 0.9445774048594412, 0.9450909804852464, 0.9457653235924295, 0.9461699140746442, 0.9465515373072706, 0.946913603717391, 0.9472499318933391, 0.9473509409057439, 0.9477267868702828, 0.9479666370158946, 0.9483350285367829, 0.9484242167869403, 0.9488132325537253, 0.9490636121726141, 0.9492071064837416, 0.9492702674037277, 0.9494907808657026, 0.9497129217477596, 0.949872769023798, 0.9501277624921246, 0.9500856063125842, 0.9504049732484989, 0.9505254589007004, 0.9505088660336678, 0.9507592666428968, 0.9510690462978166, 0.9509010049526899, 0.9510815754856629, 0.9512259117087458, 0.9514210044763088, 0.9516370662234784, 0.9516927745664154, 0.9518615432985662, 0.951889661673685, 0.9464602140317873, 0.9508052908493201, 0.951481447144016, 0.9518345538440545, 0.9521635485256389, 0.9523515337744892, 0.952406197895081, 0.952444465755345, 0.952605458770882, 0.9525574428097277, 0.9525688655865582, 0.9526194391846105, 0.9529432948979214, 0.9530112335289896, 0.9531013499021231, 0.95308938536611, 0.9532234478240945, 0.9533373894310226, 0.9532909226712303, 0.9534250874124862], 'mDice': [0.16924072001801974, 0.40515106398973205, 0.48828418703096366, 0.5346861140938745, 0.5653436121536258, 0.5889001186458472, 0.6079098654269887, 0.6230047047186908, 0.6334978082485042, 0.6429498882849721, 0.6526768081530099, 0.6582921391303201, 0.6674504627440531, 0.6717324277705522, 0.6793014263413348, 0.6803692847962642, 0.6856454096778755, 0.6905258223937881, 0.6940654992966355, 0.6974485157836036, 0.700995116002432, 0.7034217341910598, 0.7058974718789144, 0.7091614180586124, 0.7111905352767143, 0.7139370063117215, 0.7152348227194728, 0.7184062939110641, 0.7209306149939542, 0.7217695367997862, 0.7227057182355797, 0.7253138789047142, 0.7272964565363477, 0.7279750148193437, 0.7300977616013801, 0.7300825365604733, 0.7330829917809963, 0.7351912368415818, 0.7344915256813963, 0.7356550412612779, 0.7372102605076594, 0.7364571800770034, 0.7398334340256847, 0.7399135331404793, 0.741679510671091, 0.7430320561636599, 0.7437284789497793, 0.7459029552106938, 0.7436103111037722, 0.6925159978695175, 0.7347618403189855, 0.7417123518792069, 0.7438550225647373, 0.746923804270157, 0.7485757453185424, 0.7486219372951116, 0.7496417330978782, 0.7509537103759016, 0.7508534681471752, 0.7503665031012182, 0.7516488872460761, 0.7540090479438364, 0.7537253714647891, 0.7548889036687862, 0.7552559358038341, 0.7559311610636553, 0.757076897104869, 0.7569765990209323, 0.757694373878218]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.37s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.12s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.91s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:00,  1.90s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:13,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:04<08:09,  1.74s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:42,  1.64s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:57,  1.71s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:35,  1.63s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:55,  1.71s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:47,  1.69s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:19,  1.81s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:36,  1.88s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:38,  1.90s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:16,  1.82s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:16,  1.83s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:36,  1.91s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:48,  1.97s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:27,  1.89s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:28,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:15,  1.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:15,  1.87s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:26,  1.92s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<08:01,  1.83s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<08:08,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:47,  1.79s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:06,  1.87s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:26,  1.95s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:11,  1.90s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:05,  1.89s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:01,  1.88s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:18,  1.96s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:24,  1.99s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:58,  1.89s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:59,  1.90s/it]predicting train subjects:  12%|█▏        | 34/285 [01:02<07:51,  1.88s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:04,  1.94s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:37,  1.84s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:36,  1.84s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:57,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:35,  1.85s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:37,  1.87s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:16,  1.79s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:07,  1.76s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:15,  1.80s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:33,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:16,  1.82s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:28,  1.88s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<07:07,  1.80s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:13,  1.83s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:34,  1.93s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:27,  1.90s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:37,  1.96s/it]predicting train subjects:  18%|█▊        | 52/285 [01:36<07:15,  1.87s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:11,  1.86s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:25,  1.93s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:03,  1.84s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:05,  1.86s/it]predicting train subjects:  20%|██        | 57/285 [01:45<06:51,  1.80s/it]predicting train subjects:  20%|██        | 58/285 [01:47<06:56,  1.83s/it]predicting train subjects:  21%|██        | 59/285 [01:49<07:16,  1.93s/it]predicting train subjects:  21%|██        | 60/285 [01:51<07:24,  1.98s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<06:57,  1.86s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<06:53,  1.86s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<06:53,  1.86s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:48,  1.85s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:49,  1.86s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:45,  1.85s/it]predicting train subjects:  24%|██▎       | 67/285 [02:04<06:46,  1.87s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:33,  1.82s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:40,  1.85s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:43,  1.87s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:39,  1.87s/it]predicting train subjects:  25%|██▌       | 72/285 [02:13<06:27,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:15<06:30,  1.84s/it]predicting train subjects:  26%|██▌       | 74/285 [02:17<06:30,  1.85s/it]predicting train subjects:  26%|██▋       | 75/285 [02:19<06:34,  1.88s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:30,  1.87s/it]predicting train subjects:  27%|██▋       | 77/285 [02:22<06:19,  1.83s/it]predicting train subjects:  27%|██▋       | 78/285 [02:24<06:12,  1.80s/it]predicting train subjects:  28%|██▊       | 79/285 [02:26<06:12,  1.81s/it]predicting train subjects:  28%|██▊       | 80/285 [02:28<06:19,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:31<06:14,  1.85s/it]predicting train subjects:  29%|██▉       | 83/285 [02:33<06:02,  1.80s/it]predicting train subjects:  29%|██▉       | 84/285 [02:35<05:52,  1.75s/it]predicting train subjects:  30%|██▉       | 85/285 [02:36<05:59,  1.80s/it]predicting train subjects:  30%|███       | 86/285 [02:38<06:01,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:40<06:01,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:42<05:51,  1.79s/it]predicting train subjects:  31%|███       | 89/285 [02:44<05:52,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:46<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:47<05:51,  1.81s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<05:55,  1.84s/it]predicting train subjects:  33%|███▎      | 93/285 [02:51<05:44,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [02:53<05:49,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:55<05:50,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:57<05:53,  1.87s/it]predicting train subjects:  34%|███▍      | 97/285 [02:59<05:55,  1.89s/it]predicting train subjects:  34%|███▍      | 98/285 [03:00<05:49,  1.87s/it]predicting train subjects:  35%|███▍      | 99/285 [03:02<05:41,  1.84s/it]predicting train subjects:  35%|███▌      | 100/285 [03:04<05:43,  1.86s/it]predicting train subjects:  35%|███▌      | 101/285 [03:06<05:35,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:08<05:36,  1.84s/it]predicting train subjects:  36%|███▌      | 103/285 [03:10<05:31,  1.82s/it]predicting train subjects:  36%|███▋      | 104/285 [03:11<05:31,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:13<05:32,  1.85s/it]predicting train subjects:  37%|███▋      | 106/285 [03:15<05:24,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:17<05:23,  1.82s/it]predicting train subjects:  38%|███▊      | 108/285 [03:19<05:18,  1.80s/it]predicting train subjects:  38%|███▊      | 109/285 [03:20<05:20,  1.82s/it]predicting train subjects:  39%|███▊      | 110/285 [03:22<05:22,  1.84s/it]predicting train subjects:  39%|███▉      | 111/285 [03:24<05:16,  1.82s/it]predicting train subjects:  39%|███▉      | 112/285 [03:26<05:18,  1.84s/it]predicting train subjects:  40%|███▉      | 113/285 [03:28<05:19,  1.86s/it]predicting train subjects:  40%|████      | 114/285 [03:30<05:15,  1.84s/it]predicting train subjects:  40%|████      | 115/285 [03:32<05:09,  1.82s/it]predicting train subjects:  41%|████      | 116/285 [03:33<05:07,  1.82s/it]predicting train subjects:  41%|████      | 117/285 [03:35<04:57,  1.77s/it]predicting train subjects:  41%|████▏     | 118/285 [03:37<04:49,  1.73s/it]predicting train subjects:  42%|████▏     | 119/285 [03:39<04:55,  1.78s/it]predicting train subjects:  42%|████▏     | 120/285 [03:40<04:49,  1.76s/it]predicting train subjects:  42%|████▏     | 121/285 [03:42<04:43,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:43<04:32,  1.67s/it]predicting train subjects:  43%|████▎     | 123/285 [03:45<04:19,  1.60s/it]predicting train subjects:  44%|████▎     | 124/285 [03:47<04:22,  1.63s/it]predicting train subjects:  44%|████▍     | 125/285 [03:48<04:19,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:50<04:14,  1.60s/it]predicting train subjects:  45%|████▍     | 127/285 [03:51<04:07,  1.57s/it]predicting train subjects:  45%|████▍     | 128/285 [03:53<04:08,  1.58s/it]predicting train subjects:  45%|████▌     | 129/285 [03:54<04:02,  1.56s/it]predicting train subjects:  46%|████▌     | 130/285 [03:56<04:04,  1.58s/it]predicting train subjects:  46%|████▌     | 131/285 [03:58<04:02,  1.57s/it]predicting train subjects:  46%|████▋     | 132/285 [03:59<04:05,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [04:01<04:02,  1.59s/it]predicting train subjects:  47%|████▋     | 134/285 [04:02<03:58,  1.58s/it]predicting train subjects:  47%|████▋     | 135/285 [04:04<03:53,  1.55s/it]predicting train subjects:  48%|████▊     | 136/285 [04:05<03:46,  1.52s/it]predicting train subjects:  48%|████▊     | 137/285 [04:07<03:51,  1.56s/it]predicting train subjects:  48%|████▊     | 138/285 [04:08<03:46,  1.54s/it]predicting train subjects:  49%|████▉     | 139/285 [04:10<03:44,  1.54s/it]predicting train subjects:  49%|████▉     | 140/285 [04:12<03:48,  1.58s/it]predicting train subjects:  49%|████▉     | 141/285 [04:13<03:42,  1.54s/it]predicting train subjects:  50%|████▉     | 142/285 [04:15<03:41,  1.55s/it]predicting train subjects:  50%|█████     | 143/285 [04:16<03:36,  1.53s/it]predicting train subjects:  51%|█████     | 144/285 [04:18<03:42,  1.58s/it]predicting train subjects:  51%|█████     | 145/285 [04:19<03:37,  1.55s/it]predicting train subjects:  51%|█████     | 146/285 [04:21<03:39,  1.58s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:22<03:34,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:24<03:34,  1.56s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:26<03:32,  1.57s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:27,  1.53s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:29<03:28,  1.56s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:23,  1.53s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:32<03:19,  1.51s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:33<03:20,  1.53s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:35<03:17,  1.52s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:36<03:22,  1.57s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:38<03:18,  1.55s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:39<03:19,  1.57s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:13,  1.54s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:42<03:11,  1.53s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:12,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:09,  1.54s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<03:13,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<03:10,  1.58s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:50<03:08,  1.57s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:09,  1.59s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:10,  1.61s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<03:03,  1.56s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<02:58,  1.54s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:55,  1.54s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:53,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:50,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [05:04<02:47,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:07<02:51,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:47,  1.55s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:10<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:39,  1.50s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:50,  1.63s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:15<02:50,  1.64s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:17<02:51,  1.66s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:19<02:42,  1.59s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:20<02:37,  1.56s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:33,  1.54s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:23<02:43,  1.65s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:25<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:27<02:48,  1.74s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:39,  1.66s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:30<02:32,  1.61s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:32<02:36,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:34,  1.67s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:35<02:27,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:36<02:22,  1.57s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:38<02:16,  1.52s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:40<02:24,  1.62s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:42<02:28,  1.69s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:43<02:29,  1.72s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:45<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:46<02:12,  1.56s/it]predicting train subjects:  71%|███████   | 201/285 [05:48<02:18,  1.65s/it]predicting train subjects:  71%|███████   | 202/285 [05:50<02:18,  1.67s/it]predicting train subjects:  71%|███████   | 203/285 [05:52<02:18,  1.69s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:53<02:11,  1.62s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:54<02:07,  1.60s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:56<02:02,  1.55s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:58<02:08,  1.65s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:00<02:13,  1.74s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:02<02:14,  1.77s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:03<02:06,  1.69s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:05<01:59,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:06<02:00,  1.65s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:08<01:59,  1.66s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:09<01:53,  1.60s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:11<01:56,  1.67s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:13<01:50,  1.60s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:15<01:55,  1.69s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:16<01:57,  1.76s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:18<01:58,  1.80s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:20<01:49,  1.69s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:21<01:43,  1.62s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:23<01:44,  1.66s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:24<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:26<01:34,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:27<01:30,  1.51s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:29<01:35,  1.62s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:31<01:38,  1.70s/it]predicting train subjects:  80%|████████  | 228/285 [06:33<01:39,  1.74s/it]predicting train subjects:  80%|████████  | 229/285 [06:35<01:36,  1.72s/it]predicting train subjects:  81%|████████  | 230/285 [06:36<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:38<01:25,  1.59s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:39<01:26,  1.64s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:41<01:21,  1.57s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:43<01:24,  1.66s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:44<01:20,  1.62s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:46<01:23,  1.70s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:48<01:25,  1.79s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:50<01:24,  1.79s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:51<01:20,  1.76s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:53<01:14,  1.66s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:54<01:11,  1.62s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:56<01:07,  1.57s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:57<01:03,  1.52s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:59<01:06,  1.62s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:01<01:02,  1.56s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:02<01:04,  1.65s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:04<01:04,  1.70s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:06<01:03,  1.70s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:07<00:58,  1.62s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:09<00:54,  1.57s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:10<00:51,  1.52s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:12<00:49,  1.50s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:14<00:51,  1.62s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:15<00:51,  1.67s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:17<00:50,  1.68s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:19<00:46,  1.61s/it]predicting train subjects:  90%|█████████ | 257/285 [07:20<00:43,  1.56s/it]predicting train subjects:  91%|█████████ | 258/285 [07:22<00:44,  1.64s/it]predicting train subjects:  91%|█████████ | 259/285 [07:23<00:42,  1.65s/it]predicting train subjects:  91%|█████████ | 260/285 [07:25<00:39,  1.58s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:26<00:36,  1.54s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:28<00:34,  1.52s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:29<00:33,  1.50s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:31<00:34,  1.63s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:33<00:33,  1.69s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:35<00:30,  1.63s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:36<00:28,  1.57s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:38<00:27,  1.64s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:39<00:26,  1.66s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:41<00:23,  1.60s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:42<00:21,  1.55s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:44<00:20,  1.60s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:45<00:18,  1.53s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:47<00:16,  1.50s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:49<00:15,  1.60s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:50<00:14,  1.65s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:52<00:12,  1.60s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:54<00:11,  1.60s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:55<00:09,  1.61s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:57<00:07,  1.57s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:58<00:06,  1.52s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:00<00:04,  1.51s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:01<00:03,  1.63s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:03<00:01,  1.71s/it]predicting train subjects: 100%|██████████| 285/285 [08:05<00:00,  1.74s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:23,  1.56s/it]Loading train:   1%|          | 2/285 [00:02<06:45,  1.43s/it]Loading train:   1%|          | 3/285 [00:04<06:40,  1.42s/it]Loading train:   1%|▏         | 4/285 [00:05<06:09,  1.31s/it]Loading train:   2%|▏         | 5/285 [00:06<06:16,  1.35s/it]Loading train:   2%|▏         | 6/285 [00:07<05:59,  1.29s/it]Loading train:   2%|▏         | 7/285 [00:09<06:20,  1.37s/it]Loading train:   3%|▎         | 8/285 [00:10<06:02,  1.31s/it]Loading train:   3%|▎         | 9/285 [00:12<06:27,  1.41s/it]Loading train:   4%|▎         | 10/285 [00:13<05:49,  1.27s/it]Loading train:   4%|▍         | 11/285 [00:13<05:06,  1.12s/it]Loading train:   4%|▍         | 12/285 [00:14<04:54,  1.08s/it]Loading train:   5%|▍         | 13/285 [00:15<04:27,  1.02it/s]Loading train:   5%|▍         | 14/285 [00:16<04:33,  1.01s/it]Loading train:   5%|▌         | 15/285 [00:17<04:25,  1.02it/s]Loading train:   6%|▌         | 16/285 [00:18<04:22,  1.02it/s]Loading train:   6%|▌         | 17/285 [00:19<04:08,  1.08it/s]Loading train:   6%|▋         | 18/285 [00:20<04:09,  1.07it/s]Loading train:   7%|▋         | 19/285 [00:21<03:58,  1.11it/s]Loading train:   7%|▋         | 20/285 [00:21<03:55,  1.13it/s]Loading train:   7%|▋         | 21/285 [00:22<03:57,  1.11it/s]Loading train:   8%|▊         | 22/285 [00:23<03:56,  1.11it/s]Loading train:   8%|▊         | 23/285 [00:24<03:52,  1.13it/s]Loading train:   8%|▊         | 24/285 [00:25<03:47,  1.15it/s]Loading train:   9%|▉         | 25/285 [00:26<03:51,  1.13it/s]Loading train:   9%|▉         | 26/285 [00:27<03:55,  1.10it/s]Loading train:   9%|▉         | 27/285 [00:28<03:50,  1.12it/s]Loading train:  10%|▉         | 28/285 [00:29<03:55,  1.09it/s]Loading train:  10%|█         | 29/285 [00:30<03:49,  1.12it/s]Loading train:  11%|█         | 30/285 [00:30<03:51,  1.10it/s]Loading train:  11%|█         | 31/285 [00:31<03:59,  1.06it/s]Loading train:  11%|█         | 32/285 [00:32<03:49,  1.10it/s]Loading train:  12%|█▏        | 33/285 [00:33<03:42,  1.13it/s]Loading train:  12%|█▏        | 34/285 [00:34<03:38,  1.15it/s]Loading train:  12%|█▏        | 35/285 [00:35<03:44,  1.11it/s]Loading train:  13%|█▎        | 36/285 [00:36<03:34,  1.16it/s]Loading train:  13%|█▎        | 37/285 [00:37<03:34,  1.16it/s]Loading train:  13%|█▎        | 38/285 [00:37<03:36,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:38<03:25,  1.20it/s]Loading train:  14%|█▍        | 40/285 [00:39<03:27,  1.18it/s]Loading train:  14%|█▍        | 41/285 [00:40<03:15,  1.25it/s]Loading train:  15%|█▍        | 42/285 [00:40<03:06,  1.30it/s]Loading train:  15%|█▌        | 43/285 [00:41<03:08,  1.28it/s]Loading train:  15%|█▌        | 44/285 [00:42<03:15,  1.23it/s]Loading train:  16%|█▌        | 45/285 [00:43<03:14,  1.24it/s]Loading train:  16%|█▌        | 46/285 [00:44<03:22,  1.18it/s]Loading train:  16%|█▋        | 47/285 [00:45<03:14,  1.22it/s]Loading train:  17%|█▋        | 48/285 [00:46<03:19,  1.19it/s]Loading train:  17%|█▋        | 49/285 [00:47<03:26,  1.14it/s]Loading train:  18%|█▊        | 50/285 [00:47<03:24,  1.15it/s]Loading train:  18%|█▊        | 51/285 [00:48<03:20,  1.17it/s]Loading train:  18%|█▊        | 52/285 [00:49<03:11,  1.22it/s]Loading train:  19%|█▊        | 53/285 [00:50<03:08,  1.23it/s]Loading train:  19%|█▉        | 54/285 [00:51<03:12,  1.20it/s]Loading train:  19%|█▉        | 55/285 [00:51<03:07,  1.23it/s]Loading train:  20%|█▉        | 56/285 [00:52<03:12,  1.19it/s]Loading train:  20%|██        | 57/285 [00:53<03:02,  1.25it/s]Loading train:  20%|██        | 58/285 [00:54<03:01,  1.25it/s]Loading train:  21%|██        | 59/285 [00:55<03:04,  1.22it/s]Loading train:  21%|██        | 60/285 [00:56<03:12,  1.17it/s]Loading train:  21%|██▏       | 61/285 [00:56<03:06,  1.20it/s]Loading train:  22%|██▏       | 62/285 [00:57<03:08,  1.18it/s]Loading train:  22%|██▏       | 63/285 [00:58<03:04,  1.20it/s]Loading train:  22%|██▏       | 64/285 [00:59<03:30,  1.05it/s]Loading train:  23%|██▎       | 65/285 [01:01<04:04,  1.11s/it]Loading train:  23%|██▎       | 66/285 [01:02<04:05,  1.12s/it]Loading train:  24%|██▎       | 67/285 [01:03<03:47,  1.05s/it]Loading train:  24%|██▍       | 68/285 [01:04<03:33,  1.02it/s]Loading train:  24%|██▍       | 69/285 [01:05<03:28,  1.03it/s]Loading train:  25%|██▍       | 70/285 [01:05<03:26,  1.04it/s]Loading train:  25%|██▍       | 71/285 [01:06<03:13,  1.11it/s]Loading train:  25%|██▌       | 72/285 [01:07<03:04,  1.16it/s]Loading train:  26%|██▌       | 73/285 [01:08<03:05,  1.14it/s]Loading train:  26%|██▌       | 74/285 [01:09<03:09,  1.12it/s]Loading train:  26%|██▋       | 75/285 [01:10<03:02,  1.15it/s]Loading train:  27%|██▋       | 76/285 [01:11<03:11,  1.09it/s]Loading train:  27%|██▋       | 77/285 [01:11<03:00,  1.16it/s]Loading train:  27%|██▋       | 78/285 [01:12<02:52,  1.20it/s]Loading train:  28%|██▊       | 79/285 [01:13<02:54,  1.18it/s]Loading train:  28%|██▊       | 80/285 [01:14<03:00,  1.14it/s]Loading train:  28%|██▊       | 81/285 [01:15<03:00,  1.13it/s]Loading train:  29%|██▉       | 82/285 [01:16<03:05,  1.10it/s]Loading train:  29%|██▉       | 83/285 [01:17<02:56,  1.14it/s]Loading train:  29%|██▉       | 84/285 [01:18<02:55,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:19<03:03,  1.09it/s]Loading train:  30%|███       | 86/285 [01:19<02:59,  1.11it/s]Loading train:  31%|███       | 87/285 [01:20<03:00,  1.10it/s]Loading train:  31%|███       | 88/285 [01:21<02:54,  1.13it/s]Loading train:  31%|███       | 89/285 [01:22<02:54,  1.12it/s]Loading train:  32%|███▏      | 90/285 [01:23<02:54,  1.12it/s]Loading train:  32%|███▏      | 91/285 [01:24<02:41,  1.20it/s]Loading train:  32%|███▏      | 92/285 [01:25<02:41,  1.19it/s]Loading train:  33%|███▎      | 93/285 [01:25<02:36,  1.22it/s]Loading train:  33%|███▎      | 94/285 [01:26<02:43,  1.17it/s]Loading train:  33%|███▎      | 95/285 [01:27<02:48,  1.13it/s]Loading train:  34%|███▎      | 96/285 [01:28<02:47,  1.13it/s]Loading train:  34%|███▍      | 97/285 [01:29<02:49,  1.11it/s]Loading train:  34%|███▍      | 98/285 [01:30<02:49,  1.10it/s]Loading train:  35%|███▍      | 99/285 [01:31<02:56,  1.05it/s]Loading train:  35%|███▌      | 100/285 [01:32<02:49,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:33<02:40,  1.15it/s]Loading train:  36%|███▌      | 102/285 [01:34<02:39,  1.15it/s]Loading train:  36%|███▌      | 103/285 [01:34<02:35,  1.17it/s]Loading train:  36%|███▋      | 104/285 [01:35<02:34,  1.17it/s]Loading train:  37%|███▋      | 105/285 [01:36<02:38,  1.13it/s]Loading train:  37%|███▋      | 106/285 [01:37<02:34,  1.16it/s]Loading train:  38%|███▊      | 107/285 [01:38<02:32,  1.17it/s]Loading train:  38%|███▊      | 108/285 [01:39<02:30,  1.17it/s]Loading train:  38%|███▊      | 109/285 [01:40<02:31,  1.16it/s]Loading train:  39%|███▊      | 110/285 [01:40<02:33,  1.14it/s]Loading train:  39%|███▉      | 111/285 [01:41<02:28,  1.17it/s]Loading train:  39%|███▉      | 112/285 [01:42<02:33,  1.13it/s]Loading train:  40%|███▉      | 113/285 [01:43<02:32,  1.13it/s]Loading train:  40%|████      | 114/285 [01:44<02:34,  1.10it/s]Loading train:  40%|████      | 115/285 [01:45<02:35,  1.09it/s]Loading train:  41%|████      | 116/285 [01:46<02:30,  1.12it/s]Loading train:  41%|████      | 117/285 [01:47<02:30,  1.12it/s]Loading train:  41%|████▏     | 118/285 [01:48<02:29,  1.11it/s]Loading train:  42%|████▏     | 119/285 [01:49<02:30,  1.10it/s]Loading train:  42%|████▏     | 120/285 [01:49<02:22,  1.16it/s]Loading train:  42%|████▏     | 121/285 [01:51<02:41,  1.02it/s]Loading train:  43%|████▎     | 122/285 [01:52<02:47,  1.03s/it]Loading train:  43%|████▎     | 123/285 [01:53<02:54,  1.08s/it]Loading train:  44%|████▎     | 124/285 [01:54<02:43,  1.02s/it]Loading train:  44%|████▍     | 125/285 [01:55<02:36,  1.03it/s]Loading train:  44%|████▍     | 126/285 [01:55<02:27,  1.08it/s]Loading train:  45%|████▍     | 127/285 [01:56<02:19,  1.13it/s]Loading train:  45%|████▍     | 128/285 [01:57<02:14,  1.17it/s]Loading train:  45%|████▌     | 129/285 [01:58<02:11,  1.18it/s]Loading train:  46%|████▌     | 130/285 [01:59<02:06,  1.23it/s]Loading train:  46%|████▌     | 131/285 [01:59<02:01,  1.27it/s]Loading train:  46%|████▋     | 132/285 [02:00<02:06,  1.21it/s]Loading train:  47%|████▋     | 133/285 [02:01<02:01,  1.25it/s]Loading train:  47%|████▋     | 134/285 [02:02<02:00,  1.25it/s]Loading train:  47%|████▋     | 135/285 [02:02<01:56,  1.29it/s]Loading train:  48%|████▊     | 136/285 [02:03<01:50,  1.35it/s]Loading train:  48%|████▊     | 137/285 [02:04<01:51,  1.33it/s]Loading train:  48%|████▊     | 138/285 [02:05<01:48,  1.36it/s]Loading train:  49%|████▉     | 139/285 [02:06<01:55,  1.27it/s]Loading train:  49%|████▉     | 140/285 [02:06<02:00,  1.20it/s]Loading train:  49%|████▉     | 141/285 [02:07<02:00,  1.19it/s]Loading train:  50%|████▉     | 142/285 [02:08<01:59,  1.20it/s]Loading train:  50%|█████     | 143/285 [02:09<01:59,  1.19it/s]Loading train:  51%|█████     | 144/285 [02:10<01:57,  1.20it/s]Loading train:  51%|█████     | 145/285 [02:11<01:57,  1.20it/s]Loading train:  51%|█████     | 146/285 [02:12<01:57,  1.18it/s]Loading train:  52%|█████▏    | 147/285 [02:12<01:53,  1.22it/s]Loading train:  52%|█████▏    | 148/285 [02:13<01:50,  1.24it/s]Loading train:  52%|█████▏    | 149/285 [02:14<01:53,  1.20it/s]Loading train:  53%|█████▎    | 150/285 [02:15<01:54,  1.17it/s]Loading train:  53%|█████▎    | 151/285 [02:16<01:57,  1.14it/s]Loading train:  53%|█████▎    | 152/285 [02:17<01:57,  1.13it/s]Loading train:  54%|█████▎    | 153/285 [02:17<01:53,  1.16it/s]Loading train:  54%|█████▍    | 154/285 [02:18<01:54,  1.15it/s]Loading train:  54%|█████▍    | 155/285 [02:19<01:51,  1.17it/s]Loading train:  55%|█████▍    | 156/285 [02:20<01:47,  1.20it/s]Loading train:  55%|█████▌    | 157/285 [02:21<01:44,  1.23it/s]Loading train:  55%|█████▌    | 158/285 [02:22<01:41,  1.25it/s]Loading train:  56%|█████▌    | 159/285 [02:22<01:38,  1.28it/s]Loading train:  56%|█████▌    | 160/285 [02:23<01:35,  1.31it/s]Loading train:  56%|█████▋    | 161/285 [02:24<01:35,  1.30it/s]Loading train:  57%|█████▋    | 162/285 [02:25<01:35,  1.29it/s]Loading train:  57%|█████▋    | 163/285 [02:25<01:35,  1.28it/s]Loading train:  58%|█████▊    | 164/285 [02:26<01:37,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [02:27<01:31,  1.31it/s]Loading train:  58%|█████▊    | 166/285 [02:28<01:32,  1.29it/s]Loading train:  59%|█████▊    | 167/285 [02:29<01:32,  1.27it/s]Loading train:  59%|█████▉    | 168/285 [02:29<01:29,  1.30it/s]Loading train:  59%|█████▉    | 169/285 [02:30<01:27,  1.33it/s]Loading train:  60%|█████▉    | 170/285 [02:31<01:27,  1.32it/s]Loading train:  60%|██████    | 171/285 [02:31<01:25,  1.33it/s]Loading train:  60%|██████    | 172/285 [02:32<01:27,  1.29it/s]Loading train:  61%|██████    | 173/285 [02:33<01:24,  1.32it/s]Loading train:  61%|██████    | 174/285 [02:34<01:24,  1.32it/s]Loading train:  61%|██████▏   | 175/285 [02:35<01:25,  1.29it/s]Loading train:  62%|██████▏   | 176/285 [02:35<01:24,  1.29it/s]Loading train:  62%|██████▏   | 177/285 [02:36<01:24,  1.27it/s]Loading train:  62%|██████▏   | 178/285 [02:37<01:19,  1.34it/s]Loading train:  63%|██████▎   | 179/285 [02:38<01:22,  1.28it/s]Loading train:  63%|██████▎   | 180/285 [02:39<01:25,  1.23it/s]Loading train:  64%|██████▎   | 181/285 [02:39<01:28,  1.18it/s]Loading train:  64%|██████▍   | 182/285 [02:40<01:27,  1.18it/s]Loading train:  64%|██████▍   | 183/285 [02:41<01:23,  1.22it/s]Loading train:  65%|██████▍   | 184/285 [02:42<01:19,  1.27it/s]Loading train:  65%|██████▍   | 185/285 [02:42<01:15,  1.33it/s]Loading train:  65%|██████▌   | 186/285 [02:43<01:20,  1.22it/s]Loading train:  66%|██████▌   | 187/285 [02:44<01:21,  1.20it/s]Loading train:  66%|██████▌   | 188/285 [02:45<01:24,  1.15it/s]Loading train:  66%|██████▋   | 189/285 [02:46<01:18,  1.22it/s]Loading train:  67%|██████▋   | 190/285 [02:47<01:16,  1.25it/s]Loading train:  67%|██████▋   | 191/285 [02:47<01:13,  1.29it/s]Loading train:  67%|██████▋   | 192/285 [02:48<01:13,  1.26it/s]Loading train:  68%|██████▊   | 193/285 [02:49<01:07,  1.36it/s]Loading train:  68%|██████▊   | 194/285 [02:50<01:07,  1.35it/s]Loading train:  68%|██████▊   | 195/285 [02:50<01:01,  1.47it/s]Loading train:  69%|██████▉   | 196/285 [02:51<01:05,  1.36it/s]Loading train:  69%|██████▉   | 197/285 [02:52<01:07,  1.30it/s]Loading train:  69%|██████▉   | 198/285 [02:53<01:10,  1.23it/s]Loading train:  70%|██████▉   | 199/285 [02:54<01:09,  1.24it/s]Loading train:  70%|███████   | 200/285 [02:54<01:06,  1.28it/s]Loading train:  71%|███████   | 201/285 [02:55<01:10,  1.19it/s]Loading train:  71%|███████   | 202/285 [02:56<01:07,  1.22it/s]Loading train:  71%|███████   | 203/285 [02:57<01:08,  1.21it/s]Loading train:  72%|███████▏  | 204/285 [02:58<01:04,  1.25it/s]Loading train:  72%|███████▏  | 205/285 [02:58<01:01,  1.31it/s]Loading train:  72%|███████▏  | 206/285 [02:59<00:58,  1.35it/s]Loading train:  73%|███████▎  | 207/285 [03:00<01:00,  1.28it/s]Loading train:  73%|███████▎  | 208/285 [03:01<01:03,  1.20it/s]Loading train:  73%|███████▎  | 209/285 [03:02<01:04,  1.18it/s]Loading train:  74%|███████▎  | 210/285 [03:02<01:00,  1.24it/s]Loading train:  74%|███████▍  | 211/285 [03:03<00:56,  1.31it/s]Loading train:  74%|███████▍  | 212/285 [03:04<00:56,  1.28it/s]Loading train:  75%|███████▍  | 213/285 [03:05<00:56,  1.28it/s]Loading train:  75%|███████▌  | 214/285 [03:05<00:52,  1.35it/s]Loading train:  75%|███████▌  | 215/285 [03:06<00:52,  1.32it/s]Loading train:  76%|███████▌  | 216/285 [03:07<00:50,  1.36it/s]Loading train:  76%|███████▌  | 217/285 [03:08<00:52,  1.29it/s]Loading train:  76%|███████▋  | 218/285 [03:09<00:53,  1.25it/s]Loading train:  77%|███████▋  | 219/285 [03:10<00:56,  1.16it/s]Loading train:  77%|███████▋  | 220/285 [03:10<00:54,  1.19it/s]Loading train:  78%|███████▊  | 221/285 [03:11<00:52,  1.23it/s]Loading train:  78%|███████▊  | 222/285 [03:12<00:53,  1.18it/s]Loading train:  78%|███████▊  | 223/285 [03:13<00:51,  1.21it/s]Loading train:  79%|███████▊  | 224/285 [03:14<00:50,  1.20it/s]Loading train:  79%|███████▉  | 225/285 [03:14<00:48,  1.23it/s]Loading train:  79%|███████▉  | 226/285 [03:15<00:50,  1.17it/s]Loading train:  80%|███████▉  | 227/285 [03:16<00:50,  1.14it/s]Loading train:  80%|████████  | 228/285 [03:17<00:52,  1.09it/s]Loading train:  80%|████████  | 229/285 [03:18<00:51,  1.08it/s]Loading train:  81%|████████  | 230/285 [03:19<00:47,  1.17it/s]Loading train:  81%|████████  | 231/285 [03:20<00:46,  1.17it/s]Loading train:  81%|████████▏ | 232/285 [03:20<00:42,  1.24it/s]Loading train:  82%|████████▏ | 233/285 [03:21<00:40,  1.27it/s]Loading train:  82%|████████▏ | 234/285 [03:22<00:40,  1.26it/s]Loading train:  82%|████████▏ | 235/285 [03:23<00:40,  1.24it/s]Loading train:  83%|████████▎ | 236/285 [03:24<00:39,  1.23it/s]Loading train:  83%|████████▎ | 237/285 [03:25<00:39,  1.22it/s]Loading train:  84%|████████▎ | 238/285 [03:26<00:40,  1.16it/s]Loading train:  84%|████████▍ | 239/285 [03:26<00:40,  1.12it/s]Loading train:  84%|████████▍ | 240/285 [03:27<00:39,  1.13it/s]Loading train:  85%|████████▍ | 241/285 [03:28<00:35,  1.23it/s]Loading train:  85%|████████▍ | 242/285 [03:29<00:36,  1.18it/s]Loading train:  85%|████████▌ | 243/285 [03:30<00:33,  1.26it/s]Loading train:  86%|████████▌ | 244/285 [03:31<00:36,  1.11it/s]Loading train:  86%|████████▌ | 245/285 [03:31<00:33,  1.20it/s]Loading train:  86%|████████▋ | 246/285 [03:32<00:33,  1.17it/s]Loading train:  87%|████████▋ | 247/285 [03:33<00:34,  1.12it/s]Loading train:  87%|████████▋ | 248/285 [03:34<00:33,  1.10it/s]Loading train:  87%|████████▋ | 249/285 [03:35<00:31,  1.15it/s]Loading train:  88%|████████▊ | 250/285 [03:36<00:30,  1.16it/s]Loading train:  88%|████████▊ | 251/285 [03:37<00:27,  1.22it/s]Loading train:  88%|████████▊ | 252/285 [03:37<00:27,  1.21it/s]Loading train:  89%|████████▉ | 253/285 [03:38<00:27,  1.18it/s]Loading train:  89%|████████▉ | 254/285 [03:39<00:27,  1.15it/s]Loading train:  89%|████████▉ | 255/285 [03:40<00:24,  1.21it/s]Loading train:  90%|████████▉ | 256/285 [03:41<00:25,  1.15it/s]Loading train:  90%|█████████ | 257/285 [03:42<00:23,  1.19it/s]Loading train:  91%|█████████ | 258/285 [03:43<00:25,  1.08it/s]Loading train:  91%|█████████ | 259/285 [03:44<00:23,  1.09it/s]Loading train:  91%|█████████ | 260/285 [03:45<00:22,  1.09it/s]Loading train:  92%|█████████▏| 261/285 [03:45<00:21,  1.14it/s]Loading train:  92%|█████████▏| 262/285 [03:46<00:19,  1.16it/s]Loading train:  92%|█████████▏| 263/285 [03:47<00:18,  1.20it/s]Loading train:  93%|█████████▎| 264/285 [03:48<00:17,  1.18it/s]Loading train:  93%|█████████▎| 265/285 [03:49<00:17,  1.14it/s]Loading train:  93%|█████████▎| 266/285 [03:50<00:15,  1.20it/s]Loading train:  94%|█████████▎| 267/285 [03:50<00:14,  1.23it/s]Loading train:  94%|█████████▍| 268/285 [03:51<00:14,  1.17it/s]Loading train:  94%|█████████▍| 269/285 [03:52<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [03:53<00:12,  1.20it/s]Loading train:  95%|█████████▌| 271/285 [03:54<00:11,  1.26it/s]Loading train:  95%|█████████▌| 272/285 [03:55<00:11,  1.18it/s]Loading train:  96%|█████████▌| 273/285 [03:55<00:09,  1.20it/s]Loading train:  96%|█████████▌| 274/285 [03:56<00:08,  1.23it/s]Loading train:  96%|█████████▋| 275/285 [03:57<00:08,  1.19it/s]Loading train:  97%|█████████▋| 276/285 [03:58<00:08,  1.12it/s]Loading train:  97%|█████████▋| 277/285 [03:59<00:06,  1.15it/s]Loading train:  98%|█████████▊| 278/285 [04:00<00:05,  1.19it/s]Loading train:  98%|█████████▊| 279/285 [04:01<00:05,  1.18it/s]Loading train:  98%|█████████▊| 280/285 [04:01<00:04,  1.23it/s]Loading train:  99%|█████████▊| 281/285 [04:02<00:03,  1.22it/s]Loading train:  99%|█████████▉| 282/285 [04:03<00:02,  1.24it/s]Loading train:  99%|█████████▉| 283/285 [04:04<00:01,  1.23it/s]Loading train: 100%|█████████▉| 284/285 [04:05<00:00,  1.20it/s]Loading train: 100%|██████████| 285/285 [04:05<00:00,  1.19it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:00, 260.00it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:01, 228.89it/s]concatenating: train:  24%|██▍       | 68/285 [00:00<00:00, 221.20it/s]concatenating: train:  36%|███▌      | 103/285 [00:00<00:00, 244.18it/s]concatenating: train:  47%|████▋     | 133/285 [00:00<00:00, 258.07it/s]concatenating: train:  55%|█████▌    | 158/285 [00:00<00:00, 255.59it/s]concatenating: train:  67%|██████▋   | 190/285 [00:00<00:00, 271.93it/s]concatenating: train:  79%|███████▊  | 224/285 [00:00<00:00, 288.07it/s]concatenating: train:  90%|█████████ | 257/285 [00:00<00:00, 297.77it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 283.70it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.23s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.20s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 832.31it/s]2019-07-11 08:59:50.401512: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 08:59:50.401617: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 08:59:50.401634: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 08:59:50.401644: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 08:59:50.402015: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  3.91it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.74it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.60it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.91it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.44it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.32it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.64it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.28it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.56it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.75it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.13it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.47it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.56it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.09it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  8.14it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.41it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.71it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.31it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 10)   100         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 10)   40          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 10)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 10)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 10)   910         dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 10)   40          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 10)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 10)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 11)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   2000        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 10)   5410        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 10)   40          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 10)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 10)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 10)   910         dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 52, 10)   40          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 52, 10)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 80, 52, 10)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 70)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 52, 13)   923         concatenate_8[0][0]              
==================================================================================================
Total params: 233,253
Trainable params: 58,493
Non-trainable params: 174,760
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 18s - loss: 2.5880 - acc: 0.6710 - mDice: 0.1162 - val_loss: 2.9982 - val_acc: 0.8791 - val_mDice: 0.1273

Epoch 00001: val_mDice improved from -inf to 0.12727, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.9391 - acc: 0.8905 - mDice: 0.3806 - val_loss: 3.1788 - val_acc: 0.8982 - val_mDice: 0.1847

Epoch 00002: val_mDice improved from 0.12727 to 0.18467, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6874 - acc: 0.9067 - mDice: 0.4876 - val_loss: 1.2612 - val_acc: 0.9230 - val_mDice: 0.3736

Epoch 00003: val_mDice improved from 0.18467 to 0.37363, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5754 - acc: 0.9200 - mDice: 0.5477 - val_loss: 1.0892 - val_acc: 0.9299 - val_mDice: 0.4252

Epoch 00004: val_mDice improved from 0.37363 to 0.42524, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.5164 - acc: 0.9273 - mDice: 0.5818 - val_loss: 0.8763 - val_acc: 0.9365 - val_mDice: 0.5353

Epoch 00005: val_mDice improved from 0.42524 to 0.53533, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4826 - acc: 0.9311 - mDice: 0.6027 - val_loss: 0.8561 - val_acc: 0.9354 - val_mDice: 0.5462

Epoch 00006: val_mDice improved from 0.53533 to 0.54615, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 12s - loss: 0.4589 - acc: 0.9334 - mDice: 0.6176 - val_loss: 0.8757 - val_acc: 0.9375 - val_mDice: 0.5430

Epoch 00007: val_mDice did not improve from 0.54615
Epoch 8/300
 - 11s - loss: 0.4373 - acc: 0.9351 - mDice: 0.6311 - val_loss: 0.8395 - val_acc: 0.9396 - val_mDice: 0.5565

Epoch 00008: val_mDice improved from 0.54615 to 0.55647, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4224 - acc: 0.9365 - mDice: 0.6409 - val_loss: 0.8647 - val_acc: 0.9388 - val_mDice: 0.5476

Epoch 00009: val_mDice did not improve from 0.55647
Epoch 10/300
 - 12s - loss: 0.4127 - acc: 0.9375 - mDice: 0.6475 - val_loss: 0.8395 - val_acc: 0.9372 - val_mDice: 0.5607

Epoch 00010: val_mDice improved from 0.55647 to 0.56071, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 12s - loss: 0.4015 - acc: 0.9384 - mDice: 0.6548 - val_loss: 0.8390 - val_acc: 0.9415 - val_mDice: 0.5611

Epoch 00011: val_mDice improved from 0.56071 to 0.56107, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 12s - loss: 0.3955 - acc: 0.9389 - mDice: 0.6589 - val_loss: 0.8305 - val_acc: 0.9393 - val_mDice: 0.5662

Epoch 00012: val_mDice improved from 0.56107 to 0.56622, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 12s - loss: 0.3843 - acc: 0.9398 - mDice: 0.6664 - val_loss: 0.8306 - val_acc: 0.9390 - val_mDice: 0.5574

Epoch 00013: val_mDice did not improve from 0.56622
Epoch 14/300
 - 11s - loss: 0.3791 - acc: 0.9403 - mDice: 0.6701 - val_loss: 0.7884 - val_acc: 0.9405 - val_mDice: 0.5698

Epoch 00014: val_mDice improved from 0.56622 to 0.56979, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 15/300
 - 12s - loss: 0.3739 - acc: 0.9407 - mDice: 0.6736 - val_loss: 0.8129 - val_acc: 0.9343 - val_mDice: 0.5527

Epoch 00015: val_mDice did not improve from 0.56979
Epoch 16/300
 - 12s - loss: 0.3672 - acc: 0.9412 - mDice: 0.6781 - val_loss: 0.7910 - val_acc: 0.9389 - val_mDice: 0.5635

Epoch 00016: val_mDice did not improve from 0.56979
Epoch 17/300
 - 12s - loss: 0.3638 - acc: 0.9415 - mDice: 0.6807 - val_loss: 0.7671 - val_acc: 0.9395 - val_mDice: 0.5783

Epoch 00017: val_mDice improved from 0.56979 to 0.57828, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 12s - loss: 0.3552 - acc: 0.9421 - mDice: 0.6865 - val_loss: 0.8005 - val_acc: 0.9438 - val_mDice: 0.5737

Epoch 00018: val_mDice did not improve from 0.57828
Epoch 19/300
 - 12s - loss: 0.3547 - acc: 0.9422 - mDice: 0.6870 - val_loss: 0.7766 - val_acc: 0.9393 - val_mDice: 0.5789

Epoch 00019: val_mDice improved from 0.57828 to 0.57893, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 12s - loss: 0.3485 - acc: 0.9427 - mDice: 0.6914 - val_loss: 0.7668 - val_acc: 0.9410 - val_mDice: 0.5729

Epoch 00020: val_mDice did not improve from 0.57893
Epoch 21/300
 - 12s - loss: 0.3461 - acc: 0.9428 - mDice: 0.6931 - val_loss: 0.7841 - val_acc: 0.9430 - val_mDice: 0.5701

Epoch 00021: val_mDice did not improve from 0.57893
Epoch 22/300
 - 11s - loss: 0.3418 - acc: 0.9431 - mDice: 0.6960 - val_loss: 0.7471 - val_acc: 0.9384 - val_mDice: 0.5822

Epoch 00022: val_mDice improved from 0.57893 to 0.58220, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 12s - loss: 0.3395 - acc: 0.9433 - mDice: 0.6978 - val_loss: 0.7756 - val_acc: 0.9386 - val_mDice: 0.5806

Epoch 00023: val_mDice did not improve from 0.58220
Epoch 24/300
 - 12s - loss: 0.3362 - acc: 0.9436 - mDice: 0.7002 - val_loss: 0.7601 - val_acc: 0.9369 - val_mDice: 0.5782

Epoch 00024: val_mDice did not improve from 0.58220
Epoch 25/300
 - 12s - loss: 0.3344 - acc: 0.9437 - mDice: 0.7015 - val_loss: 0.7452 - val_acc: 0.9424 - val_mDice: 0.5815

Epoch 00025: val_mDice did not improve from 0.58220
Epoch 26/300
 - 12s - loss: 0.3305 - acc: 0.9440 - mDice: 0.7043 - val_loss: 0.7635 - val_acc: 0.9396 - val_mDice: 0.5810

Epoch 00026: val_mDice did not improve from 0.58220
Epoch 27/300
 - 11s - loss: 0.3285 - acc: 0.9442 - mDice: 0.7058 - val_loss: 0.7711 - val_acc: 0.9343 - val_mDice: 0.5670

Epoch 00027: val_mDice did not improve from 0.58220
Epoch 28/300
 - 12s - loss: 0.3258 - acc: 0.9443 - mDice: 0.7077 - val_loss: 0.7757 - val_acc: 0.9403 - val_mDice: 0.5796

Epoch 00028: val_mDice did not improve from 0.58220
Epoch 29/300
 - 11s - loss: 0.3239 - acc: 0.9445 - mDice: 0.7090 - val_loss: 0.7442 - val_acc: 0.9400 - val_mDice: 0.5828

Epoch 00029: val_mDice improved from 0.58220 to 0.58282, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 30/300
 - 12s - loss: 0.3201 - acc: 0.9448 - mDice: 0.7119 - val_loss: 0.7247 - val_acc: 0.9353 - val_mDice: 0.5785

Epoch 00030: val_mDice did not improve from 0.58282
Epoch 31/300
 - 12s - loss: 0.3178 - acc: 0.9451 - mDice: 0.7136 - val_loss: 0.7273 - val_acc: 0.9384 - val_mDice: 0.5751

Epoch 00031: val_mDice did not improve from 0.58282
Epoch 32/300
 - 11s - loss: 0.3179 - acc: 0.9451 - mDice: 0.7136 - val_loss: 0.7793 - val_acc: 0.9415 - val_mDice: 0.5763

Epoch 00032: val_mDice did not improve from 0.58282
Epoch 33/300
 - 12s - loss: 0.3152 - acc: 0.9452 - mDice: 0.7155 - val_loss: 0.7531 - val_acc: 0.9394 - val_mDice: 0.5763

Epoch 00033: val_mDice did not improve from 0.58282
Epoch 34/300
 - 12s - loss: 0.3120 - acc: 0.9456 - mDice: 0.7180 - val_loss: 0.7456 - val_acc: 0.9390 - val_mDice: 0.5825

Epoch 00034: val_mDice did not improve from 0.58282
Epoch 35/300
 - 11s - loss: 0.3113 - acc: 0.9457 - mDice: 0.7185 - val_loss: 0.7488 - val_acc: 0.9402 - val_mDice: 0.5779

Epoch 00035: val_mDice did not improve from 0.58282
Epoch 36/300
 - 11s - loss: 0.3097 - acc: 0.9456 - mDice: 0.7197 - val_loss: 0.7333 - val_acc: 0.9395 - val_mDice: 0.5752

Epoch 00036: val_mDice did not improve from 0.58282
Epoch 37/300
 - 11s - loss: 0.3072 - acc: 0.9459 - mDice: 0.7215 - val_loss: 0.7751 - val_acc: 0.9384 - val_mDice: 0.5746

Epoch 00037: val_mDice did not improve from 0.58282
Epoch 38/300
 - 12s - loss: 0.3073 - acc: 0.9459 - mDice: 0.7214 - val_loss: 0.7839 - val_acc: 0.9422 - val_mDice: 0.5673

Epoch 00038: val_mDice did not improve from 0.58282
Epoch 39/300
 - 12s - loss: 0.3056 - acc: 0.9460 - mDice: 0.7227 - val_loss: 0.7022 - val_acc: 0.9384 - val_mDice: 0.5807

Epoch 00039: val_mDice did not improve from 0.58282
Epoch 40/300
 - 11s - loss: 0.3040 - acc: 0.9462 - mDice: 0.7239 - val_loss: 0.7676 - val_acc: 0.9400 - val_mDice: 0.5743

Epoch 00040: val_mDice did not improve from 0.58282
Epoch 41/300
 - 11s - loss: 0.3022 - acc: 0.9461 - mDice: 0.7252 - val_loss: 0.7642 - val_acc: 0.9405 - val_mDice: 0.5766

Epoch 00041: val_mDice did not improve from 0.58282
Epoch 42/300
 - 11s - loss: 0.3011 - acc: 0.9463 - mDice: 0.7261 - val_loss: 0.7416 - val_acc: 0.9411 - val_mDice: 0.5744

Epoch 00042: val_mDice did not improve from 0.58282
Epoch 43/300
 - 11s - loss: 0.2992 - acc: 0.9464 - mDice: 0.7275 - val_loss: 0.7270 - val_acc: 0.9397 - val_mDice: 0.5798

Epoch 00043: val_mDice did not improve from 0.58282
Epoch 44/300
 - 12s - loss: 0.2998 - acc: 0.9464 - mDice: 0.7271 - val_loss: 0.7403 - val_acc: 0.9395 - val_mDice: 0.5841

Epoch 00044: val_mDice improved from 0.58282 to 0.58409, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM10_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 12s - loss: 0.2994 - acc: 0.9465 - mDice: 0.7275 - val_loss: 0.7338 - val_acc: 0.9397 - val_mDice: 0.5754

Epoch 00045: val_mDice did not improve from 0.58409
Epoch 46/300
 - 11s - loss: 0.2977 - acc: 0.9466 - mDice: 0.7287 - val_loss: 0.7529 - val_acc: 0.9388 - val_mDice: 0.5719

Epoch 00046: val_mDice did not improve from 0.58409
Epoch 47/300
 - 11s - loss: 0.2941 - acc: 0.9469 - mDice: 0.7314 - val_loss: 0.7522 - val_acc: 0.9391 - val_mDice: 0.5702

Epoch 00047: val_mDice did not improve from 0.58409
Epoch 48/300
 - 11s - loss: 0.2925 - acc: 0.9469 - mDice: 0.7326 - val_loss: 0.7357 - val_acc: 0.9402 - val_mDice: 0.5740

Epoch 00048: val_mDice did not improve from 0.58409
Epoch 49/300
 - 11s - loss: 0.2936 - acc: 0.9468 - mDice: 0.7318 - val_loss: 0.7297 - val_acc: 0.9405 - val_mDice: 0.5800

Epoch 00049: val_mDice did not improve from 0.58409
Epoch 50/300
 - 11s - loss: 0.2932 - acc: 0.9469 - mDice: 0.7321 - val_loss: 0.7592 - val_acc: 0.9344 - val_mDice: 0.5592

Epoch 00050: val_mDice did not improve from 0.58409
Epoch 51/300
 - 11s - loss: 0.2931 - acc: 0.9470 - mDice: 0.7321 - val_loss: 0.7290 - val_acc: 0.9399 - val_mDice: 0.5772

Epoch 00051: val_mDice did not improve from 0.58409
Epoch 52/300
 - 12s - loss: 0.2901 - acc: 0.9470 - mDice: 0.7345 - val_loss: 0.7264 - val_acc: 0.9404 - val_mDice: 0.5797

Epoch 00052: val_mDice did not improve from 0.58409
Epoch 53/300
 - 11s - loss: 0.2895 - acc: 0.9471 - mDice: 0.7349 - val_loss: 0.7492 - val_acc: 0.9357 - val_mDice: 0.5726

Epoch 00053: val_mDice did not improve from 0.58409
Epoch 54/300
 - 11s - loss: 0.2887 - acc: 0.9473 - mDice: 0.7355 - val_loss: 0.7330 - val_acc: 0.9372 - val_mDice: 0.5807

Epoch 00054: val_mDice did not improve from 0.58409
Epoch 55/300
 - 11s - loss: 0.2876 - acc: 0.9473 - mDice: 0.7364 - val_loss: 0.7148 - val_acc: 0.9401 - val_mDice: 0.5828

Epoch 00055: val_mDice did not improve from 0.58409
Epoch 56/300
 - 11s - loss: 0.2863 - acc: 0.9474 - mDice: 0.7373 - val_loss: 0.7153 - val_acc: 0.9402 - val_mDice: 0.5726

Epoch 00056: val_mDice did not improve from 0.58409
Epoch 57/300
 - 11s - loss: 0.2859 - acc: 0.9474 - mDice: 0.7378 - val_loss: 0.7207 - val_acc: 0.9405 - val_mDice: 0.5781

Epoch 00057: val_mDice did not improve from 0.58409
Epoch 58/300
 - 11s - loss: 0.2867 - acc: 0.9473 - mDice: 0.7370 - val_loss: 0.7072 - val_acc: 0.9398 - val_mDice: 0.5735

Epoch 00058: val_mDice did not improve from 0.58409
Epoch 59/300
 - 11s - loss: 0.2849 - acc: 0.9474 - mDice: 0.7384 - val_loss: 0.7142 - val_acc: 0.9354 - val_mDice: 0.5711

Epoch 00059: val_mDice did not improve from 0.58409
Epoch 60/300
 - 11s - loss: 0.2838 - acc: 0.9477 - mDice: 0.7392 - val_loss: 0.7215 - val_acc: 0.9424 - val_mDice: 0.5741

Epoch 00060: val_mDice did not improve from 0.58409
Epoch 61/300
 - 12s - loss: 0.2833 - acc: 0.9476 - mDice: 0.7397 - val_loss: 0.7186 - val_acc: 0.9395 - val_mDice: 0.5734

Epoch 00061: val_mDice did not improve from 0.58409
Epoch 62/300
 - 11s - loss: 0.2811 - acc: 0.9478 - mDice: 0.7413 - val_loss: 0.7108 - val_acc: 0.9398 - val_mDice: 0.5692

Epoch 00062: val_mDice did not improve from 0.58409
Epoch 63/300
 - 11s - loss: 0.2826 - acc: 0.9475 - mDice: 0.7402 - val_loss: 0.6881 - val_acc: 0.9383 - val_mDice: 0.5763

Epoch 00063: val_mDice did not improve from 0.58409
Epoch 64/300
 - 11s - loss: 0.2798 - acc: 0.9480 - mDice: 0.7424 - val_loss: 0.6972 - val_acc: 0.9368 - val_mDice: 0.5757

Epoch 00064: val_mDice did not improve from 0.58409
Epoch 65/300
 - 11s - loss: 0.2795 - acc: 0.9479 - mDice: 0.7426 - val_loss: 0.7190 - val_acc: 0.9394 - val_mDice: 0.5755

Epoch 00065: val_mDice did not improve from 0.58409
Epoch 66/300
 - 11s - loss: 0.2779 - acc: 0.9480 - mDice: 0.7438 - val_loss: 0.7161 - val_acc: 0.9405 - val_mDice: 0.5657

Epoch 00066: val_mDice did not improve from 0.58409
Epoch 67/300
 - 11s - loss: 0.2769 - acc: 0.9482 - mDice: 0.7446 - val_loss: 0.7081 - val_acc: 0.9380 - val_mDice: 0.5658

Epoch 00067: val_mDice did not improve from 0.58409
Epoch 68/300
 - 12s - loss: 0.2770 - acc: 0.9479 - mDice: 0.7445 - val_loss: 0.6651 - val_acc: 0.9395 - val_mDice: 0.5754

Epoch 00068: val_mDice did not improve from 0.58409
Epoch 69/300
 - 12s - loss: 0.2760 - acc: 0.9482 - mDice: 0.7453 - val_loss: 0.7091 - val_acc: 0.9393 - val_mDice: 0.5673

Epoch 00069: val_mDice did not improve from 0.58409
Epoch 70/300
 - 12s - loss: 0.2754 - acc: 0.9481 - mDice: 0.7457 - val_loss: 0.6712 - val_acc: 0.9397 - val_mDice: 0.5803

Epoch 00070: val_mDice did not improve from 0.58409
Epoch 71/300
 - 12s - loss: 0.2750 - acc: 0.9482 - mDice: 0.7461 - val_loss: 0.7097 - val_acc: 0.9378 - val_mDice: 0.5755

Epoch 00071: val_mDice did not improve from 0.58409
Epoch 72/300
 - 12s - loss: 0.2761 - acc: 0.9481 - mDice: 0.7453 - val_loss: 0.6837 - val_acc: 0.9390 - val_mDice: 0.5734

Epoch 00072: val_mDice did not improve from 0.58409
Epoch 73/300
 - 12s - loss: 0.2733 - acc: 0.9483 - mDice: 0.7473 - val_loss: 0.6959 - val_acc: 0.9381 - val_mDice: 0.5662

Epoch 00073: val_mDice did not improve from 0.58409
Epoch 74/300
 - 12s - loss: 0.2741 - acc: 0.9482 - mDice: 0.7467 - val_loss: 0.7139 - val_acc: 0.9390 - val_mDice: 0.5627

Epoch 00074: val_mDice did not improve from 0.58409
Epoch 75/300
 - 12s - loss: 0.2731 - acc: 0.9483 - mDice: 0.7475 - val_loss: 0.6982 - val_acc: 0.9398 - val_mDice: 0.5659

Epoch 00075: val_mDice did not improve from 0.58409
Epoch 76/300
 - 12s - loss: 0.2709 - acc: 0.9485 - mDice: 0.7493 - val_loss: 0.6946 - val_acc: 0.9410 - val_mDice: 0.5677

Epoch 00076: val_mDice did not improve from 0.58409
Epoch 77/300
 - 11s - loss: 0.2722 - acc: 0.9486 - mDice: 0.7484 - val_loss: 0.7066 - val_acc: 0.9393 - val_mDice: 0.5621

Epoch 00077: val_mDice did not improve from 0.58409
Epoch 78/300
 - 12s - loss: 0.2713 - acc: 0.9486 - mDice: 0.7489 - val_loss: 0.6644 - val_acc: 0.9382 - val_mDice: 0.5745

Epoch 00078: val_mDice did not improve from 0.58409
Epoch 79/300
 - 12s - loss: 0.2707 - acc: 0.9486 - mDice: 0.7494 - val_loss: 0.6561 - val_acc: 0.9397 - val_mDice: 0.5760

Epoch 00079: val_mDice did not improve from 0.58409
Epoch 80/300
 - 11s - loss: 0.2712 - acc: 0.9485 - mDice: 0.7491 - val_loss: 0.6890 - val_acc: 0.9386 - val_mDice: 0.5624

Epoch 00080: val_mDice did not improve from 0.58409
Epoch 81/300
 - 11s - loss: 0.2703 - acc: 0.9486 - mDice: 0.7497 - val_loss: 0.6953 - val_acc: 0.9342 - val_mDice: 0.5715

Epoch 00081: val_mDice did not improve from 0.58409
Epoch 82/300
 - 11s - loss: 0.2692 - acc: 0.9487 - mDice: 0.7506 - val_loss: 0.6800 - val_acc: 0.9393 - val_mDice: 0.5733

Epoch 00082: val_mDice did not improve from 0.58409
Epoch 83/300
 - 11s - loss: 0.2683 - acc: 0.9487 - mDice: 0.7513 - val_loss: 0.6592 - val_acc: 0.9403 - val_mDice: 0.5788

Epoch 00083: val_mDice did not improve from 0.58409
Epoch 84/300
 - 12s - loss: 0.2674 - acc: 0.9488 - mDice: 0.7519 - val_loss: 0.6744 - val_acc: 0.9382 - val_mDice: 0.5680

Epoch 00084: val_mDice did not improve from 0.58409
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [2.99816541488354, 3.1788469094496508, 1.2612249071781452, 1.0892078211674323, 0.876346964102525, 0.8560833518321698, 0.875722383077328, 0.8394595407522641, 0.8647372057804694, 0.8394555426560916, 0.8389968390648181, 0.8305090665817261, 0.8306048948031205, 0.7884381551008958, 0.8128999242415795, 0.7910115925165323, 0.7670696274592326, 0.800469662134464, 0.7766133145644114, 0.7668411983893468, 0.7840902805328369, 0.7470569507433817, 0.7755848673673776, 0.7600660129235342, 0.7451688819206678, 0.763504737844834, 0.7710832930528201, 0.7756932584139017, 0.7442395446392206, 0.7246789806164228, 0.7272879550090203, 0.7793426387585126, 0.7530966229163684, 0.7455801803332108, 0.7488293728003135, 0.7332599438153781, 0.7751188599146329, 0.7839340430039626, 0.7021773549226614, 0.7675562592653128, 0.7641701469054589, 0.7416006831022409, 0.7269647660163733, 0.7402909810726459, 0.733771379177387, 0.752910675910803, 0.7521548569202423, 0.7356771093148452, 0.7297339015282117, 0.7591790648607107, 0.7289953759083381, 0.7264169271175678, 0.7491881205485418, 0.7330380861575787, 0.7147702127695084, 0.7153069101847135, 0.7207221927551123, 0.7072222943489368, 0.7141846326681284, 0.7214871209401351, 0.7185514408808488, 0.7108133618648236, 0.6881155921862676, 0.6972408248828008, 0.7189649870762458, 0.7160929051729349, 0.7081341674694648, 0.6650551282442533, 0.7091044095846323, 0.6712372910517913, 0.7097246463482196, 0.6837079226970673, 0.6959170676194705, 0.713899525312277, 0.6981532206902137, 0.6946343962962811, 0.7066156543218173, 0.6644409619844877, 0.6561437478432288, 0.6889631954523233, 0.6952594381112319, 0.6800283697935251, 0.6592327872147927, 0.6744488638180953], 'val_acc': [0.8791443040737739, 0.8982433264072125, 0.9229613267458402, 0.9299140297449552, 0.9365246089605185, 0.9354474613299737, 0.9375208134834583, 0.9395987230997819, 0.9388082531782297, 0.9372272766553439, 0.941452464232078, 0.9393305961902325, 0.9390046986249777, 0.9405163893332849, 0.9342779356699723, 0.9388637290551112, 0.9394508210512308, 0.9438170171700991, 0.9393121279202975, 0.9409832404210017, 0.9430403824035938, 0.9383829442354349, 0.9386094441780677, 0.9369036417741042, 0.942381677719263, 0.9396310884218949, 0.9343056449523339, 0.9403176101354452, 0.9400448248936579, 0.935257952946883, 0.9384360909461975, 0.9414663200195019, 0.9393907372768109, 0.9390139671472403, 0.9401881603094248, 0.9395455786815057, 0.9383713671794305, 0.9421875155889071, 0.9384152866326846, 0.9399870336055756, 0.9404747577813956, 0.941142744742907, 0.9396726970489209, 0.9394924319707431, 0.9397119788023142, 0.938766612456395, 0.939076345700484, 0.9401742540873014, 0.9404793817263383, 0.9343911982499636, 0.9399408033260932, 0.9403591752052307, 0.9357317754855523, 0.9372064746343173, 0.9401395962788508, 0.9401835478269137, 0.9405394838406489, 0.9398137170534867, 0.9354035693865556, 0.9423839426957644, 0.9395063038055713, 0.9398367978059329, 0.9382928059651301, 0.9368297090897193, 0.93944618335137, 0.940514073922084, 0.9380316207042108, 0.9394507866639358, 0.9393237049763019, 0.9397119925572321, 0.9378444025149713, 0.939044001010748, 0.9381217406346247, 0.9390440101806934, 0.9397651621928582, 0.9409532455297617, 0.939321355177806, 0.938223462838393, 0.9397143079684331, 0.9385794080220736, 0.9341993354834043, 0.9393352270126343, 0.9403430040066059, 0.9381564465852884], 'val_mDice': [0.12726896686049607, 0.18466979866990677, 0.3736316063083135, 0.4252429954134501, 0.5353313982486725, 0.5461526530293318, 0.5430314724261944, 0.5564733674893012, 0.5476179014031703, 0.5607111923969709, 0.561073610988947, 0.5662232706179986, 0.5574406024355155, 0.5697949253595792, 0.5527260527014732, 0.5634786801842543, 0.5782775340171961, 0.5736918254540517, 0.5789289245238671, 0.5728962192168603, 0.5700946404383733, 0.5821982054756238, 0.580614182811517, 0.5781689240382268, 0.5814975053071976, 0.5809942082716868, 0.5669887845332806, 0.5795686783698889, 0.5828238321611514, 0.5785018944969544, 0.5750812507019594, 0.5762739124206396, 0.576308933015053, 0.5825229757107221, 0.5778893839854461, 0.5751958899199963, 0.5745665448216292, 0.5673004285647318, 0.5806790942756029, 0.5742796828540472, 0.5765642403410032, 0.5744040069671777, 0.5797981447898425, 0.5840880088508129, 0.5754485863905686, 0.5719401377897996, 0.570194294819465, 0.5739972814917564, 0.5799596504523203, 0.5592139145502677, 0.5771507574961736, 0.579692331644205, 0.5725799684341137, 0.5806589877376189, 0.5828359215878524, 0.5725652363437873, 0.5781436032400682, 0.573512573654835, 0.5710997650256524, 0.5741050335077139, 0.5733584956480906, 0.5692142053292348, 0.5762954428792, 0.5757339808803338, 0.5754802702711179, 0.5657460858615545, 0.5658114346174093, 0.5754133288103801, 0.5672710658265994, 0.5802706766587037, 0.5754805872073541, 0.5734265810595109, 0.5662134943100122, 0.5627002793435867, 0.5659106408174222, 0.5676624368016536, 0.5620642771514562, 0.5744860304089693, 0.5760013868029301, 0.5623997048689768, 0.5715096357923287, 0.5733246533916547, 0.5788177432349095, 0.5679908423469617], 'loss': [2.5879777439689655, 0.939064434200682, 0.687423111981685, 0.5753929193506027, 0.5164369238425607, 0.482615738889998, 0.4589053707639307, 0.43733277126980435, 0.4224075165872786, 0.41267720208686515, 0.40154291994345426, 0.3954570216632556, 0.38428437419288614, 0.3791347600916133, 0.37393598999636735, 0.3671735360301817, 0.3637517921919974, 0.35517857185613294, 0.3547278419995917, 0.3484543052989927, 0.34611620475783467, 0.3418172433028238, 0.33948193181982605, 0.3362315726612235, 0.33443923837791384, 0.3305368110294284, 0.32849451375658484, 0.32579777755113276, 0.3239451822628342, 0.3200550006207291, 0.31784451388514573, 0.31786178298281487, 0.3152407156160086, 0.3119955098514659, 0.31132260251889576, 0.30971272202212247, 0.307201624232707, 0.30726263333563103, 0.30557153772287543, 0.3040071090742263, 0.30221092751256373, 0.301118437551566, 0.2992155912572647, 0.29984487287674755, 0.29937334890120654, 0.29773760700834906, 0.29406246547603104, 0.2925420745700133, 0.2935501646453534, 0.29317437755350234, 0.2930986873725128, 0.2900772123173859, 0.28954100005797967, 0.28869989703174975, 0.2875962883005896, 0.28631814339938644, 0.2858689904878096, 0.28670289771127866, 0.2849359251246135, 0.28382527192206464, 0.2832658474849707, 0.2811348355257301, 0.28257246866972036, 0.2798232010020372, 0.27949000288285114, 0.27785363863185797, 0.2768681637037837, 0.27702824370256157, 0.2760257393377333, 0.2754301302032608, 0.27497566106364946, 0.2761342819657458, 0.27332298866466526, 0.2741322127186064, 0.27311923305734126, 0.27088415388261483, 0.27215651576175776, 0.2713492715819388, 0.2707123129523725, 0.27123422126515834, 0.27031968068529033, 0.2691851274109432, 0.2683231626793345, 0.26744343943562027], 'acc': [0.671036436360865, 0.8904882137992884, 0.9067453338817775, 0.9200024930663206, 0.9273421478141753, 0.9311253413067393, 0.9334487115821198, 0.9351193866562186, 0.9364646589482258, 0.9375417472844985, 0.9384475713735752, 0.9389362779532611, 0.9398031946061052, 0.9403459774131849, 0.9406594952775754, 0.9412119380884435, 0.9414556030691478, 0.9421312901066269, 0.942161973465152, 0.9426599212604443, 0.9427530573850891, 0.9430901435296012, 0.9432597208163797, 0.9436037685503261, 0.9437339952771958, 0.9439610536606629, 0.9442373103874697, 0.9443177175150249, 0.9445392391915406, 0.9448373952024506, 0.9450780453084305, 0.9450612649050826, 0.9452235012446714, 0.9455568167783562, 0.9456652716320291, 0.9456353495561427, 0.945851383795875, 0.9458592571445269, 0.9460046004239763, 0.9461720012919242, 0.9461232990694367, 0.9463249276586535, 0.946409461903504, 0.9463509340122662, 0.946503616633763, 0.9466084564819466, 0.9469118709495166, 0.9468837992287228, 0.9468476421485844, 0.9468508334185357, 0.9469688677935102, 0.9470234692706884, 0.9471098414252828, 0.9472698844095927, 0.9472567145426225, 0.947396427731029, 0.9473676757872748, 0.9472760033598687, 0.9474083777284485, 0.9476819056531418, 0.9476172133234388, 0.947775105422772, 0.9475301775964855, 0.9479884664961566, 0.9479148634946908, 0.9480403675140737, 0.9481894550239491, 0.9479352820296685, 0.9481734711613964, 0.9481282906867389, 0.9481887921717052, 0.9480607825639139, 0.9482897088326048, 0.9481892547549813, 0.9483300729243395, 0.9485368089604221, 0.9485549859418801, 0.9486260635380286, 0.9485588210827198, 0.9485250584129081, 0.9485800604774955, 0.948695054531845, 0.9487067384274807, 0.9487820920398465], 'mDice': [0.11615068078752946, 0.38064343958645086, 0.4876483951032266, 0.5477198176714675, 0.5817530133963225, 0.6027238441219434, 0.617580493756637, 0.6310648082818293, 0.6409274686650466, 0.6474629531187687, 0.654794158134515, 0.6588711545089838, 0.6664433191263026, 0.6701376096223604, 0.673558115915191, 0.6781408158899244, 0.6806870796116892, 0.6865377888560328, 0.686962270565186, 0.6913835364305851, 0.6930516211735656, 0.6959899525179323, 0.6977913492139081, 0.7002129807008717, 0.7014959246197783, 0.7043084122867895, 0.7057598354927918, 0.7077292840847789, 0.7090459344550427, 0.711919354213886, 0.7135666744477919, 0.7136345060947119, 0.7155223634424854, 0.7179513728938551, 0.7185275441967208, 0.7197028345302232, 0.7214735694271518, 0.7214479050072953, 0.7227376376880026, 0.7239175831261216, 0.725249699117908, 0.726090234209666, 0.7275425223619045, 0.7271121469830759, 0.7275036499034784, 0.7287104340493652, 0.731433778608196, 0.7326042856181073, 0.7317901633107485, 0.7321303755025698, 0.7321171894357574, 0.7344528993128367, 0.7348849677153424, 0.7355306858804451, 0.7363798311580583, 0.7373092832968132, 0.7377501850164234, 0.737037605952592, 0.7384494408672392, 0.7392264440536147, 0.7397447302697011, 0.7413120286156636, 0.7402170130679454, 0.7423703556822464, 0.7426157997101531, 0.7438106145034645, 0.7445626633309971, 0.7444746545855656, 0.7453013281590009, 0.7457365182606396, 0.7460693457706448, 0.7452609975168892, 0.7473376082569253, 0.746715060972831, 0.7475143844083283, 0.7492984980550912, 0.7483774320639269, 0.7489027653762492, 0.7493893833581695, 0.7490920235527339, 0.7497213105813259, 0.7506162150642984, 0.7513165532866495, 0.7519057374054201]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.19s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:01,  1.95s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.75s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:18,  1.76s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:39,  1.62s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:36,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:06,  1.52s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:23,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:00,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:11,  1.55s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:06,  1.54s/it]predicting train subjects:   3%|▎         | 9/285 [00:13<07:23,  1.61s/it]predicting train subjects:   4%|▎         | 10/285 [00:15<07:36,  1.66s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:12,  1.58s/it]predicting train subjects:   4%|▍         | 12/285 [00:18<07:28,  1.64s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:11,  1.59s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:19,  1.62s/it]predicting train subjects:   5%|▌         | 15/285 [00:23<07:38,  1.70s/it]predicting train subjects:   6%|▌         | 16/285 [00:25<07:43,  1.72s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:21,  1.65s/it]predicting train subjects:   6%|▋         | 18/285 [00:28<07:21,  1.65s/it]predicting train subjects:   7%|▋         | 19/285 [00:30<07:03,  1.59s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:10,  1.63s/it]predicting train subjects:   7%|▋         | 21/285 [00:33<07:24,  1.68s/it]predicting train subjects:   8%|▊         | 22/285 [00:35<07:14,  1.65s/it]predicting train subjects:   8%|▊         | 23/285 [00:37<07:19,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:38<07:06,  1.63s/it]predicting train subjects:   9%|▉         | 25/285 [00:40<07:32,  1.74s/it]predicting train subjects:   9%|▉         | 26/285 [00:42<07:42,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:19,  1.70s/it]predicting train subjects:  10%|▉         | 28/285 [00:45<07:19,  1.71s/it]predicting train subjects:  10%|█         | 29/285 [00:47<07:20,  1.72s/it]predicting train subjects:  11%|█         | 30/285 [00:49<07:39,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:51<07:33,  1.79s/it]predicting train subjects:  11%|█         | 32/285 [00:52<07:10,  1.70s/it]predicting train subjects:  12%|█▏        | 33/285 [00:54<07:09,  1.70s/it]predicting train subjects:  12%|█▏        | 34/285 [00:56<07:11,  1.72s/it]predicting train subjects:  12%|█▏        | 35/285 [00:58<07:21,  1.77s/it]predicting train subjects:  13%|█▎        | 36/285 [00:59<07:04,  1.71s/it]predicting train subjects:  13%|█▎        | 37/285 [01:01<07:09,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:03<07:17,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:04<06:52,  1.68s/it]predicting train subjects:  14%|█▍        | 40/285 [01:06<06:55,  1.70s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:37,  1.63s/it]predicting train subjects:  15%|█▍        | 42/285 [01:09<06:26,  1.59s/it]predicting train subjects:  15%|█▌        | 43/285 [01:11<06:31,  1.62s/it]predicting train subjects:  15%|█▌        | 44/285 [01:13<06:46,  1.69s/it]predicting train subjects:  16%|█▌        | 45/285 [01:14<06:40,  1.67s/it]predicting train subjects:  16%|█▌        | 46/285 [01:16<06:48,  1.71s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:41,  1.69s/it]predicting train subjects:  17%|█▋        | 48/285 [01:19<06:46,  1.71s/it]predicting train subjects:  17%|█▋        | 49/285 [01:21<06:55,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:23<06:51,  1.75s/it]predicting train subjects:  18%|█▊        | 51/285 [01:25<07:02,  1.81s/it]predicting train subjects:  18%|█▊        | 52/285 [01:26<06:43,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:28<06:39,  1.72s/it]predicting train subjects:  19%|█▉        | 54/285 [01:30<06:49,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:33,  1.71s/it]predicting train subjects:  20%|█▉        | 56/285 [01:33<06:36,  1.73s/it]predicting train subjects:  20%|██        | 57/285 [01:35<06:21,  1.67s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:23,  1.69s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:36,  1.75s/it]predicting train subjects:  21%|██        | 60/285 [01:40<06:42,  1.79s/it]predicting train subjects:  21%|██▏       | 61/285 [01:42<06:21,  1.70s/it]predicting train subjects:  22%|██▏       | 62/285 [01:44<06:25,  1.73s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:24,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:47<06:22,  1.73s/it]predicting train subjects:  23%|██▎       | 65/285 [01:49<06:24,  1.75s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:17,  1.72s/it]predicting train subjects:  24%|██▎       | 67/285 [01:52<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:54<05:59,  1.66s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:02,  1.68s/it]predicting train subjects:  25%|██▍       | 70/285 [01:57<06:03,  1.69s/it]predicting train subjects:  25%|██▍       | 71/285 [01:59<06:04,  1.70s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:56,  1.67s/it]predicting train subjects:  26%|██▌       | 73/285 [02:02<05:58,  1.69s/it]predicting train subjects:  26%|██▌       | 74/285 [02:04<06:03,  1.72s/it]predicting train subjects:  26%|██▋       | 75/285 [02:06<06:01,  1.72s/it]predicting train subjects:  27%|██▋       | 76/285 [02:08<05:57,  1.71s/it]predicting train subjects:  27%|██▋       | 77/285 [02:09<05:43,  1.65s/it]predicting train subjects:  27%|██▋       | 78/285 [02:11<05:34,  1.62s/it]predicting train subjects:  28%|██▊       | 79/285 [02:12<05:40,  1.65s/it]predicting train subjects:  28%|██▊       | 80/285 [02:14<05:40,  1.66s/it]predicting train subjects:  28%|██▊       | 81/285 [02:16<05:29,  1.62s/it]predicting train subjects:  29%|██▉       | 82/285 [02:17<05:31,  1.63s/it]predicting train subjects:  29%|██▉       | 83/285 [02:19<05:24,  1.61s/it]predicting train subjects:  29%|██▉       | 84/285 [02:20<05:19,  1.59s/it]predicting train subjects:  30%|██▉       | 85/285 [02:22<05:23,  1.62s/it]predicting train subjects:  30%|███       | 86/285 [02:24<05:24,  1.63s/it]predicting train subjects:  31%|███       | 87/285 [02:25<05:25,  1.65s/it]predicting train subjects:  31%|███       | 88/285 [02:27<05:16,  1.61s/it]predicting train subjects:  31%|███       | 89/285 [02:29<05:17,  1.62s/it]predicting train subjects:  32%|███▏      | 90/285 [02:30<05:17,  1.63s/it]predicting train subjects:  32%|███▏      | 91/285 [02:32<05:09,  1.60s/it]predicting train subjects:  32%|███▏      | 92/285 [02:34<05:18,  1.65s/it]predicting train subjects:  33%|███▎      | 93/285 [02:35<05:10,  1.62s/it]predicting train subjects:  33%|███▎      | 94/285 [02:37<05:13,  1.64s/it]predicting train subjects:  33%|███▎      | 95/285 [02:39<05:18,  1.68s/it]predicting train subjects:  34%|███▎      | 96/285 [02:40<05:16,  1.67s/it]predicting train subjects:  34%|███▍      | 97/285 [02:42<05:17,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:44<05:20,  1.72s/it]predicting train subjects:  35%|███▍      | 99/285 [02:45<05:19,  1.72s/it]predicting train subjects:  35%|███▌      | 100/285 [02:47<05:21,  1.74s/it]predicting train subjects:  35%|███▌      | 101/285 [02:49<05:09,  1.68s/it]predicting train subjects:  36%|███▌      | 102/285 [02:51<05:13,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:52<04:59,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:54<05:05,  1.69s/it]predicting train subjects:  37%|███▋      | 105/285 [02:55<05:01,  1.68s/it]predicting train subjects:  37%|███▋      | 106/285 [02:57<04:51,  1.63s/it]predicting train subjects:  38%|███▊      | 107/285 [02:59<04:59,  1.68s/it]predicting train subjects:  38%|███▊      | 108/285 [03:00<04:49,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:02<04:51,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:04<04:58,  1.71s/it]predicting train subjects:  39%|███▉      | 111/285 [03:05<04:47,  1.65s/it]predicting train subjects:  39%|███▉      | 112/285 [03:07<04:53,  1.69s/it]predicting train subjects:  40%|███▉      | 113/285 [03:09<04:53,  1.71s/it]predicting train subjects:  40%|████      | 114/285 [03:11<04:53,  1.72s/it]predicting train subjects:  40%|████      | 115/285 [03:12<04:53,  1.73s/it]predicting train subjects:  41%|████      | 116/285 [03:14<04:48,  1.71s/it]predicting train subjects:  41%|████      | 117/285 [03:16<04:39,  1.66s/it]predicting train subjects:  41%|████▏     | 118/285 [03:17<04:30,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:19<04:36,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:20<04:28,  1.62s/it]predicting train subjects:  42%|████▏     | 121/285 [03:22<04:20,  1.59s/it]predicting train subjects:  43%|████▎     | 122/285 [03:23<04:12,  1.55s/it]predicting train subjects:  43%|████▎     | 123/285 [03:25<03:59,  1.48s/it]predicting train subjects:  44%|████▎     | 124/285 [03:26<03:58,  1.48s/it]predicting train subjects:  44%|████▍     | 125/285 [03:28<03:55,  1.47s/it]predicting train subjects:  44%|████▍     | 126/285 [03:29<03:50,  1.45s/it]predicting train subjects:  45%|████▍     | 127/285 [03:30<03:44,  1.42s/it]predicting train subjects:  45%|████▍     | 128/285 [03:32<03:46,  1.44s/it]predicting train subjects:  45%|████▌     | 129/285 [03:33<03:42,  1.43s/it]predicting train subjects:  46%|████▌     | 130/285 [03:35<03:37,  1.40s/it]predicting train subjects:  46%|████▌     | 131/285 [03:36<03:32,  1.38s/it]predicting train subjects:  46%|████▋     | 132/285 [03:37<03:34,  1.40s/it]predicting train subjects:  47%|████▋     | 133/285 [03:39<03:36,  1.42s/it]predicting train subjects:  47%|████▋     | 134/285 [03:40<03:30,  1.39s/it]predicting train subjects:  47%|████▋     | 135/285 [03:41<03:24,  1.36s/it]predicting train subjects:  48%|████▊     | 136/285 [03:43<03:20,  1.35s/it]predicting train subjects:  48%|████▊     | 137/285 [03:44<03:31,  1.43s/it]predicting train subjects:  48%|████▊     | 138/285 [03:46<03:26,  1.41s/it]predicting train subjects:  49%|████▉     | 139/285 [03:47<03:32,  1.45s/it]predicting train subjects:  49%|████▉     | 140/285 [03:49<03:33,  1.47s/it]predicting train subjects:  49%|████▉     | 141/285 [03:50<03:28,  1.45s/it]predicting train subjects:  50%|████▉     | 142/285 [03:52<03:24,  1.43s/it]predicting train subjects:  50%|█████     | 143/285 [03:53<03:20,  1.42s/it]predicting train subjects:  51%|█████     | 144/285 [03:54<03:22,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [03:56<03:17,  1.41s/it]predicting train subjects:  51%|█████     | 146/285 [03:57<03:19,  1.44s/it]predicting train subjects:  52%|█████▏    | 147/285 [03:59<03:16,  1.42s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:00<03:17,  1.44s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:02<03:13,  1.42s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:03<03:06,  1.38s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:04<03:12,  1.43s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:06<03:08,  1.42s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:07<03:03,  1.39s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:09<03:08,  1.44s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:10<03:07,  1.44s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:12<03:11,  1.49s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:13<03:06,  1.46s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:15<03:11,  1.51s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:16<03:08,  1.49s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:18<03:01,  1.45s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:19<03:01,  1.47s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:20<02:56,  1.43s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:22<02:57,  1.45s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:23<02:53,  1.43s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:25<02:47,  1.40s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:26<02:51,  1.44s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:28<02:52,  1.46s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:29<02:43,  1.40s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:30<02:40,  1.39s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:32<02:37,  1.37s/it]predicting train subjects:  60%|██████    | 171/285 [04:33<02:34,  1.35s/it]predicting train subjects:  60%|██████    | 172/285 [04:34<02:31,  1.34s/it]predicting train subjects:  61%|██████    | 173/285 [04:36<02:29,  1.33s/it]predicting train subjects:  61%|██████    | 174/285 [04:37<02:28,  1.34s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:38<02:35,  1.41s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:40<02:41,  1.48s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:42<02:36,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:43<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:44<02:27,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:46<02:37,  1.50s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:47<02:36,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:49<02:36,  1.52s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:50<02:32,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:52<02:26,  1.45s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:53<02:19,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:55<02:28,  1.50s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:56<02:30,  1.54s/it]predicting train subjects:  66%|██████▌   | 188/285 [04:58<02:30,  1.56s/it]predicting train subjects:  66%|██████▋   | 189/285 [04:59<02:19,  1.46s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:01<02:13,  1.41s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:02<02:16,  1.45s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:04<02:15,  1.46s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:05<02:11,  1.43s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:06<02:07,  1.41s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:08<02:04,  1.38s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:09<02:13,  1.50s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:11<02:15,  1.54s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:13<02:16,  1.57s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:14<02:07,  1.48s/it]predicting train subjects:  70%|███████   | 200/285 [05:15<02:00,  1.42s/it]predicting train subjects:  71%|███████   | 201/285 [05:17<02:07,  1.52s/it]predicting train subjects:  71%|███████   | 202/285 [05:19<02:07,  1.54s/it]predicting train subjects:  71%|███████   | 203/285 [05:20<02:09,  1.58s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:22<02:02,  1.51s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:23<01:58,  1.48s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:24<01:53,  1.43s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:26<01:57,  1.51s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:28<02:01,  1.58s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:29<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:31<01:53,  1.51s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:32<01:49,  1.47s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:34<01:49,  1.51s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:35<01:49,  1.52s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:36<01:42,  1.44s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:38<01:46,  1.52s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:39<01:39,  1.44s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:41<01:43,  1.53s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:43<01:46,  1.60s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:45<01:48,  1.64s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:46<01:39,  1.53s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:47<01:34,  1.48s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:49<01:35,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:50<01:29,  1.45s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:52<01:26,  1.41s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:53<01:21,  1.36s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:54<01:25,  1.45s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:56<01:27,  1.51s/it]predicting train subjects:  80%|████████  | 228/285 [05:58<01:30,  1.59s/it]predicting train subjects:  80%|████████  | 229/285 [05:59<01:27,  1.56s/it]predicting train subjects:  81%|████████  | 230/285 [06:01<01:20,  1.47s/it]predicting train subjects:  81%|████████  | 231/285 [06:02<01:17,  1.43s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:04<01:18,  1.48s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:05<01:14,  1.43s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:07<01:17,  1.52s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:08<01:13,  1.47s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:10<01:16,  1.57s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:11<01:17,  1.62s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:13<01:19,  1.69s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:15<01:16,  1.65s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:16<01:09,  1.55s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:18<01:05,  1.49s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:19<01:02,  1.45s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:20<00:59,  1.41s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:22<01:00,  1.47s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:23<00:56,  1.42s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:25<00:59,  1.51s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:27<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:28<00:58,  1.59s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:29<00:53,  1.50s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:31<00:50,  1.44s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:32<00:48,  1.41s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:33<00:45,  1.39s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:35<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:37<00:49,  1.58s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:39<00:48,  1.61s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:40<00:44,  1.52s/it]predicting train subjects:  90%|█████████ | 257/285 [06:42<00:42,  1.53s/it]predicting train subjects:  91%|█████████ | 258/285 [06:43<00:43,  1.61s/it]predicting train subjects:  91%|█████████ | 259/285 [06:45<00:41,  1.59s/it]predicting train subjects:  91%|█████████ | 260/285 [06:46<00:37,  1.51s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:48<00:35,  1.46s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:49<00:32,  1.43s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:50<00:30,  1.40s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:52<00:31,  1.49s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:54<00:30,  1.55s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:55<00:28,  1.48s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:56<00:26,  1.47s/it]predicting train subjects:  94%|█████████▍| 268/285 [06:58<00:25,  1.53s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:00<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:01<00:22,  1.49s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:02<00:20,  1.44s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:04<00:19,  1.48s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:05<00:17,  1.43s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:07<00:15,  1.38s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:08<00:14,  1.48s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:10<00:13,  1.54s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:11<00:11,  1.47s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:13<00:10,  1.45s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:14<00:08,  1.47s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:15<00:07,  1.42s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:17<00:05,  1.40s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:18<00:04,  1.37s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:20<00:02,  1.45s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:21<00:01,  1.53s/it]predicting train subjects: 100%|██████████| 285/285 [07:23<00:00,  1.57s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:20,  1.55s/it]Loading train:   1%|          | 2/285 [00:02<06:40,  1.41s/it]Loading train:   1%|          | 3/285 [00:03<06:33,  1.39s/it]Loading train:   1%|▏         | 4/285 [00:04<05:55,  1.26s/it]Loading train:   2%|▏         | 5/285 [00:06<06:24,  1.37s/it]Loading train:   2%|▏         | 6/285 [00:07<06:14,  1.34s/it]Loading train:   2%|▏         | 7/285 [00:09<06:45,  1.46s/it]Loading train:   3%|▎         | 8/285 [00:10<06:28,  1.40s/it]Loading train:   3%|▎         | 9/285 [00:12<06:48,  1.48s/it]Loading train:   4%|▎         | 10/285 [00:13<06:14,  1.36s/it]Loading train:   4%|▍         | 11/285 [00:14<05:35,  1.22s/it]Loading train:   4%|▍         | 12/285 [00:15<05:25,  1.19s/it]Loading train:   5%|▍         | 13/285 [00:16<05:02,  1.11s/it]Loading train:   5%|▍         | 14/285 [00:17<04:59,  1.11s/it]Loading train:   5%|▌         | 15/285 [00:18<05:01,  1.12s/it]Loading train:   6%|▌         | 16/285 [00:19<04:54,  1.10s/it]Loading train:   6%|▌         | 17/285 [00:20<04:31,  1.01s/it]Loading train:   6%|▋         | 18/285 [00:21<04:18,  1.03it/s]Loading train:   7%|▋         | 19/285 [00:22<04:02,  1.10it/s]Loading train:   7%|▋         | 20/285 [00:23<04:03,  1.09it/s]Loading train:   7%|▋         | 21/285 [00:24<04:08,  1.06it/s]Loading train:   8%|▊         | 22/285 [00:24<03:52,  1.13it/s]Loading train:   8%|▊         | 23/285 [00:25<03:56,  1.11it/s]Loading train:   8%|▊         | 24/285 [00:26<03:41,  1.18it/s]Loading train:   9%|▉         | 25/285 [00:27<03:52,  1.12it/s]Loading train:   9%|▉         | 26/285 [00:28<03:59,  1.08it/s]Loading train:   9%|▉         | 27/285 [00:29<03:55,  1.10it/s]Loading train:  10%|▉         | 28/285 [00:30<04:04,  1.05it/s]Loading train:  10%|█         | 29/285 [00:31<03:56,  1.08it/s]Loading train:  11%|█         | 30/285 [00:32<04:09,  1.02it/s]Loading train:  11%|█         | 31/285 [00:33<04:15,  1.01s/it]Loading train:  11%|█         | 32/285 [00:34<04:05,  1.03it/s]Loading train:  12%|█▏        | 33/285 [00:35<04:13,  1.01s/it]Loading train:  12%|█▏        | 34/285 [00:36<04:05,  1.02it/s]Loading train:  12%|█▏        | 35/285 [00:37<04:06,  1.02it/s]Loading train:  13%|█▎        | 36/285 [00:38<03:43,  1.12it/s]Loading train:  13%|█▎        | 37/285 [00:39<03:43,  1.11it/s]Loading train:  13%|█▎        | 38/285 [00:39<03:37,  1.14it/s]Loading train:  14%|█▎        | 39/285 [00:40<03:38,  1.12it/s]Loading train:  14%|█▍        | 40/285 [00:41<03:46,  1.08it/s]Loading train:  14%|█▍        | 41/285 [00:42<03:50,  1.06it/s]Loading train:  15%|█▍        | 42/285 [00:43<03:42,  1.09it/s]Loading train:  15%|█▌        | 43/285 [00:44<03:50,  1.05it/s]Loading train:  15%|█▌        | 44/285 [00:45<03:47,  1.06it/s]Loading train:  16%|█▌        | 45/285 [00:46<03:53,  1.03it/s]Loading train:  16%|█▌        | 46/285 [00:47<03:49,  1.04it/s]Loading train:  16%|█▋        | 47/285 [00:48<03:35,  1.11it/s]Loading train:  17%|█▋        | 48/285 [00:49<03:38,  1.09it/s]Loading train:  17%|█▋        | 49/285 [00:50<03:57,  1.01s/it]Loading train:  18%|█▊        | 50/285 [00:51<03:51,  1.01it/s]Loading train:  18%|█▊        | 51/285 [00:52<03:54,  1.00s/it]Loading train:  18%|█▊        | 52/285 [00:53<03:43,  1.04it/s]Loading train:  19%|█▊        | 53/285 [00:54<03:41,  1.05it/s]Loading train:  19%|█▉        | 54/285 [00:55<03:46,  1.02it/s]Loading train:  19%|█▉        | 55/285 [00:56<03:31,  1.09it/s]Loading train:  20%|█▉        | 56/285 [00:57<03:32,  1.08it/s]Loading train:  20%|██        | 57/285 [00:57<03:14,  1.17it/s]Loading train:  20%|██        | 58/285 [00:58<03:18,  1.14it/s]Loading train:  21%|██        | 59/285 [00:59<03:13,  1.17it/s]Loading train:  21%|██        | 60/285 [01:00<03:12,  1.17it/s]Loading train:  21%|██▏       | 61/285 [01:01<03:13,  1.16it/s]Loading train:  22%|██▏       | 62/285 [01:02<03:30,  1.06it/s]Loading train:  22%|██▏       | 63/285 [01:03<03:31,  1.05it/s]Loading train:  22%|██▏       | 64/285 [01:04<04:04,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:06<04:44,  1.29s/it]Loading train:  23%|██▎       | 66/285 [01:07<04:42,  1.29s/it]Loading train:  24%|██▎       | 67/285 [01:08<04:14,  1.17s/it]Loading train:  24%|██▍       | 68/285 [01:09<03:54,  1.08s/it]Loading train:  24%|██▍       | 69/285 [01:10<03:39,  1.01s/it]Loading train:  25%|██▍       | 70/285 [01:11<03:38,  1.02s/it]Loading train:  25%|██▍       | 71/285 [01:12<03:33,  1.00it/s]Loading train:  25%|██▌       | 72/285 [01:13<03:24,  1.04it/s]Loading train:  26%|██▌       | 73/285 [01:14<03:17,  1.07it/s]Loading train:  26%|██▌       | 74/285 [01:14<03:09,  1.11it/s]Loading train:  26%|██▋       | 75/285 [01:15<03:10,  1.10it/s]Loading train:  27%|██▋       | 76/285 [01:16<03:10,  1.10it/s]Loading train:  27%|██▋       | 77/285 [01:17<03:05,  1.12it/s]Loading train:  27%|██▋       | 78/285 [01:18<03:00,  1.15it/s]Loading train:  28%|██▊       | 79/285 [01:19<03:09,  1.09it/s]Loading train:  28%|██▊       | 80/285 [01:20<03:08,  1.09it/s]Loading train:  28%|██▊       | 81/285 [01:21<02:59,  1.14it/s]Loading train:  29%|██▉       | 82/285 [01:22<02:57,  1.14it/s]Loading train:  29%|██▉       | 83/285 [01:23<03:01,  1.11it/s]Loading train:  29%|██▉       | 84/285 [01:23<02:56,  1.14it/s]Loading train:  30%|██▉       | 85/285 [01:24<02:55,  1.14it/s]Loading train:  30%|███       | 86/285 [01:25<03:12,  1.03it/s]Loading train:  31%|███       | 87/285 [01:26<03:10,  1.04it/s]Loading train:  31%|███       | 88/285 [01:27<02:59,  1.10it/s]Loading train:  31%|███       | 89/285 [01:28<03:01,  1.08it/s]Loading train:  32%|███▏      | 90/285 [01:29<03:07,  1.04it/s]Loading train:  32%|███▏      | 91/285 [01:30<02:57,  1.09it/s]Loading train:  32%|███▏      | 92/285 [01:31<03:03,  1.05it/s]Loading train:  33%|███▎      | 93/285 [01:32<02:54,  1.10it/s]Loading train:  33%|███▎      | 94/285 [01:33<02:56,  1.08it/s]Loading train:  33%|███▎      | 95/285 [01:34<02:59,  1.06it/s]Loading train:  34%|███▎      | 96/285 [01:35<02:52,  1.10it/s]Loading train:  34%|███▍      | 97/285 [01:36<02:52,  1.09it/s]Loading train:  34%|███▍      | 98/285 [01:37<03:03,  1.02it/s]Loading train:  35%|███▍      | 99/285 [01:37<02:51,  1.08it/s]Loading train:  35%|███▌      | 100/285 [01:39<03:03,  1.01it/s]Loading train:  35%|███▌      | 101/285 [01:39<02:51,  1.07it/s]Loading train:  36%|███▌      | 102/285 [01:40<02:50,  1.07it/s]Loading train:  36%|███▌      | 103/285 [01:41<02:41,  1.13it/s]Loading train:  36%|███▋      | 104/285 [01:42<02:52,  1.05it/s]Loading train:  37%|███▋      | 105/285 [01:43<02:51,  1.05it/s]Loading train:  37%|███▋      | 106/285 [01:44<02:54,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:45<02:51,  1.04it/s]Loading train:  38%|███▊      | 108/285 [01:46<02:54,  1.02it/s]Loading train:  38%|███▊      | 109/285 [01:47<02:43,  1.08it/s]Loading train:  39%|███▊      | 110/285 [01:48<02:46,  1.05it/s]Loading train:  39%|███▉      | 111/285 [01:49<02:32,  1.14it/s]Loading train:  39%|███▉      | 112/285 [01:50<02:36,  1.11it/s]Loading train:  40%|███▉      | 113/285 [01:51<02:43,  1.06it/s]Loading train:  40%|████      | 114/285 [01:52<02:37,  1.08it/s]Loading train:  40%|████      | 115/285 [01:53<02:44,  1.03it/s]Loading train:  41%|████      | 116/285 [01:54<02:48,  1.01it/s]Loading train:  41%|████      | 117/285 [01:55<02:45,  1.01it/s]Loading train:  41%|████▏     | 118/285 [01:55<02:35,  1.07it/s]Loading train:  42%|████▏     | 119/285 [01:56<02:35,  1.07it/s]Loading train:  42%|████▏     | 120/285 [01:57<02:32,  1.08it/s]Loading train:  42%|████▏     | 121/285 [01:59<02:47,  1.02s/it]Loading train:  43%|████▎     | 122/285 [02:00<02:53,  1.06s/it]Loading train:  43%|████▎     | 123/285 [02:01<02:59,  1.11s/it]Loading train:  44%|████▎     | 124/285 [02:02<02:49,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:02<02:28,  1.08it/s]Loading train:  44%|████▍     | 126/285 [02:03<02:14,  1.19it/s]Loading train:  45%|████▍     | 127/285 [02:04<02:10,  1.21it/s]Loading train:  45%|████▍     | 128/285 [02:05<02:05,  1.25it/s]Loading train:  45%|████▌     | 129/285 [02:05<02:05,  1.24it/s]Loading train:  46%|████▌     | 130/285 [02:06<01:59,  1.30it/s]Loading train:  46%|████▌     | 131/285 [02:07<01:54,  1.34it/s]Loading train:  46%|████▋     | 132/285 [02:08<02:00,  1.27it/s]Loading train:  47%|████▋     | 133/285 [02:08<01:54,  1.33it/s]Loading train:  47%|████▋     | 134/285 [02:09<01:54,  1.32it/s]Loading train:  47%|████▋     | 135/285 [02:10<01:51,  1.34it/s]Loading train:  48%|████▊     | 136/285 [02:11<01:48,  1.37it/s]Loading train:  48%|████▊     | 137/285 [02:11<01:47,  1.38it/s]Loading train:  48%|████▊     | 138/285 [02:12<01:43,  1.41it/s]Loading train:  49%|████▉     | 139/285 [02:13<01:50,  1.33it/s]Loading train:  49%|████▉     | 140/285 [02:14<01:45,  1.37it/s]Loading train:  49%|████▉     | 141/285 [02:14<01:45,  1.36it/s]Loading train:  50%|████▉     | 142/285 [02:15<01:47,  1.33it/s]Loading train:  50%|█████     | 143/285 [02:16<01:50,  1.29it/s]Loading train:  51%|█████     | 144/285 [02:17<01:51,  1.27it/s]Loading train:  51%|█████     | 145/285 [02:17<01:48,  1.29it/s]Loading train:  51%|█████     | 146/285 [02:18<01:48,  1.28it/s]Loading train:  52%|█████▏    | 147/285 [02:19<01:47,  1.29it/s]Loading train:  52%|█████▏    | 148/285 [02:20<01:46,  1.28it/s]Loading train:  52%|█████▏    | 149/285 [02:21<01:46,  1.28it/s]Loading train:  53%|█████▎    | 150/285 [02:21<01:46,  1.26it/s]Loading train:  53%|█████▎    | 151/285 [02:22<01:51,  1.20it/s]Loading train:  53%|█████▎    | 152/285 [02:23<01:44,  1.27it/s]Loading train:  54%|█████▎    | 153/285 [02:24<01:46,  1.24it/s]Loading train:  54%|█████▍    | 154/285 [02:25<01:42,  1.28it/s]Loading train:  54%|█████▍    | 155/285 [02:26<01:47,  1.21it/s]Loading train:  55%|█████▍    | 156/285 [02:26<01:42,  1.25it/s]Loading train:  55%|█████▌    | 157/285 [02:27<01:42,  1.25it/s]Loading train:  55%|█████▌    | 158/285 [02:28<01:41,  1.25it/s]Loading train:  56%|█████▌    | 159/285 [02:29<01:36,  1.30it/s]Loading train:  56%|█████▌    | 160/285 [02:29<01:38,  1.27it/s]Loading train:  56%|█████▋    | 161/285 [02:30<01:44,  1.19it/s]Loading train:  57%|█████▋    | 162/285 [02:31<01:41,  1.21it/s]Loading train:  57%|█████▋    | 163/285 [02:32<01:47,  1.14it/s]Loading train:  58%|█████▊    | 164/285 [02:33<01:42,  1.18it/s]Loading train:  58%|█████▊    | 165/285 [02:34<01:34,  1.28it/s]Loading train:  58%|█████▊    | 166/285 [02:34<01:38,  1.21it/s]Loading train:  59%|█████▊    | 167/285 [02:35<01:41,  1.17it/s]Loading train:  59%|█████▉    | 168/285 [02:36<01:42,  1.14it/s]Loading train:  59%|█████▉    | 169/285 [02:37<01:36,  1.21it/s]Loading train:  60%|█████▉    | 170/285 [02:38<01:41,  1.14it/s]Loading train:  60%|██████    | 171/285 [02:39<01:35,  1.19it/s]Loading train:  60%|██████    | 172/285 [02:40<01:33,  1.21it/s]Loading train:  61%|██████    | 173/285 [02:40<01:33,  1.20it/s]Loading train:  61%|██████    | 174/285 [02:41<01:27,  1.27it/s]Loading train:  61%|██████▏   | 175/285 [02:42<01:28,  1.25it/s]Loading train:  62%|██████▏   | 176/285 [02:43<01:32,  1.18it/s]Loading train:  62%|██████▏   | 177/285 [02:44<01:28,  1.22it/s]Loading train:  62%|██████▏   | 178/285 [02:44<01:25,  1.25it/s]Loading train:  63%|██████▎   | 179/285 [02:45<01:23,  1.26it/s]Loading train:  63%|██████▎   | 180/285 [02:46<01:26,  1.21it/s]Loading train:  64%|██████▎   | 181/285 [02:47<01:30,  1.15it/s]Loading train:  64%|██████▍   | 182/285 [02:48<01:26,  1.20it/s]Loading train:  64%|██████▍   | 183/285 [02:49<01:24,  1.21it/s]Loading train:  65%|██████▍   | 184/285 [02:49<01:22,  1.22it/s]Loading train:  65%|██████▍   | 185/285 [02:50<01:26,  1.16it/s]Loading train:  65%|██████▌   | 186/285 [02:51<01:28,  1.11it/s]Loading train:  66%|██████▌   | 187/285 [02:52<01:30,  1.09it/s]Loading train:  66%|██████▌   | 188/285 [02:53<01:34,  1.02it/s]Loading train:  66%|██████▋   | 189/285 [02:54<01:29,  1.07it/s]Loading train:  67%|██████▋   | 190/285 [02:55<01:28,  1.08it/s]Loading train:  67%|██████▋   | 191/285 [02:56<01:23,  1.12it/s]Loading train:  67%|██████▋   | 192/285 [02:57<01:20,  1.16it/s]Loading train:  68%|██████▊   | 193/285 [02:57<01:14,  1.24it/s]Loading train:  68%|██████▊   | 194/285 [02:58<01:12,  1.25it/s]Loading train:  68%|██████▊   | 195/285 [02:59<01:06,  1.34it/s]Loading train:  69%|██████▉   | 196/285 [03:00<01:11,  1.24it/s]Loading train:  69%|██████▉   | 197/285 [03:01<01:11,  1.23it/s]Loading train:  69%|██████▉   | 198/285 [03:02<01:14,  1.17it/s]Loading train:  70%|██████▉   | 199/285 [03:02<01:06,  1.30it/s]Loading train:  70%|███████   | 200/285 [03:03<01:10,  1.21it/s]Loading train:  71%|███████   | 201/285 [03:04<01:13,  1.15it/s]Loading train:  71%|███████   | 202/285 [03:05<01:11,  1.17it/s]Loading train:  71%|███████   | 203/285 [03:06<01:09,  1.18it/s]Loading train:  72%|███████▏  | 204/285 [03:07<01:06,  1.22it/s]Loading train:  72%|███████▏  | 205/285 [03:07<01:04,  1.25it/s]Loading train:  72%|███████▏  | 206/285 [03:08<00:59,  1.32it/s]Loading train:  73%|███████▎  | 207/285 [03:09<01:01,  1.26it/s]Loading train:  73%|███████▎  | 208/285 [03:10<01:03,  1.21it/s]Loading train:  73%|███████▎  | 209/285 [03:11<01:08,  1.11it/s]Loading train:  74%|███████▎  | 210/285 [03:11<01:02,  1.19it/s]Loading train:  74%|███████▍  | 211/285 [03:12<01:01,  1.21it/s]Loading train:  74%|███████▍  | 212/285 [03:13<00:59,  1.22it/s]Loading train:  75%|███████▍  | 213/285 [03:14<01:00,  1.20it/s]Loading train:  75%|███████▌  | 214/285 [03:15<00:55,  1.27it/s]Loading train:  75%|███████▌  | 215/285 [03:16<01:01,  1.13it/s]Loading train:  76%|███████▌  | 216/285 [03:17<00:59,  1.17it/s]Loading train:  76%|███████▌  | 217/285 [03:17<00:59,  1.15it/s]Loading train:  76%|███████▋  | 218/285 [03:18<00:59,  1.13it/s]Loading train:  77%|███████▋  | 219/285 [03:19<01:00,  1.09it/s]Loading train:  77%|███████▋  | 220/285 [03:20<00:56,  1.15it/s]Loading train:  78%|███████▊  | 221/285 [03:21<00:55,  1.16it/s]Loading train:  78%|███████▊  | 222/285 [03:22<00:54,  1.16it/s]Loading train:  78%|███████▊  | 223/285 [03:22<00:47,  1.29it/s]Loading train:  79%|███████▊  | 224/285 [03:23<00:49,  1.23it/s]Loading train:  79%|███████▉  | 225/285 [03:24<00:51,  1.16it/s]Loading train:  79%|███████▉  | 226/285 [03:25<00:52,  1.12it/s]Loading train:  80%|███████▉  | 227/285 [03:26<00:55,  1.04it/s]Loading train:  80%|████████  | 228/285 [03:27<00:53,  1.06it/s]Loading train:  80%|████████  | 229/285 [03:28<00:52,  1.07it/s]Loading train:  81%|████████  | 230/285 [03:29<00:48,  1.14it/s]Loading train:  81%|████████  | 231/285 [03:30<00:45,  1.18it/s]Loading train:  81%|████████▏ | 232/285 [03:31<00:46,  1.13it/s]Loading train:  82%|████████▏ | 233/285 [03:31<00:42,  1.24it/s]Loading train:  82%|████████▏ | 234/285 [03:32<00:44,  1.15it/s]Loading train:  82%|████████▏ | 235/285 [03:33<00:39,  1.26it/s]Loading train:  83%|████████▎ | 236/285 [03:34<00:41,  1.19it/s]Loading train:  83%|████████▎ | 237/285 [03:35<00:40,  1.20it/s]Loading train:  84%|████████▎ | 238/285 [03:36<00:40,  1.16it/s]Loading train:  84%|████████▍ | 239/285 [03:37<00:40,  1.15it/s]Loading train:  84%|████████▍ | 240/285 [03:37<00:37,  1.20it/s]Loading train:  85%|████████▍ | 241/285 [03:38<00:35,  1.24it/s]Loading train:  85%|████████▍ | 242/285 [03:39<00:34,  1.26it/s]Loading train:  85%|████████▌ | 243/285 [03:39<00:31,  1.35it/s]Loading train:  86%|████████▌ | 244/285 [03:40<00:34,  1.20it/s]Loading train:  86%|████████▌ | 245/285 [03:41<00:31,  1.26it/s]Loading train:  86%|████████▋ | 246/285 [03:42<00:34,  1.14it/s]Loading train:  87%|████████▋ | 247/285 [03:43<00:33,  1.12it/s]Loading train:  87%|████████▋ | 248/285 [03:44<00:32,  1.13it/s]Loading train:  87%|████████▋ | 249/285 [03:45<00:29,  1.21it/s]Loading train:  88%|████████▊ | 250/285 [03:46<00:28,  1.22it/s]Loading train:  88%|████████▊ | 251/285 [03:46<00:26,  1.28it/s]Loading train:  88%|████████▊ | 252/285 [03:47<00:24,  1.37it/s]Loading train:  89%|████████▉ | 253/285 [03:48<00:25,  1.27it/s]Loading train:  89%|████████▉ | 254/285 [03:49<00:25,  1.20it/s]Loading train:  89%|████████▉ | 255/285 [03:49<00:24,  1.21it/s]Loading train:  90%|████████▉ | 256/285 [03:50<00:22,  1.28it/s]Loading train:  90%|█████████ | 257/285 [03:51<00:21,  1.32it/s]Loading train:  91%|█████████ | 258/285 [03:52<00:22,  1.21it/s]Loading train:  91%|█████████ | 259/285 [03:53<00:21,  1.19it/s]Loading train:  91%|█████████ | 260/285 [03:53<00:19,  1.26it/s]Loading train:  92%|█████████▏| 261/285 [03:54<00:19,  1.26it/s]Loading train:  92%|█████████▏| 262/285 [03:55<00:17,  1.28it/s]Loading train:  92%|█████████▏| 263/285 [03:56<00:16,  1.31it/s]Loading train:  93%|█████████▎| 264/285 [03:57<00:17,  1.22it/s]Loading train:  93%|█████████▎| 265/285 [03:58<00:17,  1.17it/s]Loading train:  93%|█████████▎| 266/285 [03:58<00:15,  1.19it/s]Loading train:  94%|█████████▎| 267/285 [03:59<00:15,  1.18it/s]Loading train:  94%|█████████▍| 268/285 [04:00<00:15,  1.12it/s]Loading train:  94%|█████████▍| 269/285 [04:01<00:13,  1.15it/s]Loading train:  95%|█████████▍| 270/285 [04:02<00:12,  1.21it/s]Loading train:  95%|█████████▌| 271/285 [04:03<00:11,  1.22it/s]Loading train:  95%|█████████▌| 272/285 [04:03<00:10,  1.19it/s]Loading train:  96%|█████████▌| 273/285 [04:04<00:09,  1.21it/s]Loading train:  96%|█████████▌| 274/285 [04:05<00:08,  1.25it/s]Loading train:  96%|█████████▋| 275/285 [04:06<00:08,  1.15it/s]Loading train:  97%|█████████▋| 276/285 [04:07<00:08,  1.11it/s]Loading train:  97%|█████████▋| 277/285 [04:08<00:06,  1.17it/s]Loading train:  98%|█████████▊| 278/285 [04:08<00:05,  1.22it/s]Loading train:  98%|█████████▊| 279/285 [04:09<00:04,  1.22it/s]Loading train:  98%|█████████▊| 280/285 [04:10<00:03,  1.27it/s]Loading train:  99%|█████████▊| 281/285 [04:11<00:03,  1.24it/s]Loading train:  99%|█████████▉| 282/285 [04:12<00:02,  1.29it/s]Loading train:  99%|█████████▉| 283/285 [04:12<00:01,  1.22it/s]Loading train: 100%|█████████▉| 284/285 [04:13<00:00,  1.21it/s]Loading train: 100%|██████████| 285/285 [04:14<00:00,  1.16it/s]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:02, 96.44it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:02, 98.87it/s]concatenating: train:  18%|█▊        | 50/285 [00:00<00:01, 123.11it/s]concatenating: train:  29%|██▉       | 83/285 [00:00<00:01, 151.38it/s]concatenating: train:  39%|███▉      | 112/285 [00:00<00:00, 175.20it/s]concatenating: train:  51%|█████     | 146/285 [00:00<00:00, 204.69it/s]concatenating: train:  63%|██████▎   | 180/285 [00:00<00:00, 232.44it/s]concatenating: train:  76%|███████▌  | 216/285 [00:00<00:00, 259.50it/s]concatenating: train:  87%|████████▋ | 247/285 [00:00<00:00, 271.44it/s]concatenating: train: 100%|█████████▉| 284/285 [00:01<00:00, 294.30it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 278.38it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.22s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 126.16it/s]2019-07-11 09:28:46.224300: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 09:28:46.224442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 09:28:46.224461: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 09:28:46.224471: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 09:28:46.224832: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.14it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.97it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.84it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.22it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.38it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.04it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.18it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.69it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.95it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.83it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  6.58it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.14it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.77it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.65it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  7.12it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.76it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  8.13it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.62it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.77it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.04it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   2850        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 20)   8120        dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 80, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 80, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 80, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 65)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 80, 13)   858         concatenate_8[0][0]              
==================================================================================================
Total params: 145,318
Trainable params: 46,698
Non-trainable params: 98,620
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 17s - loss: 2.8478 - acc: 0.6526 - mDice: 0.1020 - val_loss: 2.1287 - val_acc: 0.9046 - val_mDice: 0.2467

Epoch 00001: val_mDice improved from -inf to 0.24673, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 11s - loss: 1.0179 - acc: 0.8750 - mDice: 0.3613 - val_loss: 1.3788 - val_acc: 0.9115 - val_mDice: 0.4271

Epoch 00002: val_mDice improved from 0.24673 to 0.42715, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 10s - loss: 0.7020 - acc: 0.8829 - mDice: 0.4810 - val_loss: 1.1441 - val_acc: 0.9215 - val_mDice: 0.5047

Epoch 00003: val_mDice improved from 0.42715 to 0.50475, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 10s - loss: 0.5966 - acc: 0.8934 - mDice: 0.5351 - val_loss: 1.1146 - val_acc: 0.9280 - val_mDice: 0.5088

Epoch 00004: val_mDice improved from 0.50475 to 0.50884, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 10s - loss: 0.5335 - acc: 0.9094 - mDice: 0.5710 - val_loss: 1.0485 - val_acc: 0.9360 - val_mDice: 0.5353

Epoch 00005: val_mDice improved from 0.50884 to 0.53532, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 11s - loss: 0.4971 - acc: 0.9217 - mDice: 0.5927 - val_loss: 1.0331 - val_acc: 0.9301 - val_mDice: 0.5375

Epoch 00006: val_mDice improved from 0.53532 to 0.53752, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 11s - loss: 0.4716 - acc: 0.9267 - mDice: 0.6085 - val_loss: 0.9642 - val_acc: 0.9372 - val_mDice: 0.5641

Epoch 00007: val_mDice improved from 0.53752 to 0.56407, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 10s - loss: 0.4532 - acc: 0.9292 - mDice: 0.6202 - val_loss: 1.0179 - val_acc: 0.9184 - val_mDice: 0.5285

Epoch 00008: val_mDice did not improve from 0.56407
Epoch 9/300
 - 10s - loss: 0.4392 - acc: 0.9304 - mDice: 0.6290 - val_loss: 1.0628 - val_acc: 0.9365 - val_mDice: 0.5095

Epoch 00009: val_mDice did not improve from 0.56407
Epoch 10/300
 - 10s - loss: 0.4271 - acc: 0.9316 - mDice: 0.6371 - val_loss: 0.9110 - val_acc: 0.9404 - val_mDice: 0.5767

Epoch 00010: val_mDice improved from 0.56407 to 0.57671, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 10s - loss: 0.4154 - acc: 0.9329 - mDice: 0.6449 - val_loss: 0.9211 - val_acc: 0.9287 - val_mDice: 0.5601

Epoch 00011: val_mDice did not improve from 0.57671
Epoch 12/300
 - 10s - loss: 0.4070 - acc: 0.9335 - mDice: 0.6503 - val_loss: 0.9535 - val_acc: 0.9394 - val_mDice: 0.5513

Epoch 00012: val_mDice did not improve from 0.57671
Epoch 13/300
 - 10s - loss: 0.4007 - acc: 0.9341 - mDice: 0.6546 - val_loss: 0.9393 - val_acc: 0.9412 - val_mDice: 0.5592

Epoch 00013: val_mDice did not improve from 0.57671
Epoch 14/300
 - 10s - loss: 0.3966 - acc: 0.9346 - mDice: 0.6576 - val_loss: 0.9211 - val_acc: 0.9365 - val_mDice: 0.5585

Epoch 00014: val_mDice did not improve from 0.57671
Epoch 15/300
 - 11s - loss: 0.3873 - acc: 0.9355 - mDice: 0.6639 - val_loss: 0.9322 - val_acc: 0.9415 - val_mDice: 0.5512

Epoch 00015: val_mDice did not improve from 0.57671
Epoch 16/300
 - 10s - loss: 0.3845 - acc: 0.9358 - mDice: 0.6659 - val_loss: 0.9264 - val_acc: 0.9412 - val_mDice: 0.5554

Epoch 00016: val_mDice did not improve from 0.57671
Epoch 17/300
 - 10s - loss: 0.3807 - acc: 0.9361 - mDice: 0.6684 - val_loss: 0.9194 - val_acc: 0.9429 - val_mDice: 0.5554

Epoch 00017: val_mDice did not improve from 0.57671
Epoch 18/300
 - 10s - loss: 0.3764 - acc: 0.9365 - mDice: 0.6714 - val_loss: 0.8951 - val_acc: 0.9418 - val_mDice: 0.5616

Epoch 00018: val_mDice did not improve from 0.57671
Epoch 19/300
 - 10s - loss: 0.3718 - acc: 0.9371 - mDice: 0.6747 - val_loss: 0.8850 - val_acc: 0.9394 - val_mDice: 0.5618

Epoch 00019: val_mDice did not improve from 0.57671
Epoch 20/300
 - 10s - loss: 0.3682 - acc: 0.9375 - mDice: 0.6772 - val_loss: 0.8346 - val_acc: 0.9412 - val_mDice: 0.5833

Epoch 00020: val_mDice improved from 0.57671 to 0.58330, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 10s - loss: 0.3661 - acc: 0.9376 - mDice: 0.6786 - val_loss: 0.8891 - val_acc: 0.9440 - val_mDice: 0.5650

Epoch 00021: val_mDice did not improve from 0.58330
Epoch 22/300
 - 10s - loss: 0.3617 - acc: 0.9381 - mDice: 0.6818 - val_loss: 0.9016 - val_acc: 0.9363 - val_mDice: 0.5470

Epoch 00022: val_mDice did not improve from 0.58330
Epoch 23/300
 - 10s - loss: 0.3620 - acc: 0.9380 - mDice: 0.6815 - val_loss: 0.8955 - val_acc: 0.9428 - val_mDice: 0.5603

Epoch 00023: val_mDice did not improve from 0.58330
Epoch 24/300
 - 11s - loss: 0.3571 - acc: 0.9386 - mDice: 0.6850 - val_loss: 0.8823 - val_acc: 0.9436 - val_mDice: 0.5622

Epoch 00024: val_mDice did not improve from 0.58330
Epoch 25/300
 - 10s - loss: 0.3550 - acc: 0.9389 - mDice: 0.6866 - val_loss: 0.8861 - val_acc: 0.9408 - val_mDice: 0.5540

Epoch 00025: val_mDice did not improve from 0.58330
Epoch 26/300
 - 10s - loss: 0.3522 - acc: 0.9391 - mDice: 0.6885 - val_loss: 0.8838 - val_acc: 0.9360 - val_mDice: 0.5473

Epoch 00026: val_mDice did not improve from 0.58330
Epoch 27/300
 - 10s - loss: 0.3504 - acc: 0.9390 - mDice: 0.6898 - val_loss: 0.8562 - val_acc: 0.9354 - val_mDice: 0.5492

Epoch 00027: val_mDice did not improve from 0.58330
Epoch 28/300
 - 10s - loss: 0.3469 - acc: 0.9394 - mDice: 0.6922 - val_loss: 0.8383 - val_acc: 0.9347 - val_mDice: 0.5637

Epoch 00028: val_mDice did not improve from 0.58330
Epoch 29/300
 - 10s - loss: 0.3443 - acc: 0.9396 - mDice: 0.6943 - val_loss: 0.8523 - val_acc: 0.9364 - val_mDice: 0.5533

Epoch 00029: val_mDice did not improve from 0.58330
Epoch 30/300
 - 10s - loss: 0.3433 - acc: 0.9398 - mDice: 0.6949 - val_loss: 0.8362 - val_acc: 0.9377 - val_mDice: 0.5648

Epoch 00030: val_mDice did not improve from 0.58330
Epoch 31/300
 - 10s - loss: 0.3418 - acc: 0.9398 - mDice: 0.6960 - val_loss: 0.8507 - val_acc: 0.9320 - val_mDice: 0.5488

Epoch 00031: val_mDice did not improve from 0.58330
Epoch 32/300
 - 10s - loss: 0.3381 - acc: 0.9404 - mDice: 0.6986 - val_loss: 0.8512 - val_acc: 0.9422 - val_mDice: 0.5583

Epoch 00032: val_mDice did not improve from 0.58330
Epoch 33/300
 - 10s - loss: 0.3355 - acc: 0.9404 - mDice: 0.7005 - val_loss: 0.8443 - val_acc: 0.9447 - val_mDice: 0.5553

Epoch 00033: val_mDice did not improve from 0.58330
Epoch 34/300
 - 11s - loss: 0.3335 - acc: 0.9407 - mDice: 0.7020 - val_loss: 0.8780 - val_acc: 0.9411 - val_mDice: 0.5389

Epoch 00034: val_mDice did not improve from 0.58330
Epoch 35/300
 - 11s - loss: 0.3336 - acc: 0.9408 - mDice: 0.7019 - val_loss: 0.8945 - val_acc: 0.9428 - val_mDice: 0.5282

Epoch 00035: val_mDice did not improve from 0.58330
Epoch 36/300
 - 10s - loss: 0.3314 - acc: 0.9409 - mDice: 0.7034 - val_loss: 0.8282 - val_acc: 0.9408 - val_mDice: 0.5446

Epoch 00036: val_mDice did not improve from 0.58330
Epoch 37/300
 - 11s - loss: 0.3291 - acc: 0.9413 - mDice: 0.7052 - val_loss: 0.7869 - val_acc: 0.9368 - val_mDice: 0.5603

Epoch 00037: val_mDice did not improve from 0.58330
Epoch 38/300
 - 10s - loss: 0.3268 - acc: 0.9414 - mDice: 0.7068 - val_loss: 0.8028 - val_acc: 0.9353 - val_mDice: 0.5530

Epoch 00038: val_mDice did not improve from 0.58330
Epoch 39/300
 - 10s - loss: 0.3267 - acc: 0.9412 - mDice: 0.7069 - val_loss: 0.7997 - val_acc: 0.9375 - val_mDice: 0.5588

Epoch 00039: val_mDice did not improve from 0.58330
Epoch 40/300
 - 10s - loss: 0.3258 - acc: 0.9414 - mDice: 0.7076 - val_loss: 0.7810 - val_acc: 0.9390 - val_mDice: 0.5721

Epoch 00040: val_mDice did not improve from 0.58330
Epoch 41/300
 - 11s - loss: 0.3240 - acc: 0.9415 - mDice: 0.7089 - val_loss: 0.8225 - val_acc: 0.9420 - val_mDice: 0.5592

Epoch 00041: val_mDice did not improve from 0.58330
Epoch 42/300
 - 10s - loss: 0.3221 - acc: 0.9417 - mDice: 0.7103 - val_loss: 0.8017 - val_acc: 0.9382 - val_mDice: 0.5508

Epoch 00042: val_mDice did not improve from 0.58330
Epoch 43/300
 - 10s - loss: 0.3197 - acc: 0.9420 - mDice: 0.7120 - val_loss: 0.7562 - val_acc: 0.9392 - val_mDice: 0.5711

Epoch 00043: val_mDice did not improve from 0.58330
Epoch 44/300
 - 11s - loss: 0.3194 - acc: 0.9421 - mDice: 0.7123 - val_loss: 0.7224 - val_acc: 0.9426 - val_mDice: 0.5669

Epoch 00044: val_mDice did not improve from 0.58330
Epoch 45/300
 - 11s - loss: 0.3195 - acc: 0.9420 - mDice: 0.7121 - val_loss: 0.7965 - val_acc: 0.9321 - val_mDice: 0.5505

Epoch 00045: val_mDice did not improve from 0.58330
Epoch 46/300
 - 10s - loss: 0.3194 - acc: 0.9420 - mDice: 0.7123 - val_loss: 0.7161 - val_acc: 0.9425 - val_mDice: 0.5671

Epoch 00046: val_mDice did not improve from 0.58330
Epoch 47/300
 - 10s - loss: 0.3165 - acc: 0.9422 - mDice: 0.7145 - val_loss: 0.8225 - val_acc: 0.9401 - val_mDice: 0.5516

Epoch 00047: val_mDice did not improve from 0.58330
Epoch 48/300
 - 10s - loss: 0.3147 - acc: 0.9424 - mDice: 0.7158 - val_loss: 0.7385 - val_acc: 0.9356 - val_mDice: 0.5566

Epoch 00048: val_mDice did not improve from 0.58330
Epoch 49/300
 - 10s - loss: 0.3149 - acc: 0.9423 - mDice: 0.7156 - val_loss: 0.7337 - val_acc: 0.9408 - val_mDice: 0.5611

Epoch 00049: val_mDice did not improve from 0.58330
Epoch 50/300
 - 11s - loss: 0.3136 - acc: 0.9426 - mDice: 0.7166 - val_loss: 0.7137 - val_acc: 0.9413 - val_mDice: 0.5606

Epoch 00050: val_mDice did not improve from 0.58330
Epoch 51/300
 - 10s - loss: 0.3113 - acc: 0.9427 - mDice: 0.7183 - val_loss: 0.7145 - val_acc: 0.9432 - val_mDice: 0.5616

Epoch 00051: val_mDice did not improve from 0.58330
Epoch 52/300
 - 10s - loss: 0.3102 - acc: 0.9427 - mDice: 0.7192 - val_loss: 0.7204 - val_acc: 0.9442 - val_mDice: 0.5727

Epoch 00052: val_mDice did not improve from 0.58330
Epoch 53/300
 - 10s - loss: 0.3123 - acc: 0.9425 - mDice: 0.7176 - val_loss: 0.7060 - val_acc: 0.9446 - val_mDice: 0.5501

Epoch 00053: val_mDice did not improve from 0.58330
Epoch 54/300
 - 10s - loss: 0.3072 - acc: 0.9431 - mDice: 0.7213 - val_loss: 0.7053 - val_acc: 0.9403 - val_mDice: 0.5681

Epoch 00054: val_mDice did not improve from 0.58330
Epoch 55/300
 - 11s - loss: 0.3101 - acc: 0.9429 - mDice: 0.7192 - val_loss: 0.6674 - val_acc: 0.9439 - val_mDice: 0.5502

Epoch 00055: val_mDice did not improve from 0.58330
Epoch 56/300
 - 10s - loss: 0.3083 - acc: 0.9428 - mDice: 0.7205 - val_loss: 0.7685 - val_acc: 0.9396 - val_mDice: 0.5584

Epoch 00056: val_mDice did not improve from 0.58330
Epoch 57/300
 - 10s - loss: 0.3051 - acc: 0.9432 - mDice: 0.7228 - val_loss: 0.6716 - val_acc: 0.9412 - val_mDice: 0.5682

Epoch 00057: val_mDice did not improve from 0.58330
Epoch 58/300
 - 11s - loss: 0.3060 - acc: 0.9432 - mDice: 0.7223 - val_loss: 0.6915 - val_acc: 0.9371 - val_mDice: 0.5480

Epoch 00058: val_mDice did not improve from 0.58330
Epoch 59/300
 - 11s - loss: 0.3036 - acc: 0.9434 - mDice: 0.7240 - val_loss: 0.6271 - val_acc: 0.9434 - val_mDice: 0.5789

Epoch 00059: val_mDice did not improve from 0.58330
Epoch 60/300
 - 10s - loss: 0.3038 - acc: 0.9434 - mDice: 0.7239 - val_loss: 0.6264 - val_acc: 0.9429 - val_mDice: 0.5730

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.01s/it]predicting test subjects: 100%|██████████| 3/3 [00:04<00:00,  1.79s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:25,  1.78s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:42,  1.63s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:35,  1.62s/it]predicting train subjects:   1%|▏         | 4/285 [00:05<07:09,  1.53s/it]predicting train subjects:   2%|▏         | 5/285 [00:07<07:25,  1.59s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:01,  1.51s/it]predicting train subjects:   2%|▏         | 7/285 [00:10<07:21,  1.59s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:13,  1.56s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:35,  1.65s/it]predicting train subjects:   4%|▎         | 10/285 [00:15<07:45,  1.69s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:25,  1.63s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:39,  1.68s/it]predicting train subjects:   5%|▍         | 13/285 [00:20<07:25,  1.64s/it]predicting train subjects:   5%|▍         | 14/285 [00:22<07:31,  1.67s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:43,  1.72s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<07:52,  1.76s/it]predicting train subjects:   6%|▌         | 17/285 [00:27<07:36,  1.70s/it]predicting train subjects:   6%|▋         | 18/285 [00:29<07:35,  1.70s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:19,  1.65s/it]predicting train subjects:   7%|▋         | 20/285 [00:32<07:27,  1.69s/it]predicting train subjects:   7%|▋         | 21/285 [00:34<07:41,  1.75s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:18,  1.67s/it]predicting train subjects:   8%|▊         | 23/285 [00:37<07:20,  1.68s/it]predicting train subjects:   8%|▊         | 24/285 [00:39<07:00,  1.61s/it]predicting train subjects:   9%|▉         | 25/285 [00:41<07:18,  1.69s/it]predicting train subjects:   9%|▉         | 26/285 [00:43<07:45,  1.80s/it]predicting train subjects:   9%|▉         | 27/285 [00:44<07:20,  1.71s/it]predicting train subjects:  10%|▉         | 28/285 [00:46<07:27,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:48<07:29,  1.76s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:38,  1.80s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:43,  1.82s/it]predicting train subjects:  11%|█         | 32/285 [00:53<07:21,  1.74s/it]predicting train subjects:  12%|█▏        | 33/285 [00:55<07:24,  1.76s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:27,  1.78s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:29,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:00<07:08,  1.72s/it]predicting train subjects:  13%|█▎        | 37/285 [01:02<07:08,  1.73s/it]predicting train subjects:  13%|█▎        | 38/285 [01:04<07:16,  1.77s/it]predicting train subjects:  14%|█▎        | 39/285 [01:05<06:52,  1.68s/it]predicting train subjects:  14%|█▍        | 40/285 [01:07<06:55,  1.70s/it]predicting train subjects:  14%|█▍        | 41/285 [01:08<06:39,  1.64s/it]predicting train subjects:  15%|█▍        | 42/285 [01:10<06:26,  1.59s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:36,  1.64s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:47,  1.69s/it]predicting train subjects:  16%|█▌        | 45/285 [01:15<06:31,  1.63s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:38,  1.67s/it]predicting train subjects:  16%|█▋        | 47/285 [01:18<06:22,  1.61s/it]predicting train subjects:  17%|█▋        | 48/285 [01:20<06:32,  1.66s/it]predicting train subjects:  17%|█▋        | 49/285 [01:22<06:50,  1.74s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:49,  1.74s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<07:00,  1.80s/it]predicting train subjects:  18%|█▊        | 52/285 [01:27<06:42,  1.73s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:43,  1.74s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:48,  1.77s/it]predicting train subjects:  19%|█▉        | 55/285 [01:32<06:28,  1.69s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:33,  1.72s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:26,  1.69s/it]predicting train subjects:  20%|██        | 58/285 [01:37<06:27,  1.71s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:36,  1.76s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:46,  1.81s/it]predicting train subjects:  21%|██▏       | 61/285 [01:43<06:24,  1.72s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:27,  1.74s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:24,  1.73s/it]predicting train subjects:  22%|██▏       | 64/285 [01:48<06:12,  1.69s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:19,  1.72s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:14,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:53<06:14,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<06:01,  1.67s/it]predicting train subjects:  24%|██▍       | 69/285 [01:56<06:02,  1.68s/it]predicting train subjects:  25%|██▍       | 70/285 [01:58<06:06,  1.71s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<06:10,  1.73s/it]predicting train subjects:  25%|██▌       | 72/285 [02:01<05:59,  1.69s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<06:04,  1.72s/it]predicting train subjects:  26%|██▌       | 74/285 [02:05<05:58,  1.70s/it]predicting train subjects:  26%|██▋       | 75/285 [02:07<05:57,  1.70s/it]predicting train subjects:  27%|██▋       | 76/285 [02:08<05:59,  1.72s/it]predicting train subjects:  27%|██▋       | 77/285 [02:10<05:47,  1.67s/it]predicting train subjects:  27%|██▋       | 78/285 [02:12<05:40,  1.64s/it]predicting train subjects:  28%|██▊       | 79/285 [02:13<05:43,  1.67s/it]predicting train subjects:  28%|██▊       | 80/285 [02:15<05:42,  1.67s/it]predicting train subjects:  28%|██▊       | 81/285 [02:16<05:34,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:18<05:39,  1.67s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:33,  1.65s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:27,  1.63s/it]predicting train subjects:  30%|██▉       | 85/285 [02:23<05:32,  1.66s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:40,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:42,  1.73s/it]predicting train subjects:  31%|███       | 88/285 [02:28<05:30,  1.68s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:33,  1.70s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:37,  1.73s/it]predicting train subjects:  32%|███▏      | 91/285 [02:33<05:28,  1.69s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:34,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:25,  1.69s/it]predicting train subjects:  33%|███▎      | 94/285 [02:39<05:24,  1.70s/it]predicting train subjects:  33%|███▎      | 95/285 [02:40<05:26,  1.72s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:22,  1.71s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:29,  1.76s/it]predicting train subjects:  34%|███▍      | 98/285 [02:46<05:26,  1.74s/it]predicting train subjects:  35%|███▍      | 99/285 [02:47<05:18,  1.71s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:15,  1.70s/it]predicting train subjects:  35%|███▌      | 101/285 [02:50<05:02,  1.64s/it]predicting train subjects:  36%|███▌      | 102/285 [02:52<05:08,  1.69s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<04:58,  1.64s/it]predicting train subjects:  36%|███▋      | 104/285 [02:55<04:57,  1.64s/it]predicting train subjects:  37%|███▋      | 105/285 [02:57<05:00,  1.67s/it]predicting train subjects:  37%|███▋      | 106/285 [02:59<04:55,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [03:00<04:54,  1.65s/it]predicting train subjects:  38%|███▊      | 108/285 [03:02<04:45,  1.62s/it]predicting train subjects:  38%|███▊      | 109/285 [03:04<04:48,  1.64s/it]predicting train subjects:  39%|███▊      | 110/285 [03:05<04:52,  1.67s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<04:41,  1.62s/it]predicting train subjects:  39%|███▉      | 112/285 [03:08<04:39,  1.61s/it]predicting train subjects:  40%|███▉      | 113/285 [03:10<04:46,  1.67s/it]predicting train subjects:  40%|████      | 114/285 [03:12<04:46,  1.67s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:45,  1.68s/it]predicting train subjects:  41%|████      | 116/285 [03:15<04:46,  1.70s/it]predicting train subjects:  41%|████      | 117/285 [03:17<04:35,  1.64s/it]predicting train subjects:  41%|████▏     | 118/285 [03:18<04:30,  1.62s/it]predicting train subjects:  42%|████▏     | 119/285 [03:20<04:37,  1.67s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:29,  1.63s/it]predicting train subjects:  42%|████▏     | 121/285 [03:23<04:19,  1.58s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:09,  1.53s/it]predicting train subjects:  43%|████▎     | 123/285 [03:26<03:58,  1.47s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:01,  1.50s/it]predicting train subjects:  44%|████▍     | 125/285 [03:29<03:54,  1.46s/it]predicting train subjects:  44%|████▍     | 126/285 [03:30<03:46,  1.42s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:45,  1.42s/it]predicting train subjects:  45%|████▍     | 128/285 [03:33<03:50,  1.47s/it]predicting train subjects:  45%|████▌     | 129/285 [03:35<03:47,  1.46s/it]predicting train subjects:  46%|████▌     | 130/285 [03:36<03:40,  1.42s/it]predicting train subjects:  46%|████▌     | 131/285 [03:37<03:35,  1.40s/it]predicting train subjects:  46%|████▋     | 132/285 [03:39<03:41,  1.45s/it]predicting train subjects:  47%|████▋     | 133/285 [03:40<03:36,  1.42s/it]predicting train subjects:  47%|████▋     | 134/285 [03:42<03:31,  1.40s/it]predicting train subjects:  47%|████▋     | 135/285 [03:43<03:26,  1.38s/it]predicting train subjects:  48%|████▊     | 136/285 [03:44<03:25,  1.38s/it]predicting train subjects:  48%|████▊     | 137/285 [03:46<03:33,  1.44s/it]predicting train subjects:  48%|████▊     | 138/285 [03:47<03:24,  1.39s/it]predicting train subjects:  49%|████▉     | 139/285 [03:49<03:29,  1.44s/it]predicting train subjects:  49%|████▉     | 140/285 [03:50<03:30,  1.45s/it]predicting train subjects:  49%|████▉     | 141/285 [03:52<03:24,  1.42s/it]predicting train subjects:  50%|████▉     | 142/285 [03:53<03:21,  1.41s/it]predicting train subjects:  50%|█████     | 143/285 [03:54<03:18,  1.40s/it]predicting train subjects:  51%|█████     | 144/285 [03:56<03:23,  1.44s/it]predicting train subjects:  51%|█████     | 145/285 [03:57<03:19,  1.43s/it]predicting train subjects:  51%|█████     | 146/285 [03:59<03:23,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:00<03:18,  1.44s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:02<03:22,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:03<03:15,  1.44s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:05<03:10,  1.41s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:06<03:13,  1.44s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:07<03:07,  1.41s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:09<03:04,  1.40s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:10<03:05,  1.42s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:12<03:03,  1.41s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:13<03:07,  1.45s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:14<03:02,  1.42s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:16<02:58,  1.41s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:17<02:58,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:19<02:56,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:20<02:58,  1.44s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:22<02:54,  1.42s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:23<02:55,  1.44s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:24<02:50,  1.41s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:26<02:47,  1.39s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:27<02:49,  1.42s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:29<02:53,  1.47s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:30<02:49,  1.45s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:32<02:45,  1.43s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:33<02:40,  1.40s/it]predicting train subjects:  60%|██████    | 171/285 [04:34<02:37,  1.39s/it]predicting train subjects:  60%|██████    | 172/285 [04:36<02:37,  1.40s/it]predicting train subjects:  61%|██████    | 173/285 [04:37<02:35,  1.39s/it]predicting train subjects:  61%|██████    | 174/285 [04:38<02:32,  1.37s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:40<02:37,  1.43s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:42<02:40,  1.47s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:43<02:34,  1.43s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:44<02:30,  1.41s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:46<02:28,  1.40s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:47<02:36,  1.49s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:49<02:41,  1.55s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:51<02:41,  1.57s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:52<02:32,  1.49s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:53<02:25,  1.44s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:55<02:19,  1.39s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:56<02:29,  1.51s/it]predicting train subjects:  66%|██████▌   | 187/285 [04:58<02:36,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:00<02:41,  1.66s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:01<02:28,  1.55s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:03<02:21,  1.49s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:04<02:22,  1.52s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:06<02:23,  1.55s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:07<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:08<02:11,  1.45s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:10<02:05,  1.40s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:11<02:12,  1.49s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:13<02:18,  1.57s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:15<02:21,  1.62s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:16<02:10,  1.52s/it]predicting train subjects:  70%|███████   | 200/285 [05:18<02:03,  1.45s/it]predicting train subjects:  71%|███████   | 201/285 [05:19<02:08,  1.53s/it]predicting train subjects:  71%|███████   | 202/285 [05:21<02:06,  1.53s/it]predicting train subjects:  71%|███████   | 203/285 [05:22<02:06,  1.54s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:24<01:58,  1.47s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:25<01:53,  1.42s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:26<01:50,  1.40s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:28<01:57,  1.51s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:30<02:02,  1.59s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:32<02:03,  1.62s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:33<01:54,  1.52s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:34<01:49,  1.48s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:36<01:51,  1.52s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:37<01:48,  1.51s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:39<01:42,  1.45s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:40<01:46,  1.53s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:42<01:40,  1.46s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:43<01:45,  1.55s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:45<01:48,  1.63s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:47<01:49,  1.66s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:48<01:40,  1.55s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:50<01:35,  1.50s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:51<01:35,  1.52s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:52<01:30,  1.46s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:54<01:27,  1.44s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:55<01:23,  1.39s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:57<01:27,  1.49s/it]predicting train subjects:  80%|███████▉  | 227/285 [05:59<01:29,  1.54s/it]predicting train subjects:  80%|████████  | 228/285 [06:00<01:30,  1.59s/it]predicting train subjects:  80%|████████  | 229/285 [06:02<01:28,  1.58s/it]predicting train subjects:  81%|████████  | 230/285 [06:03<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [06:04<01:18,  1.46s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:06<01:19,  1.50s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:07<01:15,  1.46s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:09<01:17,  1.53s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:10<01:12,  1.46s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:12<01:16,  1.55s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:14<01:16,  1.60s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:16<01:17,  1.64s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:17<01:14,  1.63s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:19<01:09,  1.54s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:20<01:04,  1.48s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:21<01:01,  1.42s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:23<00:58,  1.39s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:24<01:00,  1.48s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:25<00:56,  1.42s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:27<00:58,  1.51s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:29<00:59,  1.57s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:30<00:58,  1.58s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:32<00:54,  1.51s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:33<00:51,  1.47s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:35<00:48,  1.43s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:36<00:46,  1.39s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:38<00:48,  1.51s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:39<00:49,  1.58s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:41<00:47,  1.57s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:42<00:43,  1.49s/it]predicting train subjects:  90%|█████████ | 257/285 [06:44<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [06:45<00:41,  1.55s/it]predicting train subjects:  91%|█████████ | 259/285 [06:47<00:40,  1.57s/it]predicting train subjects:  91%|█████████ | 260/285 [06:48<00:36,  1.47s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:50<00:34,  1.43s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:51<00:31,  1.38s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:52<00:29,  1.35s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:54<00:30,  1.46s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:56<00:30,  1.53s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:57<00:27,  1.45s/it]predicting train subjects:  94%|█████████▎| 267/285 [06:58<00:25,  1.43s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:00<00:25,  1.52s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:02<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:03<00:22,  1.48s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:04<00:20,  1.43s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:06<00:19,  1.47s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:07<00:17,  1.42s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:08<00:15,  1.37s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:10<00:14,  1.48s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:12<00:14,  1.59s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:13<00:12,  1.51s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:15<00:10,  1.50s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:16<00:09,  1.54s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:18<00:07,  1.49s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:19<00:05,  1.46s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:20<00:04,  1.42s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:22<00:03,  1.55s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:24<00:01,  1.62s/it]predicting train subjects: 100%|██████████| 285/285 [07:26<00:00,  1.67s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:14,  1.74s/it]Loading train:   1%|          | 2/285 [00:03<07:38,  1.62s/it]Loading train:   1%|          | 3/285 [00:04<07:27,  1.59s/it]
Epoch 00060: val_mDice did not improve from 0.58330
Restoring model weights from the end of the best epoch
Epoch 00060: early stopping
{'val_loss': [2.128745192573184, 1.3787541275932675, 1.1441287767319452, 1.1145949817839123, 1.0485218479519798, 1.0330662727355957, 0.9642209325517926, 1.0179105940319242, 1.06281954901559, 0.9110257739112491, 0.9210509118579683, 0.9534651438395182, 0.939287889571417, 0.9211145469120571, 0.93215545018514, 0.926405532019479, 0.9194387254260835, 0.8950909887041364, 0.8850264095124745, 0.8346081915355864, 0.8890899476550874, 0.9015763827732631, 0.8954914865039644, 0.8822986625489735, 0.8861218747638521, 0.8837723050798688, 0.8562377293904623, 0.8382961636497861, 0.852331592923119, 0.836198784056164, 0.850727399190267, 0.8512186095828101, 0.8443345796494257, 0.8780243964422316, 0.8945470537458148, 0.8281757490975517, 0.7869368394215902, 0.8028359980810256, 0.799736567905971, 0.7809575569062006, 0.8225495020548502, 0.8016517162322998, 0.7561564331962949, 0.7223937738509405, 0.7964603219713483, 0.7161499488921392, 0.8224882852463495, 0.7384956904820034, 0.7336891038077218, 0.7136711847214472, 0.7145015058063325, 0.7203697193236578, 0.705977031162807, 0.7053097600028628, 0.6673691272735596, 0.768467630658831, 0.6715735197067261, 0.691518193199521, 0.6270717268898374, 0.6264369487762451], 'val_acc': [0.904567301273346, 0.9115338779631115, 0.9214949721381778, 0.9280288560049874, 0.9359707094374157, 0.9301327807562692, 0.9372435609499613, 0.9184317588806152, 0.9365453038896833, 0.9404029079845974, 0.9287110964457194, 0.9394024865967887, 0.9412041930925279, 0.9365064076014927, 0.9414606065977187, 0.9411652882893881, 0.9428663026718866, 0.9418406770342872, 0.9393566790081206, 0.9412270983060201, 0.94395835626693, 0.9363186898685637, 0.9428182471366156, 0.9436423750150771, 0.9407875651404971, 0.9359684331076485, 0.9354326923688253, 0.9346657281830197, 0.9363828074364435, 0.9376854612713769, 0.932012364977882, 0.9421680399349758, 0.9446726271084377, 0.941092054049174, 0.9428434116499764, 0.9407990120706105, 0.9368269046147665, 0.9353434273174831, 0.937495401927403, 0.938992664927528, 0.9419780061358497, 0.938202821073078, 0.939152941817329, 0.9426167777606419, 0.9321131053425017, 0.942518310887473, 0.9400869863373893, 0.9356433124769301, 0.9408058807963416, 0.9413026599656968, 0.9431776659829276, 0.9441666830153692, 0.9446268507412502, 0.940343405519213, 0.9438599035853431, 0.9396290949412754, 0.9411538356826419, 0.9371107986995152, 0.9434340397516886, 0.942859431107839], 'val_mDice': [0.246727331053643, 0.4271457539427848, 0.5047473421409017, 0.508839955464715, 0.535318153599898, 0.5375161972783861, 0.5640729098092943, 0.5285144934342021, 0.5095168340596414, 0.5767113053727717, 0.5601127422636464, 0.5513469858893326, 0.5591916892500151, 0.558543191424438, 0.5512066291911262, 0.5553872869128272, 0.5553941258362362, 0.5615679891336531, 0.5618248326437814, 0.5833043425920463, 0.5650345835657347, 0.5469984396227768, 0.5602518093018305, 0.5621696751387346, 0.5539764073633012, 0.5473160207981155, 0.5491733990964436, 0.5637064347309726, 0.5532533723328795, 0.564783933439425, 0.5487763597851708, 0.5583413654849643, 0.5553453451111203, 0.5389269242684046, 0.5281733386218548, 0.5446226971135253, 0.5603451826387927, 0.5529957745401632, 0.5588435734666529, 0.5721390641161374, 0.5592340975999832, 0.550838384422518, 0.5710811804802645, 0.5669082314485595, 0.5505010510484377, 0.5670900131974902, 0.5516087888252168, 0.5565782272744746, 0.5611462337630135, 0.5605636038595722, 0.5616189401064601, 0.5726874818404516, 0.5500694064512139, 0.5681232765671753, 0.5501679689401672, 0.5583732369400206, 0.5682385045857656, 0.548040276304597, 0.5789045666654905, 0.573037373877707], 'loss': [2.8477777297588265, 1.0179031085182022, 0.7019647935440206, 0.5966085638065938, 0.5335476475114052, 0.4970615549781131, 0.47159535721797624, 0.45319543789525657, 0.4392139923372594, 0.4271141887285679, 0.4153821791542135, 0.40704468077079903, 0.4006724025050822, 0.39662073574728973, 0.3873048019714845, 0.3845012173306535, 0.3807114084458245, 0.3763859511364028, 0.37179101939511155, 0.36815340977563593, 0.36614653918585477, 0.3617042541929079, 0.3619939333640566, 0.3571298837156132, 0.3549997049396567, 0.3522155581928067, 0.350364368793154, 0.3469051157081428, 0.3442702207844313, 0.3433232441478459, 0.34178135818844013, 0.3381325552142698, 0.3355393369682313, 0.33347584489615917, 0.33361840141240123, 0.3314425024380453, 0.3290964819193576, 0.3268041303731445, 0.32670237312133954, 0.32583707132641926, 0.3239641030709914, 0.32205092611629105, 0.31970490154696957, 0.319399683030097, 0.31951943028402946, 0.31936056882930164, 0.31645397361887195, 0.314721218579441, 0.3149355282116102, 0.3136432760306951, 0.3112552344327904, 0.31015678053764517, 0.31230130750870505, 0.3072303824395326, 0.3100841776562123, 0.30834720691251966, 0.30510301881956187, 0.30599402578115603, 0.30364649838074703, 0.3038071211372149], 'acc': [0.6525652377114076, 0.8749589631386017, 0.8828636174236898, 0.8933729930767003, 0.9094200937394488, 0.9217000991157743, 0.926694484960833, 0.9291541079507758, 0.9303881698475652, 0.931604761274789, 0.9328752060214149, 0.9335341156735594, 0.9340547204063604, 0.9345656532139959, 0.93553887241857, 0.9358064407371064, 0.9360680299754867, 0.9364722138405398, 0.9371241078639688, 0.9374526342215831, 0.9375780681803526, 0.9380862472005402, 0.9379982180234115, 0.9386266618880873, 0.9388514977786636, 0.9390770510048772, 0.9389941904249278, 0.9393770825731885, 0.9396215186129192, 0.9397814311410321, 0.9398336129218874, 0.9404048934616241, 0.9403959002273262, 0.9407489688520099, 0.9407829856031406, 0.9408971311178699, 0.9412660488784486, 0.9414246572288953, 0.9411670796232736, 0.941402832103966, 0.9415310178622129, 0.941748278217323, 0.9419989731814191, 0.942060631250448, 0.9419713063301643, 0.9419774006321776, 0.9421790183820039, 0.942398453243716, 0.9423249772754689, 0.942594399290414, 0.9426894964844545, 0.9427052490486445, 0.9425232130850996, 0.9430811709352879, 0.9428959564250721, 0.9428272724312488, 0.9431697293377713, 0.9431669494194265, 0.9433792504428645, 0.9433796934040842], 'mDice': [0.1019986838936168, 0.36133083852817033, 0.4809547296971376, 0.5351137421897365, 0.5709986353003269, 0.5926693990691586, 0.6084743064677575, 0.620237723512872, 0.628964362517703, 0.6371019658082617, 0.6448903460711304, 0.6503079000502072, 0.6546255291508001, 0.6575537617321026, 0.6639427828011955, 0.6658540442887588, 0.6683792459705052, 0.6714195193917116, 0.6747318258491444, 0.6772257321966115, 0.6785960448415655, 0.6817651354487471, 0.6815444778931814, 0.6850362225651672, 0.6865899455278439, 0.6884929312891139, 0.689760561115323, 0.6922345713243472, 0.6942546323978858, 0.6948658943015393, 0.6960447723750138, 0.6985885169502856, 0.7004867613671808, 0.7019739993073151, 0.7018539433606171, 0.7034232467499132, 0.7051736402768999, 0.7068482108582231, 0.7068834350774209, 0.7075687401184853, 0.7088671905102242, 0.7103445758152174, 0.7119713989967139, 0.7122623810355365, 0.7120991183632667, 0.712317275856188, 0.7145255690069586, 0.7157606510659139, 0.7155918699251289, 0.7165648157435253, 0.7182622988811918, 0.71915207257132, 0.7175933375095663, 0.7212708365349543, 0.7192023834535007, 0.720519968843745, 0.7228451496676395, 0.7222602672836145, 0.7239574499849136, 0.7238783524494675]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0Loading train:   1%|▏         | 4/285 [00:05<07:03,  1.51s/it]Loading train:   2%|▏         | 5/285 [00:07<07:10,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:08<06:50,  1.47s/it]Loading train:   2%|▏         | 7/285 [00:10<07:03,  1.52s/it]Loading train:   3%|▎         | 8/285 [00:11<06:52,  1.49s/it]Loading train:   3%|▎         | 9/285 [00:13<07:40,  1.67s/it]Loading train:   4%|▎         | 10/285 [00:15<06:57,  1.52s/it]Loading train:   4%|▍         | 11/285 [00:16<06:17,  1.38s/it]Loading train:   4%|▍         | 12/285 [00:17<06:18,  1.39s/it]Loading train:   5%|▍         | 13/285 [00:18<05:48,  1.28s/it]Loading train:   5%|▍         | 14/285 [00:19<05:37,  1.25s/it]Loading train:   5%|▌         | 15/285 [00:21<05:38,  1.25s/it]Loading train:   6%|▌         | 16/285 [00:22<05:36,  1.25s/it]Loading train:   6%|▌         | 17/285 [00:23<05:12,  1.17s/it]Loading train:   6%|▋         | 18/285 [00:24<05:02,  1.13s/it]Loading train:   7%|▋         | 19/285 [00:25<04:46,  1.08s/it]Loading train:   7%|▋         | 20/285 [00:26<04:31,  1.02s/it]Loading train:   7%|▋         | 21/285 [00:27<05:01,  1.14s/it]Loading train:   8%|▊         | 22/285 [00:28<04:55,  1.12s/it]Loading train:   8%|▊         | 23/285 [00:29<04:44,  1.09s/it]Loading train:   8%|▊         | 24/285 [00:30<04:44,  1.09s/it]Loading train:   9%|▉         | 25/285 [00:31<04:52,  1.13s/it]Loading train:   9%|▉         | 26/285 [00:33<05:12,  1.20s/it]Loading train:   9%|▉         | 27/285 [00:34<05:02,  1.17s/it]Loading train:  10%|▉         | 28/285 [00:35<04:45,  1.11s/it]Loading train:  10%|█         | 29/285 [00:36<04:44,  1.11s/it]Loading train:  11%|█         | 30/285 [00:37<04:51,  1.14s/it]Loading train:  11%|█         | 31/285 [00:39<05:09,  1.22s/it]Loading train:  11%|█         | 32/285 [00:40<04:53,  1.16s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:51,  1.16s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:37,  1.11s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:35,  1.10s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:25,  1.07s/it]Loading train:  13%|█▎        | 37/285 [00:45<04:16,  1.03s/it]Loading train:  13%|█▎        | 38/285 [00:46<04:34,  1.11s/it]Loading train:  14%|█▎        | 39/285 [00:47<04:20,  1.06s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:18,  1.06s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:14,  1.04s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:08,  1.02s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:18,  1.07s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:29,  1.12s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:19,  1.08s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:31,  1.14s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:19,  1.09s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:15,  1.08s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:25,  1.12s/it]Loading train:  18%|█▊        | 50/285 [00:59<04:12,  1.08s/it]Loading train:  18%|█▊        | 51/285 [01:00<04:24,  1.13s/it]Loading train:  18%|█▊        | 52/285 [01:01<04:24,  1.14s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:19,  1.12s/it]Loading train:  19%|█▉        | 54/285 [01:04<04:31,  1.18s/it]Loading train:  19%|█▉        | 55/285 [01:05<04:29,  1.17s/it]Loading train:  20%|█▉        | 56/285 [01:06<04:22,  1.15s/it]Loading train:  20%|██        | 57/285 [01:07<04:05,  1.08s/it]Loading train:  20%|██        | 58/285 [01:08<03:55,  1.04s/it]Loading train:  21%|██        | 59/285 [01:09<04:05,  1.08s/it]Loading train:  21%|██        | 60/285 [01:10<04:10,  1.11s/it]Loading train:  21%|██▏       | 61/285 [01:11<04:05,  1.09s/it]Loading train:  22%|██▏       | 62/285 [01:12<04:01,  1.08s/it]Loading train:  22%|██▏       | 63/285 [01:14<04:06,  1.11s/it]Loading train:  22%|██▏       | 64/285 [01:15<04:38,  1.26s/it]Loading train:  23%|██▎       | 65/285 [01:17<04:58,  1.36s/it]Loading train:  23%|██▎       | 66/285 [01:18<04:58,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:19<04:38,  1.28s/it]Loading train:  24%|██▍       | 68/285 [01:20<04:34,  1.26s/it]Loading train:  24%|██▍       | 69/285 [01:22<04:29,  1.25s/it]Loading train:  25%|██▍       | 70/285 [01:23<04:25,  1.24s/it]Loading train:  25%|██▍       | 71/285 [01:24<04:12,  1.18s/it]Loading train:  25%|██▌       | 72/285 [01:25<03:54,  1.10s/it]Loading train:  26%|██▌       | 73/285 [01:26<03:48,  1.08s/it]Loading train:  26%|██▌       | 74/285 [01:27<03:40,  1.04s/it]Loading train:  26%|██▋       | 75/285 [01:28<03:36,  1.03s/it]Loading train:  27%|██▋       | 76/285 [01:29<03:32,  1.01s/it]Loading train:  27%|██▋       | 77/285 [01:30<03:24,  1.02it/s]Loading train:  27%|██▋       | 78/285 [01:31<03:22,  1.02it/s]Loading train:  28%|██▊       | 79/285 [01:32<03:27,  1.01s/it]Loading train:  28%|██▊       | 80/285 [01:33<03:32,  1.04s/it]Loading train:  28%|██▊       | 81/285 [01:34<03:28,  1.02s/it]Loading train:  29%|██▉       | 82/285 [01:35<03:31,  1.04s/it]Loading train:  29%|██▉       | 83/285 [01:36<03:20,  1.01it/s]Loading train:  29%|██▉       | 84/285 [01:37<03:28,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:38<03:37,  1.09s/it]Loading train:  30%|███       | 86/285 [01:39<03:39,  1.11s/it]Loading train:  31%|███       | 87/285 [01:40<03:36,  1.09s/it]Loading train:  31%|███       | 88/285 [01:41<03:30,  1.07s/it]Loading train:  31%|███       | 89/285 [01:42<03:31,  1.08s/it]Loading train:  32%|███▏      | 90/285 [01:44<03:32,  1.09s/it]Loading train:  32%|███▏      | 91/285 [01:45<03:28,  1.08s/it]Loading train:  32%|███▏      | 92/285 [01:46<03:27,  1.07s/it]Loading train:  33%|███▎      | 93/285 [01:47<03:18,  1.03s/it]Loading train:  33%|███▎      | 94/285 [01:48<03:12,  1.01s/it]Loading train:  33%|███▎      | 95/285 [01:49<03:09,  1.00it/s]Loading train:  34%|███▎      | 96/285 [01:50<03:14,  1.03s/it]Loading train:  34%|███▍      | 97/285 [01:51<03:15,  1.04s/it]Loading train:  34%|███▍      | 98/285 [01:52<03:12,  1.03s/it]Loading train:  35%|███▍      | 99/285 [01:53<03:16,  1.06s/it]Loading train:  35%|███▌      | 100/285 [01:54<03:18,  1.08s/it]Loading train:  35%|███▌      | 101/285 [01:55<03:20,  1.09s/it]Loading train:  36%|███▌      | 102/285 [01:56<03:29,  1.15s/it]Loading train:  36%|███▌      | 103/285 [01:58<03:29,  1.15s/it]Loading train:  36%|███▋      | 104/285 [01:59<03:34,  1.19s/it]Loading train:  37%|███▋      | 105/285 [02:00<03:35,  1.20s/it]Loading train:  37%|███▋      | 106/285 [02:01<03:30,  1.18s/it]Loading train:  38%|███▊      | 107/285 [02:02<03:24,  1.15s/it]Loading train:  38%|███▊      | 108/285 [02:03<03:14,  1.10s/it]Loading train:  38%|███▊      | 109/285 [02:04<03:18,  1.13s/it]Loading train:  39%|███▊      | 110/285 [02:06<03:14,  1.11s/it]Loading train:  39%|███▉      | 111/285 [02:07<03:11,  1.10s/it]Loading train:  39%|███▉      | 112/285 [02:08<03:09,  1.10s/it]Loading train:  40%|███▉      | 113/285 [02:09<03:07,  1.09s/it]Loading train:  40%|████      | 114/285 [02:10<03:05,  1.09s/it]Loading train:  40%|████      | 115/285 [02:11<03:07,  1.11s/it]Loading train:  41%|████      | 116/285 [02:12<03:01,  1.08s/it]Loading train:  41%|████      | 117/285 [02:13<03:06,  1.11s/it]Loading train:  41%|████▏     | 118/285 [02:14<03:00,  1.08s/it]Loading train:  42%|████▏     | 119/285 [02:15<03:03,  1.11s/it]Loading train:  42%|████▏     | 120/285 [02:16<02:50,  1.04s/it]Loading train:  42%|████▏     | 121/285 [02:18<03:07,  1.14s/it]Loading train:  43%|████▎     | 122/285 [02:19<03:13,  1.19s/it]Loading train:  43%|████▎     | 123/285 [02:20<03:14,  1.20s/it]Loading train:  44%|████▎     | 124/285 [02:21<02:58,  1.11s/it]Loading train:  44%|████▍     | 125/285 [02:22<02:51,  1.07s/it]Loading train:  44%|████▍     | 126/285 [02:23<02:42,  1.02s/it]Loading train:  45%|████▍     | 127/285 [02:24<02:41,  1.02s/it]Loading train:  45%|████▍     | 128/285 [02:25<02:29,  1.05it/s]Loading train:  45%|████▌     | 129/285 [02:26<02:31,  1.03it/s]Loading train:  46%|████▌     | 130/285 [02:27<02:32,  1.02it/s]Loading train:  46%|████▌     | 131/285 [02:28<02:30,  1.02it/s]Loading train:  46%|████▋     | 132/285 [02:29<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:30<02:28,  1.02it/s]Loading train:  47%|████▋     | 134/285 [02:31<02:26,  1.03it/s]Loading train:  47%|████▋     | 135/285 [02:32<02:21,  1.06it/s]Loading train:  48%|████▊     | 136/285 [02:32<02:19,  1.07it/s]Loading train:  48%|████▊     | 137/285 [02:33<02:20,  1.05it/s]Loading train:  48%|████▊     | 138/285 [02:34<02:13,  1.10it/s]Loading train:  49%|████▉     | 139/285 [02:35<02:14,  1.08it/s]Loading train:  49%|████▉     | 140/285 [02:36<02:12,  1.10it/s]Loading train:  49%|████▉     | 141/285 [02:37<02:14,  1.07it/s]Loading train:  50%|████▉     | 142/285 [02:38<02:16,  1.05it/s]Loading train:  50%|█████     | 143/285 [02:39<02:09,  1.10it/s]Loading train:  51%|█████     | 144/285 [02:40<02:08,  1.10it/s]Loading train:  51%|█████     | 145/285 [02:41<02:05,  1.11it/s]Loading train:  51%|█████     | 146/285 [02:42<02:09,  1.07it/s]Loading train:  52%|█████▏    | 147/285 [02:43<02:06,  1.09it/s]Loading train:  52%|█████▏    | 148/285 [02:44<02:07,  1.07it/s]Loading train:  52%|█████▏    | 149/285 [02:44<02:08,  1.05it/s]Loading train:  53%|█████▎    | 150/285 [02:45<02:05,  1.08it/s]Loading train:  53%|█████▎    | 151/285 [02:46<02:01,  1.11it/s]Loading train:  53%|█████▎    | 152/285 [02:47<01:59,  1.11it/s]Loading train:  54%|█████▎    | 153/285 [02:48<01:57,  1.12it/s]Loading train:  54%|█████▍    | 154/285 [02:49<01:59,  1.09it/s]Loading train:  54%|█████▍    | 155/285 [02:50<02:02,  1.06it/s]Loading train:  55%|█████▍    | 156/285 [02:51<02:00,  1.07it/s]Loading train:  55%|█████▌    | 157/285 [02:52<02:01,  1.05it/s]Loading train:  55%|█████▌    | 158/285 [02:53<02:01,  1.04it/s]Loading train:  56%|█████▌    | 159/285 [02:54<01:57,  1.07it/s]Loading train:  56%|█████▌    | 160/285 [02:55<01:58,  1.05it/s]Loading train:  56%|█████▋    | 161/285 [02:56<02:02,  1.01it/s]Loading train:  57%|█████▋    | 162/285 [02:57<02:01,  1.02it/s]Loading train:  57%|█████▋    | 163/285 [02:58<01:59,  1.02it/s]Loading train:  58%|█████▊    | 164/285 [02:59<02:02,  1.01s/it]Loading train:  58%|█████▊    | 165/285 [03:00<02:03,  1.03s/it]Loading train:  58%|█████▊    | 166/285 [03:01<02:01,  1.02s/it]Loading train:  59%|█████▊    | 167/285 [03:02<01:57,  1.00it/s]Loading train:  59%|█████▉    | 168/285 [03:03<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [03:04<01:51,  1.04it/s]Loading train:  60%|█████▉    | 170/285 [03:05<01:50,  1.04it/s]Loading train:  60%|██████    | 171/285 [03:06<01:54,  1.00s/it]Loading train:  60%|██████    | 172/285 [03:07<01:48,  1.04it/s]Loading train:  61%|██████    | 173/285 [03:07<01:42,  1.09it/s]Loading train:  61%|██████    | 174/285 [03:08<01:40,  1.11it/s]Loading train:  61%|██████▏   | 175/285 [03:09<01:40,  1.10it/s]Loading train:  62%|██████▏   | 176/285 [03:10<01:44,  1.05it/s]Loading train:  62%|██████▏   | 177/285 [03:11<01:45,  1.03it/s]Loading train:  62%|██████▏   | 178/285 [03:12<01:42,  1.04it/s]Loading train:  63%|██████▎   | 179/285 [03:13<01:43,  1.03it/s]Loading train:  63%|██████▎   | 180/285 [03:14<01:45,  1.00s/it]Loading train:  64%|██████▎   | 181/285 [03:15<01:44,  1.01s/it]Loading train:  64%|██████▍   | 182/285 [03:16<01:40,  1.03it/s]Loading train:  64%|██████▍   | 183/285 [03:17<01:39,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:18<01:35,  1.06it/s]Loading train:  65%|██████▍   | 185/285 [03:19<01:32,  1.08it/s]Loading train:  65%|██████▌   | 186/285 [03:20<01:39,  1.01s/it]Loading train:  66%|██████▌   | 187/285 [03:21<01:40,  1.03s/it]Loading train:  66%|██████▌   | 188/285 [03:22<01:40,  1.03s/it]Loading train:  66%|██████▋   | 189/285 [03:23<01:37,  1.02s/it]Loading train:  67%|██████▋   | 190/285 [03:24<01:30,  1.05it/s]Loading train:  67%|██████▋   | 191/285 [03:25<01:28,  1.06it/s]Loading train:  67%|██████▋   | 192/285 [03:26<01:26,  1.07it/s]Loading train:  68%|██████▊   | 193/285 [03:27<01:26,  1.07it/s]Loading train:  68%|██████▊   | 194/285 [03:28<01:24,  1.08it/s]Loading train:  68%|██████▊   | 195/285 [03:29<01:23,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [03:30<01:24,  1.05it/s]Loading train:  69%|██████▉   | 197/285 [03:31<01:26,  1.01it/s]Loading train:  69%|██████▉   | 198/285 [03:32<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [03:33<01:25,  1.01it/s]Loading train:  70%|███████   | 200/285 [03:34<01:22,  1.03it/s]Loading train:  71%|███████   | 201/285 [03:35<01:29,  1.06s/it]Loading train:  71%|███████   | 202/285 [03:36<01:25,  1.03s/it]Loading train:  71%|███████   | 203/285 [03:37<01:21,  1.00it/s]Loading train:  72%|███████▏  | 204/285 [03:38<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:39<01:20,  1.01s/it]Loading train:  72%|███████▏  | 206/285 [03:40<01:16,  1.03it/s]Loading train:  73%|███████▎  | 207/285 [03:41<01:19,  1.01s/it]Loading train:  73%|███████▎  | 208/285 [03:42<01:19,  1.03s/it]Loading train:  73%|███████▎  | 209/285 [03:43<01:17,  1.02s/it]Loading train:  74%|███████▎  | 210/285 [03:44<01:15,  1.00s/it]Loading train:  74%|███████▍  | 211/285 [03:45<01:12,  1.02it/s]Loading train:  74%|███████▍  | 212/285 [03:46<01:09,  1.04it/s]Loading train:  75%|███████▍  | 213/285 [03:47<01:09,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [03:48<01:11,  1.00s/it]Loading train:  75%|███████▌  | 215/285 [03:49<01:13,  1.06s/it]Loading train:  76%|███████▌  | 216/285 [03:50<01:09,  1.01s/it]Loading train:  76%|███████▌  | 217/285 [03:51<01:09,  1.02s/it]Loading train:  76%|███████▋  | 218/285 [03:52<01:10,  1.05s/it]Loading train:  77%|███████▋  | 219/285 [03:53<01:10,  1.07s/it]Loading train:  77%|███████▋  | 220/285 [03:54<01:05,  1.01s/it]Loading train:  78%|███████▊  | 221/285 [03:55<01:02,  1.02it/s]Loading train:  78%|███████▊  | 222/285 [03:56<01:02,  1.01it/s]Loading train:  78%|███████▊  | 223/285 [03:57<01:00,  1.03it/s]Loading train:  79%|███████▊  | 224/285 [03:58<00:59,  1.03it/s]Loading train:  79%|███████▉  | 225/285 [03:59<01:01,  1.02s/it]Loading train:  79%|███████▉  | 226/285 [04:00<01:04,  1.09s/it]Loading train:  80%|███████▉  | 227/285 [04:01<01:01,  1.06s/it]Loading train:  80%|████████  | 228/285 [04:02<01:00,  1.06s/it]Loading train:  80%|████████  | 229/285 [04:04<01:01,  1.10s/it]Loading train:  81%|████████  | 230/285 [04:05<01:00,  1.09s/it]Loading train:  81%|████████  | 231/285 [04:05<00:55,  1.03s/it]Loading train:  81%|████████▏ | 232/285 [04:06<00:53,  1.01s/it]Loading train:  82%|████████▏ | 233/285 [04:07<00:51,  1.02it/s]Loading train:  82%|████████▏ | 234/285 [04:08<00:51,  1.01s/it]Loading train:  82%|████████▏ | 235/285 [04:09<00:49,  1.00it/s]Loading train:  83%|████████▎ | 236/285 [04:11<00:51,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [04:12<00:50,  1.06s/it]Loading train:  84%|████████▎ | 238/285 [04:13<00:48,  1.04s/it]Loading train:  84%|████████▍ | 239/285 [04:14<00:46,  1.01s/it]Loading train:  84%|████████▍ | 240/285 [04:15<00:45,  1.02s/it]Loading train:  85%|████████▍ | 241/285 [04:15<00:41,  1.05it/s]Loading train:  85%|████████▍ | 242/285 [04:16<00:39,  1.08it/s]Loading train:  85%|████████▌ | 243/285 [04:17<00:39,  1.06it/s]Loading train:  86%|████████▌ | 244/285 [04:18<00:41,  1.01s/it]Loading train:  86%|████████▌ | 245/285 [04:19<00:39,  1.00it/s]Loading train:  86%|████████▋ | 246/285 [04:21<00:40,  1.04s/it]Loading train:  87%|████████▋ | 247/285 [04:22<00:39,  1.05s/it]Loading train:  87%|████████▋ | 248/285 [04:23<00:37,  1.01s/it]Loading train:  87%|████████▋ | 249/285 [04:24<00:36,  1.01s/it]Loading train:  88%|████████▊ | 250/285 [04:24<00:33,  1.04it/s]Loading train:  88%|████████▊ | 251/285 [04:25<00:33,  1.01it/s]Loading train:  88%|████████▊ | 252/285 [04:26<00:32,  1.02it/s]Loading train:  89%|████████▉ | 253/285 [04:28<00:32,  1.03s/it]Loading train:  89%|████████▉ | 254/285 [04:29<00:31,  1.03s/it]Loading train:  89%|████████▉ | 255/285 [04:30<00:30,  1.01s/it]Loading train:  90%|████████▉ | 256/285 [04:30<00:27,  1.05it/s]Loading train:  90%|█████████ | 257/285 [04:31<00:25,  1.10it/s]Loading train:  91%|█████████ | 258/285 [04:32<00:25,  1.07it/s]Loading train:  91%|█████████ | 259/285 [04:33<00:25,  1.04it/s]Loading train:  91%|█████████ | 260/285 [04:34<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:35<00:21,  1.14it/s]Loading train:  92%|█████████▏| 262/285 [04:36<00:19,  1.16it/s]Loading train:  92%|█████████▏| 263/285 [04:36<00:18,  1.17it/s]Loading train:  93%|█████████▎| 264/285 [04:38<00:19,  1.07it/s]Loading train:  93%|█████████▎| 265/285 [04:39<00:18,  1.07it/s]Loading train:  93%|█████████▎| 266/285 [04:40<00:18,  1.02it/s]Loading train:  94%|█████████▎| 267/285 [04:41<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [04:42<00:17,  1.00s/it]Loading train:  94%|█████████▍| 269/285 [04:43<00:16,  1.00s/it]Loading train:  95%|█████████▍| 270/285 [04:44<00:14,  1.04it/s]Loading train:  95%|█████████▌| 271/285 [04:44<00:13,  1.07it/s]Loading train:  95%|█████████▌| 272/285 [04:45<00:12,  1.02it/s]Loading train:  96%|█████████▌| 273/285 [04:46<00:11,  1.03it/s]Loading train:  96%|█████████▌| 274/285 [04:47<00:10,  1.04it/s]Loading train:  96%|█████████▋| 275/285 [04:49<00:10,  1.03s/it]Loading train:  97%|█████████▋| 276/285 [04:50<00:09,  1.06s/it]Loading train:  97%|█████████▋| 277/285 [04:51<00:08,  1.03s/it]Loading train:  98%|█████████▊| 278/285 [04:51<00:06,  1.03it/s]Loading train:  98%|█████████▊| 279/285 [04:53<00:05,  1.01it/s]Loading train:  98%|█████████▊| 280/285 [04:53<00:04,  1.06it/s]Loading train:  99%|█████████▊| 281/285 [04:54<00:03,  1.08it/s]Loading train:  99%|█████████▉| 282/285 [04:55<00:02,  1.02it/s]Loading train:  99%|█████████▉| 283/285 [04:56<00:02,  1.00s/it]Loading train: 100%|█████████▉| 284/285 [04:57<00:01,  1.01s/it]Loading train: 100%|██████████| 285/285 [04:59<00:00,  1.04s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 62.93it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 62.13it/s]concatenating: train:  12%|█▏        | 34/285 [00:00<00:03, 78.26it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:02, 98.71it/s]concatenating: train:  31%|███       | 87/285 [00:00<00:01, 121.26it/s]concatenating: train:  41%|████      | 116/285 [00:00<00:01, 145.89it/s]concatenating: train:  49%|████▉     | 140/285 [00:00<00:00, 165.32it/s]concatenating: train:  61%|██████    | 173/285 [00:00<00:00, 193.60it/s]concatenating: train:  69%|██████▉   | 198/285 [00:00<00:00, 207.31it/s]concatenating: train:  78%|███████▊  | 223/285 [00:01<00:00, 178.42it/s]concatenating: train:  88%|████████▊ | 250/285 [00:01<00:00, 197.66it/s]concatenating: train:  97%|█████████▋| 277/285 [00:01<00:00, 214.20it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 210.28it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.41s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.41s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 95.52it/s]2019-07-11 09:52:30.228047: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 09:52:30.228168: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 09:52:30.228186: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 09:52:30.228196: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 09:52:30.228557: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:08,  5.06it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:06,  5.94it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.59it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:04,  7.21it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:00<00:05,  6.37it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:04,  6.99it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  6.19it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  8.06it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:02,  8.67it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  7.20it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  8.97it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:01,  9.32it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:02<00:01,  9.27it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  7.17it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  8.92it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  9.33it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:03<00:00,  9.56it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  7.41it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00, 10.50it/s] max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 20)   10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 52, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 52, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 52, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 80)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 246,273
Trainable params: 71,433
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 21s - loss: 1.9069 - acc: 0.6988 - mDice: 0.2537 - val_loss: 0.6979 - val_acc: 0.9176 - val_mDice: 0.5131

Epoch 00001: val_mDice improved from -inf to 0.51309, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 15s - loss: 0.5531 - acc: 0.9009 - mDice: 0.5629 - val_loss: 0.5059 - val_acc: 0.9286 - val_mDice: 0.5939

Epoch 00002: val_mDice improved from 0.51309 to 0.59391, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 15s - loss: 0.4501 - acc: 0.9081 - mDice: 0.6250 - val_loss: 0.4823 - val_acc: 0.9359 - val_mDice: 0.6093

Epoch 00003: val_mDice improved from 0.59391 to 0.60935, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 15s - loss: 0.4082 - acc: 0.9146 - mDice: 0.6523 - val_loss: 0.4553 - val_acc: 0.9375 - val_mDice: 0.6266

Epoch 00004: val_mDice improved from 0.60935 to 0.62657, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 15s - loss: 0.3891 - acc: 0.9267 - mDice: 0.6650 - val_loss: 0.4512 - val_acc: 0.9521 - val_mDice: 0.6288

Epoch 00005: val_mDice improved from 0.62657 to 0.62882, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 15s - loss: 0.3706 - acc: 0.9426 - mDice: 0.6772 - val_loss: 0.4679 - val_acc: 0.9547 - val_mDice: 0.6229

Epoch 00006: val_mDice did not improve from 0.62882
Epoch 7/300
 - 15s - loss: 0.3551 - acc: 0.9476 - mDice: 0.6874 - val_loss: 0.4575 - val_acc: 0.9549 - val_mDice: 0.6296

Epoch 00007: val_mDice improved from 0.62882 to 0.62955, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 15s - loss: 0.3449 - acc: 0.9487 - mDice: 0.6944 - val_loss: 0.5068 - val_acc: 0.9544 - val_mDice: 0.6168

Epoch 00008: val_mDice did not improve from 0.62955
Epoch 9/300
 - 15s - loss: 0.3357 - acc: 0.9497 - mDice: 0.7011 - val_loss: 0.4666 - val_acc: 0.9516 - val_mDice: 0.6214

Epoch 00009: val_mDice did not improve from 0.62955
Epoch 10/300
 - 15s - loss: 0.3281 - acc: 0.9503 - mDice: 0.7065 - val_loss: 0.4763 - val_acc: 0.9548 - val_mDice: 0.6176

Epoch 00010: val_mDice did not improve from 0.62955
Epoch 11/300
 - 15s - loss: 0.3345 - acc: 0.9501 - mDice: 0.7027 - val_loss: 0.4504 - val_acc: 0.9522 - val_mDice: 0.6274

Epoch 00011: val_mDice did not improve from 0.62955
Epoch 12/300
 - 15s - loss: 0.3193 - acc: 0.9510 - mDice: 0.7129 - val_loss: 0.4667 - val_acc: 0.9533 - val_mDice: 0.6243

Epoch 00012: val_mDice did not improve from 0.62955
Epoch 13/300
 - 15s - loss: 0.3098 - acc: 0.9518 - mDice: 0.7200 - val_loss: 0.4691 - val_acc: 0.9550 - val_mDice: 0.6221

Epoch 00013: val_mDice did not improve from 0.62955
Epoch 14/300
 - 15s - loss: 0.3033 - acc: 0.9522 - mDice: 0.7248 - val_loss: 0.4584 - val_acc: 0.9539 - val_mDice: 0.6269

Epoch 00014: val_mDice did not improve from 0.62955
Epoch 15/300
 - 15s - loss: 0.3003 - acc: 0.9525 - mDice: 0.7272 - val_loss: 0.4497 - val_acc: 0.9546 - val_mDice: 0.6308

Epoch 00015: val_mDice improved from 0.62955 to 0.63075, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 15s - loss: 0.2952 - acc: 0.9529 - mDice: 0.7310 - val_loss: 0.4816 - val_acc: 0.9553 - val_mDice: 0.6238

Epoch 00016: val_mDice did not improve from 0.63075
Epoch 17/300
 - 15s - loss: 0.2902 - acc: 0.9534 - mDice: 0.7347 - val_loss: 0.4607 - val_acc: 0.9514 - val_mDice: 0.6219

Epoch 00017: val_mDice did not improve from 0.63075
Epoch 18/300
 - 15s - loss: 0.2882 - acc: 0.9534 - mDice: 0.7364 - val_loss: 0.4785 - val_acc: 0.9559 - val_mDice: 0.6256

Epoch 00018: val_mDice did not improve from 0.63075
Epoch 19/300
 - 15s - loss: 0.2862 - acc: 0.9536 - mDice: 0.7380 - val_loss: 0.4517 - val_acc: 0.9547 - val_mDice: 0.6304

Epoch 00019: val_mDice did not improve from 0.63075
Epoch 20/300
 - 15s - loss: 0.2822 - acc: 0.9539 - mDice: 0.7408 - val_loss: 0.4508 - val_acc: 0.9543 - val_mDice: 0.6294

Epoch 00020: val_mDice did not improve from 0.63075
Epoch 21/300
 - 15s - loss: 0.2832 - acc: 0.9540 - mDice: 0.7421 - val_loss: 0.4533 - val_acc: 0.9555 - val_mDice: 0.6296

Epoch 00021: val_mDice did not improve from 0.63075
Epoch 22/300
 - 15s - loss: 0.2984 - acc: 0.9528 - mDice: 0.7295 - val_loss: 0.4316 - val_acc: 0.9559 - val_mDice: 0.6416

Epoch 00022: val_mDice improved from 0.63075 to 0.64156, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 23/300
 - 15s - loss: 0.2781 - acc: 0.9542 - mDice: 0.7439 - val_loss: 0.4513 - val_acc: 0.9538 - val_mDice: 0.6287

Epoch 00023: val_mDice did not improve from 0.64156
Epoch 24/300
 - 15s - loss: 0.2755 - acc: 0.9544 - mDice: 0.7461 - val_loss: 0.4556 - val_acc: 0.9552 - val_mDice: 0.6281

Epoch 00024: val_mDice did not improve from 0.64156
Epoch 25/300
 - 15s - loss: 0.2717 - acc: 0.9546 - mDice: 0.7489 - val_loss: 0.4682 - val_acc: 0.9557 - val_mDice: 0.6202

Epoch 00025: val_mDice did not improve from 0.64156
Epoch 26/300
 - 15s - loss: 0.2686 - acc: 0.9548 - mDice: 0.7513 - val_loss: 0.5014 - val_acc: 0.9546 - val_mDice: 0.6180

Epoch 00026: val_mDice did not improve from 0.64156
Epoch 27/300
 - 15s - loss: 0.2669 - acc: 0.9549 - mDice: 0.7527 - val_loss: 0.4530 - val_acc: 0.9554 - val_mDice: 0.6293

Epoch 00027: val_mDice did not improve from 0.64156
Epoch 28/300
 - 15s - loss: 0.2692 - acc: 0.9550 - mDice: 0.7521 - val_loss: 0.4534 - val_acc: 0.9537 - val_mDice: 0.6262

Epoch 00028: val_mDice did not improve from 0.64156
Epoch 29/300
 - 15s - loss: 0.3014 - acc: 0.9522 - mDice: 0.7267 - val_loss: 0.4660 - val_acc: 0.9537 - val_mDice: 0.6220

Epoch 00029: val_mDice did not improve from 0.64156
Epoch 30/300
 - 15s - loss: 0.2686 - acc: 0.9548 - mDice: 0.7513 - val_loss: 0.4922 - val_acc: 0.9556 - val_mDice: 0.6153

Epoch 00030: val_mDice did not improve from 0.64156
Epoch 31/300
 - 16s - loss: 0.2637 - acc: 0.9552 - mDice: 0.7551 - val_loss: 0.4508 - val_acc: 0.9558 - val_mDice: 0.6317

Epoch 00031: val_mDice did not improve from 0.64156
Epoch 32/300
 - 16s - loss: 0.2612 - acc: 0.9554 - mDice: 0.7572 - val_loss: 0.4518 - val_acc: 0.9558 - val_mDice: 0.6317

Epoch 00032: val_mDice did not improve from 0.64156
Epoch 33/300
 - 16s - loss: 0.2586 - acc: 0.9555 - mDice: 0.7592 - val_loss: 0.4702 - val_acc: 0.9544 - val_mDice: 0.6246

Epoch 00033: val_mDice did not improve from 0.64156
Epoch 34/300
 - 15s - loss: 0.2572 - acc: 0.9557 - mDice: 0.7604 - val_loss: 0.4461 - val_acc: 0.9550 - val_mDice: 0.6369

Epoch 00034: val_mDice did not improve from 0.64156
Epoch 35/300
 - 15s - loss: 0.2567 - acc: 0.9557 - mDice: 0.7607 - val_loss: 0.4771 - val_acc: 0.9543 - val_mDice: 0.6207

Epoch 00035: val_mDice did not improve from 0.64156
Epoch 36/300
 - 16s - loss: 0.2554 - acc: 0.9558 - mDice: 0.7617 - val_loss: 0.4802 - val_acc: 0.9544 - val_mDice: 0.6190

Epoch 00036: val_mDice did not improve from 0.64156
Epoch 37/300
 - 15s - loss: 0.2531 - acc: 0.9560 - mDice: 0.7637 - val_loss: 0.4855 - val_acc: 0.9552 - val_mDice: 0.6182

Epoch 00037: val_mDice did not improve from 0.64156
Epoch 38/300
 - 15s - loss: 0.2538 - acc: 0.9560 - mDice: 0.7631 - val_loss: 0.4903 - val_acc: 0.9561 - val_mDice: 0.6164

Epoch 00038: val_mDice did not improve from 0.64156
Epoch 39/300
 - 15s - loss: 0.2508 - acc: 0.9562 - mDice: 0.7655 - val_loss: 0.4685 - val_acc: 0.9549 - val_mDice: 0.6250

Epoch 00039: val_mDice did not improve from 0.64156
Epoch 40/300
 - 15s - loss: 0.2715 - acc: 0.9553 - mDice: 0.7548 - val_loss: 0.4603 - val_acc: 0.9531 - val_mDice: 0.6231

Epoch 00040: val_mDice did not improve from 0.64156
Epoch 41/300
 - 15s - loss: 0.2547 - acc: 0.9559 - mDice: 0.7623 - val_loss: 0.4575 - val_acc: 0.9563 - val_mDice: 0.6318

Epoch 00041: val_mDice did not improve from 0.64156
Epoch 42/300
 - 15s - loss: 0.2496 - acc: 0.9562 - mDice: 0.7664 - val_loss: 0.4562 - val_acc: 0.9553 - val_mDice: 0.6284

Epoch 00042: val_mDice did not improve from 0.64156
Epoch 43/300
 - 15s - loss: 0.2475 - acc: 0.9564 - mDice: 0.7682 - val_loss: 0.4607 - val_acc: 0.9540 - val_mDice: 0.6274

Epoch 00043: val_mDice did not improve from 0.64156
Epoch 44/300
 - 15s - loss: 0.2461 - acc: 0.9566 - mDice: 0.7692 - val_loss: 0.4546 - val_acc: 0.9553 - val_mDice: 0.6321

Epoch 00044: val_mDice did not improve from 0.64156
Epoch 45/300
 - 15s - loss: 0.2452 - acc: 0.9567 - mDice: 0.7700 - val_loss: 0.4622 - val_acc: 0.9569 - val_mDice: 0.6314

Epoch 00045: val_mDice did not improve from 0.64156
Epoch 46/300
 - 15s - loss: 0.2443 - acc: 0.9567 - mDice: 0.7708 - val_loss: 0.4765 - val_acc: 0.9542 - val_mDice: 0.6208

Epoch 00046: val_mDice did not improve from 0.64156
Epoch 47/300
 - 15s - loss: 0.2429 - acc: 0.9568 - mDice: 0.7719 - val_loss: 0.4624 - val_acc: 0.9526 - val_mDice: 0.6229

Epoch 00047: val_mDice did not improve from 0.64156
Epoch 48/300
 - 15s - loss: 0.2431 - acc: 0.9568 - mDice: 0.7717 - val_loss: 0.4745 - val_acc: 0.9543 - val_mDice: 0.6215

Epoch 00048: val_mDice did not improve from 0.64156
Epoch 49/300
 - 15s - loss: 0.2413 - acc: 0.9569 - mDice: 0.7731 - val_loss: 0.5168 - val_acc: 0.9540 - val_mDice: 0.6156

Epoch 00049: val_mDice did not improve from 0.64156
Epoch 50/300
 - 15s - loss: 0.2419 - acc: 0.9569 - mDice: 0.7726 - val_loss: 0.4677 - val_acc: 0.9538 - val_mDice: 0.6251

Epoch 00050: val_mDice did not improve from 0.64156
Epoch 51/300
 - 15s - loss: 0.2406 - acc: 0.9570 - mDice: 0.7737 - val_loss: 0.4630 - val_acc: 0.9546 - val_mDice: 0.6266

Epoch 00051: val_mDice did not improve from 0.64156
Epoch 52/300
 - 15s - loss: 0.2386 - acc: 0.9572 - mDice: 0.7753 - val_loss: 0.5109 - val_acc: 0.9538 - val_mDice: 0.6082

Epoch 00052: val_mDice did not improve from 0.64156
Epoch 53/300
 - 15s - loss: 0.2397 - acc: 0.9570 - mDice: 0.7744 - val_loss: 0.4879 - val_acc: 0.9544 - val_mDice: 0.6163

Epoch 00053: val_mDice did not improve from 0.64156
Epoch 54/300
 - 15s - loss: 0.2383 - acc: 0.9572 - mDice: 0.7757 - val_loss: 0.5064 - val_acc: 0.9539 - val_mDice: 0.6135

Epoch 00054: val_mDice did not improve from 0.64156
Epoch 55/300
 - 15s - loss: 0.2381 - acc: 0.9571 - mDice: 0.7758 - val_loss: 0.4550 - val_acc: 0.9546 - val_mDice: 0.6280

Epoch 00055: val_mDice did not improve from 0.64156
Epoch 56/300
 - 15s - loss: 0.2369 - acc: 0.9573 - mDice: 0.7768 - val_loss: 0.4689 - val_acc: 0.9549 - val_mDice: 0.6262

Epoch 00056: val_mDice did not improve from 0.64156
Epoch 57/300
 - 15s - loss: 0.2371 - acc: 0.9572 - mDice: 0.7766 - val_loss: 0.4738 - val_acc: 0.9554 - val_mDice: 0.6223

Epoch 00057: val_mDice did not improve from 0.64156
Epoch 58/300
 - 15s - loss: 0.2351 - acc: 0.9573 - mDice: 0.7782 - val_loss: 0.4774 - val_acc: 0.9532 - val_mDice: 0.6161

Epoch 00058: val_mDice did not improve from 0.64156
Epoch 59/300
 - 15s - loss: 0.2351 - acc: 0.9573 - mDice: 0.7782 - val_loss: 0.4794 - val_acc: 0.9539 - val_mDice: 0.6195

Epoch 00059: val_mDice did not improve from 0.64156
Epoch 60/300
 - 15s - loss: 0.2335 - acc: 0.9575 - mDice: 0.7796 - val_loss: 0.4961 - val_acc: 0.9546 - val_mDice: 0.6185

Epoch 00060: val_mDice did not improve from 0.64156
Epoch 61/300
 - 15s - loss: 0.2343 - acc: 0.9575 - mDice: 0.7788 - val_loss: 0.4845 - val_acc: 0.9555 - val_mDice: 0.6251

Epoch 00061: val_mDice did not improve from 0.64156
Epoch 62/300
 - 16s - loss: 0.2330 - acc: 0.9575 - mDice: 0.7799 - val_loss: 0.4627 - val_acc: 0.9545 - val_mDice: 0.6272

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.25s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.04s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.84s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:31,  1.80s/it]predicting train subjects:   1%|          | 2/285 [00:03<07:53,  1.67s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:49,  1.66s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:30,  1.60s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:49,  1.68s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:24,  1.59s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:39,  1.65s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:38,  1.66s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:08,  1.77s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:30,  1.85s/it]predicting train subjects:   4%|▍         | 11/285 [00:18<08:10,  1.79s/it]predicting train subjects:   4%|▍         | 12/285 [00:20<08:28,  1.86s/it]predicting train subjects:   5%|▍         | 13/285 [00:22<08:02,  1.77s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:06,  1.80s/it]predicting train subjects:   5%|▌         | 15/285 [00:26<08:21,  1.86s/it]predicting train subjects:   6%|▌         | 16/285 [00:28<08:29,  1.89s/it]predicting train subjects:   6%|▌         | 17/285 [00:29<08:02,  1.80s/it]predicting train subjects:   6%|▋         | 18/285 [00:31<08:02,  1.81s/it]predicting train subjects:   7%|▋         | 19/285 [00:33<07:44,  1.75s/it]predicting train subjects:   7%|▋         | 20/285 [00:34<07:46,  1.76s/it]predicting train subjects:   7%|▋         | 21/285 [00:36<08:03,  1.83s/it]predicting train subjects:   8%|▊         | 22/285 [00:38<07:44,  1.77s/it]predicting train subjects:   8%|▊         | 23/285 [00:40<07:45,  1.78s/it]predicting train subjects:   8%|▊         | 24/285 [00:41<07:25,  1.71s/it]predicting train subjects:   9%|▉         | 25/285 [00:43<07:49,  1.81s/it]predicting train subjects:   9%|▉         | 26/285 [00:45<08:03,  1.87s/it]predicting train subjects:   9%|▉         | 27/285 [00:47<07:35,  1.76s/it]predicting train subjects:  10%|▉         | 28/285 [00:49<07:37,  1.78s/it]predicting train subjects:  10%|█         | 29/285 [00:51<07:39,  1.80s/it]predicting train subjects:  11%|█         | 30/285 [00:53<07:52,  1.85s/it]predicting train subjects:  11%|█         | 31/285 [00:55<08:06,  1.91s/it]predicting train subjects:  11%|█         | 32/285 [00:56<07:41,  1.82s/it]predicting train subjects:  12%|█▏        | 33/285 [00:58<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 34/285 [01:00<07:46,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:02<07:58,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:04<07:36,  1.83s/it]predicting train subjects:  13%|█▎        | 37/285 [01:06<07:30,  1.81s/it]predicting train subjects:  13%|█▎        | 38/285 [01:08<07:41,  1.87s/it]predicting train subjects:  14%|█▎        | 39/285 [01:09<07:19,  1.79s/it]predicting train subjects:  14%|█▍        | 40/285 [01:11<07:17,  1.79s/it]predicting train subjects:  14%|█▍        | 41/285 [01:13<07:02,  1.73s/it]predicting train subjects:  15%|█▍        | 42/285 [01:14<06:47,  1.68s/it]predicting train subjects:  15%|█▌        | 43/285 [01:16<06:49,  1.69s/it]predicting train subjects:  15%|█▌        | 44/285 [01:18<07:06,  1.77s/it]predicting train subjects:  16%|█▌        | 45/285 [01:19<06:54,  1.73s/it]predicting train subjects:  16%|█▌        | 46/285 [01:21<07:10,  1.80s/it]predicting train subjects:  16%|█▋        | 47/285 [01:23<06:54,  1.74s/it]predicting train subjects:  17%|█▋        | 48/285 [01:25<06:56,  1.76s/it]predicting train subjects:  17%|█▋        | 49/285 [01:27<07:13,  1.84s/it]predicting train subjects:  18%|█▊        | 50/285 [01:29<07:11,  1.84s/it]predicting train subjects:  18%|█▊        | 51/285 [01:31<07:26,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:32<07:03,  1.82s/it]predicting train subjects:  19%|█▊        | 53/285 [01:34<07:02,  1.82s/it]predicting train subjects:  19%|█▉        | 54/285 [01:36<07:17,  1.89s/it]predicting train subjects:  19%|█▉        | 55/285 [01:38<06:53,  1.80s/it]predicting train subjects:  20%|█▉        | 56/285 [01:40<06:53,  1.80s/it]predicting train subjects:  20%|██        | 57/285 [01:41<06:42,  1.77s/it]predicting train subjects:  20%|██        | 58/285 [01:43<06:42,  1.77s/it]predicting train subjects:  21%|██        | 59/285 [01:45<06:58,  1.85s/it]predicting train subjects:  21%|██        | 60/285 [01:47<07:08,  1.91s/it]predicting train subjects:  21%|██▏       | 61/285 [01:49<06:49,  1.83s/it]predicting train subjects:  22%|██▏       | 62/285 [01:51<06:46,  1.82s/it]predicting train subjects:  22%|██▏       | 63/285 [01:52<06:45,  1.83s/it]predicting train subjects:  22%|██▏       | 64/285 [01:54<06:35,  1.79s/it]predicting train subjects:  23%|██▎       | 65/285 [01:56<06:34,  1.79s/it]predicting train subjects:  23%|██▎       | 66/285 [01:58<06:37,  1.81s/it]predicting train subjects:  24%|██▎       | 67/285 [02:00<06:34,  1.81s/it]predicting train subjects:  24%|██▍       | 68/285 [02:01<06:26,  1.78s/it]predicting train subjects:  24%|██▍       | 69/285 [02:03<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:05<06:27,  1.80s/it]predicting train subjects:  25%|██▍       | 71/285 [02:07<06:32,  1.83s/it]predicting train subjects:  25%|██▌       | 72/285 [02:09<06:20,  1.79s/it]predicting train subjects:  26%|██▌       | 73/285 [02:10<06:23,  1.81s/it]predicting train subjects:  26%|██▌       | 74/285 [02:12<06:22,  1.81s/it]predicting train subjects:  26%|██▋       | 75/285 [02:14<06:23,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:16<06:17,  1.81s/it]predicting train subjects:  27%|██▋       | 77/285 [02:17<06:05,  1.76s/it]predicting train subjects:  27%|██▋       | 78/285 [02:19<05:54,  1.71s/it]predicting train subjects:  28%|██▊       | 79/285 [02:21<05:58,  1.74s/it]predicting train subjects:  28%|██▊       | 80/285 [02:23<06:01,  1.76s/it]predicting train subjects:  28%|██▊       | 81/285 [02:24<05:56,  1.75s/it]predicting train subjects:  29%|██▉       | 82/285 [02:26<05:57,  1.76s/it]predicting train subjects:  29%|██▉       | 83/285 [02:28<05:51,  1.74s/it]predicting train subjects:  29%|██▉       | 84/285 [02:30<05:43,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:31<05:46,  1.73s/it]predicting train subjects:  30%|███       | 86/285 [02:33<05:50,  1.76s/it]predicting train subjects:  31%|███       | 87/285 [02:35<05:53,  1.79s/it]predicting train subjects:  31%|███       | 88/285 [02:37<05:42,  1.74s/it]predicting train subjects:  31%|███       | 89/285 [02:38<05:42,  1.75s/it]predicting train subjects:  32%|███▏      | 90/285 [02:40<05:47,  1.78s/it]predicting train subjects:  32%|███▏      | 91/285 [02:42<05:38,  1.74s/it]predicting train subjects:  32%|███▏      | 92/285 [02:44<05:44,  1.78s/it]predicting train subjects:  33%|███▎      | 93/285 [02:45<05:35,  1.75s/it]predicting train subjects:  33%|███▎      | 94/285 [02:47<05:38,  1.77s/it]predicting train subjects:  33%|███▎      | 95/285 [02:49<05:47,  1.83s/it]predicting train subjects:  34%|███▎      | 96/285 [02:51<05:46,  1.83s/it]predicting train subjects:  34%|███▍      | 97/285 [02:53<05:46,  1.84s/it]predicting train subjects:  34%|███▍      | 98/285 [02:55<05:51,  1.88s/it]predicting train subjects:  35%|███▍      | 99/285 [02:57<05:41,  1.84s/it]predicting train subjects:  35%|███▌      | 100/285 [02:58<05:36,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [03:00<05:33,  1.81s/it]predicting train subjects:  36%|███▌      | 102/285 [03:02<05:37,  1.84s/it]predicting train subjects:  36%|███▌      | 103/285 [03:04<05:31,  1.82s/it]predicting train subjects:  36%|███▋      | 104/285 [03:06<05:31,  1.83s/it]predicting train subjects:  37%|███▋      | 105/285 [03:08<05:34,  1.86s/it]predicting train subjects:  37%|███▋      | 106/285 [03:09<05:23,  1.81s/it]predicting train subjects:  38%|███▊      | 107/285 [03:11<05:17,  1.79s/it]predicting train subjects:  38%|███▊      | 108/285 [03:13<05:09,  1.75s/it]predicting train subjects:  38%|███▊      | 109/285 [03:15<05:12,  1.77s/it]predicting train subjects:  39%|███▊      | 110/285 [03:16<05:12,  1.79s/it]predicting train subjects:  39%|███▉      | 111/285 [03:18<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:20<05:09,  1.79s/it]predicting train subjects:  40%|███▉      | 113/285 [03:22<05:10,  1.80s/it]predicting train subjects:  40%|████      | 114/285 [03:24<05:07,  1.80s/it]predicting train subjects:  40%|████      | 115/285 [03:25<05:05,  1.80s/it]predicting train subjects:  41%|████      | 116/285 [03:27<05:08,  1.82s/it]predicting train subjects:  41%|████      | 117/285 [03:29<05:06,  1.82s/it]predicting train subjects:  41%|████▏     | 118/285 [03:31<05:00,  1.80s/it]predicting train subjects:  42%|████▏     | 119/285 [03:33<05:03,  1.83s/it]predicting train subjects:  42%|████▏     | 120/285 [03:34<04:55,  1.79s/it]predicting train subjects:  42%|████▏     | 121/285 [03:36<04:44,  1.73s/it]predicting train subjects:  43%|████▎     | 122/285 [03:38<04:33,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [03:39<04:23,  1.63s/it]predicting train subjects:  44%|████▎     | 124/285 [03:41<04:26,  1.65s/it]predicting train subjects:  44%|████▍     | 125/285 [03:42<04:19,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:44<04:18,  1.63s/it]predicting train subjects:  45%|████▍     | 127/285 [03:46<04:14,  1.61s/it]predicting train subjects:  45%|████▍     | 128/285 [03:47<04:17,  1.64s/it]predicting train subjects:  45%|████▌     | 129/285 [03:49<04:16,  1.65s/it]predicting train subjects:  46%|████▌     | 130/285 [03:50<04:09,  1.61s/it]predicting train subjects:  46%|████▌     | 131/285 [03:52<04:03,  1.58s/it]predicting train subjects:  46%|████▋     | 132/285 [03:54<04:05,  1.61s/it]predicting train subjects:  47%|████▋     | 133/285 [03:55<04:04,  1.61s/it]predicting train subjects:  47%|████▋     | 134/285 [03:57<03:56,  1.57s/it]predicting train subjects:  47%|████▋     | 135/285 [03:58<03:51,  1.54s/it]predicting train subjects:  48%|████▊     | 136/285 [04:00<03:51,  1.55s/it]predicting train subjects:  48%|████▊     | 137/285 [04:01<03:57,  1.60s/it]predicting train subjects:  48%|████▊     | 138/285 [04:03<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:05<03:55,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:06<03:52,  1.61s/it]predicting train subjects:  49%|████▉     | 141/285 [04:08<03:46,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:10<03:52,  1.62s/it]predicting train subjects:  50%|█████     | 143/285 [04:11<03:44,  1.58s/it]predicting train subjects:  51%|█████     | 144/285 [04:13<03:46,  1.61s/it]predicting train subjects:  51%|█████     | 145/285 [04:14<03:38,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:16<03:42,  1.60s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:17<03:33,  1.55s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:19<03:35,  1.57s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:20<03:32,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:22<03:29,  1.55s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:24<03:33,  1.59s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:25<03:27,  1.56s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:27<03:26,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:28<03:27,  1.58s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:30<03:23,  1.56s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:32<03:25,  1.59s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:33<03:20,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:34<03:14,  1.53s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:36<03:14,  1.54s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:38<03:15,  1.56s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:39<03:18,  1.60s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:41<03:14,  1.58s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:43<03:17,  1.62s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:44<03:13,  1.60s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:46<03:09,  1.58s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:47<03:12,  1.62s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:49<03:13,  1.64s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:51<03:10,  1.63s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:52<03:07,  1.62s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:54<03:03,  1.59s/it]predicting train subjects:  60%|██████    | 171/285 [04:55<02:59,  1.57s/it]predicting train subjects:  60%|██████    | 172/285 [04:57<02:57,  1.57s/it]predicting train subjects:  61%|██████    | 173/285 [04:59<02:56,  1.58s/it]predicting train subjects:  61%|██████    | 174/285 [05:00<02:50,  1.54s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:02<02:52,  1.57s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:03<02:54,  1.60s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:05<02:49,  1.57s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:06<02:42,  1.52s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:08<02:39,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:09<02:48,  1.61s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:11<02:50,  1.63s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:13<02:52,  1.67s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:14<02:43,  1.61s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:16<02:38,  1.57s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:17<02:31,  1.51s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:19<02:42,  1.64s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:21<02:47,  1.71s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:23<02:49,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:24<02:40,  1.67s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:26<02:31,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:28<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:29<02:34,  1.66s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:31<02:27,  1.60s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:32<02:21,  1.56s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:34<02:17,  1.53s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:36<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:38<02:32,  1.74s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:39<02:34,  1.77s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:41<02:23,  1.67s/it]predicting train subjects:  70%|███████   | 200/285 [05:42<02:17,  1.62s/it]predicting train subjects:  71%|███████   | 201/285 [05:44<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:46<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:48<02:18,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:49<02:12,  1.63s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:50<02:05,  1.57s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:52<02:01,  1.53s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:54<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:56<02:13,  1.73s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:58<02:15,  1.79s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:59<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:01<02:02,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:02<02:03,  1.69s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:04<02:01,  1.69s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:06<01:57,  1.66s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:08<02:01,  1.73s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:09<01:55,  1.68s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:11<02:00,  1.77s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:13<02:02,  1.83s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:15<02:02,  1.85s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:17<01:53,  1.75s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:18<01:47,  1.68s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:20<01:47,  1.70s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:21<01:41,  1.64s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:23<01:37,  1.60s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:24<01:34,  1.57s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:26<01:41,  1.72s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:28<01:40,  1.74s/it]predicting train subjects:  80%|████████  | 228/285 [06:30<01:41,  1.79s/it]predicting train subjects:  80%|████████  | 229/285 [06:32<01:39,  1.78s/it]predicting train subjects:  81%|████████  | 230/285 [06:33<01:33,  1.70s/it]predicting train subjects:  81%|████████  | 231/285 [06:35<01:29,  1.67s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:37<01:30,  1.71s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:38<01:26,  1.67s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:40<01:29,  1.76s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:42<01:25,  1.70s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:44<01:29,  1.83s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:46<01:29,  1.87s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:48<01:30,  1.93s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:50<01:27,  1.90s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:51<01:20,  1.78s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:53<01:16,  1.73s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:55<01:11,  1.67s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:56<01:09,  1.65s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:58<01:12,  1.78s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:00<01:08,  1.70s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:02<01:11,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:04<01:11,  1.88s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:06<01:08,  1.85s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:07<01:03,  1.77s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:09<00:59,  1.70s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:10<00:57,  1.68s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:12<00:55,  1.69s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:14<00:57,  1.80s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:16<00:56,  1.82s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:18<00:54,  1.80s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:19<00:50,  1.74s/it]predicting train subjects:  90%|█████████ | 257/285 [07:21<00:47,  1.70s/it]predicting train subjects:  91%|█████████ | 258/285 [07:23<00:49,  1.82s/it]predicting train subjects:  91%|█████████ | 259/285 [07:25<00:46,  1.80s/it]predicting train subjects:  91%|█████████ | 260/285 [07:26<00:42,  1.71s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:28<00:39,  1.67s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:29<00:37,  1.61s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:31<00:34,  1.57s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:33<00:36,  1.72s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:35<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:36<00:32,  1.70s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:38<00:29,  1.66s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:40<00:28,  1.70s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:41<00:27,  1.72s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:43<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:44<00:22,  1.61s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:46<00:21,  1.67s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:48<00:19,  1.60s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:49<00:17,  1.55s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:51<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:53<00:16,  1.78s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:55<00:13,  1.75s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:56<00:12,  1.72s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:58<00:10,  1.78s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:00<00:08,  1.74s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:02<00:06,  1.71s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:03<00:05,  1.72s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:06<00:04,  2.01s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:08<00:02,  2.05s/it]predicting train subjects: 100%|██████████| 285/285 [08:10<00:00,  2.01s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:08,  1.72s/it]Loading train:   1%|          | 2/285 [00:03<07:38,  1.62s/it]Loading train:   1%|          | 3/285 [00:05<08:15,  1.76s/it]
Epoch 00062: val_mDice did not improve from 0.64156
Restoring model weights from the end of the best epoch
Epoch 00062: early stopping
{'val_loss': [0.6979239349924652, 0.5059118414058366, 0.4822530197031671, 0.45532183007821025, 0.4512236767640993, 0.4678731890364066, 0.45753878088636774, 0.5067698875619047, 0.46657782793045044, 0.47629650744645957, 0.450382679534358, 0.46667397155442053, 0.4691076258707313, 0.45840514805063853, 0.44974688644515737, 0.4816116454215023, 0.4606946253909745, 0.4785107747136548, 0.4516788068430384, 0.4507927564935311, 0.4533036054845629, 0.4315733902947197, 0.4513470051008896, 0.455564326081196, 0.4681683772103081, 0.501398425528457, 0.45301321864794086, 0.4533570871672817, 0.4659772515296936, 0.49221868188687545, 0.45078132438926055, 0.4518325092406246, 0.4702059296922311, 0.4460671054584354, 0.47713744174168765, 0.48024023378361536, 0.4854587516305167, 0.4902752414761975, 0.46850709409021135, 0.46025152912353007, 0.4574665280693736, 0.4562467706270058, 0.46071558524776435, 0.4546376579966625, 0.46219439946073393, 0.4765138649407712, 0.462379434921222, 0.47452315038808895, 0.5168253719473684, 0.4676642547772583, 0.4629777237023721, 0.5109365642403757, 0.4878513083777614, 0.5063772554504139, 0.4550286354965338, 0.46891078136486714, 0.47381865978240967, 0.47741124516758837, 0.479354538398082, 0.49613301947130173, 0.4845408614121336, 0.4627338624533328], 'val_acc': [0.9176370111923644, 0.9286201566291254, 0.9359153465851725, 0.9374938204301803, 0.9520573712594016, 0.9546688741811827, 0.9549436362762025, 0.9543692762625284, 0.951633845294654, 0.9547845474834549, 0.9522454079302995, 0.9532598030633767, 0.9549973577094477, 0.9538630953048195, 0.9545758746189779, 0.9552721351218623, 0.9513983127125148, 0.9559270782843649, 0.9547205161115977, 0.9542907529703065, 0.9554994189539435, 0.9559270619680096, 0.9537990479495938, 0.9552225630376592, 0.9557039358096415, 0.954590350555974, 0.9554291800413718, 0.9537432699896103, 0.953689533904944, 0.9556109945201341, 0.9558361828660166, 0.9557989938965057, 0.954389924110647, 0.9550014754247399, 0.9543258714276319, 0.954394084448255, 0.9552266770900961, 0.9561150966409865, 0.9549312428389182, 0.9530862573138829, 0.9562989446703948, 0.9553052010482916, 0.9539519391912322, 0.9553093217604653, 0.9568567958624004, 0.9541668159335686, 0.9526482594079811, 0.9542866585640933, 0.9539891215010062, 0.953848613707047, 0.9545882850385911, 0.9538362379180653, 0.9544229800474711, 0.9538961292645118, 0.9546254756730362, 0.9548506923228003, 0.9553919804162819, 0.9532040444166301, 0.9539333378802465, 0.9545965534348727, 0.9554828921509855, 0.9544663962039202], 'val_mDice': [0.5130859122262986, 0.5939106308548144, 0.6093469222164687, 0.6265744853286104, 0.6288226966085381, 0.6228796300275365, 0.6295507506951273, 0.6168167770907865, 0.621384407221938, 0.6175893968044046, 0.6273770279058531, 0.6243352510409648, 0.6220557606420037, 0.6268783594642937, 0.6307522151723254, 0.623801922664962, 0.6218538857039126, 0.625579481351309, 0.6303582414568469, 0.6293739726423552, 0.6295718430806805, 0.6415584933158406, 0.628714564459284, 0.62805252235029, 0.62018947028581, 0.6179730069703896, 0.6292828118334935, 0.6261966521513529, 0.6220196981669804, 0.6152656544520202, 0.6317135378635129, 0.6317004504816492, 0.6245776298325821, 0.6369021445013291, 0.620697496656599, 0.6189664742134137, 0.6181951618061385, 0.6163511795704592, 0.6249556101900239, 0.6230904882846597, 0.6318225574227019, 0.6284423716907395, 0.6274194470996963, 0.632136021579444, 0.6313985532888488, 0.620776765173374, 0.6228799034097341, 0.6214767777719977, 0.6156369334492604, 0.6251487771892015, 0.6265732256393859, 0.6081872665682319, 0.6162952008194098, 0.6135186066840614, 0.6279679270429984, 0.626216711944708, 0.6222793886115431, 0.6160628212896805, 0.6195217767241281, 0.6184541639668981, 0.6251200530782092, 0.627249674091126], 'loss': [1.9069244699029906, 0.5531331214563409, 0.4500816372392562, 0.40820709225379737, 0.3890924661415061, 0.37056958002758716, 0.3550677273399553, 0.34492364243856993, 0.33567811357748417, 0.3281270757940014, 0.33454950509536996, 0.3193405568762014, 0.3097727477216142, 0.30333698835321504, 0.3002730780622745, 0.295164832912183, 0.29021044783093336, 0.28817474509654145, 0.28619296907774794, 0.2821707708904033, 0.2832282407826169, 0.2983934656869001, 0.2781382061873417, 0.2755082975798109, 0.2717491828238326, 0.26857467081336295, 0.2668639222970229, 0.2692269073333312, 0.3014014914634278, 0.2686128583740522, 0.26369422321634856, 0.2612056051842054, 0.25858584847703986, 0.25715990479225803, 0.2567197340979087, 0.2554137727500216, 0.25309247837419324, 0.2537867945138227, 0.25076213230378264, 0.2714837586725208, 0.25474769486190774, 0.24957597351633876, 0.24749966029455756, 0.24612602142150558, 0.24524157513824724, 0.2442672483001774, 0.242921332085154, 0.2431389106595109, 0.24127252641686894, 0.24193096717947496, 0.24062629223249685, 0.23860836859446946, 0.23967621948560477, 0.23827513522113905, 0.23805629842181747, 0.23687188260114814, 0.2371067213379774, 0.23509058729930027, 0.2350685643439498, 0.23349349707223824, 0.23434862722843328, 0.2330017312651048], 'acc': [0.698835649513762, 0.900870214210578, 0.9081233740502158, 0.9146160607107856, 0.926745700739443, 0.9426021643450015, 0.9476111945578244, 0.9487368750400802, 0.9496596288910866, 0.9502831765667986, 0.9500632894356639, 0.9510412516011424, 0.9518330652861415, 0.9522267131366265, 0.9524771169044699, 0.9529104064339471, 0.9533527984636541, 0.9533846611375675, 0.9535874093963744, 0.9538635526417089, 0.9540156229772921, 0.9527790198742412, 0.9541604016466173, 0.9543807928088599, 0.9546238609982384, 0.9548377101993089, 0.9549481028740744, 0.9549632944524966, 0.9521899565483813, 0.9547834863597016, 0.9551866631266092, 0.9553760368640526, 0.9555113478057765, 0.9556994920273985, 0.9557153640291502, 0.9558167788634522, 0.956037911702771, 0.9560214555813437, 0.9561586838474682, 0.9553489255188377, 0.9559344041354646, 0.9561817244106723, 0.9564254000538686, 0.9565919734126543, 0.9566514509889361, 0.9566582581503615, 0.9567899846620312, 0.9567672642355982, 0.9569323690789021, 0.9568674935928897, 0.9570175888075962, 0.9571691524144267, 0.9570112234756232, 0.95722039327221, 0.9571472603662764, 0.9572870840103588, 0.9572116533244307, 0.957334639381904, 0.9573307105362737, 0.9575428222884059, 0.9574542389534884, 0.957494664760945], 'mDice': [0.2536990415240177, 0.5629406548502087, 0.6249877571845378, 0.652264111838396, 0.6650142830692406, 0.6771658303840092, 0.6873675474549981, 0.6944388505725727, 0.701093994819951, 0.7064953977931436, 0.7027140002151725, 0.7129428982410054, 0.7199920160786907, 0.7247799431360286, 0.7271689325173393, 0.7309794153927471, 0.7347018908301273, 0.7363682432532032, 0.7380095267437374, 0.7408374743675603, 0.74207579768189, 0.7295053726278562, 0.7438901914898901, 0.7460509692036464, 0.7489487311301307, 0.7513258917633858, 0.7527011980788912, 0.7521396722092906, 0.7266600911968265, 0.7513353472850361, 0.7551142325244706, 0.757167766958493, 0.759150106759121, 0.7603536976895868, 0.7607026699126777, 0.7617240794784953, 0.7636920538358157, 0.7631202410602419, 0.7654813245928149, 0.7547551330531399, 0.7622649978821356, 0.7664079527976719, 0.7681529393747192, 0.7692273041306157, 0.7699685543686287, 0.77078636319385, 0.7718599930346373, 0.7717012421256751, 0.7731050186236176, 0.7726185960932226, 0.7737200566609631, 0.7753098606771129, 0.7744351534676976, 0.7756682165106243, 0.7757685407659378, 0.7767840971465491, 0.7765665734153798, 0.778235853318912, 0.7782328364298654, 0.7795512187481576, 0.7788379615892298, 0.7799085112615554]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLaLoading train:   1%|▏         | 4/285 [00:06<07:10,  1.53s/it]Loading train:   2%|▏         | 5/285 [00:07<07:12,  1.54s/it]Loading train:   2%|▏         | 6/285 [00:08<06:44,  1.45s/it]Loading train:   2%|▏         | 7/285 [00:10<06:53,  1.49s/it]Loading train:   3%|▎         | 8/285 [00:12<06:48,  1.48s/it]Loading train:   3%|▎         | 9/285 [00:13<06:53,  1.50s/it]Loading train:   4%|▎         | 10/285 [00:14<06:28,  1.41s/it]Loading train:   4%|▍         | 11/285 [00:15<05:50,  1.28s/it]Loading train:   4%|▍         | 12/285 [00:16<05:39,  1.24s/it]Loading train:   5%|▍         | 13/285 [00:17<05:03,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:18<04:55,  1.09s/it]Loading train:   5%|▌         | 15/285 [00:19<04:52,  1.08s/it]Loading train:   6%|▌         | 16/285 [00:20<04:43,  1.05s/it]Loading train:   6%|▌         | 17/285 [00:21<04:32,  1.02s/it]Loading train:   6%|▋         | 18/285 [00:22<04:19,  1.03it/s]Loading train:   7%|▋         | 19/285 [00:23<04:05,  1.08it/s]Loading train:   7%|▋         | 20/285 [00:24<04:17,  1.03it/s]Loading train:   7%|▋         | 21/285 [00:25<04:20,  1.02it/s]Loading train:   8%|▊         | 22/285 [00:26<04:26,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:27<04:18,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:28<04:05,  1.06it/s]Loading train:   9%|▉         | 25/285 [00:29<04:18,  1.00it/s]Loading train:   9%|▉         | 26/285 [00:30<04:18,  1.00it/s]Loading train:   9%|▉         | 27/285 [00:31<04:03,  1.06it/s]Loading train:  10%|▉         | 28/285 [00:32<04:04,  1.05it/s]Loading train:  10%|█         | 29/285 [00:33<04:06,  1.04it/s]Loading train:  11%|█         | 30/285 [00:34<04:13,  1.00it/s]Loading train:  11%|█         | 31/285 [00:35<04:21,  1.03s/it]Loading train:  11%|█         | 32/285 [00:36<04:00,  1.05it/s]Loading train:  12%|█▏        | 33/285 [00:37<04:07,  1.02it/s]Loading train:  12%|█▏        | 34/285 [00:38<03:59,  1.05it/s]Loading train:  12%|█▏        | 35/285 [00:39<04:01,  1.03it/s]Loading train:  13%|█▎        | 36/285 [00:40<04:01,  1.03it/s]Loading train:  13%|█▎        | 37/285 [00:40<03:53,  1.06it/s]Loading train:  13%|█▎        | 38/285 [00:42<04:00,  1.03it/s]Loading train:  14%|█▎        | 39/285 [00:42<03:49,  1.07it/s]Loading train:  14%|█▍        | 40/285 [00:43<03:45,  1.09it/s]Loading train:  14%|█▍        | 41/285 [00:44<03:41,  1.10it/s]Loading train:  15%|█▍        | 42/285 [00:45<03:38,  1.11it/s]Loading train:  15%|█▌        | 43/285 [00:46<03:54,  1.03it/s]Loading train:  15%|█▌        | 44/285 [00:47<04:01,  1.00s/it]Loading train:  16%|█▌        | 45/285 [00:48<03:41,  1.08it/s]Loading train:  16%|█▌        | 46/285 [00:49<03:44,  1.06it/s]Loading train:  16%|█▋        | 47/285 [00:50<03:47,  1.05it/s]Loading train:  17%|█▋        | 48/285 [00:51<04:00,  1.02s/it]Loading train:  17%|█▋        | 49/285 [00:52<04:07,  1.05s/it]Loading train:  18%|█▊        | 50/285 [00:53<04:00,  1.02s/it]Loading train:  18%|█▊        | 51/285 [00:54<03:59,  1.02s/it]Loading train:  18%|█▊        | 52/285 [00:55<03:46,  1.03it/s]Loading train:  19%|█▊        | 53/285 [00:56<03:39,  1.06it/s]Loading train:  19%|█▉        | 54/285 [00:57<03:44,  1.03it/s]Loading train:  19%|█▉        | 55/285 [00:58<03:31,  1.09it/s]Loading train:  20%|█▉        | 56/285 [00:59<03:39,  1.04it/s]Loading train:  20%|██        | 57/285 [01:00<03:39,  1.04it/s]Loading train:  20%|██        | 58/285 [01:01<03:40,  1.03it/s]Loading train:  21%|██        | 59/285 [01:02<03:45,  1.00it/s]Loading train:  21%|██        | 60/285 [01:03<03:45,  1.00s/it]Loading train:  21%|██▏       | 61/285 [01:04<03:40,  1.02it/s]Loading train:  22%|██▏       | 62/285 [01:05<03:55,  1.05s/it]Loading train:  22%|██▏       | 63/285 [01:06<03:45,  1.02s/it]Loading train:  22%|██▏       | 64/285 [01:07<04:04,  1.11s/it]Loading train:  23%|██▎       | 65/285 [01:09<04:38,  1.26s/it]Loading train:  23%|██▎       | 66/285 [01:11<05:21,  1.47s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:52,  1.34s/it]Loading train:  24%|██▍       | 68/285 [01:13<04:50,  1.34s/it]Loading train:  24%|██▍       | 69/285 [01:15<04:51,  1.35s/it]Loading train:  25%|██▍       | 70/285 [01:16<04:54,  1.37s/it]Loading train:  25%|██▍       | 71/285 [01:17<04:39,  1.31s/it]Loading train:  25%|██▌       | 72/285 [01:18<04:27,  1.26s/it]Loading train:  26%|██▌       | 73/285 [01:19<04:04,  1.15s/it]Loading train:  26%|██▌       | 74/285 [01:20<04:01,  1.15s/it]Loading train:  26%|██▋       | 75/285 [01:21<03:57,  1.13s/it]Loading train:  27%|██▋       | 76/285 [01:22<03:42,  1.06s/it]Loading train:  27%|██▋       | 77/285 [01:23<03:30,  1.01s/it]Loading train:  27%|██▋       | 78/285 [01:24<03:22,  1.02it/s]Loading train:  28%|██▊       | 79/285 [01:25<03:19,  1.03it/s]Loading train:  28%|██▊       | 80/285 [01:26<03:13,  1.06it/s]Loading train:  28%|██▊       | 81/285 [01:27<03:12,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:28<03:14,  1.05it/s]Loading train:  29%|██▉       | 83/285 [01:29<03:06,  1.08it/s]Loading train:  29%|██▉       | 84/285 [01:30<03:02,  1.10it/s]Loading train:  30%|██▉       | 85/285 [01:31<03:02,  1.10it/s]Loading train:  30%|███       | 86/285 [01:32<03:04,  1.08it/s]Loading train:  31%|███       | 87/285 [01:33<03:14,  1.02it/s]Loading train:  31%|███       | 88/285 [01:33<03:04,  1.07it/s]Loading train:  31%|███       | 89/285 [01:34<03:04,  1.06it/s]Loading train:  32%|███▏      | 90/285 [01:35<03:01,  1.07it/s]Loading train:  32%|███▏      | 91/285 [01:36<02:56,  1.10it/s]Loading train:  32%|███▏      | 92/285 [01:37<02:51,  1.12it/s]Loading train:  33%|███▎      | 93/285 [01:38<02:43,  1.17it/s]Loading train:  33%|███▎      | 94/285 [01:39<02:47,  1.14it/s]Loading train:  33%|███▎      | 95/285 [01:40<02:50,  1.12it/s]Loading train:  34%|███▎      | 96/285 [01:41<02:49,  1.11it/s]Loading train:  34%|███▍      | 97/285 [01:41<02:46,  1.13it/s]Loading train:  34%|███▍      | 98/285 [01:42<02:55,  1.07it/s]Loading train:  35%|███▍      | 99/285 [01:44<03:03,  1.01it/s]Loading train:  35%|███▌      | 100/285 [01:45<02:59,  1.03it/s]Loading train:  35%|███▌      | 101/285 [01:45<02:45,  1.11it/s]Loading train:  36%|███▌      | 102/285 [01:46<02:45,  1.10it/s]Loading train:  36%|███▌      | 103/285 [01:47<02:34,  1.18it/s]Loading train:  36%|███▋      | 104/285 [01:48<02:35,  1.16it/s]Loading train:  37%|███▋      | 105/285 [01:49<02:33,  1.17it/s]Loading train:  37%|███▋      | 106/285 [01:49<02:24,  1.24it/s]Loading train:  38%|███▊      | 107/285 [01:50<02:29,  1.19it/s]Loading train:  38%|███▊      | 108/285 [01:51<02:34,  1.15it/s]Loading train:  38%|███▊      | 109/285 [01:52<02:42,  1.08it/s]Loading train:  39%|███▊      | 110/285 [01:53<02:38,  1.10it/s]Loading train:  39%|███▉      | 111/285 [01:54<02:31,  1.15it/s]Loading train:  39%|███▉      | 112/285 [01:55<02:33,  1.13it/s]Loading train:  40%|███▉      | 113/285 [01:56<02:41,  1.07it/s]Loading train:  40%|████      | 114/285 [01:57<02:51,  1.00s/it]Loading train:  40%|████      | 115/285 [01:58<02:50,  1.00s/it]Loading train:  41%|████      | 116/285 [01:59<02:56,  1.04s/it]Loading train:  41%|████      | 117/285 [02:00<02:41,  1.04it/s]Loading train:  41%|████▏     | 118/285 [02:01<02:27,  1.13it/s]Loading train:  42%|████▏     | 119/285 [02:01<02:24,  1.15it/s]Loading train:  42%|████▏     | 120/285 [02:02<02:14,  1.23it/s]Loading train:  42%|████▏     | 121/285 [02:03<02:37,  1.04it/s]Loading train:  43%|████▎     | 122/285 [02:05<02:47,  1.03s/it]Loading train:  43%|████▎     | 123/285 [02:06<02:50,  1.05s/it]Loading train:  44%|████▎     | 124/285 [02:07<02:40,  1.01it/s]Loading train:  44%|████▍     | 125/285 [02:07<02:33,  1.04it/s]Loading train:  44%|████▍     | 126/285 [02:08<02:32,  1.04it/s]Loading train:  45%|████▍     | 127/285 [02:09<02:34,  1.02it/s]Loading train:  45%|████▍     | 128/285 [02:10<02:36,  1.00it/s]Loading train:  45%|████▌     | 129/285 [02:12<02:38,  1.02s/it]Loading train:  46%|████▌     | 130/285 [02:12<02:33,  1.01it/s]Loading train:  46%|████▌     | 131/285 [02:13<02:21,  1.09it/s]Loading train:  46%|████▋     | 132/285 [02:14<02:28,  1.03it/s]Loading train:  47%|████▋     | 133/285 [02:15<02:17,  1.11it/s]Loading train:  47%|████▋     | 134/285 [02:16<02:07,  1.19it/s]Loading train:  47%|████▋     | 135/285 [02:17<02:08,  1.16it/s]Loading train:  48%|████▊     | 136/285 [02:17<02:03,  1.21it/s]Loading train:  48%|████▊     | 137/285 [02:19<02:16,  1.09it/s]Loading train:  48%|████▊     | 138/285 [02:19<02:07,  1.16it/s]Loading train:  49%|████▉     | 139/285 [02:20<02:12,  1.11it/s]Loading train:  49%|████▉     | 140/285 [02:21<02:08,  1.13it/s]Loading train:  49%|████▉     | 141/285 [02:22<02:05,  1.15it/s]Loading train:  50%|████▉     | 142/285 [02:23<02:05,  1.14it/s]Loading train:  50%|█████     | 143/285 [02:24<02:11,  1.08it/s]Loading train:  51%|█████     | 144/285 [02:25<02:19,  1.01it/s]Loading train:  51%|█████     | 145/285 [02:26<02:13,  1.05it/s]Loading train:  51%|█████     | 146/285 [02:27<02:08,  1.08it/s]Loading train:  52%|█████▏    | 147/285 [02:27<01:58,  1.16it/s]Loading train:  52%|█████▏    | 148/285 [02:29<02:04,  1.10it/s]Loading train:  52%|█████▏    | 149/285 [02:29<02:01,  1.12it/s]Loading train:  53%|█████▎    | 150/285 [02:30<01:52,  1.20it/s]Loading train:  53%|█████▎    | 151/285 [02:31<01:56,  1.15it/s]Loading train:  53%|█████▎    | 152/285 [02:32<01:52,  1.18it/s]Loading train:  54%|█████▎    | 153/285 [02:33<01:46,  1.24it/s]Loading train:  54%|█████▍    | 154/285 [02:33<01:51,  1.18it/s]Loading train:  54%|█████▍    | 155/285 [02:34<01:51,  1.17it/s]Loading train:  55%|█████▍    | 156/285 [02:35<01:49,  1.17it/s]Loading train:  55%|█████▌    | 157/285 [02:36<01:46,  1.20it/s]Loading train:  55%|█████▌    | 158/285 [02:37<01:42,  1.23it/s]Loading train:  56%|█████▌    | 159/285 [02:38<01:41,  1.25it/s]Loading train:  56%|█████▌    | 160/285 [02:38<01:44,  1.20it/s]Loading train:  56%|█████▋    | 161/285 [02:39<01:45,  1.17it/s]Loading train:  57%|█████▋    | 162/285 [02:40<01:46,  1.15it/s]Loading train:  57%|█████▋    | 163/285 [02:41<01:53,  1.08it/s]Loading train:  58%|█████▊    | 164/285 [02:42<02:01,  1.00s/it]Loading train:  58%|█████▊    | 165/285 [02:43<01:58,  1.02it/s]Loading train:  58%|█████▊    | 166/285 [02:45<02:00,  1.02s/it]Loading train:  59%|█████▊    | 167/285 [02:46<02:02,  1.03s/it]Loading train:  59%|█████▉    | 168/285 [02:46<01:55,  1.01it/s]Loading train:  59%|█████▉    | 169/285 [02:48<01:58,  1.02s/it]Loading train:  60%|█████▉    | 170/285 [02:48<01:53,  1.02it/s]Loading train:  60%|██████    | 171/285 [02:49<01:53,  1.00it/s]Loading train:  60%|██████    | 172/285 [02:50<01:50,  1.02it/s]Loading train:  61%|██████    | 173/285 [02:51<01:45,  1.07it/s]Loading train:  61%|██████    | 174/285 [02:52<01:44,  1.06it/s]Loading train:  61%|██████▏   | 175/285 [02:53<01:44,  1.05it/s]Loading train:  62%|██████▏   | 176/285 [02:54<01:49,  1.01s/it]Loading train:  62%|██████▏   | 177/285 [02:55<01:50,  1.02s/it]Loading train:  62%|██████▏   | 178/285 [02:56<01:51,  1.04s/it]Loading train:  63%|██████▎   | 179/285 [02:58<01:50,  1.05s/it]Loading train:  63%|██████▎   | 180/285 [02:59<01:53,  1.08s/it]Loading train:  64%|██████▎   | 181/285 [03:00<01:50,  1.06s/it]Loading train:  64%|██████▍   | 182/285 [03:01<01:49,  1.07s/it]Loading train:  64%|██████▍   | 183/285 [03:02<01:45,  1.03s/it]Loading train:  65%|██████▍   | 184/285 [03:03<01:44,  1.04s/it]Loading train:  65%|██████▍   | 185/285 [03:04<01:38,  1.02it/s]Loading train:  65%|██████▌   | 186/285 [03:05<01:40,  1.01s/it]Loading train:  66%|██████▌   | 187/285 [03:06<01:40,  1.02s/it]Loading train:  66%|██████▌   | 188/285 [03:07<01:54,  1.18s/it]Loading train:  66%|██████▋   | 189/285 [03:09<01:57,  1.22s/it]Loading train:  67%|██████▋   | 190/285 [03:10<01:48,  1.14s/it]Loading train:  67%|██████▋   | 191/285 [03:11<01:54,  1.21s/it]Loading train:  67%|██████▋   | 192/285 [03:12<01:48,  1.17s/it]Loading train:  68%|██████▊   | 193/285 [03:13<01:41,  1.10s/it]Loading train:  68%|██████▊   | 194/285 [03:14<01:41,  1.12s/it]Loading train:  68%|██████▊   | 195/285 [03:15<01:39,  1.11s/it]Loading train:  69%|██████▉   | 196/285 [03:16<01:38,  1.10s/it]Loading train:  69%|██████▉   | 197/285 [03:17<01:34,  1.07s/it]Loading train:  69%|██████▉   | 198/285 [03:18<01:31,  1.05s/it]Loading train:  70%|██████▉   | 199/285 [03:19<01:29,  1.04s/it]Loading train:  70%|███████   | 200/285 [03:20<01:30,  1.06s/it]Loading train:  71%|███████   | 201/285 [03:21<01:29,  1.07s/it]Loading train:  71%|███████   | 202/285 [03:22<01:26,  1.04s/it]Loading train:  71%|███████   | 203/285 [03:24<01:31,  1.11s/it]Loading train:  72%|███████▏  | 204/285 [03:25<01:28,  1.09s/it]Loading train:  72%|███████▏  | 205/285 [03:26<01:27,  1.09s/it]Loading train:  72%|███████▏  | 206/285 [03:27<01:20,  1.02s/it]Loading train:  73%|███████▎  | 207/285 [03:28<01:22,  1.06s/it]Loading train:  73%|███████▎  | 208/285 [03:29<01:24,  1.10s/it]Loading train:  73%|███████▎  | 209/285 [03:30<01:28,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [03:31<01:17,  1.04s/it]Loading train:  74%|███████▍  | 211/285 [03:32<01:20,  1.09s/it]Loading train:  74%|███████▍  | 212/285 [03:34<01:24,  1.16s/it]Loading train:  75%|███████▍  | 213/285 [03:35<01:20,  1.11s/it]Loading train:  75%|███████▌  | 214/285 [03:36<01:16,  1.08s/it]Loading train:  75%|███████▌  | 215/285 [03:37<01:23,  1.19s/it]Loading train:  76%|███████▌  | 216/285 [03:38<01:23,  1.21s/it]Loading train:  76%|███████▌  | 217/285 [03:40<01:40,  1.48s/it]Loading train:  76%|███████▋  | 218/285 [03:42<01:48,  1.62s/it]Loading train:  77%|███████▋  | 219/285 [03:45<01:59,  1.80s/it]Loading train:  77%|███████▋  | 220/285 [03:46<01:44,  1.61s/it]Loading train:  78%|███████▊  | 221/285 [03:47<01:37,  1.52s/it]Loading train:  78%|███████▊  | 222/285 [03:49<01:42,  1.62s/it]Loading train:  78%|███████▊  | 223/285 [03:51<01:42,  1.65s/it]Loading train:  79%|███████▊  | 224/285 [03:52<01:33,  1.53s/it]Loading train:  79%|███████▉  | 225/285 [03:53<01:26,  1.43s/it]Loading train:  79%|███████▉  | 226/285 [03:55<01:27,  1.49s/it]Loading train:  80%|███████▉  | 227/285 [03:56<01:25,  1.47s/it]Loading train:  80%|████████  | 228/285 [03:58<01:21,  1.42s/it]Loading train:  80%|████████  | 229/285 [03:59<01:16,  1.37s/it]Loading train:  81%|████████  | 230/285 [04:00<01:08,  1.25s/it]Loading train:  81%|████████  | 231/285 [04:01<01:03,  1.18s/it]Loading train:  81%|████████▏ | 232/285 [04:02<01:00,  1.14s/it]Loading train:  82%|████████▏ | 233/285 [04:03<00:55,  1.07s/it]Loading train:  82%|████████▏ | 234/285 [04:04<00:56,  1.11s/it]Loading train:  82%|████████▏ | 235/285 [04:05<00:52,  1.04s/it]Loading train:  83%|████████▎ | 236/285 [04:06<00:55,  1.13s/it]Loading train:  83%|████████▎ | 237/285 [04:07<00:54,  1.14s/it]Loading train:  84%|████████▎ | 238/285 [04:09<00:54,  1.16s/it]Loading train:  84%|████████▍ | 239/285 [04:10<00:52,  1.15s/it]Loading train:  84%|████████▍ | 240/285 [04:11<00:50,  1.13s/it]Loading train:  85%|████████▍ | 241/285 [04:11<00:44,  1.02s/it]Loading train:  85%|████████▍ | 242/285 [04:12<00:41,  1.03it/s]Loading train:  85%|████████▌ | 243/285 [04:13<00:38,  1.09it/s]Loading train:  86%|████████▌ | 244/285 [04:14<00:42,  1.04s/it]Loading train:  86%|████████▌ | 245/285 [04:15<00:39,  1.00it/s]Loading train:  86%|████████▋ | 246/285 [04:17<00:41,  1.07s/it]Loading train:  87%|████████▋ | 247/285 [04:18<00:40,  1.08s/it]Loading train:  87%|████████▋ | 248/285 [04:19<00:43,  1.17s/it]Loading train:  87%|████████▋ | 249/285 [04:21<00:52,  1.47s/it]Loading train:  88%|████████▊ | 250/285 [04:23<00:58,  1.67s/it]Loading train:  88%|████████▊ | 251/285 [04:25<00:59,  1.74s/it]Loading train:  88%|████████▊ | 252/285 [04:27<00:53,  1.63s/it]Loading train:  89%|████████▉ | 253/285 [04:28<00:47,  1.49s/it]Loading train:  89%|████████▉ | 254/285 [04:30<00:51,  1.67s/it]Loading train:  89%|████████▉ | 255/285 [04:32<00:52,  1.75s/it]Loading train:  90%|████████▉ | 256/285 [04:33<00:47,  1.63s/it]Loading train:  90%|█████████ | 257/285 [04:35<00:48,  1.74s/it]Loading train:  91%|█████████ | 258/285 [04:37<00:46,  1.71s/it]Loading train:  91%|█████████ | 259/285 [04:38<00:42,  1.64s/it]Loading train:  91%|█████████ | 260/285 [04:40<00:38,  1.53s/it]Loading train:  92%|█████████▏| 261/285 [04:41<00:34,  1.43s/it]Loading train:  92%|█████████▏| 262/285 [04:42<00:31,  1.36s/it]Loading train:  92%|█████████▏| 263/285 [04:43<00:30,  1.37s/it]Loading train:  93%|█████████▎| 264/285 [04:45<00:30,  1.44s/it]Loading train:  93%|█████████▎| 265/285 [04:46<00:29,  1.47s/it]Loading train:  93%|█████████▎| 266/285 [04:48<00:28,  1.52s/it]Loading train:  94%|█████████▎| 267/285 [04:50<00:28,  1.58s/it]Loading train:  94%|█████████▍| 268/285 [04:51<00:25,  1.53s/it]Loading train:  94%|█████████▍| 269/285 [04:53<00:23,  1.46s/it]Loading train:  95%|█████████▍| 270/285 [04:54<00:20,  1.36s/it]Loading train:  95%|█████████▌| 271/285 [04:55<00:18,  1.31s/it]Loading train:  95%|█████████▌| 272/285 [04:56<00:17,  1.33s/it]Loading train:  96%|█████████▌| 273/285 [04:57<00:14,  1.21s/it]Loading train:  96%|█████████▌| 274/285 [04:59<00:14,  1.33s/it]Loading train:  96%|█████████▋| 275/285 [05:00<00:12,  1.28s/it]Loading train:  97%|█████████▋| 276/285 [05:01<00:11,  1.30s/it]Loading train:  97%|█████████▋| 277/285 [05:03<00:10,  1.29s/it]Loading train:  98%|█████████▊| 278/285 [05:04<00:08,  1.25s/it]Loading train:  98%|█████████▊| 279/285 [05:05<00:07,  1.26s/it]Loading train:  98%|█████████▊| 280/285 [05:06<00:06,  1.23s/it]Loading train:  99%|█████████▊| 281/285 [05:07<00:05,  1.25s/it]Loading train:  99%|█████████▉| 282/285 [05:08<00:03,  1.18s/it]Loading train:  99%|█████████▉| 283/285 [05:10<00:02,  1.23s/it]Loading train: 100%|█████████▉| 284/285 [05:12<00:01,  1.39s/it]Loading train: 100%|██████████| 285/285 [05:13<00:00,  1.45s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 42.57it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:05, 47.07it/s]concatenating: train:   7%|▋         | 19/285 [00:00<00:05, 51.29it/s]concatenating: train:   9%|▉         | 26/285 [00:00<00:04, 54.21it/s]concatenating: train:  11%|█         | 31/285 [00:00<00:05, 47.45it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:05, 44.08it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:05, 46.15it/s]concatenating: train:  17%|█▋        | 48/285 [00:00<00:04, 48.57it/s]concatenating: train:  19%|█▉        | 54/285 [00:01<00:04, 48.03it/s]concatenating: train:  21%|██        | 60/285 [00:01<00:04, 49.13it/s]concatenating: train:  23%|██▎       | 65/285 [00:01<00:04, 48.88it/s]concatenating: train:  25%|██▍       | 70/285 [00:01<00:04, 46.43it/s]concatenating: train:  27%|██▋       | 76/285 [00:01<00:04, 47.45it/s]concatenating: train:  28%|██▊       | 81/285 [00:01<00:04, 46.00it/s]concatenating: train:  30%|███       | 86/285 [00:01<00:04, 46.66it/s]concatenating: train:  32%|███▏      | 92/285 [00:01<00:03, 49.51it/s]concatenating: train:  34%|███▍      | 98/285 [00:01<00:03, 49.16it/s]concatenating: train:  36%|███▌      | 103/285 [00:02<00:04, 42.37it/s]concatenating: train:  38%|███▊      | 109/285 [00:02<00:03, 45.21it/s]concatenating: train:  41%|████      | 116/285 [00:02<00:03, 49.30it/s]concatenating: train:  43%|████▎     | 123/285 [00:02<00:03, 53.12it/s]concatenating: train:  46%|████▌     | 130/285 [00:02<00:02, 56.16it/s]concatenating: train:  48%|████▊     | 138/285 [00:02<00:02, 59.74it/s]concatenating: train:  51%|█████     | 145/285 [00:02<00:02, 48.92it/s]concatenating: train:  53%|█████▎    | 151/285 [00:03<00:02, 45.39it/s]concatenating: train:  55%|█████▍    | 156/285 [00:03<00:02, 44.23it/s]concatenating: train:  56%|█████▋    | 161/285 [00:03<00:02, 45.64it/s]concatenating: train:  59%|█████▊    | 167/285 [00:03<00:02, 47.84it/s]concatenating: train:  60%|██████    | 172/285 [00:03<00:02, 42.98it/s]concatenating: train:  62%|██████▏   | 178/285 [00:03<00:02, 45.69it/s]concatenating: train:  65%|██████▍   | 184/285 [00:03<00:02, 45.20it/s]concatenating: train:  67%|██████▋   | 191/285 [00:03<00:01, 50.14it/s]concatenating: train:  70%|██████▉   | 199/285 [00:03<00:01, 54.14it/s]concatenating: train:  72%|███████▏  | 205/285 [00:04<00:01, 52.93it/s]concatenating: train:  74%|███████▍  | 212/285 [00:04<00:01, 55.27it/s]concatenating: train:  77%|███████▋  | 220/285 [00:04<00:01, 59.45it/s]concatenating: train:  80%|███████▉  | 227/285 [00:04<00:01, 44.67it/s]concatenating: train:  82%|████████▏ | 234/285 [00:04<00:01, 49.69it/s]concatenating: train:  85%|████████▍ | 241/285 [00:04<00:00, 52.94it/s]concatenating: train:  88%|████████▊ | 250/285 [00:04<00:00, 60.28it/s]concatenating: train:  90%|█████████ | 257/285 [00:05<00:00, 50.95it/s]concatenating: train:  92%|█████████▏| 263/285 [00:05<00:00, 46.62it/s]concatenating: train:  94%|█████████▍| 269/285 [00:05<00:00, 44.43it/s]concatenating: train:  97%|█████████▋| 276/285 [00:05<00:00, 48.21it/s]concatenating: train:  99%|█████████▉| 282/285 [00:05<00:00, 46.09it/s]concatenating: train: 100%|██████████| 285/285 [00:05<00:00, 49.88it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:02<00:04,  2.02s/it]Loading test:  67%|██████▋   | 2/3 [00:03<00:01,  1.90s/it]Loading test: 100%|██████████| 3/3 [00:05<00:00,  1.85s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 26.65it/s]2019-07-11 10:22:22.754296: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 10:22:22.754497: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 10:22:22.754516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 10:22:22.754530: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 10:22:22.754922: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:12,  3.34it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:11,  3.45it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:01<00:14,  2.75it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:10,  3.58it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:02<00:10,  3.30it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:02<00:08,  3.75it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:02<00:10,  3.11it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:03<00:06,  4.03it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:03<00:07,  3.67it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:03<00:05,  4.25it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:04<00:06,  3.76it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:04<00:04,  4.63it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:04<00:03,  4.94it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:05<00:03,  4.25it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:05<00:03,  4.20it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:06<00:03,  3.47it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:06<00:02,  4.29it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:06<00:01,  4.95it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:07<00:01,  4.09it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:07<00:00,  4.52it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:07<00:00,  3.48it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:07<00:00,  5.53it/s]
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 20)   200         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 20)   80          conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 20)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 20)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 20)   3620        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 20)   80          conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 20)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 20)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 21)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   3800        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 20)   10820       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 20)   80          conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 20)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 20)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 20)   3620        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 52, 20)   80          conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 52, 20)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 80, 52, 20)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 80)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 52, 13)   1053        concatenate_8[0][0]              
==================================================================================================
Total params: 246,273
Trainable params: 71,433
Non-trainable params: 174,840
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2.4182 - acc: 0.5513 - mDice: 0.1560 - val_loss: 1.3396 - val_acc: 0.9098 - val_mDice: 0.3478

Epoch 00001: val_mDice improved from -inf to 0.34781, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 13s - loss: 0.8445 - acc: 0.8932 - mDice: 0.4160 - val_loss: 1.0008 - val_acc: 0.9164 - val_mDice: 0.4604

Epoch 00002: val_mDice improved from 0.34781 to 0.46039, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.6521 - acc: 0.9008 - mDice: 0.5041 - val_loss: 0.8873 - val_acc: 0.9252 - val_mDice: 0.5244

Epoch 00003: val_mDice improved from 0.46039 to 0.52439, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 12s - loss: 0.5655 - acc: 0.9092 - mDice: 0.5517 - val_loss: 0.8713 - val_acc: 0.9350 - val_mDice: 0.5330

Epoch 00004: val_mDice improved from 0.52439 to 0.53295, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5182 - acc: 0.9180 - mDice: 0.5797 - val_loss: 0.8629 - val_acc: 0.9365 - val_mDice: 0.5362

Epoch 00005: val_mDice improved from 0.53295 to 0.53624, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 13s - loss: 0.4906 - acc: 0.9252 - mDice: 0.5969 - val_loss: 0.8191 - val_acc: 0.9343 - val_mDice: 0.5446

Epoch 00006: val_mDice improved from 0.53624 to 0.54462, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4675 - acc: 0.9298 - mDice: 0.6112 - val_loss: 0.8113 - val_acc: 0.9341 - val_mDice: 0.5545

Epoch 00007: val_mDice improved from 0.54462 to 0.55446, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4481 - acc: 0.9326 - mDice: 0.6236 - val_loss: 0.8026 - val_acc: 0.9364 - val_mDice: 0.5588

Epoch 00008: val_mDice improved from 0.55446 to 0.55882, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 13s - loss: 0.4363 - acc: 0.9340 - mDice: 0.6312 - val_loss: 0.8230 - val_acc: 0.9342 - val_mDice: 0.5438

Epoch 00009: val_mDice did not improve from 0.55882
Epoch 10/300
 - 13s - loss: 0.4206 - acc: 0.9355 - mDice: 0.6415 - val_loss: 0.7890 - val_acc: 0.9372 - val_mDice: 0.5661

Epoch 00010: val_mDice improved from 0.55882 to 0.56611, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 13s - loss: 0.4092 - acc: 0.9366 - mDice: 0.6489 - val_loss: 0.7681 - val_acc: 0.9361 - val_mDice: 0.5754

Epoch 00011: val_mDice improved from 0.56611 to 0.57539, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 12s - loss: 0.4020 - acc: 0.9375 - mDice: 0.6538 - val_loss: 0.7765 - val_acc: 0.9417 - val_mDice: 0.5690

Epoch 00012: val_mDice did not improve from 0.57539
Epoch 13/300
 - 12s - loss: 0.3923 - acc: 0.9384 - mDice: 0.6604 - val_loss: 0.7887 - val_acc: 0.9365 - val_mDice: 0.5567

Epoch 00013: val_mDice did not improve from 0.57539
Epoch 14/300
 - 13s - loss: 0.3874 - acc: 0.9389 - mDice: 0.6638 - val_loss: 0.7927 - val_acc: 0.9289 - val_mDice: 0.5615

Epoch 00014: val_mDice did not improve from 0.57539
Epoch 15/300
 - 13s - loss: 0.3789 - acc: 0.9395 - mDice: 0.6695 - val_loss: 0.7759 - val_acc: 0.9357 - val_mDice: 0.5595

Epoch 00015: val_mDice did not improve from 0.57539
Epoch 16/300
 - 13s - loss: 0.3711 - acc: 0.9401 - mDice: 0.6749 - val_loss: 0.7477 - val_acc: 0.9414 - val_mDice: 0.5802

Epoch 00016: val_mDice improved from 0.57539 to 0.58025, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 17/300
 - 13s - loss: 0.3672 - acc: 0.9406 - mDice: 0.6778 - val_loss: 0.7347 - val_acc: 0.9422 - val_mDice: 0.5822

Epoch 00017: val_mDice improved from 0.58025 to 0.58220, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 18/300
 - 13s - loss: 0.3662 - acc: 0.9408 - mDice: 0.6787 - val_loss: 0.7676 - val_acc: 0.9408 - val_mDice: 0.5734

Epoch 00018: val_mDice did not improve from 0.58220
Epoch 19/300
 - 13s - loss: 0.3603 - acc: 0.9413 - mDice: 0.6828 - val_loss: 0.7575 - val_acc: 0.9415 - val_mDice: 0.5801

Epoch 00019: val_mDice did not improve from 0.58220
Epoch 20/300
 - 13s - loss: 0.3550 - acc: 0.9417 - mDice: 0.6864 - val_loss: 0.7911 - val_acc: 0.9418 - val_mDice: 0.5724

Epoch 00020: val_mDice did not improve from 0.58220
Epoch 21/300
 - 13s - loss: 0.3501 - acc: 0.9423 - mDice: 0.6899 - val_loss: 0.7717 - val_acc: 0.9422 - val_mDice: 0.5792

Epoch 00021: val_mDice did not improve from 0.58220
Epoch 22/300
 - 13s - loss: 0.3461 - acc: 0.9426 - mDice: 0.6928 - val_loss: 0.7649 - val_acc: 0.9408 - val_mDice: 0.5738

Epoch 00022: val_mDice did not improve from 0.58220
Epoch 23/300
 - 13s - loss: 0.3451 - acc: 0.9428 - mDice: 0.6934 - val_loss: 0.7767 - val_acc: 0.9406 - val_mDice: 0.5672

Epoch 00023: val_mDice did not improve from 0.58220
Epoch 24/300
 - 13s - loss: 0.3416 - acc: 0.9432 - mDice: 0.6960 - val_loss: 0.7440 - val_acc: 0.9380 - val_mDice: 0.5620

Epoch 00024: val_mDice did not improve from 0.58220
Epoch 25/300
 - 12s - loss: 0.3372 - acc: 0.9436 - mDice: 0.6992 - val_loss: 0.7507 - val_acc: 0.9392 - val_mDice: 0.5778

Epoch 00025: val_mDice did not improve from 0.58220
Epoch 26/300
 - 12s - loss: 0.3346 - acc: 0.9438 - mDice: 0.7011 - val_loss: 0.7611 - val_acc: 0.9396 - val_mDice: 0.5710

Epoch 00026: val_mDice did not improve from 0.58220
Epoch 27/300
 - 14s - loss: 0.3321 - acc: 0.9440 - mDice: 0.7030 - val_loss: 0.7756 - val_acc: 0.9412 - val_mDice: 0.5697

Epoch 00027: val_mDice did not improve from 0.58220
Epoch 28/300
 - 13s - loss: 0.3307 - acc: 0.9442 - mDice: 0.7039 - val_loss: 0.7672 - val_acc: 0.9416 - val_mDice: 0.5704

Epoch 00028: val_mDice did not improve from 0.58220
Epoch 29/300
 - 13s - loss: 0.3270 - acc: 0.9445 - mDice: 0.7066 - val_loss: 0.7647 - val_acc: 0.9376 - val_mDice: 0.5623

Epoch 00029: val_mDice did not improve from 0.58220
Epoch 30/300
 - 13s - loss: 0.3238 - acc: 0.9448 - mDice: 0.7090 - val_loss: 0.7712 - val_acc: 0.9364 - val_mDice: 0.5521

Epoch 00030: val_mDice did not improve from 0.58220
Epoch 31/300
 - 13s - loss: 0.3240 - acc: 0.9449 - mDice: 0.7088 - val_loss: 0.7459 - val_acc: 0.9409 - val_mDice: 0.5785

Epoch 00031: val_mDice did not improve from 0.58220
Epoch 32/300
 - 13s - loss: 0.3212 - acc: 0.9451 - mDice: 0.7109 - val_loss: 0.7297 - val_acc: 0.9400 - val_mDice: 0.5686

Epoch 00032: val_mDice did not improve from 0.58220
Epoch 33/300
 - 14s - loss: 0.3197 - acc: 0.9451 - mDice: 0.7119 - val_loss: 0.7913 - val_acc: 0.9417 - val_mDice: 0.5668

Epoch 00033: val_mDice did not improve from 0.58220
Epoch 34/300
 - 13s - loss: 0.3166 - acc: 0.9454 - mDice: 0.7143 - val_loss: 0.7731 - val_acc: 0.9414 - val_mDice: 0.5667

Epoch 00034: val_mDice did not improve from 0.58220
Epoch 35/300
 - 13s - loss: 0.3163 - acc: 0.9455 - mDice: 0.7145 - val_loss: 0.7962 - val_acc: 0.9422 - val_mDice: 0.5711

Epoch 00035: val_mDice did not improve from 0.58220
Epoch 36/300
 - 13s - loss: 0.3148 - acc: 0.9457 - mDice: 0.7157 - val_loss: 0.7895 - val_acc: 0.9417 - val_mDice: 0.5701

Epoch 00036: val_mDice did not improve from 0.58220
Epoch 37/300
 - 13s - loss: 0.3113 - acc: 0.9460 - mDice: 0.7183 - val_loss: 0.7865 - val_acc: 0.9407 - val_mDice: 0.5715

Epoch 00037: val_mDice did not improve from 0.58220
Epoch 38/300
 - 13s - loss: 0.3085 - acc: 0.9462 - mDice: 0.7203 - val_loss: 0.7312 - val_acc: 0.9414 - val_mDice: 0.5668

Epoch 00038: val_mDice did not improve from 0.58220
Epoch 39/300
 - 13s - loss: 0.3095 - acc: 0.9462 - mDice: 0.7196 - val_loss: 0.7656 - val_acc: 0.9445 - val_mDice: 0.5710

Epoch 00039: val_mDice did not improve from 0.58220
Epoch 40/300
 - 13s - loss: 0.3055 - acc: 0.9464 - mDice: 0.7226 - val_loss: 0.7986 - val_acc: 0.9425 - val_mDice: 0.5724

Epoch 00040: val_mDice did not improve from 0.58220
Epoch 41/300
 - 13s - loss: 0.3069 - acc: 0.9464 - mDice: 0.7215 - val_loss: 0.7581 - val_acc: 0.9417 - val_mDice: 0.5694

Epoch 00041: val_mDice did not improve from 0.58220
Epoch 42/300
 - 13s - loss: 0.3051 - acc: 0.9465 - mDice: 0.7230 - val_loss: 0.7995 - val_acc: 0.9440 - val_mDice: 0.5707

Epoch 00042: val_mDice did not improve from 0.58220
Epoch 43/300
 - 13s - loss: 0.3030 - acc: 0.9467 - mDice: 0.7245 - val_loss: 0.7207 - val_acc: 0.9436 - val_mDice: 0.5823

Epoch 00043: val_mDice improved from 0.58220 to 0.58226, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM20_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 44/300
 - 13s - loss: 0.3046 - acc: 0.9466 - mDice: 0.7233 - val_loss: 0.7714 - val_acc: 0.9444 - val_mDice: 0.5708

Epoch 00044: val_mDice did not improve from 0.58226
Epoch 45/300
 - 12s - loss: 0.3000 - acc: 0.9469 - mDice: 0.7267 - val_loss: 0.6732 - val_acc: 0.9417 - val_mDice: 0.5708

Epoch 00045: val_mDice did not improve from 0.58226
Epoch 46/300
 - 12s - loss: 0.2990 - acc: 0.9469 - mDice: 0.7274 - val_loss: 0.7942 - val_acc: 0.9404 - val_mDice: 0.5573

Epoch 00046: val_mDice did not improve from 0.58226
Epoch 47/300
 - 13s - loss: 0.2975 - acc: 0.9471 - mDice: 0.7287 - val_loss: 0.7030 - val_acc: 0.9428 - val_mDice: 0.5661

Epoch 00047: val_mDice did not improve from 0.58226
Epoch 48/300
 - 13s - loss: 0.2977 - acc: 0.9471 - mDice: 0.7285 - val_loss: 0.7172 - val_acc: 0.9395 - val_mDice: 0.5660

Epoch 00048: val_mDice did not improve from 0.58226
Epoch 49/300
 - 13s - loss: 0.2935 - acc: 0.9475 - mDice: 0.7317 - val_loss: 0.7259 - val_acc: 0.9449 - val_mDice: 0.5796

Epoch 00049: val_mDice did not improve from 0.58226
Epoch 50/300
 - 13s - loss: 0.2963 - acc: 0.9473 - mDice: 0.7296 - val_loss: 0.7121 - val_acc: 0.9427 - val_mDice: 0.5758

Epoch 00050: val_mDice did not improve from 0.58226
Epoch 51/300
 - 13s - loss: 0.2948 - acc: 0.9474 - mDice: 0.7307 - val_loss: 0.6855 - val_acc: 0.9403 - val_mDice: 0.5752

Epoch 00051: val_mDice did not improve from 0.58226
Epoch 52/300
 - 12s - loss: 0.2939 - acc: 0.9475 - mDice: 0.7314 - val_loss: 0.7428 - val_acc: 0.9425 - val_mDice: 0.5702

Epoch 00052: val_mDice did not improve from 0.58226
Epoch 53/300
 - 13s - loss: 0.2913 - acc: 0.9477 - mDice: 0.7333 - val_loss: 0.7236 - val_acc: 0.9401 - val_mDice: 0.5734

Epoch 00053: val_mDice did not improve from 0.58226
Epoch 54/300
 - 13s - loss: 0.2897 - acc: 0.9478 - mDice: 0.7346 - val_loss: 0.6869 - val_acc: 0.9438 - val_mDice: 0.5790

Epoch 00054: val_mDice did not improve from 0.58226
Epoch 55/300
 - 12s - loss: 0.2907 - acc: 0.9478 - mDice: 0.7339 - val_loss: 0.6909 - val_acc: 0.9389 - val_mDice: 0.5622

Epoch 00055: val_mDice did not improve from 0.58226
Epoch 56/300
 - 13s - loss: 0.2885 - acc: 0.9479 - mDice: 0.7356 - val_loss: 0.7739 - val_acc: 0.9434 - val_mDice: 0.5703

Epoch 00056: val_mDice did not improve from 0.58226
Epoch 57/300
 - 13s - loss: 0.2901 - acc: 0.9477 - mDice: 0.7343 - val_loss: 0.7317 - val_acc: 0.9411 - val_mDice: 0.5622

Epoch 00057: val_mDice did not improve from 0.58226
Epoch 58/300
 - 14s - loss: 0.2875 - acc: 0.9480 - mDice: 0.7364 - val_loss: 0.7394 - val_acc: 0.9419 - val_mDice: 0.5513

Epoch 00058: val_mDice did not improve from 0.58226
Epoch 59/300
 - 13s - loss: 0.2867 - acc: 0.9481 - mDice: 0.7369 - val_loss: 0.7070 - val_acc: 0.9409 - val_mDice: 0.5704

Epoch 00059: val_mDice did not improve from 0.58226
Epoch 60/300
 - 13s - loss: 0.2835 - acc: 0.9484 - mDice: 0.7394 - val_loss: 0.7246 - val_acc: 0.9405 - val_mDice: 0.5722

Epoch 00060: val_mDice did not improve from 0.58226
Epoch 61/300
 - 13s - loss: 0.2843 - acc: 0.9484 - mDice: 0.7388 - val_loss: 0.6930 - val_acc: 0.9420 - val_mDice: 0.5652

Epoch 00061: val_mDice did not improve from 0.58226
Epoch 62/300
 - 12s - loss: 0.2834 - acc: 0.9485 - mDice: 0.7394 - val_loss: 0.7597 - val_acc: 0.9429 - val_mDice: 0.5719

Epoch 00062: val_mDice did not improve from 0.58226
Epoch 63/300
 - 13s - loss: 0.2829 - acc: 0.9484 - mDice: 0.7399 - val_loss: 0.7426 - val_acc: 0.9417 - val_mDice: 0.5677

Epoch 00063: val_mDice did not improve from 0.58226
Epoch 64/300
 - 12s - loss: 0.2836 - acc: 0.9485 - mDice: 0.7393 - val_loss: 0.7188 - val_acc: 0.9439 - val_mDice: 0.5745

Epoch 00064: val_mDice did not improve from 0.58226
Epoch 65/300
 - 13s - loss: 0.2834 - acc: 0.9485 - mDice: 0.7395 - val_loss: 0.7596 - val_acc: 0.9436 - val_mDice: 0.5711

Epoch 00065: val_mDice did not improve from 0.58226
Epoch 66/300
 - 13s - loss: 0.2824 - acc: 0.9485 - mDice: 0.7402 - val_loss: 0.7044 - val_acc: 0.9426 - val_mDice: 0.5766

Epoch 00066: val_mDice did not improve from 0.58226
Epoch 67/300
 - 12s - loss: 0.2809 - acc: 0.9487 - mDice: 0.7414 - val_loss: 0.7368 - val_acc: 0.9431 - val_mDice: 0.5735

Epoch 00067: val_mDice did not improve from 0.58226
Epoch 68/300
 - 13s - loss: 0.2798 - acc: 0.9486 - mDice: 0.7422 - val_loss: 0.7548 - val_acc: 0.9443 - val_mDice: 0.5749

Epoch 00068: val_mDice did not improve from 0.58226
Epoch 69/300
 - 12s - loss: 0.2782 - acc: 0.9489 - mDice: 0.7435 - val_loss: 0.6847 - val_acc: 0.9437 - val_mDice: 0.5680

Epoch 00069: val_mDice did not improve from 0.58226
Epoch 70/300
 - 12s - loss: 0.2778 - acc: 0.9489 - mDice: 0.7438 - val_loss: 0.7405 - val_acc: 0.9399 - val_mDice: 0.5591

Epoch 00070: val_mDice did not improve from 0.58226
Epoch 71/300
 - 13s - loss: 0.2776 - acc: 0.9489 - mDice: 0.7441 - val_loss: 0.6988 - val_acc: 0.9442 - val_mDice: 0.5729

Epoch 00071: val_mDice did not improve from 0.58226
Epoch 72/300
 - 13s - loss: 0.2755 - acc: 0.9491 - mDice: 0.7456 - val_loss: 0.7504 - val_acc: 0.9427 - val_mDice: 0.5760

Epoch 00072: val_mDice did not improve from 0.58226
Epoch 73/300
 - 13s - loss: 0.2765 - acc: 0.9490 - mDice: 0.7449 - val_loss: 0.7264 - val_acc: 0.9420 - val_mDice: 0.5680

Epoch 00073: val_mDice did not improve from 0.58226
Epoch 74/300
 - 13s - loss: 0.2752 - acc: 0.9491 - mDice: 0.7459 - val_loss: 0.7163 - val_acc: 0.9417 - val_mDice: 0.5665

Epoch 00074: val_mDice did not improve from 0.58226
Epoch 75/300
 - 13s - loss: 0.2739 - acc: 0.9491 - mDice: 0.7469 - val_loss: 0.7133 - val_acc: 0.9434 - val_mDice: 0.5663

Epoch 00075: val_mDice did not improve from 0.58226
Epoch 76/300
 - 13s - loss: 0.2741 - acc: 0.9492 - mDice: 0.7467 - val_loss: 0.7434 - val_acc: 0.9404 - val_mDice: 0.5635

Epoch 00076: val_mDice did not improve from 0.58226
Epoch 77/300
 - 13s - loss: 0.2745 - acc: 0.9492 - mDice: 0.7465 - val_loss: 0.6625 - val_acc: 0.9439 - val_mDice: 0.5751

Epoch 00077: val_mDice did not improve from 0.58226
Epoch 78/300
 - 13s - loss: 0.2737 - acc: 0.9492 - mDice: 0.7470 - val_loss: 0.6719 - val_acc: 0.9439 - val_mDice: 0.5685

Epoch 00078: val_mDice did not improve from 0.58226
Epoch 79/300
 - 13s - loss: 0.2725 - acc: 0.9493 - mDice: 0.7479 - val_loss: 0.7146 - val_acc: 0.9436 - val_mDice: 0.5708

Epoch 00079: val_mDice did not improve from 0.58226
Epoch 80/300
 - 13s - loss: 0.2742 - acc: 0.9491 - mDice: 0.7467 - val_loss: 0.7154 - val_acc: 0.9435 - val_mDice: 0.5738

Epoch 00080: val_mDice did not improve from 0.58226
Epoch 81/300
 - 13s - loss: 0.2741 - acc: 0.9492 - mDice: 0.7467 - val_loss: 0.7203 - val_acc: 0.9424 - val_mDice: 0.5633

Epoch 00081: val_mDice did not improve from 0.58226
Epoch 82/300
 - 13s - loss: 0.2720 - acc: 0.9493 - mDice: 0.7484 - val_loss: 0.6789 - val_acc: 0.9401 - val_mDice: 0.5730

Epoch 00082: val_mDice did not improve from 0.58226
Epoch 83/300
 - 13s - loss: 0.2705 - acc: 0.9494 - mDice: 0.7495 - val_loss: 0.7070 - val_acc: 0.9419 - val_mDice: 0.5759

Epoch 00083: val_mDice did not improve from 0.58226
Restoring model weights from the end of the best epoch
Epoch 00083: early stopping
{'val_loss': [1.3396388177688305, 1.0008479150441976, 0.8872519731521606, 0.871256968149772, 0.862857841528379, 0.8191240888375503, 0.8113458569233234, 0.8025681376457214, 0.8230412969222436, 0.7889930514188913, 0.768142085808974, 0.7764572042685288, 0.7887362746091989, 0.7927342309401586, 0.7759032111901504, 0.747685255912634, 0.7347378409825839, 0.7676072074816778, 0.7574615994325051, 0.7910801011782426, 0.7717287047551229, 0.7649363325192378, 0.7766960882223569, 0.7439870238304138, 0.7507370698910493, 0.7611418458131644, 0.7755944407903231, 0.7672409896667187, 0.7647169965964097, 0.7711725097436172, 0.7459436689431851, 0.7297260211064265, 0.7913290858268738, 0.773054512647482, 0.7961679949210241, 0.7894852642829602, 0.7864782328789051, 0.7312067105219915, 0.7656095532270578, 0.7985818890424875, 0.7581307567082919, 0.7994596041165866, 0.7207335577561305, 0.7713961463708144, 0.6731819625084217, 0.79424682030311, 0.7030456845576947, 0.7172219455242157, 0.7259232940582129, 0.7121017735738021, 0.6855246837322528, 0.7427643697995406, 0.7236292155889364, 0.6869084605803857, 0.6908848102276142, 0.7739175603939936, 0.7317295143237481, 0.7394489370859586, 0.7070137904240534, 0.7245735709483807, 0.6930474226291363, 0.7596602210631738, 0.7425604714797094, 0.7187687571232135, 0.7596365167544439, 0.704428338087522, 0.7368448651753939, 0.7548402181038489, 0.6847102412810693, 0.7404798040023217, 0.6987714446507968, 0.7504294147858253, 0.7264264661532182, 0.716336170068154, 0.7132585300849035, 0.7433609641515292, 0.662467339864144, 0.6718573799500098, 0.7146050150577838, 0.7154152209942157, 0.7203073180638827, 0.6789108125063089, 0.7069639838658847], 'val_acc': [0.9098303455572861, 0.9163993069758782, 0.9252103246175326, 0.9350014076783106, 0.9364922551008371, 0.9343264653132513, 0.9340745027248676, 0.9363882495806768, 0.934180871798442, 0.9372134139904609, 0.9361178072599264, 0.9417067582790668, 0.9365431024478033, 0.9288831353187561, 0.9357156134568728, 0.9413854709038367, 0.9422152592585638, 0.9408445770923908, 0.9415333683674152, 0.9417783961846278, 0.9422429547860072, 0.9407660204630631, 0.9406227033871871, 0.9379645998661335, 0.9392173702900226, 0.9395964558307941, 0.9411612657400278, 0.9415842180068676, 0.9375993655278132, 0.9363604921561021, 0.9409046929616195, 0.9399708830393277, 0.9416905251833109, 0.9414201355897464, 0.9421736368766198, 0.9417183147026942, 0.9406573474407196, 0.9414455455083114, 0.9444827231077048, 0.9425180485615363, 0.9416997845356281, 0.9439834608481481, 0.9435535485927875, 0.9443902442088494, 0.9416558673748603, 0.9403915634522071, 0.942793105657284, 0.9395155402330252, 0.9449334236291739, 0.9426567050126883, 0.94031989803681, 0.9424695028708532, 0.9401419231524835, 0.9437985259753007, 0.9389076439233927, 0.9433778616098257, 0.9411150262906001, 0.9418569872012506, 0.9408538501996261, 0.9405441238329961, 0.9420441824656266, 0.9428531573368952, 0.941681330020611, 0.9438701959756705, 0.9436020828210391, 0.9425804546246161, 0.9431328315001267, 0.9443371112530048, 0.9437106916537652, 0.9399292583648975, 0.9441614311475021, 0.9427144963007706, 0.9420256958558009, 0.9417113615916326, 0.9433501316950872, 0.940398477591001, 0.943872522849303, 0.9438586395520431, 0.9436274743997134, 0.9434726077776688, 0.9424209503027109, 0.9401141726053678, 0.9419494362977835], 'val_mDice': [0.3478051902583012, 0.460392490029335, 0.524392863878837, 0.5329502270771906, 0.5362446875526354, 0.5446221278263972, 0.5544594703958585, 0.5588202081047572, 0.5438412187191156, 0.5661125286267354, 0.5753865505640323, 0.5690443641864337, 0.5567388752332101, 0.56150716313949, 0.5595460551289412, 0.5802498041437223, 0.5821994050191, 0.573400093958928, 0.5801204122029818, 0.5723832089167374, 0.5792182064973391, 0.5737795887085108, 0.567202862065572, 0.5619931570612468, 0.5778291867329524, 0.5710378518471351, 0.5696643843100622, 0.5703643428591582, 0.562262165431793, 0.5521101596263739, 0.5785017145367769, 0.5686192913697317, 0.5667717955433406, 0.5666950075672224, 0.5711309737884082, 0.5700906102473919, 0.5714728419597332, 0.5667995340549029, 0.5710431446249669, 0.5724242690664071, 0.5693545656708571, 0.5706997920687382, 0.5822649798714198, 0.5707700229608096, 0.5707675860478327, 0.5572958107178028, 0.5660785276156205, 0.5660424312719932, 0.579573889191334, 0.5757896011838546, 0.575215852031341, 0.5701501770661428, 0.5734053930410972, 0.5789896593644068, 0.562223018361972, 0.5702775476070551, 0.5622179278960595, 0.5513290476340514, 0.5704005074042541, 0.5721984482728518, 0.5651675428335483, 0.5718777202642881, 0.5676711694552348, 0.5744804338766978, 0.5710854816895264, 0.5766212149308279, 0.5734509980449309, 0.5748756608137717, 0.5680466546462133, 0.5591312520779096, 0.5728699977581317, 0.5759873292767085, 0.5680001710469906, 0.5665439292788506, 0.5663102251979021, 0.5635123992195497, 0.5750909745693207, 0.5685059817937704, 0.5707971470860335, 0.573764403279011, 0.5633193432138517, 0.5730234923271033, 0.575906097315825], 'loss': [2.4181749222518927, 0.8444876694749622, 0.6520811648185454, 0.5654742765017654, 0.5181533327723169, 0.4905803093394153, 0.4674685472691399, 0.44808362935737833, 0.4362701452367697, 0.4205992747213989, 0.4091979291598911, 0.40198159736207434, 0.39231611349744727, 0.3874414237285687, 0.3788655667076095, 0.37109851346270556, 0.3671804660499882, 0.366233628075204, 0.36032453787884217, 0.35495753122477647, 0.35010406374931335, 0.3460746375570919, 0.3451226673794224, 0.34157213304003897, 0.33720339855441506, 0.33457356082011136, 0.3321214358816285, 0.33072068818400707, 0.3269980978170884, 0.3237926593832146, 0.32395730349648805, 0.3211992991418072, 0.3197407723325189, 0.3165992349949664, 0.31634435024108, 0.3147559777337841, 0.3113000103411041, 0.3085077015921318, 0.3095006783114339, 0.3054551807214422, 0.3068710075641353, 0.30507642066996554, 0.30299950301520756, 0.3046137865323219, 0.30004216713416315, 0.29903678157766467, 0.29746108714267466, 0.29771476597305724, 0.29348883948334464, 0.29634625853113966, 0.29478504316817566, 0.2939116135988576, 0.2913275539385792, 0.2896849367244321, 0.2907263102247125, 0.28853445039962605, 0.29005662233728574, 0.28752480644774286, 0.28674105372385356, 0.2834690612345112, 0.2843193888092551, 0.283446539869874, 0.28290082370125585, 0.2836264925288679, 0.2834472033982566, 0.28240742049489437, 0.2809473228423806, 0.27982128851639987, 0.27816425531451183, 0.2777931117697043, 0.2775628058456093, 0.2754855128239631, 0.2764725769719415, 0.27518340377122463, 0.27392013617121713, 0.2741234716641928, 0.27447973079460636, 0.2737381626217719, 0.2725288807647668, 0.27420297647923175, 0.27411673159262007, 0.27198245965564843, 0.27051795926314376], 'acc': [0.5512648438989297, 0.8932270182022296, 0.900752059611669, 0.9091882669847632, 0.9180146555701361, 0.9252263489908962, 0.9297679861148411, 0.9326021226967633, 0.9340395297795702, 0.9355360862734484, 0.9366209536067984, 0.9375066495926785, 0.9384446674185706, 0.9388726752017418, 0.9394536488205483, 0.9401105323544092, 0.9406090165200427, 0.9408123968910338, 0.9413213028708123, 0.9417462661885736, 0.942292418645271, 0.9426021697412807, 0.9428012516570468, 0.9431788674098346, 0.9436009521085508, 0.9437656962903435, 0.9440190742115445, 0.9442374637115268, 0.9445189727162958, 0.9447667610048314, 0.9448610727256881, 0.9451114773409487, 0.9451198777369244, 0.9453711074777034, 0.9455187319664786, 0.9456887495184608, 0.9459587342512846, 0.9462229494490901, 0.9461921981029006, 0.9464382815985489, 0.9463548807874439, 0.946517337608698, 0.9466580491130624, 0.9465899216252522, 0.946893244610714, 0.9469274528448975, 0.9471387739145458, 0.9471097538515858, 0.947498960759074, 0.9473039114825963, 0.9473962095141532, 0.9475075865236032, 0.9476705554181839, 0.9477837076598754, 0.9477946390406865, 0.947946098181063, 0.9477300779918216, 0.9480102378416356, 0.9480584783273946, 0.948396676296701, 0.948375104252707, 0.948463027414378, 0.948442832389947, 0.9484608778981697, 0.9484772369572018, 0.9484518359070894, 0.9486609349872621, 0.9486143127541409, 0.9489062183305454, 0.9488921429270321, 0.9488711940794757, 0.9490996949909952, 0.9490457780904505, 0.9490746664108193, 0.949081382996194, 0.9492076990580873, 0.9491830291777071, 0.9491678003971069, 0.9492547711487858, 0.9491067881965883, 0.9492436870815767, 0.9493374623331452, 0.9494462037376732], 'mDice': [0.1559715644349683, 0.4160282575126549, 0.5041140568802787, 0.5516509250236549, 0.5796961478176432, 0.5968720018011633, 0.6111556803081832, 0.6235548976183839, 0.6312036180335702, 0.6414533662892768, 0.6489088467694973, 0.6538285330071238, 0.6603531356030676, 0.6638348926579195, 0.669496404017556, 0.6749441581470307, 0.677763907273713, 0.6786558524077859, 0.6828067551171066, 0.6864101896863862, 0.6899189620586181, 0.692809053560382, 0.6933572087947111, 0.6960004834927371, 0.6992152315833896, 0.7011075700922424, 0.7029558646770175, 0.7039121346951719, 0.7066208248339401, 0.709009587676787, 0.7088008010826086, 0.7108927699051406, 0.711938148152616, 0.7142891460466372, 0.7145043341455827, 0.7157105630662052, 0.7182767034885266, 0.720320668682713, 0.7195879074026054, 0.7226168211344411, 0.7215213401284833, 0.7229563293724848, 0.7244581457687503, 0.7232684939646209, 0.7267091290093014, 0.7274254376154088, 0.7287468692533624, 0.7285176605676073, 0.7316775968195074, 0.729595533065291, 0.7307437574314827, 0.7313862937211133, 0.7333359800888627, 0.7346202183570147, 0.7339230848999027, 0.7355999007531113, 0.7343236426030492, 0.7363744001596119, 0.7369445505962814, 0.7394446234943616, 0.7387787895174932, 0.7394286952510835, 0.7398795962476603, 0.7393372429920103, 0.7394919523473354, 0.7402491305055383, 0.7413748523180395, 0.7422368143918185, 0.7435426062833094, 0.7438141145378991, 0.7440527981578517, 0.7456104507703991, 0.7448904022270713, 0.7458597956290381, 0.7468609916298611, 0.7467156378070465, 0.7464817045503004, 0.7469886419331798, 0.7479454284662868, 0.746657896276045, 0.7467362885104437, 0.7483632249892841, 0.7495409862137387]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.29s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:03<00:02,  2.07s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.87s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<08:53,  1.88s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:16,  1.75s/it]predicting train subjects:   1%|          | 3/285 [00:04<07:56,  1.69s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:23,  1.58s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<07:40,  1.64s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:21,  1.58s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<07:34,  1.63s/it]predicting train subjects:   3%|▎         | 8/285 [00:12<07:21,  1.59s/it]predicting train subjects:   3%|▎         | 9/285 [00:14<07:42,  1.68s/it]predicting train subjects:   4%|▎         | 10/285 [00:16<07:52,  1.72s/it]predicting train subjects:   4%|▍         | 11/285 [00:17<07:35,  1.66s/it]predicting train subjects:   4%|▍         | 12/285 [00:19<07:47,  1.71s/it]predicting train subjects:   5%|▍         | 13/285 [00:21<07:30,  1.66s/it]predicting train subjects:   5%|▍         | 14/285 [00:23<07:35,  1.68s/it]predicting train subjects:   5%|▌         | 15/285 [00:24<07:50,  1.74s/it]predicting train subjects:   6%|▌         | 16/285 [00:26<08:04,  1.80s/it]predicting train subjects:   6%|▌         | 17/285 [00:28<07:41,  1.72s/it]predicting train subjects:   6%|▋         | 18/285 [00:30<07:42,  1.73s/it]predicting train subjects:   7%|▋         | 19/285 [00:31<07:30,  1.69s/it]predicting train subjects:   7%|▋         | 20/285 [00:33<07:27,  1.69s/it]predicting train subjects:   7%|▋         | 21/285 [00:35<07:46,  1.77s/it]predicting train subjects:   8%|▊         | 22/285 [00:36<07:31,  1.72s/it]predicting train subjects:   8%|▊         | 23/285 [00:38<07:34,  1.74s/it]predicting train subjects:   8%|▊         | 24/285 [00:40<07:20,  1.69s/it]predicting train subjects:   9%|▉         | 25/285 [00:42<07:29,  1.73s/it]predicting train subjects:   9%|▉         | 26/285 [00:44<07:42,  1.79s/it]predicting train subjects:   9%|▉         | 27/285 [00:45<07:18,  1.70s/it]predicting train subjects:  10%|▉         | 28/285 [00:47<07:27,  1.74s/it]predicting train subjects:  10%|█         | 29/285 [00:49<07:18,  1.71s/it]predicting train subjects:  11%|█         | 30/285 [00:50<07:30,  1.77s/it]predicting train subjects:  11%|█         | 31/285 [00:52<07:36,  1.80s/it]predicting train subjects:  11%|█         | 32/285 [00:54<07:15,  1.72s/it]predicting train subjects:  12%|█▏        | 33/285 [00:56<07:16,  1.73s/it]predicting train subjects:  12%|█▏        | 34/285 [00:57<07:17,  1.74s/it]predicting train subjects:  12%|█▏        | 35/285 [00:59<07:30,  1.80s/it]predicting train subjects:  13%|█▎        | 36/285 [01:01<07:14,  1.75s/it]predicting train subjects:  13%|█▎        | 37/285 [01:03<07:16,  1.76s/it]predicting train subjects:  13%|█▎        | 38/285 [01:05<07:23,  1.79s/it]predicting train subjects:  14%|█▎        | 39/285 [01:06<06:57,  1.70s/it]predicting train subjects:  14%|█▍        | 40/285 [01:08<06:54,  1.69s/it]predicting train subjects:  14%|█▍        | 41/285 [01:09<06:34,  1.62s/it]predicting train subjects:  15%|█▍        | 42/285 [01:11<06:20,  1.56s/it]predicting train subjects:  15%|█▌        | 43/285 [01:12<06:26,  1.60s/it]predicting train subjects:  15%|█▌        | 44/285 [01:14<06:38,  1.65s/it]predicting train subjects:  16%|█▌        | 45/285 [01:16<06:27,  1.61s/it]predicting train subjects:  16%|█▌        | 46/285 [01:17<06:33,  1.64s/it]predicting train subjects:  16%|█▋        | 47/285 [01:19<06:21,  1.60s/it]predicting train subjects:  17%|█▋        | 48/285 [01:21<06:39,  1.69s/it]predicting train subjects:  17%|█▋        | 49/285 [01:23<06:56,  1.76s/it]predicting train subjects:  18%|█▊        | 50/285 [01:24<06:49,  1.74s/it]predicting train subjects:  18%|█▊        | 51/285 [01:26<06:55,  1.78s/it]predicting train subjects:  18%|█▊        | 52/285 [01:28<06:34,  1.69s/it]predicting train subjects:  19%|█▊        | 53/285 [01:29<06:29,  1.68s/it]predicting train subjects:  19%|█▉        | 54/285 [01:31<06:39,  1.73s/it]predicting train subjects:  19%|█▉        | 55/285 [01:33<06:25,  1.68s/it]predicting train subjects:  20%|█▉        | 56/285 [01:34<06:27,  1.69s/it]predicting train subjects:  20%|██        | 57/285 [01:36<06:10,  1.63s/it]predicting train subjects:  20%|██        | 58/285 [01:38<06:13,  1.65s/it]predicting train subjects:  21%|██        | 59/285 [01:39<06:26,  1.71s/it]predicting train subjects:  21%|██        | 60/285 [01:41<06:33,  1.75s/it]predicting train subjects:  21%|██▏       | 61/285 [01:43<06:18,  1.69s/it]predicting train subjects:  22%|██▏       | 62/285 [01:45<06:17,  1.69s/it]predicting train subjects:  22%|██▏       | 63/285 [01:46<06:18,  1.70s/it]predicting train subjects:  22%|██▏       | 64/285 [01:48<06:06,  1.66s/it]predicting train subjects:  23%|██▎       | 65/285 [01:50<06:08,  1.67s/it]predicting train subjects:  23%|██▎       | 66/285 [01:51<06:13,  1.71s/it]predicting train subjects:  24%|██▎       | 67/285 [01:53<06:15,  1.72s/it]predicting train subjects:  24%|██▍       | 68/285 [01:55<06:04,  1.68s/it]predicting train subjects:  24%|██▍       | 69/285 [01:57<06:13,  1.73s/it]predicting train subjects:  25%|██▍       | 70/285 [01:58<06:16,  1.75s/it]predicting train subjects:  25%|██▍       | 71/285 [02:00<06:11,  1.74s/it]predicting train subjects:  25%|██▌       | 72/285 [02:02<05:58,  1.68s/it]predicting train subjects:  26%|██▌       | 73/285 [02:03<05:54,  1.67s/it]predicting train subjects:  26%|██▌       | 74/285 [02:05<05:51,  1.67s/it]predicting train subjects:  26%|██▋       | 75/285 [02:07<05:49,  1.66s/it]predicting train subjects:  27%|██▋       | 76/285 [02:08<05:52,  1.69s/it]predicting train subjects:  27%|██▋       | 77/285 [02:10<05:40,  1.64s/it]predicting train subjects:  27%|██▋       | 78/285 [02:11<05:32,  1.61s/it]predicting train subjects:  28%|██▊       | 79/285 [02:13<05:46,  1.68s/it]predicting train subjects:  28%|██▊       | 80/285 [02:15<05:49,  1.70s/it]predicting train subjects:  28%|██▊       | 81/285 [02:16<05:35,  1.64s/it]predicting train subjects:  29%|██▉       | 82/285 [02:18<05:42,  1.69s/it]predicting train subjects:  29%|██▉       | 83/285 [02:20<05:37,  1.67s/it]predicting train subjects:  29%|██▉       | 84/285 [02:21<05:28,  1.63s/it]predicting train subjects:  30%|██▉       | 85/285 [02:23<05:35,  1.68s/it]predicting train subjects:  30%|███       | 86/285 [02:25<05:40,  1.71s/it]predicting train subjects:  31%|███       | 87/285 [02:27<05:39,  1.72s/it]predicting train subjects:  31%|███       | 88/285 [02:28<05:25,  1.65s/it]predicting train subjects:  31%|███       | 89/285 [02:30<05:26,  1.67s/it]predicting train subjects:  32%|███▏      | 90/285 [02:32<05:26,  1.67s/it]predicting train subjects:  32%|███▏      | 91/285 [02:33<05:14,  1.62s/it]predicting train subjects:  32%|███▏      | 92/285 [02:35<05:33,  1.73s/it]predicting train subjects:  33%|███▎      | 93/285 [02:37<05:26,  1.70s/it]predicting train subjects:  33%|███▎      | 94/285 [02:38<05:23,  1.69s/it]predicting train subjects:  33%|███▎      | 95/285 [02:40<05:26,  1.72s/it]predicting train subjects:  34%|███▎      | 96/285 [02:42<05:23,  1.71s/it]predicting train subjects:  34%|███▍      | 97/285 [02:44<05:16,  1.69s/it]predicting train subjects:  34%|███▍      | 98/285 [02:45<05:17,  1.70s/it]predicting train subjects:  35%|███▍      | 99/285 [02:47<05:26,  1.75s/it]predicting train subjects:  35%|███▌      | 100/285 [02:49<05:39,  1.84s/it]predicting train subjects:  35%|███▌      | 101/285 [02:51<05:18,  1.73s/it]predicting train subjects:  36%|███▌      | 102/285 [02:52<05:12,  1.71s/it]predicting train subjects:  36%|███▌      | 103/285 [02:54<05:00,  1.65s/it]predicting train subjects:  36%|███▋      | 104/285 [02:56<05:02,  1.67s/it]predicting train subjects:  37%|███▋      | 105/285 [02:57<05:09,  1.72s/it]predicting train subjects:  37%|███▋      | 106/285 [02:59<04:56,  1.65s/it]predicting train subjects:  38%|███▊      | 107/285 [03:01<05:00,  1.69s/it]predicting train subjects:  38%|███▊      | 108/285 [03:02<04:49,  1.64s/it]predicting train subjects:  38%|███▊      | 109/285 [03:04<04:50,  1.65s/it]predicting train subjects:  39%|███▊      | 110/285 [03:06<05:00,  1.72s/it]predicting train subjects:  39%|███▉      | 111/285 [03:07<04:48,  1.66s/it]predicting train subjects:  39%|███▉      | 112/285 [03:09<04:57,  1.72s/it]predicting train subjects:  40%|███▉      | 113/285 [03:11<05:08,  1.79s/it]predicting train subjects:  40%|████      | 114/285 [03:13<05:00,  1.76s/it]predicting train subjects:  40%|████      | 115/285 [03:14<04:56,  1.74s/it]predicting train subjects:  41%|████      | 116/285 [03:16<04:52,  1.73s/it]predicting train subjects:  41%|████      | 117/285 [03:18<04:39,  1.66s/it]predicting train subjects:  41%|████▏     | 118/285 [03:19<04:29,  1.61s/it]predicting train subjects:  42%|████▏     | 119/285 [03:21<04:29,  1.63s/it]predicting train subjects:  42%|████▏     | 120/285 [03:22<04:21,  1.58s/it]predicting train subjects:  42%|████▏     | 121/285 [03:24<04:21,  1.59s/it]predicting train subjects:  43%|████▎     | 122/285 [03:25<04:11,  1.54s/it]predicting train subjects:  43%|████▎     | 123/285 [03:27<04:01,  1.49s/it]predicting train subjects:  44%|████▎     | 124/285 [03:28<04:01,  1.50s/it]predicting train subjects:  44%|████▍     | 125/285 [03:30<03:55,  1.47s/it]predicting train subjects:  44%|████▍     | 126/285 [03:31<03:51,  1.46s/it]predicting train subjects:  45%|████▍     | 127/285 [03:32<03:50,  1.46s/it]predicting train subjects:  45%|████▍     | 128/285 [03:34<03:53,  1.48s/it]predicting train subjects:  45%|████▌     | 129/285 [03:36<03:52,  1.49s/it]predicting train subjects:  46%|████▌     | 130/285 [03:37<03:45,  1.45s/it]predicting train subjects:  46%|████▌     | 131/285 [03:38<03:40,  1.43s/it]predicting train subjects:  46%|████▋     | 132/285 [03:40<03:43,  1.46s/it]predicting train subjects:  47%|████▋     | 133/285 [03:41<03:38,  1.44s/it]predicting train subjects:  47%|████▋     | 134/285 [03:43<03:33,  1.41s/it]predicting train subjects:  47%|████▋     | 135/285 [03:44<03:31,  1.41s/it]predicting train subjects:  48%|████▊     | 136/285 [03:45<03:27,  1.39s/it]predicting train subjects:  48%|████▊     | 137/285 [03:47<03:38,  1.48s/it]predicting train subjects:  48%|████▊     | 138/285 [03:48<03:35,  1.47s/it]predicting train subjects:  49%|████▉     | 139/285 [03:50<03:35,  1.48s/it]predicting train subjects:  49%|████▉     | 140/285 [03:52<03:40,  1.52s/it]predicting train subjects:  49%|████▉     | 141/285 [03:53<03:31,  1.47s/it]predicting train subjects:  50%|████▉     | 142/285 [03:54<03:25,  1.44s/it]predicting train subjects:  50%|█████     | 143/285 [03:56<03:20,  1.41s/it]predicting train subjects:  51%|█████     | 144/285 [03:57<03:24,  1.45s/it]predicting train subjects:  51%|█████     | 145/285 [03:59<03:20,  1.43s/it]predicting train subjects:  51%|█████     | 146/285 [04:00<03:24,  1.47s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:02<03:25,  1.49s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:03<03:23,  1.48s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:04<03:17,  1.45s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:06<03:13,  1.43s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:07<03:16,  1.46s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:09<03:10,  1.43s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:10<03:09,  1.43s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:12<03:16,  1.50s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:13<03:13,  1.49s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:15<03:14,  1.51s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:16<03:08,  1.47s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:18<03:04,  1.45s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:19<02:57,  1.41s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:20<02:56,  1.41s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:22<03:01,  1.46s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:23<02:58,  1.45s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:25<03:00,  1.48s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:26<02:55,  1.45s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:28<02:51,  1.43s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:29<02:53,  1.46s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:31<02:56,  1.50s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:32<02:51,  1.46s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:34<02:48,  1.45s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:35<02:46,  1.44s/it]predicting train subjects:  60%|██████    | 171/285 [04:37<02:46,  1.46s/it]predicting train subjects:  60%|██████    | 172/285 [04:38<02:43,  1.45s/it]predicting train subjects:  61%|██████    | 173/285 [04:39<02:38,  1.42s/it]predicting train subjects:  61%|██████    | 174/285 [04:41<02:37,  1.42s/it]predicting train subjects:  61%|██████▏   | 175/285 [04:42<02:39,  1.45s/it]predicting train subjects:  62%|██████▏   | 176/285 [04:44<02:42,  1.49s/it]predicting train subjects:  62%|██████▏   | 177/285 [04:45<02:36,  1.45s/it]predicting train subjects:  62%|██████▏   | 178/285 [04:47<02:31,  1.42s/it]predicting train subjects:  63%|██████▎   | 179/285 [04:48<02:27,  1.39s/it]predicting train subjects:  63%|██████▎   | 180/285 [04:50<02:35,  1.48s/it]predicting train subjects:  64%|██████▎   | 181/285 [04:51<02:35,  1.50s/it]predicting train subjects:  64%|██████▍   | 182/285 [04:53<02:34,  1.50s/it]predicting train subjects:  64%|██████▍   | 183/285 [04:54<02:27,  1.45s/it]predicting train subjects:  65%|██████▍   | 184/285 [04:55<02:24,  1.43s/it]predicting train subjects:  65%|██████▍   | 185/285 [04:57<02:20,  1.41s/it]predicting train subjects:  65%|██████▌   | 186/285 [04:58<02:28,  1.50s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:00<02:36,  1.59s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:02<02:38,  1.64s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:03<02:29,  1.56s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:05<02:24,  1.52s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:06<02:25,  1.55s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:08<02:26,  1.57s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:09<02:17,  1.50s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:11<02:15,  1.49s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:12<02:09,  1.44s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:14<02:17,  1.55s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:16<02:21,  1.61s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:17<02:22,  1.64s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:19<02:18,  1.61s/it]predicting train subjects:  70%|███████   | 200/285 [05:20<02:10,  1.53s/it]predicting train subjects:  71%|███████   | 201/285 [05:22<02:12,  1.58s/it]predicting train subjects:  71%|███████   | 202/285 [05:24<02:10,  1.57s/it]predicting train subjects:  71%|███████   | 203/285 [05:25<02:08,  1.57s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:26<02:01,  1.50s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:28<01:57,  1.47s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:29<01:53,  1.44s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:31<01:57,  1.50s/it]predicting train subjects:  73%|███████▎  | 208/285 [05:33<02:00,  1.57s/it]predicting train subjects:  73%|███████▎  | 209/285 [05:34<02:02,  1.61s/it]predicting train subjects:  74%|███████▎  | 210/285 [05:36<01:52,  1.50s/it]predicting train subjects:  74%|███████▍  | 211/285 [05:37<01:47,  1.45s/it]predicting train subjects:  74%|███████▍  | 212/285 [05:38<01:49,  1.50s/it]predicting train subjects:  75%|███████▍  | 213/285 [05:40<01:50,  1.53s/it]predicting train subjects:  75%|███████▌  | 214/285 [05:41<01:43,  1.46s/it]predicting train subjects:  75%|███████▌  | 215/285 [05:43<01:47,  1.54s/it]predicting train subjects:  76%|███████▌  | 216/285 [05:44<01:41,  1.46s/it]predicting train subjects:  76%|███████▌  | 217/285 [05:46<01:45,  1.54s/it]predicting train subjects:  76%|███████▋  | 218/285 [05:48<01:45,  1.58s/it]predicting train subjects:  77%|███████▋  | 219/285 [05:49<01:45,  1.60s/it]predicting train subjects:  77%|███████▋  | 220/285 [05:51<01:38,  1.51s/it]predicting train subjects:  78%|███████▊  | 221/285 [05:52<01:33,  1.47s/it]predicting train subjects:  78%|███████▊  | 222/285 [05:54<01:33,  1.48s/it]predicting train subjects:  78%|███████▊  | 223/285 [05:55<01:27,  1.41s/it]predicting train subjects:  79%|███████▊  | 224/285 [05:56<01:25,  1.39s/it]predicting train subjects:  79%|███████▉  | 225/285 [05:57<01:21,  1.36s/it]predicting train subjects:  79%|███████▉  | 226/285 [05:59<01:26,  1.46s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:01<01:29,  1.54s/it]predicting train subjects:  80%|████████  | 228/285 [06:03<01:30,  1.59s/it]predicting train subjects:  80%|████████  | 229/285 [06:04<01:28,  1.59s/it]predicting train subjects:  81%|████████  | 230/285 [06:06<01:22,  1.50s/it]predicting train subjects:  81%|████████  | 231/285 [06:07<01:19,  1.46s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:08<01:18,  1.49s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:10<01:14,  1.44s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:11<01:17,  1.52s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:13<01:12,  1.45s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:14<01:14,  1.53s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:16<01:16,  1.59s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:18<01:16,  1.63s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:19<01:13,  1.61s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:21<01:08,  1.52s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:22<01:04,  1.46s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:23<01:01,  1.42s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:25<00:58,  1.40s/it]predicting train subjects:  86%|████████▌ | 244/285 [06:27<01:01,  1.50s/it]predicting train subjects:  86%|████████▌ | 245/285 [06:28<00:57,  1.45s/it]predicting train subjects:  86%|████████▋ | 246/285 [06:30<00:59,  1.53s/it]predicting train subjects:  87%|████████▋ | 247/285 [06:31<01:00,  1.60s/it]predicting train subjects:  87%|████████▋ | 248/285 [06:33<00:58,  1.59s/it]predicting train subjects:  87%|████████▋ | 249/285 [06:34<00:54,  1.51s/it]predicting train subjects:  88%|████████▊ | 250/285 [06:36<00:51,  1.46s/it]predicting train subjects:  88%|████████▊ | 251/285 [06:37<00:47,  1.41s/it]predicting train subjects:  88%|████████▊ | 252/285 [06:38<00:45,  1.38s/it]predicting train subjects:  89%|████████▉ | 253/285 [06:40<00:47,  1.49s/it]predicting train subjects:  89%|████████▉ | 254/285 [06:42<00:48,  1.57s/it]predicting train subjects:  89%|████████▉ | 255/285 [06:43<00:47,  1.58s/it]predicting train subjects:  90%|████████▉ | 256/285 [06:45<00:43,  1.50s/it]predicting train subjects:  90%|█████████ | 257/285 [06:46<00:41,  1.47s/it]predicting train subjects:  91%|█████████ | 258/285 [06:48<00:41,  1.53s/it]predicting train subjects:  91%|█████████ | 259/285 [06:49<00:40,  1.55s/it]predicting train subjects:  91%|█████████ | 260/285 [06:51<00:37,  1.49s/it]predicting train subjects:  92%|█████████▏| 261/285 [06:52<00:34,  1.45s/it]predicting train subjects:  92%|█████████▏| 262/285 [06:53<00:32,  1.40s/it]predicting train subjects:  92%|█████████▏| 263/285 [06:55<00:30,  1.38s/it]predicting train subjects:  93%|█████████▎| 264/285 [06:56<00:31,  1.49s/it]predicting train subjects:  93%|█████████▎| 265/285 [06:58<00:31,  1.57s/it]predicting train subjects:  93%|█████████▎| 266/285 [06:59<00:28,  1.51s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:01<00:26,  1.48s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:03<00:26,  1.54s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:04<00:24,  1.55s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:05<00:22,  1.47s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:07<00:20,  1.45s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:08<00:19,  1.49s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:10<00:17,  1.44s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:11<00:15,  1.41s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:13<00:14,  1.50s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:14<00:14,  1.57s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:16<00:12,  1.50s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:17<00:10,  1.47s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:19<00:09,  1.51s/it]predicting train subjects:  98%|█████████▊| 280/285 [07:20<00:07,  1.45s/it]predicting train subjects:  99%|█████████▊| 281/285 [07:22<00:05,  1.43s/it]predicting train subjects:  99%|█████████▉| 282/285 [07:23<00:04,  1.45s/it]predicting train subjects:  99%|█████████▉| 283/285 [07:25<00:03,  1.52s/it]predicting train subjects: 100%|█████████▉| 284/285 [07:26<00:01,  1.57s/it]predicting train subjects: 100%|██████████| 285/285 [07:28<00:00,  1.62s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<07:51,  1.66s/it]Loading train:   1%|          | 2/285 [00:02<07:04,  1.50s/it]Loading train:   1%|          | 3/285 [00:04<06:49,  1.45s/it]Loading train:   1%|▏         | 4/285 [00:05<06:22,  1.36s/it]Loading train:   2%|▏         | 5/285 [00:06<06:36,  1.42s/it]Loading train:   2%|▏         | 6/285 [00:07<06:15,  1.34s/it]Loading train:   2%|▏         | 7/285 [00:09<06:31,  1.41s/it]Loading train:   3%|▎         | 8/285 [00:10<06:27,  1.40s/it]Loading train:   3%|▎         | 9/285 [00:12<06:40,  1.45s/it]Loading train:   4%|▎         | 10/285 [00:13<06:15,  1.37s/it]Loading train:   4%|▍         | 11/285 [00:14<05:33,  1.22s/it]Loading train:   4%|▍         | 12/285 [00:15<05:14,  1.15s/it]Loading train:   5%|▍         | 13/285 [00:16<05:03,  1.12s/it]Loading train:   5%|▍         | 14/285 [00:17<05:10,  1.14s/it]Loading train:   5%|▌         | 15/285 [00:18<05:09,  1.15s/it]Loading train:   6%|▌         | 16/285 [00:19<05:01,  1.12s/it]Loading train:   6%|▌         | 17/285 [00:20<04:40,  1.05s/it]Loading train:   6%|▋         | 18/285 [00:22<05:03,  1.14s/it]Loading train:   7%|▋         | 19/285 [00:23<04:41,  1.06s/it]Loading train:   7%|▋         | 20/285 [00:24<04:29,  1.02s/it]Loading train:   7%|▋         | 21/285 [00:25<04:42,  1.07s/it]Loading train:   8%|▊         | 22/285 [00:26<04:24,  1.01s/it]Loading train:   8%|▊         | 23/285 [00:27<04:19,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:27<04:08,  1.05it/s]Loading train:   9%|▉         | 25/285 [00:29<04:26,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:30<04:23,  1.02s/it]Loading train:   9%|▉         | 27/285 [00:30<04:11,  1.03it/s]Loading train:  10%|▉         | 28/285 [00:32<04:27,  1.04s/it]Loading train:  10%|█         | 29/285 [00:33<04:34,  1.07s/it]Loading train:  11%|█         | 30/285 [00:34<04:31,  1.06s/it]Loading train:  11%|█         | 31/285 [00:35<04:28,  1.06s/it]Loading train:  11%|█         | 32/285 [00:36<04:19,  1.03s/it]Loading train:  12%|█▏        | 33/285 [00:37<04:19,  1.03s/it]Loading train:  12%|█▏        | 34/285 [00:38<04:28,  1.07s/it]Loading train:  12%|█▏        | 35/285 [00:39<04:22,  1.05s/it]Loading train:  13%|█▎        | 36/285 [00:40<04:15,  1.03s/it]Loading train:  13%|█▎        | 37/285 [00:41<04:09,  1.01s/it]Loading train:  13%|█▎        | 38/285 [00:42<04:18,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:43<04:01,  1.02it/s]Loading train:  14%|█▍        | 40/285 [00:44<04:10,  1.02s/it]Loading train:  14%|█▍        | 41/285 [00:45<03:53,  1.04it/s]Loading train:  15%|█▍        | 42/285 [00:46<03:36,  1.12it/s]Loading train:  15%|█▌        | 43/285 [00:47<03:49,  1.06it/s]Loading train:  15%|█▌        | 44/285 [00:48<04:03,  1.01s/it]Loading train:  16%|█▌        | 45/285 [00:49<03:50,  1.04it/s]Loading train:  16%|█▌        | 46/285 [00:50<03:56,  1.01it/s]Loading train:  16%|█▋        | 47/285 [00:51<03:47,  1.05it/s]Loading train:  17%|█▋        | 48/285 [00:52<03:47,  1.04it/s]Loading train:  17%|█▋        | 49/285 [00:53<04:05,  1.04s/it]Loading train:  18%|█▊        | 50/285 [00:54<04:05,  1.05s/it]Loading train:  18%|█▊        | 51/285 [00:55<04:17,  1.10s/it]Loading train:  18%|█▊        | 52/285 [00:56<03:53,  1.00s/it]Loading train:  19%|█▊        | 53/285 [00:57<04:03,  1.05s/it]Loading train:  19%|█▉        | 54/285 [00:58<04:09,  1.08s/it]Loading train:  19%|█▉        | 55/285 [00:59<03:50,  1.00s/it]Loading train:  20%|█▉        | 56/285 [01:00<03:51,  1.01s/it]Loading train:  20%|██        | 57/285 [01:01<03:38,  1.04it/s]Loading train:  20%|██        | 58/285 [01:02<03:41,  1.02it/s]Loading train:  21%|██        | 59/285 [01:03<03:41,  1.02it/s]Loading train:  21%|██        | 60/285 [01:04<03:43,  1.01it/s]Loading train:  21%|██▏       | 61/285 [01:05<03:29,  1.07it/s]Loading train:  22%|██▏       | 62/285 [01:06<03:28,  1.07it/s]Loading train:  22%|██▏       | 63/285 [01:07<03:34,  1.03it/s]Loading train:  22%|██▏       | 64/285 [01:08<03:59,  1.08s/it]Loading train:  23%|██▎       | 65/285 [01:10<04:41,  1.28s/it]Loading train:  23%|██▎       | 66/285 [01:11<04:46,  1.31s/it]Loading train:  24%|██▎       | 67/285 [01:12<04:37,  1.27s/it]Loading train:  24%|██▍       | 68/285 [01:13<04:21,  1.21s/it]Loading train:  24%|██▍       | 69/285 [01:14<04:04,  1.13s/it]Loading train:  25%|██▍       | 70/285 [01:16<04:06,  1.15s/it]Loading train:  25%|██▍       | 71/285 [01:17<04:06,  1.15s/it]Loading train:  25%|██▌       | 72/285 [01:18<03:53,  1.10s/it]Loading train:  26%|██▌       | 73/285 [01:19<03:39,  1.04s/it]Loading train:  26%|██▌       | 74/285 [01:19<03:19,  1.06it/s]Loading train:  26%|██▋       | 75/285 [01:20<03:32,  1.01s/it]Loading train:  27%|██▋       | 76/285 [01:21<03:30,  1.01s/it]Loading train:  27%|██▋       | 77/285 [01:22<03:26,  1.01it/s]Loading train:  27%|██▋       | 78/285 [01:23<03:14,  1.06it/s]Loading train:  28%|██▊       | 79/285 [01:24<03:16,  1.05it/s]Loading train:  28%|██▊       | 80/285 [01:25<03:17,  1.04it/s]Loading train:  28%|██▊       | 81/285 [01:26<03:12,  1.06it/s]Loading train:  29%|██▉       | 82/285 [01:27<03:18,  1.02it/s]Loading train:  29%|██▉       | 83/285 [01:28<03:10,  1.06it/s]Loading train:  29%|██▉       | 84/285 [01:29<03:04,  1.09it/s]Loading train:  30%|██▉       | 85/285 [01:30<03:13,  1.04it/s]Loading train:  30%|███       | 86/285 [01:31<03:38,  1.10s/it]Loading train:  31%|███       | 87/285 [01:32<03:30,  1.07s/it]Loading train:  31%|███       | 88/285 [01:33<03:25,  1.05s/it]Loading train:  31%|███       | 89/285 [01:34<03:19,  1.02s/it]Loading train:  32%|███▏      | 90/285 [01:35<03:15,  1.00s/it]Loading train:  32%|███▏      | 91/285 [01:36<03:07,  1.03it/s]Loading train:  32%|███▏      | 92/285 [01:37<03:10,  1.01it/s]Loading train:  33%|███▎      | 93/285 [01:38<02:59,  1.07it/s]Loading train:  33%|███▎      | 94/285 [01:39<03:06,  1.02it/s]Loading train:  33%|███▎      | 95/285 [01:40<03:05,  1.02it/s]Loading train:  34%|███▎      | 96/285 [01:41<02:59,  1.06it/s]Loading train:  34%|███▍      | 97/285 [01:42<02:59,  1.05it/s]Loading train:  34%|███▍      | 98/285 [01:43<02:59,  1.04it/s]Loading train:  35%|███▍      | 99/285 [01:44<02:51,  1.09it/s]Loading train:  35%|███▌      | 100/285 [01:45<02:50,  1.09it/s]Loading train:  35%|███▌      | 101/285 [01:46<02:50,  1.08it/s]Loading train:  36%|███▌      | 102/285 [01:47<02:52,  1.06it/s]Loading train:  36%|███▌      | 103/285 [01:47<02:43,  1.11it/s]Loading train:  36%|███▋      | 104/285 [01:48<02:51,  1.06it/s]Loading train:  37%|███▋      | 105/285 [01:50<02:59,  1.00it/s]Loading train:  37%|███▋      | 106/285 [01:50<02:53,  1.03it/s]Loading train:  38%|███▊      | 107/285 [01:51<02:50,  1.04it/s]Loading train:  38%|███▊      | 108/285 [01:52<02:47,  1.06it/s]Loading train:  38%|███▊      | 109/285 [01:53<02:51,  1.03it/s]Loading train:  39%|███▊      | 110/285 [01:54<02:55,  1.00s/it]Loading train:  39%|███▉      | 111/285 [01:55<02:49,  1.02it/s]Loading train:  39%|███▉      | 112/285 [01:56<02:54,  1.01s/it]Loading train:  40%|███▉      | 113/285 [01:57<02:56,  1.03s/it]Loading train:  40%|████      | 114/285 [01:58<02:56,  1.03s/it]Loading train:  40%|████      | 115/285 [01:59<02:51,  1.01s/it]Loading train:  41%|████      | 116/285 [02:01<02:56,  1.05s/it]Loading train:  41%|████      | 117/285 [02:01<02:46,  1.01it/s]Loading train:  41%|████▏     | 118/285 [02:02<02:41,  1.03it/s]Loading train:  42%|████▏     | 119/285 [02:03<02:46,  1.00s/it]Loading train:  42%|████▏     | 120/285 [02:04<02:39,  1.04it/s]Loading train:  42%|████▏     | 121/285 [02:06<02:59,  1.09s/it]Loading train:  43%|████▎     | 122/285 [02:07<03:01,  1.11s/it]Loading train:  43%|████▎     | 123/285 [02:08<03:04,  1.14s/it]Loading train:  44%|████▎     | 124/285 [02:09<02:48,  1.05s/it]Loading train:  44%|████▍     | 125/285 [02:10<02:45,  1.03s/it]Loading train:  44%|████▍     | 126/285 [02:11<02:32,  1.05it/s]Loading train:  45%|████▍     | 127/285 [02:12<02:29,  1.06it/s]Loading train:  45%|████▍     | 128/285 [02:13<02:29,  1.05it/s]Loading train:  45%|████▌     | 129/285 [02:13<02:18,  1.13it/s]Loading train:  46%|████▌     | 130/285 [02:14<02:10,  1.19it/s]Loading train:  46%|████▌     | 131/285 [02:15<02:07,  1.21it/s]Loading train:  46%|████▋     | 132/285 [02:16<02:16,  1.12it/s]Loading train:  47%|████▋     | 133/285 [02:17<02:12,  1.15it/s]Loading train:  47%|████▋     | 134/285 [02:17<02:00,  1.26it/s]Loading train:  47%|████▋     | 135/285 [02:18<01:58,  1.27it/s]Loading train:  48%|████▊     | 136/285 [02:19<01:55,  1.29it/s]Loading train:  48%|████▊     | 137/285 [02:20<01:53,  1.30it/s]Loading train:  48%|████▊     | 138/285 [02:20<01:56,  1.26it/s]Loading train:  49%|████▉     | 139/285 [02:21<01:58,  1.23it/s]Loading train:  49%|████▉     | 140/285 [02:22<01:56,  1.25it/s]Loading train:  49%|████▉     | 141/285 [02:23<01:53,  1.27it/s]Loading train:  50%|████▉     | 142/285 [02:24<01:49,  1.31it/s]Loading train:  50%|█████     | 143/285 [02:24<01:51,  1.27it/s]Loading train:  51%|█████     | 144/285 [02:25<01:54,  1.23it/s]Loading train:  51%|█████     | 145/285 [02:26<02:00,  1.16it/s]Loading train:  51%|█████     | 146/285 [02:27<01:59,  1.17it/s]Loading train:  52%|█████▏    | 147/285 [02:28<02:02,  1.13it/s]Loading train:  52%|█████▏    | 148/285 [02:29<02:00,  1.14it/s]Loading train:  52%|█████▏    | 149/285 [02:30<01:59,  1.14it/s]Loading train:  53%|█████▎    | 150/285 [02:31<02:03,  1.09it/s]Loading train:  53%|█████▎    | 151/285 [02:32<02:01,  1.10it/s]Loading train:  53%|█████▎    | 152/285 [02:32<01:54,  1.16it/s]Loading train:  54%|█████▎    | 153/285 [02:33<01:52,  1.17it/s]Loading train:  54%|█████▍    | 154/285 [02:34<01:50,  1.19it/s]Loading train:  54%|█████▍    | 155/285 [02:35<01:47,  1.21it/s]Loading train:  55%|█████▍    | 156/285 [02:36<01:48,  1.19it/s]Loading train:  55%|█████▌    | 157/285 [02:37<01:50,  1.16it/s]Loading train:  55%|█████▌    | 158/285 [02:37<01:48,  1.18it/s]Loading train:  56%|█████▌    | 159/285 [02:38<01:49,  1.15it/s]Loading train:  56%|█████▌    | 160/285 [02:39<01:42,  1.22it/s]Loading train:  56%|█████▋    | 161/285 [02:40<01:37,  1.27it/s]Loading train:  57%|█████▋    | 162/285 [02:41<01:43,  1.19it/s]Loading train:  57%|█████▋    | 163/285 [02:42<01:42,  1.19it/s]Loading train:  58%|█████▊    | 164/285 [02:42<01:37,  1.25it/s]Loading train:  58%|█████▊    | 165/285 [02:43<01:40,  1.19it/s]Loading train:  58%|█████▊    | 166/285 [02:44<01:39,  1.20it/s]Loading train:  59%|█████▊    | 167/285 [02:45<01:38,  1.19it/s]Loading train:  59%|█████▉    | 168/285 [02:46<01:37,  1.20it/s]Loading train:  59%|█████▉    | 169/285 [02:46<01:33,  1.24it/s]Loading train:  60%|█████▉    | 170/285 [02:47<01:30,  1.26it/s]Loading train:  60%|██████    | 171/285 [02:48<01:32,  1.23it/s]Loading train:  60%|██████    | 172/285 [02:49<01:29,  1.26it/s]Loading train:  61%|██████    | 173/285 [02:50<01:27,  1.27it/s]Loading train:  61%|██████    | 174/285 [02:50<01:27,  1.26it/s]Loading train:  61%|██████▏   | 175/285 [02:51<01:33,  1.17it/s]Loading train:  62%|██████▏   | 176/285 [02:52<01:34,  1.15it/s]Loading train:  62%|██████▏   | 177/285 [02:53<01:32,  1.17it/s]Loading train:  62%|██████▏   | 178/285 [02:54<01:40,  1.06it/s]Loading train:  63%|██████▎   | 179/285 [02:55<01:34,  1.12it/s]Loading train:  63%|██████▎   | 180/285 [02:56<01:42,  1.02it/s]Loading train:  64%|██████▎   | 181/285 [02:57<01:40,  1.04it/s]Loading train:  64%|██████▍   | 182/285 [02:58<01:34,  1.09it/s]Loading train:  64%|██████▍   | 183/285 [02:59<01:31,  1.11it/s]Loading train:  65%|██████▍   | 184/285 [03:00<01:26,  1.16it/s]Loading train:  65%|██████▍   | 185/285 [03:00<01:18,  1.27it/s]Loading train:  65%|██████▌   | 186/285 [03:01<01:28,  1.12it/s]Loading train:  66%|██████▌   | 187/285 [03:03<01:35,  1.02it/s]Loading train:  66%|██████▌   | 188/285 [03:04<01:47,  1.10s/it]Loading train:  66%|██████▋   | 189/285 [03:05<01:38,  1.03s/it]Loading train:  67%|██████▋   | 190/285 [03:06<01:31,  1.04it/s]Loading train:  67%|██████▋   | 191/285 [03:07<01:31,  1.02it/s]Loading train:  67%|██████▋   | 192/285 [03:08<01:29,  1.03it/s]Loading train:  68%|██████▊   | 193/285 [03:08<01:28,  1.04it/s]Loading train:  68%|██████▊   | 194/285 [03:09<01:24,  1.08it/s]Loading train:  68%|██████▊   | 195/285 [03:10<01:23,  1.07it/s]Loading train:  69%|██████▉   | 196/285 [03:11<01:30,  1.01s/it]Loading train:  69%|██████▉   | 197/285 [03:13<01:30,  1.03s/it]Loading train:  69%|██████▉   | 198/285 [03:14<01:34,  1.08s/it]Loading train:  70%|██████▉   | 199/285 [03:14<01:24,  1.02it/s]Loading train:  70%|███████   | 200/285 [03:15<01:22,  1.04it/s]Loading train:  71%|███████   | 201/285 [03:17<01:35,  1.13s/it]Loading train:  71%|███████   | 202/285 [03:18<01:31,  1.10s/it]Loading train:  71%|███████   | 203/285 [03:19<01:23,  1.01s/it]Loading train:  72%|███████▏  | 204/285 [03:20<01:22,  1.02s/it]Loading train:  72%|███████▏  | 205/285 [03:21<01:20,  1.01s/it]Loading train:  72%|███████▏  | 206/285 [03:22<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [03:23<01:21,  1.04s/it]Loading train:  73%|███████▎  | 208/285 [03:24<01:22,  1.07s/it]Loading train:  73%|███████▎  | 209/285 [03:25<01:27,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [03:26<01:20,  1.08s/it]Loading train:  74%|███████▍  | 211/285 [03:28<01:24,  1.14s/it]Loading train:  74%|███████▍  | 212/285 [03:29<01:20,  1.10s/it]Loading train:  75%|███████▍  | 213/285 [03:30<01:17,  1.07s/it]Loading train:  75%|███████▌  | 214/285 [03:31<01:18,  1.11s/it]Loading train:  75%|███████▌  | 215/285 [03:32<01:18,  1.11s/it]Loading train:  76%|███████▌  | 216/285 [03:33<01:19,  1.15s/it]Loading train:  76%|███████▌  | 217/285 [03:34<01:17,  1.14s/it]Loading train:  76%|███████▋  | 218/285 [03:35<01:15,  1.12s/it]Loading train:  77%|███████▋  | 219/285 [03:37<01:18,  1.19s/it]Loading train:  77%|███████▋  | 220/285 [03:38<01:14,  1.14s/it]Loading train:  78%|███████▊  | 221/285 [03:39<01:08,  1.08s/it]Loading train:  78%|███████▊  | 222/285 [03:40<01:06,  1.05s/it]Loading train:  78%|███████▊  | 223/285 [03:41<01:04,  1.04s/it]Loading train:  79%|███████▊  | 224/285 [03:42<00:58,  1.04it/s]Loading train:  79%|███████▉  | 225/285 [03:42<00:56,  1.06it/s]Loading train:  79%|███████▉  | 226/285 [03:44<01:01,  1.04s/it]Loading train:  80%|███████▉  | 227/285 [03:45<01:05,  1.13s/it]Loading train:  80%|████████  | 228/285 [03:46<01:03,  1.12s/it]Loading train:  80%|████████  | 229/285 [03:47<01:01,  1.11s/it]Loading train:  81%|████████  | 230/285 [03:48<00:58,  1.07s/it]Loading train:  81%|████████  | 231/285 [03:49<00:55,  1.03s/it]Loading train:  81%|████████▏ | 232/285 [03:50<00:55,  1.04s/it]Loading train:  82%|████████▏ | 233/285 [03:51<00:52,  1.00s/it]Loading train:  82%|████████▏ | 234/285 [03:52<00:52,  1.02s/it]Loading train:  82%|████████▏ | 235/285 [03:53<00:52,  1.04s/it]Loading train:  83%|████████▎ | 236/285 [03:54<00:52,  1.06s/it]Loading train:  83%|████████▎ | 237/285 [03:55<00:52,  1.09s/it]Loading train:  84%|████████▎ | 238/285 [03:57<00:51,  1.10s/it]Loading train:  84%|████████▍ | 239/285 [03:58<00:52,  1.14s/it]Loading train:  84%|████████▍ | 240/285 [03:59<00:48,  1.08s/it]Loading train:  85%|████████▍ | 241/285 [04:00<00:45,  1.02s/it]Loading train:  85%|████████▍ | 242/285 [04:01<00:45,  1.05s/it]Loading train:  85%|████████▌ | 243/285 [04:02<00:42,  1.02s/it]Loading train:  86%|████████▌ | 244/285 [04:03<00:41,  1.02s/it]Loading train:  86%|████████▌ | 245/285 [04:04<00:41,  1.03s/it]Loading train:  86%|████████▋ | 246/285 [04:05<00:41,  1.07s/it]Loading train:  87%|████████▋ | 247/285 [04:06<00:39,  1.03s/it]Loading train:  87%|████████▋ | 248/285 [04:07<00:37,  1.01s/it]Loading train:  87%|████████▋ | 249/285 [04:08<00:34,  1.03it/s]Loading train:  88%|████████▊ | 250/285 [04:09<00:32,  1.06it/s]Loading train:  88%|████████▊ | 251/285 [04:09<00:31,  1.09it/s]Loading train:  88%|████████▊ | 252/285 [04:10<00:29,  1.13it/s]Loading train:  89%|████████▉ | 253/285 [04:12<00:31,  1.02it/s]Loading train:  89%|████████▉ | 254/285 [04:13<00:31,  1.01s/it]Loading train:  89%|████████▉ | 255/285 [04:14<00:31,  1.03s/it]Loading train:  90%|████████▉ | 256/285 [04:15<00:28,  1.01it/s]Loading train:  90%|█████████ | 257/285 [04:15<00:26,  1.06it/s]Loading train:  91%|█████████ | 258/285 [04:16<00:25,  1.05it/s]Loading train:  91%|█████████ | 259/285 [04:17<00:25,  1.04it/s]Loading train:  91%|█████████ | 260/285 [04:18<00:22,  1.10it/s]Loading train:  92%|█████████▏| 261/285 [04:19<00:20,  1.16it/s]Loading train:  92%|█████████▏| 262/285 [04:20<00:20,  1.13it/s]Loading train:  92%|█████████▏| 263/285 [04:21<00:20,  1.10it/s]Loading train:  93%|█████████▎| 264/285 [04:22<00:20,  1.04it/s]Loading train:  93%|█████████▎| 265/285 [04:23<00:20,  1.01s/it]Loading train:  93%|█████████▎| 266/285 [04:24<00:18,  1.05it/s]Loading train:  94%|█████████▎| 267/285 [04:25<00:17,  1.03it/s]Loading train:  94%|█████████▍| 268/285 [04:26<00:17,  1.00s/it]Loading train:  94%|█████████▍| 269/285 [04:27<00:16,  1.01s/it]Loading train:  95%|█████████▍| 270/285 [04:28<00:14,  1.05it/s]Loading train:  95%|█████████▌| 271/285 [04:29<00:12,  1.08it/s]Loading train:  95%|█████████▌| 272/285 [04:30<00:12,  1.01it/s]Loading train:  96%|█████████▌| 273/285 [04:31<00:11,  1.04it/s]Loading train:  96%|█████████▌| 274/285 [04:32<00:10,  1.04it/s]Loading train:  96%|█████████▋| 275/285 [04:33<00:10,  1.05s/it]Loading train:  97%|█████████▋| 276/285 [04:34<00:09,  1.09s/it]Loading train:  97%|█████████▋| 277/285 [04:35<00:08,  1.05s/it]Loading train:  98%|█████████▊| 278/285 [04:36<00:07,  1.08s/it]Loading train:  98%|█████████▊| 279/285 [04:37<00:06,  1.07s/it]Loading train:  98%|█████████▊| 280/285 [04:38<00:04,  1.01it/s]Loading train:  99%|█████████▊| 281/285 [04:39<00:03,  1.03it/s]Loading train:  99%|█████████▉| 282/285 [04:40<00:02,  1.03it/s]Loading train:  99%|█████████▉| 283/285 [04:41<00:01,  1.02it/s]Loading train: 100%|█████████▉| 284/285 [04:42<00:00,  1.03it/s]Loading train: 100%|██████████| 285/285 [04:43<00:00,  1.05s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   6%|▌         | 17/285 [00:00<00:01, 167.46it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:01, 192.22it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:01, 205.60it/s]concatenating: train:  31%|███       | 88/285 [00:00<00:01, 182.09it/s]concatenating: train:  43%|████▎     | 123/285 [00:00<00:00, 211.77it/s]concatenating: train:  51%|█████     | 145/285 [00:00<00:01, 137.63it/s]concatenating: train:  63%|██████▎   | 179/285 [00:00<00:00, 167.02it/s]concatenating: train:  76%|███████▌  | 216/285 [00:01<00:00, 199.15it/s]concatenating: train:  88%|████████▊ | 252/285 [00:01<00:00, 229.29it/s]concatenating: train: 100%|██████████| 285/285 [00:01<00:00, 234.90it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.43s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.37s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.34s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 201.93it/s]2019-07-11 10:53:34.803387: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 10:53:34.803494: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 10:53:34.803508: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 10:53:34.803516: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 10:53:34.803873: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:09,  4.72it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:07,  5.67it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:07,  5.43it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.96it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:05,  6.04it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.53it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.83it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.33it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:01<00:03,  7.79it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:03,  6.55it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  5.79it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.34it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.09it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.43it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:01,  6.59it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.80it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:03<00:00,  8.02it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:00,  6.77it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  7.46it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  6.26it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  9.53it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   4200        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 30)   12180       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 80, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 80, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 80, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 75)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 80, 13)   988         concatenate_8[0][0]              
==================================================================================================
Total params: 160,138
Trainable params: 61,438
Non-trainable params: 98,700
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 18s - loss: 2.3992 - acc: 0.8164 - mDice: 0.1438 - val_loss: 1.8567 - val_acc: 0.9117 - val_mDice: 0.3038

Epoch 00001: val_mDice improved from -inf to 0.30384, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 12s - loss: 0.9339 - acc: 0.8963 - mDice: 0.3990 - val_loss: 1.3504 - val_acc: 0.9210 - val_mDice: 0.4519

Epoch 00002: val_mDice improved from 0.30384 to 0.45190, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 11s - loss: 0.6128 - acc: 0.9147 - mDice: 0.5270 - val_loss: 1.1672 - val_acc: 0.9328 - val_mDice: 0.5271

Epoch 00003: val_mDice improved from 0.45190 to 0.52710, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 11s - loss: 0.5101 - acc: 0.9224 - mDice: 0.5839 - val_loss: 1.0746 - val_acc: 0.9375 - val_mDice: 0.5453

Epoch 00004: val_mDice improved from 0.52710 to 0.54527, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 11s - loss: 0.4705 - acc: 0.9261 - mDice: 0.6086 - val_loss: 1.0181 - val_acc: 0.9408 - val_mDice: 0.5679

Epoch 00005: val_mDice improved from 0.54527 to 0.56791, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 12s - loss: 0.4473 - acc: 0.9286 - mDice: 0.6233 - val_loss: 1.0583 - val_acc: 0.9395 - val_mDice: 0.5488

Epoch 00006: val_mDice did not improve from 0.56791
Epoch 7/300
 - 12s - loss: 0.4256 - acc: 0.9309 - mDice: 0.6375 - val_loss: 1.0000 - val_acc: 0.9403 - val_mDice: 0.5634

Epoch 00007: val_mDice did not improve from 0.56791
Epoch 8/300
 - 11s - loss: 0.4140 - acc: 0.9324 - mDice: 0.6455 - val_loss: 0.9447 - val_acc: 0.9405 - val_mDice: 0.5866

Epoch 00008: val_mDice improved from 0.56791 to 0.58658, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 11s - loss: 0.4055 - acc: 0.9330 - mDice: 0.6511 - val_loss: 0.9548 - val_acc: 0.9452 - val_mDice: 0.5712

Epoch 00009: val_mDice did not improve from 0.58658
Epoch 10/300
 - 11s - loss: 0.3972 - acc: 0.9340 - mDice: 0.6568 - val_loss: 0.9393 - val_acc: 0.9404 - val_mDice: 0.5831

Epoch 00010: val_mDice did not improve from 0.58658
Epoch 11/300
 - 12s - loss: 0.3923 - acc: 0.9344 - mDice: 0.6601 - val_loss: 0.9091 - val_acc: 0.9434 - val_mDice: 0.5846

Epoch 00011: val_mDice did not improve from 0.58658
Epoch 12/300
 - 12s - loss: 0.3857 - acc: 0.9351 - mDice: 0.6646 - val_loss: 0.9145 - val_acc: 0.9435 - val_mDice: 0.5926

Epoch 00012: val_mDice improved from 0.58658 to 0.59257, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 12s - loss: 0.3780 - acc: 0.9361 - mDice: 0.6700 - val_loss: 0.9425 - val_acc: 0.9424 - val_mDice: 0.5768

Epoch 00013: val_mDice did not improve from 0.59257
Epoch 14/300
 - 12s - loss: 0.3735 - acc: 0.9365 - mDice: 0.6731 - val_loss: 0.9583 - val_acc: 0.9461 - val_mDice: 0.5688

Epoch 00014: val_mDice did not improve from 0.59257
Epoch 15/300
 - 12s - loss: 0.3672 - acc: 0.9371 - mDice: 0.6775 - val_loss: 0.8810 - val_acc: 0.9431 - val_mDice: 0.5926

Epoch 00015: val_mDice improved from 0.59257 to 0.59264, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 12s - loss: 0.3620 - acc: 0.9377 - mDice: 0.6812 - val_loss: 0.8839 - val_acc: 0.9419 - val_mDice: 0.5906

Epoch 00016: val_mDice did not improve from 0.59264
Epoch 17/300
 - 12s - loss: 0.3607 - acc: 0.9379 - mDice: 0.6822 - val_loss: 0.8935 - val_acc: 0.9459 - val_mDice: 0.5861

Epoch 00017: val_mDice did not improve from 0.59264
Epoch 18/300
 - 12s - loss: 0.3592 - acc: 0.9380 - mDice: 0.6833 - val_loss: 0.9058 - val_acc: 0.9441 - val_mDice: 0.5926

Epoch 00018: val_mDice did not improve from 0.59264
Epoch 19/300
 - 12s - loss: 0.3541 - acc: 0.9385 - mDice: 0.6869 - val_loss: 0.8965 - val_acc: 0.9448 - val_mDice: 0.5763

Epoch 00019: val_mDice did not improve from 0.59264
Epoch 20/300
 - 12s - loss: 0.3516 - acc: 0.9387 - mDice: 0.6886 - val_loss: 0.8886 - val_acc: 0.9464 - val_mDice: 0.5857

Epoch 00020: val_mDice did not improve from 0.59264
Epoch 21/300
 - 12s - loss: 0.3481 - acc: 0.9390 - mDice: 0.6912 - val_loss: 0.8762 - val_acc: 0.9445 - val_mDice: 0.5904

Epoch 00021: val_mDice did not improve from 0.59264
Epoch 22/300
 - 12s - loss: 0.3450 - acc: 0.9394 - mDice: 0.6935 - val_loss: 0.8950 - val_acc: 0.9404 - val_mDice: 0.5800

Epoch 00022: val_mDice did not improve from 0.59264
Epoch 23/300
 - 12s - loss: 0.3422 - acc: 0.9398 - mDice: 0.6955 - val_loss: 0.9127 - val_acc: 0.9454 - val_mDice: 0.5637

Epoch 00023: val_mDice did not improve from 0.59264
Epoch 24/300
 - 12s - loss: 0.3398 - acc: 0.9398 - mDice: 0.6971 - val_loss: 0.8817 - val_acc: 0.9475 - val_mDice: 0.5794

Epoch 00024: val_mDice did not improve from 0.59264
Epoch 25/300
 - 12s - loss: 0.3390 - acc: 0.9400 - mDice: 0.6977 - val_loss: 0.9175 - val_acc: 0.9446 - val_mDice: 0.5486

Epoch 00025: val_mDice did not improve from 0.59264
Epoch 26/300
 - 12s - loss: 0.3360 - acc: 0.9404 - mDice: 0.6999 - val_loss: 0.9235 - val_acc: 0.9461 - val_mDice: 0.5672

Epoch 00026: val_mDice did not improve from 0.59264
Epoch 27/300
 - 12s - loss: 0.3344 - acc: 0.9405 - mDice: 0.7011 - val_loss: 0.9156 - val_acc: 0.9431 - val_mDice: 0.5765

Epoch 00027: val_mDice did not improve from 0.59264
Epoch 28/300
 - 12s - loss: 0.3311 - acc: 0.9409 - mDice: 0.7035 - val_loss: 0.8403 - val_acc: 0.9435 - val_mDice: 0.5845

Epoch 00028: val_mDice did not improve from 0.59264
Epoch 29/300
 - 12s - loss: 0.3288 - acc: 0.9409 - mDice: 0.7052 - val_loss: 0.8356 - val_acc: 0.9454 - val_mDice: 0.5771

Epoch 00029: val_mDice did not improve from 0.59264
Epoch 30/300
 - 12s - loss: 0.3285 - acc: 0.9411 - mDice: 0.7055 - val_loss: 0.8877 - val_acc: 0.9465 - val_mDice: 0.5650

Epoch 00030: val_mDice did not improve from 0.59264
Epoch 31/300
 - 12s - loss: 0.3259 - acc: 0.9413 - mDice: 0.7072 - val_loss: 0.8313 - val_acc: 0.9474 - val_mDice: 0.5878

Epoch 00031: val_mDice did not improve from 0.59264
Epoch 32/300
 - 12s - loss: 0.3239 - acc: 0.9414 - mDice: 0.7088 - val_loss: 0.8474 - val_acc: 0.9448 - val_mDice: 0.5788

Epoch 00032: val_mDice did not improve from 0.59264
Epoch 33/300
 - 11s - loss: 0.3220 - acc: 0.9416 - mDice: 0.7103 - val_loss: 0.8505 - val_acc: 0.9453 - val_mDice: 0.5652

Epoch 00033: val_mDice did not improve from 0.59264
Epoch 34/300
 - 12s - loss: 0.3222 - acc: 0.9417 - mDice: 0.7100 - val_loss: 0.8190 - val_acc: 0.9461 - val_mDice: 0.5841

Epoch 00034: val_mDice did not improve from 0.59264
Epoch 35/300
 - 12s - loss: 0.3180 - acc: 0.9421 - mDice: 0.7131 - val_loss: 0.8102 - val_acc: 0.9460 - val_mDice: 0.5810

Epoch 00035: val_mDice did not improve from 0.59264
Epoch 36/300
 - 12s - loss: 0.3179 - acc: 0.9420 - mDice: 0.7133 - val_loss: 0.7574 - val_acc: 0.9462 - val_mDice: 0.5913

Epoch 00036: val_mDice did not improve from 0.59264
Epoch 37/300
 - 12s - loss: 0.3159 - acc: 0.9423 - mDice: 0.7147 - val_loss: 0.8020 - val_acc: 0.9451 - val_mDice: 0.5875

Epoch 00037: val_mDice did not improve from 0.59264
Epoch 38/300
 - 12s - loss: 0.3174 - acc: 0.9422 - mDice: 0.7137 - val_loss: 0.7904 - val_acc: 0.9415 - val_mDice: 0.5766

Epoch 00038: val_mDice did not improve from 0.59264
Epoch 39/300
 - 12s - loss: 0.3151 - acc: 0.9423 - mDice: 0.7153 - val_loss: 0.8319 - val_acc: 0.9469 - val_mDice: 0.5668

Epoch 00039: val_mDice did not improve from 0.59264
Epoch 40/300
 - 12s - loss: 0.3135 - acc: 0.9426 - mDice: 0.7164 - val_loss: 0.8077 - val_acc: 0.9430 - val_mDice: 0.5975

Epoch 00040: val_mDice improved from 0.59264 to 0.59751, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 41/300
 - 12s - loss: 0.3106 - acc: 0.9429 - mDice: 0.7187 - val_loss: 0.7917 - val_acc: 0.9446 - val_mDice: 0.5806

Epoch 00041: val_mDice did not improve from 0.59751
Epoch 42/300
 - 11s - loss: 0.3094 - acc: 0.9429 - mDice: 0.7196 - val_loss: 0.8192 - val_acc: 0.9425 - val_mDice: 0.5759

Epoch 00042: val_mDice did not improve from 0.59751
Epoch 43/300
 - 12s - loss: 0.3085 - acc: 0.9431 - mDice: 0.7203 - val_loss: 0.7605 - val_acc: 0.9453 - val_mDice: 0.5669

Epoch 00043: val_mDice did not improve from 0.59751
Epoch 44/300
 - 12s - loss: 0.3089 - acc: 0.9429 - mDice: 0.7200 - val_loss: 0.8141 - val_acc: 0.9456 - val_mDice: 0.5798

Epoch 00044: val_mDice did not improve from 0.59751
Epoch 45/300
 - 12s - loss: 0.3067 - acc: 0.9432 - mDice: 0.7216 - val_loss: 0.8320 - val_acc: 0.9453 - val_mDice: 0.5649

Epoch 00045: val_mDice did not improve from 0.59751
Epoch 46/300
 - 12s - loss: 0.3062 - acc: 0.9433 - mDice: 0.7220 - val_loss: 0.7663 - val_acc: 0.9407 - val_mDice: 0.5734

Epoch 00046: val_mDice did not improve from 0.59751
Epoch 47/300
 - 12s - loss: 0.3066 - acc: 0.9432 - mDice: 0.7218 - val_loss: 0.8054 - val_acc: 0.9463 - val_mDice: 0.5401

Epoch 00047: val_mDice did not improve from 0.59751
Epoch 48/300
 - 12s - loss: 0.3040 - acc: 0.9434 - mDice: 0.7235 - val_loss: 0.7926 - val_acc: 0.9417 - val_mDice: 0.5862

Epoch 00048: val_mDice did not improve from 0.59751
Epoch 49/300
 - 12s - loss: 0.3018 - acc: 0.9436 - mDice: 0.7253 - val_loss: 0.7711 - val_acc: 0.9469 - val_mDice: 0.5790

Epoch 00049: val_mDice did not improve from 0.59751
Epoch 50/300
 - 12s - loss: 0.3017 - acc: 0.9438 - mDice: 0.7254 - val_loss: 0.7625 - val_acc: 0.9422 - val_mDice: 0.5870

Epoch 00050: val_mDice did not improve from 0.59751
Epoch 51/300
 - 12s - loss: 0.3001 - acc: 0.9438 - mDice: 0.7267 - val_loss: 0.7260 - val_acc: 0.9417 - val_mDice: 0.5883

Epoch 00051: val_mDice did not improve from 0.59751
Epoch 52/300
 - 12s - loss: 0.3007 - acc: 0.9438 - mDice: 0.7261 - val_loss: 0.7489 - val_acc: 0.9455 - val_mDice: 0.5586

Epoch 00052: val_mDice did not improve from 0.59751
Epoch 53/300
 - 12s - loss: 0.3000 - acc: 0.9437 - mDice: 0.7266 - val_loss: 0.7275 - val_acc: 0.9444 - val_mDice: 0.5836

Epoch 00053: val_mDice did not improve from 0.59751
Epoch 54/300
 - 12s - loss: 0.2996 - acc: 0.9437 - mDice: 0.7270 - val_loss: 0.6961 - val_acc: 0.9450 - val_mDice: 0.5752

Epoch 00054: val_mDice did not improve from 0.59751
Epoch 55/300
 - 12s - loss: 0.2980 - acc: 0.9438 - mDice: 0.7282 - val_loss: 0.7186 - val_acc: 0.9462 - val_mDice: 0.5799

Epoch 00055: val_mDice did not improve from 0.59751
Epoch 56/300
 - 12s - loss: 0.2959 - acc: 0.9442 - mDice: 0.7298 - val_loss: 0.7442 - val_acc: 0.9430 - val_mDice: 0.5798

Epoch 00056: val_mDice did not improve from 0.59751
Epoch 57/300
 - 12s - loss: 0.2938 - acc: 0.9444 - mDice: 0.7314 - val_loss: 0.7210 - val_acc: 0.9460 - val_mDice: 0.5748

Epoch 00057: val_mDice did not improve from 0.59751
Epoch 58/300
 - 12s - loss: 0.2928 - acc: 0.9444 - mDice: 0.7321 - val_loss: 0.7553 - val_acc: 0.9448 - val_mDice: 0.5799

Epoch 00058: val_mDice did not improve from 0.59751
Epoch 59/300
 - 12s - loss: 0.2941 - acc: 0.9444 - mDice: 0.7311 - val_loss: 0.7004 - val_acc: 0.9463 - val_mDice: 0.5751

Epoch 00059: val_mDice did not improve from 0.59751
Epoch 60/300
 - 12s - loss: 0.2924 - acc: 0.9445 - mDice: 0.7325 - val_loss: 0.7276 - val_acc: 0.9442 - val_mDice: 0.5794

Epoch 00060: val_mDice did not improve from 0.59751
Epoch 61/300
 - 12s - loss: 0.2928 - acc: 0.9445 - mDice: 0.7321 - val_loss: 0.7343 - val_acc: 0.9392 - val_mDice: 0.5766

Epoch 00061: val_mDice did not improve from 0.59751
Epoch 62/300
 - 12s - loss: 0.2895 - acc: 0.9449 - mDice: 0.7347 - val_loss: 0.6549 - val_acc: 0.9456 - val_mDice: 0.5780

Epoch 00062: val_mDice did not improve from 0.59751
Epoch 63/300
 - 12s - loss: 0.2915 - acc: 0.9447 - mDice: 0.7332 - val_loss: 0.7509 - val_acc: 0.9394 - val_mDice: 0.5781

Epoch 00063: val_mDice did not improve from 0.59751
Epoch 64/300
 - 12s - loss: 0.2914 - acc: 0.9447 - mDice: 0.7333 - val_loss: 0.7002 - val_acc: 0.9431 - val_mDice: 0.5812

Epoch 00064: val_mDice did not improve from 0.59751
Epoch 65/300
 - 12s - loss: 0.2891 - acc: 0.9448 - mDice: 0.7350 - val_loss: 0.6610 - val_acc: 0.9449 - val_mDice: 0.5756

Epoch 00065: val_mDice did not improve from 0.59751
Epoch 66/300
 - 12s - loss: 0.2910 - acc: 0.9446 - mDice: 0.7335 - val_loss: 0.7187 - val_acc: 0.9457 - val_mDice: 0.5850

Epoch 00066: val_mDice did not improve from 0.59751
Epoch 67/300
 - 12s - loss: 0.2879 - acc: 0.9451 - mDice: 0.7359 - val_loss: 0.7406 - val_acc: 0.9424 - val_mDice: 0.5861

Epoch 00067: val_mDice did not improve from 0.59751
Epoch 68/300
 - 12s - loss: 0.2871 - acc: 0.9450 - mDice: 0.7365 - val_loss: 0.7083 - val_acc: 0.9447 - val_mDice: 0.5788

Epoch 00068: val_mDice did not improve from 0.59751
Epoch 69/300
 - 12s - loss: 0.2853 - acc: 0.9452 - mDice: 0.7379 - val_loss: 0.7307 - val_acc: 0.9392 - val_mDice: 0.5745

Epoch 00069: val_mDice did not improve from 0.59751
Epoch 70/300
 - 12s - loss: 0.2860 - acc: 0.9451 - mDice: 0.7374 - val_loss: 0.6393 - val_acc: 0.9438 - val_mDice: 0.5753

Epoch 00070: val_mDice did not improve from 0.59751
Epoch 71/300
 - 12s - loss: 0.2862 - acc: 0.9452 - mDice: 0.7372 - val_loss: 0.6951 - val_acc: 0.9467 - val_mDice: 0.5735

Epoch 00071: val_mDice did not improve from 0.59751
Epoch 72/300
 - 12s - loss: 0.2850 - acc: 0.9454 - mDice: 0.7382 - val_loss: 0.7017 - val_acc: 0.9447 - val_mDice: 0.5661

Epoch 00072: val_mDice did not improve from 0.59751
Epoch 73/300
 - 12s - loss: 0.2850 - acc: 0.9452 - mDice: 0.7381 - val_loss: 0.6986 - val_acc: 0.9423 - val_mDice: 0.5800

Epoch 00073: val_mDice did not improve from 0.59751
Epoch 74/300
 - 12s - loss: 0.2822 - acc: 0.9455 - mDice: 0.7403 - val_loss: 0.6554 - val_acc: 0.9440 - val_mDice: 0.5723

Epoch 00074: val_mDice did not improve from 0.59751
Epoch 75/300
 - 12s - loss: 0.2823 - acc: 0.9455 - mDice: 0.7402 - val_loss: 0.6769 - val_acc: 0.9404 - val_mDice: 0.5718

Epoch 00075: val_mDice did not improve from 0.59751
Epoch 76/300
 - 12s - loss: 0.2821 - acc: 0.9455 - mDice: 0.7403 - val_loss: 0.7054 - val_acc: 0.9461 - val_mDice: 0.5752

Epoch 00076: val_mDice did not improve from 0.59751
Epoch 77/300
 - 12s - loss: 0.2818 - acc: 0.9455 - mDice: 0.7406 - val_loss: 0.6833 - val_acc: 0.9429 - val_mDice: 0.5645

Epoch 00077: val_mDice did not improve from 0.59751
Epoch 78/300
 - 12s - loss: 0.2822 - acc: 0.9455 - mDice: 0.7403 - val_loss: 0.6293 - val_acc: 0.9461 - val_mDice: 0.5861

Epoch 00078: val_mDice did not improve from 0.59751
Epoch 79/300
 - 12s - loss: 0.2828 - acc: 0.9455 - mDice: 0.7398 - val_loss: 0.6869 - val_acc: 0.9433 - val_mDice: 0.5781

Epoch 00079: val_mDice did not improve from 0.59751
Epoch 80/300
 - 12s - loss: 0.2799 - acc: 0.9459 - mDice: 0.7421 - val_loss: 0.7022 - val_acc: 0.9407 - val_mDice: 0.5782

Epoch 00080: val_mDice did not improve from 0.59751
Restoring model weights from the end of the best epoch
Epoch 00080: early stopping
{'val_loss': [1.856724012465704, 1.350407702582223, 1.1672051407042003, 1.0746068613869804, 1.0181293090184529, 1.058322588602702, 0.9999515896751767, 0.9446555148987543, 0.9547586270741054, 0.9392842905861991, 0.9091300283159528, 0.9144591093063354, 0.9424842368988764, 0.9583433071772257, 0.8809737307684762, 0.8839044060025897, 0.8934994708924067, 0.9058346918651036, 0.8964788232530866, 0.8885636727015177, 0.876207675252642, 0.8949807314645677, 0.9127032870338077, 0.8817239715939477, 0.9174751440684, 0.9234839904875982, 0.9155789613723755, 0.8403139114379883, 0.8356063820066906, 0.8877036798567999, 0.8313199962888446, 0.8474368481408983, 0.8505351429893857, 0.8189530542918614, 0.8101804880868821, 0.7573927357083275, 0.802014498483567, 0.7903665077118647, 0.8319334586461385, 0.8076790287381127, 0.7917266516458421, 0.8191832190468198, 0.7605268784931728, 0.8141036998657953, 0.8319603375026158, 0.7662703934169951, 0.8053913116455078, 0.7926172812779745, 0.7711251576741537, 0.7624984355199904, 0.7259934402647472, 0.7488671938578287, 0.7275323243368239, 0.6960909877504621, 0.7185709079106649, 0.7442444562911987, 0.7209874959219069, 0.7552769240878877, 0.7003972246533349, 0.7275991099221366, 0.7343250342777797, 0.6549366769336519, 0.7508827504657564, 0.7001734063738868, 0.6609975667226882, 0.7186527649561564, 0.7406075227828253, 0.7082764705022176, 0.7306560845602126, 0.6392549333118257, 0.6950734229314894, 0.7016733260381789, 0.6986317464283535, 0.6553690603801182, 0.6769259600412278, 0.7054037196295602, 0.6833048434484572, 0.6293365557988485, 0.686949298495338, 0.702191154162089], 'val_acc': [0.9117216354324704, 0.9209592455909366, 0.9327609680947804, 0.9374976839338031, 0.9407509139605931, 0.9395375195003691, 0.9403228106952849, 0.9405151293391273, 0.9452014679000491, 0.9403891790480841, 0.9434066045851934, 0.9435027412005833, 0.9423900842666626, 0.9461126157215664, 0.9430860735121227, 0.9418726989201137, 0.9458768339384169, 0.9441414730889457, 0.9447779059410095, 0.9464331297647386, 0.9445192217826843, 0.9403502600533622, 0.9454326686405, 0.9474885719163078, 0.9446428730374291, 0.9460577198437282, 0.9430975261188689, 0.9434775710105896, 0.9453937808672587, 0.946504104705084, 0.9474382003148397, 0.9448168504805792, 0.945320515405564, 0.9461286380177453, 0.9460439313025701, 0.9462179399672008, 0.9451053341229757, 0.9415247184889657, 0.9468795742307391, 0.9429624307723272, 0.9445673227310181, 0.9425068667956761, 0.9452609788803827, 0.945554032212212, 0.9452724485170274, 0.9407348774728321, 0.9462659983407884, 0.9417491015933809, 0.9468681471688407, 0.9422481854756674, 0.9416643721716744, 0.945537975856236, 0.9444047808647156, 0.9450114227476574, 0.9462088091032845, 0.9430288218316578, 0.9460324900490897, 0.9448443367367699, 0.9463301187469846, 0.9442078783398583, 0.9391987266994658, 0.9456295995485215, 0.9393864699772426, 0.943054043111347, 0.9449176050367809, 0.9456661854471479, 0.9423626263936361, 0.9447229845183236, 0.9392376315026056, 0.9437683139528547, 0.9466735096204848, 0.9447252920695713, 0.9423443334443229, 0.9439903696378072, 0.9404052126975286, 0.9461424095290047, 0.9429372719355992, 0.9461286749158587, 0.9433401993342808, 0.9407005508740743], 'val_mDice': [0.30383947314251036, 0.45189614984251203, 0.5270996913313866, 0.5452741611571539, 0.5679118668749219, 0.5487504058650562, 0.5633696949198133, 0.5865754272256579, 0.5712257870251224, 0.5831203985781896, 0.5846143391515527, 0.5925669200008824, 0.5768395736813545, 0.5688414013101941, 0.5926394058125359, 0.5906194056428614, 0.5860896499029228, 0.5925810730883053, 0.5762655557621092, 0.5856689787691548, 0.5904057811768282, 0.5800183106745992, 0.5636781805327961, 0.5794399315047831, 0.5485995876647177, 0.5671779406922204, 0.5764929778164342, 0.5845100230404309, 0.5771428509837105, 0.5649789358888354, 0.5878359902472723, 0.5788405181041786, 0.5652246233962831, 0.5840952254477001, 0.5810254973669847, 0.5912929865575972, 0.5874598796168963, 0.5765524150005409, 0.5667639046552635, 0.5975138566323689, 0.5806424954817409, 0.5758500194975308, 0.5668956903474671, 0.5797594526693934, 0.5649065652063915, 0.5733846452619348, 0.5400987095421269, 0.5861800579088075, 0.5789892536898454, 0.5870157937918391, 0.5882555714675358, 0.5585564662303243, 0.5836356690242177, 0.5752473711257889, 0.5798907212558246, 0.5797938544835363, 0.5747882411593482, 0.5798601309458414, 0.5751238797037375, 0.5794083586051351, 0.5765766473043532, 0.5779867801992666, 0.5780693956074261, 0.5812079267842429, 0.5755524555487292, 0.5850374767822879, 0.5861475208685512, 0.5788308160290832, 0.5744657505835805, 0.5753208505255836, 0.5734703262292203, 0.5660885088145733, 0.5800092885536807, 0.5722639819695836, 0.5718468995321364, 0.5751648914246332, 0.5645196975341865, 0.5861425030799139, 0.5780627103078932, 0.5781990782845587], 'loss': [2.3991633174689215, 0.9338695451844191, 0.6128316819495448, 0.5100897970584769, 0.4704526499020058, 0.4472746807462061, 0.4256273491984276, 0.4139618060137004, 0.4055488284081881, 0.3971826380988824, 0.3922859515692426, 0.38570921178472645, 0.3780021200594655, 0.37351921311067393, 0.36721542338564694, 0.36202499555419904, 0.36067895587524373, 0.3591610708860894, 0.3541491311341553, 0.3515760699850483, 0.34808617262613206, 0.3449733530323653, 0.3421969412665664, 0.33978600632553735, 0.3389582204145344, 0.3360201364851007, 0.3344442659613023, 0.33105429377839907, 0.3287900111648603, 0.32845026472411404, 0.325938792921156, 0.32391624797601704, 0.3219923021385659, 0.32218522206307926, 0.3180402329093532, 0.31788452081949653, 0.31589760110629694, 0.31737339662085245, 0.3150597291919384, 0.31353583151673176, 0.3105780986179523, 0.3094356705199231, 0.3084558879269647, 0.30885117398030915, 0.30669615870039657, 0.3062075519288278, 0.3065907872433329, 0.3040249867661739, 0.3018063349727953, 0.301671380318266, 0.3000653367270526, 0.3006571265045609, 0.29999613010380016, 0.29955520812822073, 0.29796380209100026, 0.2958735222413817, 0.29376331153278157, 0.2928139801392648, 0.2940863823129971, 0.29238307327807744, 0.2927611521760324, 0.2894888923637941, 0.29146665241048586, 0.29139689004028235, 0.28906681362617814, 0.2909640672638027, 0.28794620108668784, 0.2870949666601673, 0.2853415113884014, 0.28600420027609297, 0.28616475802132546, 0.2849673519411229, 0.2849706382059237, 0.28222169851622464, 0.2823089506783788, 0.28214207599566166, 0.281814217073324, 0.28217195241879195, 0.2828230712083762, 0.27985546061798217], 'acc': [0.8163714812099302, 0.896275218337033, 0.914702552015758, 0.9223919866952405, 0.9261237635579394, 0.9286003945787127, 0.9308786275116998, 0.932381084309117, 0.9330422934916798, 0.9340005449437903, 0.9343690909538651, 0.93509026853386, 0.9361074179933783, 0.9364502933274949, 0.937114331219866, 0.937701151921199, 0.937941241291922, 0.9379909171036771, 0.9384724739684014, 0.9386868847687395, 0.9390458190213606, 0.9393543033028053, 0.939819152963766, 0.939804740211328, 0.9399946080206538, 0.9404361010953736, 0.9404736662591288, 0.9408740499747243, 0.9409021597182519, 0.9411089645545332, 0.9412562718321552, 0.941415136021779, 0.9416040754143572, 0.9416714868541856, 0.9421124697558931, 0.9419920459771768, 0.9422986119014577, 0.9422434847295594, 0.9422642888879418, 0.9425854045852475, 0.9428908790906821, 0.942898669671709, 0.9430691921828178, 0.9429317308180084, 0.9431519128349168, 0.9432609569872417, 0.9431798784333386, 0.9433599961891049, 0.9436378939569583, 0.9437621402239464, 0.9438336738070151, 0.9437909661769776, 0.9437174216639634, 0.943681251021371, 0.9438450313129245, 0.9442478024203446, 0.9444052053021861, 0.9444068039867812, 0.9443650721745246, 0.9445163155190398, 0.9445015307632926, 0.9448989052314715, 0.9446832674280949, 0.9446915890845532, 0.9447958129827103, 0.9445804798789215, 0.9450808752127781, 0.9450238734190695, 0.9452296859017911, 0.9451150484849935, 0.9451699907526429, 0.9453536764789874, 0.9451594495212546, 0.9454570247278017, 0.9455106654032959, 0.9454616121480937, 0.9454627924395683, 0.9455233158600085, 0.9454549358992855, 0.9458521249576044], 'mDice': [0.14377835926644508, 0.39903054230241203, 0.5269998622027946, 0.5839115236222411, 0.6085773873862352, 0.6233092007757451, 0.6374863198043892, 0.6455022928823688, 0.6510771219271191, 0.6567915905434341, 0.6601241605921198, 0.6645994838639585, 0.6699521211569356, 0.6730783714341685, 0.677512446441746, 0.6811743103655772, 0.6822398396868546, 0.6832554839768344, 0.6868830854225784, 0.6886363461202846, 0.6911768245402847, 0.693503765166323, 0.6954683853593064, 0.6970812093551986, 0.6977185608565244, 0.6999053622523966, 0.7011154163704227, 0.7035090296696394, 0.7052166980195878, 0.7055323105316206, 0.7072430924342412, 0.7088020132161161, 0.7102612046255917, 0.7100383600380601, 0.713142816814035, 0.7132737572560404, 0.7147431008522052, 0.7136545171506928, 0.7153464910817188, 0.7163874629561051, 0.7186952871303695, 0.7195688365556979, 0.7203208382404998, 0.720026804011797, 0.7215630771889953, 0.7220198306270663, 0.7217521872023109, 0.7235415119046487, 0.7252621157265409, 0.7253638832284601, 0.7266506029733555, 0.726149212953234, 0.726635167909905, 0.7269563793285702, 0.7281650626661692, 0.7297853769675968, 0.7314082539584886, 0.7320920078423939, 0.7311455824941897, 0.7324512091150903, 0.7321372947206565, 0.7346938493073918, 0.7331770110824376, 0.7332560528742685, 0.7349587133998514, 0.7335426711567293, 0.7359456807886311, 0.7365177073574305, 0.7378613662232502, 0.737369285938435, 0.7372226648668988, 0.7381804586031406, 0.7381100689075529, 0.7402659611410549, 0.7402305559131114, 0.7403228617895768, 0.7406102208151669, 0.7402910674516925, 0.7398474362628732, 0.7421044915633002]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.54s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.29s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.01s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:44,  2.06s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:46,  1.86s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:27,  1.80s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:58,  1.70s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:15,  1.77s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<07:59,  1.72s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:12,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<08:05,  1.75s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:35,  1.87s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:40,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:35,  1.89s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:13,  1.82s/it]predicting train subjects:   5%|▍         | 14/285 [00:25<08:19,  1.84s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:31,  1.89s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:41,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:16,  1.85s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:28,  1.90s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<08:13,  1.86s/it]predicting train subjects:   7%|▋         | 20/285 [00:36<08:25,  1.91s/it]predicting train subjects:   7%|▋         | 21/285 [00:38<08:40,  1.97s/it]predicting train subjects:   8%|▊         | 22/285 [00:40<08:17,  1.89s/it]predicting train subjects:   8%|▊         | 23/285 [00:42<08:07,  1.86s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:36,  1.75s/it]predicting train subjects:   9%|▉         | 25/285 [00:45<08:02,  1.86s/it]predicting train subjects:   9%|▉         | 26/285 [00:48<08:33,  1.98s/it]predicting train subjects:   9%|▉         | 27/285 [00:49<08:10,  1.90s/it]predicting train subjects:  10%|▉         | 28/285 [00:51<08:13,  1.92s/it]predicting train subjects:  10%|█         | 29/285 [00:53<08:22,  1.96s/it]predicting train subjects:  11%|█         | 30/285 [00:55<08:20,  1.96s/it]predicting train subjects:  11%|█         | 31/285 [00:57<08:22,  1.98s/it]predicting train subjects:  11%|█         | 32/285 [00:59<07:49,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:01<07:44,  1.84s/it]predicting train subjects:  12%|█▏        | 34/285 [01:03<07:47,  1.86s/it]predicting train subjects:  12%|█▏        | 35/285 [01:05<08:01,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:06<07:41,  1.86s/it]predicting train subjects:  13%|█▎        | 37/285 [01:08<07:44,  1.87s/it]predicting train subjects:  13%|█▎        | 38/285 [01:10<07:53,  1.92s/it]predicting train subjects:  14%|█▎        | 39/285 [01:12<07:27,  1.82s/it]predicting train subjects:  14%|█▍        | 40/285 [01:14<07:24,  1.81s/it]predicting train subjects:  14%|█▍        | 41/285 [01:15<07:10,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:17<07:02,  1.74s/it]predicting train subjects:  15%|█▌        | 43/285 [01:19<07:07,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:21<07:19,  1.83s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:02,  1.76s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:12,  1.81s/it]predicting train subjects:  16%|█▋        | 47/285 [01:26<06:57,  1.75s/it]predicting train subjects:  17%|█▋        | 48/285 [01:28<07:10,  1.82s/it]predicting train subjects:  17%|█▋        | 49/285 [01:30<07:27,  1.90s/it]predicting train subjects:  18%|█▊        | 50/285 [01:32<07:29,  1.91s/it]predicting train subjects:  18%|█▊        | 51/285 [01:34<07:36,  1.95s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:05,  1.83s/it]predicting train subjects:  19%|█▊        | 53/285 [01:38<07:21,  1.90s/it]predicting train subjects:  19%|█▉        | 54/285 [01:40<07:30,  1.95s/it]predicting train subjects:  19%|█▉        | 55/285 [01:41<07:17,  1.90s/it]predicting train subjects:  20%|█▉        | 56/285 [01:43<07:17,  1.91s/it]predicting train subjects:  20%|██        | 57/285 [01:45<07:27,  1.96s/it]predicting train subjects:  20%|██        | 58/285 [01:48<07:32,  1.99s/it]predicting train subjects:  21%|██        | 59/285 [01:50<07:36,  2.02s/it]predicting train subjects:  21%|██        | 60/285 [01:52<07:34,  2.02s/it]predicting train subjects:  21%|██▏       | 61/285 [01:53<07:00,  1.88s/it]predicting train subjects:  22%|██▏       | 62/285 [01:55<06:58,  1.88s/it]predicting train subjects:  22%|██▏       | 63/285 [01:57<07:11,  1.94s/it]predicting train subjects:  22%|██▏       | 64/285 [01:59<07:01,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:01<07:15,  1.98s/it]predicting train subjects:  23%|██▎       | 66/285 [02:03<07:14,  1.98s/it]predicting train subjects:  24%|██▎       | 67/285 [02:05<07:12,  1.99s/it]predicting train subjects:  24%|██▍       | 68/285 [02:07<06:43,  1.86s/it]predicting train subjects:  24%|██▍       | 69/285 [02:09<06:51,  1.91s/it]predicting train subjects:  25%|██▍       | 70/285 [02:11<06:49,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:12<06:43,  1.88s/it]predicting train subjects:  25%|██▌       | 72/285 [02:14<06:28,  1.82s/it]predicting train subjects:  26%|██▌       | 73/285 [02:16<06:37,  1.88s/it]predicting train subjects:  26%|██▌       | 74/285 [02:18<06:46,  1.93s/it]predicting train subjects:  26%|██▋       | 75/285 [02:20<06:52,  1.97s/it]predicting train subjects:  27%|██▋       | 76/285 [02:22<06:54,  1.98s/it]predicting train subjects:  27%|██▋       | 77/285 [02:24<06:39,  1.92s/it]predicting train subjects:  27%|██▋       | 78/285 [02:26<06:26,  1.87s/it]predicting train subjects:  28%|██▊       | 79/285 [02:28<06:19,  1.84s/it]predicting train subjects:  28%|██▊       | 80/285 [02:29<06:15,  1.83s/it]predicting train subjects:  28%|██▊       | 81/285 [02:31<06:06,  1.80s/it]predicting train subjects:  29%|██▉       | 82/285 [02:33<06:01,  1.78s/it]predicting train subjects:  29%|██▉       | 83/285 [02:34<05:52,  1.75s/it]predicting train subjects:  29%|██▉       | 84/285 [02:36<05:44,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:38<05:51,  1.76s/it]predicting train subjects:  30%|███       | 86/285 [02:40<06:01,  1.81s/it]predicting train subjects:  31%|███       | 87/285 [02:42<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:44<05:55,  1.81s/it]predicting train subjects:  31%|███       | 89/285 [02:45<05:48,  1.78s/it]predicting train subjects:  32%|███▏      | 90/285 [02:47<05:50,  1.80s/it]predicting train subjects:  32%|███▏      | 91/285 [02:49<05:44,  1.78s/it]predicting train subjects:  32%|███▏      | 92/285 [02:51<05:50,  1.81s/it]predicting train subjects:  33%|███▎      | 93/285 [02:52<05:42,  1.79s/it]predicting train subjects:  33%|███▎      | 94/285 [02:54<05:53,  1.85s/it]predicting train subjects:  33%|███▎      | 95/285 [02:56<05:54,  1.87s/it]predicting train subjects:  34%|███▎      | 96/285 [02:58<06:04,  1.93s/it]predicting train subjects:  34%|███▍      | 97/285 [03:00<06:09,  1.97s/it]predicting train subjects:  34%|███▍      | 98/285 [03:02<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:04<05:52,  1.90s/it]predicting train subjects:  35%|███▌      | 100/285 [03:06<05:51,  1.90s/it]predicting train subjects:  35%|███▌      | 101/285 [03:08<05:31,  1.80s/it]predicting train subjects:  36%|███▌      | 102/285 [03:10<05:45,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:11<05:39,  1.86s/it]predicting train subjects:  36%|███▋      | 104/285 [03:13<05:40,  1.88s/it]predicting train subjects:  37%|███▋      | 105/285 [03:15<05:38,  1.88s/it]predicting train subjects:  37%|███▋      | 106/285 [03:17<05:27,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:19<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:20<05:13,  1.77s/it]predicting train subjects:  38%|███▊      | 109/285 [03:22<05:20,  1.82s/it]predicting train subjects:  39%|███▊      | 110/285 [03:24<05:18,  1.82s/it]predicting train subjects:  39%|███▉      | 111/285 [03:26<05:05,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:28<05:28,  1.90s/it]predicting train subjects:  40%|███▉      | 113/285 [03:30<05:29,  1.92s/it]predicting train subjects:  40%|████      | 114/285 [03:32<05:25,  1.90s/it]predicting train subjects:  40%|████      | 115/285 [03:34<05:23,  1.90s/it]predicting train subjects:  41%|████      | 116/285 [03:36<05:17,  1.88s/it]predicting train subjects:  41%|████      | 117/285 [03:37<05:02,  1.80s/it]predicting train subjects:  41%|████▏     | 118/285 [03:39<04:53,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:41<04:54,  1.78s/it]predicting train subjects:  42%|████▏     | 120/285 [03:42<04:46,  1.73s/it]predicting train subjects:  42%|████▏     | 121/285 [03:44<04:39,  1.70s/it]predicting train subjects:  43%|████▎     | 122/285 [03:46<04:33,  1.68s/it]predicting train subjects:  43%|████▎     | 123/285 [03:47<04:26,  1.64s/it]predicting train subjects:  44%|████▎     | 124/285 [03:49<04:24,  1.64s/it]predicting train subjects:  44%|████▍     | 125/285 [03:50<04:14,  1.59s/it]predicting train subjects:  44%|████▍     | 126/285 [03:52<04:08,  1.57s/it]predicting train subjects:  45%|████▍     | 127/285 [03:53<04:00,  1.52s/it]predicting train subjects:  45%|████▍     | 128/285 [03:55<04:05,  1.57s/it]predicting train subjects:  45%|████▌     | 129/285 [03:56<03:59,  1.53s/it]predicting train subjects:  46%|████▌     | 130/285 [03:58<03:51,  1.49s/it]predicting train subjects:  46%|████▌     | 131/285 [03:59<03:53,  1.52s/it]predicting train subjects:  46%|████▋     | 132/285 [04:01<04:02,  1.58s/it]predicting train subjects:  47%|████▋     | 133/285 [04:03<03:58,  1.57s/it]predicting train subjects:  47%|████▋     | 134/285 [04:04<04:00,  1.59s/it]predicting train subjects:  47%|████▋     | 135/285 [04:06<03:52,  1.55s/it]predicting train subjects:  48%|████▊     | 136/285 [04:07<03:53,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:09<04:02,  1.64s/it]predicting train subjects:  48%|████▊     | 138/285 [04:10<03:51,  1.57s/it]predicting train subjects:  49%|████▉     | 139/285 [04:12<03:55,  1.61s/it]predicting train subjects:  49%|████▉     | 140/285 [04:14<03:55,  1.62s/it]predicting train subjects:  49%|████▉     | 141/285 [04:15<03:49,  1.59s/it]predicting train subjects:  50%|████▉     | 142/285 [04:17<03:44,  1.57s/it]predicting train subjects:  50%|█████     | 143/285 [04:18<03:39,  1.55s/it]predicting train subjects:  51%|█████     | 144/285 [04:20<03:42,  1.58s/it]predicting train subjects:  51%|█████     | 145/285 [04:22<03:38,  1.56s/it]predicting train subjects:  51%|█████     | 146/285 [04:23<03:44,  1.61s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:25<03:42,  1.61s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:27<03:45,  1.64s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:28<03:43,  1.64s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:30<03:30,  1.56s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:31<03:28,  1.56s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:33<03:25,  1.55s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:34<03:25,  1.56s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:36<03:29,  1.60s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:37<03:24,  1.57s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:39<03:36,  1.68s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:41<03:27,  1.62s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:43<03:30,  1.65s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:44<03:28,  1.66s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:46<03:19,  1.59s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:47<03:17,  1.59s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:49<03:12,  1.57s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:50<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:52<03:07,  1.55s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:53<03:03,  1.53s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:55<03:12,  1.61s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:57<03:10,  1.62s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:58<03:04,  1.57s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:00<03:03,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:01<02:59,  1.56s/it]predicting train subjects:  60%|██████    | 171/285 [05:03<02:55,  1.54s/it]predicting train subjects:  60%|██████    | 172/285 [05:04<02:50,  1.51s/it]predicting train subjects:  61%|██████    | 173/285 [05:06<02:47,  1.49s/it]predicting train subjects:  61%|██████    | 174/285 [05:07<02:43,  1.47s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:09<02:51,  1.56s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:11<02:53,  1.59s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:12<02:49,  1.57s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:14<02:43,  1.53s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:15<02:42,  1.53s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:17<02:56,  1.68s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:19<03:06,  1.79s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:21<03:13,  1.88s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:23<02:59,  1.76s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:24<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:26<02:38,  1.58s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:28<02:47,  1.69s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:29<02:49,  1.73s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:31<02:52,  1.78s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:33<02:41,  1.68s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:34<02:33,  1.61s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:36<02:36,  1.67s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:38<02:32,  1.64s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:39<02:24,  1.57s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:40<02:18,  1.52s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:42<02:15,  1.51s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:44<02:24,  1.63s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:46<02:28,  1.68s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:48<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:49<02:23,  1.66s/it]predicting train subjects:  70%|███████   | 200/285 [05:50<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:52<02:19,  1.66s/it]predicting train subjects:  71%|███████   | 202/285 [05:54<02:16,  1.65s/it]predicting train subjects:  71%|███████   | 203/285 [05:56<02:17,  1.68s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:57<02:09,  1.60s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:59<02:06,  1.58s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:00<02:00,  1.52s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:02<02:15,  1.74s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:04<02:19,  1.81s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:06<02:18,  1.82s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:07<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:09<01:58,  1.61s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:11<01:59,  1.63s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:12<01:57,  1.63s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:14<01:52,  1.58s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:15<01:56,  1.66s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:17<01:49,  1.59s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:19<01:52,  1.66s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:21<01:55,  1.72s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:22<01:55,  1.75s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:24<01:48,  1.67s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:25<01:41,  1.59s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:27<01:41,  1.62s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:28<01:34,  1.52s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:30<01:34,  1.55s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:31<01:28,  1.48s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:33<01:34,  1.60s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:35<01:37,  1.68s/it]predicting train subjects:  80%|████████  | 228/285 [06:37<01:41,  1.77s/it]predicting train subjects:  80%|████████  | 229/285 [06:39<01:37,  1.74s/it]predicting train subjects:  81%|████████  | 230/285 [06:40<01:30,  1.64s/it]predicting train subjects:  81%|████████  | 231/285 [06:41<01:24,  1.57s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:43<01:26,  1.63s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:45<01:23,  1.60s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:47<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:48<01:20,  1.62s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:50<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:52<01:27,  1.82s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:54<01:29,  1.90s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:56<01:27,  1.90s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:58<01:21,  1.81s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:59<01:16,  1.73s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:01<01:12,  1.68s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:02<01:09,  1.67s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:04<01:10,  1.73s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:06<01:08,  1.72s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:08<01:11,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:10<01:11,  1.89s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:12<01:09,  1.89s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:13<01:03,  1.76s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:15<00:58,  1.67s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:16<00:54,  1.60s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:18<00:52,  1.60s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:20<00:55,  1.73s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:22<00:55,  1.79s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:24<00:53,  1.78s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:25<00:48,  1.68s/it]predicting train subjects:  90%|█████████ | 257/285 [07:27<00:46,  1.67s/it]predicting train subjects:  91%|█████████ | 258/285 [07:29<00:46,  1.72s/it]predicting train subjects:  91%|█████████ | 259/285 [07:30<00:43,  1.67s/it]predicting train subjects:  91%|█████████ | 260/285 [07:32<00:39,  1.59s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:33<00:37,  1.55s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:35<00:35,  1.53s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:36<00:33,  1.51s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:38<00:34,  1.65s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:40<00:34,  1.74s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:41<00:31,  1.64s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:43<00:29,  1.63s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:45<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:47<00:28,  1.76s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:48<00:25,  1.69s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:50<00:23,  1.66s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:52<00:22,  1.71s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:53<00:19,  1.66s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:55<00:17,  1.62s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:57<00:17,  1.79s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:59<00:16,  1.84s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:00<00:13,  1.74s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:02<00:12,  1.72s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:04<00:10,  1.73s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:05<00:08,  1.67s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:07<00:06,  1.66s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:08<00:04,  1.60s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:10<00:03,  1.73s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:12<00:01,  1.80s/it]predicting train subjects: 100%|██████████| 285/285 [08:14<00:00,  1.85s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<09:49,  2.07s/it]Loading train:   1%|          | 2/285 [00:03<09:15,  1.96s/it]Loading train:   1%|          | 3/285 [00:05<09:33,  2.03s/it]Loading train:   1%|▏         | 4/285 [00:07<09:00,  1.92s/it]Loading train:   2%|▏         | 5/285 [00:09<09:20,  2.00s/it]Loading train:   2%|▏         | 6/285 [00:11<08:40,  1.86s/it]Loading train:   2%|▏         | 7/285 [00:13<08:40,  1.87s/it]Loading train:   3%|▎         | 8/285 [00:14<08:13,  1.78s/it]Loading train:   3%|▎         | 9/285 [00:16<08:28,  1.84s/it]Loading train:   4%|▎         | 10/285 [00:18<08:00,  1.75s/it]Loading train:   4%|▍         | 11/285 [00:19<07:24,  1.62s/it]Loading train:   4%|▍         | 12/285 [00:21<07:16,  1.60s/it]Loading train:   5%|▍         | 13/285 [00:22<06:34,  1.45s/it]Loading train:   5%|▍         | 14/285 [00:23<06:41,  1.48s/it]Loading train:   5%|▌         | 15/285 [00:25<06:43,  1.50s/it]Loading train:   6%|▌         | 16/285 [00:26<06:29,  1.45s/it]Loading train:   6%|▌         | 17/285 [00:27<06:03,  1.35s/it]Loading train:   6%|▋         | 18/285 [00:29<06:27,  1.45s/it]Loading train:   7%|▋         | 19/285 [00:30<06:16,  1.42s/it]Loading train:   7%|▋         | 20/285 [00:32<06:23,  1.45s/it]Loading train:   7%|▋         | 21/285 [00:33<06:25,  1.46s/it]Loading train:   8%|▊         | 22/285 [00:35<06:07,  1.40s/it]Loading train:   8%|▊         | 23/285 [00:36<06:12,  1.42s/it]Loading train:   8%|▊         | 24/285 [00:37<05:58,  1.37s/it]Loading train:   9%|▉         | 25/285 [00:39<06:07,  1.41s/it]Loading train:   9%|▉         | 26/285 [00:40<05:58,  1.39s/it]Loading train:   9%|▉         | 27/285 [00:41<05:42,  1.33s/it]Loading train:  10%|▉         | 28/285 [00:43<05:33,  1.30s/it]Loading train:  10%|█         | 29/285 [00:44<05:31,  1.30s/it]Loading train:  11%|█         | 30/285 [00:45<05:42,  1.34s/it]Loading train:  11%|█         | 31/285 [00:47<06:29,  1.53s/it]Loading train:  11%|█         | 32/285 [00:49<06:05,  1.44s/it]Loading train:  12%|█▏        | 33/285 [00:50<06:02,  1.44s/it]Loading train:  12%|█▏        | 34/285 [00:52<06:18,  1.51s/it]Loading train:  12%|█▏        | 35/285 [00:53<06:32,  1.57s/it]Loading train:  13%|█▎        | 36/285 [00:55<05:58,  1.44s/it]Loading train:  13%|█▎        | 37/285 [00:56<05:57,  1.44s/it]Loading train:  13%|█▎        | 38/285 [00:58<06:16,  1.52s/it]Loading train:  14%|█▎        | 39/285 [00:59<06:08,  1.50s/it]Loading train:  14%|█▍        | 40/285 [01:01<06:13,  1.52s/it]Loading train:  14%|█▍        | 41/285 [01:02<05:51,  1.44s/it]Loading train:  15%|█▍        | 42/285 [01:03<05:24,  1.34s/it]Loading train:  15%|█▌        | 43/285 [01:04<05:15,  1.30s/it]Loading train:  15%|█▌        | 44/285 [01:06<05:27,  1.36s/it]Loading train:  16%|█▌        | 45/285 [01:07<05:15,  1.31s/it]Loading train:  16%|█▌        | 46/285 [01:08<05:27,  1.37s/it]Loading train:  16%|█▋        | 47/285 [01:10<05:24,  1.36s/it]Loading train:  17%|█▋        | 48/285 [01:11<05:23,  1.36s/it]Loading train:  17%|█▋        | 49/285 [01:13<05:32,  1.41s/it]Loading train:  18%|█▊        | 50/285 [01:14<05:35,  1.43s/it]Loading train:  18%|█▊        | 51/285 [01:16<05:37,  1.44s/it]Loading train:  18%|█▊        | 52/285 [01:17<05:43,  1.47s/it]Loading train:  19%|█▊        | 53/285 [01:19<05:34,  1.44s/it]Loading train:  19%|█▉        | 54/285 [01:20<05:52,  1.52s/it]Loading train:  19%|█▉        | 55/285 [01:22<05:37,  1.47s/it]Loading train:  20%|█▉        | 56/285 [01:23<05:33,  1.45s/it]Loading train:  20%|██        | 57/285 [01:24<05:30,  1.45s/it]Loading train:  20%|██        | 58/285 [01:26<05:10,  1.37s/it]Loading train:  21%|██        | 59/285 [01:27<05:21,  1.42s/it]Loading train:  21%|██        | 60/285 [01:29<05:16,  1.41s/it]Loading train:  21%|██▏       | 61/285 [01:30<05:03,  1.36s/it]Loading train:  22%|██▏       | 62/285 [01:31<05:02,  1.36s/it]Loading train:  22%|██▏       | 63/285 [01:33<04:58,  1.34s/it]Loading train:  22%|██▏       | 64/285 [01:34<05:34,  1.51s/it]Loading train:  23%|██▎       | 65/285 [01:36<06:10,  1.69s/it]Loading train:  23%|██▎       | 66/285 [01:38<06:18,  1.73s/it]Loading train:  24%|██▎       | 67/285 [01:40<06:11,  1.70s/it]Loading train:  24%|██▍       | 68/285 [01:41<05:34,  1.54s/it]Loading train:  24%|██▍       | 69/285 [01:42<05:06,  1.42s/it]Loading train:  25%|██▍       | 70/285 [01:44<05:18,  1.48s/it]Loading train:  25%|██▍       | 71/285 [01:45<05:04,  1.42s/it]Loading train:  25%|██▌       | 72/285 [01:47<05:23,  1.52s/it]Loading train:  26%|██▌       | 73/285 [01:48<05:15,  1.49s/it]Loading train:  26%|██▌       | 74/285 [01:50<05:14,  1.49s/it]Loading train:  26%|██▋       | 75/285 [01:51<05:16,  1.51s/it]Loading train:  27%|██▋       | 76/285 [01:53<04:54,  1.41s/it]Loading train:  27%|██▋       | 77/285 [01:54<04:50,  1.39s/it]Loading train:  27%|██▋       | 78/285 [01:55<04:34,  1.33s/it]Loading train:  28%|██▊       | 79/285 [01:57<04:42,  1.37s/it]Loading train:  28%|██▊       | 80/285 [01:58<04:33,  1.33s/it]Loading train:  28%|██▊       | 81/285 [01:59<04:32,  1.34s/it]Loading train:  29%|██▉       | 82/285 [02:01<04:35,  1.36s/it]Loading train:  29%|██▉       | 83/285 [02:02<04:23,  1.30s/it]Loading train:  29%|██▉       | 84/285 [02:03<04:33,  1.36s/it]Loading train:  30%|██▉       | 85/285 [02:05<04:36,  1.38s/it]Loading train:  30%|███       | 86/285 [02:06<04:42,  1.42s/it]Loading train:  31%|███       | 87/285 [02:08<04:42,  1.42s/it]Loading train:  31%|███       | 88/285 [02:09<04:22,  1.33s/it]Loading train:  31%|███       | 89/285 [02:10<04:22,  1.34s/it]Loading train:  32%|███▏      | 90/285 [02:11<04:21,  1.34s/it]Loading train:  32%|███▏      | 91/285 [02:13<04:27,  1.38s/it]Loading train:  32%|███▏      | 92/285 [02:14<04:19,  1.35s/it]Loading train:  33%|███▎      | 93/285 [02:15<04:07,  1.29s/it]Loading train:  33%|███▎      | 94/285 [02:17<04:05,  1.28s/it]Loading train:  33%|███▎      | 95/285 [02:18<04:18,  1.36s/it]Loading train:  34%|███▎      | 96/285 [02:19<04:17,  1.36s/it]Loading train:  34%|███▍      | 97/285 [02:21<04:21,  1.39s/it]Loading train:  34%|███▍      | 98/285 [02:22<04:16,  1.37s/it]Loading train:  35%|███▍      | 99/285 [02:23<04:04,  1.32s/it]Loading train:  35%|███▌      | 100/285 [02:25<04:05,  1.33s/it]Loading train:  35%|███▌      | 101/285 [02:26<04:03,  1.32s/it]Loading train:  36%|███▌      | 102/285 [02:28<04:22,  1.43s/it]Loading train:  36%|███▌      | 103/285 [02:29<04:10,  1.38s/it]Loading train:  36%|███▋      | 104/285 [02:30<04:02,  1.34s/it]Loading train:  37%|███▋      | 105/285 [02:32<04:07,  1.37s/it]Loading train:  37%|███▋      | 106/285 [02:33<04:04,  1.36s/it]Loading train:  38%|███▊      | 107/285 [02:35<04:08,  1.40s/it]Loading train:  38%|███▊      | 108/285 [02:36<04:12,  1.42s/it]Loading train:  38%|███▊      | 109/285 [02:37<04:07,  1.41s/it]Loading train:  39%|███▊      | 110/285 [02:39<04:04,  1.40s/it]Loading train:  39%|███▉      | 111/285 [02:40<03:59,  1.37s/it]Loading train:  39%|███▉      | 112/285 [02:42<04:03,  1.41s/it]Loading train:  40%|███▉      | 113/285 [02:43<04:08,  1.45s/it]Loading train:  40%|████      | 114/285 [02:45<04:02,  1.42s/it]Loading train:  40%|████      | 115/285 [02:46<04:02,  1.43s/it]Loading train:  41%|████      | 116/285 [02:48<04:07,  1.47s/it]Loading train:  41%|████      | 117/285 [02:49<04:04,  1.45s/it]Loading train:  41%|████▏     | 118/285 [02:50<03:55,  1.41s/it]Loading train:  42%|████▏     | 119/285 [02:52<03:59,  1.44s/it]Loading train:  42%|████▏     | 120/285 [02:53<03:51,  1.40s/it]Loading train:  42%|████▏     | 121/285 [02:55<04:14,  1.55s/it]Loading train:  43%|████▎     | 122/285 [02:57<04:11,  1.55s/it]Loading train:  43%|████▎     | 123/285 [02:58<04:06,  1.52s/it]Loading train:  44%|████▎     | 124/285 [02:59<03:42,  1.38s/it]Loading train:  44%|████▍     | 125/285 [03:00<03:30,  1.32s/it]Loading train:  44%|████▍     | 126/285 [03:01<03:25,  1.29s/it]Loading train:  45%|████▍     | 127/285 [03:03<03:23,  1.29s/it]Loading train:  45%|████▍     | 128/285 [03:04<03:17,  1.26s/it]Loading train:  45%|████▌     | 129/285 [03:05<03:09,  1.22s/it]Loading train:  46%|████▌     | 130/285 [03:06<02:56,  1.14s/it]Loading train:  46%|████▌     | 131/285 [03:07<02:55,  1.14s/it]Loading train:  46%|████▋     | 132/285 [03:08<02:54,  1.14s/it]Loading train:  47%|████▋     | 133/285 [03:09<02:51,  1.13s/it]Loading train:  47%|████▋     | 134/285 [03:10<02:45,  1.10s/it]Loading train:  47%|████▋     | 135/285 [03:12<02:46,  1.11s/it]Loading train:  48%|████▊     | 136/285 [03:13<02:42,  1.09s/it]Loading train:  48%|████▊     | 137/285 [03:14<02:46,  1.12s/it]Loading train:  48%|████▊     | 138/285 [03:15<02:50,  1.16s/it]Loading train:  49%|████▉     | 139/285 [03:16<02:46,  1.14s/it]Loading train:  49%|████▉     | 140/285 [03:17<02:44,  1.14s/it]Loading train:  49%|████▉     | 141/285 [03:18<02:39,  1.11s/it]Loading train:  50%|████▉     | 142/285 [03:20<02:43,  1.14s/it]Loading train:  50%|█████     | 143/285 [03:21<02:46,  1.17s/it]Loading train:  51%|█████     | 144/285 [03:22<02:45,  1.18s/it]Loading train:  51%|█████     | 145/285 [03:23<02:49,  1.21s/it]Loading train:  51%|█████     | 146/285 [03:24<02:43,  1.17s/it]Loading train:  52%|█████▏    | 147/285 [03:25<02:40,  1.16s/it]Loading train:  52%|█████▏    | 148/285 [03:26<02:30,  1.10s/it]Loading train:  52%|█████▏    | 149/285 [03:28<02:32,  1.12s/it]Loading train:  53%|█████▎    | 150/285 [03:29<02:34,  1.14s/it]Loading train:  53%|█████▎    | 151/285 [03:30<02:34,  1.15s/it]Loading train:  53%|█████▎    | 152/285 [03:31<02:30,  1.13s/it]Loading train:  54%|█████▎    | 153/285 [03:32<02:33,  1.16s/it]Loading train:  54%|█████▍    | 154/285 [03:33<02:33,  1.17s/it]Loading train:  54%|█████▍    | 155/285 [03:35<02:41,  1.24s/it]Loading train:  55%|█████▍    | 156/285 [03:36<02:31,  1.18s/it]Loading train:  55%|█████▌    | 157/285 [03:37<02:31,  1.18s/it]Loading train:  55%|█████▌    | 158/285 [03:38<02:35,  1.22s/it]Loading train:  56%|█████▌    | 159/285 [03:40<02:38,  1.26s/it]Loading train:  56%|█████▌    | 160/285 [03:41<02:28,  1.19s/it]Loading train:  56%|█████▋    | 161/285 [03:42<02:24,  1.16s/it]Loading train:  57%|█████▋    | 162/285 [03:43<02:13,  1.08s/it]Loading train:  57%|█████▋    | 163/285 [03:44<02:32,  1.25s/it]Loading train:  58%|█████▊    | 164/285 [03:46<02:32,  1.26s/it]Loading train:  58%|█████▊    | 165/285 [03:47<02:33,  1.28s/it]Loading train:  58%|█████▊    | 166/285 [03:48<02:32,  1.28s/it]Loading train:  59%|█████▊    | 167/285 [03:50<02:37,  1.33s/it]Loading train:  59%|█████▉    | 168/285 [03:51<02:27,  1.26s/it]Loading train:  59%|█████▉    | 169/285 [03:52<02:19,  1.20s/it]Loading train:  60%|█████▉    | 170/285 [03:53<02:05,  1.09s/it]Loading train:  60%|██████    | 171/285 [03:54<01:58,  1.04s/it]Loading train:  60%|██████    | 172/285 [03:55<01:55,  1.02s/it]Loading train:  61%|██████    | 173/285 [03:56<01:54,  1.02s/it]Loading train:  61%|██████    | 174/285 [03:57<01:56,  1.05s/it]Loading train:  61%|██████▏   | 175/285 [03:58<01:53,  1.04s/it]Loading train:  62%|██████▏   | 176/285 [03:59<01:47,  1.01it/s]Loading train:  62%|██████▏   | 177/285 [04:00<01:51,  1.03s/it]Loading train:  62%|██████▏   | 178/285 [04:01<01:49,  1.02s/it]Loading train:  63%|██████▎   | 179/285 [04:02<01:54,  1.08s/it]Loading train:  63%|██████▎   | 180/285 [04:03<01:57,  1.12s/it]Loading train:  64%|██████▎   | 181/285 [04:04<01:57,  1.13s/it]Loading train:  64%|██████▍   | 182/285 [04:05<01:56,  1.13s/it]Loading train:  64%|██████▍   | 183/285 [04:07<01:56,  1.14s/it]Loading train:  65%|██████▍   | 184/285 [04:08<01:59,  1.19s/it]Loading train:  65%|██████▍   | 185/285 [04:09<01:54,  1.15s/it]Loading train:  65%|██████▌   | 186/285 [04:11<02:08,  1.30s/it]Loading train:  66%|██████▌   | 187/285 [04:12<02:10,  1.34s/it]Loading train:  66%|██████▌   | 188/285 [04:13<02:06,  1.31s/it]Loading train:  66%|██████▋   | 189/285 [04:14<02:01,  1.27s/it]Loading train:  67%|██████▋   | 190/285 [04:16<01:59,  1.26s/it]Loading train:  67%|██████▋   | 191/285 [04:17<01:55,  1.23s/it]Loading train:  67%|██████▋   | 192/285 [04:18<01:51,  1.20s/it]Loading train:  68%|██████▊   | 193/285 [04:19<01:49,  1.19s/it]Loading train:  68%|██████▊   | 194/285 [04:20<01:47,  1.18s/it]Loading train:  68%|██████▊   | 195/285 [04:21<01:41,  1.13s/it]Loading train:  69%|██████▉   | 196/285 [04:23<01:41,  1.14s/it]Loading train:  69%|██████▉   | 197/285 [04:24<01:44,  1.19s/it]Loading train:  69%|██████▉   | 198/285 [04:25<01:45,  1.22s/it]Loading train:  70%|██████▉   | 199/285 [04:26<01:44,  1.22s/it]Loading train:  70%|███████   | 200/285 [04:27<01:39,  1.17s/it]Loading train:  71%|███████   | 201/285 [04:29<01:44,  1.24s/it]Loading train:  71%|███████   | 202/285 [04:30<01:42,  1.24s/it]Loading train:  71%|███████   | 203/285 [04:31<01:42,  1.25s/it]Loading train:  72%|███████▏  | 204/285 [04:32<01:39,  1.23s/it]Loading train:  72%|███████▏  | 205/285 [04:34<01:39,  1.24s/it]Loading train:  72%|███████▏  | 206/285 [04:35<01:37,  1.23s/it]Loading train:  73%|███████▎  | 207/285 [04:37<01:47,  1.37s/it]Loading train:  73%|███████▎  | 208/285 [04:38<01:42,  1.33s/it]Loading train:  73%|███████▎  | 209/285 [04:40<01:50,  1.45s/it]Loading train:  74%|███████▎  | 210/285 [04:41<01:40,  1.33s/it]Loading train:  74%|███████▍  | 211/285 [04:42<01:33,  1.27s/it]Loading train:  74%|███████▍  | 212/285 [04:43<01:36,  1.32s/it]Loading train:  75%|███████▍  | 213/285 [04:44<01:33,  1.30s/it]Loading train:  75%|███████▌  | 214/285 [04:46<01:32,  1.30s/it]Loading train:  75%|███████▌  | 215/285 [04:47<01:31,  1.30s/it]Loading train:  76%|███████▌  | 216/285 [04:48<01:28,  1.28s/it]Loading train:  76%|███████▌  | 217/285 [04:50<01:29,  1.31s/it]Loading train:  76%|███████▋  | 218/285 [04:51<01:28,  1.32s/it]Loading train:  77%|███████▋  | 219/285 [04:53<01:30,  1.38s/it]Loading train:  77%|███████▋  | 220/285 [04:54<01:28,  1.37s/it]Loading train:  78%|███████▊  | 221/285 [04:55<01:27,  1.37s/it]Loading train:  78%|███████▊  | 222/285 [04:57<01:28,  1.41s/it]Loading train:  78%|███████▊  | 223/285 [04:58<01:27,  1.41s/it]Loading train:  79%|███████▊  | 224/285 [04:59<01:20,  1.32s/it]Loading train:  79%|███████▉  | 225/285 [05:00<01:14,  1.24s/it]Loading train:  79%|███████▉  | 226/285 [05:02<01:13,  1.25s/it]Loading train:  80%|███████▉  | 227/285 [05:03<01:18,  1.35s/it]Loading train:  80%|████████  | 228/285 [05:05<01:20,  1.41s/it]Loading train:  80%|████████  | 229/285 [05:06<01:17,  1.39s/it]Loading train:  81%|████████  | 230/285 [05:07<01:09,  1.27s/it]Loading train:  81%|████████  | 231/285 [05:08<01:02,  1.16s/it]Loading train:  81%|████████▏ | 232/285 [05:09<01:02,  1.19s/it]Loading train:  82%|████████▏ | 233/285 [05:10<00:59,  1.14s/it]Loading train:  82%|████████▏ | 234/285 [05:12<01:01,  1.21s/it]Loading train:  82%|████████▏ | 235/285 [05:13<00:58,  1.18s/it]Loading train:  83%|████████▎ | 236/285 [05:14<00:58,  1.20s/it]Loading train:  83%|████████▎ | 237/285 [05:15<00:58,  1.21s/it]Loading train:  84%|████████▎ | 238/285 [05:16<00:56,  1.20s/it]Loading train:  84%|████████▍ | 239/285 [05:18<00:54,  1.19s/it]Loading train:  84%|████████▍ | 240/285 [05:19<00:51,  1.14s/it]Loading train:  85%|████████▍ | 241/285 [05:20<00:51,  1.17s/it]Loading train:  85%|████████▍ | 242/285 [05:21<00:50,  1.17s/it]Loading train:  85%|████████▌ | 243/285 [05:22<00:48,  1.16s/it]Loading train:  86%|████████▌ | 244/285 [05:24<00:51,  1.26s/it]Loading train:  86%|████████▌ | 245/285 [05:25<00:46,  1.16s/it]Loading train:  86%|████████▋ | 246/285 [05:26<00:47,  1.23s/it]Loading train:  87%|████████▋ | 247/285 [05:27<00:47,  1.26s/it]Loading train:  87%|████████▋ | 248/285 [05:29<00:51,  1.39s/it]Loading train:  87%|████████▋ | 249/285 [05:30<00:48,  1.35s/it]Loading train:  88%|████████▊ | 250/285 [05:31<00:45,  1.30s/it]Loading train:  88%|████████▊ | 251/285 [05:32<00:40,  1.19s/it]Loading train:  88%|████████▊ | 252/285 [05:34<00:39,  1.21s/it]Loading train:  89%|████████▉ | 253/285 [05:35<00:42,  1.31s/it]Loading train:  89%|████████▉ | 254/285 [05:36<00:40,  1.31s/it]Loading train:  89%|████████▉ | 255/285 [05:38<00:37,  1.25s/it]Loading train:  90%|████████▉ | 256/285 [05:39<00:34,  1.19s/it]Loading train:  90%|█████████ | 257/285 [05:40<00:31,  1.12s/it]Loading train:  91%|█████████ | 258/285 [05:41<00:32,  1.20s/it]Loading train:  91%|█████████ | 259/285 [05:42<00:32,  1.23s/it]Loading train:  91%|█████████ | 260/285 [05:44<00:32,  1.29s/it]Loading train:  92%|█████████▏| 261/285 [05:45<00:28,  1.20s/it]Loading train:  92%|█████████▏| 262/285 [05:46<00:25,  1.10s/it]Loading train:  92%|█████████▏| 263/285 [05:47<00:24,  1.13s/it]Loading train:  93%|█████████▎| 264/285 [05:48<00:25,  1.21s/it]Loading train:  93%|█████████▎| 265/285 [05:49<00:24,  1.23s/it]Loading train:  93%|█████████▎| 266/285 [05:50<00:22,  1.16s/it]Loading train:  94%|█████████▎| 267/285 [05:51<00:20,  1.12s/it]Loading train:  94%|█████████▍| 268/285 [05:53<00:19,  1.17s/it]Loading train:  94%|█████████▍| 269/285 [05:54<00:19,  1.19s/it]Loading train:  95%|█████████▍| 270/285 [05:55<00:18,  1.24s/it]Loading train:  95%|█████████▌| 271/285 [05:56<00:16,  1.19s/it]Loading train:  95%|█████████▌| 272/285 [05:58<00:16,  1.23s/it]Loading train:  96%|█████████▌| 273/285 [05:59<00:13,  1.16s/it]Loading train:  96%|█████████▌| 274/285 [06:00<00:12,  1.15s/it]Loading train:  96%|█████████▋| 275/285 [06:01<00:12,  1.23s/it]Loading train:  97%|█████████▋| 276/285 [06:03<00:11,  1.27s/it]Loading train:  97%|█████████▋| 277/285 [06:04<00:09,  1.20s/it]Loading train:  98%|█████████▊| 278/285 [06:05<00:08,  1.15s/it]Loading train:  98%|█████████▊| 279/285 [06:06<00:07,  1.17s/it]Loading train:  98%|█████████▊| 280/285 [06:07<00:06,  1.21s/it]Loading train:  99%|█████████▊| 281/285 [06:08<00:04,  1.19s/it]Loading train:  99%|█████████▉| 282/285 [06:09<00:03,  1.18s/it]Loading train:  99%|█████████▉| 283/285 [06:11<00:02,  1.20s/it]Loading train: 100%|█████████▉| 284/285 [06:12<00:01,  1.26s/it]Loading train: 100%|██████████| 285/285 [06:14<00:00,  1.31s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:05, 48.77it/s]concatenating: train:   4%|▎         | 10/285 [00:00<00:05, 46.87it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:05, 49.42it/s]concatenating: train:   8%|▊         | 24/285 [00:00<00:04, 55.07it/s]concatenating: train:  11%|█         | 30/285 [00:00<00:04, 53.45it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:04, 51.08it/s]concatenating: train:  14%|█▍        | 40/285 [00:00<00:04, 50.75it/s]concatenating: train:  16%|█▌        | 45/285 [00:00<00:05, 46.57it/s]concatenating: train:  18%|█▊        | 51/285 [00:00<00:04, 48.76it/s]concatenating: train:  20%|█▉        | 56/285 [00:01<00:04, 49.08it/s]concatenating: train:  22%|██▏       | 62/285 [00:01<00:04, 51.76it/s]concatenating: train:  24%|██▍       | 69/285 [00:01<00:04, 53.44it/s]concatenating: train:  27%|██▋       | 77/285 [00:01<00:03, 59.29it/s]concatenating: train:  32%|███▏      | 91/285 [00:01<00:02, 70.82it/s]concatenating: train:  35%|███▌      | 100/285 [00:01<00:02, 74.91it/s]concatenating: train:  38%|███▊      | 109/285 [00:01<00:02, 74.93it/s]concatenating: train:  41%|████▏     | 118/285 [00:01<00:02, 72.08it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:01, 82.57it/s]concatenating: train:  49%|████▉     | 141/285 [00:02<00:01, 72.42it/s]concatenating: train:  53%|█████▎    | 150/285 [00:02<00:01, 72.06it/s]concatenating: train:  59%|█████▊    | 167/285 [00:02<00:01, 86.59it/s]concatenating: train:  62%|██████▏   | 178/285 [00:02<00:01, 77.04it/s]concatenating: train:  66%|██████▌   | 188/285 [00:02<00:01, 65.56it/s]concatenating: train:  69%|██████▉   | 196/285 [00:02<00:01, 62.60it/s]concatenating: train:  72%|███████▏  | 205/285 [00:03<00:01, 68.08it/s]concatenating: train:  75%|███████▍  | 213/285 [00:03<00:01, 61.97it/s]concatenating: train:  77%|███████▋  | 220/285 [00:03<00:01, 58.34it/s]concatenating: train:  80%|███████▉  | 227/285 [00:03<00:00, 60.22it/s]concatenating: train:  82%|████████▏ | 234/285 [00:03<00:00, 60.89it/s]concatenating: train:  85%|████████▌ | 243/285 [00:03<00:00, 67.35it/s]concatenating: train:  88%|████████▊ | 251/285 [00:03<00:00, 68.53it/s]concatenating: train:  91%|█████████ | 259/285 [00:03<00:00, 55.31it/s]concatenating: train:  94%|█████████▍| 268/285 [00:04<00:00, 61.75it/s]concatenating: train:  98%|█████████▊| 280/285 [00:04<00:00, 72.27it/s]concatenating: train: 100%|██████████| 285/285 [00:04<00:00, 67.09it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.48s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.49s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.49s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 277.00it/s]2019-07-11 11:24:47.899670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 11:24:47.899758: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 11:24:47.899772: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 11:24:47.899780: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 11:24:47.900112: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.30it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.91it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.03it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:06,  5.27it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.78it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.29it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:07,  4.34it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  5.76it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.57it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.51it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:02,  6.76it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.70it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:03,  5.31it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.60it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  5.06it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.34it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.45it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  5.36it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.65it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  4.94it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  7.79it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 30)   16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 52, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 52, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 52, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 90)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 262,893
Trainable params: 87,973
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 22s - loss: 1.8311 - acc: 0.7304 - mDice: 0.2602 - val_loss: 0.7313 - val_acc: 0.9404 - val_mDice: 0.4856

Epoch 00001: val_mDice improved from -inf to 0.48563, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 17s - loss: 0.5209 - acc: 0.9323 - mDice: 0.5802 - val_loss: 0.4871 - val_acc: 0.9503 - val_mDice: 0.6050

Epoch 00002: val_mDice improved from 0.48563 to 0.60495, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.4240 - acc: 0.9423 - mDice: 0.6402 - val_loss: 0.4772 - val_acc: 0.9524 - val_mDice: 0.6107

Epoch 00003: val_mDice improved from 0.60495 to 0.61069, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 17s - loss: 0.3881 - acc: 0.9456 - mDice: 0.6644 - val_loss: 0.4421 - val_acc: 0.9546 - val_mDice: 0.6320

Epoch 00004: val_mDice improved from 0.61069 to 0.63201, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 16s - loss: 0.3656 - acc: 0.9475 - mDice: 0.6799 - val_loss: 0.4458 - val_acc: 0.9537 - val_mDice: 0.6291

Epoch 00005: val_mDice did not improve from 0.63201
Epoch 6/300
 - 17s - loss: 0.3529 - acc: 0.9486 - mDice: 0.6890 - val_loss: 0.4518 - val_acc: 0.9532 - val_mDice: 0.6244

Epoch 00006: val_mDice did not improve from 0.63201
Epoch 7/300
 - 17s - loss: 0.3403 - acc: 0.9495 - mDice: 0.6978 - val_loss: 0.4546 - val_acc: 0.9509 - val_mDice: 0.6254

Epoch 00007: val_mDice did not improve from 0.63201
Epoch 8/300
 - 17s - loss: 0.3287 - acc: 0.9505 - mDice: 0.7062 - val_loss: 0.4452 - val_acc: 0.9558 - val_mDice: 0.6317

Epoch 00008: val_mDice did not improve from 0.63201
Epoch 9/300
 - 17s - loss: 0.3205 - acc: 0.9511 - mDice: 0.7121 - val_loss: 0.4500 - val_acc: 0.9542 - val_mDice: 0.6273

Epoch 00009: val_mDice did not improve from 0.63201
Epoch 10/300
 - 17s - loss: 0.3146 - acc: 0.9516 - mDice: 0.7166 - val_loss: 0.4351 - val_acc: 0.9560 - val_mDice: 0.6372

Epoch 00010: val_mDice improved from 0.63201 to 0.63722, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 17s - loss: 0.3076 - acc: 0.9520 - mDice: 0.7216 - val_loss: 0.4518 - val_acc: 0.9551 - val_mDice: 0.6281

Epoch 00011: val_mDice did not improve from 0.63722
Epoch 12/300
 - 16s - loss: 0.3037 - acc: 0.9524 - mDice: 0.7249 - val_loss: 0.4818 - val_acc: 0.9554 - val_mDice: 0.6153

Epoch 00012: val_mDice did not improve from 0.63722
Epoch 13/300
 - 17s - loss: 0.2965 - acc: 0.9529 - mDice: 0.7300 - val_loss: 0.4493 - val_acc: 0.9544 - val_mDice: 0.6305

Epoch 00013: val_mDice did not improve from 0.63722
Epoch 14/300
 - 17s - loss: 0.2926 - acc: 0.9533 - mDice: 0.7330 - val_loss: 0.4706 - val_acc: 0.9544 - val_mDice: 0.6177

Epoch 00014: val_mDice did not improve from 0.63722
Epoch 15/300
 - 17s - loss: 0.2879 - acc: 0.9536 - mDice: 0.7364 - val_loss: 0.4381 - val_acc: 0.9562 - val_mDice: 0.6348

Epoch 00015: val_mDice did not improve from 0.63722
Epoch 16/300
 - 17s - loss: 0.2865 - acc: 0.9537 - mDice: 0.7377 - val_loss: 0.4590 - val_acc: 0.9568 - val_mDice: 0.6253

Epoch 00016: val_mDice did not improve from 0.63722
Epoch 17/300
 - 18s - loss: 0.2812 - acc: 0.9541 - mDice: 0.7417 - val_loss: 0.4640 - val_acc: 0.9546 - val_mDice: 0.6220

Epoch 00017: val_mDice did not improve from 0.63722
Epoch 18/300
 - 17s - loss: 0.3052 - acc: 0.9523 - mDice: 0.7254 - val_loss: 0.4754 - val_acc: 0.9532 - val_mDice: 0.6123

Epoch 00018: val_mDice did not improve from 0.63722
Epoch 19/300
 - 17s - loss: 0.2885 - acc: 0.9535 - mDice: 0.7360 - val_loss: 0.4351 - val_acc: 0.9554 - val_mDice: 0.6366

Epoch 00019: val_mDice did not improve from 0.63722
Epoch 20/300
 - 17s - loss: 0.2769 - acc: 0.9544 - mDice: 0.7450 - val_loss: 0.4404 - val_acc: 0.9560 - val_mDice: 0.6350

Epoch 00020: val_mDice did not improve from 0.63722
Epoch 21/300
 - 17s - loss: 0.2730 - acc: 0.9547 - mDice: 0.7482 - val_loss: 0.4676 - val_acc: 0.9535 - val_mDice: 0.6185

Epoch 00021: val_mDice did not improve from 0.63722
Epoch 22/300
 - 17s - loss: 0.2699 - acc: 0.9549 - mDice: 0.7504 - val_loss: 0.4382 - val_acc: 0.9560 - val_mDice: 0.6351

Epoch 00022: val_mDice did not improve from 0.63722
Epoch 23/300
 - 17s - loss: 0.2669 - acc: 0.9551 - mDice: 0.7527 - val_loss: 0.4495 - val_acc: 0.9557 - val_mDice: 0.6278

Epoch 00023: val_mDice did not improve from 0.63722
Epoch 24/300
 - 16s - loss: 0.2658 - acc: 0.9552 - mDice: 0.7537 - val_loss: 0.4623 - val_acc: 0.9548 - val_mDice: 0.6203

Epoch 00024: val_mDice did not improve from 0.63722
Epoch 25/300
 - 17s - loss: 0.2629 - acc: 0.9554 - mDice: 0.7560 - val_loss: 0.4516 - val_acc: 0.9556 - val_mDice: 0.6272

Epoch 00025: val_mDice did not improve from 0.63722
Epoch 26/300
 - 17s - loss: 0.2613 - acc: 0.9556 - mDice: 0.7572 - val_loss: 0.4781 - val_acc: 0.9555 - val_mDice: 0.6145

Epoch 00026: val_mDice did not improve from 0.63722
Epoch 27/300
 - 17s - loss: 0.2586 - acc: 0.9558 - mDice: 0.7592 - val_loss: 0.4387 - val_acc: 0.9564 - val_mDice: 0.6355

Epoch 00027: val_mDice did not improve from 0.63722
Epoch 28/300
 - 17s - loss: 0.2574 - acc: 0.9558 - mDice: 0.7602 - val_loss: 0.4553 - val_acc: 0.9561 - val_mDice: 0.6268

Epoch 00028: val_mDice did not improve from 0.63722
Epoch 29/300
 - 17s - loss: 0.2558 - acc: 0.9559 - mDice: 0.7615 - val_loss: 0.4517 - val_acc: 0.9558 - val_mDice: 0.6288

Epoch 00029: val_mDice did not improve from 0.63722
Epoch 30/300
 - 16s - loss: 0.2538 - acc: 0.9560 - mDice: 0.7631 - val_loss: 0.4494 - val_acc: 0.9532 - val_mDice: 0.6288

Epoch 00030: val_mDice did not improve from 0.63722
Epoch 31/300
 - 17s - loss: 0.2535 - acc: 0.9561 - mDice: 0.7633 - val_loss: 0.4410 - val_acc: 0.9551 - val_mDice: 0.6335

Epoch 00031: val_mDice did not improve from 0.63722
Epoch 32/300
 - 17s - loss: 0.2513 - acc: 0.9562 - mDice: 0.7651 - val_loss: 0.4678 - val_acc: 0.9553 - val_mDice: 0.6229

Epoch 00032: val_mDice did not improve from 0.63722
Epoch 33/300
 - 17s - loss: 0.2506 - acc: 0.9563 - mDice: 0.7656 - val_loss: 0.4703 - val_acc: 0.9553 - val_mDice: 0.6189

Epoch 00033: val_mDice did not improve from 0.63722
Epoch 34/300
 - 17s - loss: 0.2495 - acc: 0.9564 - mDice: 0.7666 - val_loss: 0.4431 - val_acc: 0.9566 - val_mDice: 0.6341

Epoch 00034: val_mDice did not improve from 0.63722
Epoch 35/300
 - 17s - loss: 0.2901 - acc: 0.9536 - mDice: 0.7386 - val_loss: 0.4592 - val_acc: 0.9517 - val_mDice: 0.6236

Epoch 00035: val_mDice did not improve from 0.63722
Epoch 36/300
 - 17s - loss: 0.2551 - acc: 0.9560 - mDice: 0.7621 - val_loss: 0.4637 - val_acc: 0.9551 - val_mDice: 0.6226

Epoch 00036: val_mDice did not improve from 0.63722
Epoch 37/300
 - 17s - loss: 0.2471 - acc: 0.9566 - mDice: 0.7684 - val_loss: 0.4406 - val_acc: 0.9553 - val_mDice: 0.6349

Epoch 00037: val_mDice did not improve from 0.63722
Epoch 38/300
 - 17s - loss: 0.2461 - acc: 0.9567 - mDice: 0.7693 - val_loss: 0.4422 - val_acc: 0.9559 - val_mDice: 0.6353

Epoch 00038: val_mDice did not improve from 0.63722
Epoch 39/300
 - 17s - loss: 0.2448 - acc: 0.9568 - mDice: 0.7703 - val_loss: 0.4451 - val_acc: 0.9545 - val_mDice: 0.6323

Epoch 00039: val_mDice did not improve from 0.63722
Epoch 40/300
 - 17s - loss: 0.2428 - acc: 0.9569 - mDice: 0.7719 - val_loss: 0.4629 - val_acc: 0.9555 - val_mDice: 0.6254

Epoch 00040: val_mDice did not improve from 0.63722
Epoch 41/300
 - 17s - loss: 0.2426 - acc: 0.9570 - mDice: 0.7720 - val_loss: 0.4435 - val_acc: 0.9563 - val_mDice: 0.6330

Epoch 00041: val_mDice did not improve from 0.63722
Epoch 42/300
 - 16s - loss: 0.2398 - acc: 0.9571 - mDice: 0.7743 - val_loss: 0.4525 - val_acc: 0.9558 - val_mDice: 0.6275

Epoch 00042: val_mDice did not improve from 0.63722
Epoch 43/300
 - 17s - loss: 0.2401 - acc: 0.9571 - mDice: 0.7741 - val_loss: 0.4457 - val_acc: 0.9525 - val_mDice: 0.6312

Epoch 00043: val_mDice did not improve from 0.63722
Epoch 44/300
 - 17s - loss: 0.2384 - acc: 0.9572 - mDice: 0.7755 - val_loss: 0.4550 - val_acc: 0.9543 - val_mDice: 0.6273

Epoch 00044: val_mDice did not improve from 0.63722
Epoch 45/300
 - 17s - loss: 0.2395 - acc: 0.9572 - mDice: 0.7747 - val_loss: 0.4366 - val_acc: 0.9560 - val_mDice: 0.6374

Epoch 00045: val_mDice improved from 0.63722 to 0.63736, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 46/300
 - 18s - loss: 0.2365 - acc: 0.9574 - mDice: 0.7770 - val_loss: 0.4572 - val_acc: 0.9550 - val_mDice: 0.6265

Epoch 00046: val_mDice did not improve from 0.63736
Epoch 47/300
 - 17s - loss: 0.2365 - acc: 0.9574 - mDice: 0.7771 - val_loss: 0.4491 - val_acc: 0.9560 - val_mDice: 0.6310

Epoch 00047: val_mDice did not improve from 0.63736
Epoch 48/300
 - 17s - loss: 0.2359 - acc: 0.9575 - mDice: 0.7776 - val_loss: 0.4485 - val_acc: 0.9543 - val_mDice: 0.6278

Epoch 00048: val_mDice did not improve from 0.63736
Epoch 49/300
 - 17s - loss: 0.2345 - acc: 0.9576 - mDice: 0.7787 - val_loss: 0.4566 - val_acc: 0.9563 - val_mDice: 0.6261

Epoch 00049: val_mDice did not improve from 0.63736
Epoch 50/300
 - 17s - loss: 0.2339 - acc: 0.9577 - mDice: 0.7792 - val_loss: 0.4594 - val_acc: 0.9559 - val_mDice: 0.6237

Epoch 00050: val_mDice did not improve from 0.63736
Epoch 51/300
 - 18s - loss: 0.2327 - acc: 0.9577 - mDice: 0.7802 - val_loss: 0.4522 - val_acc: 0.9556 - val_mDice: 0.6283

Epoch 00051: val_mDice did not improve from 0.63736
Epoch 52/300
 - 17s - loss: 0.2325 - acc: 0.9577 - mDice: 0.7803 - val_loss: 0.4538 - val_acc: 0.9552 - val_mDice: 0.6277

Epoch 00052: val_mDice did not improve from 0.63736
Epoch 53/300
 - 17s - loss: 0.2309 - acc: 0.9578 - mDice: 0.7817 - val_loss: 0.4410 - val_acc: 0.9553 - val_mDice: 0.6351

Epoch 00053: val_mDice did not improve from 0.63736
Epoch 54/300
 - 17s - loss: 0.2311 - acc: 0.9578 - mDice: 0.7815 - val_loss: 0.4496 - val_acc: 0.9565 - val_mDice: 0.6301

Epoch 00054: val_mDice did not improve from 0.63736
Epoch 55/300
 - 17s - loss: 0.2305 - acc: 0.9579 - mDice: 0.7819 - val_loss: 0.4576 - val_acc: 0.9555 - val_mDice: 0.6251

Epoch 00055: val_mDice did not improve from 0.63736
Epoch 56/300
 - 17s - loss: 0.2296 - acc: 0.9579 - mDice: 0.7827 - val_loss: 0.4578 - val_acc: 0.9545 - val_mDice: 0.6261

Epoch 00056: val_mDice did not improve from 0.63736
Epoch 57/300
 - 17s - loss: 0.2287 - acc: 0.9580 - mDice: 0.7835 - val_loss: 0.4740 - val_acc: 0.9560 - val_mDice: 0.6241

Epoch 00057: val_mDice did not improve from 0.63736
Epoch 58/300
 - 17s - loss: 0.2288 - acc: 0.9580 - mDice: 0.7834 - val_loss: 0.4617 - val_acc: 0.9549 - val_mDice: 0.6223

Epoch 00058: val_mDice did not improve from 0.63736
Epoch 59/300
 - 17s - loss: 0.2275 - acc: 0.9580 - mDice: 0.7844 - val_loss: 0.4471 - val_acc: 0.9546 - val_mDice: 0.6307

Epoch 00059: val_mDice did not improve from 0.63736
Epoch 60/300
 - 17s - loss: 0.2282 - acc: 0.9580 - mDice: 0.7839 - val_loss: 0.4585 - val_acc: 0.9559 - val_mDice: 0.6252

Epoch 00060: val_mDice did not improve from 0.63736
Epoch 61/300
 - 17s - loss: 0.2262 - acc: 0.9582 - mDice: 0.7855 - val_loss: 0.4652 - val_acc: 0.9567 - val_mDice: 0.6262

Epoch 00061: val_mDice did not improve from 0.63736
Epoch 62/300
 - 17s - loss: 0.2257 - acc: 0.9582 - mDice: 0.7859 - val_loss: 0.4598 - val_acc: 0.9534 - val_mDice: 0.6241

Epoch 00062: val_mDice did not improve from 0.63736
Epoch 63/300
 - 17s - loss: 0.2250 - acc: 0.9583 - mDice: 0.7865 - val_loss: 0.4548 - val_acc: 0.9557 - val_mDice: 0.6271

Epoch 00063: val_mDice did not improve from 0.63736
Epoch 64/300
 - 17s - loss: 0.2252 - acc: 0.9583 - mDice: 0.7863 - val_loss: 0.4436 - val_acc: 0.9562 - val_mDice: 0.6329

Epoch 00064: val_mDice did not improve from 0.63736
Epoch 65/300
 - 17s - loss: 0.2233 - acc: 0.9585 - mDice: 0.7879 - val_loss: 0.4610 - val_acc: 0.9566 - val_mDice: 0.6258

Epoch 00065: val_mDice did not improve from 0.63736
Epoch 66/300
 - 17s - loss: 0.2238 - acc: 0.9584 - mDice: 0.7875 - val_loss: 0.4455 - val_acc: 0.9560 - val_mDice: 0.6330

Epoch 00066: val_mDice did not improve from 0.63736
Epoch 67/300
 - 17s - loss: 0.2230 - acc: 0.9585 - mDice: 0.7882 - val_loss: 0.4661 - val_acc: 0.9554 - val_mDice: 0.6217

Epoch 00067: val_mDice did not improve from 0.63736
Epoch 68/300
 - 16s - loss: 0.2218 - acc: 0.9586 - mDice: 0.7891 - val_loss: 0.4636 - val_acc: 0.9565 - val_mDice: 0.6228

Epoch 00068: val_mDice did not improve from 0.63736
Epoch 69/300
 - 17s - loss: 0.2214 - acc: 0.9586 - mDice: 0.7895 - val_loss: 0.4701 - val_acc: 0.9563 - val_mDice: 0.6192

Epoch 00069: val_mDice did not improve from 0.63736
Epoch 70/300
 - 17s - loss: 0.2208 - acc: 0.9586 - mDice: 0.7899 - val_loss: 0.4610 - val_acc: 0.9574 - val_mDice: 0.6270

Epoch 00070: val_mDice did not improve from 0.63736
Epoch 71/300
 - 17s - loss: 0.2200 - acc: 0.9586 - mDice: 0.7906 - val_loss: 0.4505 - val_acc: 0.9558 - val_mDice: 0.6299

Epoch 00071: val_mDice did not improve from 0.63736
Epoch 72/300
 - 17s - loss: 0.2195 - acc: 0.9586 - mDice: 0.7910 - val_loss: 0.4585 - val_acc: 0.9559 - val_mDice: 0.6277

Epoch 00072: val_mDice did not improve from 0.63736
Epoch 73/300
 - 16s - loss: 0.2209 - acc: 0.9585 - mDice: 0.7899 - val_loss: 0.4644 - val_acc: 0.9557 - val_mDice: 0.6222

Epoch 00073: val_mDice did not improve from 0.63736
Epoch 74/300
 - 17s - loss: 0.2195 - acc: 0.9586 - mDice: 0.7910 - val_loss: 0.4405 - val_acc: 0.9563 - val_mDice: 0.6349

Epoch 00074: val_mDice did not improve from 0.63736
Epoch 75/300
 - 17s - loss: 0.2180 - acc: 0.9588 - mDice: 0.7923 - val_loss: 0.4625 - val_acc: 0.9559 - val_mDice: 0.6262

Epoch 00075: val_mDice did not improve from 0.63736
Epoch 76/300
 - 17s - loss: 0.2178 - acc: 0.9588 - mDice: 0.7924 - val_loss: 0.4380 - val_acc: 0.9557 - val_mDice: 0.6370

Epoch 00076: val_mDice did not improve from 0.63736
Epoch 77/300
 - 17s - loss: 0.2174 - acc: 0.9588 - mDice: 0.7927 - val_loss: 0.4491 - val_acc: 0.9548 - val_mDice: 0.6311

Epoch 00077: val_mDice did not improve from 0.63736
Epoch 78/300
 - 16s - loss: 0.2180 - acc: 0.9588 - mDice: 0.7923 - val_loss: 0.4366 - val_acc: 0.9560 - val_mDice: 0.6378

Epoch 00078: val_mDice improved from 0.63736 to 0.63783, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 79/300
 - 17s - loss: 0.2171 - acc: 0.9589 - mDice: 0.7929 - val_loss: 0.4473 - val_acc: 0.9556 - val_mDice: 0.6309

Epoch 00079: val_mDice did not improve from 0.63783
Epoch 80/300
 - 17s - loss: 0.2168 - acc: 0.9590 - mDice: 0.7933 - val_loss: 0.4572 - val_acc: 0.9558 - val_mDice: 0.6265

Epoch 00080: val_mDice did not improve from 0.63783
Epoch 81/300
 - 17s - loss: 0.2158 - acc: 0.9590 - mDice: 0.7941 - val_loss: 0.4502 - val_acc: 0.9557 - val_mDice: 0.6285

Epoch 00081: val_mDice did not improve from 0.63783
Epoch 82/300
 - 17s - loss: 0.2161 - acc: 0.9589 - mDice: 0.7939 - val_loss: 0.4560 - val_acc: 0.9555 - val_mDice: 0.6267

Epoch 00082: val_mDice did not improve from 0.63783
Epoch 83/300
 - 17s - loss: 0.2143 - acc: 0.9591 - mDice: 0.7953 - val_loss: 0.4510 - val_acc: 0.9556 - val_mDice: 0.6298

Epoch 00083: val_mDice did not improve from 0.63783
Epoch 84/300
 - 17s - loss: 0.2150 - acc: 0.9591 - mDice: 0.7949 - val_loss: 0.4682 - val_acc: 0.9559 - val_mDice: 0.6221

Epoch 00084: val_mDice did not improve from 0.63783
Epoch 85/300
 - 16s - loss: 0.2161 - acc: 0.9590 - mDice: 0.7939 - val_loss: 0.4537 - val_acc: 0.9569 - val_mDice: 0.6291

Epoch 00085: val_mDice did not improve from 0.63783
Epoch 86/300
 - 17s - loss: 0.2132 - acc: 0.9591 - mDice: 0.7963 - val_loss: 0.4469 - val_acc: 0.9550 - val_mDice: 0.6314

Epoch 00086: val_mDice did not improve from 0.63783
Epoch 87/300
 - 16s - loss: 0.2143 - acc: 0.9591 - mDice: 0.7954 - val_loss: 0.4495 - val_acc: 0.9543 - val_mDice: 0.6290

Epoch 00087: val_mDice did not improve from 0.63783
Epoch 88/300
 - 17s - loss: 0.2144 - acc: 0.9591 - mDice: 0.7953 - val_loss: 0.4618 - val_acc: 0.9569 - val_mDice: 0.6240

Epoch 00088: val_mDice did not improve from 0.63783
Epoch 89/300
 - 17s - loss: 0.2126 - acc: 0.9591 - mDice: 0.7968 - val_loss: 0.4380 - val_acc: 0.9556 - val_mDice: 0.6378

Epoch 00089: val_mDice did not improve from 0.63783
Epoch 90/300
 - 17s - loss: 0.2131 - acc: 0.9592 - mDice: 0.7964 - val_loss: 0.4528 - val_acc: 0.9562 - val_mDice: 0.6271

Epoch 00090: val_mDice did not improve from 0.63783
Epoch 91/300
 - 17s - loss: 0.2114 - acc: 0.9593 - mDice: 0.7978 - val_loss: 0.4598 - val_acc: 0.9563 - val_mDice: 0.6249

Epoch 00091: val_mDice did not improve from 0.63783
Epoch 92/300
 - 16s - loss: 0.2123 - acc: 0.9591 - mDice: 0.7970 - val_loss: 0.4514 - val_acc: 0.9556 - val_mDice: 0.6287

Epoch 00092: val_mDice did not improve from 0.63783
Epoch 93/300
 - 17s - loss: 0.2120 - acc: 0.9592 - mDice: 0.7973 - val_loss: 0.4371 - val_acc: 0.9572 - val_mDice: 0.6367

Epoch 00093: val_mDice did not improve from 0.63783
Epoch 94/300
 - 17s - loss: 0.2125 - acc: 0.9593 - mDice: 0.7970 - val_loss: 0.4377 - val_acc: 0.9569 - val_mDice: 0.6363

Epoch 00094: val_mDice did not improve from 0.63783
Epoch 95/300
 - 17s - loss: 0.2101 - acc: 0.9593 - mDice: 0.7989 - val_loss: 0.4521 - val_acc: 0.9565 - val_mDice: 0.6291

Epoch 00095: val_mDice did not improve from 0.63783
Epoch 96/300
 - 17s - loss: 0.2104 - acc: 0.9594 - mDice: 0.7986 - val_loss: 0.4363 - val_acc: 0.9551 - val_mDice: 0.6375

Epoch 00096: val_mDice did not improve from 0.63783
Epoch 97/300
 - 17s - loss: 0.2102 - acc: 0.9593 - mDice: 0.7988 - val_loss: 0.4298 - val_acc: 0.9568 - val_mDice: 0.6418

Epoch 00097: val_mDice improved from 0.63783 to 0.64176, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 98/300
 - 17s - loss: 0.2102 - acc: 0.9594 - mDice: 0.7989 - val_loss: 0.4427 - val_acc: 0.9564 - val_mDice: 0.6347

Epoch 00098: val_mDice did not improve from 0.64176
Epoch 99/300
 - 17s - loss: 0.2098 - acc: 0.9593 - mDice: 0.7991 - val_loss: 0.4463 - val_acc: 0.9550 - val_mDice: 0.6326

Epoch 00099: val_mDice did not improve from 0.64176
Epoch 100/300
 - 17s - loss: 0.2096 - acc: 0.9594 - mDice: 0.7993 - val_loss: 0.4428 - val_acc: 0.9558 - val_mDice: 0.6338

Epoch 00100: val_mDice did not improve from 0.64176
Epoch 101/300
 - 17s - loss: 0.2102 - acc: 0.9593 - mDice: 0.7989 - val_loss: 0.4512 - val_acc: 0.9561 - val_mDice: 0.6305

Epoch 00101: val_mDice did not improve from 0.64176
Epoch 102/300
 - 17s - loss: 0.2091 - acc: 0.9595 - mDice: 0.7997 - val_loss: 0.4758 - val_acc: 0.9553 - val_mDice: 0.6185

Epoch 00102: val_mDice did not improve from 0.64176
Epoch 103/300
 - 17s - loss: 0.2082 - acc: 0.9595 - mDice: 0.8004 - val_loss: 0.4577 - val_acc: 0.9545 - val_mDice: 0.6256

Epoch 00103: val_mDice did not improve from 0.64176
Epoch 104/300
 - 17s - loss: 0.2085 - acc: 0.9595 - mDice: 0.8003 - val_loss: 0.4605 - val_acc: 0.9547 - val_mDice: 0.6232

Epoch 00104: val_mDice did not improve from 0.64176
Epoch 105/300
 - 17s - loss: 0.2079 - acc: 0.9595 - mDice: 0.8008 - val_loss: 0.4491 - val_acc: 0.9565 - val_mDice: 0.6323

Epoch 00105: val_mDice did not improve from 0.64176
Epoch 106/300
 - 17s - loss: 0.2071 - acc: 0.9597 - mDice: 0.8014 - val_loss: 0.4680 - val_acc: 0.9564 - val_mDice: 0.6221

Epoch 00106: val_mDice did not improve from 0.64176
Epoch 107/300
 - 17s - loss: 0.2084 - acc: 0.9595 - mDice: 0.8003 - val_loss: 0.4589 - val_acc: 0.9565 - val_mDice: 0.6258

Epoch 00107: val_mDice did not improve from 0.64176
Epoch 108/300
 - 17s - loss: 0.2070 - acc: 0.9596 - mDice: 0.8015 - val_loss: 0.4666 - val_acc: 0.9559 - val_mDice: 0.6227

Epoch 00108: val_mDice did not improve from 0.64176
Epoch 109/300
 - 16s - loss: 0.2068 - acc: 0.9596 - mDice: 0.8017 - val_loss: 0.4569 - val_acc: 0.9554 - val_mDice: 0.6267

Epoch 00109: val_mDice did not improve from 0.64176
Epoch 110/300
 - 18s - loss: 0.2078 - acc: 0.9596 - mDice: 0.8009 - val_loss: 0.4589 - val_acc: 0.9562 - val_mDice: 0.6264

Epoch 00110: val_mDice did not improve from 0.64176
Epoch 111/300
 - 17s - loss: 0.2065 - acc: 0.9597 - mDice: 0.8019 - val_loss: 0.4569 - val_acc: 0.9562 - val_mDice: 0.6267

Epoch 00111: val_mDice did not improve from 0.64176
Epoch 112/300
 - 17s - loss: 0.2075 - acc: 0.9597 - mDice: 0.8010 - val_loss: 0.4539 - val_acc: 0.9563 - val_mDice: 0.6298

Epoch 00112: val_mDice did not improve from 0.64176
Epoch 113/300
 - 16s - loss: 0.2060 - acc: 0.9597 - mDice: 0.8023 - val_loss: 0.4605 - val_acc: 0.9558 - val_mDice: 0.6232

Epoch 00113: val_mDice did not improve from 0.64176
Epoch 114/300
 - 18s - loss: 0.2066 - acc: 0.9597 - mDice: 0.8018 - val_loss: 0.4509 - val_acc: 0.9563 - val_mDice: 0.6305

Epoch 00114: val_mDice did not improve from 0.64176
Epoch 115/300
 - 17s - loss: 0.2060 - acc: 0.9597 - mDice: 0.8024 - val_loss: 0.4664 - val_acc: 0.9560 - val_mDice: 0.6232

Epoch 00115: val_mDice did not improve from 0.64176
Epoch 116/300
 - 17s - loss: 0.2051 - acc: 0.9598 - mDice: 0.8031 - val_loss: 0.4529 - val_acc: 0.9566 - val_mDice: 0.6289

Epoch 00116: val_mDice did not improve from 0.64176
Epoch 117/300
 - 17s - loss: 0.2052 - acc: 0.9598 - mDice: 0.8030 - val_loss: 0.4598 - val_acc: 0.9555 - val_mDice: 0.6243

Epoch 00117: val_mDice did not improve from 0.64176
Epoch 118/300
 - 17s - loss: 0.2049 - acc: 0.9598 - mDice: 0.8033 - val_loss: 0.4635 - val_acc: 0.9555 - val_mDice: 0.6236

Epoch 00118: val_mDice did not improve from 0.64176
Epoch 119/300
 - 17s - loss: 0.2052 - acc: 0.9598 - mDice: 0.8031 - val_loss: 0.4518 - val_acc: 0.9557 - val_mDice: 0.6281

Epoch 00119: val_mDice did not improve from 0.64176
Epoch 120/300
 - 17s - loss: 0.2045 - acc: 0.9599 - mDice: 0.8037 - val_loss: 0.4509 - val_acc: 0.9557 - val_mDice: 0.6309

Epoch 00120: val_mDice did not improve from 0.64176
Epoch 121/300
 - 17s - loss: 0.2051 - acc: 0.9598 - mDice: 0.8031 - val_loss: 0.4744 - val_acc: 0.9558 - val_mDice: 0.6180

Epoch 00121: val_mDice did not improve from 0.64176
Epoch 122/300
 - 17s - loss: 0.2060 - acc: 0.9597 - mDice: 0.8025 - val_loss: 0.4694 - val_acc: 0.9551 - val_mDice: 0.6180

Epoch 00122: val_mDice did not improve from 0.64176
Epoch 123/300
 - 16s - loss: 0.2036 - acc: 0.9600 - mDice: 0.8045 - val_loss: 0.4379 - val_acc: 0.9559 - val_mDice: 0.6369

Epoch 00123: val_mDice did not improve from 0.64176
Epoch 124/300
 - 17s - loss: 0.2043 - acc: 0.9599 - mDice: 0.8039 - val_loss: 0.5008 - val_acc: 0.9564 - val_mDice: 0.6096

Epoch 00124: val_mDice did not improve from 0.64176
Epoch 125/300
 - 17s - loss: 0.2045 - acc: 0.9598 - mDice: 0.8036 - val_loss: 0.4641 - val_acc: 0.9570 - val_mDice: 0.6226

Epoch 00125: val_mDice did not improve from 0.64176
Epoch 126/300
 - 16s - loss: 0.2031 - acc: 0.9599 - mDice: 0.8048 - val_loss: 0.4684 - val_acc: 0.9559 - val_mDice: 0.6209

Epoch 00126: val_mDice did not improve from 0.64176
Epoch 127/300
 - 17s - loss: 0.2029 - acc: 0.9599 - mDice: 0.8049 - val_loss: 0.4509 - val_acc: 0.9559 - val_mDice: 0.6297

Epoch 00127: val_mDice did not improve from 0.64176
Epoch 128/300
 - 17s - loss: 0.2034 - acc: 0.9599 - mDice: 0.8046 - val_loss: 0.4558 - val_acc: 0.9561 - val_mDice: 0.6256

Epoch 00128: val_mDice did not improve from 0.64176
Epoch 129/300
 - 16s - loss: 0.2026 - acc: 0.9600 - mDice: 0.8053 - val_loss: 0.4674 - val_acc: 0.9561 - val_mDice: 0.6181

Epoch 00129: val_mDice did not improve from 0.64176
Epoch 130/300
 - 17s - loss: 0.2022 - acc: 0.9600 - mDice: 0.8055 - val_loss: 0.4650 - val_acc: 0.9551 - val_mDice: 0.6207

Epoch 00130: val_mDice did not improve from 0.64176
Epoch 131/300
 - 17s - loss: 0.2012 - acc: 0.9601 - mDice: 0.8064 - val_loss: 0.4631 - val_acc: 0.9560 - val_mDice: 0.6214

Epoch 00131: val_mDice did not improve from 0.64176
Epoch 132/300
 - 16s - loss: 0.2025 - acc: 0.9600 - mDice: 0.8053 - val_loss: 0.4523 - val_acc: 0.9545 - val_mDice: 0.6297

Epoch 00132: val_mDice did not improve from 0.64176
Epoch 133/300
 - 17s - loss: 0.2014 - acc: 0.9601 - mDice: 0.8063 - val_loss: 0.4671 - val_acc: 0.9546 - val_mDice: 0.6231

Epoch 00133: val_mDice did not improve from 0.64176
Epoch 134/300
 - 17s - loss: 0.2021 - acc: 0.9600 - mDice: 0.8056 - val_loss: 0.4858 - val_acc: 0.9559 - val_mDice: 0.6113

Epoch 00134: val_mDice did not improve from 0.64176
Epoch 135/300
 - 17s - loss: 0.2029 - acc: 0.9600 - mDice: 0.8050 - val_loss: 0.4372 - val_acc: 0.9555 - val_mDice: 0.6377

Epoch 00135: val_mDice did not improve from 0.64176
Epoch 136/300
 - 17s - loss: 0.2005 - acc: 0.9601 - mDice: 0.8071 - val_loss: 0.4471 - val_acc: 0.9572 - val_mDice: 0.6326

Epoch 00136: val_mDice did not improve from 0.64176
Epoch 137/300
 - 18s - loss: 0.2000 - acc: 0.9602 - mDice: 0.8075 - val_loss: 0.4564 - val_acc: 0.9556 - val_mDice: 0.6283

Epoch 00137: val_mDice did not improve from 0.64176
Restoring model weights from the end of the best epoch
Epoch 00137: early stopping
{'val_loss': [0.7313033552143161, 0.4870891411211238, 0.4771955812443568, 0.4421196140390535, 0.4458446486036205, 0.45181050047528143, 0.4546139496664761, 0.4451864837934185, 0.44999844501804376, 0.4350782246563022, 0.45181771097236506, 0.48183483318243614, 0.44925750833649875, 0.47061391116520546, 0.43814936396795945, 0.45895918521135215, 0.4639749896592934, 0.47537739849623356, 0.4351475115594917, 0.4403825671979169, 0.4676325054808036, 0.4381742687198703, 0.4494656870485018, 0.4623106957813881, 0.4516127818789562, 0.47805311027185876, 0.438705988103451, 0.45530887122926766, 0.4516526207577583, 0.4493883671707281, 0.4410226501566072, 0.46778837695468073, 0.4703341988877877, 0.4430527727031175, 0.45921752173141395, 0.46369329477821647, 0.44064716187269326, 0.4422186513186833, 0.4450650901101821, 0.46287167305386934, 0.4435322987300724, 0.45252374264115064, 0.4457007040524616, 0.45502463632455753, 0.43662506974609205, 0.4572018568076235, 0.44910869018991567, 0.44852115022403566, 0.45660726884223896, 0.45938990136098595, 0.4522184110220584, 0.45377622802830275, 0.44104453305292396, 0.44959813656087694, 0.45764265613182964, 0.45781190968092594, 0.4740267109604521, 0.46169169688357986, 0.4471331621681512, 0.4584576151224488, 0.46515465948168794, 0.45984366819179257, 0.45478350057282263, 0.4435984475652599, 0.46098692989882145, 0.44546970974799643, 0.466075455676244, 0.46355272604766506, 0.4700597794362287, 0.46102991084146766, 0.4505215750060268, 0.458528421111613, 0.4644131167640899, 0.4404672767196954, 0.4624582039577335, 0.43803901978711174, 0.44911784200029, 0.43662877955250234, 0.447325684504802, 0.4571855584336393, 0.4502307199899045, 0.4559871657600616, 0.4510128834394103, 0.4681862679273723, 0.453681376060294, 0.44692955569848003, 0.4495402228232869, 0.4618169149207003, 0.43799954519591516, 0.4528268905325309, 0.45975381735316867, 0.45143708303653995, 0.4371101782974584, 0.43774989164075373, 0.45211823292950676, 0.436264117336806, 0.4298211549247443, 0.4427447172516551, 0.44632165425316583, 0.4427567613857418, 0.4511624081840728, 0.4758240976813119, 0.45767721184139143, 0.46048210686145546, 0.44911614809622313, 0.46797477932615655, 0.4589469106503705, 0.4665879374109833, 0.4569363996969255, 0.4588873333105162, 0.45694827533967003, 0.4539177680814732, 0.4604773654618077, 0.4508705588692393, 0.46636198386133715, 0.45287335818040303, 0.45983228770048257, 0.46348962470805843, 0.45177981540477474, 0.45091258846847704, 0.47435859794723256, 0.46937332972467943, 0.4379066841562367, 0.5007613657573082, 0.46408940826714373, 0.46837742934679855, 0.4508541689238735, 0.455778684030032, 0.4673672994421847, 0.4650314137256345, 0.46310021357829345, 0.45225666455050423, 0.4671327291920198, 0.4857884525586773, 0.4371892703312069, 0.44712543687340933, 0.4564118272099415], 'val_acc': [0.9403759427576758, 0.9502991584426198, 0.9524437052577568, 0.9546048318207597, 0.9536977876498046, 0.9531627217484586, 0.9509479113797236, 0.9558403079070192, 0.9541730014971515, 0.9560303814584317, 0.9551337351346149, 0.955433287101085, 0.9543610105301414, 0.9544374556514804, 0.9562411005270548, 0.9567741568528074, 0.9546275488491165, 0.9531544297101111, 0.955427095210752, 0.9559828475866904, 0.9534560828235562, 0.9560055885900999, 0.955675028555886, 0.9548052169757182, 0.9555510379082663, 0.9555428014787216, 0.9563815833470009, 0.9561006260317797, 0.9558093151566702, 0.9531957650317826, 0.9550882767698619, 0.9552618045380662, 0.9553010899927363, 0.9566150730548624, 0.9517123292944285, 0.9550675833025458, 0.9552845268942124, 0.9558795640588472, 0.9545283767098155, 0.9554973307934553, 0.9562658920634393, 0.9557865824779319, 0.9525470274120735, 0.9542597871918918, 0.9560014452348208, 0.9549601690729237, 0.9559704601431692, 0.9542845627449078, 0.9563216760171859, 0.9559250087711398, 0.9555593206229822, 0.9551750198422864, 0.9553134514632837, 0.9565345102182313, 0.9555221166690635, 0.9545221561826142, 0.9560014445688472, 0.9549457024595591, 0.9545738317447001, 0.9559105491504989, 0.9566832464500512, 0.9534189061745585, 0.9557163435653602, 0.9561997685352517, 0.9566398429471021, 0.9560241772475855, 0.9553568453096145, 0.9564560025763911, 0.9562679728982169, 0.957418760440869, 0.9558175838859387, 0.9559250011124425, 0.9557142670594114, 0.956325814710649, 0.9558589142128076, 0.9557225178073905, 0.9548176047522262, 0.9560056019095735, 0.9555758494238614, 0.9558485559911035, 0.95565846778827, 0.9555324569094781, 0.9556047736599459, 0.9558527033422246, 0.9569435922127196, 0.9550159373762888, 0.9543114114740041, 0.9569084424546311, 0.9556151055756894, 0.9562307769359824, 0.9562989749721975, 0.9556275166612763, 0.9572100802506814, 0.9568526811439898, 0.956482828995369, 0.9551171930142621, 0.9568485301300134, 0.9564332662347975, 0.9550076799685728, 0.9557762505621884, 0.956121266221201, 0.9553341096339945, 0.9545345602754775, 0.9547019151335988, 0.9565014522834863, 0.9563857320300694, 0.9564766557522992, 0.9559022674347435, 0.9554312435608336, 0.9562163056608018, 0.9562452502090838, 0.9563340897666676, 0.9558155070470032, 0.9563010461503567, 0.9559766556963575, 0.956588214003174, 0.9555221406441161, 0.9555489767197124, 0.9557493885136183, 0.9557060246361034, 0.9558175885477546, 0.9550944753199316, 0.9559353403538965, 0.956383697147476, 0.9569621585600869, 0.9559456686067848, 0.9558712776812761, 0.9561378209950537, 0.9561440248729131, 0.9550799990499486, 0.9559849317513365, 0.9545201089795076, 0.9546068933423005, 0.9559146835151331, 0.9554870245176986, 0.9572183669612394, 0.9555613771497204], 'val_mDice': [0.48563124447561506, 0.6049506904026649, 0.6106861946303085, 0.6320057105085704, 0.6290544777609116, 0.6244110541636717, 0.6254316628312265, 0.6316860261576136, 0.6273282683095452, 0.6372160342152559, 0.6280861620130486, 0.6153044394274664, 0.6304775666258189, 0.6177171738454084, 0.6347870806741981, 0.6252789860331146, 0.6219835860769176, 0.6122934858226243, 0.6366445288977809, 0.6349780799290321, 0.6184525949328972, 0.635107841571616, 0.6277606513913118, 0.6203350491363909, 0.6271833747458857, 0.6145098668902946, 0.6355479922374534, 0.6268400060397953, 0.6287751510822573, 0.6288499219457531, 0.633476214701903, 0.6228817541506038, 0.6189101594786405, 0.6341298339087204, 0.6236339834149324, 0.6226326297115348, 0.634862723297247, 0.6352620371227158, 0.632330494886004, 0.6254400291256399, 0.6330222976940304, 0.6274573486610497, 0.6311762006589154, 0.6272748618818528, 0.6373627472190218, 0.6265069276260931, 0.6310149328002717, 0.6277608192166803, 0.6260710501804032, 0.6237067293854399, 0.6283261789289932, 0.6276895913331868, 0.6350883721639324, 0.6300678939126724, 0.6251367576961411, 0.6260693129880468, 0.6241039693688547, 0.6223310095637871, 0.6306776341113298, 0.6252459121150011, 0.6262107321669935, 0.6240992582710095, 0.6271164357329214, 0.6329452445387175, 0.6257967502711206, 0.6330267660444675, 0.6216643652436453, 0.6228072503425556, 0.6192266494868188, 0.6270037396660064, 0.6298663289853315, 0.6276509488761092, 0.6221663152705358, 0.6348511859691343, 0.6262466794285695, 0.6369645732075142, 0.6310683325682273, 0.6378325330478519, 0.6308713865013762, 0.62646335263492, 0.6285311836104154, 0.6267028564181407, 0.6297582794168142, 0.622060190698954, 0.6290725482908707, 0.631394694304333, 0.6290024432390096, 0.6239584055026817, 0.6377574265336191, 0.6270803426231086, 0.6249186899408948, 0.6287416559357882, 0.63665047970564, 0.636272816684659, 0.6290501432711851, 0.6375481546258127, 0.6417581232566407, 0.6346795752061812, 0.6325922018988839, 0.6337671086774858, 0.630506119914561, 0.6185235364477062, 0.6255932113977783, 0.6231537534537928, 0.6323113528043864, 0.6221238934127978, 0.6258336019249602, 0.6226899397439797, 0.6266970328112554, 0.6264478384449496, 0.6266576900828484, 0.6298282419503068, 0.6232052615234972, 0.6304818481706375, 0.6232008241408364, 0.6288647262077758, 0.6243345058164117, 0.6236205104343052, 0.6280972950951347, 0.6309004802277635, 0.618006957642859, 0.6179535735252849, 0.6368526203672313, 0.6095663109305185, 0.622550894095245, 0.6209340575021073, 0.62965426098701, 0.6256342200593575, 0.6181210565833406, 0.6207309062254496, 0.6213966115226959, 0.6297028098026467, 0.6231164309565581, 0.6112798312522846, 0.6376514574668927, 0.6325642862799448, 0.6282516924362609], 'loss': [1.8310906297890075, 0.5208964488418798, 0.42402957364479366, 0.3880936946476618, 0.3656173586215623, 0.3528644728651494, 0.3402859370038177, 0.3286501046447256, 0.320452056458739, 0.3145567954875345, 0.30758802229254006, 0.3036602520259674, 0.29651720658164615, 0.29259262179557055, 0.28789129007434633, 0.2865351527194027, 0.28120194060546266, 0.3052019775790279, 0.28849409569238865, 0.27688420571524375, 0.27295926497799466, 0.2699474607974276, 0.26689945439790874, 0.2658389656104577, 0.2628518431789572, 0.2612913688454556, 0.2585985206709105, 0.2573888541796934, 0.2558297208695427, 0.25377894585691346, 0.2535414389771292, 0.2513104422449786, 0.2506123293534284, 0.24950663894325628, 0.29012098715109386, 0.25507608792645614, 0.2471157214420955, 0.24610374607971555, 0.24483371422000716, 0.24280546521427623, 0.242639737822029, 0.23983672876486195, 0.24005316990853187, 0.2383650476144917, 0.23948155221716524, 0.23649459955794352, 0.2365224677013303, 0.23591074407876533, 0.23448550877088842, 0.23390960411259074, 0.23267227946660154, 0.23254179145884563, 0.23088832684565289, 0.23106258288800902, 0.23046569470927888, 0.2295712412611266, 0.2286561161472831, 0.2287809576586203, 0.22748806472080713, 0.22819184235683498, 0.22618000909388244, 0.22567402124956773, 0.22500559965332287, 0.22522562215851644, 0.22330475232679206, 0.22381461859658344, 0.22299988986678285, 0.22182603857822522, 0.2213904463279404, 0.2208248696335455, 0.2199631339470342, 0.2194908565701265, 0.22092212187338808, 0.21946220737248684, 0.21796207395418493, 0.2178256216318829, 0.21740640328166258, 0.21798545593666385, 0.21714745597066484, 0.2168055672090393, 0.2157594917643259, 0.21610124682615306, 0.214349649408714, 0.2150106232299452, 0.2161475142101779, 0.21324680210536268, 0.21428255304182078, 0.21439008620233813, 0.2125681897850638, 0.21309876433921063, 0.21140131823011268, 0.21230638532147456, 0.21198968693105155, 0.21246596570433332, 0.21005826331315935, 0.21043635285969983, 0.21024666578721898, 0.21017811167919262, 0.20983080954101374, 0.20958509285750196, 0.21024840115205595, 0.2091289922415668, 0.20822829109223526, 0.2085068910359609, 0.2079019669233782, 0.2070715635175779, 0.20844129160152894, 0.2069591297805845, 0.206757491962218, 0.20777394548752398, 0.20652256502359692, 0.20754756637144423, 0.20596382485145798, 0.20663157206242344, 0.2059554020141206, 0.20514617197430216, 0.20521918563280261, 0.20489332023645873, 0.20520801381973663, 0.2044881812761074, 0.20513116943067497, 0.20602844371952644, 0.20360382777511876, 0.20427750879386875, 0.20449867935233512, 0.20310432493871713, 0.2029315718530758, 0.20338631972421403, 0.20256816920459703, 0.2022488000855701, 0.201233650383058, 0.20247391784485244, 0.20138108283792613, 0.20214772453774787, 0.20292597746730248, 0.20045458536334795, 0.1999702227819421], 'acc': [0.7304333891167918, 0.9322776098921631, 0.9422867086891853, 0.9455560315837593, 0.9474856719057334, 0.9486300441364494, 0.9495487894233318, 0.9505253217622973, 0.9511209723054892, 0.9516273369022227, 0.9520408841793745, 0.9524381020919513, 0.9529340532108964, 0.9532669147247388, 0.95357848594381, 0.9536555284287999, 0.9541494017280749, 0.952349840325407, 0.9534765052273411, 0.9544180728506078, 0.9547069881692262, 0.9549145876475068, 0.9551443241434766, 0.9551727654926009, 0.9554196197374617, 0.955579347414659, 0.9557760905046933, 0.9558074723128355, 0.9559338600454647, 0.9560211952017917, 0.9561207590166256, 0.9562353631859414, 0.9563061442745776, 0.9564067720815017, 0.9535743550961849, 0.9560313275823743, 0.9565777716134916, 0.9567485751815367, 0.956789000378696, 0.9569229016272333, 0.9569732764533231, 0.957134046499249, 0.9571487305600764, 0.9572352767120512, 0.9572022462045696, 0.9574357509729903, 0.9574210470774926, 0.9575388771692566, 0.9575606106666495, 0.9576861740950567, 0.9576990825601032, 0.9577249256972816, 0.9577569509992594, 0.9578037205120816, 0.9579081151176528, 0.9578947020631413, 0.9579981063440808, 0.9579734549589403, 0.9580117837710485, 0.9580217542117746, 0.9581671369490647, 0.9582293138584016, 0.9583159214296825, 0.9582520557783455, 0.9584569133358397, 0.9583670619681837, 0.9585278976016182, 0.9585785128330004, 0.9585821155687347, 0.958568322104077, 0.9585860462777204, 0.9586300530547144, 0.9585471740443425, 0.9586406069853409, 0.9587831924790216, 0.9587543294013089, 0.9588286304978996, 0.9587901823466513, 0.9588940728626819, 0.9589961312654836, 0.9589809029166342, 0.9588884956910325, 0.9590875336069614, 0.9590585296673814, 0.959006646393522, 0.9591089437797525, 0.95907133853057, 0.9590754915436825, 0.9591488259744101, 0.9592390011276375, 0.9592937459211244, 0.959147073904301, 0.9592049391231637, 0.9593048458343224, 0.959345894492625, 0.9593745746855888, 0.9593391838718308, 0.9593696178099759, 0.9593273194570777, 0.9593691170738256, 0.9593478044350223, 0.9594709938546748, 0.9594718787309281, 0.9595073680980007, 0.9595378041397246, 0.9596701921035596, 0.9595283149673064, 0.959626846593694, 0.9596225985072614, 0.9596361540857272, 0.9597300965180487, 0.959651100577745, 0.9597344854338861, 0.9596714029046719, 0.9596808108263601, 0.9597661876547318, 0.9597626245818454, 0.9598066352965571, 0.9597914668185461, 0.9598808771748083, 0.959819788036442, 0.9597212740307728, 0.9599552594929127, 0.9598903816663442, 0.9598212791718881, 0.9599273630843094, 0.9599420661098083, 0.9598951596208961, 0.9600163518223561, 0.9600263830363819, 0.9600685365929413, 0.9600392915825848, 0.9600965147521993, 0.960036589701213, 0.9600262792176277, 0.9601264448767362, 0.9602249592589719], 'mDice': [0.26019669591448846, 0.580239352898935, 0.6402171730547194, 0.6643700601163691, 0.679894789719814, 0.6889882461287528, 0.6978058210937723, 0.7062017043414287, 0.7121175158699706, 0.7165507960505205, 0.721595745471417, 0.724891474496162, 0.7300480119179981, 0.7330025939028297, 0.7364272488227669, 0.7376622181073506, 0.7416947641947139, 0.7254083444983745, 0.7359964753228279, 0.7449693084801927, 0.748226713763493, 0.7504413834773055, 0.7527201928660524, 0.7536650489802507, 0.7560051498469701, 0.757228432732154, 0.7592191866985379, 0.7602278438926451, 0.7615414772098097, 0.7630585381053813, 0.7633380859897103, 0.7651003340504592, 0.7656421920169082, 0.7665965027275717, 0.738569432039626, 0.7621398142470844, 0.7684006404009307, 0.76927629649967, 0.7703480338077713, 0.7718921379679189, 0.7720216831008656, 0.7742894015101317, 0.774149026527143, 0.7754752862025603, 0.774665910205864, 0.7770369126187594, 0.7770695155089304, 0.7775715457660091, 0.7786652975550898, 0.7792376836240502, 0.7801907595144976, 0.7802626407131521, 0.781672682795128, 0.7814806037839672, 0.7819136444970833, 0.7827105797244134, 0.7835166437921555, 0.7833725100774844, 0.7843624446251951, 0.7838733082184844, 0.7855004273879684, 0.7859464154563681, 0.7864743723445232, 0.7862748220383579, 0.7879122106651486, 0.7874661617682628, 0.7881733788545924, 0.7891275375492269, 0.7894799799046792, 0.7899068733048812, 0.7906452802932378, 0.7910373740047939, 0.7898860900310265, 0.7910283863346442, 0.7923003370891333, 0.792435332685571, 0.7927358747372654, 0.792327285475165, 0.7929476571137606, 0.7933294206693745, 0.794099945322399, 0.7939005254997965, 0.7953165945459585, 0.7948798194189203, 0.7938732380317997, 0.7962549979679855, 0.7953791135660243, 0.7952860945073954, 0.7967954428424101, 0.7963775410370905, 0.7977934564440918, 0.7970399892276282, 0.797286474310646, 0.7969545495126393, 0.7988790870199769, 0.7985958640601769, 0.7987786516288313, 0.7988610802233839, 0.7991159675324004, 0.799331911839494, 0.7988907192424844, 0.7997019733811807, 0.8004456472600716, 0.8002979444409565, 0.800751889513557, 0.8014022685475004, 0.8002656609571471, 0.8015369899775051, 0.8017185773246202, 0.8009039375797725, 0.8019105696897609, 0.8010478976550532, 0.802331782330044, 0.8018438371819392, 0.8024136593909145, 0.8031205124380049, 0.8030153748438669, 0.8032801183283793, 0.8030526621637375, 0.8036604966806188, 0.8031493916918487, 0.8024685096782275, 0.8044610865968848, 0.803884173366708, 0.8036248691168612, 0.8048300470611666, 0.8049422249828546, 0.8045693411980831, 0.8052971885294042, 0.8055174877542172, 0.8064318975749913, 0.8053394705633355, 0.8063071541235368, 0.8056262085837844, 0.8050176186419009, 0.8070639107139157, 0.8075351165398086]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:03<00:06,  3.01s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.63s/it]predicting test subjects: 100%|██████████| 3/3 [00:06<00:00,  2.31s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:56,  2.10s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:14,  1.96s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:17,  1.98s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:54,  1.90s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:28,  2.03s/it]predicting train subjects:   2%|▏         | 6/285 [00:11<09:21,  2.01s/it]predicting train subjects:   2%|▏         | 7/285 [00:13<09:35,  2.07s/it]predicting train subjects:   3%|▎         | 8/285 [00:15<09:25,  2.04s/it]predicting train subjects:   3%|▎         | 9/285 [00:18<09:44,  2.12s/it]predicting train subjects:   4%|▎         | 10/285 [00:21<10:35,  2.31s/it]predicting train subjects:   4%|▍         | 11/285 [00:23<10:10,  2.23s/it]predicting train subjects:   4%|▍         | 12/285 [00:25<10:28,  2.30s/it]predicting train subjects:   5%|▍         | 13/285 [00:27<09:52,  2.18s/it]predicting train subjects:   5%|▍         | 14/285 [00:29<10:12,  2.26s/it]predicting train subjects:   5%|▌         | 15/285 [00:32<10:31,  2.34s/it]predicting train subjects:   6%|▌         | 16/285 [00:34<10:43,  2.39s/it]predicting train subjects:   6%|▌         | 17/285 [00:36<10:16,  2.30s/it]predicting train subjects:   6%|▋         | 18/285 [00:39<10:14,  2.30s/it]predicting train subjects:   7%|▋         | 19/285 [00:41<10:02,  2.26s/it]predicting train subjects:   7%|▋         | 20/285 [00:43<10:06,  2.29s/it]predicting train subjects:   7%|▋         | 21/285 [00:46<10:13,  2.32s/it]predicting train subjects:   8%|▊         | 22/285 [00:48<09:53,  2.26s/it]predicting train subjects:   8%|▊         | 23/285 [00:50<09:54,  2.27s/it]predicting train subjects:   8%|▊         | 24/285 [00:52<09:09,  2.11s/it]predicting train subjects:   9%|▉         | 25/285 [00:54<09:37,  2.22s/it]predicting train subjects:   9%|▉         | 26/285 [00:57<10:13,  2.37s/it]predicting train subjects:   9%|▉         | 27/285 [00:59<09:35,  2.23s/it]predicting train subjects:  10%|▉         | 28/285 [01:01<09:29,  2.22s/it]predicting train subjects:  10%|█         | 29/285 [01:03<09:36,  2.25s/it]predicting train subjects:  11%|█         | 30/285 [01:06<09:51,  2.32s/it]predicting train subjects:  11%|█         | 31/285 [01:08<09:51,  2.33s/it]predicting train subjects:  11%|█         | 32/285 [01:10<09:12,  2.18s/it]predicting train subjects:  12%|█▏        | 33/285 [01:12<09:11,  2.19s/it]predicting train subjects:  12%|█▏        | 34/285 [01:14<08:59,  2.15s/it]predicting train subjects:  12%|█▏        | 35/285 [01:17<09:00,  2.16s/it]predicting train subjects:  13%|█▎        | 36/285 [01:18<08:36,  2.07s/it]predicting train subjects:  13%|█▎        | 37/285 [01:21<08:33,  2.07s/it]predicting train subjects:  13%|█▎        | 38/285 [01:23<08:51,  2.15s/it]predicting train subjects:  14%|█▎        | 39/285 [01:25<08:39,  2.11s/it]predicting train subjects:  14%|█▍        | 40/285 [01:27<08:31,  2.09s/it]predicting train subjects:  14%|█▍        | 41/285 [01:29<08:14,  2.03s/it]predicting train subjects:  15%|█▍        | 42/285 [01:31<08:00,  1.98s/it]predicting train subjects:  15%|█▌        | 43/285 [01:33<08:03,  2.00s/it]predicting train subjects:  15%|█▌        | 44/285 [01:35<08:34,  2.14s/it]predicting train subjects:  16%|█▌        | 45/285 [01:37<08:08,  2.04s/it]predicting train subjects:  16%|█▌        | 46/285 [01:39<08:25,  2.11s/it]predicting train subjects:  16%|█▋        | 47/285 [01:41<08:03,  2.03s/it]predicting train subjects:  17%|█▋        | 48/285 [01:43<08:02,  2.04s/it]predicting train subjects:  17%|█▋        | 49/285 [01:45<08:14,  2.09s/it]predicting train subjects:  18%|█▊        | 50/285 [01:47<08:07,  2.08s/it]predicting train subjects:  18%|█▊        | 51/285 [01:50<08:25,  2.16s/it]predicting train subjects:  18%|█▊        | 52/285 [01:52<08:09,  2.10s/it]predicting train subjects:  19%|█▊        | 53/285 [01:54<08:16,  2.14s/it]predicting train subjects:  19%|█▉        | 54/285 [01:56<08:36,  2.24s/it]predicting train subjects:  19%|█▉        | 55/285 [01:58<08:11,  2.14s/it]predicting train subjects:  20%|█▉        | 56/285 [02:01<08:17,  2.17s/it]predicting train subjects:  20%|██        | 57/285 [02:02<07:48,  2.06s/it]predicting train subjects:  20%|██        | 58/285 [02:04<07:44,  2.05s/it]predicting train subjects:  21%|██        | 59/285 [02:07<07:47,  2.07s/it]predicting train subjects:  21%|██        | 60/285 [02:09<08:01,  2.14s/it]predicting train subjects:  21%|██▏       | 61/285 [02:11<07:41,  2.06s/it]predicting train subjects:  22%|██▏       | 62/285 [02:13<07:38,  2.05s/it]predicting train subjects:  22%|██▏       | 63/285 [02:15<07:30,  2.03s/it]predicting train subjects:  22%|██▏       | 64/285 [02:16<07:11,  1.95s/it]predicting train subjects:  23%|██▎       | 65/285 [02:19<07:25,  2.03s/it]predicting train subjects:  23%|██▎       | 66/285 [02:21<07:16,  1.99s/it]predicting train subjects:  24%|██▎       | 67/285 [02:23<07:15,  2.00s/it]predicting train subjects:  24%|██▍       | 68/285 [02:25<07:05,  1.96s/it]predicting train subjects:  24%|██▍       | 69/285 [02:27<07:14,  2.01s/it]predicting train subjects:  25%|██▍       | 70/285 [02:29<07:15,  2.03s/it]predicting train subjects:  25%|██▍       | 71/285 [02:31<07:15,  2.04s/it]predicting train subjects:  25%|██▌       | 72/285 [02:33<07:07,  2.01s/it]predicting train subjects:  26%|██▌       | 73/285 [02:35<07:05,  2.01s/it]predicting train subjects:  26%|██▌       | 74/285 [02:37<07:07,  2.02s/it]predicting train subjects:  26%|██▋       | 75/285 [02:39<07:14,  2.07s/it]predicting train subjects:  27%|██▋       | 76/285 [02:41<07:10,  2.06s/it]predicting train subjects:  27%|██▋       | 77/285 [02:43<06:54,  1.99s/it]predicting train subjects:  27%|██▋       | 78/285 [02:45<06:46,  1.96s/it]predicting train subjects:  28%|██▊       | 79/285 [02:47<06:41,  1.95s/it]predicting train subjects:  28%|██▊       | 80/285 [02:49<06:47,  1.99s/it]predicting train subjects:  28%|██▊       | 81/285 [02:51<06:38,  1.95s/it]predicting train subjects:  29%|██▉       | 82/285 [02:53<06:38,  1.96s/it]predicting train subjects:  29%|██▉       | 83/285 [02:54<06:31,  1.94s/it]predicting train subjects:  29%|██▉       | 84/285 [02:56<06:19,  1.89s/it]predicting train subjects:  30%|██▉       | 85/285 [02:58<06:21,  1.91s/it]predicting train subjects:  30%|███       | 86/285 [03:00<06:27,  1.95s/it]predicting train subjects:  31%|███       | 87/285 [03:02<06:32,  1.98s/it]predicting train subjects:  31%|███       | 88/285 [03:04<06:26,  1.96s/it]predicting train subjects:  31%|███       | 89/285 [03:06<06:35,  2.02s/it]predicting train subjects:  32%|███▏      | 90/285 [03:08<06:40,  2.05s/it]predicting train subjects:  32%|███▏      | 91/285 [03:10<06:32,  2.02s/it]predicting train subjects:  32%|███▏      | 92/285 [03:13<06:41,  2.08s/it]predicting train subjects:  33%|███▎      | 93/285 [03:15<06:31,  2.04s/it]predicting train subjects:  33%|███▎      | 94/285 [03:17<06:35,  2.07s/it]predicting train subjects:  33%|███▎      | 95/285 [03:19<06:26,  2.03s/it]predicting train subjects:  34%|███▎      | 96/285 [03:21<06:27,  2.05s/it]predicting train subjects:  34%|███▍      | 97/285 [03:23<06:19,  2.02s/it]predicting train subjects:  34%|███▍      | 98/285 [03:25<06:17,  2.02s/it]predicting train subjects:  35%|███▍      | 99/285 [03:27<06:08,  1.98s/it]predicting train subjects:  35%|███▌      | 100/285 [03:29<06:12,  2.01s/it]predicting train subjects:  35%|███▌      | 101/285 [03:31<06:06,  1.99s/it]predicting train subjects:  36%|███▌      | 102/285 [03:33<06:07,  2.01s/it]predicting train subjects:  36%|███▌      | 103/285 [03:35<05:56,  1.96s/it]predicting train subjects:  36%|███▋      | 104/285 [03:36<05:54,  1.96s/it]predicting train subjects:  37%|███▋      | 105/285 [03:39<06:02,  2.01s/it]predicting train subjects:  37%|███▋      | 106/285 [03:41<05:56,  1.99s/it]predicting train subjects:  38%|███▊      | 107/285 [03:43<06:02,  2.04s/it]predicting train subjects:  38%|███▊      | 108/285 [03:44<05:46,  1.96s/it]predicting train subjects:  38%|███▊      | 109/285 [03:47<05:50,  1.99s/it]predicting train subjects:  39%|███▊      | 110/285 [03:49<05:58,  2.05s/it]predicting train subjects:  39%|███▉      | 111/285 [03:51<05:49,  2.01s/it]predicting train subjects:  39%|███▉      | 112/285 [03:53<05:51,  2.03s/it]predicting train subjects:  40%|███▉      | 113/285 [03:55<05:55,  2.07s/it]predicting train subjects:  40%|████      | 114/285 [03:57<05:51,  2.06s/it]predicting train subjects:  40%|████      | 115/285 [03:59<05:47,  2.04s/it]predicting train subjects:  41%|████      | 116/285 [04:01<05:52,  2.08s/it]predicting train subjects:  41%|████      | 117/285 [04:03<05:39,  2.02s/it]predicting train subjects:  41%|████▏     | 118/285 [04:05<05:30,  1.98s/it]predicting train subjects:  42%|████▏     | 119/285 [04:07<05:31,  2.00s/it]predicting train subjects:  42%|████▏     | 120/285 [04:09<05:28,  1.99s/it]predicting train subjects:  42%|████▏     | 121/285 [04:11<05:20,  1.96s/it]predicting train subjects:  43%|████▎     | 122/285 [04:13<05:12,  1.92s/it]predicting train subjects:  43%|████▎     | 123/285 [04:14<05:00,  1.85s/it]predicting train subjects:  44%|████▎     | 124/285 [04:16<04:57,  1.85s/it]predicting train subjects:  44%|████▍     | 125/285 [04:18<04:52,  1.83s/it]predicting train subjects:  44%|████▍     | 126/285 [04:20<04:50,  1.83s/it]predicting train subjects:  45%|████▍     | 127/285 [04:21<04:41,  1.78s/it]predicting train subjects:  45%|████▍     | 128/285 [04:23<04:41,  1.79s/it]predicting train subjects:  45%|████▌     | 129/285 [04:25<04:35,  1.77s/it]predicting train subjects:  46%|████▌     | 130/285 [04:27<04:28,  1.73s/it]predicting train subjects:  46%|████▌     | 131/285 [04:28<04:22,  1.71s/it]predicting train subjects:  46%|████▋     | 132/285 [04:30<04:25,  1.74s/it]predicting train subjects:  47%|████▋     | 133/285 [04:32<04:19,  1.71s/it]predicting train subjects:  47%|████▋     | 134/285 [04:33<04:12,  1.67s/it]predicting train subjects:  47%|████▋     | 135/285 [04:35<04:15,  1.70s/it]predicting train subjects:  48%|████▊     | 136/285 [04:37<04:09,  1.67s/it]predicting train subjects:  48%|████▊     | 137/285 [04:38<04:13,  1.71s/it]predicting train subjects:  48%|████▊     | 138/285 [04:40<04:12,  1.72s/it]predicting train subjects:  49%|████▉     | 139/285 [04:42<04:16,  1.75s/it]predicting train subjects:  49%|████▉     | 140/285 [04:44<04:19,  1.79s/it]predicting train subjects:  49%|████▉     | 141/285 [04:45<04:07,  1.72s/it]predicting train subjects:  50%|████▉     | 142/285 [04:47<04:07,  1.73s/it]predicting train subjects:  50%|█████     | 143/285 [04:49<04:01,  1.70s/it]predicting train subjects:  51%|█████     | 144/285 [04:51<04:08,  1.76s/it]predicting train subjects:  51%|█████     | 145/285 [04:53<04:06,  1.76s/it]predicting train subjects:  51%|█████     | 146/285 [04:54<04:08,  1.79s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:56<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:58<03:59,  1.75s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:59<03:55,  1.73s/it]predicting train subjects:  53%|█████▎    | 150/285 [05:01<03:53,  1.73s/it]predicting train subjects:  53%|█████▎    | 151/285 [05:03<03:53,  1.74s/it]predicting train subjects:  53%|█████▎    | 152/285 [05:05<03:45,  1.69s/it]predicting train subjects:  54%|█████▎    | 153/285 [05:06<03:43,  1.69s/it]predicting train subjects:  54%|█████▍    | 154/285 [05:08<03:44,  1.72s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:10<03:43,  1.72s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:12<03:48,  1.77s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:13<03:44,  1.76s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:15<03:39,  1.73s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:17<03:39,  1.74s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:18<03:35,  1.73s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:20<03:36,  1.75s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:22<03:28,  1.70s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:24<03:33,  1.75s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:25<03:30,  1.74s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:27<03:27,  1.73s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:29<03:32,  1.78s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:31<03:33,  1.81s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:33<03:26,  1.77s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:34<03:22,  1.75s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:36<03:18,  1.73s/it]predicting train subjects:  60%|██████    | 171/285 [05:38<03:16,  1.73s/it]predicting train subjects:  60%|██████    | 172/285 [05:39<03:16,  1.74s/it]predicting train subjects:  61%|██████    | 173/285 [05:41<03:10,  1.70s/it]predicting train subjects:  61%|██████    | 174/285 [05:43<03:04,  1.66s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:44<03:05,  1.69s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:46<03:13,  1.77s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:48<03:03,  1.70s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:49<02:58,  1.67s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:51<02:57,  1.67s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:53<03:04,  1.76s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:55<03:02,  1.76s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:57<03:07,  1.82s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:58<03:00,  1.77s/it]predicting train subjects:  65%|██████▍   | 184/285 [06:00<02:56,  1.75s/it]predicting train subjects:  65%|██████▍   | 185/285 [06:02<02:48,  1.68s/it]predicting train subjects:  65%|██████▌   | 186/285 [06:04<02:58,  1.81s/it]predicting train subjects:  66%|██████▌   | 187/285 [06:06<03:07,  1.92s/it]predicting train subjects:  66%|██████▌   | 188/285 [06:08<03:06,  1.93s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:09<02:54,  1.82s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:11<02:48,  1.77s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:13<02:48,  1.80s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:15<02:48,  1.81s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:16<02:41,  1.76s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:18<02:34,  1.69s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:20<02:32,  1.69s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:22<02:40,  1.81s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:24<02:42,  1.84s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:26<02:47,  1.92s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:27<02:35,  1.80s/it]predicting train subjects:  70%|███████   | 200/285 [06:29<02:31,  1.78s/it]predicting train subjects:  71%|███████   | 201/285 [06:31<02:34,  1.84s/it]predicting train subjects:  71%|███████   | 202/285 [06:33<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [06:35<02:34,  1.88s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:36<02:21,  1.75s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:38<02:18,  1.73s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:40<02:11,  1.66s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:42<02:21,  1.81s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:44<02:22,  1.85s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:46<02:24,  1.90s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:47<02:13,  1.79s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:49<02:12,  1.79s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:51<02:13,  1.82s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:53<02:11,  1.83s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:54<02:05,  1.76s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:56<02:09,  1.84s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:58<02:00,  1.74s/it]predicting train subjects:  76%|███████▌  | 217/285 [07:00<02:05,  1.85s/it]predicting train subjects:  76%|███████▋  | 218/285 [07:02<02:08,  1.92s/it]predicting train subjects:  77%|███████▋  | 219/285 [07:04<02:09,  1.96s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:06<02:03,  1.89s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:07<01:54,  1.80s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:09<01:52,  1.79s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:11<01:45,  1.70s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:12<01:42,  1.68s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:14<01:37,  1.63s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:16<01:41,  1.72s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:18<01:43,  1.78s/it]predicting train subjects:  80%|████████  | 228/285 [07:19<01:42,  1.80s/it]predicting train subjects:  80%|████████  | 229/285 [07:21<01:40,  1.79s/it]predicting train subjects:  81%|████████  | 230/285 [07:23<01:33,  1.71s/it]predicting train subjects:  81%|████████  | 231/285 [07:24<01:27,  1.63s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:26<01:28,  1.67s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:28<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:30<01:29,  1.76s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:31<01:25,  1.71s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:33<01:25,  1.75s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:35<01:24,  1.77s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:37<01:26,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:39<01:24,  1.83s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:40<01:18,  1.75s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:42<01:13,  1.67s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:43<01:09,  1.61s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:45<01:07,  1.61s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:47<01:09,  1.70s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:48<01:05,  1.64s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:50<01:08,  1.75s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:52<01:08,  1.81s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:54<01:06,  1.79s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:55<01:01,  1.72s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:57<00:58,  1.66s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:58<00:54,  1.61s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:00<00:53,  1.62s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:02<00:55,  1.72s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:04<00:54,  1.76s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:06<00:54,  1.81s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:07<00:51,  1.76s/it]predicting train subjects:  90%|█████████ | 257/285 [08:09<00:47,  1.69s/it]predicting train subjects:  91%|█████████ | 258/285 [08:11<00:47,  1.75s/it]predicting train subjects:  91%|█████████ | 259/285 [08:13<00:45,  1.75s/it]predicting train subjects:  91%|█████████ | 260/285 [08:14<00:42,  1.70s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:16<00:39,  1.66s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:17<00:36,  1.60s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:19<00:35,  1.64s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:21<00:37,  1.80s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:23<00:36,  1.85s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:25<00:34,  1.79s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:26<00:31,  1.76s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:29<00:31,  1.88s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:31<00:30,  1.89s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:32<00:26,  1.80s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:34<00:24,  1.75s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:36<00:22,  1.77s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:37<00:20,  1.72s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:39<00:18,  1.66s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:41<00:17,  1.79s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:43<00:16,  1.86s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:44<00:14,  1.76s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:46<00:11,  1.69s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:48<00:10,  1.72s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:49<00:08,  1.66s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:51<00:06,  1.64s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:52<00:04,  1.64s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:54<00:03,  1.72s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:56<00:01,  1.78s/it]predicting train subjects: 100%|██████████| 285/285 [08:58<00:00,  1.82s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:45,  1.85s/it]Loading train:   1%|          | 2/285 [00:03<07:54,  1.68s/it]Loading train:   1%|          | 3/285 [00:04<07:43,  1.64s/it]Loading train:   1%|▏         | 4/285 [00:05<06:59,  1.49s/it]Loading train:   2%|▏         | 5/285 [00:07<07:07,  1.53s/it]Loading train:   2%|▏         | 6/285 [00:08<06:46,  1.46s/it]Loading train:   2%|▏         | 7/285 [00:10<06:55,  1.49s/it]Loading train:   3%|▎         | 8/285 [00:11<06:43,  1.46s/it]Loading train:   3%|▎         | 9/285 [00:13<07:09,  1.55s/it]Loading train:   4%|▎         | 10/285 [00:14<06:56,  1.51s/it]Loading train:   4%|▍         | 11/285 [00:15<06:11,  1.35s/it]Loading train:   4%|▍         | 12/285 [00:17<06:07,  1.35s/it]Loading train:   5%|▍         | 13/285 [00:18<05:59,  1.32s/it]Loading train:   5%|▍         | 14/285 [00:19<05:55,  1.31s/it]Loading train:   5%|▌         | 15/285 [00:21<06:00,  1.33s/it]Loading train:   6%|▌         | 16/285 [00:22<06:21,  1.42s/it]Loading train:   6%|▌         | 17/285 [00:23<05:46,  1.29s/it]Loading train:   6%|▋         | 18/285 [00:25<05:49,  1.31s/it]Loading train:   7%|▋         | 19/285 [00:25<05:13,  1.18s/it]Loading train:   7%|▋         | 20/285 [00:26<04:50,  1.10s/it]Loading train:   7%|▋         | 21/285 [00:27<04:49,  1.10s/it]Loading train:   8%|▊         | 22/285 [00:28<04:23,  1.00s/it]Loading train:   8%|▊         | 23/285 [00:29<04:19,  1.01it/s]Loading train:   8%|▊         | 24/285 [00:30<04:20,  1.00it/s]Loading train:   9%|▉         | 25/285 [00:31<04:24,  1.02s/it]Loading train:   9%|▉         | 26/285 [00:32<04:36,  1.07s/it]Loading train:   9%|▉         | 27/285 [00:33<04:19,  1.01s/it]Loading train:  10%|▉         | 28/285 [00:34<04:13,  1.01it/s]Loading train:  10%|█         | 29/285 [00:36<04:45,  1.12s/it]Loading train:  11%|█         | 30/285 [00:37<04:44,  1.12s/it]Loading train:  11%|█         | 31/285 [00:38<04:57,  1.17s/it]Loading train:  11%|█         | 32/285 [00:39<04:41,  1.11s/it]Loading train:  12%|█▏        | 33/285 [00:40<04:40,  1.11s/it]Loading train:  12%|█▏        | 34/285 [00:41<04:20,  1.04s/it]Loading train:  12%|█▏        | 35/285 [00:42<04:31,  1.09s/it]Loading train:  13%|█▎        | 36/285 [00:43<04:10,  1.01s/it]Loading train:  13%|█▎        | 37/285 [00:44<04:24,  1.07s/it]Loading train:  13%|█▎        | 38/285 [00:45<04:19,  1.05s/it]Loading train:  14%|█▎        | 39/285 [00:46<04:08,  1.01s/it]Loading train:  14%|█▍        | 40/285 [00:48<04:46,  1.17s/it]Loading train:  14%|█▍        | 41/285 [00:49<04:37,  1.14s/it]Loading train:  15%|█▍        | 42/285 [00:50<04:35,  1.13s/it]Loading train:  15%|█▌        | 43/285 [00:51<04:44,  1.18s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:54,  1.22s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:44,  1.18s/it]Loading train:  16%|█▌        | 46/285 [00:55<05:00,  1.26s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:35,  1.16s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:36,  1.17s/it]Loading train:  17%|█▋        | 49/285 [00:58<04:38,  1.18s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:41,  1.20s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:49,  1.24s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:39,  1.20s/it]Loading train:  19%|█▊        | 53/285 [01:03<04:39,  1.21s/it]Loading train:  19%|█▉        | 54/285 [01:05<04:40,  1.21s/it]Loading train:  19%|█▉        | 55/285 [01:06<04:36,  1.20s/it]Loading train:  20%|█▉        | 56/285 [01:07<04:24,  1.16s/it]Loading train:  20%|██        | 57/285 [01:08<04:33,  1.20s/it]Loading train:  20%|██        | 58/285 [01:09<04:25,  1.17s/it]Loading train:  21%|██        | 59/285 [01:11<04:43,  1.25s/it]Loading train:  21%|██        | 60/285 [01:12<04:36,  1.23s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:22,  1.17s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:31,  1.22s/it]Loading train:  22%|██▏       | 63/285 [01:15<04:35,  1.24s/it]Loading train:  22%|██▏       | 64/285 [01:17<05:02,  1.37s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:16,  1.44s/it]Loading train:  23%|██▎       | 66/285 [01:20<05:37,  1.54s/it]Loading train:  24%|██▎       | 67/285 [01:22<05:21,  1.48s/it]Loading train:  24%|██▍       | 68/285 [01:23<04:54,  1.36s/it]Loading train:  24%|██▍       | 69/285 [01:24<04:44,  1.32s/it]Loading train:  25%|██▍       | 70/285 [01:25<04:39,  1.30s/it]Loading train:  25%|██▍       | 71/285 [01:27<04:35,  1.29s/it]Loading train:  25%|██▌       | 72/285 [01:28<04:10,  1.18s/it]Loading train:  26%|██▌       | 73/285 [01:29<04:18,  1.22s/it]Loading train:  26%|██▌       | 74/285 [01:30<04:10,  1.19s/it]Loading train:  26%|██▋       | 75/285 [01:31<04:23,  1.25s/it]Loading train:  27%|██▋       | 76/285 [01:33<04:16,  1.23s/it]Loading train:  27%|██▋       | 77/285 [01:34<04:11,  1.21s/it]Loading train:  27%|██▋       | 78/285 [01:35<03:48,  1.11s/it]Loading train:  28%|██▊       | 79/285 [01:36<03:52,  1.13s/it]Loading train:  28%|██▊       | 80/285 [01:37<03:54,  1.14s/it]Loading train:  28%|██▊       | 81/285 [01:38<03:54,  1.15s/it]Loading train:  29%|██▉       | 82/285 [01:39<03:49,  1.13s/it]Loading train:  29%|██▉       | 83/285 [01:40<03:37,  1.08s/it]Loading train:  29%|██▉       | 84/285 [01:41<03:29,  1.04s/it]Loading train:  30%|██▉       | 85/285 [01:42<03:41,  1.11s/it]Loading train:  30%|███       | 86/285 [01:44<03:41,  1.11s/it]Loading train:  31%|███       | 87/285 [01:45<03:42,  1.13s/it]Loading train:  31%|███       | 88/285 [01:46<03:34,  1.09s/it]Loading train:  31%|███       | 89/285 [01:47<03:36,  1.11s/it]Loading train:  32%|███▏      | 90/285 [01:48<03:41,  1.13s/it]Loading train:  32%|███▏      | 91/285 [01:49<03:37,  1.12s/it]Loading train:  32%|███▏      | 92/285 [01:50<03:44,  1.16s/it]Loading train:  33%|███▎      | 93/285 [01:51<03:37,  1.13s/it]Loading train:  33%|███▎      | 94/285 [01:53<03:44,  1.18s/it]Loading train:  33%|███▎      | 95/285 [01:54<03:46,  1.19s/it]Loading train:  34%|███▎      | 96/285 [01:55<03:48,  1.21s/it]Loading train:  34%|███▍      | 97/285 [01:56<03:42,  1.18s/it]Loading train:  34%|███▍      | 98/285 [01:57<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [01:58<03:30,  1.13s/it]Loading train:  35%|███▌      | 100/285 [02:00<03:43,  1.21s/it]Loading train:  35%|███▌      | 101/285 [02:01<03:35,  1.17s/it]Loading train:  36%|███▌      | 102/285 [02:02<03:39,  1.20s/it]Loading train:  36%|███▌      | 103/285 [02:03<03:26,  1.13s/it]Loading train:  36%|███▋      | 104/285 [02:05<03:40,  1.22s/it]Loading train:  37%|███▋      | 105/285 [02:06<03:41,  1.23s/it]Loading train:  37%|███▋      | 106/285 [02:07<03:26,  1.15s/it]Loading train:  38%|███▊      | 107/285 [02:08<03:15,  1.10s/it]Loading train:  38%|███▊      | 108/285 [02:09<03:03,  1.04s/it]Loading train:  38%|███▊      | 109/285 [02:10<03:08,  1.07s/it]Loading train:  39%|███▊      | 110/285 [02:11<03:17,  1.13s/it]Loading train:  39%|███▉      | 111/285 [02:12<03:07,  1.08s/it]Loading train:  39%|███▉      | 112/285 [02:13<03:17,  1.14s/it]Loading train:  40%|███▉      | 113/285 [02:15<03:19,  1.16s/it]Loading train:  40%|████      | 114/285 [02:16<03:15,  1.14s/it]Loading train:  40%|████      | 115/285 [02:17<03:40,  1.30s/it]Loading train:  41%|████      | 116/285 [02:19<03:38,  1.29s/it]Loading train:  41%|████      | 117/285 [02:20<03:20,  1.19s/it]Loading train:  41%|████▏     | 118/285 [02:21<03:12,  1.15s/it]Loading train:  42%|████▏     | 119/285 [02:22<03:16,  1.19s/it]Loading train:  42%|████▏     | 120/285 [02:23<03:07,  1.14s/it]Loading train:  42%|████▏     | 121/285 [02:24<03:20,  1.22s/it]Loading train:  43%|████▎     | 122/285 [02:26<03:26,  1.27s/it]Loading train:  43%|████▎     | 123/285 [02:27<03:28,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:28<03:12,  1.19s/it]Loading train:  44%|████▍     | 125/285 [02:29<02:58,  1.12s/it]Loading train:  44%|████▍     | 126/285 [02:30<02:55,  1.10s/it]Loading train:  45%|████▍     | 127/285 [02:31<02:48,  1.06s/it]Loading train:  45%|████▍     | 128/285 [02:32<02:36,  1.00it/s]Loading train:  45%|████▌     | 129/285 [02:33<02:29,  1.04it/s]Loading train:  46%|████▌     | 130/285 [02:34<02:29,  1.04it/s]Loading train:  46%|████▌     | 131/285 [02:35<02:27,  1.04it/s]Loading train:  46%|████▋     | 132/285 [02:36<02:38,  1.04s/it]Loading train:  47%|████▋     | 133/285 [02:37<02:33,  1.01s/it]Loading train:  47%|████▋     | 134/285 [02:38<02:30,  1.00it/s]Loading train:  47%|████▋     | 135/285 [02:39<02:38,  1.06s/it]Loading train:  48%|████▊     | 136/285 [02:40<02:35,  1.04s/it]Loading train:  48%|████▊     | 137/285 [02:41<02:34,  1.04s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:23,  1.03it/s]Loading train:  49%|████▉     | 139/285 [02:43<02:20,  1.04it/s]Loading train:  49%|████▉     | 140/285 [02:44<02:20,  1.03it/s]Loading train:  49%|████▉     | 141/285 [02:45<02:19,  1.03it/s]Loading train:  50%|████▉     | 142/285 [02:46<02:25,  1.02s/it]Loading train:  50%|█████     | 143/285 [02:47<02:19,  1.02it/s]Loading train:  51%|█████     | 144/285 [02:48<02:26,  1.04s/it]Loading train:  51%|█████     | 145/285 [02:49<02:29,  1.07s/it]Loading train:  51%|█████     | 146/285 [02:50<02:35,  1.12s/it]Loading train:  52%|█████▏    | 147/285 [02:52<02:47,  1.21s/it]Loading train:  52%|█████▏    | 148/285 [02:53<02:49,  1.24s/it]Loading train:  52%|█████▏    | 149/285 [02:54<02:40,  1.18s/it]Loading train:  53%|█████▎    | 150/285 [02:55<02:37,  1.16s/it]Loading train:  53%|█████▎    | 151/285 [02:57<02:46,  1.24s/it]Loading train:  53%|█████▎    | 152/285 [02:58<02:48,  1.27s/it]Loading train:  54%|█████▎    | 153/285 [02:59<02:39,  1.21s/it]Loading train:  54%|█████▍    | 154/285 [03:00<02:38,  1.21s/it]Loading train:  54%|█████▍    | 155/285 [03:01<02:32,  1.17s/it]Loading train:  55%|█████▍    | 156/285 [03:02<02:28,  1.15s/it]Loading train:  55%|█████▌    | 157/285 [03:03<02:19,  1.09s/it]Loading train:  55%|█████▌    | 158/285 [03:04<02:18,  1.09s/it]Loading train:  56%|█████▌    | 159/285 [03:06<02:17,  1.09s/it]Loading train:  56%|█████▌    | 160/285 [03:07<02:15,  1.09s/it]Loading train:  56%|█████▋    | 161/285 [03:08<02:15,  1.09s/it]Loading train:  57%|█████▋    | 162/285 [03:09<02:08,  1.04s/it]Loading train:  57%|█████▋    | 163/285 [03:10<02:01,  1.01it/s]Loading train:  58%|█████▊    | 164/285 [03:11<02:00,  1.00it/s]Loading train:  58%|█████▊    | 165/285 [03:12<02:04,  1.04s/it]Loading train:  58%|█████▊    | 166/285 [03:13<02:07,  1.07s/it]Loading train:  59%|█████▊    | 167/285 [03:14<02:12,  1.12s/it]Loading train:  59%|█████▉    | 168/285 [03:15<02:09,  1.11s/it]Loading train:  59%|█████▉    | 169/285 [03:16<02:16,  1.18s/it]Loading train:  60%|█████▉    | 170/285 [03:18<02:12,  1.16s/it]Loading train:  60%|██████    | 171/285 [03:19<02:12,  1.16s/it]Loading train:  60%|██████    | 172/285 [03:20<02:06,  1.12s/it]Loading train:  61%|██████    | 173/285 [03:21<02:02,  1.09s/it]Loading train:  61%|██████    | 174/285 [03:22<02:04,  1.12s/it]Loading train:  61%|██████▏   | 175/285 [03:23<02:08,  1.17s/it]Loading train:  62%|██████▏   | 176/285 [03:25<02:10,  1.20s/it]Loading train:  62%|██████▏   | 177/285 [03:26<02:03,  1.15s/it]Loading train:  62%|██████▏   | 178/285 [03:27<02:09,  1.21s/it]Loading train:  63%|██████▎   | 179/285 [03:28<01:55,  1.09s/it]Loading train:  63%|██████▎   | 180/285 [03:29<02:08,  1.22s/it]Loading train:  64%|██████▎   | 181/285 [03:31<02:10,  1.25s/it]Loading train:  64%|██████▍   | 182/285 [03:32<02:07,  1.24s/it]Loading train:  64%|██████▍   | 183/285 [03:33<02:13,  1.30s/it]Loading train:  65%|██████▍   | 184/285 [03:34<02:01,  1.21s/it]Loading train:  65%|██████▍   | 185/285 [03:35<01:57,  1.17s/it]Loading train:  65%|██████▌   | 186/285 [03:37<02:08,  1.30s/it]Loading train:  66%|██████▌   | 187/285 [03:38<02:06,  1.29s/it]Loading train:  66%|██████▌   | 188/285 [03:40<02:06,  1.31s/it]Loading train:  66%|██████▋   | 189/285 [03:41<02:00,  1.26s/it]Loading train:  67%|██████▋   | 190/285 [03:42<01:49,  1.15s/it]Loading train:  67%|██████▋   | 191/285 [03:43<01:44,  1.11s/it]Loading train:  67%|██████▋   | 192/285 [03:44<01:44,  1.13s/it]Loading train:  68%|██████▊   | 193/285 [03:45<01:48,  1.18s/it]Loading train:  68%|██████▊   | 194/285 [03:46<01:41,  1.12s/it]Loading train:  68%|██████▊   | 195/285 [03:47<01:37,  1.09s/it]Loading train:  69%|██████▉   | 196/285 [03:48<01:39,  1.12s/it]Loading train:  69%|██████▉   | 197/285 [03:49<01:40,  1.14s/it]Loading train:  69%|██████▉   | 198/285 [03:51<01:41,  1.17s/it]Loading train:  70%|██████▉   | 199/285 [03:52<01:35,  1.11s/it]Loading train:  70%|███████   | 200/285 [03:53<01:33,  1.11s/it]Loading train:  71%|███████   | 201/285 [03:54<01:38,  1.18s/it]Loading train:  71%|███████   | 202/285 [03:55<01:41,  1.22s/it]Loading train:  71%|███████   | 203/285 [03:56<01:34,  1.16s/it]Loading train:  72%|███████▏  | 204/285 [03:58<01:34,  1.16s/it]Loading train:  72%|███████▏  | 205/285 [03:59<01:29,  1.12s/it]Loading train:  72%|███████▏  | 206/285 [03:59<01:22,  1.04s/it]Loading train:  73%|███████▎  | 207/285 [04:01<01:25,  1.10s/it]Loading train:  73%|███████▎  | 208/285 [04:02<01:25,  1.11s/it]Loading train:  73%|███████▎  | 209/285 [04:03<01:27,  1.16s/it]Loading train:  74%|███████▎  | 210/285 [04:04<01:23,  1.12s/it]Loading train:  74%|███████▍  | 211/285 [04:05<01:25,  1.16s/it]Loading train:  74%|███████▍  | 212/285 [04:07<01:24,  1.16s/it]Loading train:  75%|███████▍  | 213/285 [04:07<01:19,  1.10s/it]Loading train:  75%|███████▌  | 214/285 [04:08<01:14,  1.05s/it]Loading train:  75%|███████▌  | 215/285 [04:10<01:15,  1.09s/it]Loading train:  76%|███████▌  | 216/285 [04:10<01:08,  1.01it/s]Loading train:  76%|███████▌  | 217/285 [04:12<01:21,  1.20s/it]Loading train:  76%|███████▋  | 218/285 [04:13<01:23,  1.25s/it]Loading train:  77%|███████▋  | 219/285 [04:15<01:21,  1.23s/it]Loading train:  77%|███████▋  | 220/285 [04:16<01:15,  1.17s/it]Loading train:  78%|███████▊  | 221/285 [04:17<01:14,  1.17s/it]Loading train:  78%|███████▊  | 222/285 [04:18<01:21,  1.29s/it]Loading train:  78%|███████▊  | 223/285 [04:19<01:08,  1.11s/it]Loading train:  79%|███████▊  | 224/285 [04:20<01:09,  1.14s/it]Loading train:  79%|███████▉  | 225/285 [04:21<01:05,  1.10s/it]Loading train:  79%|███████▉  | 226/285 [04:23<01:09,  1.17s/it]Loading train:  80%|███████▉  | 227/285 [04:24<01:08,  1.17s/it]Loading train:  80%|████████  | 228/285 [04:25<01:09,  1.22s/it]Loading train:  80%|████████  | 229/285 [04:26<01:08,  1.23s/it]Loading train:  81%|████████  | 230/285 [04:27<01:04,  1.16s/it]Loading train:  81%|████████  | 231/285 [04:28<01:00,  1.12s/it]Loading train:  81%|████████▏ | 232/285 [04:30<01:01,  1.16s/it]Loading train:  82%|████████▏ | 233/285 [04:31<01:05,  1.26s/it]Loading train:  82%|████████▏ | 234/285 [04:32<01:04,  1.27s/it]Loading train:  82%|████████▏ | 235/285 [04:33<00:58,  1.18s/it]Loading train:  83%|████████▎ | 236/285 [04:35<01:00,  1.24s/it]Loading train:  83%|████████▎ | 237/285 [04:36<01:02,  1.31s/it]Loading train:  84%|████████▎ | 238/285 [04:37<00:57,  1.23s/it]Loading train:  84%|████████▍ | 239/285 [04:39<01:00,  1.32s/it]Loading train:  84%|████████▍ | 240/285 [04:40<00:55,  1.24s/it]Loading train:  85%|████████▍ | 241/285 [04:41<00:54,  1.23s/it]Loading train:  85%|████████▍ | 242/285 [04:42<00:53,  1.23s/it]Loading train:  85%|████████▌ | 243/285 [04:43<00:48,  1.16s/it]Loading train:  86%|████████▌ | 244/285 [04:45<00:51,  1.26s/it]Loading train:  86%|████████▌ | 245/285 [04:46<00:45,  1.13s/it]Loading train:  86%|████████▋ | 246/285 [04:47<00:42,  1.08s/it]Loading train:  87%|████████▋ | 247/285 [04:48<00:41,  1.09s/it]Loading train:  87%|████████▋ | 248/285 [04:49<00:40,  1.08s/it]Loading train:  87%|████████▋ | 249/285 [04:50<00:37,  1.05s/it]Loading train:  88%|████████▊ | 250/285 [04:51<00:38,  1.09s/it]Loading train:  88%|████████▊ | 251/285 [04:52<00:37,  1.11s/it]Loading train:  88%|████████▊ | 252/285 [04:53<00:35,  1.08s/it]Loading train:  89%|████████▉ | 253/285 [04:55<00:40,  1.28s/it]Loading train:  89%|████████▉ | 254/285 [04:56<00:42,  1.36s/it]Loading train:  89%|████████▉ | 255/285 [04:57<00:37,  1.26s/it]Loading train:  90%|████████▉ | 256/285 [04:58<00:32,  1.11s/it]Loading train:  90%|█████████ | 257/285 [04:59<00:32,  1.15s/it]Loading train:  91%|█████████ | 258/285 [05:01<00:30,  1.14s/it]Loading train:  91%|█████████ | 259/285 [05:02<00:29,  1.14s/it]Loading train:  91%|█████████ | 260/285 [05:03<00:29,  1.19s/it]Loading train:  92%|█████████▏| 261/285 [05:04<00:28,  1.19s/it]Loading train:  92%|█████████▏| 262/285 [05:05<00:26,  1.15s/it]Loading train:  92%|█████████▏| 263/285 [05:06<00:23,  1.08s/it]Loading train:  93%|█████████▎| 264/285 [05:07<00:23,  1.12s/it]Loading train:  93%|█████████▎| 265/285 [05:09<00:23,  1.16s/it]Loading train:  93%|█████████▎| 266/285 [05:09<00:19,  1.04s/it]Loading train:  94%|█████████▎| 267/285 [05:10<00:17,  1.01it/s]Loading train:  94%|█████████▍| 268/285 [05:11<00:17,  1.02s/it]Loading train:  94%|█████████▍| 269/285 [05:12<00:16,  1.05s/it]Loading train:  95%|█████████▍| 270/285 [05:13<00:14,  1.00it/s]Loading train:  95%|█████████▌| 271/285 [05:14<00:14,  1.01s/it]Loading train:  95%|█████████▌| 272/285 [05:16<00:13,  1.05s/it]Loading train:  96%|█████████▌| 273/285 [05:17<00:12,  1.04s/it]Loading train:  96%|█████████▌| 274/285 [05:18<00:12,  1.12s/it]Loading train:  96%|█████████▋| 275/285 [05:19<00:10,  1.10s/it]Loading train:  97%|█████████▋| 276/285 [05:20<00:10,  1.17s/it]Loading train:  97%|█████████▋| 277/285 [05:21<00:09,  1.15s/it]Loading train:  98%|█████████▊| 278/285 [05:22<00:07,  1.13s/it]Loading train:  98%|█████████▊| 279/285 [05:23<00:06,  1.12s/it]Loading train:  98%|█████████▊| 280/285 [05:25<00:05,  1.09s/it]Loading train:  99%|█████████▊| 281/285 [05:26<00:04,  1.14s/it]Loading train:  99%|█████████▉| 282/285 [05:27<00:03,  1.07s/it]Loading train:  99%|█████████▉| 283/285 [05:28<00:02,  1.18s/it]Loading train: 100%|█████████▉| 284/285 [05:29<00:01,  1.11s/it]Loading train: 100%|██████████| 285/285 [05:30<00:00,  1.18s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 5/285 [00:00<00:06, 45.33it/s]concatenating: train:   3%|▎         | 9/285 [00:00<00:06, 41.12it/s]concatenating: train:   6%|▌         | 16/285 [00:00<00:05, 46.55it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:04, 56.74it/s]concatenating: train:  13%|█▎        | 36/285 [00:00<00:04, 62.09it/s]concatenating: train:  16%|█▋        | 47/285 [00:00<00:03, 70.87it/s]concatenating: train:  21%|██        | 59/285 [00:00<00:02, 79.57it/s]concatenating: train:  24%|██▍       | 69/285 [00:00<00:02, 84.68it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:02, 93.75it/s]concatenating: train:  33%|███▎      | 93/285 [00:01<00:03, 59.47it/s]concatenating: train:  36%|███▌      | 102/285 [00:01<00:03, 59.37it/s]concatenating: train:  39%|███▊      | 110/285 [00:01<00:03, 54.32it/s]concatenating: train:  41%|████      | 117/285 [00:01<00:03, 55.46it/s]concatenating: train:  44%|████▎     | 124/285 [00:01<00:02, 58.55it/s]concatenating: train:  46%|████▌     | 131/285 [00:01<00:02, 57.34it/s]concatenating: train:  48%|████▊     | 138/285 [00:02<00:03, 41.02it/s]concatenating: train:  52%|█████▏    | 147/285 [00:02<00:02, 48.67it/s]concatenating: train:  54%|█████▍    | 154/285 [00:02<00:02, 52.18it/s]concatenating: train:  57%|█████▋    | 162/285 [00:02<00:02, 56.77it/s]concatenating: train:  61%|██████    | 173/285 [00:02<00:01, 65.88it/s]concatenating: train:  64%|██████▍   | 183/285 [00:02<00:01, 71.57it/s]concatenating: train:  68%|██████▊   | 195/285 [00:02<00:01, 80.71it/s]concatenating: train:  73%|███████▎  | 208/285 [00:03<00:00, 90.30it/s]concatenating: train:  77%|███████▋  | 219/285 [00:03<00:01, 65.45it/s]concatenating: train:  80%|████████  | 228/285 [00:03<00:00, 63.44it/s]concatenating: train:  84%|████████▍ | 240/285 [00:03<00:00, 71.77it/s]concatenating: train:  89%|████████▉ | 253/285 [00:03<00:00, 82.28it/s]concatenating: train:  93%|█████████▎| 265/285 [00:03<00:00, 90.22it/s]concatenating: train:  98%|█████████▊| 278/285 [00:03<00:00, 98.26it/s]concatenating: train: 100%|██████████| 285/285 [00:03<00:00, 72.61it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.42s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.42s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.35s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 142.32it/s]2019-07-11 12:18:59.034985: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 12:18:59.035114: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 12:18:59.035132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 12:18:59.035142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 12:18:59.035498: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:12,  3.41it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:09,  4.15it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:10,  3.78it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:01<00:07,  4.81it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:08,  4.04it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  4.89it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  4.64it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:04,  6.08it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  6.34it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:04,  5.11it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  4.77it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  6.17it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  6.46it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:03<00:02,  5.46it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.17it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.58it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.89it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.80it/s]loading the weights for Res Unet:  89%|████████▊ | 39/44 [00:04<00:00,  7.38it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.76it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  4.95it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.07it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 30)   300         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 30)   120         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 30)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 30)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 30)   8130        dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 30)   120         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 30)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 30)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 31)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   5600        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 30)   16230       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 30)   120         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 30)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 30)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 30)   8130        dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 52, 30)   120         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 52, 30)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 80, 52, 30)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 90)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 52, 13)   1183        concatenate_8[0][0]              
==================================================================================================
Total params: 262,893
Trainable params: 87,973
Non-trainable params: 174,920
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 21s - loss: 2.5251 - acc: 0.7073 - mDice: 0.1510 - val_loss: 1.4905 - val_acc: 0.9034 - val_mDice: 0.3072

Epoch 00001: val_mDice improved from -inf to 0.30715, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.8554 - acc: 0.8794 - mDice: 0.4189 - val_loss: 1.1439 - val_acc: 0.9052 - val_mDice: 0.4288

Epoch 00002: val_mDice improved from 0.30715 to 0.42875, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 14s - loss: 0.6279 - acc: 0.8871 - mDice: 0.5203 - val_loss: 0.8764 - val_acc: 0.9164 - val_mDice: 0.5310

Epoch 00003: val_mDice improved from 0.42875 to 0.53103, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 14s - loss: 0.5544 - acc: 0.8981 - mDice: 0.5602 - val_loss: 0.8571 - val_acc: 0.9244 - val_mDice: 0.5464

Epoch 00004: val_mDice improved from 0.53103 to 0.54639, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 14s - loss: 0.5087 - acc: 0.9152 - mDice: 0.5868 - val_loss: 0.8545 - val_acc: 0.9281 - val_mDice: 0.5277

Epoch 00005: val_mDice did not improve from 0.54639
Epoch 6/300
 - 14s - loss: 0.4774 - acc: 0.9289 - mDice: 0.6056 - val_loss: 0.8358 - val_acc: 0.9393 - val_mDice: 0.5574

Epoch 00006: val_mDice improved from 0.54639 to 0.55736, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 13s - loss: 0.4559 - acc: 0.9329 - mDice: 0.6186 - val_loss: 0.8126 - val_acc: 0.9367 - val_mDice: 0.5631

Epoch 00007: val_mDice improved from 0.55736 to 0.56307, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 14s - loss: 0.4390 - acc: 0.9346 - mDice: 0.6294 - val_loss: 0.8066 - val_acc: 0.9391 - val_mDice: 0.5676

Epoch 00008: val_mDice improved from 0.56307 to 0.56761, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 14s - loss: 0.4256 - acc: 0.9356 - mDice: 0.6380 - val_loss: 0.8210 - val_acc: 0.9416 - val_mDice: 0.5705

Epoch 00009: val_mDice improved from 0.56761 to 0.57054, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4119 - acc: 0.9369 - mDice: 0.6469 - val_loss: 0.7962 - val_acc: 0.9412 - val_mDice: 0.5641

Epoch 00010: val_mDice did not improve from 0.57054
Epoch 11/300
 - 13s - loss: 0.4034 - acc: 0.9375 - mDice: 0.6528 - val_loss: 0.7579 - val_acc: 0.9411 - val_mDice: 0.5767

Epoch 00011: val_mDice improved from 0.57054 to 0.57669, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 14s - loss: 0.3932 - acc: 0.9382 - mDice: 0.6596 - val_loss: 0.7649 - val_acc: 0.9408 - val_mDice: 0.5773

Epoch 00012: val_mDice improved from 0.57669 to 0.57727, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 13/300
 - 14s - loss: 0.3859 - acc: 0.9388 - mDice: 0.6646 - val_loss: 0.8113 - val_acc: 0.9367 - val_mDice: 0.5653

Epoch 00013: val_mDice did not improve from 0.57727
Epoch 14/300
 - 13s - loss: 0.3788 - acc: 0.9395 - mDice: 0.6693 - val_loss: 0.7636 - val_acc: 0.9423 - val_mDice: 0.5736

Epoch 00014: val_mDice did not improve from 0.57727
Epoch 15/300
 - 13s - loss: 0.3740 - acc: 0.9400 - mDice: 0.6729 - val_loss: 0.7684 - val_acc: 0.9351 - val_mDice: 0.5751

Epoch 00015: val_mDice did not improve from 0.57727
Epoch 16/300
 - 13s - loss: 0.3691 - acc: 0.9404 - mDice: 0.6763 - val_loss: 0.7566 - val_acc: 0.9390 - val_mDice: 0.5683

Epoch 00016: val_mDice did not improve from 0.57727
Epoch 17/300
 - 13s - loss: 0.3645 - acc: 0.9408 - mDice: 0.6795 - val_loss: 0.7628 - val_acc: 0.9363 - val_mDice: 0.5707

Epoch 00017: val_mDice did not improve from 0.57727
Epoch 18/300
 - 14s - loss: 0.3591 - acc: 0.9412 - mDice: 0.6832 - val_loss: 0.7922 - val_acc: 0.9378 - val_mDice: 0.5744

Epoch 00018: val_mDice did not improve from 0.57727
Epoch 19/300
 - 14s - loss: 0.3552 - acc: 0.9415 - mDice: 0.6860 - val_loss: 0.7950 - val_acc: 0.9406 - val_mDice: 0.5695

Epoch 00019: val_mDice did not improve from 0.57727
Epoch 20/300
 - 13s - loss: 0.3521 - acc: 0.9417 - mDice: 0.6881 - val_loss: 0.7684 - val_acc: 0.9373 - val_mDice: 0.5708

Epoch 00020: val_mDice did not improve from 0.57727
Epoch 21/300
 - 13s - loss: 0.3483 - acc: 0.9421 - mDice: 0.6909 - val_loss: 0.7714 - val_acc: 0.9377 - val_mDice: 0.5759

Epoch 00021: val_mDice did not improve from 0.57727
Epoch 22/300
 - 13s - loss: 0.3438 - acc: 0.9425 - mDice: 0.6941 - val_loss: 0.7812 - val_acc: 0.9373 - val_mDice: 0.5749

Epoch 00022: val_mDice did not improve from 0.57727
Epoch 23/300
 - 13s - loss: 0.3416 - acc: 0.9427 - mDice: 0.6959 - val_loss: 0.7899 - val_acc: 0.9412 - val_mDice: 0.5536

Epoch 00023: val_mDice did not improve from 0.57727
Epoch 24/300
 - 14s - loss: 0.3371 - acc: 0.9430 - mDice: 0.6991 - val_loss: 0.7643 - val_acc: 0.9332 - val_mDice: 0.5701

Epoch 00024: val_mDice did not improve from 0.57727
Epoch 25/300
 - 14s - loss: 0.3325 - acc: 0.9433 - mDice: 0.7024 - val_loss: 0.7777 - val_acc: 0.9382 - val_mDice: 0.5720

Epoch 00025: val_mDice did not improve from 0.57727
Epoch 26/300
 - 14s - loss: 0.3325 - acc: 0.9435 - mDice: 0.7025 - val_loss: 0.7847 - val_acc: 0.9394 - val_mDice: 0.5746

Epoch 00026: val_mDice did not improve from 0.57727
Epoch 27/300
 - 14s - loss: 0.3277 - acc: 0.9439 - mDice: 0.7060 - val_loss: 0.7883 - val_acc: 0.9420 - val_mDice: 0.5750

Epoch 00027: val_mDice did not improve from 0.57727
Epoch 28/300
 - 14s - loss: 0.3272 - acc: 0.9440 - mDice: 0.7064 - val_loss: 0.7883 - val_acc: 0.9418 - val_mDice: 0.5668

Epoch 00028: val_mDice did not improve from 0.57727
Epoch 29/300
 - 13s - loss: 0.3231 - acc: 0.9443 - mDice: 0.7094 - val_loss: 0.7592 - val_acc: 0.9349 - val_mDice: 0.5656

Epoch 00029: val_mDice did not improve from 0.57727
Epoch 30/300
 - 13s - loss: 0.3222 - acc: 0.9444 - mDice: 0.7100 - val_loss: 0.7517 - val_acc: 0.9388 - val_mDice: 0.5790

Epoch 00030: val_mDice improved from 0.57727 to 0.57903, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 31/300
 - 13s - loss: 0.3191 - acc: 0.9447 - mDice: 0.7122 - val_loss: 0.7734 - val_acc: 0.9370 - val_mDice: 0.5709

Epoch 00031: val_mDice did not improve from 0.57903
Epoch 32/300
 - 14s - loss: 0.3184 - acc: 0.9448 - mDice: 0.7129 - val_loss: 0.7793 - val_acc: 0.9425 - val_mDice: 0.5664

Epoch 00032: val_mDice did not improve from 0.57903
Epoch 33/300
 - 14s - loss: 0.3153 - acc: 0.9449 - mDice: 0.7152 - val_loss: 0.7604 - val_acc: 0.9399 - val_mDice: 0.5753

Epoch 00033: val_mDice did not improve from 0.57903
Epoch 34/300
 - 13s - loss: 0.3151 - acc: 0.9451 - mDice: 0.7153 - val_loss: 0.7818 - val_acc: 0.9321 - val_mDice: 0.5567

Epoch 00034: val_mDice did not improve from 0.57903
Epoch 35/300
 - 13s - loss: 0.3120 - acc: 0.9453 - mDice: 0.7176 - val_loss: 0.7647 - val_acc: 0.9400 - val_mDice: 0.5777

Epoch 00035: val_mDice did not improve from 0.57903
Epoch 36/300
 - 13s - loss: 0.3102 - acc: 0.9455 - mDice: 0.7190 - val_loss: 0.7441 - val_acc: 0.9377 - val_mDice: 0.5728

Epoch 00036: val_mDice did not improve from 0.57903
Epoch 37/300
 - 14s - loss: 0.3089 - acc: 0.9454 - mDice: 0.7199 - val_loss: 0.7619 - val_acc: 0.9406 - val_mDice: 0.5744

Epoch 00037: val_mDice did not improve from 0.57903
Epoch 38/300
 - 14s - loss: 0.3083 - acc: 0.9457 - mDice: 0.7203 - val_loss: 0.7586 - val_acc: 0.9407 - val_mDice: 0.5772

Epoch 00038: val_mDice did not improve from 0.57903
Epoch 39/300
 - 14s - loss: 0.3063 - acc: 0.9458 - mDice: 0.7218 - val_loss: 0.7822 - val_acc: 0.9392 - val_mDice: 0.5664

Epoch 00039: val_mDice did not improve from 0.57903
Epoch 40/300
 - 14s - loss: 0.3040 - acc: 0.9461 - mDice: 0.7236 - val_loss: 0.7547 - val_acc: 0.9403 - val_mDice: 0.5732

Epoch 00040: val_mDice did not improve from 0.57903
Epoch 41/300
 - 14s - loss: 0.3012 - acc: 0.9463 - mDice: 0.7257 - val_loss: 0.7521 - val_acc: 0.9419 - val_mDice: 0.5764

Epoch 00041: val_mDice did not improve from 0.57903
Epoch 42/300
 - 13s - loss: 0.3022 - acc: 0.9464 - mDice: 0.7251 - val_loss: 0.7678 - val_acc: 0.9375 - val_mDice: 0.5624

Epoch 00042: val_mDice did not improve from 0.57903
Epoch 43/300
 - 13s - loss: 0.3001 - acc: 0.9465 - mDice: 0.7266 - val_loss: 0.7781 - val_acc: 0.9432 - val_mDice: 0.5635

Epoch 00043: val_mDice did not improve from 0.57903
Epoch 44/300
 - 13s - loss: 0.2997 - acc: 0.9464 - mDice: 0.7269 - val_loss: 0.7427 - val_acc: 0.9405 - val_mDice: 0.5808

Epoch 00044: val_mDice improved from 0.57903 to 0.58077, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM30_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 45/300
 - 14s - loss: 0.2982 - acc: 0.9465 - mDice: 0.7280 - val_loss: 0.7932 - val_acc: 0.9354 - val_mDice: 0.5547

Epoch 00045: val_mDice did not improve from 0.58077
Epoch 46/300
 - 14s - loss: 0.2966 - acc: 0.9466 - mDice: 0.7292 - val_loss: 0.7693 - val_acc: 0.9406 - val_mDice: 0.5720

Epoch 00046: val_mDice did not improve from 0.58077
Epoch 47/300
 - 13s - loss: 0.2939 - acc: 0.9469 - mDice: 0.7313 - val_loss: 0.7631 - val_acc: 0.9425 - val_mDice: 0.5720

Epoch 00047: val_mDice did not improve from 0.58077
Epoch 48/300
 - 14s - loss: 0.2913 - acc: 0.9473 - mDice: 0.7333 - val_loss: 0.7387 - val_acc: 0.9414 - val_mDice: 0.5804

Epoch 00048: val_mDice did not improve from 0.58077
Epoch 49/300
 - 14s - loss: 0.2901 - acc: 0.9471 - mDice: 0.7341 - val_loss: 0.7616 - val_acc: 0.9400 - val_mDice: 0.5697

Epoch 00049: val_mDice did not improve from 0.58077
Epoch 50/300
 - 14s - loss: 0.2900 - acc: 0.9472 - mDice: 0.7343 - val_loss: 0.7452 - val_acc: 0.9402 - val_mDice: 0.5754

Epoch 00050: val_mDice did not improve from 0.58077
Epoch 51/300
 - 14s - loss: 0.2904 - acc: 0.9473 - mDice: 0.7340 - val_loss: 0.7625 - val_acc: 0.9417 - val_mDice: 0.5646

Epoch 00051: val_mDice did not improve from 0.58077
Epoch 52/300
 - 13s - loss: 0.2900 - acc: 0.9474 - mDice: 0.7344 - val_loss: 0.7918 - val_acc: 0.9400 - val_mDice: 0.5511

Epoch 00052: val_mDice did not improve from 0.58077
Epoch 53/300
 - 13s - loss: 0.2871 - acc: 0.9475 - mDice: 0.7365 - val_loss: 0.7790 - val_acc: 0.9406 - val_mDice: 0.5588

Epoch 00053: val_mDice did not improve from 0.58077
Epoch 54/300
 - 14s - loss: 0.2855 - acc: 0.9477 - mDice: 0.7377 - val_loss: 0.7738 - val_acc: 0.9411 - val_mDice: 0.5696

Epoch 00054: val_mDice did not improve from 0.58077
Epoch 55/300
 - 13s - loss: 0.2843 - acc: 0.9479 - mDice: 0.7388 - val_loss: 0.7640 - val_acc: 0.9376 - val_mDice: 0.5646

Epoch 00055: val_mDice did not improve from 0.58077
Epoch 56/300
 - 14s - loss: 0.2847 - acc: 0.9478 - mDice: 0.7384 - val_loss: 0.7415 - val_acc: 0.9383 - val_mDice: 0.5695

Epoch 00056: val_mDice did not improve from 0.58077
Epoch 57/300
 - 14s - loss: 0.2827 - acc: 0.9480 - mDice: 0.7399 - val_loss: 0.7729 - val_acc: 0.9413 - val_mDice: 0.5663

Epoch 00057: val_mDice did not improve from 0.58077
Epoch 58/300
 - 14s - loss: 0.2810 - acc: 0.9482 - mDice: 0.7413 - val_loss: 0.7512 - val_acc: 0.9372 - val_mDice: 0.5708

Epoch 00058: val_mDice did not improve from 0.58077
Epoch 59/300
 - 14s - loss: 0.2806 - acc: 0.9482 - mDice: 0.7415 - val_loss: 0.7742 - val_acc: 0.9401 - val_mDice: 0.5685

Epoch 00059: val_mDice did not improve from 0.58077
Epoch 60/300
 - 14s - loss: 0.2808 - acc: 0.9482 - mDice: 0.7414 - val_loss: 0.7657 - val_acc: 0.9408 - val_mDice: 0.5733

Epoch 00060: val_mDice did not improve from 0.58077
Epoch 61/300
 - 14s - loss: 0.2791 - acc: 0.9483 - mDice: 0.7428 - val_loss: 0.7659 - val_acc: 0.9362 - val_mDice: 0.5595

Epoch 00061: val_mDice did not improve from 0.58077
Epoch 62/300
 - 14s - loss: 0.2791 - acc: 0.9483 - mDice: 0.7427 - val_loss: 0.8133 - val_acc: 0.9387 - val_mDice: 0.5550

Epoch 00062: val_mDice did not improve from 0.58077
Epoch 63/300
 - 14s - loss: 0.2780 - acc: 0.9483 - mDice: 0.7436 - val_loss: 0.7524 - val_acc: 0.9392 - val_mDice: 0.5735

Epoch 00063: val_mDice did not improve from 0.58077
Epoch 64/300
 - 14s - loss: 0.2787 - acc: 0.9483 - mDice: 0.7429 - val_loss: 0.7543 - val_acc: 0.9383 - val_mDice: 0.5697

Epoch 00064: val_mDice did not improve from 0.58077
Epoch 65/300
 - 14s - loss: 0.2771 - acc: 0.9484 - mDice: 0.7443 - val_loss: 0.7677 - val_acc: 0.9403 - val_mDice: 0.5701

Epoch 00065: val_mDice did not improve from 0.58077
Epoch 66/300
 - 14s - loss: 0.2753 - acc: 0.9486 - mDice: 0.7457 - val_loss: 0.7554 - val_acc: 0.9408 - val_mDice: 0.5662

Epoch 00066: val_mDice did not improve from 0.58077
Epoch 67/300
 - 14s - loss: 0.2751 - acc: 0.9486 - mDice: 0.7458 - val_loss: 0.7633 - val_acc: 0.9434 - val_mDice: 0.5637

Epoch 00067: val_mDice did not improve from 0.58077
Epoch 68/300
 - 14s - loss: 0.2746 - acc: 0.9487 - mDice: 0.7462 - val_loss: 0.7612 - val_acc: 0.9411 - val_mDice: 0.5735

Epoch 00068: val_mDice did not improve from 0.58077
Epoch 69/300
 - 14s - loss: 0.2747 - acc: 0.9488 - mDice: 0.7462 - val_loss: 0.7727 - val_acc: 0.9396 - val_mDice: 0.5675

Epoch 00069: val_mDice did not improve from 0.58077
Epoch 70/300
 - 14s - loss: 0.2732 - acc: 0.9487 - mDice: 0.7474 - val_loss: 0.7817 - val_acc: 0.9395 - val_mDice: 0.5620

Epoch 00070: val_mDice did not improve from 0.58077
Epoch 71/300
 - 14s - loss: 0.2711 - acc: 0.9490 - mDice: 0.7489 - val_loss: 0.7328 - val_acc: 0.9402 - val_mDice: 0.5717

Epoch 00071: val_mDice did not improve from 0.58077
Epoch 72/300
 - 14s - loss: 0.2708 - acc: 0.9491 - mDice: 0.7493 - val_loss: 0.7489 - val_acc: 0.9407 - val_mDice: 0.5743

Epoch 00072: val_mDice did not improve from 0.58077
Epoch 73/300
 - 14s - loss: 0.2698 - acc: 0.9491 - mDice: 0.7499 - val_loss: 0.7602 - val_acc: 0.9399 - val_mDice: 0.5614

Epoch 00073: val_mDice did not improve from 0.58077
Epoch 74/300
 - 13s - loss: 0.2715 - acc: 0.9489 - mDice: 0.7487 - val_loss: 0.7174 - val_acc: 0.9399 - val_mDice: 0.5733

Epoch 00074: val_mDice did not improve from 0.58077
Epoch 75/300
 - 14s - loss: 0.2708 - acc: 0.9491 - mDice: 0.7493 - val_loss: 0.7332 - val_acc: 0.9369 - val_mDice: 0.5705

Epoch 00075: val_mDice did not improve from 0.58077
Epoch 76/300
 - 13s - loss: 0.2685 - acc: 0.9493 - mDice: 0.7510 - val_loss: 0.7590 - val_acc: 0.9399 - val_mDice: 0.5655

Epoch 00076: val_mDice did not improve from 0.58077
Epoch 77/300
 - 13s - loss: 0.2671 - acc: 0.9494 - mDice: 0.7520 - val_loss: 0.7589 - val_acc: 0.9401 - val_mDice: 0.5664

Epoch 00077: val_mDice did not improve from 0.58077
Epoch 78/300
 - 14s - loss: 0.2675 - acc: 0.9494 - mDice: 0.7518 - val_loss: 0.7325 - val_acc: 0.9369 - val_mDice: 0.5752

Epoch 00078: val_mDice did not improve from 0.58077
Epoch 79/300
 - 14s - loss: 0.2679 - acc: 0.9493 - mDice: 0.7515 - val_loss: 0.7373 - val_acc: 0.9378 - val_mDice: 0.5678

Epoch 00079: val_mDice did not improve from 0.58077
Epoch 80/300
 - 13s - loss: 0.2664 - acc: 0.9495 - mDice: 0.7526 - val_loss: 0.7721 - val_acc: 0.9389 - val_mDice: 0.5636

Epoch 00080: val_mDice did not improve from 0.58077
Epoch 81/300
 - 13s - loss: 0.2661 - acc: 0.9494 - mDice: 0.7529 - val_loss: 0.7309 - val_acc: 0.9415 - val_mDice: 0.5697

Epoch 00081: val_mDice did not improve from 0.58077
Epoch 82/300
 - 13s - loss: 0.2648 - acc: 0.9495 - mDice: 0.7539 - val_loss: 0.7361 - val_acc: 0.9345 - val_mDice: 0.5644

Epoch 00082: val_mDice did not improve from 0.58077
Epoch 83/300
 - 14s - loss: 0.2650 - acc: 0.9496 - mDice: 0.7537 - val_loss: 0.7369 - val_acc: 0.9411 - val_mDice: 0.5614

Epoch 00083: val_mDice did not improve from 0.58077
Epoch 84/300
 - 14s - loss: 0.2640 - acc: 0.9496 - mDice: 0.7546 - val_loss: 0.7581 - val_acc: 0.9379 - val_mDice: 0.5598

Epoch 00084: val_mDice did not improve from 0.58077
Restoring model weights from the end of the best epoch
Epoch 00084: early stopping
{'val_loss': [1.4904984327463002, 1.1438924165872426, 0.8764292047573969, 0.8571304908165565, 0.8545245367747086, 0.8357669550638932, 0.8125594029059777, 0.8065735560197097, 0.8209793338408837, 0.7961704616363232, 0.7579213816386002, 0.764896436379506, 0.8112902710070977, 0.7635987171759973, 0.7684349761559413, 0.7565820721479563, 0.7628248058832608, 0.7921885710496169, 0.7949669429889092, 0.7684114965108725, 0.7713557825638697, 0.7811722984680762, 0.7899077786849096, 0.7643094933949984, 0.777659691297091, 0.7846709443972661, 0.7882802853217492, 0.7882764110198388, 0.7591633865466485, 0.7517038514980903, 0.7734026679625878, 0.779339285997244, 0.7603848301447355, 0.7817859053611755, 0.7646719263150141, 0.7441303982184484, 0.7618726881650778, 0.7585925093063941, 0.7821657841022198, 0.754689844755026, 0.7520734461454245, 0.7678368504230793, 0.7780737578868866, 0.7427038928637137, 0.7932285597691169, 0.7692862886648911, 0.7631454353149121, 0.7387100412295415, 0.761589146577395, 0.7452291135604565, 0.7624580997687119, 0.7917883762946496, 0.7789632976055145, 0.7738498243001791, 0.7640424622939184, 0.7414519351262313, 0.7729425155199491, 0.7512058248886695, 0.7742305856484634, 0.7657156953444848, 0.7659098551823542, 0.8133471333063566, 0.7523598074913025, 0.7542860874762902, 0.7677015157846304, 0.7554307557069339, 0.7633395493030548, 0.7612394025692573, 0.7726643154254327, 0.7817233755038335, 0.7328122028937707, 0.7489430216642526, 0.7601954868206611, 0.71742821427492, 0.7331697436479422, 0.7589720877317282, 0.7588838866123786, 0.732539367217284, 0.7372888349569761, 0.7721495926380157, 0.7309266924858093, 0.7361042339068192, 0.7368888969604785, 0.758106128527568], 'val_acc': [0.9033931424984565, 0.9051844661052411, 0.9164293523018177, 0.9243759146103492, 0.9281342304669894, 0.9392543503871331, 0.9366725316414466, 0.9391225920273707, 0.9416119410441472, 0.9412121062095349, 0.9411265552043915, 0.9407983628603128, 0.9366609408305242, 0.9423053539716281, 0.9351377533032343, 0.9390347760457259, 0.9363396603327531, 0.9377565727784083, 0.9405741393566132, 0.9372781010774466, 0.9377357501250047, 0.9372734817174765, 0.9411635467639337, 0.9331846283032343, 0.9382465642232162, 0.9394415502364819, 0.9420210558634537, 0.9417576079185193, 0.9348603762113131, 0.938782838674692, 0.9370330916001246, 0.9425388184877542, 0.9398761001917032, 0.93212140752719, 0.9400078585514655, 0.9376918604740729, 0.9406272952373211, 0.9406989583602319, 0.9392219621401566, 0.9403199094992417, 0.9419332490517542, 0.937460686151798, 0.9432345376564906, 0.9405256372231704, 0.9353573459845322, 0.9406249821186066, 0.9424995252719293, 0.9413785200852615, 0.9399824165380918, 0.9402274145529821, 0.9416743883719811, 0.9400309576438024, 0.9405718583327073, 0.9411404545490558, 0.9376155596513015, 0.9383136079861567, 0.9412721739365504, 0.9371787126247699, 0.9400956905805148, 0.9407705962657928, 0.9361940782803756, 0.9387250473866096, 0.9391942230554727, 0.9383228581685287, 0.94029445373095, 0.9407960657890027, 0.9433963413421924, 0.9411126902470222, 0.9395571442750784, 0.9394716230722574, 0.940202004634417, 0.9406989583602319, 0.9399107648776128, 0.9398737985354203, 0.9368782456104572, 0.9398691722979913, 0.9401164948940277, 0.9368643531432519, 0.9378443750051352, 0.9389376594470098, 0.941528742129986, 0.9345321701123164, 0.9411473549329318, 0.9379160518829639], 'val_mDice': [0.30715225350398284, 0.4287529905828146, 0.531026117503643, 0.546394406316372, 0.5276672301384119, 0.557364181543772, 0.5630667828596555, 0.567607252070537, 0.5705392188750781, 0.5641462275615106, 0.5766923433313003, 0.5772672464641241, 0.5652573292072003, 0.573623844064199, 0.5750969659823638, 0.5683253247004288, 0.5707430369578875, 0.5744121091870161, 0.5695322666030663, 0.5708471399087173, 0.5759000869897696, 0.5749401782567685, 0.5536468126452886, 0.5700573749267138, 0.5719976654419532, 0.5745604055432173, 0.5750407163913434, 0.5667510892336185, 0.565568385215906, 0.5790293480341251, 0.5708946356406579, 0.5663944674799075, 0.5752856106712267, 0.5567116370567908, 0.5776608024652188, 0.572786093617861, 0.574409330693575, 0.5772471319024379, 0.5663560181856155, 0.5731706951673214, 0.5764180800089469, 0.5624214430841116, 0.5635456706468875, 0.5807684631301806, 0.5546944814805801, 0.5720362875324029, 0.5719587063560119, 0.5804438424798158, 0.5697322642573943, 0.5753849716140673, 0.5646244674347914, 0.5511426805303647, 0.5588169957582767, 0.5695836864984952, 0.5645908484092126, 0.5694532772669425, 0.5663226040510031, 0.5708170934365346, 0.5685009463475301, 0.57330800478275, 0.5595366530693494, 0.5550390951908551, 0.5735482349991798, 0.5696588903665543, 0.5700597783120779, 0.5662094199886689, 0.5636511685756537, 0.573466861477265, 0.5675137934203331, 0.5619658114245305, 0.57168936672119, 0.574330214697581, 0.5613575348487267, 0.573252603984796, 0.5704560956129661, 0.5655444396229891, 0.5664467891821494, 0.5751668650370377, 0.5677996025635645, 0.5636129986781341, 0.5696629921977336, 0.5644434403914672, 0.5614239169427981, 0.5598336968284386], 'loss': [2.5250750561762283, 0.8553727259992575, 0.6279123462478932, 0.5544459975635413, 0.5086765898161243, 0.4774285894741731, 0.4559448578778112, 0.4390261244627643, 0.42557955548451704, 0.4119249888064731, 0.40336716305634573, 0.39320867420078415, 0.38587404520795493, 0.37884428728047875, 0.37400325163917153, 0.36906259521714196, 0.3644900856879566, 0.3590740035691297, 0.35517821647381415, 0.352130380993805, 0.3483200773128139, 0.34384334872627154, 0.34161090551515044, 0.33711588553129873, 0.3324679310340718, 0.33245666526971923, 0.3277191801351737, 0.3272445559595098, 0.3231475347963787, 0.3222398273121175, 0.31913785497486774, 0.31835844831076165, 0.31528538927253097, 0.3150679794314778, 0.3120246805421741, 0.310174414100742, 0.3088682399682868, 0.3082873423161305, 0.3062693305443455, 0.3039891815164658, 0.3012011542642819, 0.302169423349381, 0.30012510569181583, 0.2996841757228033, 0.29824114498876175, 0.29660884898977397, 0.29387492980671626, 0.29128150812189685, 0.2900741606288364, 0.29000906721973707, 0.2903544702488569, 0.2899882557162783, 0.28708564549104587, 0.28550571787294665, 0.28426324838555456, 0.2847314998418172, 0.2827397000000264, 0.28100676253131535, 0.2806492039448857, 0.2807763689180851, 0.2791342311522007, 0.2791031337934348, 0.2779758660503939, 0.2786958026955249, 0.2770705236963578, 0.2752754016631887, 0.2751224644425104, 0.27458515231167163, 0.27469150155691996, 0.27324208641672315, 0.27110778599397556, 0.2707581456424587, 0.26981047174042905, 0.2714516945203204, 0.2707505054736856, 0.268543015117961, 0.2671442171155906, 0.2674742381390001, 0.2678792353327464, 0.26641413825201193, 0.26608578753841877, 0.2647788564124077, 0.2649924271767247, 0.2639732027800334], 'acc': [0.7072722859997421, 0.8794480146907039, 0.8870733925076546, 0.898121130116848, 0.9151576884633048, 0.9288986976720811, 0.9328995037153618, 0.9345695812368178, 0.9355526675787027, 0.936895260223326, 0.9375476860135923, 0.9381508296742976, 0.9388456696086646, 0.9394501926911489, 0.9400195475655003, 0.9403575008330854, 0.9408157691187736, 0.9412042041342933, 0.9415372103263033, 0.9416534217875195, 0.9420625654399741, 0.9425256167359208, 0.9426525866018938, 0.9429830874748515, 0.9433320398250651, 0.9434521047543262, 0.9438821528325779, 0.9440106019799608, 0.944283775701455, 0.9444257930384278, 0.9446505273574725, 0.9447993505356178, 0.9449280695447752, 0.9450752301199854, 0.945323706140468, 0.9455022150812955, 0.9454182383045108, 0.9456608643184825, 0.9458040994196308, 0.9461300779200343, 0.9463448150454989, 0.946354036229811, 0.9464718018039439, 0.9464370611847893, 0.9464935517383657, 0.9465842440670776, 0.9469044383992835, 0.9472576902876434, 0.9471231465199815, 0.9472376927121873, 0.947274453677584, 0.947434759751288, 0.9475441228680469, 0.9476777854621449, 0.9478511740599986, 0.9478362940460029, 0.9480486107325516, 0.948150503396834, 0.9482164795049319, 0.9481757107414707, 0.9483226953996984, 0.9482737420824063, 0.9483096366613364, 0.9483222100091114, 0.9483605203654486, 0.9485733011634567, 0.9486200098213889, 0.9487421222248937, 0.9488234382367031, 0.948700864030505, 0.9490066040906807, 0.9490924710432762, 0.9490700082773214, 0.948877088359325, 0.9490577269829606, 0.9492560551635544, 0.9494267134421054, 0.9493793423991795, 0.9492894185047841, 0.949450751281275, 0.9494355407839034, 0.9495426875786578, 0.9495665849568955, 0.9496305868391026], 'mDice': [0.15097720023712902, 0.418854221587558, 0.5203291358273154, 0.5602265017439186, 0.5868470954639956, 0.605552345780905, 0.618600364442924, 0.6294070514851606, 0.6379939268009805, 0.6468786682181502, 0.6528301525300668, 0.659588864536113, 0.6645621567714437, 0.6692520718529228, 0.6729077759026976, 0.6763027403986367, 0.6794731918267852, 0.6831952651565303, 0.6860284202325105, 0.6881232370554515, 0.6909107061744253, 0.6941489710267329, 0.6958909726699186, 0.6990517550681027, 0.702390771163716, 0.7025117571917031, 0.705957445669117, 0.706355397896739, 0.7094097830740649, 0.7099661353680411, 0.7121862435125397, 0.7128504227967453, 0.7151562475381957, 0.7153208528477075, 0.7176348618406503, 0.7189962563012937, 0.7198530337714427, 0.7203320560778109, 0.7218138422020949, 0.7236106947846357, 0.7257343010797741, 0.72508027950886, 0.7266413183391705, 0.7269336010690084, 0.7279958158833156, 0.729225465108644, 0.7313037692846368, 0.733284718599155, 0.7341488996390255, 0.7342663318878014, 0.734034931759745, 0.7343822563638945, 0.7364792435369093, 0.7377122327607023, 0.7387692297966093, 0.7383509235585252, 0.7399260399252091, 0.7412556422369118, 0.7414542615364192, 0.7413829665919308, 0.742762726088528, 0.7426860462714415, 0.7435955783378195, 0.7428891016506218, 0.7443107862726719, 0.7456985780764669, 0.7458009133202161, 0.7462233561580278, 0.7461612417415797, 0.7473677068434771, 0.7489316120014017, 0.7492944792299201, 0.7499334565456158, 0.7487434279343678, 0.7492510369592934, 0.7509710987775426, 0.7520125040453451, 0.7518377965483665, 0.7515359412345193, 0.7526499137528365, 0.7529123318950639, 0.7539365737077375, 0.7537328299149743, 0.7545818918406342]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.34s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.15s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  1.97s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:21,  1.98s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:37,  1.83s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:37,  1.84s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<08:12,  1.75s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:41,  1.86s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:26,  1.82s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:40,  1.87s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:29,  1.84s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<08:47,  1.91s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:08,  1.99s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:53,  1.95s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<09:24,  2.07s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:58,  1.98s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:50,  1.96s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:16,  2.06s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:05,  2.03s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:35,  1.92s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:53,  2.00s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:35,  1.94s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:49,  2.00s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:59,  2.04s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:29,  1.94s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:23,  1.92s/it]predicting train subjects:   8%|▊         | 24/285 [00:45<07:59,  1.84s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:29,  1.96s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:51,  2.05s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:36,  2.00s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:30,  1.99s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:25,  1.98s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:41,  2.05s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:43,  2.06s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:17,  1.97s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:24,  2.00s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:30,  2.03s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:37,  2.07s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<08:26,  2.03s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<08:25,  2.04s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<08:25,  2.05s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:09,  1.99s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:24,  2.06s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<07:59,  1.97s/it]predicting train subjects:  15%|█▍        | 42/285 [01:22<07:59,  1.97s/it]predicting train subjects:  15%|█▌        | 43/285 [01:24<08:00,  1.99s/it]predicting train subjects:  15%|█▌        | 44/285 [01:26<08:13,  2.05s/it]predicting train subjects:  16%|█▌        | 45/285 [01:28<08:03,  2.01s/it]predicting train subjects:  16%|█▌        | 46/285 [01:30<08:12,  2.06s/it]predicting train subjects:  16%|█▋        | 47/285 [01:32<07:58,  2.01s/it]predicting train subjects:  17%|█▋        | 48/285 [01:34<08:07,  2.06s/it]predicting train subjects:  17%|█▋        | 49/285 [01:37<08:10,  2.08s/it]predicting train subjects:  18%|█▊        | 50/285 [01:39<07:59,  2.04s/it]predicting train subjects:  18%|█▊        | 51/285 [01:41<07:52,  2.02s/it]predicting train subjects:  18%|█▊        | 52/285 [01:42<07:34,  1.95s/it]predicting train subjects:  19%|█▊        | 53/285 [01:44<07:34,  1.96s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<07:47,  2.02s/it]predicting train subjects:  19%|█▉        | 55/285 [01:48<07:29,  1.95s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<07:34,  1.99s/it]predicting train subjects:  20%|██        | 57/285 [01:52<07:22,  1.94s/it]predicting train subjects:  20%|██        | 58/285 [01:54<07:33,  2.00s/it]predicting train subjects:  21%|██        | 59/285 [01:56<07:45,  2.06s/it]predicting train subjects:  21%|██        | 60/285 [01:58<07:37,  2.03s/it]predicting train subjects:  21%|██▏       | 61/285 [02:00<07:16,  1.95s/it]predicting train subjects:  22%|██▏       | 62/285 [02:02<07:20,  1.97s/it]predicting train subjects:  22%|██▏       | 63/285 [02:04<07:20,  1.98s/it]predicting train subjects:  22%|██▏       | 64/285 [02:06<07:03,  1.92s/it]predicting train subjects:  23%|██▎       | 65/285 [02:08<07:07,  1.94s/it]predicting train subjects:  23%|██▎       | 66/285 [02:10<07:06,  1.95s/it]predicting train subjects:  24%|██▎       | 67/285 [02:12<07:09,  1.97s/it]predicting train subjects:  24%|██▍       | 68/285 [02:14<06:56,  1.92s/it]predicting train subjects:  24%|██▍       | 69/285 [02:16<07:06,  1.98s/it]predicting train subjects:  25%|██▍       | 70/285 [02:18<07:07,  1.99s/it]predicting train subjects:  25%|██▍       | 71/285 [02:20<07:16,  2.04s/it]predicting train subjects:  25%|██▌       | 72/285 [02:22<06:59,  1.97s/it]predicting train subjects:  26%|██▌       | 73/285 [02:24<07:14,  2.05s/it]predicting train subjects:  26%|██▌       | 74/285 [02:26<07:15,  2.07s/it]predicting train subjects:  26%|██▋       | 75/285 [02:29<07:27,  2.13s/it]predicting train subjects:  27%|██▋       | 76/285 [02:31<07:36,  2.19s/it]predicting train subjects:  27%|██▋       | 77/285 [02:33<07:05,  2.05s/it]predicting train subjects:  27%|██▋       | 78/285 [02:34<06:50,  1.98s/it]predicting train subjects:  28%|██▊       | 79/285 [02:36<06:50,  1.99s/it]predicting train subjects:  28%|██▊       | 80/285 [02:38<06:51,  2.01s/it]predicting train subjects:  28%|██▊       | 81/285 [02:40<06:49,  2.01s/it]predicting train subjects:  29%|██▉       | 82/285 [02:43<07:01,  2.07s/it]predicting train subjects:  29%|██▉       | 83/285 [02:45<07:02,  2.09s/it]predicting train subjects:  29%|██▉       | 84/285 [02:47<06:52,  2.05s/it]predicting train subjects:  30%|██▉       | 85/285 [02:49<07:09,  2.15s/it]predicting train subjects:  30%|███       | 86/285 [02:51<06:55,  2.09s/it]predicting train subjects:  31%|███       | 87/285 [02:53<06:51,  2.08s/it]predicting train subjects:  31%|███       | 88/285 [02:55<06:41,  2.04s/it]predicting train subjects:  31%|███       | 89/285 [02:57<06:42,  2.06s/it]predicting train subjects:  32%|███▏      | 90/285 [02:59<06:40,  2.06s/it]predicting train subjects:  32%|███▏      | 91/285 [03:01<06:21,  1.97s/it]predicting train subjects:  32%|███▏      | 92/285 [03:03<06:25,  2.00s/it]predicting train subjects:  33%|███▎      | 93/285 [03:05<06:13,  1.94s/it]predicting train subjects:  33%|███▎      | 94/285 [03:07<06:17,  1.98s/it]predicting train subjects:  33%|███▎      | 95/285 [03:09<06:22,  2.01s/it]predicting train subjects:  34%|███▎      | 96/285 [03:11<06:22,  2.03s/it]predicting train subjects:  34%|███▍      | 97/285 [03:13<06:08,  1.96s/it]predicting train subjects:  34%|███▍      | 98/285 [03:15<06:00,  1.93s/it]predicting train subjects:  35%|███▍      | 99/285 [03:17<06:06,  1.97s/it]predicting train subjects:  35%|███▌      | 100/285 [03:19<06:07,  1.99s/it]predicting train subjects:  35%|███▌      | 101/285 [03:21<05:56,  1.94s/it]predicting train subjects:  36%|███▌      | 102/285 [03:22<05:46,  1.89s/it]predicting train subjects:  36%|███▌      | 103/285 [03:24<05:43,  1.89s/it]predicting train subjects:  36%|███▋      | 104/285 [03:26<05:45,  1.91s/it]predicting train subjects:  37%|███▋      | 105/285 [03:28<05:46,  1.93s/it]predicting train subjects:  37%|███▋      | 106/285 [03:30<05:40,  1.90s/it]predicting train subjects:  38%|███▊      | 107/285 [03:32<05:43,  1.93s/it]predicting train subjects:  38%|███▊      | 108/285 [03:34<05:37,  1.91s/it]predicting train subjects:  38%|███▊      | 109/285 [03:36<05:52,  2.01s/it]predicting train subjects:  39%|███▊      | 110/285 [03:38<05:47,  1.99s/it]predicting train subjects:  39%|███▉      | 111/285 [03:40<05:28,  1.89s/it]predicting train subjects:  39%|███▉      | 112/285 [03:42<05:29,  1.91s/it]predicting train subjects:  40%|███▉      | 113/285 [03:44<05:38,  1.97s/it]predicting train subjects:  40%|████      | 114/285 [03:46<05:47,  2.03s/it]predicting train subjects:  40%|████      | 115/285 [03:48<05:37,  1.98s/it]predicting train subjects:  41%|████      | 116/285 [03:50<05:35,  1.98s/it]predicting train subjects:  41%|████      | 117/285 [03:52<05:24,  1.93s/it]predicting train subjects:  41%|████▏     | 118/285 [03:54<05:16,  1.90s/it]predicting train subjects:  42%|████▏     | 119/285 [03:56<05:21,  1.94s/it]predicting train subjects:  42%|████▏     | 120/285 [03:57<05:13,  1.90s/it]predicting train subjects:  42%|████▏     | 121/285 [03:59<05:06,  1.87s/it]predicting train subjects:  43%|████▎     | 122/285 [04:01<04:52,  1.80s/it]predicting train subjects:  43%|████▎     | 123/285 [04:02<04:43,  1.75s/it]predicting train subjects:  44%|████▎     | 124/285 [04:04<04:44,  1.77s/it]predicting train subjects:  44%|████▍     | 125/285 [04:06<04:36,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [04:08<04:37,  1.75s/it]predicting train subjects:  45%|████▍     | 127/285 [04:09<04:29,  1.70s/it]predicting train subjects:  45%|████▍     | 128/285 [04:11<04:30,  1.73s/it]predicting train subjects:  45%|████▌     | 129/285 [04:13<04:37,  1.78s/it]predicting train subjects:  46%|████▌     | 130/285 [04:15<04:36,  1.78s/it]predicting train subjects:  46%|████▌     | 131/285 [04:16<04:30,  1.76s/it]predicting train subjects:  46%|████▋     | 132/285 [04:18<04:22,  1.72s/it]predicting train subjects:  47%|████▋     | 133/285 [04:20<04:24,  1.74s/it]predicting train subjects:  47%|████▋     | 134/285 [04:21<04:14,  1.69s/it]predicting train subjects:  47%|████▋     | 135/285 [04:23<04:07,  1.65s/it]predicting train subjects:  48%|████▊     | 136/285 [04:25<04:08,  1.67s/it]predicting train subjects:  48%|████▊     | 137/285 [04:26<04:11,  1.70s/it]predicting train subjects:  48%|████▊     | 138/285 [04:28<04:01,  1.65s/it]predicting train subjects:  49%|████▉     | 139/285 [04:30<04:00,  1.65s/it]predicting train subjects:  49%|████▉     | 140/285 [04:32<04:11,  1.73s/it]predicting train subjects:  49%|████▉     | 141/285 [04:33<04:06,  1.71s/it]predicting train subjects:  50%|████▉     | 142/285 [04:35<04:04,  1.71s/it]predicting train subjects:  50%|█████     | 143/285 [04:37<04:05,  1.73s/it]predicting train subjects:  51%|█████     | 144/285 [04:38<04:05,  1.74s/it]predicting train subjects:  51%|█████     | 145/285 [04:40<03:57,  1.70s/it]predicting train subjects:  51%|█████     | 146/285 [04:42<04:06,  1.78s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:44<03:59,  1.74s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:46<04:07,  1.80s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:47<04:01,  1.78s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:49<03:51,  1.71s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:51<03:48,  1.71s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:52<03:47,  1.71s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:54<03:48,  1.73s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:56<03:56,  1.81s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:58<03:52,  1.79s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:00<03:52,  1.81s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:01<03:46,  1.77s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:03<03:44,  1.77s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:05<03:33,  1.69s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:06<03:31,  1.69s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:08<03:31,  1.71s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:10<03:27,  1.69s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:12<03:30,  1.73s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:13<03:29,  1.73s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:15<03:28,  1.74s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:17<03:34,  1.80s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:19<03:30,  1.78s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:20<03:28,  1.78s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:22<03:24,  1.76s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:24<03:22,  1.76s/it]predicting train subjects:  60%|██████    | 171/285 [05:26<03:21,  1.77s/it]predicting train subjects:  60%|██████    | 172/285 [05:27<03:18,  1.75s/it]predicting train subjects:  61%|██████    | 173/285 [05:29<03:15,  1.75s/it]predicting train subjects:  61%|██████    | 174/285 [05:31<03:08,  1.69s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:33<03:14,  1.77s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:35<03:19,  1.83s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:36<03:16,  1.82s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:38<03:05,  1.74s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:40<02:57,  1.67s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:41<03:02,  1.74s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:43<03:01,  1.74s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:45<03:00,  1.75s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:46<02:51,  1.68s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:48<02:46,  1.65s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:50<02:39,  1.60s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:52<02:49,  1.71s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:54<02:58,  1.82s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:55<02:58,  1.84s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:57<02:43,  1.71s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:58<02:37,  1.65s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:00<02:38,  1.69s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:02<02:37,  1.69s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:03<02:26,  1.60s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:05<02:23,  1.58s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:06<02:19,  1.55s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:08<02:27,  1.66s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:10<02:33,  1.74s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:12<02:36,  1.80s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:13<02:24,  1.68s/it]predicting train subjects:  70%|███████   | 200/285 [06:15<02:20,  1.65s/it]predicting train subjects:  71%|███████   | 201/285 [06:17<02:22,  1.70s/it]predicting train subjects:  71%|███████   | 202/285 [06:19<02:21,  1.71s/it]predicting train subjects:  71%|███████   | 203/285 [06:20<02:22,  1.74s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:22<02:15,  1.67s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:23<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:25<02:04,  1.57s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:27<02:11,  1.69s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:29<02:16,  1.77s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:31<02:20,  1.85s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:32<02:07,  1.70s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:34<02:01,  1.65s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:35<02:01,  1.66s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:37<02:00,  1.68s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:39<01:55,  1.63s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:41<02:01,  1.74s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:42<01:55,  1.67s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:44<01:59,  1.75s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:46<02:01,  1.82s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:48<02:04,  1.88s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:49<01:53,  1.75s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:51<01:49,  1.72s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:53<01:49,  1.73s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:54<01:40,  1.62s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:56<01:36,  1.58s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:57<01:31,  1.52s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:59<01:37,  1.65s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:01<01:42,  1.76s/it]predicting train subjects:  80%|████████  | 228/285 [07:03<01:45,  1.84s/it]predicting train subjects:  80%|████████  | 229/285 [07:05<01:41,  1.81s/it]predicting train subjects:  81%|████████  | 230/285 [07:06<01:35,  1.74s/it]predicting train subjects:  81%|████████  | 231/285 [07:08<01:30,  1.68s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:10<01:29,  1.69s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:11<01:26,  1.66s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:13<01:28,  1.73s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:15<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:17<01:24,  1.73s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:19<01:27,  1.82s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:21<01:26,  1.85s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:22<01:24,  1.84s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:24<01:19,  1.76s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:26<01:15,  1.71s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:27<01:11,  1.65s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:28<01:06,  1.59s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:30<01:08,  1.68s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:32<01:04,  1.61s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:34<01:06,  1.69s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:36<01:06,  1.75s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:37<01:05,  1.77s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:39<01:01,  1.71s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:41<00:58,  1.66s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:42<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:43<00:51,  1.56s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:45<00:53,  1.66s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:47<00:53,  1.72s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:49<00:51,  1.72s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:50<00:47,  1.62s/it]predicting train subjects:  90%|█████████ | 257/285 [07:52<00:44,  1.61s/it]predicting train subjects:  91%|█████████ | 258/285 [07:54<00:45,  1.67s/it]predicting train subjects:  91%|█████████ | 259/285 [07:55<00:44,  1.71s/it]predicting train subjects:  91%|█████████ | 260/285 [07:57<00:41,  1.67s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:59<00:39,  1.63s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:00<00:36,  1.60s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:02<00:35,  1.59s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:04<00:35,  1.70s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:06<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:07<00:32,  1.71s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:09<00:29,  1.66s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:11<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:12<00:27,  1.74s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:14<00:24,  1.65s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:15<00:22,  1.60s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:17<00:21,  1.66s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:19<00:19,  1.58s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:20<00:17,  1.55s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:22<00:16,  1.66s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:24<00:15,  1.76s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:25<00:13,  1.70s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:27<00:11,  1.65s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:29<00:10,  1.67s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:30<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:32<00:06,  1.56s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:33<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:35<00:03,  1.65s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:37<00:01,  1.74s/it]predicting train subjects: 100%|██████████| 285/285 [08:39<00:00,  1.82s/it]mkdir: cannot create directory ‘/array/ssd/msmajdi/experiments/keras/exp7/results/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a’: File exists

Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<09:08,  1.93s/it]Loading train:   1%|          | 2/285 [00:03<08:24,  1.78s/it]Loading train:   1%|          | 3/285 [00:04<08:00,  1.71s/it]Loading train:   1%|▏         | 4/285 [00:06<07:27,  1.59s/it]Loading train:   2%|▏         | 5/285 [00:08<07:47,  1.67s/it]Loading train:   2%|▏         | 6/285 [00:09<07:20,  1.58s/it]Loading train:   2%|▏         | 7/285 [00:11<07:30,  1.62s/it]Loading train:   3%|▎         | 8/285 [00:12<07:07,  1.54s/it]Loading train:   3%|▎         | 9/285 [00:14<07:24,  1.61s/it]Loading train:   4%|▎         | 10/285 [00:15<07:09,  1.56s/it]Loading train:   4%|▍         | 11/285 [00:16<06:41,  1.46s/it]Loading train:   4%|▍         | 12/285 [00:18<06:25,  1.41s/it]Loading train:   5%|▍         | 13/285 [00:19<05:52,  1.30s/it]Loading train:   5%|▍         | 14/285 [00:20<05:51,  1.30s/it]Loading train:   5%|▌         | 15/285 [00:21<05:33,  1.24s/it]Loading train:   6%|▌         | 16/285 [00:22<05:21,  1.19s/it]Loading train:   6%|▌         | 17/285 [00:23<05:03,  1.13s/it]Loading train:   6%|▋         | 18/285 [00:24<05:02,  1.13s/it]Loading train:   7%|▋         | 19/285 [00:25<04:52,  1.10s/it]Loading train:   7%|▋         | 20/285 [00:27<05:08,  1.16s/it]Loading train:   7%|▋         | 21/285 [00:28<05:23,  1.22s/it]Loading train:   8%|▊         | 22/285 [00:29<05:05,  1.16s/it]Loading train:   8%|▊         | 23/285 [00:30<05:11,  1.19s/it]Loading train:   8%|▊         | 24/285 [00:31<04:55,  1.13s/it]Loading train:   9%|▉         | 25/285 [00:32<04:52,  1.12s/it]Loading train:   9%|▉         | 26/285 [00:34<05:01,  1.16s/it]Loading train:   9%|▉         | 27/285 [00:34<04:27,  1.04s/it]Loading train:  10%|▉         | 28/285 [00:35<04:23,  1.02s/it]Loading train:  10%|█         | 29/285 [00:37<04:37,  1.08s/it]Loading train:  11%|█         | 30/285 [00:38<04:46,  1.12s/it]Loading train:  11%|█         | 31/285 [00:39<04:45,  1.12s/it]Loading train:  11%|█         | 32/285 [00:40<04:26,  1.05s/it]Loading train:  12%|█▏        | 33/285 [00:41<04:33,  1.09s/it]Loading train:  12%|█▏        | 34/285 [00:42<04:34,  1.09s/it]Loading train:  12%|█▏        | 35/285 [00:43<04:38,  1.11s/it]Loading train:  13%|█▎        | 36/285 [00:44<04:37,  1.12s/it]Loading train:  13%|█▎        | 37/285 [00:46<04:34,  1.11s/it]Loading train:  13%|█▎        | 38/285 [00:47<04:40,  1.14s/it]Loading train:  14%|█▎        | 39/285 [00:48<04:37,  1.13s/it]Loading train:  14%|█▍        | 40/285 [00:49<04:31,  1.11s/it]Loading train:  14%|█▍        | 41/285 [00:50<04:18,  1.06s/it]Loading train:  15%|█▍        | 42/285 [00:51<04:14,  1.05s/it]Loading train:  15%|█▌        | 43/285 [00:52<04:22,  1.08s/it]Loading train:  15%|█▌        | 44/285 [00:53<04:25,  1.10s/it]Loading train:  16%|█▌        | 45/285 [00:54<04:12,  1.05s/it]Loading train:  16%|█▌        | 46/285 [00:55<04:21,  1.09s/it]Loading train:  16%|█▋        | 47/285 [00:56<04:15,  1.07s/it]Loading train:  17%|█▋        | 48/285 [00:57<04:17,  1.09s/it]Loading train:  17%|█▋        | 49/285 [00:59<04:32,  1.16s/it]Loading train:  18%|█▊        | 50/285 [01:00<04:37,  1.18s/it]Loading train:  18%|█▊        | 51/285 [01:01<04:49,  1.24s/it]Loading train:  18%|█▊        | 52/285 [01:02<04:35,  1.18s/it]Loading train:  19%|█▊        | 53/285 [01:04<04:51,  1.26s/it]Loading train:  19%|█▉        | 54/285 [01:06<05:24,  1.40s/it]Loading train:  19%|█▉        | 55/285 [01:07<04:49,  1.26s/it]Loading train:  20%|█▉        | 56/285 [01:08<04:34,  1.20s/it]Loading train:  20%|██        | 57/285 [01:09<04:28,  1.18s/it]Loading train:  20%|██        | 58/285 [01:10<04:22,  1.16s/it]Loading train:  21%|██        | 59/285 [01:11<04:25,  1.17s/it]Loading train:  21%|██        | 60/285 [01:12<04:25,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:13<04:15,  1.14s/it]Loading train:  22%|██▏       | 62/285 [01:14<04:17,  1.15s/it]Loading train:  22%|██▏       | 63/285 [01:16<04:23,  1.19s/it]Loading train:  22%|██▏       | 64/285 [01:17<04:52,  1.32s/it]Loading train:  23%|██▎       | 65/285 [01:19<05:09,  1.41s/it]Loading train:  23%|██▎       | 66/285 [01:21<05:17,  1.45s/it]Loading train:  24%|██▎       | 67/285 [01:22<05:03,  1.39s/it]Loading train:  24%|██▍       | 68/285 [01:23<04:35,  1.27s/it]Loading train:  24%|██▍       | 69/285 [01:24<04:20,  1.21s/it]Loading train:  25%|██▍       | 70/285 [01:25<04:15,  1.19s/it]Loading train:  25%|██▍       | 71/285 [01:26<04:21,  1.22s/it]Loading train:  25%|██▌       | 72/285 [01:27<04:01,  1.13s/it]Loading train:  26%|██▌       | 73/285 [01:28<04:09,  1.17s/it]Loading train:  26%|██▌       | 74/285 [01:30<03:59,  1.14s/it]Loading train:  26%|██▋       | 75/285 [01:31<04:15,  1.22s/it]Loading train:  27%|██▋       | 76/285 [01:32<04:10,  1.20s/it]Loading train:  27%|██▋       | 77/285 [01:33<03:51,  1.11s/it]Loading train:  27%|██▋       | 78/285 [01:34<03:41,  1.07s/it]Loading train:  28%|██▊       | 79/285 [01:35<03:40,  1.07s/it]Loading train:  28%|██▊       | 80/285 [01:36<04:00,  1.17s/it]Loading train:  28%|██▊       | 81/285 [01:37<03:48,  1.12s/it]Loading train:  29%|██▉       | 82/285 [01:39<03:51,  1.14s/it]Loading train:  29%|██▉       | 83/285 [01:40<04:00,  1.19s/it]Loading train:  29%|██▉       | 84/285 [01:41<03:51,  1.15s/it]Loading train:  30%|██▉       | 85/285 [01:42<03:50,  1.15s/it]Loading train:  30%|███       | 86/285 [01:43<03:52,  1.17s/it]Loading train:  31%|███       | 87/285 [01:45<03:56,  1.19s/it]Loading train:  31%|███       | 88/285 [01:45<03:35,  1.09s/it]Loading train:  31%|███       | 89/285 [01:46<03:22,  1.03s/it]Loading train:  32%|███▏      | 90/285 [01:47<03:19,  1.02s/it]Loading train:  32%|███▏      | 91/285 [01:48<03:15,  1.01s/it]Loading train:  32%|███▏      | 92/285 [01:50<03:24,  1.06s/it]Loading train:  33%|███▎      | 93/285 [01:51<03:20,  1.04s/it]Loading train:  33%|███▎      | 94/285 [01:52<03:22,  1.06s/it]Loading train:  33%|███▎      | 95/285 [01:53<03:27,  1.09s/it]Loading train:  34%|███▎      | 96/285 [01:54<03:23,  1.08s/it]Loading train:  34%|███▍      | 97/285 [01:55<03:20,  1.07s/it]Loading train:  34%|███▍      | 98/285 [01:56<03:21,  1.08s/it]Loading train:  35%|███▍      | 99/285 [01:57<03:11,  1.03s/it]Loading train:  35%|███▌      | 100/285 [01:58<03:17,  1.07s/it]Loading train:  35%|███▌      | 101/285 [01:59<03:14,  1.05s/it]Loading train:  36%|███▌      | 102/285 [02:00<03:14,  1.06s/it]Loading train:  36%|███▌      | 103/285 [02:01<03:23,  1.12s/it]Loading train:  36%|███▋      | 104/285 [02:03<03:22,  1.12s/it]Loading train:  37%|███▋      | 105/285 [02:04<03:21,  1.12s/it]Loading train:  37%|███▋      | 106/285 [02:05<03:09,  1.06s/it]Loading train:  38%|███▊      | 107/285 [02:06<03:13,  1.09s/it]Loading train:  38%|███▊      | 108/285 [02:07<03:07,  1.06s/it]Loading train:  38%|███▊      | 109/285 [02:08<03:01,  1.03s/it]Loading train:  39%|███▊      | 110/285 [02:09<03:01,  1.04s/it]Loading train:  39%|███▉      | 111/285 [02:10<02:56,  1.02s/it]Loading train:  39%|███▉      | 112/285 [02:11<02:55,  1.01s/it]Loading train:  40%|███▉      | 113/285 [02:12<02:59,  1.05s/it]Loading train:  40%|████      | 114/285 [02:13<02:58,  1.04s/it]Loading train:  40%|████      | 115/285 [02:14<03:01,  1.07s/it]Loading train:  41%|████      | 116/285 [02:15<03:07,  1.11s/it]Loading train:  41%|████      | 117/285 [02:16<03:08,  1.12s/it]Loading train:  41%|████▏     | 118/285 [02:17<03:01,  1.09s/it]Loading train:  42%|████▏     | 119/285 [02:19<03:16,  1.18s/it]Loading train:  42%|████▏     | 120/285 [02:20<03:00,  1.09s/it]Loading train:  42%|████▏     | 121/285 [02:22<03:38,  1.34s/it]Loading train:  43%|████▎     | 122/285 [02:23<03:32,  1.30s/it]Loading train:  43%|████▎     | 123/285 [02:24<03:48,  1.41s/it]Loading train:  44%|████▎     | 124/285 [02:26<03:33,  1.33s/it]Loading train:  44%|████▍     | 125/285 [02:26<03:11,  1.20s/it]Loading train:  44%|████▍     | 126/285 [02:27<02:59,  1.13s/it]Loading train:  45%|████▍     | 127/285 [02:28<02:53,  1.10s/it]Loading train:  45%|████▍     | 128/285 [02:29<02:47,  1.07s/it]Loading train:  45%|████▌     | 129/285 [02:30<02:39,  1.02s/it]Loading train:  46%|████▌     | 130/285 [02:31<02:32,  1.02it/s]Loading train:  46%|████▌     | 131/285 [02:32<02:27,  1.05it/s]Loading train:  46%|████▋     | 132/285 [02:33<02:32,  1.00it/s]Loading train:  47%|████▋     | 133/285 [02:34<02:35,  1.03s/it]Loading train:  47%|████▋     | 134/285 [02:35<02:26,  1.03it/s]Loading train:  47%|████▋     | 135/285 [02:36<02:26,  1.02it/s]Loading train:  48%|████▊     | 136/285 [02:37<02:20,  1.06it/s]Loading train:  48%|████▊     | 137/285 [02:38<02:29,  1.01s/it]Loading train:  48%|████▊     | 138/285 [02:39<02:33,  1.05s/it]Loading train:  49%|████▉     | 139/285 [02:40<02:25,  1.00it/s]Loading train:  49%|████▉     | 140/285 [02:41<02:26,  1.01s/it]Loading train:  49%|████▉     | 141/285 [02:42<02:21,  1.02it/s]Loading train:  50%|████▉     | 142/285 [02:43<02:29,  1.04s/it]Loading train:  50%|█████     | 143/285 [02:44<02:21,  1.00it/s]Loading train:  51%|█████     | 144/285 [02:45<02:22,  1.01s/it]Loading train:  51%|█████     | 145/285 [02:46<02:15,  1.03it/s]Loading train:  51%|█████     | 146/285 [02:47<02:21,  1.02s/it]Loading train:  52%|█████▏    | 147/285 [02:48<02:15,  1.02it/s]Loading train:  52%|█████▏    | 148/285 [02:49<02:15,  1.01it/s]Loading train:  52%|█████▏    | 149/285 [02:50<02:15,  1.00it/s]Loading train:  53%|█████▎    | 150/285 [02:51<02:09,  1.04it/s]Loading train:  53%|█████▎    | 151/285 [02:52<02:06,  1.06it/s]Loading train:  53%|█████▎    | 152/285 [02:53<02:02,  1.08it/s]Loading train:  54%|█████▎    | 153/285 [02:54<01:59,  1.11it/s]Loading train:  54%|█████▍    | 154/285 [02:55<02:03,  1.06it/s]Loading train:  54%|█████▍    | 155/285 [02:56<01:59,  1.09it/s]Loading train:  55%|█████▍    | 156/285 [02:57<01:59,  1.08it/s]Loading train:  55%|█████▌    | 157/285 [02:58<02:01,  1.06it/s]Loading train:  55%|█████▌    | 158/285 [02:59<02:04,  1.02it/s]Loading train:  56%|█████▌    | 159/285 [03:00<02:02,  1.03it/s]Loading train:  56%|█████▌    | 160/285 [03:01<01:59,  1.05it/s]Loading train:  56%|█████▋    | 161/285 [03:02<02:01,  1.02it/s]Loading train:  57%|█████▋    | 162/285 [03:02<01:56,  1.06it/s]Loading train:  57%|█████▋    | 163/285 [03:03<01:55,  1.06it/s]Loading train:  58%|█████▊    | 164/285 [03:04<01:55,  1.05it/s]Loading train:  58%|█████▊    | 165/285 [03:05<01:55,  1.04it/s]Loading train:  58%|█████▊    | 166/285 [03:06<01:54,  1.04it/s]Loading train:  59%|█████▊    | 167/285 [03:07<01:53,  1.04it/s]Loading train:  59%|█████▉    | 168/285 [03:08<01:51,  1.05it/s]Loading train:  59%|█████▉    | 169/285 [03:09<01:48,  1.07it/s]Loading train:  60%|█████▉    | 170/285 [03:10<01:42,  1.12it/s]Loading train:  60%|██████    | 171/285 [03:11<01:46,  1.07it/s]Loading train:  60%|██████    | 172/285 [03:12<01:50,  1.02it/s]Loading train:  61%|██████    | 173/285 [03:13<01:47,  1.05it/s]Loading train:  61%|██████    | 174/285 [03:14<01:43,  1.07it/s]Loading train:  61%|██████▏   | 175/285 [03:15<01:46,  1.03it/s]Loading train:  62%|██████▏   | 176/285 [03:16<01:44,  1.04it/s]Loading train:  62%|██████▏   | 177/285 [03:17<01:52,  1.04s/it]Loading train:  62%|██████▏   | 178/285 [03:18<01:49,  1.02s/it]Loading train:  63%|██████▎   | 179/285 [03:19<01:43,  1.02it/s]Loading train:  63%|██████▎   | 180/285 [03:20<01:48,  1.03s/it]Loading train:  64%|██████▎   | 181/285 [03:21<01:49,  1.06s/it]Loading train:  64%|██████▍   | 182/285 [03:22<01:46,  1.03s/it]Loading train:  64%|██████▍   | 183/285 [03:23<01:40,  1.02it/s]Loading train:  65%|██████▍   | 184/285 [03:24<01:39,  1.01it/s]Loading train:  65%|██████▍   | 185/285 [03:25<01:32,  1.08it/s]Loading train:  65%|██████▌   | 186/285 [03:26<01:37,  1.02it/s]Loading train:  66%|██████▌   | 187/285 [03:27<01:36,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:28<01:40,  1.04s/it]Loading train:  66%|██████▋   | 189/285 [03:29<01:37,  1.01s/it]Loading train:  67%|██████▋   | 190/285 [03:30<01:32,  1.02it/s]Loading train:  67%|██████▋   | 191/285 [03:31<01:32,  1.01it/s]Loading train:  67%|██████▋   | 192/285 [03:32<01:31,  1.02it/s]Loading train:  68%|██████▊   | 193/285 [03:33<01:29,  1.03it/s]Loading train:  68%|██████▊   | 194/285 [03:34<01:27,  1.04it/s]Loading train:  68%|██████▊   | 195/285 [03:35<01:25,  1.05it/s]Loading train:  69%|██████▉   | 196/285 [03:36<01:29,  1.01s/it]Loading train:  69%|██████▉   | 197/285 [03:37<01:37,  1.11s/it]Loading train:  69%|██████▉   | 198/285 [03:38<01:35,  1.10s/it]Loading train:  70%|██████▉   | 199/285 [03:39<01:26,  1.01s/it]Loading train:  70%|███████   | 200/285 [03:40<01:31,  1.08s/it]Loading train:  71%|███████   | 201/285 [03:42<01:39,  1.18s/it]Loading train:  71%|███████   | 202/285 [03:43<01:32,  1.11s/it]Loading train:  71%|███████   | 203/285 [03:44<01:27,  1.07s/it]Loading train:  72%|███████▏  | 204/285 [03:45<01:27,  1.07s/it]Loading train:  72%|███████▏  | 205/285 [03:46<01:30,  1.13s/it]Loading train:  72%|███████▏  | 206/285 [03:47<01:24,  1.07s/it]Loading train:  73%|███████▎  | 207/285 [03:48<01:25,  1.09s/it]Loading train:  73%|███████▎  | 208/285 [03:49<01:24,  1.09s/it]Loading train:  73%|███████▎  | 209/285 [03:50<01:23,  1.10s/it]Loading train:  74%|███████▎  | 210/285 [03:51<01:16,  1.02s/it]Loading train:  74%|███████▍  | 211/285 [03:52<01:10,  1.05it/s]Loading train:  74%|███████▍  | 212/285 [03:53<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:54<01:16,  1.07s/it]Loading train:  75%|███████▌  | 214/285 [03:55<01:12,  1.03s/it]Loading train:  75%|███████▌  | 215/285 [03:57<01:23,  1.19s/it]Loading train:  76%|███████▌  | 216/285 [03:58<01:18,  1.14s/it]Loading train:  76%|███████▌  | 217/285 [03:59<01:20,  1.19s/it]Loading train:  76%|███████▋  | 218/285 [04:00<01:15,  1.12s/it]Loading train:  77%|███████▋  | 219/285 [04:01<01:11,  1.09s/it]Loading train:  77%|███████▋  | 220/285 [04:02<01:06,  1.02s/it]Loading train:  78%|███████▊  | 221/285 [04:03<01:02,  1.03it/s]Loading train:  78%|███████▊  | 222/285 [04:04<01:01,  1.02it/s]Loading train:  78%|███████▊  | 223/285 [04:05<01:00,  1.03it/s]Loading train:  79%|███████▊  | 224/285 [04:06<00:58,  1.04it/s]Loading train:  79%|███████▉  | 225/285 [04:07<00:57,  1.03it/s]Loading train:  79%|███████▉  | 226/285 [04:08<00:59,  1.01s/it]Loading train:  80%|███████▉  | 227/285 [04:09<01:02,  1.07s/it]Loading train:  80%|████████  | 228/285 [04:10<01:01,  1.08s/it]Loading train:  80%|████████  | 229/285 [04:11<00:59,  1.06s/it]Loading train:  81%|████████  | 230/285 [04:12<00:56,  1.02s/it]Loading train:  81%|████████  | 231/285 [04:13<00:54,  1.00s/it]Loading train:  81%|████████▏ | 232/285 [04:14<00:52,  1.00it/s]Loading train:  82%|████████▏ | 233/285 [04:15<00:51,  1.01it/s]Loading train:  82%|████████▏ | 234/285 [04:16<00:55,  1.08s/it]Loading train:  82%|████████▏ | 235/285 [04:17<00:53,  1.07s/it]Loading train:  83%|████████▎ | 236/285 [04:18<00:53,  1.08s/it]Loading train:  83%|████████▎ | 237/285 [04:19<00:53,  1.11s/it]Loading train:  84%|████████▎ | 238/285 [04:21<00:51,  1.10s/it]Loading train:  84%|████████▍ | 239/285 [04:22<00:50,  1.09s/it]Loading train:  84%|████████▍ | 240/285 [04:23<00:48,  1.09s/it]Loading train:  85%|████████▍ | 241/285 [04:24<00:44,  1.01s/it]Loading train:  85%|████████▍ | 242/285 [04:24<00:42,  1.01it/s]Loading train:  85%|████████▌ | 243/285 [04:26<00:43,  1.03s/it]Loading train:  86%|████████▌ | 244/285 [04:27<00:45,  1.12s/it]Loading train:  86%|████████▌ | 245/285 [04:28<00:42,  1.05s/it]Loading train:  86%|████████▋ | 246/285 [04:29<00:43,  1.12s/it]Loading train:  87%|████████▋ | 247/285 [04:30<00:44,  1.18s/it]Loading train:  87%|████████▋ | 248/285 [04:31<00:41,  1.13s/it]Loading train:  87%|████████▋ | 249/285 [04:32<00:38,  1.07s/it]Loading train:  88%|████████▊ | 250/285 [04:33<00:36,  1.06s/it]Loading train:  88%|████████▊ | 251/285 [04:34<00:34,  1.03s/it]Loading train:  88%|████████▊ | 252/285 [04:35<00:32,  1.01it/s]Loading train:  89%|████████▉ | 253/285 [04:36<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [04:38<00:34,  1.11s/it]Loading train:  89%|████████▉ | 255/285 [04:39<00:30,  1.03s/it]Loading train:  90%|████████▉ | 256/285 [04:39<00:27,  1.06it/s]Loading train:  90%|█████████ | 257/285 [04:40<00:27,  1.00it/s]Loading train:  91%|█████████ | 258/285 [04:42<00:30,  1.12s/it]Loading train:  91%|█████████ | 259/285 [04:43<00:27,  1.06s/it]Loading train:  91%|█████████ | 260/285 [04:44<00:25,  1.02s/it]Loading train:  92%|█████████▏| 261/285 [04:45<00:23,  1.03it/s]Loading train:  92%|█████████▏| 262/285 [04:45<00:21,  1.09it/s]Loading train:  92%|█████████▏| 263/285 [04:46<00:20,  1.07it/s]Loading train:  93%|█████████▎| 264/285 [04:48<00:23,  1.10s/it]Loading train:  93%|█████████▎| 265/285 [04:49<00:22,  1.14s/it]Loading train:  93%|█████████▎| 266/285 [04:50<00:20,  1.07s/it]Loading train:  94%|█████████▎| 267/285 [04:51<00:18,  1.02s/it]Loading train:  94%|█████████▍| 268/285 [04:52<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [04:53<00:17,  1.11s/it]Loading train:  95%|█████████▍| 270/285 [04:54<00:16,  1.09s/it]Loading train:  95%|█████████▌| 271/285 [04:55<00:15,  1.09s/it]Loading train:  95%|█████████▌| 272/285 [04:56<00:13,  1.04s/it]Loading train:  96%|█████████▌| 273/285 [04:57<00:11,  1.03it/s]Loading train:  96%|█████████▌| 274/285 [04:58<00:10,  1.06it/s]Loading train:  96%|█████████▋| 275/285 [04:59<00:09,  1.05it/s]Loading train:  97%|█████████▋| 276/285 [05:00<00:09,  1.05s/it]Loading train:  97%|█████████▋| 277/285 [05:01<00:08,  1.02s/it]Loading train:  98%|█████████▊| 278/285 [05:02<00:07,  1.07s/it]Loading train:  98%|█████████▊| 279/285 [05:03<00:06,  1.05s/it]Loading train:  98%|█████████▊| 280/285 [05:04<00:04,  1.01it/s]Loading train:  99%|█████████▊| 281/285 [05:05<00:03,  1.11it/s]Loading train:  99%|█████████▉| 282/285 [05:06<00:02,  1.19it/s]Loading train:  99%|█████████▉| 283/285 [05:07<00:01,  1.11it/s]Loading train: 100%|█████████▉| 284/285 [05:08<00:00,  1.06it/s]Loading train: 100%|██████████| 285/285 [05:09<00:00,  1.04s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   4%|▍         | 12/285 [00:00<00:02, 111.80it/s]concatenating: train:   8%|▊         | 22/285 [00:00<00:02, 106.56it/s]concatenating: train:  12%|█▏        | 33/285 [00:00<00:02, 106.34it/s]concatenating: train:  16%|█▌        | 46/285 [00:00<00:02, 110.20it/s]concatenating: train:  21%|██        | 60/285 [00:00<00:01, 115.38it/s]concatenating: train:  26%|██▌       | 73/285 [00:00<00:01, 118.12it/s]concatenating: train:  30%|███       | 86/285 [00:00<00:01, 118.78it/s]concatenating: train:  35%|███▍      | 99/285 [00:00<00:01, 120.60it/s]concatenating: train:  39%|███▉      | 111/285 [00:00<00:01, 107.46it/s]concatenating: train:  43%|████▎     | 122/285 [00:01<00:01, 104.52it/s]concatenating: train:  47%|████▋     | 135/285 [00:01<00:01, 108.83it/s]concatenating: train:  52%|█████▏    | 147/285 [00:01<00:01, 109.50it/s]concatenating: train:  55%|█████▌    | 158/285 [00:01<00:01, 99.09it/s] concatenating: train:  59%|█████▉    | 169/285 [00:01<00:01, 102.02it/s]concatenating: train:  64%|██████▍   | 183/285 [00:01<00:00, 111.05it/s]concatenating: train:  72%|███████▏  | 205/285 [00:01<00:00, 129.27it/s]concatenating: train:  77%|███████▋  | 220/285 [00:01<00:00, 121.34it/s]concatenating: train:  82%|████████▏ | 234/285 [00:02<00:00, 115.83it/s]concatenating: train:  87%|████████▋ | 247/285 [00:02<00:00, 117.17it/s]concatenating: train:  91%|█████████ | 260/285 [00:02<00:00, 113.16it/s]concatenating: train:  95%|█████████▌| 272/285 [00:02<00:00, 102.48it/s]concatenating: train: 100%|█████████▉| 284/285 [00:02<00:00, 106.90it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 113.28it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.33s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.28s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 86.04it/s]2019-07-11 12:53:11.515586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 12:53:11.515727: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 12:53:11.515743: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 12:53:11.515752: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 12:53:11.516039: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:12,  3.55it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:09,  4.33it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:09,  4.34it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:06,  5.56it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:07,  4.55it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:06,  5.21it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:07,  4.08it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:02<00:05,  5.25it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:06,  4.23it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:05,  4.66it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:03<00:05,  4.06it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:03<00:03,  5.25it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  5.86it/s]loading the weights for Res Unet:  64%|██████▎   | 28/44 [00:04<00:03,  4.88it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:04<00:02,  5.30it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:04<00:02,  4.70it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  5.95it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:05<00:01,  6.19it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:05<00:01,  4.79it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:05<00:00,  5.12it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:06<00:00,  4.46it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:06<00:00,  7.26it/s]
---------------------- check Layers Step ------------------------------
 N: [1]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------------------------------------------------
 Nucleus: [1]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
---------------------- check Layers Step ------------------------------
 N: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1

 #layer 3 #layers changed False
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 2  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM15_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd2/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 80, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 80, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 80, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 80, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 80, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 80, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 80, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 80, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 80, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 80, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 80, 15)   5550        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 80, 15)   60          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 80, 15)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 80, 15)   2040        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 80, 15)   60          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 80, 15)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 40, 15)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 40, 15)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 40, 30)   4080        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 40, 30)   120         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 40, 30)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 40, 30)   8130        activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 40, 30)   120         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 40, 30)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 40, 45)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 20, 45)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 20, 45)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 20, 60)   24360       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 20, 60)   240         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 20, 60)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 20, 60)   32460       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 20, 60)   240         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 20, 60)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 20, 105)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 20, 105)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 40, 30)   12630       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 40, 75)   0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 40, 30)   20280       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 40, 30)   120         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 40, 30)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 40, 30)   8130        activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 40, 30)   120         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 40, 30)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 40, 105)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 40, 105)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 80, 15)   6315        dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 80, 30)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 80, 15)   4065        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 80, 15)   60          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 80, 15)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 80, 15)   2040        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 80, 15)   60          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 80, 15)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 80, 45)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 80, 45)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 80, 40)   16240       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 80, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 80, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 80, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 80, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 80, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 80, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 80, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 80, 85)   0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 80, 13)   1118        concatenate_8[0][0]              
==================================================================================================
Total params: 178,558
Trainable params: 79,778
Non-trainable params: 98,780
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.47467835e-02 3.18797950e-02 7.48227142e-02 9.29948699e-03
 2.70301111e-02 7.04843275e-03 8.49024940e-02 1.12367134e-01
 8.58192333e-02 1.32164642e-02 2.93445604e-01 1.95153089e-01
 2.68657757e-04]
Train on 10374 samples, validate on 105 samples
Epoch 1/300
 - 20s - loss: 2.5653 - acc: 0.6681 - mDice: 0.1265 - val_loss: 4.3765 - val_acc: 0.9013 - val_mDice: 0.0840

Epoch 00001: val_mDice improved from -inf to 0.08399, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 14s - loss: 0.9461 - acc: 0.8878 - mDice: 0.3780 - val_loss: 1.4170 - val_acc: 0.9166 - val_mDice: 0.4019

Epoch 00002: val_mDice improved from 0.08399 to 0.40190, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 13s - loss: 0.7138 - acc: 0.8988 - mDice: 0.4734 - val_loss: 1.3754 - val_acc: 0.9139 - val_mDice: 0.4269

Epoch 00003: val_mDice improved from 0.40190 to 0.42689, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 13s - loss: 0.6171 - acc: 0.9091 - mDice: 0.5224 - val_loss: 1.1368 - val_acc: 0.9313 - val_mDice: 0.4912

Epoch 00004: val_mDice improved from 0.42689 to 0.49118, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 13s - loss: 0.5586 - acc: 0.9164 - mDice: 0.5551 - val_loss: 1.0862 - val_acc: 0.9291 - val_mDice: 0.5379

Epoch 00005: val_mDice improved from 0.49118 to 0.53790, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 14s - loss: 0.5196 - acc: 0.9201 - mDice: 0.5780 - val_loss: 1.0673 - val_acc: 0.9154 - val_mDice: 0.5290

Epoch 00006: val_mDice did not improve from 0.53790
Epoch 7/300
 - 14s - loss: 0.4925 - acc: 0.9231 - mDice: 0.5948 - val_loss: 1.0341 - val_acc: 0.9361 - val_mDice: 0.5560

Epoch 00007: val_mDice improved from 0.53790 to 0.55600, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 13s - loss: 0.4709 - acc: 0.9255 - mDice: 0.6084 - val_loss: 1.0548 - val_acc: 0.9356 - val_mDice: 0.5131

Epoch 00008: val_mDice did not improve from 0.55600
Epoch 9/300
 - 13s - loss: 0.4527 - acc: 0.9278 - mDice: 0.6201 - val_loss: 1.0487 - val_acc: 0.9333 - val_mDice: 0.5613

Epoch 00009: val_mDice improved from 0.55600 to 0.56130, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 10/300
 - 13s - loss: 0.4385 - acc: 0.9292 - mDice: 0.6295 - val_loss: 0.9567 - val_acc: 0.9411 - val_mDice: 0.5789

Epoch 00010: val_mDice improved from 0.56130 to 0.57890, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 11/300
 - 14s - loss: 0.4284 - acc: 0.9306 - mDice: 0.6364 - val_loss: 0.9553 - val_acc: 0.9397 - val_mDice: 0.5765

Epoch 00011: val_mDice did not improve from 0.57890
Epoch 12/300
 - 14s - loss: 0.4178 - acc: 0.9320 - mDice: 0.6433 - val_loss: 0.9742 - val_acc: 0.9293 - val_mDice: 0.5554

Epoch 00012: val_mDice did not improve from 0.57890
Epoch 13/300
 - 14s - loss: 0.4062 - acc: 0.9331 - mDice: 0.6511 - val_loss: 0.9533 - val_acc: 0.9429 - val_mDice: 0.5766

Epoch 00013: val_mDice did not improve from 0.57890
Epoch 14/300
 - 13s - loss: 0.4004 - acc: 0.9338 - mDice: 0.6550 - val_loss: 0.9647 - val_acc: 0.9446 - val_mDice: 0.5766

Epoch 00014: val_mDice did not improve from 0.57890
Epoch 15/300
 - 13s - loss: 0.3935 - acc: 0.9348 - mDice: 0.6598 - val_loss: 0.9471 - val_acc: 0.9451 - val_mDice: 0.5844

Epoch 00015: val_mDice improved from 0.57890 to 0.58444, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 13s - loss: 0.3864 - acc: 0.9353 - mDice: 0.6647 - val_loss: 0.9270 - val_acc: 0.9430 - val_mDice: 0.5629

Epoch 00016: val_mDice did not improve from 0.58444
Epoch 17/300
 - 14s - loss: 0.3808 - acc: 0.9360 - mDice: 0.6684 - val_loss: 0.9296 - val_acc: 0.9443 - val_mDice: 0.5775

Epoch 00017: val_mDice did not improve from 0.58444
Epoch 18/300
 - 14s - loss: 0.3780 - acc: 0.9365 - mDice: 0.6705 - val_loss: 0.9810 - val_acc: 0.9437 - val_mDice: 0.5677

Epoch 00018: val_mDice did not improve from 0.58444
Epoch 19/300
 - 13s - loss: 0.3717 - acc: 0.9370 - mDice: 0.6749 - val_loss: 0.8585 - val_acc: 0.9449 - val_mDice: 0.5857

Epoch 00019: val_mDice improved from 0.58444 to 0.58571, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 13s - loss: 0.3677 - acc: 0.9375 - mDice: 0.6777 - val_loss: 0.9484 - val_acc: 0.9455 - val_mDice: 0.5833

Epoch 00020: val_mDice did not improve from 0.58571
Epoch 21/300
 - 13s - loss: 0.3661 - acc: 0.9376 - mDice: 0.6787 - val_loss: 0.9255 - val_acc: 0.9440 - val_mDice: 0.5852

Epoch 00021: val_mDice did not improve from 0.58571
Epoch 22/300
 - 13s - loss: 0.3599 - acc: 0.9382 - mDice: 0.6831 - val_loss: 0.9148 - val_acc: 0.9417 - val_mDice: 0.5696

Epoch 00022: val_mDice did not improve from 0.58571
Epoch 23/300
 - 14s - loss: 0.3549 - acc: 0.9388 - mDice: 0.6866 - val_loss: 0.9126 - val_acc: 0.9438 - val_mDice: 0.5765

Epoch 00023: val_mDice did not improve from 0.58571
Epoch 24/300
 - 14s - loss: 0.3541 - acc: 0.9389 - mDice: 0.6873 - val_loss: 0.8695 - val_acc: 0.9459 - val_mDice: 0.5758

Epoch 00024: val_mDice did not improve from 0.58571
Epoch 25/300
 - 13s - loss: 0.3486 - acc: 0.9393 - mDice: 0.6910 - val_loss: 0.8591 - val_acc: 0.9459 - val_mDice: 0.5787

Epoch 00025: val_mDice did not improve from 0.58571
Epoch 26/300
 - 13s - loss: 0.3463 - acc: 0.9396 - mDice: 0.6927 - val_loss: 0.8900 - val_acc: 0.9445 - val_mDice: 0.5746

Epoch 00026: val_mDice did not improve from 0.58571
Epoch 27/300
 - 13s - loss: 0.3448 - acc: 0.9397 - mDice: 0.6938 - val_loss: 0.8530 - val_acc: 0.9443 - val_mDice: 0.5850

Epoch 00027: val_mDice did not improve from 0.58571
Epoch 28/300
 - 13s - loss: 0.3421 - acc: 0.9401 - mDice: 0.6957 - val_loss: 0.8861 - val_acc: 0.9453 - val_mDice: 0.5623

Epoch 00028: val_mDice did not improve from 0.58571
Epoch 29/300
 - 13s - loss: 0.3423 - acc: 0.9398 - mDice: 0.6955 - val_loss: 0.8322 - val_acc: 0.9443 - val_mDice: 0.5828

Epoch 00029: val_mDice did not improve from 0.58571
Epoch 30/300
 - 14s - loss: 0.3392 - acc: 0.9402 - mDice: 0.6978 - val_loss: 0.9064 - val_acc: 0.9337 - val_mDice: 0.5522

Epoch 00030: val_mDice did not improve from 0.58571
Epoch 31/300
 - 14s - loss: 0.3352 - acc: 0.9406 - mDice: 0.7007 - val_loss: 0.8642 - val_acc: 0.9434 - val_mDice: 0.5768

Epoch 00031: val_mDice did not improve from 0.58571
Epoch 32/300
 - 13s - loss: 0.3303 - acc: 0.9413 - mDice: 0.7043 - val_loss: 0.8157 - val_acc: 0.9447 - val_mDice: 0.5794

Epoch 00032: val_mDice did not improve from 0.58571
Epoch 33/300
 - 13s - loss: 0.3301 - acc: 0.9412 - mDice: 0.7044 - val_loss: 0.8113 - val_acc: 0.9463 - val_mDice: 0.5859

Epoch 00033: val_mDice improved from 0.58571 to 0.58586, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 34/300
 - 13s - loss: 0.3290 - acc: 0.9413 - mDice: 0.7052 - val_loss: 0.7908 - val_acc: 0.9466 - val_mDice: 0.5852

Epoch 00034: val_mDice did not improve from 0.58586
Epoch 35/300
 - 13s - loss: 0.3261 - acc: 0.9417 - mDice: 0.7073 - val_loss: 0.8347 - val_acc: 0.9469 - val_mDice: 0.5808

Epoch 00035: val_mDice did not improve from 0.58586
Epoch 36/300
 - 13s - loss: 0.3239 - acc: 0.9419 - mDice: 0.7089 - val_loss: 0.8105 - val_acc: 0.9466 - val_mDice: 0.5809

Epoch 00036: val_mDice did not improve from 0.58586
Epoch 37/300
 - 13s - loss: 0.3232 - acc: 0.9419 - mDice: 0.7095 - val_loss: 0.8090 - val_acc: 0.9466 - val_mDice: 0.5816

Epoch 00037: val_mDice did not improve from 0.58586
Epoch 38/300
 - 14s - loss: 0.3219 - acc: 0.9420 - mDice: 0.7105 - val_loss: 0.7929 - val_acc: 0.9450 - val_mDice: 0.5770

Epoch 00038: val_mDice did not improve from 0.58586
Epoch 39/300
 - 14s - loss: 0.3196 - acc: 0.9422 - mDice: 0.7120 - val_loss: 0.8099 - val_acc: 0.9458 - val_mDice: 0.5843

Epoch 00039: val_mDice did not improve from 0.58586
Epoch 40/300
 - 13s - loss: 0.3182 - acc: 0.9424 - mDice: 0.7132 - val_loss: 0.7344 - val_acc: 0.9439 - val_mDice: 0.5776

Epoch 00040: val_mDice did not improve from 0.58586
Epoch 41/300
 - 13s - loss: 0.3174 - acc: 0.9425 - mDice: 0.7137 - val_loss: 0.8200 - val_acc: 0.9454 - val_mDice: 0.5611

Epoch 00041: val_mDice did not improve from 0.58586
Epoch 42/300
 - 13s - loss: 0.3158 - acc: 0.9426 - mDice: 0.7148 - val_loss: 0.7640 - val_acc: 0.9477 - val_mDice: 0.5887

Epoch 00042: val_mDice improved from 0.58586 to 0.58868, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd2/best_model_weights_TF_CSFn2.h5
Epoch 43/300
 - 13s - loss: 0.3132 - acc: 0.9429 - mDice: 0.7168 - val_loss: 0.8269 - val_acc: 0.9441 - val_mDice: 0.5729

Epoch 00043: val_mDice did not improve from 0.58868
Epoch 44/300
 - 13s - loss: 0.3127 - acc: 0.9429 - mDice: 0.7172 - val_loss: 0.7467 - val_acc: 0.9459 - val_mDice: 0.5726

Epoch 00044: val_mDice did not improve from 0.58868
Epoch 45/300
 - 13s - loss: 0.3103 - acc: 0.9431 - mDice: 0.7189 - val_loss: 0.7470 - val_acc: 0.9474 - val_mDice: 0.5873

Epoch 00045: val_mDice did not improve from 0.58868
Epoch 46/300
 - 13s - loss: 0.3089 - acc: 0.9433 - mDice: 0.7201 - val_loss: 0.7488 - val_acc: 0.9461 - val_mDice: 0.5725

Epoch 00046: val_mDice did not improve from 0.58868
Epoch 47/300
 - 14s - loss: 0.3059 - acc: 0.9436 - mDice: 0.7223 - val_loss: 0.7835 - val_acc: 0.9459 - val_mDice: 0.5736

Epoch 00047: val_mDice did not improve from 0.58868
Epoch 48/300
 - 14s - loss: 0.3053 - acc: 0.9435 - mDice: 0.7227 - val_loss: 0.7700 - val_acc: 0.9460 - val_mDice: 0.5831

Epoch 00048: val_mDice did not improve from 0.58868
Epoch 49/300
 - 13s - loss: 0.3053 - acc: 0.9435 - mDice: 0.7227 - val_loss: 0.7796 - val_acc: 0.9456 - val_mDice: 0.5799

Epoch 00049: val_mDice did not improve from 0.58868
Epoch 50/300
 - 13s - loss: 0.3028 - acc: 0.9439 - mDice: 0.7247 - val_loss: 0.7505 - val_acc: 0.9392 - val_mDice: 0.5692

Epoch 00050: val_mDice did not improve from 0.58868
Epoch 51/300
 - 13s - loss: 0.3012 - acc: 0.9440 - mDice: 0.7258 - val_loss: 0.7339 - val_acc: 0.9454 - val_mDice: 0.5563

Epoch 00051: val_mDice did not improve from 0.58868
Epoch 52/300
 - 13s - loss: 0.3008 - acc: 0.9440 - mDice: 0.7261 - val_loss: 0.7861 - val_acc: 0.9447 - val_mDice: 0.5774

Epoch 00052: val_mDice did not improve from 0.58868
Epoch 53/300
 - 13s - loss: 0.3008 - acc: 0.9441 - mDice: 0.7261 - val_loss: 0.8234 - val_acc: 0.9322 - val_mDice: 0.5447

Epoch 00053: val_mDice did not improve from 0.58868
Epoch 54/300
 - 14s - loss: 0.2993 - acc: 0.9443 - mDice: 0.7272 - val_loss: 0.7615 - val_acc: 0.9469 - val_mDice: 0.5786

Epoch 00054: val_mDice did not improve from 0.58868
Epoch 55/300
 - 14s - loss: 0.2989 - acc: 0.9442 - mDice: 0.7276 - val_loss: 0.7348 - val_acc: 0.9453 - val_mDice: 0.5750

Epoch 00055: val_mDice did not improve from 0.58868
Epoch 56/300
 - 13s - loss: 0.2984 - acc: 0.9442 - mDice: 0.7280 - val_loss: 0.7764 - val_acc: 0.9458 - val_mDice: 0.5704

Epoch 00056: val_mDice did not improve from 0.58868
Epoch 57/300
 - 13s - loss: 0.2955 - acc: 0.9444 - mDice: 0.7302 - val_loss: 0.7329 - val_acc: 0.9449 - val_mDice: 0.5760

Epoch 00057: val_mDice did not improve from 0.58868
Epoch 58/300
 - 14s - loss: 0.2959 - acc: 0.9444 - mDice: 0.7298 - val_loss: 0.7638 - val_acc: 0.9418 - val_mDice: 0.5697

Epoch 00058: val_mDice did not improve from 0.58868
Epoch 59/300
 - 13s - loss: 0.2947 - acc: 0.9446 - mDice: 0.7307 - val_loss: 0.7083 - val_acc: 0.9448 - val_mDice: 0.5728

Epoch 00059: val_mDice did not improve from 0.58868
Epoch 60/300
 - 13s - loss: 0.2930 - acc: 0.9447 - mDice: 0.7320 - val_loss: 0.7021 - val_acc: 0.9423 - val_mDice: 0.5769

Epoch 00060: val_mDice did not improve from 0.58868
Epoch 61/300
 - 13s - loss: 0.2918 - acc: 0.9447 - mDice: 0.7330 - val_loss: 0.7838 - val_acc: 0.9467 - val_mDice: 0.5727

Epoch 00061: val_mDice did not improve from 0.58868
Epoch 62/300
 - 13s - loss: 0.2922 - acc: 0.9447 - mDice: 0.7327 - val_loss: 0.7456 - val_acc: 0.9454 - val_mDice: 0.5767

Epoch 00062: val_mDice did not improve from 0.58868
Epoch 63/300
 - 14s - loss: 0.2914 - acc: 0.9448 - mDice: 0.7333 - val_loss: 0.6958 - val_acc: 0.9445 - val_mDice: 0.5734

Epoch 00063: val_mDice did not improve from 0.58868
Epoch 64/300
 - 14s - loss: 0.2918 - acc: 0.9448 - mDice: 0.7329 - val_loss: 0.6843 - val_acc: 0.9438 - val_mDice: 0.5726

Epoch 00064: val_mDice did not improve from 0.58868
Epoch 65/300
 - 13s - loss: 0.2899 - acc: 0.9449 - mDice: 0.7345 - val_loss: 0.7221 - val_acc: 0.9429 - val_mDice: 0.5773

Epoch 00065: val_mDice did not improve from 0.58868
Epoch 66/300
 - 13s - loss: 0.2887 - acc: 0.9452 - mDice: 0.7354 - val_loss: 0.6943 - val_acc: 0.9413 - val_mDice: 0.5629

Epoch 00066: val_mDice did not improve from 0.58868
Epoch 67/300
 - 13s - loss: 0.2882 - acc: 0.9452 - mDice: 0.7358 - val_loss: 0.7169 - val_acc: 0.9435 - val_mDice: 0.5762

Epoch 00067: val_mDice did not improve from 0.58868
Epoch 68/300
 - 13s - loss: 0.2869 - acc: 0.9453 - mDice: 0.7368 - val_loss: 0.7552 - val_acc: 0.9454 - val_mDice: 0.5814

Epoch 00068: val_mDice did not improve from 0.58868
Epoch 69/300
 - 13s - loss: 0.2861 - acc: 0.9454 - mDice: 0.7373 - val_loss: 0.7106 - val_acc: 0.9448 - val_mDice: 0.5771

Epoch 00069: val_mDice did not improve from 0.58868
Epoch 70/300
 - 14s - loss: 0.2867 - acc: 0.9453 - mDice: 0.7368 - val_loss: 0.6993 - val_acc: 0.9446 - val_mDice: 0.5799

Epoch 00070: val_mDice did not improve from 0.58868
Epoch 71/300
 - 14s - loss: 0.2825 - acc: 0.9456 - mDice: 0.7401 - val_loss: 0.7207 - val_acc: 0.9458 - val_mDice: 0.5737

Epoch 00071: val_mDice did not improve from 0.58868
Epoch 72/300
 - 13s - loss: 0.2839 - acc: 0.9455 - mDice: 0.7391 - val_loss: 0.7259 - val_acc: 0.9450 - val_mDice: 0.5751

Epoch 00072: val_mDice did not improve from 0.58868
Epoch 73/300
 - 13s - loss: 0.2839 - acc: 0.9457 - mDice: 0.7390 - val_loss: 0.7402 - val_acc: 0.9454 - val_mDice: 0.5346

Epoch 00073: val_mDice did not improve from 0.58868
Epoch 74/300
 - 13s - loss: 0.2829 - acc: 0.9457 - mDice: 0.7399 - val_loss: 0.7059 - val_acc: 0.9426 - val_mDice: 0.5638

Epoch 00074: val_mDice did not improve from 0.58868
Epoch 75/300
 - 13s - loss: 0.2820 - acc: 0.9457 - mDice: 0.7405 - val_loss: 0.7521 - val_acc: 0.9438 - val_mDice: 0.5621

Epoch 00075: val_mDice did not improve from 0.58868
Epoch 76/300
 - 13s - loss: 0.2822 - acc: 0.9457 - mDice: 0.7404 - val_loss: 0.7693 - val_acc: 0.9429 - val_mDice: 0.5641

Epoch 00076: val_mDice did not improve from 0.58868
Epoch 77/300
 - 13s - loss: 0.2826 - acc: 0.9456 - mDice: 0.7400 - val_loss: 0.7564 - val_acc: 0.9447 - val_mDice: 0.5633

Epoch 00077: val_mDice did not improve from 0.58868
Epoch 78/300
 - 13s - loss: 0.2805 - acc: 0.9458 - mDice: 0.7416 - val_loss: 0.7138 - val_acc: 0.9454 - val_mDice: 0.5813

Epoch 00078: val_mDice did not improve from 0.58868
Epoch 79/300
 - 13s - loss: 0.2793 - acc: 0.9459 - mDice: 0.7426 - val_loss: 0.7502 - val_acc: 0.9441 - val_mDice: 0.5606

Epoch 00079: val_mDice did not improve from 0.58868
Epoch 80/300
 - 14s - loss: 0.2771 - acc: 0.9462 - mDice: 0.7443 - val_loss: 0.7019 - val_acc: 0.9458 - val_mDice: 0.5758

Epoch 00080: val_mDice did not improve from 0.58868
Epoch 81/300
 - 14s - loss: 0.2779 - acc: 0.9461 - mDice: 0.7436 - val_loss: 0.7710 - val_acc: 0.9454 - val_mDice: 0.5728

Epoch 00081: val_mDice did not improve from 0.58868
Epoch 82/300
 - 13s - loss: 0.2772 - acc: 0.9461 - mDice: 0.7442 - val_loss: 0.7660 - val_acc: 0.9422 - val_mDice: 0.5616

Epoch 00082: val_mDice did not improve from 0.58868
Restoring model weights from the end of the best epoch
Epoch 00082: early stopping
{'val_loss': [4.376453626723516, 1.4170152573358445, 1.375383978798276, 1.136774222056071, 1.0861832868485224, 1.0672690300714403, 1.0340734890529089, 1.0548353989919026, 1.048733847481864, 0.9566997403190249, 0.9553379388082595, 0.9742497830163865, 0.9532849391301473, 0.9646920306341988, 0.9471244301114764, 0.9270174957457042, 0.9296169621603829, 0.9810132469449725, 0.8585312763849894, 0.9483977045331683, 0.925482710202535, 0.9147717782429287, 0.9125856104351225, 0.8694522267296201, 0.8591433025541759, 0.8900379566919236, 0.8529710996718634, 0.8860872245970226, 0.8322418757847377, 0.9063819363003686, 0.8642263242176601, 0.8156942640032087, 0.8112523498989287, 0.7907861698241461, 0.8346850304376512, 0.8105245147432599, 0.809022931825547, 0.7929482857386271, 0.8099230244046166, 0.7344066415514264, 0.8199911344619024, 0.7640206927344912, 0.8269413425808861, 0.7466738621393839, 0.7470232986268543, 0.7487650428499494, 0.7835366782687959, 0.7700418801534743, 0.779577374458313, 0.7504875603176299, 0.7339256604512533, 0.7860575857616606, 0.8233772913614908, 0.7615290823436919, 0.7348309812091646, 0.7764136507397607, 0.7329001937593732, 0.7637747015271869, 0.7082642770948864, 0.7020934649876186, 0.7837953964869181, 0.7455649546214512, 0.6957801693961734, 0.6843466588429042, 0.7220533915928432, 0.6943039667038691, 0.7169079326447987, 0.7551697152001517, 0.7105537823268345, 0.6992922226587931, 0.7207485550925845, 0.725929992539542, 0.7401732490176246, 0.7059008848099482, 0.7521479016258603, 0.7692817279270717, 0.7563693069276356, 0.7138411147253854, 0.7501789047604516, 0.7019427220026652, 0.7710215477716356, 0.7660338878631592], 'val_acc': [0.9013323954173497, 0.9165567557017008, 0.9138644507953099, 0.9313003591128758, 0.929068230447315, 0.9154372527485802, 0.9360599716504415, 0.9356020774160113, 0.9333470832733881, 0.9411378275780451, 0.9396932153474717, 0.9292834117299035, 0.9429464482125782, 0.9445947635741461, 0.9451327948343187, 0.9429738947323391, 0.944324635324024, 0.943676715805417, 0.9449496155693418, 0.9455357279096331, 0.9440407497542245, 0.9416872688702175, 0.9438301041012719, 0.9459295074144999, 0.9458882666769481, 0.944452859106518, 0.9442719930694217, 0.9453068006606329, 0.9443361021223522, 0.9336996532621837, 0.9434340766498021, 0.9447458556720189, 0.9462751973242987, 0.9465979735056559, 0.9469368060429891, 0.9466094204357692, 0.9465544876598176, 0.9449565155165536, 0.9458287727265131, 0.943949165798369, 0.945428124495915, 0.9476625181379772, 0.9440704867953346, 0.9459065880094256, 0.9473924097560701, 0.9461126582963126, 0.9458814093044826, 0.9459546776044936, 0.945608947958265, 0.9392170054571969, 0.9453548391660055, 0.9446863815897987, 0.9321543120202564, 0.9469299401555743, 0.945263303461529, 0.9457806575865972, 0.9449359121776763, 0.9417697049322582, 0.9448031300590152, 0.9423122547921681, 0.9467078702790397, 0.9453960571970258, 0.9444803027879625, 0.9438118253435407, 0.9428777410870507, 0.9413186737469265, 0.9435004450026012, 0.9454464486667088, 0.9447802220072065, 0.9446474086670649, 0.9457509432520185, 0.9450206245694842, 0.9454166548592704, 0.9426259114628747, 0.943786640961965, 0.9428685648100716, 0.9447206854820251, 0.9453617334365845, 0.9440590483801705, 0.9458150125685192, 0.945354856195904, 0.9422481797990345], 'val_mDice': [0.08399175594968256, 0.4018992137696062, 0.4268912955054215, 0.49117672727221534, 0.5378993428533986, 0.5290214795441854, 0.555996916833378, 0.5131440846515554, 0.5613025547493071, 0.5788991642849786, 0.5764987424370789, 0.5554403985540072, 0.5765988542920067, 0.5765833964660054, 0.5844372063875198, 0.5628751507472425, 0.5774883697075504, 0.5677177902488482, 0.5857082454576379, 0.5832700779040655, 0.5851926503791696, 0.5696385705045292, 0.5765482173079536, 0.5758208864856333, 0.5786773773531119, 0.5745527449817884, 0.5849985451925368, 0.5623330223773207, 0.5827542839660531, 0.5521948406738895, 0.5768336800947076, 0.579419589468411, 0.5858589481739771, 0.5852146159325328, 0.5807653353327796, 0.5808801104625066, 0.5815831853875092, 0.5770276101926962, 0.5843340555826823, 0.5775752463156268, 0.5611490710150628, 0.5886820515706426, 0.572911340211119, 0.5725803650206044, 0.5873177250226339, 0.5724834741226265, 0.5735796964949086, 0.5831180984775225, 0.579911137620608, 0.5691981688141823, 0.5563026436028027, 0.5773783216164226, 0.5446602359768891, 0.578551169307459, 0.574991993251301, 0.5704471617937088, 0.5759587192109653, 0.569739869307904, 0.5728024006599471, 0.5769019119796299, 0.5726651226480802, 0.5767000902976308, 0.5733774985585894, 0.5726236257524717, 0.5772554196772122, 0.5629273401129813, 0.576175058704047, 0.5813504876125426, 0.5770621909981682, 0.579922922310375, 0.5736983773254213, 0.5751183535016718, 0.5346246026456356, 0.5637835934758186, 0.5620591170376256, 0.5640738507111868, 0.5632625339286668, 0.5812696846468108, 0.5605892237453234, 0.5758409329823085, 0.5727722600457215, 0.5616481082425231], 'loss': [2.565313765118755, 0.9461189612892751, 0.713802448938365, 0.6170896598546749, 0.5586375615282833, 0.5195584681846743, 0.49247412564829407, 0.4708947092208509, 0.4527479855913589, 0.438494619903524, 0.4283877583753863, 0.4177688375612387, 0.40624307878265176, 0.40039019221994765, 0.3935461991240529, 0.38644486538748396, 0.3807753763873154, 0.3780489660180417, 0.37168192009671197, 0.36771980202655374, 0.3660560002475431, 0.35988299855727185, 0.3549027645521272, 0.35407890271699244, 0.34860005295067503, 0.3462915412603326, 0.34480988752963754, 0.34210484662634205, 0.3423318548114722, 0.3391936621512892, 0.3351673335038055, 0.3302694059806406, 0.33012950219858905, 0.32900385587045816, 0.3261015846052679, 0.32386862224458796, 0.3231995143434412, 0.32189690994347636, 0.31960783725601183, 0.3182381648754876, 0.3174498449556396, 0.31579292573197076, 0.3131534000088398, 0.3126978912587016, 0.3103216843141258, 0.3088636421642484, 0.30592639355018736, 0.30529086585101856, 0.305339097861773, 0.30278590520337895, 0.30124337357869835, 0.3007723601401737, 0.3008350554472315, 0.2992785558584271, 0.29886142883384437, 0.2984256262273165, 0.29550601051610764, 0.29585045002686716, 0.2947224668737595, 0.29298080231312823, 0.29176366610726523, 0.2921609213201899, 0.2914020851533124, 0.2918310949734371, 0.2898794485754146, 0.2886607200280766, 0.2882328515903601, 0.28688332320684545, 0.2861175079359033, 0.28674663763320213, 0.28247111665161445, 0.2838912405201482, 0.2839066130429627, 0.2828597184238301, 0.2819989361881589, 0.2822071972473844, 0.28258038109521405, 0.2805362877495054, 0.27925365256026735, 0.27710118176207643, 0.27786870787133133, 0.2772354637758337], 'acc': [0.6680732196595872, 0.8878207652353243, 0.8987978222353141, 0.9090785829460596, 0.9163689539913775, 0.9200865522684885, 0.9230833199756417, 0.9255438644646541, 0.9278345400712061, 0.9292388930241681, 0.9305569771192472, 0.9320487800144566, 0.9331206403441435, 0.9337890113114805, 0.9347967524875077, 0.9352822208050613, 0.9359853481060512, 0.9365232812891766, 0.9370454392475454, 0.9374615106022792, 0.9375884933165555, 0.9381969400469866, 0.9387586707781109, 0.9389415665102161, 0.9393438742366259, 0.9395774280103342, 0.9397232911479664, 0.9400609750174961, 0.9398096768134864, 0.9401872847635024, 0.9406111653034503, 0.9412791420320842, 0.9411804254675086, 0.9412689224612352, 0.9417019553535679, 0.9418603172875885, 0.9419310575784551, 0.9420241639635709, 0.9421580253434314, 0.9424228777838554, 0.9424905389265814, 0.9425980793687451, 0.9428608047610559, 0.9429043446498178, 0.9431491540373234, 0.9433075331736098, 0.9436242913427623, 0.9435480838684257, 0.94349921202416, 0.94385837676646, 0.9439554872806072, 0.943954049667596, 0.9440801753252256, 0.9442855673808915, 0.9441830831753488, 0.9442418447826924, 0.9444300250462859, 0.9444414922468046, 0.9445821449939102, 0.9446508958892645, 0.9446739538087766, 0.9446796543432243, 0.9448427353517522, 0.9448478342435574, 0.9448808544468553, 0.9452131888828273, 0.9452491477893132, 0.9453040647189558, 0.9453959895140959, 0.9453050383763987, 0.9456493959781727, 0.9455412280152753, 0.9456889488942044, 0.9457472966934, 0.9456531950819348, 0.9457250292852294, 0.9455823122547246, 0.9458266599619115, 0.9459409650084093, 0.9461591289593623, 0.9461199233751203, 0.9461492561572361], 'mDice': [0.1264823890277329, 0.37796661295090106, 0.47336117274871053, 0.5224129545199105, 0.5550713510970194, 0.5779968327195377, 0.5948094645975089, 0.6084471520187998, 0.6201036448696571, 0.6294623757686508, 0.6364182667256965, 0.6433390183602313, 0.6511108769441079, 0.6550049022233668, 0.6597921779924719, 0.6646621937303155, 0.6683831114931696, 0.670536739094905, 0.6748591638011282, 0.6776519452810793, 0.6787097707106379, 0.6830583287498867, 0.6865975198567384, 0.6872740741499546, 0.6910322459649093, 0.6926987219665789, 0.6937709924272427, 0.6956782121752093, 0.6954621748357052, 0.6978067491517399, 0.7006870211722053, 0.7042794335961733, 0.7044383648022398, 0.7052385403467829, 0.7072851314396672, 0.70892628401673, 0.7094678146797314, 0.7104557836035071, 0.7119869449038898, 0.7131945731576891, 0.7136679344124847, 0.7147976110177806, 0.7168265917592134, 0.7172319896997503, 0.718919547635603, 0.7200947299912782, 0.7222835739062934, 0.7227023341004413, 0.7227407697654997, 0.7246733848037852, 0.7257965997117136, 0.72606252975861, 0.7260796731667917, 0.7272364396177461, 0.7276117905431431, 0.7279502581787036, 0.7301567070787988, 0.7298488599361885, 0.7307304977474356, 0.7320462699246264, 0.7329984224437863, 0.7326685410256512, 0.73334367498856, 0.7329472885647559, 0.7344594718473643, 0.7354368802001303, 0.7358317233037461, 0.7367569814188898, 0.7373151591179434, 0.7368295346470222, 0.7401017580093022, 0.739085494150471, 0.739042604891165, 0.7398594004675353, 0.7405106661428669, 0.7403960043418286, 0.7400438341534572, 0.7416402920606578, 0.7426152105089647, 0.7442902393117676, 0.7436493884535775, 0.7441842162542451]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:05,  2.61s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.31s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.13s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<09:41,  2.05s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:56,  1.90s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:56,  1.90s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:27,  1.81s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<09:03,  1.94s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:31,  1.84s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:42,  1.88s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:33,  1.85s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<09:07,  1.98s/it]predicting train subjects:   4%|▎         | 10/285 [00:19<09:23,  2.05s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<08:43,  1.91s/it]predicting train subjects:   4%|▍         | 12/285 [00:22<08:59,  1.98s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:33,  1.89s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:49,  1.95s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<08:56,  1.99s/it]predicting train subjects:   6%|▌         | 16/285 [00:30<09:09,  2.04s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:44,  1.96s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:45,  1.97s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:28,  1.91s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:28,  1.92s/it]predicting train subjects:   7%|▋         | 21/285 [00:40<08:49,  2.01s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:34,  1.96s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:36,  1.97s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<08:18,  1.91s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:39,  2.00s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:59,  2.08s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:20,  1.94s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:28,  1.98s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:29,  1.99s/it]predicting train subjects:  11%|█         | 30/285 [00:58<08:26,  1.99s/it]predicting train subjects:  11%|█         | 31/285 [01:00<08:26,  2.00s/it]predicting train subjects:  11%|█         | 32/285 [01:01<07:51,  1.86s/it]predicting train subjects:  12%|█▏        | 33/285 [01:03<07:55,  1.89s/it]predicting train subjects:  12%|█▏        | 34/285 [01:05<07:53,  1.89s/it]predicting train subjects:  12%|█▏        | 35/285 [01:07<07:58,  1.92s/it]predicting train subjects:  13%|█▎        | 36/285 [01:09<07:34,  1.82s/it]predicting train subjects:  13%|█▎        | 37/285 [01:11<07:33,  1.83s/it]predicting train subjects:  13%|█▎        | 38/285 [01:13<07:42,  1.87s/it]predicting train subjects:  14%|█▎        | 39/285 [01:14<07:22,  1.80s/it]predicting train subjects:  14%|█▍        | 40/285 [01:16<07:27,  1.83s/it]predicting train subjects:  14%|█▍        | 41/285 [01:18<07:12,  1.77s/it]predicting train subjects:  15%|█▍        | 42/285 [01:20<07:05,  1.75s/it]predicting train subjects:  15%|█▌        | 43/285 [01:21<07:08,  1.77s/it]predicting train subjects:  15%|█▌        | 44/285 [01:24<07:32,  1.88s/it]predicting train subjects:  16%|█▌        | 45/285 [01:25<07:08,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:27<07:18,  1.83s/it]predicting train subjects:  16%|█▋        | 47/285 [01:29<06:56,  1.75s/it]predicting train subjects:  17%|█▋        | 48/285 [01:30<07:05,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:32<07:19,  1.86s/it]predicting train subjects:  18%|█▊        | 50/285 [01:34<07:22,  1.88s/it]predicting train subjects:  18%|█▊        | 51/285 [01:36<07:32,  1.93s/it]predicting train subjects:  18%|█▊        | 52/285 [01:38<07:10,  1.85s/it]predicting train subjects:  19%|█▊        | 53/285 [01:40<07:20,  1.90s/it]predicting train subjects:  19%|█▉        | 54/285 [01:42<07:29,  1.94s/it]predicting train subjects:  19%|█▉        | 55/285 [01:44<07:05,  1.85s/it]predicting train subjects:  20%|█▉        | 56/285 [01:46<07:12,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:47<06:55,  1.82s/it]predicting train subjects:  20%|██        | 58/285 [01:50<07:13,  1.91s/it]predicting train subjects:  21%|██        | 59/285 [01:52<07:20,  1.95s/it]predicting train subjects:  21%|██        | 60/285 [01:54<07:40,  2.05s/it]predicting train subjects:  21%|██▏       | 61/285 [01:56<07:15,  1.95s/it]predicting train subjects:  22%|██▏       | 62/285 [01:58<07:18,  1.96s/it]predicting train subjects:  22%|██▏       | 63/285 [02:00<07:18,  1.97s/it]predicting train subjects:  22%|██▏       | 64/285 [02:01<07:01,  1.91s/it]predicting train subjects:  23%|██▎       | 65/285 [02:03<07:07,  1.94s/it]predicting train subjects:  23%|██▎       | 66/285 [02:05<07:06,  1.95s/it]predicting train subjects:  24%|██▎       | 67/285 [02:07<07:05,  1.95s/it]predicting train subjects:  24%|██▍       | 68/285 [02:09<06:46,  1.87s/it]predicting train subjects:  24%|██▍       | 69/285 [02:11<06:42,  1.86s/it]predicting train subjects:  25%|██▍       | 70/285 [02:13<06:48,  1.90s/it]predicting train subjects:  25%|██▍       | 71/285 [02:15<06:52,  1.93s/it]predicting train subjects:  25%|██▌       | 72/285 [02:17<06:38,  1.87s/it]predicting train subjects:  26%|██▌       | 73/285 [02:18<06:36,  1.87s/it]predicting train subjects:  26%|██▌       | 74/285 [02:20<06:42,  1.91s/it]predicting train subjects:  26%|██▋       | 75/285 [02:22<06:44,  1.93s/it]predicting train subjects:  27%|██▋       | 76/285 [02:24<06:51,  1.97s/it]predicting train subjects:  27%|██▋       | 77/285 [02:26<06:40,  1.92s/it]predicting train subjects:  27%|██▋       | 78/285 [02:28<06:28,  1.88s/it]predicting train subjects:  28%|██▊       | 79/285 [02:30<06:30,  1.89s/it]predicting train subjects:  28%|██▊       | 80/285 [02:32<06:32,  1.91s/it]predicting train subjects:  28%|██▊       | 81/285 [02:34<06:22,  1.87s/it]predicting train subjects:  29%|██▉       | 82/285 [02:36<06:20,  1.87s/it]predicting train subjects:  29%|██▉       | 83/285 [02:37<06:14,  1.85s/it]predicting train subjects:  29%|██▉       | 84/285 [02:39<06:03,  1.81s/it]predicting train subjects:  30%|██▉       | 85/285 [02:41<06:01,  1.81s/it]predicting train subjects:  30%|███       | 86/285 [02:43<06:01,  1.82s/it]predicting train subjects:  31%|███       | 87/285 [02:45<06:03,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:46<05:51,  1.79s/it]predicting train subjects:  31%|███       | 89/285 [02:48<05:54,  1.81s/it]predicting train subjects:  32%|███▏      | 90/285 [02:50<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 91/285 [02:52<05:57,  1.84s/it]predicting train subjects:  32%|███▏      | 92/285 [02:54<05:57,  1.85s/it]predicting train subjects:  33%|███▎      | 93/285 [02:56<05:48,  1.82s/it]predicting train subjects:  33%|███▎      | 94/285 [02:57<05:49,  1.83s/it]predicting train subjects:  33%|███▎      | 95/285 [02:59<05:49,  1.84s/it]predicting train subjects:  34%|███▎      | 96/285 [03:01<05:42,  1.81s/it]predicting train subjects:  34%|███▍      | 97/285 [03:03<05:44,  1.83s/it]predicting train subjects:  34%|███▍      | 98/285 [03:05<05:44,  1.84s/it]predicting train subjects:  35%|███▍      | 99/285 [03:07<05:40,  1.83s/it]predicting train subjects:  35%|███▌      | 100/285 [03:09<05:45,  1.87s/it]predicting train subjects:  35%|███▌      | 101/285 [03:10<05:34,  1.82s/it]predicting train subjects:  36%|███▌      | 102/285 [03:12<05:35,  1.83s/it]predicting train subjects:  36%|███▌      | 103/285 [03:14<05:21,  1.76s/it]predicting train subjects:  36%|███▋      | 104/285 [03:16<05:22,  1.78s/it]predicting train subjects:  37%|███▋      | 105/285 [03:17<05:22,  1.79s/it]predicting train subjects:  37%|███▋      | 106/285 [03:19<05:15,  1.76s/it]predicting train subjects:  38%|███▊      | 107/285 [03:21<05:17,  1.78s/it]predicting train subjects:  38%|███▊      | 108/285 [03:22<05:06,  1.73s/it]predicting train subjects:  38%|███▊      | 109/285 [03:24<05:11,  1.77s/it]predicting train subjects:  39%|███▊      | 110/285 [03:26<05:15,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:28<05:07,  1.77s/it]predicting train subjects:  39%|███▉      | 112/285 [03:30<05:07,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:32<05:12,  1.82s/it]predicting train subjects:  40%|████      | 114/285 [03:33<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:36<05:26,  1.92s/it]predicting train subjects:  41%|████      | 116/285 [03:38<05:33,  1.97s/it]predicting train subjects:  41%|████      | 117/285 [03:40<05:41,  2.03s/it]predicting train subjects:  41%|████▏     | 118/285 [03:42<05:43,  2.06s/it]predicting train subjects:  42%|████▏     | 119/285 [03:44<05:32,  2.00s/it]predicting train subjects:  42%|████▏     | 120/285 [03:45<05:13,  1.90s/it]predicting train subjects:  42%|████▏     | 121/285 [03:47<05:00,  1.83s/it]predicting train subjects:  43%|████▎     | 122/285 [03:49<04:45,  1.75s/it]predicting train subjects:  43%|████▎     | 123/285 [03:50<04:32,  1.68s/it]predicting train subjects:  44%|████▎     | 124/285 [03:52<04:40,  1.74s/it]predicting train subjects:  44%|████▍     | 125/285 [03:54<04:37,  1.73s/it]predicting train subjects:  44%|████▍     | 126/285 [03:55<04:23,  1.66s/it]predicting train subjects:  45%|████▍     | 127/285 [03:57<04:11,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:58<04:13,  1.61s/it]predicting train subjects:  45%|████▌     | 129/285 [04:00<04:12,  1.62s/it]predicting train subjects:  46%|████▌     | 130/285 [04:02<04:07,  1.59s/it]predicting train subjects:  46%|████▌     | 131/285 [04:03<04:00,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [04:05<04:04,  1.59s/it]predicting train subjects:  47%|████▋     | 133/285 [04:06<03:57,  1.57s/it]predicting train subjects:  47%|████▋     | 134/285 [04:08<03:57,  1.57s/it]predicting train subjects:  47%|████▋     | 135/285 [04:09<03:50,  1.53s/it]predicting train subjects:  48%|████▊     | 136/285 [04:11<03:44,  1.51s/it]predicting train subjects:  48%|████▊     | 137/285 [04:12<03:53,  1.58s/it]predicting train subjects:  48%|████▊     | 138/285 [04:14<03:45,  1.53s/it]predicting train subjects:  49%|████▉     | 139/285 [04:16<03:52,  1.59s/it]predicting train subjects:  49%|████▉     | 140/285 [04:17<03:56,  1.63s/it]predicting train subjects:  49%|████▉     | 141/285 [04:19<03:46,  1.58s/it]predicting train subjects:  50%|████▉     | 142/285 [04:20<03:43,  1.56s/it]predicting train subjects:  50%|█████     | 143/285 [04:22<03:40,  1.56s/it]predicting train subjects:  51%|█████     | 144/285 [04:23<03:41,  1.57s/it]predicting train subjects:  51%|█████     | 145/285 [04:25<03:42,  1.59s/it]predicting train subjects:  51%|█████     | 146/285 [04:27<03:47,  1.63s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:28<03:37,  1.57s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:30<03:38,  1.60s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:31<03:32,  1.56s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:33<03:27,  1.54s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:35<03:34,  1.60s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:36<03:30,  1.58s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:38<03:24,  1.55s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:39<03:30,  1.61s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:41<03:28,  1.60s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:43<03:29,  1.62s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:44<03:21,  1.57s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:46<03:20,  1.58s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:47<03:14,  1.54s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:49<03:08,  1.51s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:50<03:15,  1.58s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:52<03:12,  1.56s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:54<03:14,  1.59s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:55<03:09,  1.57s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:57<03:07,  1.56s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:58<03:16,  1.65s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:00<03:12,  1.63s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:01<03:01,  1.55s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:03<02:56,  1.52s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:04<02:55,  1.52s/it]predicting train subjects:  60%|██████    | 171/285 [05:06<02:56,  1.55s/it]predicting train subjects:  60%|██████    | 172/285 [05:07<02:53,  1.54s/it]predicting train subjects:  61%|██████    | 173/285 [05:09<02:49,  1.52s/it]predicting train subjects:  61%|██████    | 174/285 [05:10<02:48,  1.52s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:12<02:50,  1.55s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:14<02:51,  1.58s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:15<02:46,  1.54s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:17<02:41,  1.51s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:18<02:39,  1.51s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:20<02:50,  1.62s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:22<02:54,  1.67s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:24<02:54,  1.69s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:25<02:43,  1.61s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:27<02:45,  1.64s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:28<02:36,  1.56s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:30<02:45,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:32<02:49,  1.73s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:34<02:50,  1.75s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:35<02:38,  1.65s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:37<02:30,  1.59s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:38<02:32,  1.62s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:40<02:33,  1.65s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:42<02:30,  1.64s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:43<02:30,  1.65s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:45<02:28,  1.65s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:47<02:38,  1.79s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:49<02:44,  1.87s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:51<02:45,  1.91s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:53<02:35,  1.80s/it]predicting train subjects:  70%|███████   | 200/285 [05:54<02:23,  1.69s/it]predicting train subjects:  71%|███████   | 201/285 [05:56<02:28,  1.77s/it]predicting train subjects:  71%|███████   | 202/285 [05:58<02:34,  1.86s/it]predicting train subjects:  71%|███████   | 203/285 [06:00<02:36,  1.90s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:02<02:27,  1.82s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:03<02:20,  1.76s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:05<02:18,  1.76s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:07<02:22,  1.82s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:09<02:25,  1.88s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:11<02:26,  1.93s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:13<02:14,  1.80s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:14<02:07,  1.72s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:16<02:05,  1.72s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:18<02:02,  1.70s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:19<01:54,  1.61s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:21<01:59,  1.70s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:22<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:25<02:03,  1.81s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:27<02:05,  1.87s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:29<02:05,  1.91s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:30<02:00,  1.85s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:32<01:55,  1.80s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:34<01:54,  1.81s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:35<01:45,  1.71s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:37<01:43,  1.69s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:38<01:35,  1.59s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:40<01:42,  1.74s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:42<01:43,  1.79s/it]predicting train subjects:  80%|████████  | 228/285 [06:44<01:47,  1.88s/it]predicting train subjects:  80%|████████  | 229/285 [06:46<01:45,  1.88s/it]predicting train subjects:  81%|████████  | 230/285 [06:48<01:37,  1.78s/it]predicting train subjects:  81%|████████  | 231/285 [06:49<01:31,  1.70s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:51<01:35,  1.81s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:53<01:28,  1.71s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:55<01:34,  1.85s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:57<01:29,  1.80s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:59<01:30,  1.85s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:01<01:30,  1.89s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:03<01:29,  1.91s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:04<01:24,  1.83s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:06<01:19,  1.76s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:07<01:14,  1.70s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:09<01:11,  1.67s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:10<01:07,  1.60s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:13<01:12,  1.78s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:14<01:07,  1.68s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:16<01:11,  1.82s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:18<01:13,  1.95s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:20<01:11,  1.94s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:22<01:05,  1.81s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:23<01:00,  1.73s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:25<00:56,  1.66s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:27<00:54,  1.64s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:29<00:57,  1.80s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:31<00:58,  1.87s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:33<00:56,  1.89s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:34<00:50,  1.75s/it]predicting train subjects:  90%|█████████ | 257/285 [07:36<00:47,  1.69s/it]predicting train subjects:  91%|█████████ | 258/285 [07:38<00:48,  1.79s/it]predicting train subjects:  91%|█████████ | 259/285 [07:40<00:48,  1.86s/it]predicting train subjects:  91%|█████████ | 260/285 [07:41<00:43,  1.73s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:43<00:41,  1.73s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:45<00:39,  1.72s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:46<00:36,  1.65s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:48<00:36,  1.74s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:50<00:35,  1.79s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:51<00:32,  1.69s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:53<00:29,  1.67s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:55<00:31,  1.86s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:57<00:30,  1.88s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:59<00:27,  1.82s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:00<00:24,  1.76s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:02<00:23,  1.79s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:04<00:20,  1.73s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:05<00:18,  1.64s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:07<00:17,  1.78s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:09<00:16,  1.81s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:11<00:13,  1.70s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:12<00:11,  1.64s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:14<00:10,  1.67s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:16<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:17<00:06,  1.61s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:19<00:04,  1.59s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:21<00:03,  1.75s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:23<00:01,  1.82s/it]predicting train subjects: 100%|██████████| 285/285 [08:25<00:00,  1.92s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:02<10:22,  2.19s/it]Loading train:   1%|          | 2/285 [00:04<10:03,  2.13s/it]Loading train:   1%|          | 3/285 [00:06<09:38,  2.05s/it]Loading train:   1%|▏         | 4/285 [00:07<09:03,  1.93s/it]Loading train:   2%|▏         | 5/285 [00:09<08:48,  1.89s/it]Loading train:   2%|▏         | 6/285 [00:11<08:16,  1.78s/it]Loading train:   2%|▏         | 7/285 [00:12<08:24,  1.82s/it]Loading train:   3%|▎         | 8/285 [00:14<08:08,  1.76s/it]Loading train:   3%|▎         | 9/285 [00:16<08:29,  1.84s/it]Loading train:   4%|▎         | 10/285 [00:18<08:26,  1.84s/it]Loading train:   4%|▍         | 11/285 [00:20<08:09,  1.79s/it]Loading train:   4%|▍         | 12/285 [00:21<08:06,  1.78s/it]Loading train:   5%|▍         | 13/285 [00:23<07:28,  1.65s/it]Loading train:   5%|▍         | 14/285 [00:24<07:28,  1.66s/it]Loading train:   5%|▌         | 15/285 [00:26<08:01,  1.78s/it]Loading train:   6%|▌         | 16/285 [00:28<08:05,  1.81s/it]Loading train:   6%|▌         | 17/285 [00:30<08:28,  1.90s/it]Loading train:   6%|▋         | 18/285 [00:32<07:52,  1.77s/it]Loading train:   7%|▋         | 19/285 [00:33<07:09,  1.61s/it]Loading train:   7%|▋         | 20/285 [00:34<06:44,  1.53s/it]Loading train:   7%|▋         | 21/285 [00:36<07:06,  1.62s/it]Loading train:   8%|▊         | 22/285 [00:38<06:47,  1.55s/it]Loading train:   8%|▊         | 23/285 [00:40<07:22,  1.69s/it]Loading train:   8%|▊         | 24/285 [00:41<07:04,  1.63s/it]Loading train:   9%|▉         | 25/285 [00:43<07:01,  1.62s/it]Loading train:   9%|▉         | 26/285 [00:45<07:32,  1.75s/it]Loading train:   9%|▉         | 27/285 [00:47<07:57,  1.85s/it]Loading train:  10%|▉         | 28/285 [00:49<07:39,  1.79s/it]Loading train:  10%|█         | 29/285 [00:50<07:35,  1.78s/it]Loading train:  11%|█         | 30/285 [00:52<07:44,  1.82s/it]Loading train:  11%|█         | 31/285 [00:54<08:01,  1.90s/it]Loading train:  11%|█         | 32/285 [00:56<07:28,  1.77s/it]Loading train:  12%|█▏        | 33/285 [00:58<07:22,  1.76s/it]Loading train:  12%|█▏        | 34/285 [00:59<07:15,  1.74s/it]Loading train:  12%|█▏        | 35/285 [01:01<07:13,  1.73s/it]Loading train:  13%|█▎        | 36/285 [01:03<07:00,  1.69s/it]Loading train:  13%|█▎        | 37/285 [01:04<07:18,  1.77s/it]Loading train:  13%|█▎        | 38/285 [01:06<07:22,  1.79s/it]Loading train:  14%|█▎        | 39/285 [01:08<07:00,  1.71s/it]Loading train:  14%|█▍        | 40/285 [01:09<06:37,  1.62s/it]Loading train:  14%|█▍        | 41/285 [01:11<06:16,  1.54s/it]Loading train:  15%|█▍        | 42/285 [01:12<05:52,  1.45s/it]Loading train:  15%|█▌        | 43/285 [01:13<05:55,  1.47s/it]Loading train:  15%|█▌        | 44/285 [01:15<06:00,  1.50s/it]Loading train:  16%|█▌        | 45/285 [01:17<06:15,  1.57s/it]Loading train:  16%|█▌        | 46/285 [01:18<06:25,  1.61s/it]Loading train:  16%|█▋        | 47/285 [01:20<06:11,  1.56s/it]Loading train:  17%|█▋        | 48/285 [01:21<06:04,  1.54s/it]Loading train:  17%|█▋        | 49/285 [01:23<06:17,  1.60s/it]Loading train:  18%|█▊        | 50/285 [01:25<06:35,  1.68s/it]Loading train:  18%|█▊        | 51/285 [01:27<06:47,  1.74s/it]Loading train:  18%|█▊        | 52/285 [01:28<06:39,  1.72s/it]Loading train:  19%|█▊        | 53/285 [01:30<06:19,  1.64s/it]Loading train:  19%|█▉        | 54/285 [01:32<06:38,  1.73s/it]Loading train:  19%|█▉        | 55/285 [01:34<07:07,  1.86s/it]Loading train:  20%|█▉        | 56/285 [01:36<07:05,  1.86s/it]Loading train:  20%|██        | 57/285 [01:37<06:35,  1.74s/it]Loading train:  20%|██        | 58/285 [01:39<06:17,  1.66s/it]Loading train:  21%|██        | 59/285 [01:41<06:21,  1.69s/it]Loading train:  21%|██        | 60/285 [01:42<06:14,  1.66s/it]Loading train:  21%|██▏       | 61/285 [01:43<05:49,  1.56s/it]Loading train:  22%|██▏       | 62/285 [01:45<05:31,  1.49s/it]Loading train:  22%|██▏       | 63/285 [01:46<05:31,  1.50s/it]Loading train:  22%|██▏       | 64/285 [01:49<06:29,  1.76s/it]Loading train:  23%|██▎       | 65/285 [01:51<07:25,  2.02s/it]Loading train:  23%|██▎       | 66/285 [01:54<07:46,  2.13s/it]Loading train:  24%|██▎       | 67/285 [01:56<07:43,  2.13s/it]Loading train:  24%|██▍       | 68/285 [01:57<06:55,  1.91s/it]Loading train:  24%|██▍       | 69/285 [01:59<06:42,  1.86s/it]Loading train:  25%|██▍       | 70/285 [02:00<06:16,  1.75s/it]Loading train:  25%|██▍       | 71/285 [02:02<05:49,  1.63s/it]Loading train:  25%|██▌       | 72/285 [02:03<05:30,  1.55s/it]Loading train:  26%|██▌       | 73/285 [02:05<05:33,  1.57s/it]Loading train:  26%|██▌       | 74/285 [02:07<05:56,  1.69s/it]Loading train:  26%|██▋       | 75/285 [02:08<05:37,  1.61s/it]Loading train:  27%|██▋       | 76/285 [02:10<05:32,  1.59s/it]Loading train:  27%|██▋       | 77/285 [02:11<05:17,  1.52s/it]Loading train:  27%|██▋       | 78/285 [02:12<05:04,  1.47s/it]Loading train:  28%|██▊       | 79/285 [02:14<05:03,  1.47s/it]Loading train:  28%|██▊       | 80/285 [02:15<05:04,  1.48s/it]Loading train:  28%|██▊       | 81/285 [02:17<05:05,  1.50s/it]Loading train:  29%|██▉       | 82/285 [02:19<05:09,  1.52s/it]Loading train:  29%|██▉       | 83/285 [02:20<05:15,  1.56s/it]Loading train:  29%|██▉       | 84/285 [02:22<05:05,  1.52s/it]Loading train:  30%|██▉       | 85/285 [02:23<05:15,  1.58s/it]Loading train:  30%|███       | 86/285 [02:25<05:12,  1.57s/it]Loading train:  31%|███       | 87/285 [02:27<05:15,  1.59s/it]Loading train:  31%|███       | 88/285 [02:28<05:06,  1.56s/it]Loading train:  31%|███       | 89/285 [02:30<05:07,  1.57s/it]Loading train:  32%|███▏      | 90/285 [02:31<05:05,  1.57s/it]Loading train:  32%|███▏      | 91/285 [02:33<04:56,  1.53s/it]Loading train:  32%|███▏      | 92/285 [02:34<04:47,  1.49s/it]Loading train:  33%|███▎      | 93/285 [02:35<04:39,  1.46s/it]Loading train:  33%|███▎      | 94/285 [02:37<04:46,  1.50s/it]Loading train:  33%|███▎      | 95/285 [02:39<04:56,  1.56s/it]Loading train:  34%|███▎      | 96/285 [02:41<05:21,  1.70s/it]Loading train:  34%|███▍      | 97/285 [02:42<05:15,  1.68s/it]Loading train:  34%|███▍      | 98/285 [02:44<05:03,  1.62s/it]Loading train:  35%|███▍      | 99/285 [02:45<04:52,  1.57s/it]Loading train:  35%|███▌      | 100/285 [02:47<05:06,  1.66s/it]Loading train:  35%|███▌      | 101/285 [02:49<05:21,  1.74s/it]Loading train:  36%|███▌      | 102/285 [02:51<05:10,  1.69s/it]Loading train:  36%|███▌      | 103/285 [02:52<05:03,  1.67s/it]Loading train:  36%|███▋      | 104/285 [02:54<04:54,  1.63s/it]Loading train:  37%|███▋      | 105/285 [02:56<05:02,  1.68s/it]Loading train:  37%|███▋      | 106/285 [02:57<04:43,  1.59s/it]Loading train:  38%|███▊      | 107/285 [02:59<04:39,  1.57s/it]Loading train:  38%|███▊      | 108/285 [03:00<04:12,  1.43s/it]Loading train:  38%|███▊      | 109/285 [03:01<04:19,  1.47s/it]Loading train:  39%|███▊      | 110/285 [03:03<04:15,  1.46s/it]Loading train:  39%|███▉      | 111/285 [03:04<04:26,  1.53s/it]Loading train:  39%|███▉      | 112/285 [03:06<04:28,  1.55s/it]Loading train:  40%|███▉      | 113/285 [03:08<04:30,  1.57s/it]Loading train:  40%|████      | 114/285 [03:09<04:26,  1.56s/it]Loading train:  40%|████      | 115/285 [03:11<04:36,  1.63s/it]Loading train:  41%|████      | 116/285 [03:13<04:36,  1.64s/it]Loading train:  41%|████      | 117/285 [03:14<04:29,  1.60s/it]Loading train:  41%|████▏     | 118/285 [03:16<04:28,  1.61s/it]Loading train:  42%|████▏     | 119/285 [03:17<04:21,  1.58s/it]Loading train:  42%|████▏     | 120/285 [03:19<04:18,  1.57s/it]Loading train:  42%|████▏     | 121/285 [03:20<04:14,  1.55s/it]Loading train:  43%|████▎     | 122/285 [03:22<04:05,  1.50s/it]Loading train:  43%|████▎     | 123/285 [03:23<03:59,  1.48s/it]Loading train:  44%|████▎     | 124/285 [03:24<03:49,  1.43s/it]Loading train:  44%|████▍     | 125/285 [03:26<03:40,  1.38s/it]Loading train:  44%|████▍     | 126/285 [03:27<03:43,  1.41s/it]Loading train:  45%|████▍     | 127/285 [03:29<03:58,  1.51s/it]Loading train:  45%|████▍     | 128/285 [03:31<04:05,  1.56s/it]Loading train:  45%|████▌     | 129/285 [03:32<04:19,  1.66s/it]Loading train:  46%|████▌     | 130/285 [03:34<03:58,  1.54s/it]Loading train:  46%|████▌     | 131/285 [03:35<04:09,  1.62s/it]Loading train:  46%|████▋     | 132/285 [03:37<03:59,  1.57s/it]Loading train:  47%|████▋     | 133/285 [03:38<03:50,  1.52s/it]Loading train:  47%|████▋     | 134/285 [03:40<03:50,  1.53s/it]Loading train:  47%|████▋     | 135/285 [03:41<03:47,  1.51s/it]Loading train:  48%|████▊     | 136/285 [03:42<03:27,  1.39s/it]Loading train:  48%|████▊     | 137/285 [03:44<03:26,  1.40s/it]Loading train:  48%|████▊     | 138/285 [03:45<03:19,  1.36s/it]Loading train:  49%|████▉     | 139/285 [03:47<03:22,  1.39s/it]Loading train:  49%|████▉     | 140/285 [03:48<03:16,  1.35s/it]Loading train:  49%|████▉     | 141/285 [03:49<03:13,  1.34s/it]Loading train:  50%|████▉     | 142/285 [03:51<03:18,  1.39s/it]Loading train:  50%|█████     | 143/285 [03:52<03:24,  1.44s/it]Loading train:  51%|█████     | 144/285 [03:53<03:14,  1.38s/it]Loading train:  51%|█████     | 145/285 [03:55<03:06,  1.33s/it]Loading train:  51%|█████     | 146/285 [03:56<03:00,  1.30s/it]Loading train:  52%|█████▏    | 147/285 [03:57<03:03,  1.33s/it]Loading train:  52%|█████▏    | 148/285 [03:59<02:58,  1.30s/it]Loading train:  52%|█████▏    | 149/285 [04:00<02:59,  1.32s/it]Loading train:  53%|█████▎    | 150/285 [04:01<03:03,  1.36s/it]Loading train:  53%|█████▎    | 151/285 [04:03<03:13,  1.45s/it]Loading train:  53%|█████▎    | 152/285 [04:04<03:12,  1.45s/it]Loading train:  54%|█████▎    | 153/285 [04:06<03:00,  1.37s/it]Loading train:  54%|█████▍    | 154/285 [04:07<02:53,  1.33s/it]Loading train:  54%|█████▍    | 155/285 [04:08<03:01,  1.39s/it]Loading train:  55%|█████▍    | 156/285 [04:10<02:51,  1.33s/it]Loading train:  55%|█████▌    | 157/285 [04:11<02:55,  1.37s/it]Loading train:  55%|█████▌    | 158/285 [04:13<03:00,  1.42s/it]Loading train:  56%|█████▌    | 159/285 [04:14<02:50,  1.36s/it]Loading train:  56%|█████▌    | 160/285 [04:15<02:50,  1.36s/it]Loading train:  56%|█████▋    | 161/285 [04:16<02:46,  1.34s/it]Loading train:  57%|█████▋    | 162/285 [04:18<02:45,  1.34s/it]Loading train:  57%|█████▋    | 163/285 [04:19<02:38,  1.30s/it]Loading train:  58%|█████▊    | 164/285 [04:21<02:46,  1.38s/it]Loading train:  58%|█████▊    | 165/285 [04:22<02:43,  1.36s/it]Loading train:  58%|█████▊    | 166/285 [04:23<02:39,  1.34s/it]Loading train:  59%|█████▊    | 167/285 [04:25<02:43,  1.39s/it]Loading train:  59%|█████▉    | 168/285 [04:26<02:46,  1.43s/it]Loading train:  59%|█████▉    | 169/285 [04:28<03:11,  1.65s/it]Loading train:  60%|█████▉    | 170/285 [04:30<02:51,  1.49s/it]Loading train:  60%|██████    | 171/285 [04:31<02:42,  1.42s/it]Loading train:  60%|██████    | 172/285 [04:33<02:57,  1.57s/it]Loading train:  61%|██████    | 173/285 [04:34<02:47,  1.49s/it]Loading train:  61%|██████    | 174/285 [04:36<02:48,  1.52s/it]Loading train:  61%|██████▏   | 175/285 [04:37<02:46,  1.52s/it]Loading train:  62%|██████▏   | 176/285 [04:39<02:44,  1.51s/it]Loading train:  62%|██████▏   | 177/285 [04:40<02:34,  1.43s/it]Loading train:  62%|██████▏   | 178/285 [04:41<02:31,  1.42s/it]Loading train:  63%|██████▎   | 179/285 [04:43<02:30,  1.42s/it]Loading train:  63%|██████▎   | 180/285 [04:44<02:32,  1.46s/it]Loading train:  64%|██████▎   | 181/285 [04:46<02:33,  1.48s/it]Loading train:  64%|██████▍   | 182/285 [04:47<02:27,  1.43s/it]Loading train:  64%|██████▍   | 183/285 [04:48<02:16,  1.33s/it]Loading train:  65%|██████▍   | 184/285 [04:50<02:26,  1.45s/it]Loading train:  65%|██████▍   | 185/285 [04:51<02:16,  1.37s/it]Loading train:  65%|██████▌   | 186/285 [04:53<02:21,  1.42s/it]Loading train:  66%|██████▌   | 187/285 [04:54<02:23,  1.47s/it]Loading train:  66%|██████▌   | 188/285 [04:56<02:22,  1.47s/it]Loading train:  66%|██████▋   | 189/285 [04:57<02:15,  1.41s/it]Loading train:  67%|██████▋   | 190/285 [04:59<02:19,  1.47s/it]Loading train:  67%|██████▋   | 191/285 [05:00<02:15,  1.44s/it]Loading train:  67%|██████▋   | 192/285 [05:01<02:12,  1.43s/it]Loading train:  68%|██████▊   | 193/285 [05:03<02:11,  1.43s/it]Loading train:  68%|██████▊   | 194/285 [05:04<02:04,  1.37s/it]Loading train:  68%|██████▊   | 195/285 [05:06<02:09,  1.44s/it]Loading train:  69%|██████▉   | 196/285 [05:07<02:19,  1.57s/it]Loading train:  69%|██████▉   | 197/285 [05:09<02:20,  1.60s/it]Loading train:  69%|██████▉   | 198/285 [05:11<02:19,  1.60s/it]Loading train:  70%|██████▉   | 199/285 [05:12<02:10,  1.52s/it]Loading train:  70%|███████   | 200/285 [05:13<02:01,  1.43s/it]Loading train:  71%|███████   | 201/285 [05:15<02:04,  1.48s/it]Loading train:  71%|███████   | 202/285 [05:17<02:09,  1.57s/it]Loading train:  71%|███████   | 203/285 [05:18<02:01,  1.48s/it]Loading train:  72%|███████▏  | 204/285 [05:19<02:00,  1.48s/it]Loading train:  72%|███████▏  | 205/285 [05:21<01:56,  1.46s/it]Loading train:  72%|███████▏  | 206/285 [05:22<01:51,  1.41s/it]Loading train:  73%|███████▎  | 207/285 [05:24<01:54,  1.47s/it]Loading train:  73%|███████▎  | 208/285 [05:25<02:00,  1.57s/it]Loading train:  73%|███████▎  | 209/285 [05:27<01:56,  1.53s/it]Loading train:  74%|███████▎  | 210/285 [05:28<01:50,  1.48s/it]Loading train:  74%|███████▍  | 211/285 [05:30<01:53,  1.53s/it]Loading train:  74%|███████▍  | 212/285 [05:32<01:55,  1.59s/it]Loading train:  75%|███████▍  | 213/285 [05:33<01:46,  1.48s/it]Loading train:  75%|███████▌  | 214/285 [05:34<01:38,  1.39s/it]Loading train:  75%|███████▌  | 215/285 [05:35<01:38,  1.40s/it]Loading train:  76%|███████▌  | 216/285 [05:37<01:33,  1.36s/it]Loading train:  76%|███████▌  | 217/285 [05:39<01:42,  1.51s/it]Loading train:  76%|███████▋  | 218/285 [05:40<01:36,  1.44s/it]Loading train:  77%|███████▋  | 219/285 [05:42<01:41,  1.55s/it]Loading train:  77%|███████▋  | 220/285 [05:43<01:42,  1.57s/it]Loading train:  78%|███████▊  | 221/285 [05:44<01:28,  1.38s/it]Loading train:  78%|███████▊  | 222/285 [05:46<01:29,  1.43s/it]Loading train:  78%|███████▊  | 223/285 [05:47<01:31,  1.47s/it]Loading train:  79%|███████▊  | 224/285 [05:48<01:21,  1.34s/it]Loading train:  79%|███████▉  | 225/285 [05:50<01:24,  1.41s/it]Loading train:  79%|███████▉  | 226/285 [05:52<01:34,  1.60s/it]Loading train:  80%|███████▉  | 227/285 [05:54<01:34,  1.62s/it]Loading train:  80%|████████  | 228/285 [05:55<01:27,  1.53s/it]Loading train:  80%|████████  | 229/285 [05:57<01:28,  1.58s/it]Loading train:  81%|████████  | 230/285 [05:58<01:22,  1.49s/it]Loading train:  81%|████████  | 231/285 [05:59<01:15,  1.41s/it]Loading train:  81%|████████▏ | 232/285 [06:00<01:11,  1.35s/it]Loading train:  82%|████████▏ | 233/285 [06:02<01:08,  1.31s/it]Loading train:  82%|████████▏ | 234/285 [06:03<01:14,  1.47s/it]Loading train:  82%|████████▏ | 235/285 [06:05<01:10,  1.42s/it]Loading train:  83%|████████▎ | 236/285 [06:06<01:13,  1.50s/it]Loading train:  83%|████████▎ | 237/285 [06:08<01:13,  1.52s/it]Loading train:  84%|████████▎ | 238/285 [06:09<01:06,  1.42s/it]Loading train:  84%|████████▍ | 239/285 [06:11<01:05,  1.43s/it]Loading train:  84%|████████▍ | 240/285 [06:12<01:07,  1.50s/it]Loading train:  85%|████████▍ | 241/285 [06:14<01:04,  1.46s/it]Loading train:  85%|████████▍ | 242/285 [06:15<01:02,  1.45s/it]Loading train:  85%|████████▌ | 243/285 [06:17<01:01,  1.47s/it]Loading train:  86%|████████▌ | 244/285 [06:18<01:03,  1.56s/it]Loading train:  86%|████████▌ | 245/285 [06:20<01:03,  1.60s/it]Loading train:  86%|████████▋ | 246/285 [06:22<01:03,  1.64s/it]Loading train:  87%|████████▋ | 247/285 [06:23<01:00,  1.60s/it]Loading train:  87%|████████▋ | 248/285 [06:25<00:58,  1.58s/it]Loading train:  87%|████████▋ | 249/285 [06:27<00:57,  1.60s/it]Loading train:  88%|████████▊ | 250/285 [06:28<00:51,  1.46s/it]Loading train:  88%|████████▊ | 251/285 [06:29<00:46,  1.36s/it]Loading train:  88%|████████▊ | 252/285 [06:30<00:44,  1.36s/it]Loading train:  89%|████████▉ | 253/285 [06:32<00:46,  1.45s/it]Loading train:  89%|████████▉ | 254/285 [06:33<00:47,  1.52s/it]Loading train:  89%|████████▉ | 255/285 [06:35<00:43,  1.46s/it]Loading train:  90%|████████▉ | 256/285 [06:36<00:41,  1.43s/it]Loading train:  90%|█████████ | 257/285 [06:38<00:40,  1.43s/it]Loading train:  91%|█████████ | 258/285 [06:39<00:40,  1.51s/it]Loading train:  91%|█████████ | 259/285 [06:41<00:37,  1.45s/it]Loading train:  91%|█████████ | 260/285 [06:42<00:36,  1.45s/it]Loading train:  92%|█████████▏| 261/285 [06:43<00:34,  1.43s/it]Loading train:  92%|█████████▏| 262/285 [06:45<00:31,  1.37s/it]Loading train:  92%|█████████▏| 263/285 [06:46<00:27,  1.25s/it]Loading train:  93%|█████████▎| 264/285 [06:47<00:25,  1.22s/it]Loading train:  93%|█████████▎| 265/285 [06:48<00:24,  1.20s/it]Loading train:  93%|█████████▎| 266/285 [06:49<00:20,  1.10s/it]Loading train:  94%|█████████▎| 267/285 [06:50<00:20,  1.14s/it]Loading train:  94%|█████████▍| 268/285 [06:52<00:22,  1.34s/it]Loading train:  94%|█████████▍| 269/285 [06:53<00:22,  1.39s/it]Loading train:  95%|█████████▍| 270/285 [06:55<00:20,  1.34s/it]Loading train:  95%|█████████▌| 271/285 [06:56<00:18,  1.31s/it]Loading train:  95%|█████████▌| 272/285 [06:57<00:16,  1.27s/it]Loading train:  96%|█████████▌| 273/285 [06:58<00:14,  1.19s/it]Loading train:  96%|█████████▌| 274/285 [06:59<00:12,  1.15s/it]Loading train:  96%|█████████▋| 275/285 [07:00<00:12,  1.22s/it]Loading train:  97%|█████████▋| 276/285 [07:02<00:11,  1.32s/it]Loading train:  97%|█████████▋| 277/285 [07:03<00:10,  1.27s/it]Loading train:  98%|█████████▊| 278/285 [07:04<00:09,  1.29s/it]Loading train:  98%|█████████▊| 279/285 [07:06<00:07,  1.28s/it]Loading train:  98%|█████████▊| 280/285 [07:07<00:06,  1.24s/it]Loading train:  99%|█████████▊| 281/285 [07:08<00:04,  1.18s/it]Loading train:  99%|█████████▉| 282/285 [07:09<00:03,  1.15s/it]Loading train:  99%|█████████▉| 283/285 [07:10<00:02,  1.22s/it]Loading train: 100%|█████████▉| 284/285 [07:12<00:01,  1.21s/it]Loading train: 100%|██████████| 285/285 [07:13<00:00,  1.24s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 7/285 [00:00<00:04, 67.80it/s]concatenating: train:   5%|▍         | 14/285 [00:00<00:04, 67.67it/s]concatenating: train:   7%|▋         | 21/285 [00:00<00:04, 65.29it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:03, 64.43it/s]concatenating: train:  12%|█▏        | 35/285 [00:00<00:03, 63.84it/s]concatenating: train:  15%|█▍        | 42/285 [00:00<00:04, 60.57it/s]concatenating: train:  17%|█▋        | 49/285 [00:00<00:03, 62.58it/s]concatenating: train:  23%|██▎       | 65/285 [00:00<00:02, 76.39it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:02, 89.57it/s]concatenating: train:  38%|███▊      | 109/285 [00:01<00:01, 111.64it/s]concatenating: train:  45%|████▍     | 128/285 [00:01<00:01, 121.91it/s]concatenating: train:  51%|█████     | 144/285 [00:01<00:01, 99.93it/s] concatenating: train:  55%|█████▌    | 158/285 [00:01<00:01, 109.05it/s]concatenating: train:  60%|██████    | 172/285 [00:01<00:00, 113.61it/s]concatenating: train:  65%|██████▍   | 185/285 [00:01<00:00, 113.26it/s]concatenating: train:  76%|███████▌  | 216/285 [00:01<00:00, 139.64it/s]concatenating: train:  86%|████████▌ | 245/285 [00:01<00:00, 164.63it/s]concatenating: train:  94%|█████████▍| 269/285 [00:02<00:00, 181.39it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 131.69it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.46s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.43s/it]Loading test: 100%|██████████| 3/3 [00:04<00:00,  1.45s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 57.81it/s]2019-07-11 13:28:19.508632: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 13:28:19.508791: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 13:28:19.508809: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 13:28:19.508819: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 13:28:19.509212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:10,  4.13it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.96it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.76it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.13it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.55it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  6.26it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:05,  5.53it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:03,  7.15it/s]loading the weights for Res Unet:  43%|████▎     | 19/44 [00:02<00:03,  7.56it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:03,  6.09it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.58it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:02<00:02,  8.09it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  8.11it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  6.48it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:03<00:01,  7.78it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:00,  7.73it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.79it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  6.42it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:04<00:00,  5.44it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:04<00:00,  8.92it/s]
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 1  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd1/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 52, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 52, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 52, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 52, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 52, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 52, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 52, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 52, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 52, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 52, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 52, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 52, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 52, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 52, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 52, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 52, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 26, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 26, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 26, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 26, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 26, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 26, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 26, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 26, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 26, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 13, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 13, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 13, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 13, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 13, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 13, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 13, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 13, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 13, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 13, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 26, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 26, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 26, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 26, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 26, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 26, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 26, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 26, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 26, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 26, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 52, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 52, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 52, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 52, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 52, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 52, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 52, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 52, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 52, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 52, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 52, 52, 40)   21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 52, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 52, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 52, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 52, 52, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 52, 52, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 52, 52, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 52, 52, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 52, 52, 100)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 52, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 283,113
Trainable params: 108,113
Non-trainable params: 175,000
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.49841486e-02 3.19966680e-02 7.50970181e-02 9.33357939e-03
 2.71292049e-02 7.07427267e-03 8.46489586e-02 1.12779077e-01
 8.61338510e-02 1.32649165e-02 2.94521391e-01 1.92807035e-01
 2.29878984e-04]
Train on 18361 samples, validate on 179 samples
Epoch 1/300
 - 26s - loss: 1.9807 - acc: 0.7231 - mDice: 0.2201 - val_loss: 1.7054 - val_acc: 0.9215 - val_mDice: 0.2583

Epoch 00001: val_mDice improved from -inf to 0.25830, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 20s - loss: 0.6828 - acc: 0.9186 - mDice: 0.4915 - val_loss: 0.6165 - val_acc: 0.9434 - val_mDice: 0.5381

Epoch 00002: val_mDice improved from 0.25830 to 0.53810, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 19s - loss: 0.5422 - acc: 0.9315 - mDice: 0.5673 - val_loss: 0.5479 - val_acc: 0.9465 - val_mDice: 0.5749

Epoch 00003: val_mDice improved from 0.53810 to 0.57493, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 4/300
 - 19s - loss: 0.4762 - acc: 0.9373 - mDice: 0.6065 - val_loss: 0.4915 - val_acc: 0.9481 - val_mDice: 0.6008

Epoch 00004: val_mDice improved from 0.57493 to 0.60080, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 19s - loss: 0.4404 - acc: 0.9404 - mDice: 0.6291 - val_loss: 0.5085 - val_acc: 0.9498 - val_mDice: 0.5939

Epoch 00005: val_mDice did not improve from 0.60080
Epoch 6/300
 - 19s - loss: 0.4136 - acc: 0.9426 - mDice: 0.6466 - val_loss: 0.4927 - val_acc: 0.9482 - val_mDice: 0.5993

Epoch 00006: val_mDice did not improve from 0.60080
Epoch 7/300
 - 19s - loss: 0.3948 - acc: 0.9442 - mDice: 0.6592 - val_loss: 0.5262 - val_acc: 0.9504 - val_mDice: 0.5832

Epoch 00007: val_mDice did not improve from 0.60080
Epoch 8/300
 - 19s - loss: 0.3803 - acc: 0.9454 - mDice: 0.6694 - val_loss: 0.4802 - val_acc: 0.9479 - val_mDice: 0.6082

Epoch 00008: val_mDice improved from 0.60080 to 0.60817, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 9/300
 - 19s - loss: 0.3680 - acc: 0.9464 - mDice: 0.6777 - val_loss: 0.4960 - val_acc: 0.9483 - val_mDice: 0.6019

Epoch 00009: val_mDice did not improve from 0.60817
Epoch 10/300
 - 19s - loss: 0.3599 - acc: 0.9468 - mDice: 0.6833 - val_loss: 0.5005 - val_acc: 0.9509 - val_mDice: 0.5998

Epoch 00010: val_mDice did not improve from 0.60817
Epoch 11/300
 - 19s - loss: 0.3478 - acc: 0.9479 - mDice: 0.6918 - val_loss: 0.4749 - val_acc: 0.9511 - val_mDice: 0.6133

Epoch 00011: val_mDice improved from 0.60817 to 0.61333, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 12/300
 - 19s - loss: 0.3411 - acc: 0.9485 - mDice: 0.6968 - val_loss: 0.4942 - val_acc: 0.9503 - val_mDice: 0.6004

Epoch 00012: val_mDice did not improve from 0.61333
Epoch 13/300
 - 19s - loss: 0.3374 - acc: 0.9488 - mDice: 0.6995 - val_loss: 0.4750 - val_acc: 0.9531 - val_mDice: 0.6159

Epoch 00013: val_mDice improved from 0.61333 to 0.61591, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd1/best_model_weights_TF_CSFn2.h5
Epoch 14/300
 - 19s - loss: 0.3269 - acc: 0.9496 - mDice: 0.7070 - val_loss: 0.4848 - val_acc: 0.9500 - val_mDice: 0.6056

Epoch 00014: val_mDice did not improve from 0.61591
Epoch 15/300
 - 19s - loss: 0.3218 - acc: 0.9499 - mDice: 0.7108 - val_loss: 0.4840 - val_acc: 0.9509 - val_mDice: 0.6047

Epoch 00015: val_mDice did not improve from 0.61591
Epoch 16/300
 - 19s - loss: 0.3178 - acc: 0.9502 - mDice: 0.7137 - val_loss: 0.4906 - val_acc: 0.9534 - val_mDice: 0.6046

Epoch 00016: val_mDice did not improve from 0.61591
Epoch 17/300
 - 19s - loss: 0.3140 - acc: 0.9506 - mDice: 0.7167 - val_loss: 0.5266 - val_acc: 0.9505 - val_mDice: 0.5877

Epoch 00017: val_mDice did not improve from 0.61591
Epoch 18/300
 - 19s - loss: 0.3072 - acc: 0.9512 - mDice: 0.7217 - val_loss: 0.5410 - val_acc: 0.9507 - val_mDice: 0.5846

Epoch 00018: val_mDice did not improve from 0.61591
Epoch 19/300
 - 19s - loss: 0.3040 - acc: 0.9514 - mDice: 0.7242 - val_loss: 0.4918 - val_acc: 0.9498 - val_mDice: 0.6044

Epoch 00019: val_mDice did not improve from 0.61591
Epoch 20/300
 - 19s - loss: 0.3007 - acc: 0.9517 - mDice: 0.7266 - val_loss: 0.5172 - val_acc: 0.9526 - val_mDice: 0.5938

Epoch 00020: val_mDice did not improve from 0.61591
Epoch 21/300
 - 19s - loss: 0.2985 - acc: 0.9518 - mDice: 0.7282 - val_loss: 0.5432 - val_acc: 0.9485 - val_mDice: 0.5813

Epoch 00021: val_mDice did not improve from 0.61591
Epoch 22/300
 - 19s - loss: 0.2942 - acc: 0.9522 - mDice: 0.7316 - val_loss: 0.5148 - val_acc: 0.9505 - val_mDice: 0.5955

Epoch 00022: val_mDice did not improve from 0.61591
Epoch 23/300
 - 19s - loss: 0.2889 - acc: 0.9526 - mDice: 0.7355 - val_loss: 0.4964 - val_acc: 0.9501 - val_mDice: 0.6030

Epoch 00023: val_mDice did not improve from 0.61591
Epoch 24/300
 - 19s - loss: 0.2874 - acc: 0.9527 - mDice: 0.7368 - val_loss: 0.5158 - val_acc: 0.9474 - val_mDice: 0.5895

Epoch 00024: val_mDice did not improve from 0.61591
Epoch 25/300
 - 19s - loss: 0.2843 - acc: 0.9530 - mDice: 0.7391 - val_loss: 0.5059 - val_acc: 0.9512 - val_mDice: 0.5981

Epoch 00025: val_mDice did not improve from 0.61591
Epoch 26/300
 - 19s - loss: 0.2818 - acc: 0.9532 - mDice: 0.7411 - val_loss: 0.4961 - val_acc: 0.9510 - val_mDice: 0.6007

Epoch 00026: val_mDice did not improve from 0.61591
Epoch 27/300
 - 19s - loss: 0.2801 - acc: 0.9534 - mDice: 0.7424 - val_loss: 0.5125 - val_acc: 0.9514 - val_mDice: 0.5933

Epoch 00027: val_mDice did not improve from 0.61591
Epoch 28/300
 - 19s - loss: 0.2760 - acc: 0.9535 - mDice: 0.7454 - val_loss: 0.5001 - val_acc: 0.9509 - val_mDice: 0.5985

Epoch 00028: val_mDice did not improve from 0.61591
Epoch 29/300
 - 19s - loss: 0.2746 - acc: 0.9538 - mDice: 0.7467 - val_loss: 0.5001 - val_acc: 0.9500 - val_mDice: 0.5985

Epoch 00029: val_mDice did not improve from 0.61591
Epoch 30/300
 - 19s - loss: 0.2761 - acc: 0.9537 - mDice: 0.7455 - val_loss: 0.4958 - val_acc: 0.9523 - val_mDice: 0.6034

Epoch 00030: val_mDice did not improve from 0.61591
Epoch 31/300
 - 19s - loss: 0.2703 - acc: 0.9541 - mDice: 0.7499 - val_loss: 0.4940 - val_acc: 0.9518 - val_mDice: 0.6047

Epoch 00031: val_mDice did not improve from 0.61591
Epoch 32/300
 - 19s - loss: 0.2710 - acc: 0.9541 - mDice: 0.7497 - val_loss: 0.4921 - val_acc: 0.9502 - val_mDice: 0.6030

Epoch 00032: val_mDice did not improve from 0.61591
Epoch 33/300
 - 19s - loss: 0.2672 - acc: 0.9544 - mDice: 0.7524 - val_loss: 0.5046 - val_acc: 0.9514 - val_mDice: 0.5995

Epoch 00033: val_mDice did not improve from 0.61591
Epoch 34/300
 - 19s - loss: 0.2655 - acc: 0.9545 - mDice: 0.7539 - val_loss: 0.5040 - val_acc: 0.9517 - val_mDice: 0.6010

Epoch 00034: val_mDice did not improve from 0.61591
Epoch 35/300
 - 19s - loss: 0.2627 - acc: 0.9547 - mDice: 0.7559 - val_loss: 0.5086 - val_acc: 0.9491 - val_mDice: 0.5964

Epoch 00035: val_mDice did not improve from 0.61591
Epoch 36/300
 - 19s - loss: 0.2627 - acc: 0.9548 - mDice: 0.7561 - val_loss: 0.5139 - val_acc: 0.9505 - val_mDice: 0.5929

Epoch 00036: val_mDice did not improve from 0.61591
Epoch 37/300
 - 19s - loss: 0.2604 - acc: 0.9549 - mDice: 0.7578 - val_loss: 0.4819 - val_acc: 0.9523 - val_mDice: 0.6104

Epoch 00037: val_mDice did not improve from 0.61591
Epoch 38/300
 - 19s - loss: 0.2585 - acc: 0.9551 - mDice: 0.7593 - val_loss: 0.4961 - val_acc: 0.9518 - val_mDice: 0.6044

Epoch 00038: val_mDice did not improve from 0.61591
Epoch 39/300
 - 19s - loss: 0.2592 - acc: 0.9550 - mDice: 0.7587 - val_loss: 0.5036 - val_acc: 0.9487 - val_mDice: 0.5965

Epoch 00039: val_mDice did not improve from 0.61591
Epoch 40/300
 - 19s - loss: 0.2564 - acc: 0.9553 - mDice: 0.7609 - val_loss: 0.5008 - val_acc: 0.9513 - val_mDice: 0.6010

Epoch 00040: val_mDice did not improve from 0.61591
Epoch 41/300
 - 19s - loss: 0.2570 - acc: 0.9552 - mDice: 0.7605 - val_loss: 0.5137 - val_acc: 0.9496 - val_mDice: 0.5920

Epoch 00041: val_mDice did not improve from 0.61591
Epoch 42/300
 - 19s - loss: 0.2555 - acc: 0.9554 - mDice: 0.7617 - val_loss: 0.4753 - val_acc: 0.9514 - val_mDice: 0.6126

Epoch 00042: val_mDice did not improve from 0.61591
Epoch 43/300
 - 19s - loss: 0.2541 - acc: 0.9555 - mDice: 0.7630 - val_loss: 0.4822 - val_acc: 0.9511 - val_mDice: 0.6098

Epoch 00043: val_mDice did not improve from 0.61591
Epoch 44/300
 - 19s - loss: 0.2515 - acc: 0.9556 - mDice: 0.7649 - val_loss: 0.4993 - val_acc: 0.9516 - val_mDice: 0.6002

Epoch 00044: val_mDice did not improve from 0.61591
Epoch 45/300
 - 19s - loss: 0.2517 - acc: 0.9556 - mDice: 0.7647 - val_loss: 0.5083 - val_acc: 0.9515 - val_mDice: 0.5977

Epoch 00045: val_mDice did not improve from 0.61591
Epoch 46/300
 - 19s - loss: 0.2491 - acc: 0.9558 - mDice: 0.7667 - val_loss: 0.4991 - val_acc: 0.9510 - val_mDice: 0.6007

Epoch 00046: val_mDice did not improve from 0.61591
Epoch 47/300
 - 19s - loss: 0.2482 - acc: 0.9559 - mDice: 0.7675 - val_loss: 0.5270 - val_acc: 0.9484 - val_mDice: 0.5877

Epoch 00047: val_mDice did not improve from 0.61591
Epoch 48/300
 - 19s - loss: 0.2468 - acc: 0.9561 - mDice: 0.7686 - val_loss: 0.5003 - val_acc: 0.9510 - val_mDice: 0.5996

Epoch 00048: val_mDice did not improve from 0.61591
Epoch 49/300
 - 19s - loss: 0.2459 - acc: 0.9561 - mDice: 0.7693 - val_loss: 0.5041 - val_acc: 0.9497 - val_mDice: 0.5996

Epoch 00049: val_mDice did not improve from 0.61591
Epoch 50/300
 - 19s - loss: 0.2451 - acc: 0.9561 - mDice: 0.7700 - val_loss: 0.4860 - val_acc: 0.9518 - val_mDice: 0.6085

Epoch 00050: val_mDice did not improve from 0.61591
Epoch 51/300
 - 19s - loss: 0.2500 - acc: 0.9558 - mDice: 0.7664 - val_loss: 0.4885 - val_acc: 0.9506 - val_mDice: 0.6070

Epoch 00051: val_mDice did not improve from 0.61591
Epoch 52/300
 - 19s - loss: 0.2435 - acc: 0.9562 - mDice: 0.7713 - val_loss: 0.4885 - val_acc: 0.9519 - val_mDice: 0.6069

Epoch 00052: val_mDice did not improve from 0.61591
Epoch 53/300
 - 19s - loss: 0.2430 - acc: 0.9563 - mDice: 0.7717 - val_loss: 0.4923 - val_acc: 0.9518 - val_mDice: 0.6066

predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.48s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.23s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.06s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:02<10:11,  2.15s/it]predicting train subjects:   1%|          | 2/285 [00:03<09:25,  2.00s/it]predicting train subjects:   1%|          | 3/285 [00:05<09:14,  1.97s/it]predicting train subjects:   1%|▏         | 4/285 [00:07<08:32,  1.82s/it]predicting train subjects:   2%|▏         | 5/285 [00:09<08:40,  1.86s/it]predicting train subjects:   2%|▏         | 6/285 [00:10<08:06,  1.74s/it]predicting train subjects:   2%|▏         | 7/285 [00:12<08:13,  1.77s/it]predicting train subjects:   3%|▎         | 8/285 [00:14<08:16,  1.79s/it]predicting train subjects:   3%|▎         | 9/285 [00:16<09:03,  1.97s/it]predicting train subjects:   4%|▎         | 10/285 [00:18<09:27,  2.06s/it]predicting train subjects:   4%|▍         | 11/285 [00:20<09:15,  2.03s/it]predicting train subjects:   4%|▍         | 12/285 [00:23<09:33,  2.10s/it]predicting train subjects:   5%|▍         | 13/285 [00:24<08:59,  1.98s/it]predicting train subjects:   5%|▍         | 14/285 [00:26<08:53,  1.97s/it]predicting train subjects:   5%|▌         | 15/285 [00:28<09:07,  2.03s/it]predicting train subjects:   6%|▌         | 16/285 [00:31<09:13,  2.06s/it]predicting train subjects:   6%|▌         | 17/285 [00:32<08:50,  1.98s/it]predicting train subjects:   6%|▋         | 18/285 [00:34<08:55,  2.01s/it]predicting train subjects:   7%|▋         | 19/285 [00:36<08:40,  1.95s/it]predicting train subjects:   7%|▋         | 20/285 [00:38<08:55,  2.02s/it]predicting train subjects:   7%|▋         | 21/285 [00:41<09:17,  2.11s/it]predicting train subjects:   8%|▊         | 22/285 [00:42<08:40,  1.98s/it]predicting train subjects:   8%|▊         | 23/285 [00:44<08:42,  2.00s/it]predicting train subjects:   8%|▊         | 24/285 [00:46<08:14,  1.89s/it]predicting train subjects:   9%|▉         | 25/285 [00:48<08:30,  1.96s/it]predicting train subjects:   9%|▉         | 26/285 [00:50<08:43,  2.02s/it]predicting train subjects:   9%|▉         | 27/285 [00:52<08:24,  1.95s/it]predicting train subjects:  10%|▉         | 28/285 [00:54<08:26,  1.97s/it]predicting train subjects:  10%|█         | 29/285 [00:56<08:36,  2.02s/it]predicting train subjects:  11%|█         | 30/285 [00:59<08:47,  2.07s/it]predicting train subjects:  11%|█         | 31/285 [01:01<08:49,  2.09s/it]predicting train subjects:  11%|█         | 32/285 [01:02<08:18,  1.97s/it]predicting train subjects:  12%|█▏        | 33/285 [01:04<08:09,  1.94s/it]predicting train subjects:  12%|█▏        | 34/285 [01:06<08:01,  1.92s/it]predicting train subjects:  12%|█▏        | 35/285 [01:08<08:19,  2.00s/it]predicting train subjects:  13%|█▎        | 36/285 [01:10<08:02,  1.94s/it]predicting train subjects:  13%|█▎        | 37/285 [01:12<08:11,  1.98s/it]predicting train subjects:  13%|█▎        | 38/285 [01:14<08:28,  2.06s/it]predicting train subjects:  14%|█▎        | 39/285 [01:16<08:22,  2.04s/it]predicting train subjects:  14%|█▍        | 40/285 [01:18<08:11,  2.01s/it]predicting train subjects:  14%|█▍        | 41/285 [01:20<07:44,  1.90s/it]predicting train subjects:  15%|█▍        | 42/285 [01:22<07:25,  1.83s/it]predicting train subjects:  15%|█▌        | 43/285 [01:24<07:26,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:26<07:38,  1.90s/it]predicting train subjects:  16%|█▌        | 45/285 [01:27<07:26,  1.86s/it]predicting train subjects:  16%|█▌        | 46/285 [01:30<07:51,  1.97s/it]predicting train subjects:  16%|█▋        | 47/285 [01:31<07:45,  1.95s/it]predicting train subjects:  17%|█▋        | 48/285 [01:34<07:51,  1.99s/it]predicting train subjects:  17%|█▋        | 49/285 [01:36<07:56,  2.02s/it]predicting train subjects:  18%|█▊        | 50/285 [01:38<07:51,  2.01s/it]predicting train subjects:  18%|█▊        | 51/285 [01:40<07:57,  2.04s/it]predicting train subjects:  18%|█▊        | 52/285 [01:42<07:36,  1.96s/it]predicting train subjects:  19%|█▊        | 53/285 [01:43<07:30,  1.94s/it]predicting train subjects:  19%|█▉        | 54/285 [01:46<07:48,  2.03s/it]predicting train subjects:  19%|█▉        | 55/285 [01:47<07:32,  1.97s/it]predicting train subjects:  20%|█▉        | 56/285 [01:50<07:36,  1.99s/it]predicting train subjects:  20%|██        | 57/285 [01:51<07:33,  1.99s/it]predicting train subjects:  20%|██        | 58/285 [01:53<07:23,  1.95s/it]predicting train subjects:  21%|██        | 59/285 [01:56<07:41,  2.04s/it]predicting train subjects:  21%|██        | 60/285 [01:58<07:47,  2.08s/it]predicting train subjects:  21%|██▏       | 61/285 [01:59<07:19,  1.96s/it]predicting train subjects:  22%|██▏       | 62/285 [02:01<07:14,  1.95s/it]predicting train subjects:  22%|██▏       | 63/285 [02:03<07:18,  1.98s/it]predicting train subjects:  22%|██▏       | 64/285 [02:05<07:09,  1.94s/it]predicting train subjects:  23%|██▎       | 65/285 [02:07<07:15,  1.98s/it]predicting train subjects:  23%|██▎       | 66/285 [02:09<07:19,  2.01s/it]predicting train subjects:  24%|██▎       | 67/285 [02:11<07:07,  1.96s/it]predicting train subjects:  24%|██▍       | 68/285 [02:13<06:51,  1.90s/it]predicting train subjects:  24%|██▍       | 69/285 [02:15<06:53,  1.92s/it]predicting train subjects:  25%|██▍       | 70/285 [02:17<07:01,  1.96s/it]predicting train subjects:  25%|██▍       | 71/285 [02:19<06:53,  1.93s/it]predicting train subjects:  25%|██▌       | 72/285 [02:21<06:41,  1.89s/it]predicting train subjects:  26%|██▌       | 73/285 [02:23<06:52,  1.95s/it]predicting train subjects:  26%|██▌       | 74/285 [02:25<07:01,  2.00s/it]predicting train subjects:  26%|██▋       | 75/285 [02:27<07:04,  2.02s/it]predicting train subjects:  27%|██▋       | 76/285 [02:29<06:59,  2.01s/it]predicting train subjects:  27%|██▋       | 77/285 [02:31<06:42,  1.93s/it]predicting train subjects:  27%|██▋       | 78/285 [02:32<06:26,  1.87s/it]predicting train subjects:  28%|██▊       | 79/285 [02:34<06:23,  1.86s/it]predicting train subjects:  28%|██▊       | 80/285 [02:36<06:18,  1.85s/it]predicting train subjects:  28%|██▊       | 81/285 [02:38<06:13,  1.83s/it]predicting train subjects:  29%|██▉       | 82/285 [02:40<06:22,  1.88s/it]predicting train subjects:  29%|██▉       | 83/285 [02:42<06:27,  1.92s/it]predicting train subjects:  29%|██▉       | 84/285 [02:44<06:30,  1.94s/it]predicting train subjects:  30%|██▉       | 85/285 [02:46<06:43,  2.02s/it]predicting train subjects:  30%|███       | 86/285 [02:48<06:37,  2.00s/it]predicting train subjects:  31%|███       | 87/285 [02:50<06:29,  1.97s/it]predicting train subjects:  31%|███       | 88/285 [02:52<06:18,  1.92s/it]predicting train subjects:  31%|███       | 89/285 [02:54<06:11,  1.90s/it]predicting train subjects:  32%|███▏      | 90/285 [02:55<06:09,  1.89s/it]predicting train subjects:  32%|███▏      | 91/285 [02:57<05:59,  1.85s/it]predicting train subjects:  32%|███▏      | 92/285 [02:59<06:10,  1.92s/it]predicting train subjects:  33%|███▎      | 93/285 [03:01<06:08,  1.92s/it]predicting train subjects:  33%|███▎      | 94/285 [03:03<06:14,  1.96s/it]predicting train subjects:  33%|███▎      | 95/285 [03:06<06:33,  2.07s/it]predicting train subjects:  34%|███▎      | 96/285 [03:08<06:26,  2.05s/it]predicting train subjects:  34%|███▍      | 97/285 [03:10<06:28,  2.07s/it]predicting train subjects:  34%|███▍      | 98/285 [03:12<06:36,  2.12s/it]predicting train subjects:  35%|███▍      | 99/285 [03:14<06:25,  2.07s/it]predicting train subjects:  35%|███▌      | 100/285 [03:16<06:20,  2.06s/it]predicting train subjects:  35%|███▌      | 101/285 [03:18<06:25,  2.09s/it]predicting train subjects:  36%|███▌      | 102/285 [03:20<06:30,  2.14s/it]predicting train subjects:  36%|███▌      | 103/285 [03:23<06:43,  2.22s/it]predicting train subjects:  36%|███▋      | 104/285 [03:25<06:53,  2.29s/it]predicting train subjects:  37%|███▋      | 105/285 [03:27<06:45,  2.25s/it]predicting train subjects:  37%|███▋      | 106/285 [03:29<06:19,  2.12s/it]predicting train subjects:  38%|███▊      | 107/285 [03:31<06:06,  2.06s/it]predicting train subjects:  38%|███▊      | 108/285 [03:33<05:51,  1.98s/it]predicting train subjects:  38%|███▊      | 109/285 [03:35<05:43,  1.95s/it]predicting train subjects:  39%|███▊      | 110/285 [03:37<05:46,  1.98s/it]predicting train subjects:  39%|███▉      | 111/285 [03:39<05:50,  2.01s/it]predicting train subjects:  39%|███▉      | 112/285 [03:41<05:57,  2.07s/it]predicting train subjects:  40%|███▉      | 113/285 [03:44<06:17,  2.19s/it]predicting train subjects:  40%|████      | 114/285 [03:46<06:23,  2.24s/it]predicting train subjects:  40%|████      | 115/285 [03:48<06:14,  2.20s/it]predicting train subjects:  41%|████      | 116/285 [03:50<05:53,  2.09s/it]predicting train subjects:  41%|████      | 117/285 [03:52<05:45,  2.05s/it]predicting train subjects:  41%|████▏     | 118/285 [03:54<05:39,  2.03s/it]predicting train subjects:  42%|████▏     | 119/285 [03:56<05:42,  2.07s/it]predicting train subjects:  42%|████▏     | 120/285 [03:58<05:44,  2.09s/it]predicting train subjects:  42%|████▏     | 121/285 [04:00<05:39,  2.07s/it]predicting train subjects:  43%|████▎     | 122/285 [04:02<05:34,  2.05s/it]predicting train subjects:  43%|████▎     | 123/285 [04:04<05:18,  1.96s/it]predicting train subjects:  44%|████▎     | 124/285 [04:06<05:18,  1.98s/it]predicting train subjects:  44%|████▍     | 125/285 [04:08<05:07,  1.92s/it]predicting train subjects:  44%|████▍     | 126/285 [04:10<05:00,  1.89s/it]predicting train subjects:  45%|████▍     | 127/285 [04:11<04:46,  1.81s/it]predicting train subjects:  45%|████▍     | 128/285 [04:13<04:39,  1.78s/it]predicting train subjects:  45%|████▌     | 129/285 [04:14<04:28,  1.72s/it]predicting train subjects:  46%|████▌     | 130/285 [04:16<04:21,  1.69s/it]predicting train subjects:  46%|████▌     | 131/285 [04:18<04:11,  1.63s/it]predicting train subjects:  46%|████▋     | 132/285 [04:19<04:20,  1.70s/it]predicting train subjects:  47%|████▋     | 133/285 [04:21<04:13,  1.67s/it]predicting train subjects:  47%|████▋     | 134/285 [04:23<04:03,  1.62s/it]predicting train subjects:  47%|████▋     | 135/285 [04:24<04:00,  1.60s/it]predicting train subjects:  48%|████▊     | 136/285 [04:26<03:54,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:27<04:02,  1.64s/it]predicting train subjects:  48%|████▊     | 138/285 [04:29<03:55,  1.60s/it]predicting train subjects:  49%|████▉     | 139/285 [04:31<03:58,  1.64s/it]predicting train subjects:  49%|████▉     | 140/285 [04:33<04:08,  1.71s/it]predicting train subjects:  49%|████▉     | 141/285 [04:34<04:04,  1.70s/it]predicting train subjects:  50%|████▉     | 142/285 [04:36<04:02,  1.69s/it]predicting train subjects:  50%|█████     | 143/285 [04:38<03:57,  1.67s/it]predicting train subjects:  51%|█████     | 144/285 [04:39<04:01,  1.71s/it]predicting train subjects:  51%|█████     | 145/285 [04:41<04:00,  1.71s/it]predicting train subjects:  51%|█████     | 146/285 [04:43<04:11,  1.81s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:45<04:01,  1.75s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:47<04:14,  1.86s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:49<04:18,  1.90s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:51<04:12,  1.87s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:53<04:14,  1.90s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:54<04:06,  1.85s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:56<04:08,  1.89s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:59<04:21,  2.00s/it]predicting train subjects:  54%|█████▍    | 155/285 [05:00<04:15,  1.96s/it]predicting train subjects:  55%|█████▍    | 156/285 [05:02<04:06,  1.91s/it]predicting train subjects:  55%|█████▌    | 157/285 [05:04<03:59,  1.87s/it]predicting train subjects:  55%|█████▌    | 158/285 [05:06<03:49,  1.81s/it]predicting train subjects:  56%|█████▌    | 159/285 [05:07<03:39,  1.74s/it]predicting train subjects:  56%|█████▌    | 160/285 [05:09<03:36,  1.73s/it]predicting train subjects:  56%|█████▋    | 161/285 [05:11<03:38,  1.76s/it]predicting train subjects:  57%|█████▋    | 162/285 [05:12<03:31,  1.72s/it]predicting train subjects:  57%|█████▋    | 163/285 [05:14<03:28,  1.71s/it]predicting train subjects:  58%|█████▊    | 164/285 [05:16<03:23,  1.68s/it]predicting train subjects:  58%|█████▊    | 165/285 [05:17<03:16,  1.64s/it]predicting train subjects:  58%|█████▊    | 166/285 [05:19<03:18,  1.67s/it]predicting train subjects:  59%|█████▊    | 167/285 [05:21<03:20,  1.70s/it]predicting train subjects:  59%|█████▉    | 168/285 [05:22<03:16,  1.68s/it]predicting train subjects:  59%|█████▉    | 169/285 [05:24<03:13,  1.66s/it]predicting train subjects:  60%|█████▉    | 170/285 [05:26<03:06,  1.62s/it]predicting train subjects:  60%|██████    | 171/285 [05:27<03:06,  1.63s/it]predicting train subjects:  60%|██████    | 172/285 [05:29<03:02,  1.61s/it]predicting train subjects:  61%|██████    | 173/285 [05:30<02:58,  1.59s/it]predicting train subjects:  61%|██████    | 174/285 [05:32<03:06,  1.68s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:34<03:10,  1.73s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:36<03:08,  1.73s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:37<02:58,  1.66s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:39<02:56,  1.65s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:41<02:55,  1.66s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:43<03:11,  1.82s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:45<03:16,  1.89s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:47<03:22,  1.97s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:49<03:11,  1.88s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:50<03:03,  1.82s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:52<02:57,  1.77s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:54<03:12,  1.94s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:56<03:14,  1.99s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:59<03:17,  2.04s/it]predicting train subjects:  66%|██████▋   | 189/285 [06:00<03:08,  1.96s/it]predicting train subjects:  67%|██████▋   | 190/285 [06:02<03:00,  1.90s/it]predicting train subjects:  67%|██████▋   | 191/285 [06:04<03:01,  1.93s/it]predicting train subjects:  67%|██████▋   | 192/285 [06:06<02:58,  1.92s/it]predicting train subjects:  68%|██████▊   | 193/285 [06:08<02:48,  1.83s/it]predicting train subjects:  68%|██████▊   | 194/285 [06:09<02:41,  1.78s/it]predicting train subjects:  68%|██████▊   | 195/285 [06:11<02:33,  1.71s/it]predicting train subjects:  69%|██████▉   | 196/285 [06:13<02:43,  1.84s/it]predicting train subjects:  69%|██████▉   | 197/285 [06:15<02:53,  1.97s/it]predicting train subjects:  69%|██████▉   | 198/285 [06:17<02:57,  2.04s/it]predicting train subjects:  70%|██████▉   | 199/285 [06:19<02:50,  1.98s/it]predicting train subjects:  70%|███████   | 200/285 [06:21<02:36,  1.84s/it]predicting train subjects:  71%|███████   | 201/285 [06:23<02:41,  1.92s/it]predicting train subjects:  71%|███████   | 202/285 [06:25<02:40,  1.93s/it]predicting train subjects:  71%|███████   | 203/285 [06:27<02:38,  1.93s/it]predicting train subjects:  72%|███████▏  | 204/285 [06:29<02:32,  1.88s/it]predicting train subjects:  72%|███████▏  | 205/285 [06:30<02:24,  1.81s/it]predicting train subjects:  72%|███████▏  | 206/285 [06:32<02:28,  1.87s/it]predicting train subjects:  73%|███████▎  | 207/285 [06:34<02:31,  1.94s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:36<02:34,  2.01s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:39<02:34,  2.03s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:40<02:23,  1.91s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:42<02:19,  1.88s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:44<02:19,  1.91s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:46<02:16,  1.89s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:48<02:10,  1.84s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:50<02:14,  1.92s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:51<02:04,  1.81s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:54<02:14,  1.97s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:56<02:15,  2.02s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:58<02:18,  2.10s/it]predicting train subjects:  77%|███████▋  | 220/285 [07:00<02:10,  2.01s/it]predicting train subjects:  78%|███████▊  | 221/285 [07:01<02:02,  1.92s/it]predicting train subjects:  78%|███████▊  | 222/285 [07:03<01:59,  1.89s/it]predicting train subjects:  78%|███████▊  | 223/285 [07:05<01:54,  1.85s/it]predicting train subjects:  79%|███████▊  | 224/285 [07:07<01:48,  1.78s/it]predicting train subjects:  79%|███████▉  | 225/285 [07:08<01:42,  1.71s/it]predicting train subjects:  79%|███████▉  | 226/285 [07:10<01:46,  1.81s/it]predicting train subjects:  80%|███████▉  | 227/285 [07:12<01:52,  1.94s/it]predicting train subjects:  80%|████████  | 228/285 [07:15<01:54,  2.01s/it]predicting train subjects:  80%|████████  | 229/285 [07:17<01:53,  2.02s/it]predicting train subjects:  81%|████████  | 230/285 [07:18<01:44,  1.91s/it]predicting train subjects:  81%|████████  | 231/285 [07:20<01:39,  1.84s/it]predicting train subjects:  81%|████████▏ | 232/285 [07:22<01:41,  1.91s/it]predicting train subjects:  82%|████████▏ | 233/285 [07:24<01:34,  1.82s/it]predicting train subjects:  82%|████████▏ | 234/285 [07:26<01:35,  1.88s/it]predicting train subjects:  82%|████████▏ | 235/285 [07:28<01:33,  1.87s/it]predicting train subjects:  83%|████████▎ | 236/285 [07:30<01:36,  1.96s/it]predicting train subjects:  83%|████████▎ | 237/285 [07:32<01:35,  2.00s/it]predicting train subjects:  84%|████████▎ | 238/285 [07:34<01:34,  2.02s/it]predicting train subjects:  84%|████████▍ | 239/285 [07:36<01:29,  1.95s/it]predicting train subjects:  84%|████████▍ | 240/285 [07:37<01:25,  1.89s/it]predicting train subjects:  85%|████████▍ | 241/285 [07:39<01:21,  1.86s/it]predicting train subjects:  85%|████████▍ | 242/285 [07:41<01:18,  1.82s/it]predicting train subjects:  85%|████████▌ | 243/285 [07:43<01:14,  1.78s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:45<01:18,  1.92s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:47<01:13,  1.85s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:49<01:18,  2.02s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:51<01:17,  2.04s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:53<01:16,  2.06s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:55<01:08,  1.90s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:56<01:04,  1.86s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:58<01:01,  1.81s/it]predicting train subjects:  88%|████████▊ | 252/285 [08:00<00:59,  1.79s/it]predicting train subjects:  89%|████████▉ | 253/285 [08:02<01:00,  1.89s/it]predicting train subjects:  89%|████████▉ | 254/285 [08:04<01:02,  2.01s/it]predicting train subjects:  89%|████████▉ | 255/285 [08:06<00:59,  2.00s/it]predicting train subjects:  90%|████████▉ | 256/285 [08:08<00:55,  1.90s/it]predicting train subjects:  90%|█████████ | 257/285 [08:10<00:51,  1.83s/it]predicting train subjects:  91%|█████████ | 258/285 [08:12<00:52,  1.96s/it]predicting train subjects:  91%|█████████ | 259/285 [08:14<00:51,  2.00s/it]predicting train subjects:  91%|█████████ | 260/285 [08:16<00:46,  1.85s/it]predicting train subjects:  92%|█████████▏| 261/285 [08:17<00:42,  1.78s/it]predicting train subjects:  92%|█████████▏| 262/285 [08:19<00:39,  1.74s/it]predicting train subjects:  92%|█████████▏| 263/285 [08:20<00:38,  1.73s/it]predicting train subjects:  93%|█████████▎| 264/285 [08:23<00:39,  1.87s/it]predicting train subjects:  93%|█████████▎| 265/285 [08:25<00:38,  1.95s/it]predicting train subjects:  93%|█████████▎| 266/285 [08:27<00:36,  1.92s/it]predicting train subjects:  94%|█████████▎| 267/285 [08:28<00:33,  1.88s/it]predicting train subjects:  94%|█████████▍| 268/285 [08:31<00:33,  1.97s/it]predicting train subjects:  94%|█████████▍| 269/285 [08:33<00:31,  1.95s/it]predicting train subjects:  95%|█████████▍| 270/285 [08:34<00:28,  1.88s/it]predicting train subjects:  95%|█████████▌| 271/285 [08:36<00:25,  1.82s/it]predicting train subjects:  95%|█████████▌| 272/285 [08:38<00:23,  1.82s/it]predicting train subjects:  96%|█████████▌| 273/285 [08:39<00:21,  1.76s/it]predicting train subjects:  96%|█████████▌| 274/285 [08:41<00:19,  1.76s/it]predicting train subjects:  96%|█████████▋| 275/285 [08:43<00:18,  1.89s/it]predicting train subjects:  97%|█████████▋| 276/285 [08:46<00:18,  2.03s/it]predicting train subjects:  97%|█████████▋| 277/285 [08:47<00:15,  1.92s/it]predicting train subjects:  98%|█████████▊| 278/285 [08:49<00:12,  1.85s/it]predicting train subjects:  98%|█████████▊| 279/285 [08:51<00:11,  1.92s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:53<00:09,  1.86s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:55<00:07,  1.84s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:56<00:05,  1.82s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:59<00:04,  2.01s/it]predicting train subjects: 100%|█████████▉| 284/285 [09:01<00:02,  2.11s/it]predicting train subjects: 100%|██████████| 285/285 [09:03<00:00,  2.15s/it]
Loading train:   0%|          | 0/285 [00:00<?, ?it/s]Loading train:   0%|          | 1/285 [00:01<08:48,  1.86s/it]Loading train:   1%|          | 2/285 [00:03<08:02,  1.70s/it]Loading train:   1%|          | 3/285 [00:04<08:01,  1.71s/it]Loading train:   1%|▏         | 4/285 [00:06<08:02,  1.72s/it]Loading train:   2%|▏         | 5/285 [00:08<08:32,  1.83s/it]Loading train:   2%|▏         | 6/285 [00:10<08:41,  1.87s/it]Loading train:   2%|▏         | 7/285 [00:12<08:36,  1.86s/it]Loading train:   3%|▎         | 8/285 [00:14<08:28,  1.83s/it]Loading train:   3%|▎         | 9/285 [00:16<09:08,  1.99s/it]Loading train:   4%|▎         | 10/285 [00:17<08:05,  1.77s/it]Loading train:   4%|▍         | 11/285 [00:19<07:17,  1.60s/it]Loading train:   4%|▍         | 12/285 [00:20<06:54,  1.52s/it]Loading train:   5%|▍         | 13/285 [00:21<06:24,  1.41s/it]Loading train:   5%|▍         | 14/285 [00:22<06:15,  1.39s/it]Loading train:   5%|▌         | 15/285 [00:24<06:21,  1.41s/it]Loading train:   6%|▌         | 16/285 [00:25<06:25,  1.43s/it]Loading train:   6%|▌         | 17/285 [00:27<06:05,  1.36s/it]Loading train:   6%|▋         | 18/285 [00:28<06:02,  1.36s/it]Loading train:   7%|▋         | 19/285 [00:29<05:54,  1.33s/it]Loading train:   7%|▋         | 20/285 [00:31<06:01,  1.36s/it]Loading train:   7%|▋         | 21/285 [00:32<06:25,  1.46s/it]Loading train:   8%|▊         | 22/285 [00:34<06:25,  1.47s/it]Loading train:   8%|▊         | 23/285 [00:35<06:05,  1.39s/it]Loading train:   8%|▊         | 24/285 [00:36<05:45,  1.32s/it]Loading train:   9%|▉         | 25/285 [00:37<05:29,  1.27s/it]Loading train:   9%|▉         | 26/285 [00:38<05:13,  1.21s/it]Loading train:   9%|▉         | 27/285 [00:40<05:08,  1.20s/it]Loading train:  10%|▉         | 28/285 [00:41<05:04,  1.19s/it]Loading train:  10%|█         | 29/285 [00:42<05:34,  1.31s/it]Loading train:  11%|█         | 30/285 [00:44<06:24,  1.51s/it]Loading train:  11%|█         | 31/285 [00:46<06:22,  1.51s/it]Loading train:  11%|█         | 32/285 [00:47<05:40,  1.35s/it]Loading train:  12%|█▏        | 33/285 [00:48<05:08,  1.22s/it]Loading train:  12%|█▏        | 34/285 [00:49<05:02,  1.21s/it]Loading train:  12%|█▏        | 35/285 [00:50<04:58,  1.19s/it]Loading train:  13%|█▎        | 36/285 [00:51<04:41,  1.13s/it]Loading train:  13%|█▎        | 37/285 [00:52<04:42,  1.14s/it]Loading train:  13%|█▎        | 38/285 [00:53<04:51,  1.18s/it]Loading train:  14%|█▎        | 39/285 [00:54<04:32,  1.11s/it]Loading train:  14%|█▍        | 40/285 [00:56<04:30,  1.10s/it]Loading train:  14%|█▍        | 41/285 [00:57<04:24,  1.09s/it]Loading train:  15%|█▍        | 42/285 [00:58<04:18,  1.06s/it]Loading train:  15%|█▌        | 43/285 [00:59<04:45,  1.18s/it]Loading train:  15%|█▌        | 44/285 [01:00<04:44,  1.18s/it]Loading train:  16%|█▌        | 45/285 [01:01<04:30,  1.13s/it]Loading train:  16%|█▌        | 46/285 [01:02<04:34,  1.15s/it]Loading train:  16%|█▋        | 47/285 [01:03<04:23,  1.11s/it]Loading train:  17%|█▋        | 48/285 [01:04<04:15,  1.08s/it]Loading train:  17%|█▋        | 49/285 [01:06<04:28,  1.14s/it]Loading train:  18%|█▊        | 50/285 [01:07<04:27,  1.14s/it]Loading train:  18%|█▊        | 51/285 [01:08<04:35,  1.18s/it]Loading train:  18%|█▊        | 52/285 [01:09<04:24,  1.14s/it]Loading train:  19%|█▊        | 53/285 [01:10<04:17,  1.11s/it]Loading train:  19%|█▉        | 54/285 [01:11<04:19,  1.12s/it]Loading train:  19%|█▉        | 55/285 [01:12<04:15,  1.11s/it]Loading train:  20%|█▉        | 56/285 [01:13<04:09,  1.09s/it]Loading train:  20%|██        | 57/285 [01:14<03:58,  1.05s/it]Loading train:  20%|██        | 58/285 [01:16<04:03,  1.07s/it]Loading train:  21%|██        | 59/285 [01:17<04:18,  1.14s/it]Loading train:  21%|██        | 60/285 [01:18<04:26,  1.18s/it]Loading train:  21%|██▏       | 61/285 [01:19<04:08,  1.11s/it]Loading train:  22%|██▏       | 62/285 [01:20<04:06,  1.10s/it]Loading train:  22%|██▏       | 63/285 [01:21<03:58,  1.07s/it]Loading train:  22%|██▏       | 64/285 [01:23<04:19,  1.17s/it]Loading train:  23%|██▎       | 65/285 [01:24<04:50,  1.32s/it]Loading train:  23%|██▎       | 66/285 [01:26<04:58,  1.36s/it]Loading train:  24%|██▎       | 67/285 [01:27<04:40,  1.29s/it]Loading train:  24%|██▍       | 68/285 [01:28<04:19,  1.19s/it]Loading train:  24%|██▍       | 69/285 [01:29<04:17,  1.19s/it]Loading train:  25%|██▍       | 70/285 [01:30<04:09,  1.16s/it]Loading train:  25%|██▍       | 71/285 [01:31<04:01,  1.13s/it]Loading train:  25%|██▌       | 72/285 [01:32<03:47,  1.07s/it]Loading train:  26%|██▌       | 73/285 [01:33<03:54,  1.11s/it]Loading train:  26%|██▌       | 74/285 [01:34<03:56,  1.12s/it]Loading train:  26%|██▋       | 75/285 [01:35<03:54,  1.12s/it]Loading train:  27%|██▋       | 76/285 [01:37<03:51,  1.11s/it]Loading train:  27%|██▋       | 77/285 [01:38<03:43,  1.08s/it]Loading train:  27%|██▋       | 78/285 [01:39<03:37,  1.05s/it]Loading train:  28%|██▊       | 79/285 [01:40<03:42,  1.08s/it]Loading train:  28%|██▊       | 80/285 [01:41<03:39,  1.07s/it]Loading train:  28%|██▊       | 81/285 [01:42<03:26,  1.01s/it]Loading train:  29%|██▉       | 82/285 [01:43<03:28,  1.03s/it]Loading train:  29%|██▉       | 83/285 [01:44<03:23,  1.01s/it]Loading train:  29%|██▉       | 84/285 [01:45<03:18,  1.01it/s]Loading train:  30%|██▉       | 85/285 [01:46<03:19,  1.00it/s]Loading train:  30%|███       | 86/285 [01:47<03:22,  1.02s/it]Loading train:  31%|███       | 87/285 [01:48<03:23,  1.03s/it]Loading train:  31%|███       | 88/285 [01:49<03:12,  1.03it/s]Loading train:  31%|███       | 89/285 [01:50<03:15,  1.00it/s]Loading train:  32%|███▏      | 90/285 [01:51<03:17,  1.01s/it]Loading train:  32%|███▏      | 91/285 [01:52<03:11,  1.01it/s]Loading train:  32%|███▏      | 92/285 [01:53<03:24,  1.06s/it]Loading train:  33%|███▎      | 93/285 [01:54<03:24,  1.07s/it]Loading train:  33%|███▎      | 94/285 [01:55<03:47,  1.19s/it]Loading train:  33%|███▎      | 95/285 [01:57<03:43,  1.18s/it]Loading train:  34%|███▎      | 96/285 [01:58<03:34,  1.14s/it]Loading train:  34%|███▍      | 97/285 [01:59<03:30,  1.12s/it]Loading train:  34%|███▍      | 98/285 [02:00<03:33,  1.14s/it]Loading train:  35%|███▍      | 99/285 [02:01<03:26,  1.11s/it]Loading train:  35%|███▌      | 100/285 [02:02<03:24,  1.11s/it]Loading train:  35%|███▌      | 101/285 [02:03<03:14,  1.06s/it]Loading train:  36%|███▌      | 102/285 [02:04<03:15,  1.07s/it]Loading train:  36%|███▌      | 103/285 [02:05<03:08,  1.03s/it]Loading train:  36%|███▋      | 104/285 [02:06<03:08,  1.04s/it]Loading train:  37%|███▋      | 105/285 [02:07<03:08,  1.05s/it]Loading train:  37%|███▋      | 106/285 [02:08<02:59,  1.00s/it]Loading train:  38%|███▊      | 107/285 [02:09<03:02,  1.03s/it]Loading train:  38%|███▊      | 108/285 [02:10<03:02,  1.03s/it]Loading train:  38%|███▊      | 109/285 [02:11<03:07,  1.06s/it]Loading train:  39%|███▊      | 110/285 [02:12<03:11,  1.09s/it]Loading train:  39%|███▉      | 111/285 [02:13<03:03,  1.06s/it]Loading train:  39%|███▉      | 112/285 [02:14<03:03,  1.06s/it]Loading train:  40%|███▉      | 113/285 [02:16<03:06,  1.08s/it]Loading train:  40%|████      | 114/285 [02:17<03:10,  1.11s/it]Loading train:  40%|████      | 115/285 [02:18<03:09,  1.11s/it]Loading train:  41%|████      | 116/285 [02:19<03:03,  1.09s/it]Loading train:  41%|████      | 117/285 [02:20<02:55,  1.05s/it]Loading train:  41%|████▏     | 118/285 [02:21<02:51,  1.02s/it]Loading train:  42%|████▏     | 119/285 [02:22<02:52,  1.04s/it]Loading train:  42%|████▏     | 120/285 [02:23<02:49,  1.02s/it]Loading train:  42%|████▏     | 121/285 [02:24<03:03,  1.12s/it]Loading train:  43%|████▎     | 122/285 [02:26<03:28,  1.28s/it]Loading train:  43%|████▎     | 123/285 [02:27<03:27,  1.28s/it]Loading train:  44%|████▎     | 124/285 [02:28<03:12,  1.19s/it]Loading train:  44%|████▍     | 125/285 [02:29<02:54,  1.09s/it]Loading train:  44%|████▍     | 126/285 [02:30<02:49,  1.07s/it]Loading train:  45%|████▍     | 127/285 [02:31<02:53,  1.10s/it]Loading train:  45%|████▍     | 128/285 [02:32<02:51,  1.09s/it]Loading train:  45%|████▌     | 129/285 [02:33<02:43,  1.05s/it]Loading train:  46%|████▌     | 130/285 [02:34<02:32,  1.02it/s]Loading train:  46%|████▌     | 131/285 [02:35<02:30,  1.02it/s]Loading train:  46%|████▋     | 132/285 [02:36<02:33,  1.00s/it]Loading train:  47%|████▋     | 133/285 [02:37<02:34,  1.02s/it]Loading train:  47%|████▋     | 134/285 [02:38<02:24,  1.04it/s]Loading train:  47%|████▋     | 135/285 [02:39<02:22,  1.05it/s]Loading train:  48%|████▊     | 136/285 [02:40<02:18,  1.08it/s]Loading train:  48%|████▊     | 137/285 [02:41<02:32,  1.03s/it]Loading train:  48%|████▊     | 138/285 [02:42<02:30,  1.02s/it]Loading train:  49%|████▉     | 139/285 [02:44<02:52,  1.18s/it]Loading train:  49%|████▉     | 140/285 [02:45<02:42,  1.12s/it]Loading train:  49%|████▉     | 141/285 [02:45<02:31,  1.05s/it]Loading train:  50%|████▉     | 142/285 [02:46<02:27,  1.03s/it]Loading train:  50%|█████     | 143/285 [02:47<02:20,  1.01it/s]Loading train:  51%|█████     | 144/285 [02:48<02:21,  1.00s/it]Loading train:  51%|█████     | 145/285 [02:49<02:21,  1.01s/it]Loading train:  51%|█████     | 146/285 [02:51<02:23,  1.03s/it]Loading train:  52%|█████▏    | 147/285 [02:51<02:16,  1.01it/s]Loading train:  52%|█████▏    | 148/285 [02:52<02:16,  1.00it/s]Loading train:  52%|█████▏    | 149/285 [02:53<02:16,  1.00s/it]Loading train:  53%|█████▎    | 150/285 [02:54<02:15,  1.00s/it]Loading train:  53%|█████▎    | 151/285 [02:55<02:13,  1.00it/s]Loading train:  53%|█████▎    | 152/285 [02:56<02:05,  1.06it/s]Loading train:  54%|█████▎    | 153/285 [02:57<01:58,  1.11it/s]Loading train:  54%|█████▍    | 154/285 [02:58<01:59,  1.10it/s]Loading train:  54%|█████▍    | 155/285 [02:59<01:57,  1.10it/s]Loading train:  55%|█████▍    | 156/285 [03:00<01:59,  1.08it/s]Loading train:  55%|█████▌    | 157/285 [03:01<01:56,  1.09it/s]Loading train:  55%|█████▌    | 158/285 [03:02<01:56,  1.09it/s]Loading train:  56%|█████▌    | 159/285 [03:03<01:58,  1.07it/s]Loading train:  56%|█████▌    | 160/285 [03:04<01:56,  1.08it/s]Loading train:  56%|█████▋    | 161/285 [03:05<02:00,  1.03it/s]Loading train:  57%|█████▋    | 162/285 [03:06<01:56,  1.05it/s]Loading train:  57%|█████▋    | 163/285 [03:07<01:57,  1.04it/s]Loading train:  58%|█████▊    | 164/285 [03:08<02:01,  1.00s/it]Loading train:  58%|█████▊    | 165/285 [03:09<01:56,  1.03it/s]Loading train:  58%|█████▊    | 166/285 [03:09<01:55,  1.03it/s]Loading train:  59%|█████▊    | 167/285 [03:10<01:54,  1.03it/s]Loading train:  59%|█████▉    | 168/285 [03:11<01:51,  1.05it/s]Loading train:  59%|█████▉    | 169/285 [03:12<01:47,  1.08it/s]Loading train:  60%|█████▉    | 170/285 [03:13<01:46,  1.08it/s]Loading train:  60%|██████    | 171/285 [03:14<01:50,  1.03it/s]Loading train:  60%|██████    | 172/285 [03:15<01:44,  1.08it/s]Loading train:  61%|██████    | 173/285 [03:16<01:46,  1.06it/s]Loading train:  61%|██████    | 174/285 [03:17<01:45,  1.05it/s]Loading train:  61%|██████▏   | 175/285 [03:18<01:46,  1.03it/s]Loading train:  62%|██████▏   | 176/285 [03:19<01:45,  1.04it/s]Loading train:  62%|██████▏   | 177/285 [03:20<01:44,  1.03it/s]Loading train:  62%|██████▏   | 178/285 [03:21<01:40,  1.07it/s]Loading train:  63%|██████▎   | 179/285 [03:22<01:38,  1.07it/s]Loading train:  63%|██████▎   | 180/285 [03:23<01:42,  1.02it/s]Loading train:  64%|██████▎   | 181/285 [03:24<01:42,  1.02it/s]Loading train:  64%|██████▍   | 182/285 [03:25<01:39,  1.03it/s]Loading train:  64%|██████▍   | 183/285 [03:26<01:39,  1.03it/s]Loading train:  65%|██████▍   | 184/285 [03:27<01:40,  1.01it/s]Loading train:  65%|██████▍   | 185/285 [03:28<01:33,  1.07it/s]Loading train:  65%|██████▌   | 186/285 [03:29<01:39,  1.01s/it]Loading train:  66%|██████▌   | 187/285 [03:30<01:36,  1.01it/s]Loading train:  66%|██████▌   | 188/285 [03:31<01:40,  1.03s/it]Loading train:  66%|██████▋   | 189/285 [03:32<01:35,  1.00it/s]Loading train:  67%|██████▋   | 190/285 [03:33<01:35,  1.00s/it]Loading train:  67%|██████▋   | 191/285 [03:34<01:32,  1.01it/s]Loading train:  67%|██████▋   | 192/285 [03:35<01:31,  1.02it/s]Loading train:  68%|██████▊   | 193/285 [03:36<01:28,  1.03it/s]Loading train:  68%|██████▊   | 194/285 [03:36<01:24,  1.07it/s]Loading train:  68%|██████▊   | 195/285 [03:37<01:20,  1.12it/s]Loading train:  69%|██████▉   | 196/285 [03:38<01:22,  1.08it/s]Loading train:  69%|██████▉   | 197/285 [03:39<01:26,  1.02it/s]Loading train:  69%|██████▉   | 198/285 [03:41<01:29,  1.03s/it]Loading train:  70%|██████▉   | 199/285 [03:41<01:24,  1.02it/s]Loading train:  70%|███████   | 200/285 [03:42<01:21,  1.05it/s]Loading train:  71%|███████   | 201/285 [03:43<01:22,  1.02it/s]Loading train:  71%|███████   | 202/285 [03:44<01:21,  1.02it/s]Loading train:  71%|███████   | 203/285 [03:45<01:21,  1.00it/s]Loading train:  72%|███████▏  | 204/285 [03:46<01:20,  1.01it/s]Loading train:  72%|███████▏  | 205/285 [03:47<01:16,  1.05it/s]Loading train:  72%|███████▏  | 206/285 [03:48<01:12,  1.09it/s]Loading train:  73%|███████▎  | 207/285 [03:49<01:15,  1.04it/s]Loading train:  73%|███████▎  | 208/285 [03:50<01:16,  1.01it/s]Loading train:  73%|███████▎  | 209/285 [03:51<01:19,  1.04s/it]Loading train:  74%|███████▎  | 210/285 [03:52<01:13,  1.01it/s]Loading train:  74%|███████▍  | 211/285 [03:53<01:11,  1.04it/s]Loading train:  74%|███████▍  | 212/285 [03:54<01:12,  1.01it/s]Loading train:  75%|███████▍  | 213/285 [03:55<01:10,  1.03it/s]Loading train:  75%|███████▌  | 214/285 [03:56<01:05,  1.08it/s]Loading train:  75%|███████▌  | 215/285 [03:57<01:07,  1.03it/s]Loading train:  76%|███████▌  | 216/285 [03:58<01:06,  1.04it/s]Loading train:  76%|███████▌  | 217/285 [03:59<01:07,  1.01it/s]Loading train:  76%|███████▋  | 218/285 [04:00<01:08,  1.03s/it]Loading train:  77%|███████▋  | 219/285 [04:01<01:12,  1.09s/it]Loading train:  77%|███████▋  | 220/285 [04:02<01:09,  1.06s/it]Loading train:  78%|███████▊  | 221/285 [04:03<01:06,  1.04s/it]Loading train:  78%|███████▊  | 222/285 [04:04<01:05,  1.05s/it]Loading train:  78%|███████▊  | 223/285 [04:05<01:00,  1.02it/s]Loading train:  79%|███████▊  | 224/285 [04:06<00:58,  1.05it/s]Loading train:  79%|███████▉  | 225/285 [04:07<00:55,  1.07it/s]Loading train:  79%|███████▉  | 226/285 [04:08<00:57,  1.03it/s]Loading train:  80%|███████▉  | 227/285 [04:09<00:58,  1.01s/it]Loading train:  80%|████████  | 228/285 [04:10<00:59,  1.04s/it]Loading train:  80%|████████  | 229/285 [04:11<00:58,  1.04s/it]Loading train:  81%|████████  | 230/285 [04:12<00:53,  1.03it/s]Loading train:  81%|████████  | 231/285 [04:13<00:52,  1.02it/s]Loading train:  81%|████████▏ | 232/285 [04:14<00:54,  1.02s/it]Loading train:  82%|████████▏ | 233/285 [04:15<00:50,  1.03it/s]Loading train:  82%|████████▏ | 234/285 [04:16<00:51,  1.01s/it]Loading train:  82%|████████▏ | 235/285 [04:17<00:47,  1.05it/s]Loading train:  83%|████████▎ | 236/285 [04:18<00:46,  1.05it/s]Loading train:  83%|████████▎ | 237/285 [04:19<00:47,  1.00it/s]Loading train:  84%|████████▎ | 238/285 [04:20<00:48,  1.03s/it]Loading train:  84%|████████▍ | 239/285 [04:21<00:48,  1.05s/it]Loading train:  84%|████████▍ | 240/285 [04:22<00:44,  1.02it/s]Loading train:  85%|████████▍ | 241/285 [04:23<00:41,  1.07it/s]Loading train:  85%|████████▍ | 242/285 [04:24<00:40,  1.06it/s]Loading train:  85%|████████▌ | 243/285 [04:25<00:39,  1.06it/s]Loading train:  86%|████████▌ | 244/285 [04:26<00:41,  1.00s/it]Loading train:  86%|████████▌ | 245/285 [04:27<00:38,  1.03it/s]Loading train:  86%|████████▋ | 246/285 [04:28<00:40,  1.03s/it]Loading train:  87%|████████▋ | 247/285 [04:29<00:40,  1.06s/it]Loading train:  87%|████████▋ | 248/285 [04:30<00:38,  1.03s/it]Loading train:  87%|████████▋ | 249/285 [04:31<00:36,  1.00s/it]Loading train:  88%|████████▊ | 250/285 [04:32<00:34,  1.02it/s]Loading train:  88%|████████▊ | 251/285 [04:33<00:33,  1.02it/s]Loading train:  88%|████████▊ | 252/285 [04:34<00:31,  1.04it/s]Loading train:  89%|████████▉ | 253/285 [04:35<00:33,  1.05s/it]Loading train:  89%|████████▉ | 254/285 [04:36<00:33,  1.09s/it]Loading train:  89%|████████▉ | 255/285 [04:37<00:32,  1.09s/it]Loading train:  90%|████████▉ | 256/285 [04:38<00:31,  1.09s/it]Loading train:  90%|█████████ | 257/285 [04:39<00:30,  1.07s/it]Loading train:  91%|█████████ | 258/285 [04:41<00:29,  1.08s/it]Loading train:  91%|█████████ | 259/285 [04:42<00:28,  1.08s/it]Loading train:  91%|█████████ | 260/285 [04:43<00:25,  1.01s/it]Loading train:  92%|█████████▏| 261/285 [04:43<00:23,  1.00it/s]Loading train:  92%|█████████▏| 262/285 [04:44<00:21,  1.05it/s]Loading train:  92%|█████████▏| 263/285 [04:45<00:20,  1.08it/s]Loading train:  93%|█████████▎| 264/285 [04:46<00:20,  1.02it/s]Loading train:  93%|█████████▎| 265/285 [04:48<00:20,  1.05s/it]Loading train:  93%|█████████▎| 266/285 [04:49<00:19,  1.05s/it]Loading train:  94%|█████████▎| 267/285 [04:50<00:18,  1.02s/it]Loading train:  94%|█████████▍| 268/285 [04:51<00:17,  1.05s/it]Loading train:  94%|█████████▍| 269/285 [04:52<00:16,  1.04s/it]Loading train:  95%|█████████▍| 270/285 [04:53<00:15,  1.04s/it]Loading train:  95%|█████████▌| 271/285 [04:54<00:14,  1.03s/it]Loading train:  95%|█████████▌| 272/285 [04:55<00:13,  1.00s/it]Loading train:  96%|█████████▌| 273/285 [04:56<00:11,  1.02it/s]Loading train:  96%|█████████▌| 274/285 [04:56<00:10,  1.05it/s]Loading train:  96%|█████████▋| 275/285 [04:58<00:10,  1.01s/it]Loading train:  97%|█████████▋| 276/285 [04:59<00:09,  1.08s/it]Loading train:  97%|█████████▋| 277/285 [05:00<00:08,  1.03s/it]Loading train:  98%|█████████▊| 278/285 [05:01<00:07,  1.03s/it]Loading train:  98%|█████████▊| 279/285 [05:02<00:06,  1.01s/it]Loading train:  98%|█████████▊| 280/285 [05:03<00:04,  1.02it/s]Loading train:  99%|█████████▊| 281/285 [05:04<00:03,  1.05it/s]Loading train:  99%|█████████▉| 282/285 [05:05<00:03,  1.03s/it]Loading train:  99%|█████████▉| 283/285 [05:06<00:02,  1.02s/it]Loading train: 100%|█████████▉| 284/285 [05:07<00:01,  1.05s/it]Loading train: 100%|██████████| 285/285 [05:08<00:00,  1.12s/it]
concatenating: train:   0%|          | 0/285 [00:00<?, ?it/s]concatenating: train:   2%|▏         | 6/285 [00:00<00:04, 59.54it/s]concatenating: train:   5%|▌         | 15/285 [00:00<00:04, 65.18it/s]concatenating: train:  10%|▉         | 28/285 [00:00<00:03, 76.59it/s]concatenating: train:  14%|█▎        | 39/285 [00:00<00:02, 83.50it/s]concatenating: train:  18%|█▊        | 52/285 [00:00<00:02, 93.52it/s]concatenating: train:  22%|██▏       | 62/285 [00:00<00:02, 94.42it/s]concatenating: train:  25%|██▌       | 72/285 [00:00<00:02, 86.11it/s]concatenating: train:  29%|██▉       | 82/285 [00:00<00:02, 87.95it/s]concatenating: train:  32%|███▏      | 91/285 [00:00<00:02, 80.82it/s]concatenating: train:  35%|███▌      | 101/285 [00:01<00:02, 84.90it/s]concatenating: train:  39%|███▉      | 111/285 [00:01<00:01, 88.08it/s]concatenating: train:  42%|████▏     | 120/285 [00:01<00:02, 79.28it/s]concatenating: train:  45%|████▌     | 129/285 [00:01<00:01, 79.49it/s]concatenating: train:  49%|████▉     | 141/285 [00:01<00:01, 87.70it/s]concatenating: train:  54%|█████▍    | 154/285 [00:01<00:01, 97.17it/s]concatenating: train:  59%|█████▊    | 167/285 [00:01<00:01, 104.13it/s]concatenating: train:  63%|██████▎   | 179/285 [00:01<00:00, 106.14it/s]concatenating: train:  67%|██████▋   | 191/285 [00:02<00:00, 101.05it/s]concatenating: train:  72%|███████▏  | 204/285 [00:02<00:00, 107.22it/s]concatenating: train:  76%|███████▌  | 216/285 [00:02<00:00, 107.21it/s]concatenating: train:  80%|███████▉  | 227/285 [00:02<00:00, 104.32it/s]concatenating: train:  84%|████████▍ | 240/285 [00:02<00:00, 109.68it/s]concatenating: train:  89%|████████▉ | 253/285 [00:02<00:00, 113.98it/s]concatenating: train:  93%|█████████▎| 265/285 [00:02<00:00, 111.84it/s]concatenating: train:  97%|█████████▋| 277/285 [00:02<00:00, 111.62it/s]concatenating: train: 100%|██████████| 285/285 [00:02<00:00, 100.33it/s]
Loading test:   0%|          | 0/3 [00:00<?, ?it/s]Loading test:  33%|███▎      | 1/3 [00:01<00:02,  1.32s/it]Loading test:  67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]Loading test: 100%|██████████| 3/3 [00:03<00:00,  1.25s/it]
concatenating: validation:   0%|          | 0/3 [00:00<?, ?it/s]concatenating: validation: 100%|██████████| 3/3 [00:00<00:00, 54.21it/s]2019-07-11 14:00:05.128586: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1471] Adding visible gpu devices: 0
2019-07-11 14:00:05.128683: I tensorflow/core/common_runtime/gpu/gpu_device.cc:952] Device interconnect StreamExecutor with strength 1 edge matrix:
2019-07-11 14:00:05.128697: I tensorflow/core/common_runtime/gpu/gpu_device.cc:958]      0 
2019-07-11 14:00:05.128705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:971] 0:   N 
2019-07-11 14:00:05.129041: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1084] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15123 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:85:00.0, compute capability: 6.0)

/array/ssd/msmajdi/anaconda3/envs/keras-gpu/lib/python3.6/site-packages/keras/engine/saving.py:292: UserWarning: No training configuration found in save file: the model was *not* compiled. Compile it manually.
  warnings.warn('No training configuration found in save file: '
loading the weights for Res Unet:   0%|          | 0/44 [00:00<?, ?it/s]loading the weights for Res Unet:   2%|▏         | 1/44 [00:00<00:11,  3.73it/s]loading the weights for Res Unet:   7%|▋         | 3/44 [00:00<00:08,  4.59it/s]loading the weights for Res Unet:   9%|▉         | 4/44 [00:00<00:08,  4.67it/s]loading the weights for Res Unet:  18%|█▊        | 8/44 [00:00<00:05,  6.00it/s]loading the weights for Res Unet:  20%|██        | 9/44 [00:01<00:06,  5.15it/s]loading the weights for Res Unet:  25%|██▌       | 11/44 [00:01<00:05,  5.68it/s]loading the weights for Res Unet:  27%|██▋       | 12/44 [00:01<00:06,  5.20it/s]loading the weights for Res Unet:  39%|███▊      | 17/44 [00:01<00:04,  6.63it/s]loading the weights for Res Unet:  41%|████      | 18/44 [00:02<00:04,  5.38it/s]loading the weights for Res Unet:  45%|████▌     | 20/44 [00:02<00:03,  6.10it/s]loading the weights for Res Unet:  48%|████▊     | 21/44 [00:02<00:04,  5.61it/s]loading the weights for Res Unet:  57%|█████▋    | 25/44 [00:02<00:02,  7.16it/s]loading the weights for Res Unet:  61%|██████▏   | 27/44 [00:03<00:02,  7.52it/s]loading the weights for Res Unet:  66%|██████▌   | 29/44 [00:03<00:01,  7.54it/s]loading the weights for Res Unet:  68%|██████▊   | 30/44 [00:03<00:02,  6.05it/s]loading the weights for Res Unet:  70%|███████   | 31/44 [00:03<00:02,  5.11it/s]loading the weights for Res Unet:  80%|███████▉  | 35/44 [00:04<00:01,  6.40it/s]loading the weights for Res Unet:  84%|████████▍ | 37/44 [00:04<00:01,  6.68it/s]loading the weights for Res Unet:  86%|████████▋ | 38/44 [00:04<00:01,  5.45it/s]loading the weights for Res Unet:  91%|█████████ | 40/44 [00:04<00:00,  5.82it/s]loading the weights for Res Unet:  93%|█████████▎| 41/44 [00:05<00:00,  5.09it/s]loading the weights for Res Unet: 100%|██████████| 44/44 [00:05<00:00,  8.52it/s]
Epoch 00053: val_mDice did not improve from 0.61591
Restoring model weights from the end of the best epoch
Epoch 00053: early stopping
{'val_loss': [1.705364195328185, 0.6164844538912427, 0.5479344629042642, 0.49150567414374324, 0.5085434946933938, 0.4927055286295587, 0.5261604999030769, 0.48015195963768986, 0.4960204635918473, 0.5005319897688967, 0.474862858236835, 0.4942452058445808, 0.4749639403886635, 0.48480958512375477, 0.4839985147534802, 0.4905997468106574, 0.5265785359137551, 0.5409727439534064, 0.49176320650058086, 0.5171707652134603, 0.5431764725200291, 0.5147823708017445, 0.4963860012299522, 0.515750115477173, 0.505899758978263, 0.49610255350613724, 0.5124735955419487, 0.5001372914740493, 0.5000970456853259, 0.4958269050001432, 0.49401403572306285, 0.49212979171529164, 0.5045897551089026, 0.5039946669972809, 0.5085808451615232, 0.5138902264600359, 0.48189978226603075, 0.4960697413156818, 0.5036326273859546, 0.5008375041977653, 0.5136844722252318, 0.4753115217112962, 0.4822498510003756, 0.4992590350145734, 0.5083311902744144, 0.499095804531481, 0.5270404915569881, 0.5002904610926878, 0.504089205624671, 0.4859807824289333, 0.48845275154326884, 0.48852288556498524, 0.49233434120370023], 'val_acc': [0.9214674690582233, 0.9433861707841884, 0.9464624927030595, 0.9481463538867801, 0.9497991657123885, 0.9481608061817105, 0.9503652813048337, 0.9479108349571015, 0.9482599796529588, 0.9509003765090218, 0.9511317674008162, 0.9502722997239182, 0.95314618129304, 0.9499665275632336, 0.9509499669075012, 0.9533837780606147, 0.9504665316150175, 0.9506586760116023, 0.9498012355586004, 0.9525779945224357, 0.9485409509536274, 0.9505429574231196, 0.9501421478207551, 0.9473529807682144, 0.9512123582083419, 0.9509768472703476, 0.9514334131885507, 0.9509251800329326, 0.9500161389398841, 0.9523466032976545, 0.9517722629302041, 0.9502412986488982, 0.9513569850495408, 0.951716490630997, 0.94907399462588, 0.9504623992483043, 0.952336275377753, 0.9517825692059607, 0.9487124544948173, 0.9513321875193932, 0.9495822394360377, 0.9513652381284277, 0.9510739182626735, 0.9516359014884054, 0.9515325923205754, 0.9509685615587501, 0.9484231775033407, 0.9510243624948257, 0.9496731528356754, 0.9518445517097771, 0.950567734308083, 0.9518920915752815, 0.9518487063866088], 'val_mDice': [0.2583018779421652, 0.5380974731631785, 0.5749258508895363, 0.600796456110544, 0.5939251490811396, 0.5993097178096878, 0.5831789410980054, 0.6081705572884842, 0.6018612697803775, 0.5998337471951319, 0.6133306286188477, 0.6003796408296297, 0.6159148898870586, 0.6056334139914487, 0.604677432076225, 0.6045515866918937, 0.5876650240834199, 0.5846210644897802, 0.604379715200243, 0.5937804726249013, 0.5813153482682212, 0.595524426945095, 0.6030297036277515, 0.589537712448802, 0.5981002693069714, 0.6007425192348118, 0.5932507608189929, 0.5984642645500226, 0.598471017190198, 0.6033923029899597, 0.6046859242396647, 0.6030490511622508, 0.5994714691652266, 0.6010402787331096, 0.596421336661504, 0.5928772278338171, 0.610428729536813, 0.6043641647147067, 0.5964526930334848, 0.6010252174052446, 0.5920459511559769, 0.6126418413396654, 0.6098493271033857, 0.6001500693779418, 0.5977475526612565, 0.6007425112431276, 0.5877316793915945, 0.5995745462412275, 0.5996410007583363, 0.6084936644111931, 0.6070319790413926, 0.6069004838693075, 0.6065928423204902], 'loss': [1.9807320030664906, 0.6828015310644461, 0.5421571658039513, 0.4761892789479246, 0.4404309500562918, 0.41363653368721615, 0.39481762775336793, 0.3802778490419696, 0.36797601498456883, 0.35989932876177055, 0.3478256584083805, 0.3410911417076916, 0.3374155329908721, 0.32693210394967714, 0.3218102023321185, 0.31784631267825436, 0.31401254744332613, 0.3072000753499085, 0.3040001100006008, 0.30068686451763116, 0.2985287853042633, 0.29420915691559496, 0.28893288494091357, 0.287435120918426, 0.28427000055125606, 0.2817799462958376, 0.28009317957246677, 0.27600951698356047, 0.2746042200883524, 0.27609506696438285, 0.27033819002488635, 0.27098604501751306, 0.26718273231532735, 0.2654579044959558, 0.2626702564194158, 0.2626809796394395, 0.2603946396927124, 0.25847561307400374, 0.2592084437055231, 0.25642499085488346, 0.25697828883095303, 0.25549176511931515, 0.2540540186257464, 0.25146625241249787, 0.2517085668016289, 0.24914401188069948, 0.2481921542399161, 0.24679624933535793, 0.24590520650581768, 0.24510928912737628, 0.2500051433028469, 0.24354248418799412, 0.24296008934886243], 'acc': [0.723143246049397, 0.9185952257112794, 0.9315094232435847, 0.9372988474355415, 0.9403770862273106, 0.9426317699470653, 0.9441590023796501, 0.945390445085842, 0.9463745723115574, 0.9467710624183421, 0.9478881032169141, 0.9484605471018281, 0.9487997607288586, 0.949552091632973, 0.9499013090236249, 0.9502421675778365, 0.9505862306453883, 0.9511655489672932, 0.9513891607540819, 0.951714144748486, 0.951773744092113, 0.9521997244677105, 0.9526289441014069, 0.9526939408353624, 0.9529993116456331, 0.9532113431144219, 0.9533552763950435, 0.9535483950513178, 0.9537631253856997, 0.9536954874787467, 0.9540813035334151, 0.9540866835562338, 0.9543675566822035, 0.9544538664347751, 0.9547118218880932, 0.9547728115252359, 0.9549332002455695, 0.9550643207707323, 0.9550449446774563, 0.9552550239991755, 0.9552003573172817, 0.9553546445716811, 0.9554764625229001, 0.955633487068914, 0.9556409194347263, 0.9557622943780993, 0.9559170658127051, 0.9560763449309458, 0.9560571688367199, 0.9561259734637727, 0.9557617697754195, 0.9562327851787397, 0.9563297886492919], 'mDice': [0.22005473354365804, 0.4915051015268308, 0.5672752000616693, 0.6065337585017387, 0.6291162672856231, 0.6466010749310841, 0.6592000072528695, 0.6694203689982511, 0.6776596836927935, 0.6833017188137598, 0.6918325169914513, 0.6968271099244008, 0.6994655951910319, 0.7070154989735051, 0.7107834296836539, 0.713724845099518, 0.7167082162933356, 0.7217363101660469, 0.7241639406694955, 0.7266415812131541, 0.7281968631254069, 0.731606037276781, 0.7354615844352386, 0.73675103129388, 0.7391119821159533, 0.741084715018416, 0.7423825749196061, 0.7454300665412618, 0.7466995246295712, 0.7455337740978796, 0.7499370315217626, 0.7497247906657295, 0.752423350071246, 0.7538518791306247, 0.7559466298340284, 0.7560653688536121, 0.7578362753484629, 0.7592946490355355, 0.7587435311348141, 0.7608752625160348, 0.7604525623274268, 0.7616752591549159, 0.7629862275234488, 0.764911053539212, 0.7647151165548464, 0.7667253672196892, 0.7675471098703092, 0.7686402207495802, 0.7693198290852107, 0.7700357548415703, 0.7663757587711468, 0.7713063654313452, 0.7717162486670759]}
---------------------------------------------------------------
 Nucleus: [2, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]  | GPU: 5  | SD 0  | Dropout 0.3  | LR 0.001  | NL 3  |  Cascade |  FM 20 |  Upsample 1
Experiment: exp7
SubExperiment: sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a
---------------------------------------------------------------
Error in label values min 0.0 max 9.0      2-AV
Error in label values min 0.0 max 2.0      4-VA
Error in label values min 0.0 max 4.0      5-VLa
Error in label values min 0.0 max 9.0      6-VLP
Error in label values min 0.0 max 5.0      7-VPL
Error in label values min 0.0 max 4.0      9-LGN
Error in label values min 0.0 max 4.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 4.0      12-MD-Pf
Error in label values min 0.0 max 7.0      2-AV
Error in label values min 0.0 max 4.0      4-VA
Error in label values min 0.0 max 16.0      5-VLa
Error in label values min 0.0 max 20.0      6-VLP
Error in label values min 0.0 max 13.0      7-VPL
Error in label values min 0.0 max 3.0      9-LGN
Error in label values min 0.0 max 2.0      10-MGN
Error in label values min 0.0 max 2.0      11-CM
Error in label values min 0.0 max 5.0      12-MD-Pf
Error in label values min 0.0 max 30.0      13-Hb
Error in label values min 0.0 max 4.0      14-MTT
ResNet model address /array/ssd/msmajdi/experiments/keras/exp6/models/sE12_Cascade_FM20_Res_Unet2_NL3_LS_MyLogDice_US1_wLRScheduler_Main_Init_3T_CV_a/MultiClass_24567891011121314/sd0/model.h5
__________________________________________________________________________________________________
Layer (type)                    Output Shape         Param #     Connected to                     
==================================================================================================
input_1 (InputLayer)            (None, 80, 52, 1)    0                                            
__________________________________________________________________________________________________
conv2d_1 (Conv2D)               (None, 80, 52, 40)   400         input_1[0][0]                    
__________________________________________________________________________________________________
batch_normalization_1 (BatchNor (None, 80, 52, 40)   160         conv2d_1[0][0]                   
__________________________________________________________________________________________________
activation_1 (Activation)       (None, 80, 52, 40)   0           batch_normalization_1[0][0]      
__________________________________________________________________________________________________
dropout_1 (Dropout)             (None, 80, 52, 40)   0           activation_1[0][0]               
__________________________________________________________________________________________________
conv2d_2 (Conv2D)               (None, 80, 52, 40)   14440       dropout_1[0][0]                  
__________________________________________________________________________________________________
batch_normalization_2 (BatchNor (None, 80, 52, 40)   160         conv2d_2[0][0]                   
__________________________________________________________________________________________________
activation_2 (Activation)       (None, 80, 52, 40)   0           batch_normalization_2[0][0]      
__________________________________________________________________________________________________
dropout_2 (Dropout)             (None, 80, 52, 40)   0           activation_2[0][0]               
__________________________________________________________________________________________________
concatenate_1 (Concatenate)     (None, 80, 52, 41)   0           input_1[0][0]                    
                                                                 dropout_2[0][0]                  
__________________________________________________________________________________________________
conv2d_3 (Conv2D)               (None, 80, 52, 20)   7400        concatenate_1[0][0]              
__________________________________________________________________________________________________
batch_normalization_3 (BatchNor (None, 80, 52, 20)   80          conv2d_3[0][0]                   
__________________________________________________________________________________________________
activation_3 (Activation)       (None, 80, 52, 20)   0           batch_normalization_3[0][0]      
__________________________________________________________________________________________________
conv2d_4 (Conv2D)               (None, 80, 52, 20)   3620        activation_3[0][0]               
__________________________________________________________________________________________________
batch_normalization_4 (BatchNor (None, 80, 52, 20)   80          conv2d_4[0][0]                   
__________________________________________________________________________________________________
activation_4 (Activation)       (None, 80, 52, 20)   0           batch_normalization_4[0][0]      
__________________________________________________________________________________________________
max_pooling2d_1 (MaxPooling2D)  (None, 40, 26, 20)   0           activation_4[0][0]               
__________________________________________________________________________________________________
dropout_3 (Dropout)             (None, 40, 26, 20)   0           max_pooling2d_1[0][0]            
__________________________________________________________________________________________________
conv2d_5 (Conv2D)               (None, 40, 26, 40)   7240        dropout_3[0][0]                  
__________________________________________________________________________________________________
batch_normalization_5 (BatchNor (None, 40, 26, 40)   160         conv2d_5[0][0]                   
__________________________________________________________________________________________________
activation_5 (Activation)       (None, 40, 26, 40)   0           batch_normalization_5[0][0]      
__________________________________________________________________________________________________
conv2d_6 (Conv2D)               (None, 40, 26, 40)   14440       activation_5[0][0]               
__________________________________________________________________________________________________
batch_normalization_6 (BatchNor (None, 40, 26, 40)   160         conv2d_6[0][0]                   
__________________________________________________________________________________________________
activation_6 (Activation)       (None, 40, 26, 40)   0           batch_normalization_6[0][0]      
__________________________________________________________________________________________________
concatenate_2 (Concatenate)     (None, 40, 26, 60)   0           dropout_3[0][0]                  
                                                                 activation_6[0][0]               
__________________________________________________________________________________________________
max_pooling2d_2 (MaxPooling2D)  (None, 20, 13, 60)   0           concatenate_2[0][0]              
__________________________________________________________________________________________________
dropout_4 (Dropout)             (None, 20, 13, 60)   0           max_pooling2d_2[0][0]            
__________________________________________________________________________________________________
conv2d_7 (Conv2D)               (None, 20, 13, 80)   43280       dropout_4[0][0]                  
__________________________________________________________________________________________________
batch_normalization_7 (BatchNor (None, 20, 13, 80)   320         conv2d_7[0][0]                   
__________________________________________________________________________________________________
activation_7 (Activation)       (None, 20, 13, 80)   0           batch_normalization_7[0][0]      
__________________________________________________________________________________________________
conv2d_8 (Conv2D)               (None, 20, 13, 80)   57680       activation_7[0][0]               
__________________________________________________________________________________________________
batch_normalization_8 (BatchNor (None, 20, 13, 80)   320         conv2d_8[0][0]                   
__________________________________________________________________________________________________
activation_8 (Activation)       (None, 20, 13, 80)   0           batch_normalization_8[0][0]      
__________________________________________________________________________________________________
concatenate_3 (Concatenate)     (None, 20, 13, 140)  0           dropout_4[0][0]                  
                                                                 activation_8[0][0]               
__________________________________________________________________________________________________
dropout_5 (Dropout)             (None, 20, 13, 140)  0           concatenate_3[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_1 (Conv2DTrans (None, 40, 26, 40)   22440       dropout_5[0][0]                  
__________________________________________________________________________________________________
concatenate_4 (Concatenate)     (None, 40, 26, 100)  0           conv2d_transpose_1[0][0]         
                                                                 concatenate_2[0][0]              
__________________________________________________________________________________________________
conv2d_9 (Conv2D)               (None, 40, 26, 40)   36040       concatenate_4[0][0]              
__________________________________________________________________________________________________
batch_normalization_9 (BatchNor (None, 40, 26, 40)   160         conv2d_9[0][0]                   
__________________________________________________________________________________________________
activation_9 (Activation)       (None, 40, 26, 40)   0           batch_normalization_9[0][0]      
__________________________________________________________________________________________________
conv2d_10 (Conv2D)              (None, 40, 26, 40)   14440       activation_9[0][0]               
__________________________________________________________________________________________________
batch_normalization_10 (BatchNo (None, 40, 26, 40)   160         conv2d_10[0][0]                  
__________________________________________________________________________________________________
activation_10 (Activation)      (None, 40, 26, 40)   0           batch_normalization_10[0][0]     
__________________________________________________________________________________________________
concatenate_5 (Concatenate)     (None, 40, 26, 140)  0           concatenate_4[0][0]              
                                                                 activation_10[0][0]              
__________________________________________________________________________________________________
dropout_6 (Dropout)             (None, 40, 26, 140)  0           concatenate_5[0][0]              
__________________________________________________________________________________________________
conv2d_transpose_2 (Conv2DTrans (None, 80, 52, 20)   11220       dropout_6[0][0]                  
__________________________________________________________________________________________________
concatenate_6 (Concatenate)     (None, 80, 52, 40)   0           conv2d_transpose_2[0][0]         
                                                                 activation_4[0][0]               
__________________________________________________________________________________________________
conv2d_11 (Conv2D)              (None, 80, 52, 20)   7220        concatenate_6[0][0]              
__________________________________________________________________________________________________
batch_normalization_11 (BatchNo (None, 80, 52, 20)   80          conv2d_11[0][0]                  
__________________________________________________________________________________________________
activation_11 (Activation)      (None, 80, 52, 20)   0           batch_normalization_11[0][0]     
__________________________________________________________________________________________________
conv2d_12 (Conv2D)              (None, 80, 52, 20)   3620        activation_11[0][0]              
__________________________________________________________________________________________________
batch_normalization_12 (BatchNo (None, 80, 52, 20)   80          conv2d_12[0][0]                  
__________________________________________________________________________________________________
activation_12 (Activation)      (None, 80, 52, 20)   0           batch_normalization_12[0][0]     
__________________________________________________________________________________________________
concatenate_7 (Concatenate)     (None, 80, 52, 60)   0           concatenate_6[0][0]              
                                                                 activation_12[0][0]              
__________________________________________________________________________________________________
dropout_7 (Dropout)             (None, 80, 52, 60)   0           concatenate_7[0][0]              
__________________________________________________________________________________________________
conv2d_13 (Conv2D)              (None, 80, 52, 40)   21640       dropout_7[0][0]                  
__________________________________________________________________________________________________
batch_normalization_13 (BatchNo (None, 80, 52, 40)   160         conv2d_13[0][0]                  
__________________________________________________________________________________________________
activation_13 (Activation)      (None, 80, 52, 40)   0           batch_normalization_13[0][0]     
__________________________________________________________________________________________________
dropout_8 (Dropout)             (None, 80, 52, 40)   0           activation_13[0][0]              
__________________________________________________________________________________________________
conv2d_14 (Conv2D)              (None, 80, 52, 40)   14440       dropout_8[0][0]                  
__________________________________________________________________________________________________
batch_normalization_14 (BatchNo (None, 80, 52, 40)   160         conv2d_14[0][0]                  
__________________________________________________________________________________________________
activation_14 (Activation)      (None, 80, 52, 40)   0           batch_normalization_14[0][0]     
__________________________________________________________________________________________________
dropout_9 (Dropout)             (None, 80, 52, 40)   0           activation_14[0][0]              
__________________________________________________________________________________________________
concatenate_8 (Concatenate)     (None, 80, 52, 100)  0           dropout_7[0][0]                  
                                                                 dropout_9[0][0]                  
__________________________________________________________________________________________________
conv2d_15 (Conv2D)              (None, 80, 52, 13)   1313        concatenate_8[0][0]              
==================================================================================================
Total params: 283,113
Trainable params: 108,113
Non-trainable params: 175,000
__________________________________________________________________________________________________
------------------------------------------------------------------
class_weights [6.48913484e-02 3.19509754e-02 7.49897764e-02 9.32025064e-03
 2.70904632e-02 7.06417031e-03 8.46180096e-02 1.12618024e-01
 8.60108482e-02 1.32459736e-02 2.94100802e-01 1.93843398e-01
 2.55960049e-04]
Train on 10843 samples, validate on 104 samples
Epoch 1/300
 - 23s - loss: 2.5337 - acc: 0.7843 - mDice: 0.1287 - val_loss: 1.8097 - val_acc: 0.9031 - val_mDice: 0.2265

Epoch 00001: val_mDice improved from -inf to 0.22649, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 2/300
 - 16s - loss: 0.9980 - acc: 0.8778 - mDice: 0.3643 - val_loss: 1.5583 - val_acc: 0.9110 - val_mDice: 0.2897

Epoch 00002: val_mDice improved from 0.22649 to 0.28970, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 3/300
 - 16s - loss: 0.7107 - acc: 0.8828 - mDice: 0.4777 - val_loss: 2.0009 - val_acc: 0.9119 - val_mDice: 0.2790

Epoch 00003: val_mDice did not improve from 0.28970
Epoch 4/300
 - 16s - loss: 0.6021 - acc: 0.8875 - mDice: 0.5340 - val_loss: 1.2264 - val_acc: 0.9179 - val_mDice: 0.3928

Epoch 00004: val_mDice improved from 0.28970 to 0.39284, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 5/300
 - 16s - loss: 0.5361 - acc: 0.8921 - mDice: 0.5710 - val_loss: 0.8900 - val_acc: 0.9228 - val_mDice: 0.5275

Epoch 00005: val_mDice improved from 0.39284 to 0.52754, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 6/300
 - 16s - loss: 0.4994 - acc: 0.8957 - mDice: 0.5929 - val_loss: 0.8753 - val_acc: 0.9244 - val_mDice: 0.5335

Epoch 00006: val_mDice improved from 0.52754 to 0.53355, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 7/300
 - 16s - loss: 0.4756 - acc: 0.8994 - mDice: 0.6080 - val_loss: 0.8466 - val_acc: 0.9275 - val_mDice: 0.5566

Epoch 00007: val_mDice improved from 0.53355 to 0.55658, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 8/300
 - 17s - loss: 0.4531 - acc: 0.9036 - mDice: 0.6220 - val_loss: 0.8554 - val_acc: 0.9355 - val_mDice: 0.5539

Epoch 00008: val_mDice did not improve from 0.55658
Epoch 9/300
 - 16s - loss: 0.4382 - acc: 0.9109 - mDice: 0.6315 - val_loss: 0.8420 - val_acc: 0.9380 - val_mDice: 0.5566

Epoch 00009: val_mDice did not improve from 0.55658
Epoch 10/300
 - 16s - loss: 0.4278 - acc: 0.9239 - mDice: 0.6377 - val_loss: 0.8521 - val_acc: 0.9351 - val_mDice: 0.5474

Epoch 00010: val_mDice did not improve from 0.55658
Epoch 11/300
 - 16s - loss: 0.4108 - acc: 0.9343 - mDice: 0.6482 - val_loss: 0.8646 - val_acc: 0.9366 - val_mDice: 0.5431

Epoch 00011: val_mDice did not improve from 0.55658
Epoch 12/300
 - 16s - loss: 0.4010 - acc: 0.9373 - mDice: 0.6545 - val_loss: 0.8385 - val_acc: 0.9261 - val_mDice: 0.5493

Epoch 00012: val_mDice did not improve from 0.55658
Epoch 13/300
 - 16s - loss: 0.3940 - acc: 0.9379 - mDice: 0.6591 - val_loss: 0.8196 - val_acc: 0.9369 - val_mDice: 0.5540

Epoch 00013: val_mDice did not improve from 0.55658
Epoch 14/300
 - 16s - loss: 0.3849 - acc: 0.9390 - mDice: 0.6654 - val_loss: 0.8341 - val_acc: 0.9367 - val_mDice: 0.5537

Epoch 00014: val_mDice did not improve from 0.55658
Epoch 15/300
 - 16s - loss: 0.3792 - acc: 0.9396 - mDice: 0.6694 - val_loss: 0.8110 - val_acc: 0.9356 - val_mDice: 0.5652

Epoch 00015: val_mDice improved from 0.55658 to 0.56520, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 16/300
 - 16s - loss: 0.3709 - acc: 0.9402 - mDice: 0.6751 - val_loss: 0.8366 - val_acc: 0.9325 - val_mDice: 0.5508

Epoch 00016: val_mDice did not improve from 0.56520
Epoch 17/300
 - 16s - loss: 0.3662 - acc: 0.9406 - mDice: 0.6784 - val_loss: 0.8204 - val_acc: 0.9357 - val_mDice: 0.5526

Epoch 00017: val_mDice did not improve from 0.56520
Epoch 18/300
 - 16s - loss: 0.3633 - acc: 0.9411 - mDice: 0.6806 - val_loss: 0.8390 - val_acc: 0.9346 - val_mDice: 0.5466

Epoch 00018: val_mDice did not improve from 0.56520
Epoch 19/300
 - 16s - loss: 0.3539 - acc: 0.9417 - mDice: 0.6869 - val_loss: 0.7969 - val_acc: 0.9343 - val_mDice: 0.5678

Epoch 00019: val_mDice improved from 0.56520 to 0.56784, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 20/300
 - 16s - loss: 0.3524 - acc: 0.9420 - mDice: 0.6882 - val_loss: 0.7805 - val_acc: 0.9367 - val_mDice: 0.5708

Epoch 00020: val_mDice improved from 0.56784 to 0.57078, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 21/300
 - 16s - loss: 0.3472 - acc: 0.9425 - mDice: 0.6918 - val_loss: 0.8009 - val_acc: 0.9372 - val_mDice: 0.5602

Epoch 00021: val_mDice did not improve from 0.57078
Epoch 22/300
 - 16s - loss: 0.3464 - acc: 0.9426 - mDice: 0.6925 - val_loss: 0.8008 - val_acc: 0.9381 - val_mDice: 0.5592

Epoch 00022: val_mDice did not improve from 0.57078
Epoch 23/300
 - 16s - loss: 0.3390 - acc: 0.9432 - mDice: 0.6976 - val_loss: 0.7854 - val_acc: 0.9403 - val_mDice: 0.5649

Epoch 00023: val_mDice did not improve from 0.57078
Epoch 24/300
 - 16s - loss: 0.3369 - acc: 0.9434 - mDice: 0.6992 - val_loss: 0.8145 - val_acc: 0.9351 - val_mDice: 0.5451

Epoch 00024: val_mDice did not improve from 0.57078
Epoch 25/300
 - 16s - loss: 0.3354 - acc: 0.9436 - mDice: 0.7003 - val_loss: 0.7760 - val_acc: 0.9382 - val_mDice: 0.5724

Epoch 00025: val_mDice improved from 0.57078 to 0.57236, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 26/300
 - 17s - loss: 0.3288 - acc: 0.9439 - mDice: 0.7050 - val_loss: 0.7744 - val_acc: 0.9414 - val_mDice: 0.5749

Epoch 00026: val_mDice improved from 0.57236 to 0.57487, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 27/300
 - 16s - loss: 0.3287 - acc: 0.9441 - mDice: 0.7053 - val_loss: 0.7570 - val_acc: 0.9389 - val_mDice: 0.5687

Epoch 00027: val_mDice did not improve from 0.57487
Epoch 28/300
 - 16s - loss: 0.3253 - acc: 0.9444 - mDice: 0.7077 - val_loss: 0.7843 - val_acc: 0.9407 - val_mDice: 0.5558

Epoch 00028: val_mDice did not improve from 0.57487
Epoch 29/300
 - 16s - loss: 0.3228 - acc: 0.9447 - mDice: 0.7096 - val_loss: 0.8093 - val_acc: 0.9409 - val_mDice: 0.5578

Epoch 00029: val_mDice did not improve from 0.57487
Epoch 30/300
 - 16s - loss: 0.3199 - acc: 0.9450 - mDice: 0.7118 - val_loss: 0.8097 - val_acc: 0.9361 - val_mDice: 0.5420

Epoch 00030: val_mDice did not improve from 0.57487
Epoch 31/300
 - 17s - loss: 0.3166 - acc: 0.9453 - mDice: 0.7142 - val_loss: 0.7571 - val_acc: 0.9387 - val_mDice: 0.5667

Epoch 00031: val_mDice did not improve from 0.57487
Epoch 32/300
 - 16s - loss: 0.3151 - acc: 0.9454 - mDice: 0.7153 - val_loss: 0.7895 - val_acc: 0.9363 - val_mDice: 0.5567

Epoch 00032: val_mDice did not improve from 0.57487
Epoch 33/300
 - 16s - loss: 0.3139 - acc: 0.9453 - mDice: 0.7162 - val_loss: 0.8231 - val_acc: 0.9360 - val_mDice: 0.5470

Epoch 00033: val_mDice did not improve from 0.57487
Epoch 34/300
 - 16s - loss: 0.3134 - acc: 0.9455 - mDice: 0.7166 - val_loss: 0.7490 - val_acc: 0.9379 - val_mDice: 0.5667

Epoch 00034: val_mDice did not improve from 0.57487
Epoch 35/300
 - 16s - loss: 0.3071 - acc: 0.9461 - mDice: 0.7213 - val_loss: 0.8097 - val_acc: 0.9390 - val_mDice: 0.5505

Epoch 00035: val_mDice did not improve from 0.57487
Epoch 36/300
 - 16s - loss: 0.3076 - acc: 0.9461 - mDice: 0.7210 - val_loss: 0.8051 - val_acc: 0.9364 - val_mDice: 0.5477

Epoch 00036: val_mDice did not improve from 0.57487
Epoch 37/300
 - 16s - loss: 0.3048 - acc: 0.9463 - mDice: 0.7231 - val_loss: 0.7758 - val_acc: 0.9399 - val_mDice: 0.5655

Epoch 00037: val_mDice did not improve from 0.57487
Epoch 38/300
 - 16s - loss: 0.3023 - acc: 0.9464 - mDice: 0.7249 - val_loss: 0.7470 - val_acc: 0.9408 - val_mDice: 0.5752

Epoch 00038: val_mDice improved from 0.57487 to 0.57515, saving model to /array/ssd/msmajdi/experiments/keras/exp7/models/sE13_Cascade_FM20_ResFCN_ResUnet2_TL_NL3_LS_MyLogDice_US1_FCNA2_FCNB2_FM40_CSFn2_TL_Main_CV_a/MultiClass_24567891011121314/sd0/best_model_weights_TF_CSFn2.h5
Epoch 39/300
 - 16s - loss: 0.3023 - acc: 0.9464 - mDice: 0.7248 - val_loss: 0.7996 - val_acc: 0.9373 - val_mDice: 0.5522

Epoch 00039: val_mDice did not improve from 0.57515
Epoch 40/300
 - 16s - loss: 0.3017 - acc: 0.9464 - mDice: 0.7254 - val_loss: 0.7789 - val_acc: 0.9386 - val_mDice: 0.5644

Epoch 00040: val_mDice did not improve from 0.57515
Epoch 41/300
 - 16s - loss: 0.2984 - acc: 0.9468 - mDice: 0.7279 - val_loss: 0.7971 - val_acc: 0.9371 - val_mDice: 0.5525

Epoch 00041: val_mDice did not improve from 0.57515
Epoch 42/300
 - 16s - loss: 0.2986 - acc: 0.9467 - mDice: 0.7277 - val_loss: 0.8033 - val_acc: 0.9399 - val_mDice: 0.5576

Epoch 00042: val_mDice did not improve from 0.57515
Epoch 43/300
 - 16s - loss: 0.2956 - acc: 0.9471 - mDice: 0.7300 - val_loss: 0.7671 - val_acc: 0.9385 - val_mDice: 0.5643

Epoch 00043: val_mDice did not improve from 0.57515
Epoch 44/300
 - 16s - loss: 0.2935 - acc: 0.9473 - mDice: 0.7316 - val_loss: 0.7960 - val_acc: 0.9383 - val_mDice: 0.5536

Epoch 00044: val_mDice did not improve from 0.57515
Epoch 45/300
 - 16s - loss: 0.2928 - acc: 0.9473 - mDice: 0.7321 - val_loss: 0.7614 - val_acc: 0.9373 - val_mDice: 0.5574

Epoch 00045: val_mDice did not improve from 0.57515
Epoch 46/300
 - 16s - loss: 0.2934 - acc: 0.9473 - mDice: 0.7317 - val_loss: 0.7653 - val_acc: 0.9351 - val_mDice: 0.5522

Epoch 00046: val_mDice did not improve from 0.57515
Epoch 47/300
 - 16s - loss: 0.2885 - acc: 0.9477 - mDice: 0.7354 - val_loss: 0.8036 - val_acc: 0.9389 - val_mDice: 0.5536

Epoch 00047: val_mDice did not improve from 0.57515
Epoch 48/300
 - 16s - loss: 0.2876 - acc: 0.9477 - mDice: 0.7362 - val_loss: 0.7595 - val_acc: 0.9381 - val_mDice: 0.5691

Epoch 00048: val_mDice did not improve from 0.57515
Epoch 49/300
 - 16s - loss: 0.2859 - acc: 0.9478 - mDice: 0.7374 - val_loss: 0.8245 - val_acc: 0.9418 - val_mDice: 0.5574

Epoch 00049: val_mDice did not improve from 0.57515
Epoch 50/300
 - 16s - loss: 0.2870 - acc: 0.9479 - mDice: 0.7366 - val_loss: 0.7634 - val_acc: 0.9400 - val_mDice: 0.5677

Epoch 00050: val_mDice did not improve from 0.57515
Epoch 51/300
 - 16s - loss: 0.2855 - acc: 0.9479 - mDice: 0.7378 - val_loss: 0.7610 - val_acc: 0.9383 - val_mDice: 0.5522

Epoch 00051: val_mDice did not improve from 0.57515
Epoch 52/300
 - 16s - loss: 0.2848 - acc: 0.9479 - mDice: 0.7384 - val_loss: 0.8037 - val_acc: 0.9430 - val_mDice: 0.5425

Epoch 00052: val_mDice did not improve from 0.57515
Epoch 53/300
 - 16s - loss: 0.2823 - acc: 0.9482 - mDice: 0.7402 - val_loss: 0.7588 - val_acc: 0.9332 - val_mDice: 0.5440

Epoch 00053: val_mDice did not improve from 0.57515
Epoch 54/300
 - 16s - loss: 0.2819 - acc: 0.9483 - mDice: 0.7406 - val_loss: 0.7637 - val_acc: 0.9369 - val_mDice: 0.5593

Epoch 00054: val_mDice did not improve from 0.57515
Epoch 55/300
 - 16s - loss: 0.2786 - acc: 0.9486 - mDice: 0.7430 - val_loss: 0.7702 - val_acc: 0.9356 - val_mDice: 0.5485

Epoch 00055: val_mDice did not improve from 0.57515
Epoch 56/300
 - 16s - loss: 0.2830 - acc: 0.9482 - mDice: 0.7398 - val_loss: 0.7956 - val_acc: 0.9323 - val_mDice: 0.5370

Epoch 00056: val_mDice did not improve from 0.57515
Epoch 57/300
 - 16s - loss: 0.2771 - acc: 0.9486 - mDice: 0.7442 - val_loss: 0.8125 - val_acc: 0.9376 - val_mDice: 0.5470

Epoch 00057: val_mDice did not improve from 0.57515
Epoch 58/300
 - 16s - loss: 0.2789 - acc: 0.9486 - mDice: 0.7429 - val_loss: 0.8264 - val_acc: 0.9363 - val_mDice: 0.5370

Epoch 00058: val_mDice did not improve from 0.57515
Epoch 59/300
 - 16s - loss: 0.2762 - acc: 0.9487 - mDice: 0.7450 - val_loss: 0.8032 - val_acc: 0.9337 - val_mDice: 0.5402

Epoch 00059: val_mDice did not improve from 0.57515
Epoch 60/300
 - 16s - loss: 0.2757 - acc: 0.9488 - mDice: 0.7454 - val_loss: 0.7793 - val_acc: 0.9400 - val_mDice: 0.5543

Epoch 00060: val_mDice did not improve from 0.57515
Epoch 61/300
 - 16s - loss: 0.2756 - acc: 0.9488 - mDice: 0.7455 - val_loss: 0.7543 - val_acc: 0.9412 - val_mDice: 0.5683

Epoch 00061: val_mDice did not improve from 0.57515
Epoch 62/300
 - 16s - loss: 0.2746 - acc: 0.9489 - mDice: 0.7462 - val_loss: 0.7941 - val_acc: 0.9342 - val_mDice: 0.5433

Epoch 00062: val_mDice did not improve from 0.57515
Epoch 63/300
 - 16s - loss: 0.2742 - acc: 0.9489 - mDice: 0.7466 - val_loss: 0.7733 - val_acc: 0.9397 - val_mDice: 0.5642

Epoch 00063: val_mDice did not improve from 0.57515
Epoch 64/300
 - 16s - loss: 0.2715 - acc: 0.9492 - mDice: 0.7487 - val_loss: 0.7468 - val_acc: 0.9372 - val_mDice: 0.5530

Epoch 00064: val_mDice did not improve from 0.57515
Epoch 65/300
 - 16s - loss: 0.2708 - acc: 0.9493 - mDice: 0.7492 - val_loss: 0.7369 - val_acc: 0.9323 - val_mDice: 0.5584

Epoch 00065: val_mDice did not improve from 0.57515
Epoch 66/300
 - 16s - loss: 0.2696 - acc: 0.9493 - mDice: 0.7501 - val_loss: 0.7569 - val_acc: 0.9374 - val_mDice: 0.5478

Epoch 00066: val_mDice did not improve from 0.57515
Epoch 67/300
 - 16s - loss: 0.2687 - acc: 0.9493 - mDice: 0.7509 - val_loss: 0.7799 - val_acc: 0.9385 - val_mDice: 0.5515

Epoch 00067: val_mDice did not improve from 0.57515
Epoch 68/300
 - 16s - loss: 0.2682 - acc: 0.9494 - mDice: 0.7513 - val_loss: 0.7765 - val_acc: 0.9394 - val_mDice: 0.5553

Epoch 00068: val_mDice did not improve from 0.57515
Epoch 69/300
 - 16s - loss: 0.2685 - acc: 0.9493 - mDice: 0.7510 - val_loss: 0.7588 - val_acc: 0.9391 - val_mDice: 0.5598

Epoch 00069: val_mDice did not improve from 0.57515
Epoch 70/300
 - 16s - loss: 0.2673 - acc: 0.9494 - mDice: 0.7520 - val_loss: 0.7758 - val_acc: 0.9384 - val_mDice: 0.5580

Epoch 00070: val_mDice did not improve from 0.57515
Epoch 71/300
 - 16s - loss: 0.2667 - acc: 0.9495 - mDice: 0.7525 - val_loss: 0.7671 - val_acc: 0.9365 - val_mDice: 0.5564

Epoch 00071: val_mDice did not improve from 0.57515
Epoch 72/300
 - 16s - loss: 0.2670 - acc: 0.9495 - mDice: 0.7522 - val_loss: 0.7805 - val_acc: 0.9390 - val_mDice: 0.5607

Epoch 00072: val_mDice did not improve from 0.57515
Epoch 73/300
 - 16s - loss: 0.2658 - acc: 0.9497 - mDice: 0.7532 - val_loss: 0.7793 - val_acc: 0.9388 - val_mDice: 0.5492

Epoch 00073: val_mDice did not improve from 0.57515
Epoch 74/300
 - 16s - loss: 0.2649 - acc: 0.9498 - mDice: 0.7539 - val_loss: 0.7814 - val_acc: 0.9392 - val_mDice: 0.5466

Epoch 00074: val_mDice did not improve from 0.57515
Epoch 75/300
 - 16s - loss: 0.2638 - acc: 0.9499 - mDice: 0.7548 - val_loss: 0.7816 - val_acc: 0.9359 - val_mDice: 0.5464

Epoch 00075: val_mDice did not improve from 0.57515
Epoch 76/300
 - 16s - loss: 0.2615 - acc: 0.9501 - mDice: 0.7566 - val_loss: 0.7645 - val_acc: 0.9360 - val_mDice: 0.5520

Epoch 00076: val_mDice did not improve from 0.57515
Epoch 77/300
 - 16s - loss: 0.2613 - acc: 0.9500 - mDice: 0.7567 - val_loss: 0.7749 - val_acc: 0.9383 - val_mDice: 0.5456

Epoch 00077: val_mDice did not improve from 0.57515
Epoch 78/300
 - 16s - loss: 0.2616 - acc: 0.9501 - mDice: 0.7564 - val_loss: 0.7750 - val_acc: 0.9389 - val_mDice: 0.5431

Epoch 00078: val_mDice did not improve from 0.57515
Restoring model weights from the end of the best epoch
Epoch 00078: early stopping
{'val_loss': [1.8097095627051134, 1.5583120401089008, 2.000940286196195, 1.2264043642924383, 0.889956323000101, 0.8753222548044645, 0.8465686898965102, 0.8553822842928079, 0.84204435807008, 0.8520710880939777, 0.8646441835623521, 0.8384905159473419, 0.8195691360877111, 0.8341361330105708, 0.8110121878293844, 0.836593359708786, 0.8204027414321899, 0.8389989687846258, 0.7969132547195141, 0.7805097034344306, 0.8008647400599259, 0.8008227829749768, 0.7854434756132272, 0.8145150817357577, 0.7759752456958477, 0.7743903123415433, 0.7570022550913004, 0.7842507912562444, 0.8093390052135174, 0.8096959820160499, 0.7570746793196752, 0.7894577727868006, 0.8230744829544654, 0.7489925577090337, 0.8096578556757706, 0.8050576035793011, 0.7757584819426904, 0.7470391117609464, 0.7995515098938575, 0.7789380114812118, 0.7971486609715682, 0.8032738520548894, 0.7671476625479184, 0.7960025782768543, 0.7614363409005679, 0.7652930915355682, 0.8035567975961245, 0.7594694770299472, 0.8245187699794769, 0.7634329291490408, 0.7610261256878192, 0.8036664861899155, 0.7587725245035611, 0.7637218557871305, 0.7702264648217422, 0.7955858638653388, 0.8124601382475632, 0.8264326315659744, 0.8032299853288211, 0.7792834318601168, 0.754323993737881, 0.7941316091097318, 0.7733106567309453, 0.7467539998201224, 0.7369384811474726, 0.7569164908849276, 0.7798947600217966, 0.7765333721270928, 0.7588375646334428, 0.7758058378329644, 0.7671320323760693, 0.7805390724769006, 0.7792849311461816, 0.7814237314921159, 0.7816388882123507, 0.764538613649515, 0.7749410271644592, 0.7750184948627765], 'val_acc': [0.9030648813797877, 0.9109560021987329, 0.9118597713800577, 0.9179202318191528, 0.9228411362721369, 0.9243805362628057, 0.9274593247817113, 0.9355260661015143, 0.9379715460997361, 0.9350892030275785, 0.9366147105510418, 0.9260655687405512, 0.9368990613864019, 0.936670197890355, 0.9356000606830304, 0.9324681254533621, 0.9357202213544112, 0.934573790201774, 0.9343403119307297, 0.9367395708194146, 0.9371509804175451, 0.9380847811698914, 0.9403360486030579, 0.93513773725583, 0.9382234788857974, 0.9413669613691477, 0.9389215065882757, 0.9407267066148611, 0.9409046677442697, 0.9360623336755313, 0.9386834387595837, 0.9363420009613037, 0.9359906567977025, 0.937920678120393, 0.9390393633108872, 0.9363789833509005, 0.9398553325579717, 0.9408353292025052, 0.93728274336228, 0.9386141162652236, 0.937137097120285, 0.9398922874377325, 0.9385424141700451, 0.9383367002010345, 0.9372827250223893, 0.9351192850332993, 0.9388937514561874, 0.938112504207171, 0.941831519970527, 0.9400055752350733, 0.9382766164266146, 0.9429617936794574, 0.9332262300528013, 0.9368689885506263, 0.9355815671957456, 0.9323340356349945, 0.9376479410208188, 0.9363234960115873, 0.9337162467149588, 0.9400101808401254, 0.9411982206197885, 0.934238653916579, 0.939737448325524, 0.9371787034548246, 0.932299398458921, 0.9373705730988429, 0.9385170202988845, 0.9393629890221816, 0.9390555666043208, 0.9384453617609464, 0.9364783878509815, 0.9390024176010718, 0.938822118135599, 0.9392127188352438, 0.9359190257696005, 0.9359768147651966, 0.9382974207401276, 0.938856805746372], 'val_mDice': [0.2264921493255175, 0.289695693896367, 0.2789582432462619, 0.3928432728235538, 0.5275439459543961, 0.5335456556998767, 0.5565818038124305, 0.5538787887646601, 0.5565580588120681, 0.5473538906528399, 0.5431145481192149, 0.5492864153706111, 0.5540388885598916, 0.5536705175271401, 0.5652018510378324, 0.5507904789768733, 0.552563339471817, 0.5465978945677097, 0.5678392683084195, 0.5707788369976557, 0.5602210960709132, 0.5591832605692056, 0.5649257800900019, 0.5451254191306921, 0.5723585234238551, 0.574871552678255, 0.5686921007358111, 0.555775662454275, 0.5577714351507334, 0.5419709292741922, 0.5667397643511112, 0.5566635865431565, 0.5469911866463147, 0.5667201807865729, 0.5505304657495939, 0.5477036925462576, 0.5655134520851649, 0.5751521220574012, 0.5522323130415037, 0.5643554971768305, 0.5524887614525281, 0.5575755152564782, 0.5643281535460398, 0.5535777108027384, 0.5573939486191823, 0.5521621704101562, 0.5536244889864554, 0.5690565699568162, 0.5574439666592158, 0.5676807807042048, 0.5521830893479861, 0.5425354895683435, 0.5440467401192739, 0.5592567972265757, 0.5485032905752842, 0.5370272420919858, 0.5469782289404136, 0.5370396570517466, 0.5402424117693534, 0.5542933035355347, 0.5682823829925977, 0.5432546110107348, 0.5642337523973905, 0.5529564005824236, 0.558389986363741, 0.5478013020295364, 0.5515280400331204, 0.5553371035135709, 0.5597758419238604, 0.5579553200648382, 0.5564067180340106, 0.5607240073955976, 0.549200625373767, 0.5465525062038348, 0.5463909317667668, 0.5519660080854709, 0.5456108783300107, 0.543054596735881], 'loss': [2.5336685734877866, 0.9979803668092694, 0.7106949553370508, 0.6020814967553444, 0.536096305663786, 0.4993766740735448, 0.47561412330682146, 0.4531369076617956, 0.43816825992933756, 0.4278451017867064, 0.41082288090795493, 0.40095902749184453, 0.3939847275387985, 0.3848566675465408, 0.37923577111783, 0.3709092007993409, 0.3661510571198392, 0.3633186659925727, 0.3539335290098019, 0.3524299889080069, 0.34723112077540624, 0.3464037501112755, 0.3390277066123471, 0.3368858400964873, 0.33541955911210575, 0.328810508885771, 0.3286542622660245, 0.32529070155708306, 0.32283648003360327, 0.31992404310617306, 0.316629076764272, 0.31505284622279983, 0.31385173428919466, 0.3133754122799243, 0.30710981170717533, 0.3075596646338847, 0.3048186269285142, 0.30225572516631677, 0.30234039200305457, 0.3016582602621455, 0.2984489653945618, 0.2985904824658974, 0.29559543963003276, 0.2935087127344949, 0.2927754422367845, 0.29344499287906084, 0.2885277517676562, 0.28759037912645036, 0.28594466592292994, 0.2870165210807828, 0.2854528109064008, 0.2848047778899518, 0.28232506972985066, 0.2818968943412548, 0.27863598492415337, 0.2829655196232889, 0.2771044467292148, 0.27893663641162586, 0.2761618163624582, 0.27574284621669415, 0.2756025359538894, 0.2746178935311393, 0.2742199699569538, 0.2714526173643638, 0.2708482464268167, 0.2696106333492054, 0.2686814863413756, 0.26822484293228516, 0.26847506779086533, 0.26729652146500193, 0.266716989324309, 0.2670011436775427, 0.26576655095522667, 0.26486552840975347, 0.2637968481461038, 0.26147629904272063, 0.2612698177927195, 0.26159614439733153], 'acc': [0.7842774095927109, 0.8778063344700381, 0.8828472951774963, 0.8874618688006138, 0.8920893218864058, 0.895728593947625, 0.8994274047603359, 0.9035609190252712, 0.9109152745609078, 0.9238510417903051, 0.9342720440906604, 0.9373122899556285, 0.9379021139819057, 0.9389917453936322, 0.9395845580516591, 0.9402452806622562, 0.9406435527309417, 0.9410863505686867, 0.9416830412501351, 0.9419873429490314, 0.9425081508764095, 0.9425663202327632, 0.9431768949430037, 0.9433525664872551, 0.9435531105390941, 0.9439481742089826, 0.9441205447289399, 0.94435964063405, 0.9446604374885823, 0.944971343918633, 0.9452658879859173, 0.9453853611289537, 0.9453166328782163, 0.9454956316292688, 0.9460534600493412, 0.9460931673026179, 0.9463487382932506, 0.9463962249338962, 0.9464287267480622, 0.946401768836502, 0.9467574560663131, 0.9467326691314918, 0.9470582758655828, 0.9472829204670763, 0.9473338227512585, 0.9472700366122492, 0.9476780699351106, 0.9476645905340684, 0.9478496861866806, 0.9478550726314384, 0.9479244421529537, 0.9479386295865935, 0.9481573086278329, 0.9482706420526924, 0.9485560079776613, 0.9481919377720643, 0.9486497183419083, 0.9485693304650648, 0.9487007962242435, 0.948802203058174, 0.9487822050759354, 0.948881077621296, 0.9489475663579237, 0.9492214042949334, 0.9492838798408786, 0.949302808891899, 0.949335356524078, 0.9494311744344638, 0.9493200807765787, 0.949408429999045, 0.9494902773458865, 0.949489812508815, 0.9496661444481235, 0.9497855325406145, 0.9498535473166626, 0.9500782800800387, 0.9499919311450349, 0.9501477370543155], 'mDice': [0.12873575780281313, 0.3643160825185557, 0.4777482540792374, 0.5339776490608242, 0.5709610153671605, 0.5928654289988808, 0.6079781249771586, 0.6220202803952574, 0.6314973615417069, 0.6376551682467744, 0.6482190987527958, 0.6544971546816296, 0.6591053007713908, 0.6654390848442647, 0.6694069459936798, 0.6750689101848041, 0.6784024784169843, 0.68056631660501, 0.6869429114295209, 0.6881771336663399, 0.6918243605481691, 0.6925074267264256, 0.697647711628864, 0.6992354593208374, 0.700345283997935, 0.7050088855994426, 0.7052567834993971, 0.7077190714393453, 0.7096177120880701, 0.7118266895172902, 0.7141504161727062, 0.7153202133140012, 0.7162104626044041, 0.7166172508261999, 0.7212970424135992, 0.7210492058278757, 0.7231172665913782, 0.7249469695787836, 0.7248309279657934, 0.7254464887422708, 0.7278640297773435, 0.7276854766236452, 0.7299631803576427, 0.731616928218355, 0.7321473450818141, 0.7317150971232707, 0.7353730854002585, 0.7361521942197952, 0.7374274265246121, 0.7366261050939275, 0.7378259228294564, 0.7383756264542606, 0.7402383922804966, 0.7405549321657924, 0.7430495124763419, 0.7397862947878776, 0.7442254068490204, 0.7429122707230968, 0.7450105646797116, 0.7453733939235307, 0.7454656360554627, 0.7462406777856228, 0.7465785576234518, 0.7486665487333405, 0.7491671205237597, 0.7501239686514479, 0.7508620926894727, 0.7512724269890955, 0.7510497001531675, 0.7519947976343946, 0.752463610274737, 0.7521662601771131, 0.7532231825958986, 0.7538789019949221, 0.7547522059866042, 0.7565523587304003, 0.7567401704099536, 0.7564338200384539]}
predicting test subjects:   0%|          | 0/3 [00:00<?, ?it/s]predicting test subjects:  33%|███▎      | 1/3 [00:02<00:04,  2.47s/it]predicting test subjects:  67%|██████▋   | 2/3 [00:04<00:02,  2.20s/it]predicting test subjects: 100%|██████████| 3/3 [00:05<00:00,  2.02s/it]
predicting train subjects:   0%|          | 0/285 [00:00<?, ?it/s]predicting train subjects:   0%|          | 1/285 [00:01<09:13,  1.95s/it]predicting train subjects:   1%|          | 2/285 [00:03<08:27,  1.79s/it]predicting train subjects:   1%|          | 3/285 [00:05<08:18,  1.77s/it]predicting train subjects:   1%|▏         | 4/285 [00:06<07:50,  1.67s/it]predicting train subjects:   2%|▏         | 5/285 [00:08<08:04,  1.73s/it]predicting train subjects:   2%|▏         | 6/285 [00:09<07:49,  1.68s/it]predicting train subjects:   2%|▏         | 7/285 [00:11<08:09,  1.76s/it]predicting train subjects:   3%|▎         | 8/285 [00:13<07:59,  1.73s/it]predicting train subjects:   3%|▎         | 9/285 [00:15<08:16,  1.80s/it]predicting train subjects:   4%|▎         | 10/285 [00:17<08:38,  1.89s/it]predicting train subjects:   4%|▍         | 11/285 [00:19<08:16,  1.81s/it]predicting train subjects:   4%|▍         | 12/285 [00:21<08:34,  1.88s/it]predicting train subjects:   5%|▍         | 13/285 [00:23<08:19,  1.84s/it]predicting train subjects:   5%|▍         | 14/285 [00:24<08:26,  1.87s/it]predicting train subjects:   5%|▌         | 15/285 [00:27<08:37,  1.92s/it]predicting train subjects:   6%|▌         | 16/285 [00:29<08:41,  1.94s/it]predicting train subjects:   6%|▌         | 17/285 [00:30<08:18,  1.86s/it]predicting train subjects:   6%|▋         | 18/285 [00:32<08:09,  1.83s/it]predicting train subjects:   7%|▋         | 19/285 [00:34<07:47,  1.76s/it]predicting train subjects:   7%|▋         | 20/285 [00:35<07:52,  1.78s/it]predicting train subjects:   7%|▋         | 21/285 [00:37<08:07,  1.85s/it]predicting train subjects:   8%|▊         | 22/285 [00:39<07:49,  1.78s/it]predicting train subjects:   8%|▊         | 23/285 [00:41<07:52,  1.80s/it]predicting train subjects:   8%|▊         | 24/285 [00:43<07:39,  1.76s/it]predicting train subjects:   9%|▉         | 25/285 [00:44<07:53,  1.82s/it]predicting train subjects:   9%|▉         | 26/285 [00:47<08:10,  1.90s/it]predicting train subjects:   9%|▉         | 27/285 [00:48<07:55,  1.84s/it]predicting train subjects:  10%|▉         | 28/285 [00:50<07:53,  1.84s/it]predicting train subjects:  10%|█         | 29/285 [00:52<07:57,  1.87s/it]predicting train subjects:  11%|█         | 30/285 [00:54<08:07,  1.91s/it]predicting train subjects:  11%|█         | 31/285 [00:56<08:09,  1.93s/it]predicting train subjects:  11%|█         | 32/285 [00:58<07:45,  1.84s/it]predicting train subjects:  12%|█▏        | 33/285 [01:00<07:48,  1.86s/it]predicting train subjects:  12%|█▏        | 34/285 [01:01<07:45,  1.85s/it]predicting train subjects:  12%|█▏        | 35/285 [01:04<08:03,  1.93s/it]predicting train subjects:  13%|█▎        | 36/285 [01:05<07:45,  1.87s/it]predicting train subjects:  13%|█▎        | 37/285 [01:07<07:55,  1.92s/it]predicting train subjects:  13%|█▎        | 38/285 [01:09<07:55,  1.93s/it]predicting train subjects:  14%|█▎        | 39/285 [01:11<07:30,  1.83s/it]predicting train subjects:  14%|█▍        | 40/285 [01:13<07:33,  1.85s/it]predicting train subjects:  14%|█▍        | 41/285 [01:14<07:22,  1.81s/it]predicting train subjects:  15%|█▍        | 42/285 [01:16<07:21,  1.82s/it]predicting train subjects:  15%|█▌        | 43/285 [01:18<07:26,  1.84s/it]predicting train subjects:  15%|█▌        | 44/285 [01:20<07:27,  1.86s/it]predicting train subjects:  16%|█▌        | 45/285 [01:22<07:10,  1.79s/it]predicting train subjects:  16%|█▌        | 46/285 [01:24<07:22,  1.85s/it]predicting train subjects:  16%|█▋        | 47/285 [01:25<07:06,  1.79s/it]predicting train subjects:  17%|█▋        | 48/285 [01:27<07:05,  1.80s/it]predicting train subjects:  17%|█▋        | 49/285 [01:29<07:23,  1.88s/it]predicting train subjects:  18%|█▊        | 50/285 [01:31<07:23,  1.89s/it]predicting train subjects:  18%|█▊        | 51/285 [01:33<07:25,  1.91s/it]predicting train subjects:  18%|█▊        | 52/285 [01:35<07:11,  1.85s/it]predicting train subjects:  19%|█▊        | 53/285 [01:37<07:13,  1.87s/it]predicting train subjects:  19%|█▉        | 54/285 [01:39<07:21,  1.91s/it]predicting train subjects:  19%|█▉        | 55/285 [01:40<07:07,  1.86s/it]predicting train subjects:  20%|█▉        | 56/285 [01:42<07:13,  1.89s/it]predicting train subjects:  20%|██        | 57/285 [01:44<06:59,  1.84s/it]predicting train subjects:  20%|██        | 58/285 [01:46<07:10,  1.90s/it]predicting train subjects:  21%|██        | 59/285 [01:48<07:22,  1.96s/it]predicting train subjects:  21%|██        | 60/285 [01:50<07:29,  2.00s/it]predicting train subjects:  21%|██▏       | 61/285 [01:52<07:06,  1.90s/it]predicting train subjects:  22%|██▏       | 62/285 [01:54<07:15,  1.95s/it]predicting train subjects:  22%|██▏       | 63/285 [01:56<07:10,  1.94s/it]predicting train subjects:  22%|██▏       | 64/285 [01:58<06:54,  1.88s/it]predicting train subjects:  23%|██▎       | 65/285 [02:00<06:58,  1.90s/it]predicting train subjects:  23%|██▎       | 66/285 [02:02<06:49,  1.87s/it]predicting train subjects:  24%|██▎       | 67/285 [02:03<06:49,  1.88s/it]predicting train subjects:  24%|██▍       | 68/285 [02:05<06:29,  1.80s/it]predicting train subjects:  24%|██▍       | 69/285 [02:07<06:32,  1.82s/it]predicting train subjects:  25%|██▍       | 70/285 [02:09<06:30,  1.82s/it]predicting train subjects:  25%|██▍       | 71/285 [02:11<06:33,  1.84s/it]predicting train subjects:  25%|██▌       | 72/285 [02:12<06:19,  1.78s/it]predicting train subjects:  26%|██▌       | 73/285 [02:14<06:21,  1.80s/it]predicting train subjects:  26%|██▌       | 74/285 [02:16<06:23,  1.82s/it]predicting train subjects:  26%|██▋       | 75/285 [02:18<06:21,  1.82s/it]predicting train subjects:  27%|██▋       | 76/285 [02:20<06:22,  1.83s/it]predicting train subjects:  27%|██▋       | 77/285 [02:21<06:16,  1.81s/it]predicting train subjects:  27%|██▋       | 78/285 [02:23<06:04,  1.76s/it]predicting train subjects:  28%|██▊       | 79/285 [02:25<06:15,  1.82s/it]predicting train subjects:  28%|██▊       | 80/285 [02:27<06:17,  1.84s/it]predicting train subjects:  28%|██▊       | 81/285 [02:29<06:05,  1.79s/it]predicting train subjects:  29%|██▉       | 82/285 [02:30<06:07,  1.81s/it]predicting train subjects:  29%|██▉       | 83/285 [02:32<05:57,  1.77s/it]predicting train subjects:  29%|██▉       | 84/285 [02:34<05:43,  1.71s/it]predicting train subjects:  30%|██▉       | 85/285 [02:35<05:48,  1.74s/it]predicting train subjects:  30%|███       | 86/285 [02:37<05:55,  1.79s/it]predicting train subjects:  31%|███       | 87/285 [02:39<06:02,  1.83s/it]predicting train subjects:  31%|███       | 88/285 [02:41<05:51,  1.78s/it]predicting train subjects:  31%|███       | 89/285 [02:43<05:53,  1.80s/it]predicting train subjects:  32%|███▏      | 90/285 [02:45<05:59,  1.84s/it]predicting train subjects:  32%|███▏      | 91/285 [02:46<05:48,  1.80s/it]predicting train subjects:  32%|███▏      | 92/285 [02:49<06:02,  1.88s/it]predicting train subjects:  33%|███▎      | 93/285 [02:50<05:50,  1.82s/it]predicting train subjects:  33%|███▎      | 94/285 [02:52<05:52,  1.85s/it]predicting train subjects:  33%|███▎      | 95/285 [02:54<05:52,  1.85s/it]predicting train subjects:  34%|███▎      | 96/285 [02:56<05:48,  1.84s/it]predicting train subjects:  34%|███▍      | 97/285 [02:58<05:42,  1.82s/it]predicting train subjects:  34%|███▍      | 98/285 [02:59<05:43,  1.84s/it]predicting train subjects:  35%|███▍      | 99/285 [03:01<05:39,  1.82s/it]predicting train subjects:  35%|███▌      | 100/285 [03:03<05:37,  1.82s/it]predicting train subjects:  35%|███▌      | 101/285 [03:05<05:23,  1.76s/it]predicting train subjects:  36%|███▌      | 102/285 [03:07<05:30,  1.81s/it]predicting train subjects:  36%|███▌      | 103/285 [03:08<05:26,  1.80s/it]predicting train subjects:  36%|███▋      | 104/285 [03:10<05:36,  1.86s/it]predicting train subjects:  37%|███▋      | 105/285 [03:12<05:40,  1.89s/it]predicting train subjects:  37%|███▋      | 106/285 [03:14<05:27,  1.83s/it]predicting train subjects:  38%|███▊      | 107/285 [03:16<05:25,  1.83s/it]predicting train subjects:  38%|███▊      | 108/285 [03:17<05:11,  1.76s/it]predicting train subjects:  38%|███▊      | 109/285 [03:19<05:14,  1.78s/it]predicting train subjects:  39%|███▊      | 110/285 [03:21<05:14,  1.80s/it]predicting train subjects:  39%|███▉      | 111/285 [03:23<05:04,  1.75s/it]predicting train subjects:  39%|███▉      | 112/285 [03:25<05:08,  1.78s/it]predicting train subjects:  40%|███▉      | 113/285 [03:26<05:11,  1.81s/it]predicting train subjects:  40%|████      | 114/285 [03:28<05:13,  1.83s/it]predicting train subjects:  40%|████      | 115/285 [03:30<05:19,  1.88s/it]predicting train subjects:  41%|████      | 116/285 [03:32<05:12,  1.85s/it]predicting train subjects:  41%|████      | 117/285 [03:34<05:01,  1.80s/it]predicting train subjects:  41%|████▏     | 118/285 [03:35<04:53,  1.76s/it]predicting train subjects:  42%|████▏     | 119/285 [03:37<04:53,  1.77s/it]predicting train subjects:  42%|████▏     | 120/285 [03:39<04:50,  1.76s/it]predicting train subjects:  42%|████▏     | 121/285 [03:41<04:46,  1.75s/it]predicting train subjects:  43%|████▎     | 122/285 [03:42<04:35,  1.69s/it]predicting train subjects:  43%|████▎     | 123/285 [03:44<04:32,  1.68s/it]predicting train subjects:  44%|████▎     | 124/285 [03:46<04:27,  1.66s/it]predicting train subjects:  44%|████▍     | 125/285 [03:47<04:18,  1.62s/it]predicting train subjects:  44%|████▍     | 126/285 [03:49<04:16,  1.61s/it]predicting train subjects:  45%|████▍     | 127/285 [03:50<04:10,  1.59s/it]predicting train subjects:  45%|████▍     | 128/285 [03:52<04:15,  1.63s/it]predicting train subjects:  45%|████▌     | 129/285 [03:53<04:10,  1.61s/it]predicting train subjects:  46%|████▌     | 130/285 [03:55<04:02,  1.57s/it]predicting train subjects:  46%|████▌     | 131/285 [03:56<03:59,  1.56s/it]predicting train subjects:  46%|████▋     | 132/285 [03:58<04:04,  1.60s/it]predicting train subjects:  47%|████▋     | 133/285 [04:00<04:09,  1.64s/it]predicting train subjects:  47%|████▋     | 134/285 [04:01<04:02,  1.61s/it]predicting train subjects:  47%|████▋     | 135/285 [04:03<03:59,  1.59s/it]predicting train subjects:  48%|████▊     | 136/285 [04:05<03:53,  1.57s/it]predicting train subjects:  48%|████▊     | 137/285 [04:06<03:59,  1.62s/it]predicting train subjects:  48%|████▊     | 138/285 [04:08<03:51,  1.58s/it]predicting train subjects:  49%|████▉     | 139/285 [04:09<03:53,  1.60s/it]predicting train subjects:  49%|████▉     | 140/285 [04:11<03:53,  1.61s/it]predicting train subjects:  49%|████▉     | 141/285 [04:13<03:50,  1.60s/it]predicting train subjects:  50%|████▉     | 142/285 [04:14<03:44,  1.57s/it]predicting train subjects:  50%|█████     | 143/285 [04:16<03:38,  1.54s/it]predicting train subjects:  51%|█████     | 144/285 [04:17<03:43,  1.59s/it]predicting train subjects:  51%|█████     | 145/285 [04:19<03:41,  1.58s/it]predicting train subjects:  51%|█████     | 146/285 [04:21<03:45,  1.62s/it]predicting train subjects:  52%|█████▏    | 147/285 [04:22<03:36,  1.57s/it]predicting train subjects:  52%|█████▏    | 148/285 [04:24<03:35,  1.57s/it]predicting train subjects:  52%|█████▏    | 149/285 [04:25<03:38,  1.61s/it]predicting train subjects:  53%|█████▎    | 150/285 [04:27<03:31,  1.56s/it]predicting train subjects:  53%|█████▎    | 151/285 [04:29<03:38,  1.63s/it]predicting train subjects:  53%|█████▎    | 152/285 [04:30<03:35,  1.62s/it]predicting train subjects:  54%|█████▎    | 153/285 [04:32<03:31,  1.60s/it]predicting train subjects:  54%|█████▍    | 154/285 [04:33<03:35,  1.65s/it]predicting train subjects:  54%|█████▍    | 155/285 [04:35<03:30,  1.62s/it]predicting train subjects:  55%|█████▍    | 156/285 [04:37<03:33,  1.65s/it]predicting train subjects:  55%|█████▌    | 157/285 [04:38<03:29,  1.63s/it]predicting train subjects:  55%|█████▌    | 158/285 [04:40<03:22,  1.59s/it]predicting train subjects:  56%|█████▌    | 159/285 [04:41<03:16,  1.56s/it]predicting train subjects:  56%|█████▌    | 160/285 [04:43<03:09,  1.52s/it]predicting train subjects:  56%|█████▋    | 161/285 [04:44<03:11,  1.55s/it]predicting train subjects:  57%|█████▋    | 162/285 [04:46<03:07,  1.52s/it]predicting train subjects:  57%|█████▋    | 163/285 [04:47<03:09,  1.56s/it]predicting train subjects:  58%|█████▊    | 164/285 [04:49<03:06,  1.54s/it]predicting train subjects:  58%|█████▊    | 165/285 [04:50<03:01,  1.51s/it]predicting train subjects:  58%|█████▊    | 166/285 [04:52<03:02,  1.53s/it]predicting train subjects:  59%|█████▊    | 167/285 [04:54<03:05,  1.57s/it]predicting train subjects:  59%|█████▉    | 168/285 [04:55<02:58,  1.52s/it]predicting train subjects:  59%|█████▉    | 169/285 [04:57<03:04,  1.59s/it]predicting train subjects:  60%|█████▉    | 170/285 [04:58<02:57,  1.55s/it]predicting train subjects:  60%|██████    | 171/285 [05:00<02:52,  1.51s/it]predicting train subjects:  60%|██████    | 172/285 [05:01<02:49,  1.50s/it]predicting train subjects:  61%|██████    | 173/285 [05:03<02:48,  1.50s/it]predicting train subjects:  61%|██████    | 174/285 [05:04<02:47,  1.51s/it]predicting train subjects:  61%|██████▏   | 175/285 [05:06<02:51,  1.56s/it]predicting train subjects:  62%|██████▏   | 176/285 [05:08<02:56,  1.62s/it]predicting train subjects:  62%|██████▏   | 177/285 [05:09<02:52,  1.59s/it]predicting train subjects:  62%|██████▏   | 178/285 [05:11<02:46,  1.55s/it]predicting train subjects:  63%|██████▎   | 179/285 [05:12<02:41,  1.52s/it]predicting train subjects:  63%|██████▎   | 180/285 [05:14<02:52,  1.65s/it]predicting train subjects:  64%|██████▎   | 181/285 [05:16<03:00,  1.73s/it]predicting train subjects:  64%|██████▍   | 182/285 [05:18<02:54,  1.70s/it]predicting train subjects:  64%|██████▍   | 183/285 [05:19<02:46,  1.63s/it]predicting train subjects:  65%|██████▍   | 184/285 [05:21<02:41,  1.60s/it]predicting train subjects:  65%|██████▍   | 185/285 [05:22<02:36,  1.57s/it]predicting train subjects:  65%|██████▌   | 186/285 [05:24<02:45,  1.67s/it]predicting train subjects:  66%|██████▌   | 187/285 [05:26<02:52,  1.76s/it]predicting train subjects:  66%|██████▌   | 188/285 [05:28<02:54,  1.80s/it]predicting train subjects:  66%|██████▋   | 189/285 [05:29<02:42,  1.69s/it]predicting train subjects:  67%|██████▋   | 190/285 [05:31<02:35,  1.64s/it]predicting train subjects:  67%|██████▋   | 191/285 [05:33<02:37,  1.68s/it]predicting train subjects:  67%|██████▋   | 192/285 [05:34<02:37,  1.70s/it]predicting train subjects:  68%|██████▊   | 193/285 [05:36<02:28,  1.61s/it]predicting train subjects:  68%|██████▊   | 194/285 [05:37<02:25,  1.60s/it]predicting train subjects:  68%|██████▊   | 195/285 [05:39<02:19,  1.55s/it]predicting train subjects:  69%|██████▉   | 196/285 [05:41<02:29,  1.68s/it]predicting train subjects:  69%|██████▉   | 197/285 [05:42<02:30,  1.71s/it]predicting train subjects:  69%|██████▉   | 198/285 [05:44<02:32,  1.75s/it]predicting train subjects:  70%|██████▉   | 199/285 [05:46<02:20,  1.63s/it]predicting train subjects:  70%|███████   | 200/285 [05:47<02:16,  1.61s/it]predicting train subjects:  71%|███████   | 201/285 [05:49<02:20,  1.67s/it]predicting train subjects:  71%|███████   | 202/285 [05:51<02:20,  1.69s/it]predicting train subjects:  71%|███████   | 203/285 [05:53<02:21,  1.72s/it]predicting train subjects:  72%|███████▏  | 204/285 [05:54<02:12,  1.64s/it]predicting train subjects:  72%|███████▏  | 205/285 [05:56<02:09,  1.62s/it]predicting train subjects:  72%|███████▏  | 206/285 [05:57<02:04,  1.58s/it]predicting train subjects:  73%|███████▎  | 207/285 [05:59<02:09,  1.66s/it]predicting train subjects:  73%|███████▎  | 208/285 [06:01<02:15,  1.75s/it]predicting train subjects:  73%|███████▎  | 209/285 [06:03<02:14,  1.78s/it]predicting train subjects:  74%|███████▎  | 210/285 [06:04<02:05,  1.68s/it]predicting train subjects:  74%|███████▍  | 211/285 [06:06<02:00,  1.62s/it]predicting train subjects:  74%|███████▍  | 212/285 [06:07<02:02,  1.68s/it]predicting train subjects:  75%|███████▍  | 213/285 [06:09<02:01,  1.68s/it]predicting train subjects:  75%|███████▌  | 214/285 [06:11<01:57,  1.65s/it]predicting train subjects:  75%|███████▌  | 215/285 [06:13<02:01,  1.74s/it]predicting train subjects:  76%|███████▌  | 216/285 [06:14<01:53,  1.64s/it]predicting train subjects:  76%|███████▌  | 217/285 [06:16<01:59,  1.76s/it]predicting train subjects:  76%|███████▋  | 218/285 [06:18<02:00,  1.79s/it]predicting train subjects:  77%|███████▋  | 219/285 [06:20<02:02,  1.86s/it]predicting train subjects:  77%|███████▋  | 220/285 [06:21<01:53,  1.74s/it]predicting train subjects:  78%|███████▊  | 221/285 [06:23<01:45,  1.64s/it]predicting train subjects:  78%|███████▊  | 222/285 [06:25<01:45,  1.67s/it]predicting train subjects:  78%|███████▊  | 223/285 [06:26<01:39,  1.60s/it]predicting train subjects:  79%|███████▊  | 224/285 [06:28<01:35,  1.56s/it]predicting train subjects:  79%|███████▉  | 225/285 [06:29<01:30,  1.50s/it]predicting train subjects:  79%|███████▉  | 226/285 [06:31<01:35,  1.63s/it]predicting train subjects:  80%|███████▉  | 227/285 [06:33<01:39,  1.71s/it]predicting train subjects:  80%|████████  | 228/285 [06:35<01:41,  1.78s/it]predicting train subjects:  80%|████████  | 229/285 [06:36<01:38,  1.75s/it]predicting train subjects:  81%|████████  | 230/285 [06:38<01:31,  1.66s/it]predicting train subjects:  81%|████████  | 231/285 [06:39<01:28,  1.64s/it]predicting train subjects:  81%|████████▏ | 232/285 [06:41<01:27,  1.65s/it]predicting train subjects:  82%|████████▏ | 233/285 [06:42<01:22,  1.59s/it]predicting train subjects:  82%|████████▏ | 234/285 [06:44<01:27,  1.71s/it]predicting train subjects:  82%|████████▏ | 235/285 [06:46<01:22,  1.65s/it]predicting train subjects:  83%|████████▎ | 236/285 [06:48<01:24,  1.72s/it]predicting train subjects:  83%|████████▎ | 237/285 [06:50<01:24,  1.76s/it]predicting train subjects:  84%|████████▎ | 238/285 [06:52<01:26,  1.83s/it]predicting train subjects:  84%|████████▍ | 239/285 [06:53<01:23,  1.81s/it]predicting train subjects:  84%|████████▍ | 240/285 [06:55<01:16,  1.69s/it]predicting train subjects:  85%|████████▍ | 241/285 [06:56<01:12,  1.65s/it]predicting train subjects:  85%|████████▍ | 242/285 [06:58<01:07,  1.58s/it]predicting train subjects:  85%|████████▌ | 243/285 [06:59<01:05,  1.56s/it]predicting train subjects:  86%|████████▌ | 244/285 [07:01<01:08,  1.67s/it]predicting train subjects:  86%|████████▌ | 245/285 [07:03<01:03,  1.59s/it]predicting train subjects:  86%|████████▋ | 246/285 [07:05<01:06,  1.71s/it]predicting train subjects:  87%|████████▋ | 247/285 [07:07<01:06,  1.76s/it]predicting train subjects:  87%|████████▋ | 248/285 [07:08<01:05,  1.77s/it]predicting train subjects:  87%|████████▋ | 249/285 [07:10<00:59,  1.66s/it]predicting train subjects:  88%|████████▊ | 250/285 [07:11<00:56,  1.63s/it]predicting train subjects:  88%|████████▊ | 251/285 [07:13<00:54,  1.59s/it]predicting train subjects:  88%|████████▊ | 252/285 [07:14<00:49,  1.51s/it]predicting train subjects:  89%|████████▉ | 253/285 [07:16<00:52,  1.63s/it]predicting train subjects:  89%|████████▉ | 254/285 [07:18<00:52,  1.70s/it]predicting train subjects:  89%|████████▉ | 255/285 [07:20<00:51,  1.71s/it]predicting train subjects:  90%|████████▉ | 256/285 [07:21<00:47,  1.64s/it]predicting train subjects:  90%|█████████ | 257/285 [07:23<00:44,  1.58s/it]predicting train subjects:  91%|█████████ | 258/285 [07:25<00:46,  1.71s/it]predicting train subjects:  91%|█████████ | 259/285 [07:26<00:45,  1.75s/it]predicting train subjects:  91%|█████████ | 260/285 [07:28<00:42,  1.68s/it]predicting train subjects:  92%|█████████▏| 261/285 [07:29<00:39,  1.63s/it]predicting train subjects:  92%|█████████▏| 262/285 [07:31<00:35,  1.56s/it]predicting train subjects:  92%|█████████▏| 263/285 [07:32<00:33,  1.53s/it]predicting train subjects:  93%|█████████▎| 264/285 [07:34<00:34,  1.64s/it]predicting train subjects:  93%|█████████▎| 265/285 [07:36<00:34,  1.71s/it]predicting train subjects:  93%|█████████▎| 266/285 [07:38<00:31,  1.66s/it]predicting train subjects:  94%|█████████▎| 267/285 [07:39<00:29,  1.65s/it]predicting train subjects:  94%|█████████▍| 268/285 [07:41<00:29,  1.73s/it]predicting train subjects:  94%|█████████▍| 269/285 [07:43<00:27,  1.71s/it]predicting train subjects:  95%|█████████▍| 270/285 [07:44<00:24,  1.62s/it]predicting train subjects:  95%|█████████▌| 271/285 [07:46<00:22,  1.62s/it]predicting train subjects:  95%|█████████▌| 272/285 [07:48<00:21,  1.68s/it]predicting train subjects:  96%|█████████▌| 273/285 [07:49<00:19,  1.64s/it]predicting train subjects:  96%|█████████▌| 274/285 [07:51<00:17,  1.57s/it]predicting train subjects:  96%|█████████▋| 275/285 [07:53<00:16,  1.68s/it]predicting train subjects:  97%|█████████▋| 276/285 [07:54<00:15,  1.75s/it]predicting train subjects:  97%|█████████▋| 277/285 [07:56<00:13,  1.66s/it]predicting train subjects:  98%|█████████▊| 278/285 [07:57<00:11,  1.63s/it]predicting train subjects:  98%|█████████▊| 279/285 [07:59<00:10,  1.67s/it]predicting train subjects:  98%|█████████▊| 280/285 [08:01<00:08,  1.62s/it]predicting train subjects:  99%|█████████▊| 281/285 [08:02<00:06,  1.57s/it]predicting train subjects:  99%|█████████▉| 282/285 [08:04<00:04,  1.52s/it]predicting train subjects:  99%|█████████▉| 283/285 [08:06<00:03,  1.64s/it]predicting train subjects: 100%|█████████▉| 284/285 [08:07<00:01,  1.72s/it]predicting train subjects: 100%|██████████| 285/285 [08:09<00:00,  1.75s/it]

